Raccogliendo 100 campioni per ogni parola con i quali sono stati testati i vari modelli (Applicando un Robust-Scaler):

- Utilizzando 5 etichette(no, ok, yes, start, stop) notiamo come i modelli non siano affatto efficenti, il migliore Ã¨ stato il Random Forest il quale ha ottenuto
un f1-score pari allo 0,65

GNB - 0,35 0,06
LR - 0,46 0,07
CART - 0,49 0,07
SVC - 0,61 0,06
RF - 0,63 0,06

- Testando i modelli con 3 etichette (tolte start e stop), le performance sono migliorate, tuttavia l'unico modello con f1-score tale da poter essere considerato
"buono" rimane il Random Forest il quale ha misurato un punteggio di 0,81



- Testando i modelli con 2 etichette(no e yes) otteniamo un miglioramento notevole in quasi tutti i modelli, i quali diventano "utilizzabili"

GNB - 0,80 0,11
LR - 0,81 0,14
CART - 0,76 0,07
SVC - 0,81 0,09
RF - 0,80 0,09
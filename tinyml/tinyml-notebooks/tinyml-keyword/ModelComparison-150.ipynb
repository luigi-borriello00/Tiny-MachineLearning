{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models Comparison for TinyML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "import numpy as np\n",
    "from numpy import arange\n",
    "import pickle\n",
    "from pandas import read_csv\n",
    "#\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#\n",
    "import pandas as pd\n",
    "from pandas import read_csv\n",
    "\n",
    "from sklearn.metrics import confusion_matrix,  classification_report, f1_score\n",
    "from sklearn.model_selection import train_test_split, KFold,StratifiedKFold, cross_val_score, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler, OneHotEncoder\n",
    "\n",
    "from keras.models import Sequential, Model \n",
    "from keras.layers import Dense, Input, concatenate, Activation, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import tensorflow\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from micromlgen import port\n",
    "import tinymlgen as tiny\n",
    "\n",
    "import warnings\n",
    "import seaborn as sbs\n",
    "import sys\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "tensorflow.random.set_seed(RANDOM_SEED)\n",
    "np.set_printoptions(threshold=sys.maxsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/X2.pkl', 'rb') as f:\n",
    "    X = pickle.load(f)\n",
    "\n",
    "with open('data/y2.pkl', 'rb') as f:\n",
    "    y = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = 2\n",
    "samples = 150\n",
    "X = X[:labels*samples]\n",
    "y = y[:labels*samples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = np.unique(y).tolist()\n",
    "for i in range(len(classes)):\n",
    "    y = np.where(y==classes[i], i, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = RobustScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90, 32)"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array(y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Spotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test options and evaluation metric\n",
    "num_folds = 10\n",
    "seed = 42\n",
    "scoring = 'f1_macro'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spot-Check Algorithms\n",
    "models = []\n",
    "\n",
    "#models.append(('XGB', XGBClassifier(random_state=seed)))\n",
    "models.append(('GNB', GaussianNB(var_smoothing=2e-9)))\n",
    "models.append(('LR', LogisticRegression(random_state=seed)))\n",
    "models.append(('CART' , DecisionTreeClassifier(random_state=seed)))\n",
    "models.append(('SVC' , SVC(gamma=0.05, random_state=seed)))\n",
    "models.append(('RF', RandomForestClassifier(random_state=seed, n_estimators = 50)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GNB - 0,51 0,09\n",
      "LR - 0,56 0,07\n",
      "CART - 0,57 0,06\n",
      "SVC - 0,69 0,08\n",
      "RF - 0,71 0,09\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "names = []\n",
    "for name, model in models:\n",
    "    # Dividere dati in n = num_folds\n",
    "    kf = StratifiedKFold(n_splits=num_folds, random_state=seed, shuffle=True)\n",
    "    cv_results = np.array([])\n",
    "    for train_idx, test_idx, in kf.split(X_train, y_train):\n",
    "        X_cross_train, y_cross_train = X_train[train_idx], y_train[train_idx]\n",
    "        X_cross_train = scaler.fit_transform(X_cross_train)\n",
    "        X_cross_test, y_cross_test = X_train[test_idx], y_train[test_idx]\n",
    "        X_cross_test = scaler.transform(X_cross_test)\n",
    "        model.fit(X_cross_train, y_cross_train)  \n",
    "        y_pred = model.predict(X_cross_test)\n",
    "        f1s = f1_score(y_cross_test, y_pred, average=\"weighted\")\n",
    "        cv_results = np.append(cv_results, [f1s])\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    #msg = \"%s - %f - %f\" % (name, cv_results.mean(), cv_results.std())\n",
    "    msg = \"{} - {:.2f} {:.2f}\".format(name, cv_results.mean(), cv_results.std()).replace('.', ',')\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compare Algorithms\n",
    "fig = plt.figure(figsize=(10,5))\n",
    "fig.suptitle('Algorithms Comparison')\n",
    "ax = fig.add_subplot(111)\n",
    "plt.boxplot(results)\n",
    "ax.set_xticklabels(names)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Valutazione dei migliori algoritmi su test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Valutazione modelli sul Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model GNB: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.36      0.13      0.20        30\n",
      "           1       0.65      0.43      0.52        30\n",
      "           2       0.42      0.83      0.56        30\n",
      "\n",
      "    accuracy                           0.47        90\n",
      "   macro avg       0.48      0.47      0.43        90\n",
      "weighted avg       0.48      0.47      0.43        90\n",
      "\n",
      "-------------------------------------------------------------\n",
      "Model LR: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.57      0.52        30\n",
      "           1       0.62      0.50      0.56        30\n",
      "           2       0.52      0.53      0.52        30\n",
      "\n",
      "    accuracy                           0.53        90\n",
      "   macro avg       0.54      0.53      0.53        90\n",
      "weighted avg       0.54      0.53      0.53        90\n",
      "\n",
      "-------------------------------------------------------------\n",
      "Model CART: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.60      0.58        30\n",
      "           1       0.50      0.57      0.53        30\n",
      "           2       0.50      0.40      0.44        30\n",
      "\n",
      "    accuracy                           0.52        90\n",
      "   macro avg       0.52      0.52      0.52        90\n",
      "weighted avg       0.52      0.52      0.52        90\n",
      "\n",
      "-------------------------------------------------------------\n",
      "Model SVC: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.60      0.65        30\n",
      "           1       0.75      0.60      0.67        30\n",
      "           2       0.59      0.80      0.68        30\n",
      "\n",
      "    accuracy                           0.67        90\n",
      "   macro avg       0.69      0.67      0.67        90\n",
      "weighted avg       0.69      0.67      0.67        90\n",
      "\n",
      "-------------------------------------------------------------\n",
      "Model RF: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.77      0.75        30\n",
      "           1       0.77      0.57      0.65        30\n",
      "           2       0.68      0.83      0.75        30\n",
      "\n",
      "    accuracy                           0.72        90\n",
      "   macro avg       0.73      0.72      0.72        90\n",
      "weighted avg       0.73      0.72      0.72        90\n",
      "\n",
      "-------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=RANDOM_SEED)\n",
    "scaler = RobustScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "for name, model in models:\n",
    "    model.fit(X_train,  y_train)\n",
    "    pred_train = model.predict(X_train)\n",
    "    pred_test = model.predict(X_test)\n",
    "    print(f\"Model {name}: \")\n",
    "    print(classification_report(y_test, pred_test))\n",
    "    print(\"-------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Sequential-NN\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_54 (Dense)             (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_55 (Dense)             (None, 15)                495       \n",
      "_________________________________________________________________\n",
      "dense_56 (Dense)             (None, 3)                 48        \n",
      "=================================================================\n",
      "Total params: 1,599\n",
      "Trainable params: 1,599\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential(name=\"Sequential-NN\")\n",
    "model.add(layers.Dense(X.shape[1], activation='relu', input_shape=(X.shape[1],)))\n",
    "model.add(layers.Dense(np.unique(y).size * 5, activation='relu'))\n",
    "model.add(layers.Dense(np.unique(y).size, activation='softmax'))\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()\n",
    "# Convert to array[int]\n",
    "y_train = np.array([int(num) for num in y_train])\n",
    "y_test = np.array([int(num) for num in y_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 1.1680 - accuracy: 0.3194\n",
      "Epoch 2/500\n",
      "12/12 [==============================] - 0s 786us/step - loss: 1.0270 - accuracy: 0.4417\n",
      "Epoch 3/500\n",
      "12/12 [==============================] - 0s 595us/step - loss: 0.9698 - accuracy: 0.4917\n",
      "Epoch 4/500\n",
      "12/12 [==============================] - 0s 644us/step - loss: 0.9353 - accuracy: 0.5472\n",
      "Epoch 5/500\n",
      "12/12 [==============================] - 0s 598us/step - loss: 0.9087 - accuracy: 0.5806\n",
      "Epoch 6/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.8867 - accuracy: 0.6028\n",
      "Epoch 7/500\n",
      "12/12 [==============================] - 0s 715us/step - loss: 0.8676 - accuracy: 0.6361\n",
      "Epoch 8/500\n",
      "12/12 [==============================] - 0s 666us/step - loss: 0.8504 - accuracy: 0.6639\n",
      "Epoch 9/500\n",
      "12/12 [==============================] - 0s 527us/step - loss: 0.8364 - accuracy: 0.6667\n",
      "Epoch 10/500\n",
      "12/12 [==============================] - 0s 820us/step - loss: 0.8230 - accuracy: 0.6778\n",
      "Epoch 11/500\n",
      "12/12 [==============================] - 0s 952us/step - loss: 0.8087 - accuracy: 0.6806\n",
      "Epoch 12/500\n",
      "12/12 [==============================] - 0s 460us/step - loss: 0.7940 - accuracy: 0.6944\n",
      "Epoch 13/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.7840 - accuracy: 0.6889\n",
      "Epoch 14/500\n",
      "12/12 [==============================] - 0s 517us/step - loss: 0.7707 - accuracy: 0.6944\n",
      "Epoch 15/500\n",
      "12/12 [==============================] - 0s 563us/step - loss: 0.7599 - accuracy: 0.7056\n",
      "Epoch 16/500\n",
      "12/12 [==============================] - 0s 623us/step - loss: 0.7500 - accuracy: 0.7028\n",
      "Epoch 17/500\n",
      "12/12 [==============================] - 0s 535us/step - loss: 0.7373 - accuracy: 0.7056\n",
      "Epoch 18/500\n",
      "12/12 [==============================] - 0s 513us/step - loss: 0.7293 - accuracy: 0.7000\n",
      "Epoch 19/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.7177 - accuracy: 0.7139\n",
      "Epoch 20/500\n",
      "12/12 [==============================] - 0s 695us/step - loss: 0.7091 - accuracy: 0.7139\n",
      "Epoch 21/500\n",
      "12/12 [==============================] - 0s 672us/step - loss: 0.6984 - accuracy: 0.7222\n",
      "Epoch 22/500\n",
      "12/12 [==============================] - 0s 731us/step - loss: 0.6890 - accuracy: 0.7278\n",
      "Epoch 23/500\n",
      "12/12 [==============================] - 0s 702us/step - loss: 0.6771 - accuracy: 0.7361\n",
      "Epoch 24/500\n",
      "12/12 [==============================] - 0s 520us/step - loss: 0.6724 - accuracy: 0.7361\n",
      "Epoch 25/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.6608 - accuracy: 0.7417\n",
      "Epoch 26/500\n",
      "12/12 [==============================] - 0s 846us/step - loss: 0.6521 - accuracy: 0.7472\n",
      "Epoch 27/500\n",
      "12/12 [==============================] - 0s 993us/step - loss: 0.6435 - accuracy: 0.7556\n",
      "Epoch 28/500\n",
      "12/12 [==============================] - 0s 905us/step - loss: 0.6336 - accuracy: 0.7694\n",
      "Epoch 29/500\n",
      "12/12 [==============================] - 0s 560us/step - loss: 0.6240 - accuracy: 0.7667\n",
      "Epoch 30/500\n",
      "12/12 [==============================] - 0s 625us/step - loss: 0.6163 - accuracy: 0.7694\n",
      "Epoch 31/500\n",
      "12/12 [==============================] - 0s 448us/step - loss: 0.6086 - accuracy: 0.7694\n",
      "Epoch 32/500\n",
      "12/12 [==============================] - 0s 612us/step - loss: 0.5992 - accuracy: 0.7750\n",
      "Epoch 33/500\n",
      "12/12 [==============================] - 0s 500us/step - loss: 0.5937 - accuracy: 0.7722\n",
      "Epoch 34/500\n",
      "12/12 [==============================] - 0s 604us/step - loss: 0.5845 - accuracy: 0.7833\n",
      "Epoch 35/500\n",
      "12/12 [==============================] - 0s 666us/step - loss: 0.5753 - accuracy: 0.7806\n",
      "Epoch 36/500\n",
      "12/12 [==============================] - 0s 669us/step - loss: 0.5691 - accuracy: 0.7944\n",
      "Epoch 37/500\n",
      "12/12 [==============================] - 0s 763us/step - loss: 0.5638 - accuracy: 0.7833\n",
      "Epoch 38/500\n",
      "12/12 [==============================] - 0s 587us/step - loss: 0.5541 - accuracy: 0.8028\n",
      "Epoch 39/500\n",
      "12/12 [==============================] - 0s 651us/step - loss: 0.5501 - accuracy: 0.7944\n",
      "Epoch 40/500\n",
      "12/12 [==============================] - 0s 476us/step - loss: 0.5409 - accuracy: 0.8056\n",
      "Epoch 41/500\n",
      "12/12 [==============================] - 0s 693us/step - loss: 0.5314 - accuracy: 0.8111\n",
      "Epoch 42/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.5261 - accuracy: 0.8139\n",
      "Epoch 43/500\n",
      "12/12 [==============================] - 0s 804us/step - loss: 0.5200 - accuracy: 0.8111\n",
      "Epoch 44/500\n",
      "12/12 [==============================] - 0s 470us/step - loss: 0.5122 - accuracy: 0.8167\n",
      "Epoch 45/500\n",
      "12/12 [==============================] - 0s 667us/step - loss: 0.5070 - accuracy: 0.8167\n",
      "Epoch 46/500\n",
      "12/12 [==============================] - 0s 925us/step - loss: 0.5007 - accuracy: 0.8194\n",
      "Epoch 47/500\n",
      "12/12 [==============================] - 0s 733us/step - loss: 0.4947 - accuracy: 0.8250\n",
      "Epoch 48/500\n",
      "12/12 [==============================] - 0s 997us/step - loss: 0.4877 - accuracy: 0.8250\n",
      "Epoch 49/500\n",
      "12/12 [==============================] - 0s 442us/step - loss: 0.4839 - accuracy: 0.8333\n",
      "Epoch 50/500\n",
      "12/12 [==============================] - 0s 652us/step - loss: 0.4806 - accuracy: 0.8222\n",
      "Epoch 51/500\n",
      "12/12 [==============================] - 0s 487us/step - loss: 0.4763 - accuracy: 0.8306\n",
      "Epoch 52/500\n",
      "12/12 [==============================] - 0s 667us/step - loss: 0.4731 - accuracy: 0.8167\n",
      "Epoch 53/500\n",
      "12/12 [==============================] - 0s 667us/step - loss: 0.4640 - accuracy: 0.8306\n",
      "Epoch 54/500\n",
      "12/12 [==============================] - 0s 893us/step - loss: 0.4568 - accuracy: 0.8417\n",
      "Epoch 55/500\n",
      "12/12 [==============================] - 0s 669us/step - loss: 0.4524 - accuracy: 0.8444\n",
      "Epoch 56/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4479 - accuracy: 0.8500\n",
      "Epoch 57/500\n",
      "12/12 [==============================] - 0s 339us/step - loss: 0.4415 - accuracy: 0.8528\n",
      "Epoch 58/500\n",
      "12/12 [==============================] - 0s 545us/step - loss: 0.4375 - accuracy: 0.8583\n",
      "Epoch 59/500\n",
      "12/12 [==============================] - 0s 577us/step - loss: 0.4329 - accuracy: 0.8528\n",
      "Epoch 60/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4274 - accuracy: 0.8611\n",
      "Epoch 61/500\n",
      "12/12 [==============================] - 0s 485us/step - loss: 0.4238 - accuracy: 0.8583\n",
      "Epoch 62/500\n",
      "12/12 [==============================] - 0s 646us/step - loss: 0.4185 - accuracy: 0.8667\n",
      "Epoch 63/500\n",
      "12/12 [==============================] - 0s 712us/step - loss: 0.4134 - accuracy: 0.8667\n",
      "Epoch 64/500\n",
      "12/12 [==============================] - 0s 689us/step - loss: 0.4113 - accuracy: 0.8639\n",
      "Epoch 65/500\n",
      "12/12 [==============================] - 0s 753us/step - loss: 0.4066 - accuracy: 0.8639\n",
      "Epoch 66/500\n",
      "12/12 [==============================] - 0s 694us/step - loss: 0.4012 - accuracy: 0.8694\n",
      "Epoch 67/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4006 - accuracy: 0.8667\n",
      "Epoch 68/500\n",
      "12/12 [==============================] - 0s 879us/step - loss: 0.3955 - accuracy: 0.8722\n",
      "Epoch 69/500\n",
      "12/12 [==============================] - 0s 667us/step - loss: 0.3903 - accuracy: 0.8667\n",
      "Epoch 70/500\n",
      "12/12 [==============================] - 0s 447us/step - loss: 0.3828 - accuracy: 0.8750\n",
      "Epoch 71/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.3810 - accuracy: 0.8667\n",
      "Epoch 72/500\n",
      "12/12 [==============================] - 0s 815us/step - loss: 0.3746 - accuracy: 0.8806\n",
      "Epoch 73/500\n",
      "12/12 [==============================] - 0s 667us/step - loss: 0.3718 - accuracy: 0.8778\n",
      "Epoch 74/500\n",
      "12/12 [==============================] - 0s 667us/step - loss: 0.3692 - accuracy: 0.8750\n",
      "Epoch 75/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.3655 - accuracy: 0.8806\n",
      "Epoch 76/500\n",
      "12/12 [==============================] - 0s 771us/step - loss: 0.3594 - accuracy: 0.8861\n",
      "Epoch 77/500\n",
      "12/12 [==============================] - 0s 633us/step - loss: 0.3556 - accuracy: 0.8806\n",
      "Epoch 78/500\n",
      "12/12 [==============================] - 0s 410us/step - loss: 0.3530 - accuracy: 0.8806\n",
      "Epoch 79/500\n",
      "12/12 [==============================] - 0s 678us/step - loss: 0.3495 - accuracy: 0.8944\n",
      "Epoch 80/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.3468 - accuracy: 0.8889\n",
      "Epoch 81/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 701us/step - loss: 0.3418 - accuracy: 0.8889\n",
      "Epoch 82/500\n",
      "12/12 [==============================] - 0s 826us/step - loss: 0.3376 - accuracy: 0.8889\n",
      "Epoch 83/500\n",
      "12/12 [==============================] - 0s 342us/step - loss: 0.3349 - accuracy: 0.8917\n",
      "Epoch 84/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.3295 - accuracy: 0.8917\n",
      "Epoch 85/500\n",
      "12/12 [==============================] - 0s 581us/step - loss: 0.3274 - accuracy: 0.8972\n",
      "Epoch 86/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.3275 - accuracy: 0.9083\n",
      "Epoch 87/500\n",
      "12/12 [==============================] - 0s 493us/step - loss: 0.3260 - accuracy: 0.8917\n",
      "Epoch 88/500\n",
      "12/12 [==============================] - 0s 943us/step - loss: 0.3172 - accuracy: 0.9028\n",
      "Epoch 89/500\n",
      "12/12 [==============================] - 0s 351us/step - loss: 0.3141 - accuracy: 0.9111\n",
      "Epoch 90/500\n",
      "12/12 [==============================] - 0s 762us/step - loss: 0.3091 - accuracy: 0.9028\n",
      "Epoch 91/500\n",
      "12/12 [==============================] - 0s 917us/step - loss: 0.3080 - accuracy: 0.9000\n",
      "Epoch 92/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.3042 - accuracy: 0.9028\n",
      "Epoch 93/500\n",
      "12/12 [==============================] - 0s 551us/step - loss: 0.3024 - accuracy: 0.9083\n",
      "Epoch 94/500\n",
      "12/12 [==============================] - 0s 766us/step - loss: 0.3007 - accuracy: 0.9083\n",
      "Epoch 95/500\n",
      "12/12 [==============================] - 0s 475us/step - loss: 0.2960 - accuracy: 0.9111\n",
      "Epoch 96/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.2909 - accuracy: 0.9111\n",
      "Epoch 97/500\n",
      "12/12 [==============================] - 0s 516us/step - loss: 0.2871 - accuracy: 0.9139\n",
      "Epoch 98/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.2838 - accuracy: 0.9111\n",
      "Epoch 99/500\n",
      "12/12 [==============================] - 0s 581us/step - loss: 0.2830 - accuracy: 0.9139\n",
      "Epoch 100/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.2779 - accuracy: 0.9167\n",
      "Epoch 101/500\n",
      "12/12 [==============================] - 0s 510us/step - loss: 0.2754 - accuracy: 0.9167\n",
      "Epoch 102/500\n",
      "12/12 [==============================] - 0s 815us/step - loss: 0.2747 - accuracy: 0.9111\n",
      "Epoch 103/500\n",
      "12/12 [==============================] - 0s 368us/step - loss: 0.2715 - accuracy: 0.9167\n",
      "Epoch 104/500\n",
      "12/12 [==============================] - 0s 210us/step - loss: 0.2692 - accuracy: 0.9222\n",
      "Epoch 105/500\n",
      "12/12 [==============================] - 0s 532us/step - loss: 0.2660 - accuracy: 0.9250\n",
      "Epoch 106/500\n",
      "12/12 [==============================] - 0s 714us/step - loss: 0.2657 - accuracy: 0.9139\n",
      "Epoch 107/500\n",
      "12/12 [==============================] - 0s 667us/step - loss: 0.2595 - accuracy: 0.9167\n",
      "Epoch 108/500\n",
      "12/12 [==============================] - 0s 310us/step - loss: 0.2579 - accuracy: 0.9111\n",
      "Epoch 109/500\n",
      "12/12 [==============================] - 0s 981us/step - loss: 0.2538 - accuracy: 0.9222\n",
      "Epoch 110/500\n",
      "12/12 [==============================] - 0s 672us/step - loss: 0.2533 - accuracy: 0.9167\n",
      "Epoch 111/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.2506 - accuracy: 0.9250\n",
      "Epoch 112/500\n",
      "12/12 [==============================] - 0s 574us/step - loss: 0.2468 - accuracy: 0.9194\n",
      "Epoch 113/500\n",
      "12/12 [==============================] - 0s 632us/step - loss: 0.2446 - accuracy: 0.9278\n",
      "Epoch 114/500\n",
      "12/12 [==============================] - 0s 486us/step - loss: 0.2408 - accuracy: 0.9278\n",
      "Epoch 115/500\n",
      "12/12 [==============================] - 0s 751us/step - loss: 0.2372 - accuracy: 0.9278\n",
      "Epoch 116/500\n",
      "12/12 [==============================] - 0s 467us/step - loss: 0.2361 - accuracy: 0.9278\n",
      "Epoch 117/500\n",
      "12/12 [==============================] - 0s 833us/step - loss: 0.2329 - accuracy: 0.9278\n",
      "Epoch 118/500\n",
      "12/12 [==============================] - 0s 425us/step - loss: 0.2343 - accuracy: 0.9194\n",
      "Epoch 119/500\n",
      "12/12 [==============================] - 0s 897us/step - loss: 0.2297 - accuracy: 0.9250\n",
      "Epoch 120/500\n",
      "12/12 [==============================] - 0s 361us/step - loss: 0.2245 - accuracy: 0.9250\n",
      "Epoch 121/500\n",
      "12/12 [==============================] - 0s 774us/step - loss: 0.2249 - accuracy: 0.9250\n",
      "Epoch 122/500\n",
      "12/12 [==============================] - 0s 314us/step - loss: 0.2169 - accuracy: 0.9333\n",
      "Epoch 123/500\n",
      "12/12 [==============================] - 0s 980us/step - loss: 0.2187 - accuracy: 0.9306\n",
      "Epoch 124/500\n",
      "12/12 [==============================] - 0s 729us/step - loss: 0.2152 - accuracy: 0.9333\n",
      "Epoch 125/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.2135 - accuracy: 0.9333\n",
      "Epoch 126/500\n",
      "12/12 [==============================] - 0s 627us/step - loss: 0.2100 - accuracy: 0.9278\n",
      "Epoch 127/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.2077 - accuracy: 0.9333\n",
      "Epoch 128/500\n",
      "12/12 [==============================] - 0s 806us/step - loss: 0.2043 - accuracy: 0.9333\n",
      "Epoch 129/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.2043 - accuracy: 0.9389\n",
      "Epoch 130/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1994 - accuracy: 0.9389\n",
      "Epoch 131/500\n",
      "12/12 [==============================] - 0s 709us/step - loss: 0.1993 - accuracy: 0.9389\n",
      "Epoch 132/500\n",
      "12/12 [==============================] - 0s 338us/step - loss: 0.1944 - accuracy: 0.9389\n",
      "Epoch 133/500\n",
      "12/12 [==============================] - 0s 432us/step - loss: 0.1953 - accuracy: 0.9472\n",
      "Epoch 134/500\n",
      "12/12 [==============================] - 0s 770us/step - loss: 0.1897 - accuracy: 0.9472\n",
      "Epoch 135/500\n",
      "12/12 [==============================] - 0s 401us/step - loss: 0.1886 - accuracy: 0.9333\n",
      "Epoch 136/500\n",
      "12/12 [==============================] - 0s 835us/step - loss: 0.1847 - accuracy: 0.9417\n",
      "Epoch 137/500\n",
      "12/12 [==============================] - 0s 436us/step - loss: 0.1852 - accuracy: 0.9500\n",
      "Epoch 138/500\n",
      "12/12 [==============================] - 0s 779us/step - loss: 0.1800 - accuracy: 0.9500\n",
      "Epoch 139/500\n",
      "12/12 [==============================] - 0s 373us/step - loss: 0.1810 - accuracy: 0.9528\n",
      "Epoch 140/500\n",
      "12/12 [==============================] - 0s 838us/step - loss: 0.1777 - accuracy: 0.9500\n",
      "Epoch 141/500\n",
      "12/12 [==============================] - 0s 355us/step - loss: 0.1736 - accuracy: 0.9500\n",
      "Epoch 142/500\n",
      "12/12 [==============================] - 0s 865us/step - loss: 0.1707 - accuracy: 0.9556\n",
      "Epoch 143/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1697 - accuracy: 0.9500\n",
      "Epoch 144/500\n",
      "12/12 [==============================] - 0s 676us/step - loss: 0.1669 - accuracy: 0.9528\n",
      "Epoch 145/500\n",
      "12/12 [==============================] - 0s 424us/step - loss: 0.1659 - accuracy: 0.9528\n",
      "Epoch 146/500\n",
      "12/12 [==============================] - 0s 229us/step - loss: 0.1648 - accuracy: 0.9500\n",
      "Epoch 147/500\n",
      "12/12 [==============================] - 0s 153us/step - loss: 0.1616 - accuracy: 0.9611\n",
      "Epoch 148/500\n",
      "12/12 [==============================] - 0s 456us/step - loss: 0.1598 - accuracy: 0.9639\n",
      "Epoch 149/500\n",
      "12/12 [==============================] - 0s 727us/step - loss: 0.1585 - accuracy: 0.9556\n",
      "Epoch 150/500\n",
      "12/12 [==============================] - 0s 402us/step - loss: 0.1556 - accuracy: 0.9583\n",
      "Epoch 151/500\n",
      "12/12 [==============================] - 0s 757us/step - loss: 0.1537 - accuracy: 0.9639\n",
      "Epoch 152/500\n",
      "12/12 [==============================] - 0s 419us/step - loss: 0.1530 - accuracy: 0.9667\n",
      "Epoch 153/500\n",
      "12/12 [==============================] - 0s 763us/step - loss: 0.1519 - accuracy: 0.9667\n",
      "Epoch 154/500\n",
      "12/12 [==============================] - 0s 358us/step - loss: 0.1481 - accuracy: 0.9667\n",
      "Epoch 155/500\n",
      "12/12 [==============================] - 0s 748us/step - loss: 0.1467 - accuracy: 0.9667\n",
      "Epoch 156/500\n",
      "12/12 [==============================] - 0s 317us/step - loss: 0.1434 - accuracy: 0.9750\n",
      "Epoch 157/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1428 - accuracy: 0.9778\n",
      "Epoch 158/500\n",
      "12/12 [==============================] - 0s 508us/step - loss: 0.1424 - accuracy: 0.9694\n",
      "Epoch 159/500\n",
      "12/12 [==============================] - 0s 622us/step - loss: 0.1398 - accuracy: 0.9667\n",
      "Epoch 160/500\n",
      "12/12 [==============================] - 0s 408us/step - loss: 0.1378 - accuracy: 0.9861\n",
      "Epoch 161/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1391 - accuracy: 0.9806\n",
      "Epoch 162/500\n",
      "12/12 [==============================] - 0s 352us/step - loss: 0.1395 - accuracy: 0.9722\n",
      "Epoch 163/500\n",
      "12/12 [==============================] - 0s 638us/step - loss: 0.1332 - accuracy: 0.9694\n",
      "Epoch 164/500\n",
      "12/12 [==============================] - 0s 350us/step - loss: 0.1301 - accuracy: 0.9750\n",
      "Epoch 165/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1301 - accuracy: 0.9833\n",
      "Epoch 166/500\n",
      "12/12 [==============================] - 0s 595us/step - loss: 0.1323 - accuracy: 0.9778\n",
      "Epoch 167/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1287 - accuracy: 0.9694\n",
      "Epoch 168/500\n",
      "12/12 [==============================] - 0s 552us/step - loss: 0.1263 - accuracy: 0.9750\n",
      "Epoch 169/500\n",
      "12/12 [==============================] - 0s 878us/step - loss: 0.1239 - accuracy: 0.9833\n",
      "Epoch 170/500\n",
      "12/12 [==============================] - 0s 490us/step - loss: 0.1213 - accuracy: 0.9861\n",
      "Epoch 171/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1204 - accuracy: 0.9833\n",
      "Epoch 172/500\n",
      "12/12 [==============================] - 0s 297us/step - loss: 0.1192 - accuracy: 0.9861\n",
      "Epoch 173/500\n",
      "12/12 [==============================] - 0s 532us/step - loss: 0.1182 - accuracy: 0.9889\n",
      "Epoch 174/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1170 - accuracy: 0.9861\n",
      "Epoch 175/500\n",
      "12/12 [==============================] - 0s 490us/step - loss: 0.1150 - accuracy: 0.9806\n",
      "Epoch 176/500\n",
      "12/12 [==============================] - 0s 803us/step - loss: 0.1155 - accuracy: 0.9833\n",
      "Epoch 177/500\n",
      "12/12 [==============================] - 0s 667us/step - loss: 0.1122 - accuracy: 0.9889\n",
      "Epoch 178/500\n",
      "12/12 [==============================] - 0s 666us/step - loss: 0.1121 - accuracy: 0.9806\n",
      "Epoch 179/500\n",
      "12/12 [==============================] - 0s 395us/step - loss: 0.1109 - accuracy: 0.9778\n",
      "Epoch 180/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1096 - accuracy: 0.9861\n",
      "Epoch 181/500\n",
      "12/12 [==============================] - 0s 380us/step - loss: 0.1074 - accuracy: 0.9889\n",
      "Epoch 182/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1050 - accuracy: 0.9889\n",
      "Epoch 183/500\n",
      "12/12 [==============================] - 0s 627us/step - loss: 0.1037 - accuracy: 0.9889\n",
      "Epoch 184/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1013 - accuracy: 0.9917\n",
      "Epoch 185/500\n",
      "12/12 [==============================] - 0s 420us/step - loss: 0.1001 - accuracy: 0.9917\n",
      "Epoch 186/500\n",
      "12/12 [==============================] - 0s 955us/step - loss: 0.0992 - accuracy: 0.9889\n",
      "Epoch 187/500\n",
      "12/12 [==============================] - 0s 303us/step - loss: 0.1004 - accuracy: 0.9944\n",
      "Epoch 188/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1006 - accuracy: 0.9917\n",
      "Epoch 189/500\n",
      "12/12 [==============================] - 0s 638us/step - loss: 0.1049 - accuracy: 0.9861\n",
      "Epoch 190/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1492 - accuracy: 0.9639\n",
      "Epoch 191/500\n",
      "12/12 [==============================] - 0s 511us/step - loss: 0.1536 - accuracy: 0.9639\n",
      "Epoch 192/500\n",
      "12/12 [==============================] - 0s 810us/step - loss: 0.1367 - accuracy: 0.9694\n",
      "Epoch 193/500\n",
      "12/12 [==============================] - 0s 431us/step - loss: 0.1225 - accuracy: 0.9806\n",
      "Epoch 194/500\n",
      "12/12 [==============================] - 0s 760us/step - loss: 0.1123 - accuracy: 0.9833\n",
      "Epoch 195/500\n",
      "12/12 [==============================] - 0s 667us/step - loss: 0.1026 - accuracy: 0.9833\n",
      "Epoch 196/500\n",
      "12/12 [==============================] - 0s 325us/step - loss: 0.1015 - accuracy: 0.9917\n",
      "Epoch 197/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0956 - accuracy: 0.9917\n",
      "Epoch 198/500\n",
      "12/12 [==============================] - 0s 608us/step - loss: 0.0929 - accuracy: 0.9917\n",
      "Epoch 199/500\n",
      "12/12 [==============================] - 0s 604us/step - loss: 0.0911 - accuracy: 0.9944\n",
      "Epoch 200/500\n",
      "12/12 [==============================] - 0s 482us/step - loss: 0.0893 - accuracy: 0.9944\n",
      "Epoch 201/500\n",
      "12/12 [==============================] - 0s 584us/step - loss: 0.0878 - accuracy: 0.9944\n",
      "Epoch 202/500\n",
      "12/12 [==============================] - 0s 488us/step - loss: 0.0869 - accuracy: 0.9944\n",
      "Epoch 203/500\n",
      "12/12 [==============================] - 0s 762us/step - loss: 0.0856 - accuracy: 0.9944\n",
      "Epoch 204/500\n",
      "12/12 [==============================] - 0s 461us/step - loss: 0.0854 - accuracy: 0.9944\n",
      "Epoch 205/500\n",
      "12/12 [==============================] - 0s 817us/step - loss: 0.0839 - accuracy: 0.9972\n",
      "Epoch 206/500\n",
      "12/12 [==============================] - 0s 359us/step - loss: 0.0823 - accuracy: 0.9944\n",
      "Epoch 207/500\n",
      "12/12 [==============================] - 0s 889us/step - loss: 0.0873 - accuracy: 0.9889\n",
      "Epoch 208/500\n",
      "12/12 [==============================] - 0s 376us/step - loss: 0.0825 - accuracy: 0.9944\n",
      "Epoch 209/500\n",
      "12/12 [==============================] - 0s 901us/step - loss: 0.0800 - accuracy: 0.9944\n",
      "Epoch 210/500\n",
      "12/12 [==============================] - 0s 303us/step - loss: 0.0793 - accuracy: 0.9944\n",
      "Epoch 211/500\n",
      "12/12 [==============================] - 0s 967us/step - loss: 0.0774 - accuracy: 0.9944\n",
      "Epoch 212/500\n",
      "12/12 [==============================] - 0s 686us/step - loss: 0.0756 - accuracy: 0.9917\n",
      "Epoch 213/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0752 - accuracy: 0.9944\n",
      "Epoch 214/500\n",
      "12/12 [==============================] - 0s 678us/step - loss: 0.0742 - accuracy: 0.9944\n",
      "Epoch 215/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0743 - accuracy: 0.9972\n",
      "Epoch 216/500\n",
      "12/12 [==============================] - 0s 455us/step - loss: 0.0721 - accuracy: 0.9972\n",
      "Epoch 217/500\n",
      "12/12 [==============================] - 0s 856us/step - loss: 0.0722 - accuracy: 0.9944\n",
      "Epoch 218/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0727 - accuracy: 0.9972\n",
      "Epoch 219/500\n",
      "12/12 [==============================] - 0s 752us/step - loss: 0.0702 - accuracy: 0.9972\n",
      "Epoch 220/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0700 - accuracy: 0.9944\n",
      "Epoch 221/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0690 - accuracy: 0.9944\n",
      "Epoch 222/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0671 - accuracy: 0.9972\n",
      "Epoch 223/500\n",
      "12/12 [==============================] - 0s 603us/step - loss: 0.0690 - accuracy: 0.9944\n",
      "Epoch 224/500\n",
      "12/12 [==============================] - 0s 741us/step - loss: 0.0664 - accuracy: 0.9972\n",
      "Epoch 225/500\n",
      "12/12 [==============================] - 0s 667us/step - loss: 0.0654 - accuracy: 0.9944\n",
      "Epoch 226/500\n",
      "12/12 [==============================] - 0s 322us/step - loss: 0.0650 - accuracy: 0.9972\n",
      "Epoch 227/500\n",
      "12/12 [==============================] - 0s 579us/step - loss: 0.0645 - accuracy: 0.9944\n",
      "Epoch 228/500\n",
      "12/12 [==============================] - 0s 540us/step - loss: 0.0640 - accuracy: 0.9972\n",
      "Epoch 229/500\n",
      "12/12 [==============================] - 0s 667us/step - loss: 0.0628 - accuracy: 0.9972\n",
      "Epoch 230/500\n",
      "12/12 [==============================] - 0s 299us/step - loss: 0.0626 - accuracy: 0.9972\n",
      "Epoch 231/500\n",
      "12/12 [==============================] - 0s 624us/step - loss: 0.0615 - accuracy: 0.9972\n",
      "Epoch 232/500\n",
      "12/12 [==============================] - 0s 445us/step - loss: 0.0616 - accuracy: 0.9972\n",
      "Epoch 233/500\n",
      "12/12 [==============================] - 0s 702us/step - loss: 0.0602 - accuracy: 0.9972\n",
      "Epoch 234/500\n",
      "12/12 [==============================] - 0s 377us/step - loss: 0.0590 - accuracy: 0.9972\n",
      "Epoch 235/500\n",
      "12/12 [==============================] - 0s 605us/step - loss: 0.0590 - accuracy: 0.9972\n",
      "Epoch 236/500\n",
      "12/12 [==============================] - 0s 377us/step - loss: 0.0586 - accuracy: 0.9972\n",
      "Epoch 237/500\n",
      "12/12 [==============================] - 0s 805us/step - loss: 0.0571 - accuracy: 0.9972\n",
      "Epoch 238/500\n",
      "12/12 [==============================] - 0s 855us/step - loss: 0.0581 - accuracy: 0.9972\n",
      "Epoch 239/500\n",
      "12/12 [==============================] - 0s 877us/step - loss: 0.0569 - accuracy: 0.9972\n",
      "Epoch 240/500\n",
      "12/12 [==============================] - 0s 778us/step - loss: 0.0566 - accuracy: 0.9972\n",
      "Epoch 241/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 957us/step - loss: 0.0551 - accuracy: 0.9972\n",
      "Epoch 242/500\n",
      "12/12 [==============================] - 0s 705us/step - loss: 0.0547 - accuracy: 0.9972\n",
      "Epoch 243/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0546 - accuracy: 0.9972\n",
      "Epoch 244/500\n",
      "12/12 [==============================] - 0s 667us/step - loss: 0.0532 - accuracy: 0.9972\n",
      "Epoch 245/500\n",
      "12/12 [==============================] - 0s 807us/step - loss: 0.0559 - accuracy: 0.9972\n",
      "Epoch 246/500\n",
      "12/12 [==============================] - 0s 340us/step - loss: 0.0543 - accuracy: 0.9972\n",
      "Epoch 247/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0524 - accuracy: 0.9972\n",
      "Epoch 248/500\n",
      "12/12 [==============================] - 0s 369us/step - loss: 0.0517 - accuracy: 0.9972\n",
      "Epoch 249/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0508 - accuracy: 0.9972\n",
      "Epoch 250/500\n",
      "12/12 [==============================] - 0s 378us/step - loss: 0.0499 - accuracy: 0.9972\n",
      "Epoch 251/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0494 - accuracy: 0.9972\n",
      "Epoch 252/500\n",
      "12/12 [==============================] - 0s 540us/step - loss: 0.0498 - accuracy: 0.9972\n",
      "Epoch 253/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0496 - accuracy: 0.9972\n",
      "Epoch 254/500\n",
      "12/12 [==============================] - 0s 423us/step - loss: 0.0491 - accuracy: 0.9972\n",
      "Epoch 255/500\n",
      "12/12 [==============================] - 0s 810us/step - loss: 0.0481 - accuracy: 0.9972\n",
      "Epoch 256/500\n",
      "12/12 [==============================] - 0s 463us/step - loss: 0.0474 - accuracy: 0.9972\n",
      "Epoch 257/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0462 - accuracy: 0.9972\n",
      "Epoch 258/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0467 - accuracy: 0.9972\n",
      "Epoch 259/500\n",
      "12/12 [==============================] - 0s 565us/step - loss: 0.0456 - accuracy: 0.9972\n",
      "Epoch 260/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0449 - accuracy: 0.9972\n",
      "Epoch 261/500\n",
      "12/12 [==============================] - 0s 565us/step - loss: 0.0450 - accuracy: 0.9972\n",
      "Epoch 262/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0443 - accuracy: 0.9972\n",
      "Epoch 263/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0430 - accuracy: 0.9972\n",
      "Epoch 264/500\n",
      "12/12 [==============================] - 0s 444us/step - loss: 0.0437 - accuracy: 0.9972\n",
      "Epoch 265/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0427 - accuracy: 0.9972\n",
      "Epoch 266/500\n",
      "12/12 [==============================] - 0s 541us/step - loss: 0.0427 - accuracy: 0.9972\n",
      "Epoch 267/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0414 - accuracy: 0.9972\n",
      "Epoch 268/500\n",
      "12/12 [==============================] - 0s 574us/step - loss: 0.0410 - accuracy: 0.9972\n",
      "Epoch 269/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0404 - accuracy: 0.9972\n",
      "Epoch 270/500\n",
      "12/12 [==============================] - 0s 340us/step - loss: 0.0409 - accuracy: 0.9972\n",
      "Epoch 271/500\n",
      "12/12 [==============================] - 0s 284us/step - loss: 0.0400 - accuracy: 0.9972\n",
      "Epoch 272/500\n",
      "12/12 [==============================] - 0s 438us/step - loss: 0.0396 - accuracy: 0.9972\n",
      "Epoch 273/500\n",
      "12/12 [==============================] - 0s 869us/step - loss: 0.0391 - accuracy: 0.9972\n",
      "Epoch 274/500\n",
      "12/12 [==============================] - 0s 291us/step - loss: 0.0388 - accuracy: 0.9972\n",
      "Epoch 275/500\n",
      "12/12 [==============================] - 0s 667us/step - loss: 0.0380 - accuracy: 0.9972\n",
      "Epoch 276/500\n",
      "12/12 [==============================] - 0s 667us/step - loss: 0.0378 - accuracy: 0.9972\n",
      "Epoch 277/500\n",
      "12/12 [==============================] - 0s 539us/step - loss: 0.0383 - accuracy: 0.9972\n",
      "Epoch 278/500\n",
      "12/12 [==============================] - 0s 756us/step - loss: 0.0382 - accuracy: 0.9972\n",
      "Epoch 279/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0378 - accuracy: 0.9972\n",
      "Epoch 280/500\n",
      "12/12 [==============================] - 0s 399us/step - loss: 0.0369 - accuracy: 0.9972\n",
      "Epoch 281/500\n",
      "12/12 [==============================] - 0s 487us/step - loss: 0.0369 - accuracy: 0.9972\n",
      "Epoch 282/500\n",
      "12/12 [==============================] - 0s 695us/step - loss: 0.0359 - accuracy: 0.9972\n",
      "Epoch 283/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0362 - accuracy: 1.0000\n",
      "Epoch 284/500\n",
      "12/12 [==============================] - 0s 410us/step - loss: 0.0360 - accuracy: 1.0000\n",
      "Epoch 285/500\n",
      "12/12 [==============================] - 0s 537us/step - loss: 0.0345 - accuracy: 1.0000\n",
      "Epoch 286/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0339 - accuracy: 0.9972\n",
      "Epoch 287/500\n",
      "12/12 [==============================] - 0s 168us/step - loss: 0.0349 - accuracy: 0.9972\n",
      "Epoch 288/500\n",
      "12/12 [==============================] - 0s 264us/step - loss: 0.0337 - accuracy: 0.9972\n",
      "Epoch 289/500\n",
      "12/12 [==============================] - 0s 615us/step - loss: 0.0327 - accuracy: 0.9972\n",
      "Epoch 290/500\n",
      "12/12 [==============================] - 0s 368us/step - loss: 0.0350 - accuracy: 0.9972\n",
      "Epoch 291/500\n",
      "12/12 [==============================] - 0s 637us/step - loss: 0.0326 - accuracy: 0.9972\n",
      "Epoch 292/500\n",
      "12/12 [==============================] - 0s 258us/step - loss: 0.0324 - accuracy: 1.0000\n",
      "Epoch 293/500\n",
      "12/12 [==============================] - 0s 767us/step - loss: 0.0323 - accuracy: 0.9972\n",
      "Epoch 294/500\n",
      "12/12 [==============================] - 0s 474us/step - loss: 0.0312 - accuracy: 0.9972\n",
      "Epoch 295/500\n",
      "12/12 [==============================] - 0s 601us/step - loss: 0.0328 - accuracy: 1.0000\n",
      "Epoch 296/500\n",
      "12/12 [==============================] - 0s 464us/step - loss: 0.0324 - accuracy: 1.0000\n",
      "Epoch 297/500\n",
      "12/12 [==============================] - 0s 796us/step - loss: 0.0312 - accuracy: 1.0000\n",
      "Epoch 298/500\n",
      "12/12 [==============================] - 0s 427us/step - loss: 0.0305 - accuracy: 1.0000\n",
      "Epoch 299/500\n",
      "12/12 [==============================] - 0s 842us/step - loss: 0.0303 - accuracy: 1.0000\n",
      "Epoch 300/500\n",
      "12/12 [==============================] - 0s 363us/step - loss: 0.0299 - accuracy: 0.9972\n",
      "Epoch 301/500\n",
      "12/12 [==============================] - 0s 874us/step - loss: 0.0292 - accuracy: 1.0000\n",
      "Epoch 302/500\n",
      "12/12 [==============================] - 0s 785us/step - loss: 0.0286 - accuracy: 1.0000\n",
      "Epoch 303/500\n",
      "12/12 [==============================] - 0s 946us/step - loss: 0.0296 - accuracy: 0.9972\n",
      "Epoch 304/500\n",
      "12/12 [==============================] - 0s 728us/step - loss: 0.0282 - accuracy: 1.0000\n",
      "Epoch 305/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0283 - accuracy: 1.0000\n",
      "Epoch 306/500\n",
      "12/12 [==============================] - 0s 684us/step - loss: 0.0287 - accuracy: 0.9972\n",
      "Epoch 307/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0279 - accuracy: 1.0000\n",
      "Epoch 308/500\n",
      "12/12 [==============================] - 0s 614us/step - loss: 0.0272 - accuracy: 1.0000\n",
      "Epoch 309/500\n",
      "12/12 [==============================] - 0s 699us/step - loss: 0.0269 - accuracy: 0.9972\n",
      "Epoch 310/500\n",
      "12/12 [==============================] - 0s 667us/step - loss: 0.0265 - accuracy: 1.0000\n",
      "Epoch 311/500\n",
      "12/12 [==============================] - 0s 373us/step - loss: 0.0264 - accuracy: 1.0000\n",
      "Epoch 312/500\n",
      "12/12 [==============================] - 0s 612us/step - loss: 0.0259 - accuracy: 1.0000\n",
      "Epoch 313/500\n",
      "12/12 [==============================] - 0s 603us/step - loss: 0.0261 - accuracy: 0.9972\n",
      "Epoch 314/500\n",
      "12/12 [==============================] - 0s 667us/step - loss: 0.0257 - accuracy: 1.0000\n",
      "Epoch 315/500\n",
      "12/12 [==============================] - 0s 269us/step - loss: 0.0255 - accuracy: 1.0000\n",
      "Epoch 316/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0254 - accuracy: 0.9972\n",
      "Epoch 317/500\n",
      "12/12 [==============================] - 0s 529us/step - loss: 0.0248 - accuracy: 0.9972\n",
      "Epoch 318/500\n",
      "12/12 [==============================] - 0s 663us/step - loss: 0.0246 - accuracy: 1.0000\n",
      "Epoch 319/500\n",
      "12/12 [==============================] - 0s 390us/step - loss: 0.0245 - accuracy: 1.0000\n",
      "Epoch 320/500\n",
      "12/12 [==============================] - 0s 655us/step - loss: 0.0244 - accuracy: 0.9972\n",
      "Epoch 321/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 424us/step - loss: 0.0241 - accuracy: 0.9972\n",
      "Epoch 322/500\n",
      "12/12 [==============================] - 0s 711us/step - loss: 0.0243 - accuracy: 1.0000\n",
      "Epoch 323/500\n",
      "12/12 [==============================] - 0s 356us/step - loss: 0.0232 - accuracy: 1.0000\n",
      "Epoch 324/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0233 - accuracy: 1.0000\n",
      "Epoch 325/500\n",
      "12/12 [==============================] - 0s 537us/step - loss: 0.0227 - accuracy: 1.0000\n",
      "Epoch 326/500\n",
      "12/12 [==============================] - 0s 905us/step - loss: 0.0224 - accuracy: 1.0000\n",
      "Epoch 327/500\n",
      "12/12 [==============================] - 0s 456us/step - loss: 0.0229 - accuracy: 1.0000\n",
      "Epoch 328/500\n",
      "12/12 [==============================] - 0s 996us/step - loss: 0.0228 - accuracy: 0.9972\n",
      "Epoch 329/500\n",
      "12/12 [==============================] - 0s 667us/step - loss: 0.0228 - accuracy: 1.0000\n",
      "Epoch 330/500\n",
      "12/12 [==============================] - 0s 667us/step - loss: 0.0222 - accuracy: 1.0000\n",
      "Epoch 331/500\n",
      "12/12 [==============================] - 0s 957us/step - loss: 0.0213 - accuracy: 1.0000\n",
      "Epoch 332/500\n",
      "12/12 [==============================] - 0s 743us/step - loss: 0.0212 - accuracy: 1.0000\n",
      "Epoch 333/500\n",
      "12/12 [==============================] - 0s 667us/step - loss: 0.0211 - accuracy: 1.0000\n",
      "Epoch 334/500\n",
      "12/12 [==============================] - 0s 672us/step - loss: 0.0207 - accuracy: 1.0000\n",
      "Epoch 335/500\n",
      "12/12 [==============================] - 0s 790us/step - loss: 0.0205 - accuracy: 1.0000\n",
      "Epoch 336/500\n",
      "12/12 [==============================] - 0s 618us/step - loss: 0.0201 - accuracy: 1.0000\n",
      "Epoch 337/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0203 - accuracy: 1.0000\n",
      "Epoch 338/500\n",
      "12/12 [==============================] - 0s 641us/step - loss: 0.0197 - accuracy: 1.0000\n",
      "Epoch 339/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0199 - accuracy: 1.0000\n",
      "Epoch 340/500\n",
      "12/12 [==============================] - 0s 542us/step - loss: 0.0200 - accuracy: 1.0000\n",
      "Epoch 341/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0196 - accuracy: 1.0000\n",
      "Epoch 342/500\n",
      "12/12 [==============================] - 0s 536us/step - loss: 0.0194 - accuracy: 1.0000\n",
      "Epoch 343/500\n",
      "12/12 [==============================] - 0s 850us/step - loss: 0.0189 - accuracy: 1.0000\n",
      "Epoch 344/500\n",
      "12/12 [==============================] - 0s 466us/step - loss: 0.0194 - accuracy: 0.9972\n",
      "Epoch 345/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0191 - accuracy: 1.0000\n",
      "Epoch 346/500\n",
      "12/12 [==============================] - 0s 370us/step - loss: 0.0185 - accuracy: 1.0000\n",
      "Epoch 347/500\n",
      "12/12 [==============================] - 0s 75us/step - loss: 0.0188 - accuracy: 1.0000\n",
      "Epoch 348/500\n",
      "12/12 [==============================] - 0s 337us/step - loss: 0.0183 - accuracy: 1.0000\n",
      "Epoch 349/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0181 - accuracy: 1.0000\n",
      "Epoch 350/500\n",
      "12/12 [==============================] - 0s 504us/step - loss: 0.0176 - accuracy: 1.0000\n",
      "Epoch 351/500\n",
      "12/12 [==============================] - 0s 609us/step - loss: 0.0173 - accuracy: 1.0000\n",
      "Epoch 352/500\n",
      "12/12 [==============================] - 0s 396us/step - loss: 0.0174 - accuracy: 1.0000\n",
      "Epoch 353/500\n",
      "12/12 [==============================] - 0s 938us/step - loss: 0.0174 - accuracy: 1.0000\n",
      "Epoch 354/500\n",
      "12/12 [==============================] - 0s 331us/step - loss: 0.0167 - accuracy: 1.0000\n",
      "Epoch 355/500\n",
      "12/12 [==============================] - 0s 799us/step - loss: 0.0167 - accuracy: 1.0000\n",
      "Epoch 356/500\n",
      "12/12 [==============================] - 0s 308us/step - loss: 0.0171 - accuracy: 1.0000\n",
      "Epoch 357/500\n",
      "12/12 [==============================] - 0s 999us/step - loss: 0.0179 - accuracy: 1.0000\n",
      "Epoch 358/500\n",
      "12/12 [==============================] - 0s 629us/step - loss: 0.0165 - accuracy: 1.0000\n",
      "Epoch 359/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0162 - accuracy: 1.0000\n",
      "Epoch 360/500\n",
      "12/12 [==============================] - 0s 590us/step - loss: 0.0161 - accuracy: 1.0000\n",
      "Epoch 361/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0181 - accuracy: 1.0000\n",
      "Epoch 362/500\n",
      "12/12 [==============================] - 0s 611us/step - loss: 0.0174 - accuracy: 1.0000\n",
      "Epoch 363/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0158 - accuracy: 1.0000\n",
      "Epoch 364/500\n",
      "12/12 [==============================] - 0s 681us/step - loss: 0.0161 - accuracy: 1.0000\n",
      "Epoch 365/500\n",
      "12/12 [==============================] - 0s 619us/step - loss: 0.0160 - accuracy: 1.0000\n",
      "Epoch 366/500\n",
      "12/12 [==============================] - 0s 491us/step - loss: 0.0156 - accuracy: 1.0000\n",
      "Epoch 367/500\n",
      "12/12 [==============================] - 0s 717us/step - loss: 0.0165 - accuracy: 1.0000\n",
      "Epoch 368/500\n",
      "12/12 [==============================] - 0s 667us/step - loss: 0.0164 - accuracy: 1.0000\n",
      "Epoch 369/500\n",
      "12/12 [==============================] - 0s 323us/step - loss: 0.0157 - accuracy: 1.0000\n",
      "Epoch 370/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0148 - accuracy: 1.0000\n",
      "Epoch 371/500\n",
      "12/12 [==============================] - 0s 554us/step - loss: 0.0143 - accuracy: 1.0000\n",
      "Epoch 372/500\n",
      "12/12 [==============================] - 0s 601us/step - loss: 0.0140 - accuracy: 1.0000\n",
      "Epoch 373/500\n",
      "12/12 [==============================] - 0s 398us/step - loss: 0.0138 - accuracy: 1.0000\n",
      "Epoch 374/500\n",
      "12/12 [==============================] - 0s 783us/step - loss: 0.0141 - accuracy: 1.0000\n",
      "Epoch 375/500\n",
      "12/12 [==============================] - 0s 419us/step - loss: 0.0141 - accuracy: 1.0000\n",
      "Epoch 376/500\n",
      "12/12 [==============================] - 0s 832us/step - loss: 0.0138 - accuracy: 1.0000\n",
      "Epoch 377/500\n",
      "12/12 [==============================] - 0s 387us/step - loss: 0.0132 - accuracy: 1.0000\n",
      "Epoch 378/500\n",
      "12/12 [==============================] - 0s 868us/step - loss: 0.0133 - accuracy: 1.0000\n",
      "Epoch 379/500\n",
      "12/12 [==============================] - 0s 380us/step - loss: 0.0134 - accuracy: 1.0000\n",
      "Epoch 380/500\n",
      "12/12 [==============================] - 0s 867us/step - loss: 0.0134 - accuracy: 1.0000\n",
      "Epoch 381/500\n",
      "12/12 [==============================] - 0s 368us/step - loss: 0.0129 - accuracy: 1.0000\n",
      "Epoch 382/500\n",
      "12/12 [==============================] - 0s 854us/step - loss: 0.0129 - accuracy: 1.0000\n",
      "Epoch 383/500\n",
      "12/12 [==============================] - 0s 315us/step - loss: 0.0126 - accuracy: 1.0000\n",
      "Epoch 384/500\n",
      "12/12 [==============================] - 0s 932us/step - loss: 0.0127 - accuracy: 1.0000\n",
      "Epoch 385/500\n",
      "12/12 [==============================] - 0s 351us/step - loss: 0.0124 - accuracy: 1.0000\n",
      "Epoch 386/500\n",
      "12/12 [==============================] - 0s 891us/step - loss: 0.0124 - accuracy: 1.0000\n",
      "Epoch 387/500\n",
      "12/12 [==============================] - 0s 362us/step - loss: 0.0126 - accuracy: 1.0000\n",
      "Epoch 388/500\n",
      "12/12 [==============================] - 0s 878us/step - loss: 0.0121 - accuracy: 1.0000\n",
      "Epoch 389/500\n",
      "12/12 [==============================] - 0s 817us/step - loss: 0.0120 - accuracy: 1.0000\n",
      "Epoch 390/500\n",
      "12/12 [==============================] - 0s 915us/step - loss: 0.0125 - accuracy: 1.0000\n",
      "Epoch 391/500\n",
      "12/12 [==============================] - 0s 720us/step - loss: 0.0117 - accuracy: 1.0000\n",
      "Epoch 392/500\n",
      "12/12 [==============================] - 0s 725us/step - loss: 0.0117 - accuracy: 1.0000\n",
      "Epoch 393/500\n",
      "12/12 [==============================] - 0s 294us/step - loss: 0.0122 - accuracy: 1.0000\n",
      "Epoch 394/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0115 - accuracy: 1.0000\n",
      "Epoch 395/500\n",
      "12/12 [==============================] - 0s 667us/step - loss: 0.0122 - accuracy: 1.0000\n",
      "Epoch 396/500\n",
      "12/12 [==============================] - 0s 806us/step - loss: 0.0114 - accuracy: 1.0000\n",
      "Epoch 397/500\n",
      "12/12 [==============================] - 0s 667us/step - loss: 0.0115 - accuracy: 1.0000\n",
      "Epoch 398/500\n",
      "12/12 [==============================] - 0s 649us/step - loss: 0.0110 - accuracy: 1.0000\n",
      "Epoch 399/500\n",
      "12/12 [==============================] - 0s 647us/step - loss: 0.0111 - accuracy: 1.0000\n",
      "Epoch 400/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 686us/step - loss: 0.0108 - accuracy: 1.0000\n",
      "Epoch 401/500\n",
      "12/12 [==============================] - 0s 667us/step - loss: 0.0109 - accuracy: 1.0000\n",
      "Epoch 402/500\n",
      "12/12 [==============================] - 0s 352us/step - loss: 0.0106 - accuracy: 1.0000\n",
      "Epoch 403/500\n",
      "12/12 [==============================] - 0s 597us/step - loss: 0.0104 - accuracy: 1.0000\n",
      "Epoch 404/500\n",
      "12/12 [==============================] - 0s 551us/step - loss: 0.0104 - accuracy: 1.0000\n",
      "Epoch 405/500\n",
      "12/12 [==============================] - 0s 667us/step - loss: 0.0104 - accuracy: 1.0000\n",
      "Epoch 406/500\n",
      "12/12 [==============================] - 0s 323us/step - loss: 0.0102 - accuracy: 1.0000\n",
      "Epoch 407/500\n",
      "12/12 [==============================] - 0s 955us/step - loss: 0.0101 - accuracy: 1.0000\n",
      "Epoch 408/500\n",
      "12/12 [==============================] - 0s 547us/step - loss: 0.0103 - accuracy: 1.0000\n",
      "Epoch 409/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0099 - accuracy: 1.0000\n",
      "Epoch 410/500\n",
      "12/12 [==============================] - 0s 386us/step - loss: 0.0099 - accuracy: 1.0000\n",
      "Epoch 411/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0098 - accuracy: 1.0000\n",
      "Epoch 412/500\n",
      "12/12 [==============================] - 0s 382us/step - loss: 0.0095 - accuracy: 1.0000\n",
      "Epoch 413/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0097 - accuracy: 1.0000\n",
      "Epoch 414/500\n",
      "12/12 [==============================] - 0s 363us/step - loss: 0.0094 - accuracy: 1.0000\n",
      "Epoch 415/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0092 - accuracy: 1.0000\n",
      "Epoch 416/500\n",
      "12/12 [==============================] - 0s 532us/step - loss: 0.0093 - accuracy: 1.0000\n",
      "Epoch 417/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0091 - accuracy: 1.0000\n",
      "Epoch 418/500\n",
      "12/12 [==============================] - 0s 414us/step - loss: 0.0091 - accuracy: 1.0000\n",
      "Epoch 419/500\n",
      "12/12 [==============================] - 0s 842us/step - loss: 0.0092 - accuracy: 1.0000\n",
      "Epoch 420/500\n",
      "12/12 [==============================] - 0s 441us/step - loss: 0.0092 - accuracy: 1.0000\n",
      "Epoch 421/500\n",
      "12/12 [==============================] - 0s 723us/step - loss: 0.0090 - accuracy: 1.0000\n",
      "Epoch 422/500\n",
      "12/12 [==============================] - 0s 667us/step - loss: 0.0089 - accuracy: 1.0000\n",
      "Epoch 423/500\n",
      "12/12 [==============================] - 0s 251us/step - loss: 0.0091 - accuracy: 1.0000\n",
      "Epoch 424/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0088 - accuracy: 1.0000\n",
      "Epoch 425/500\n",
      "12/12 [==============================] - 0s 698us/step - loss: 0.0085 - accuracy: 1.0000\n",
      "Epoch 426/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0084 - accuracy: 1.0000\n",
      "Epoch 427/500\n",
      "12/12 [==============================] - 0s 605us/step - loss: 0.0083 - accuracy: 1.0000\n",
      "Epoch 428/500\n",
      "12/12 [==============================] - 0s 738us/step - loss: 0.0082 - accuracy: 1.0000\n",
      "Epoch 429/500\n",
      "12/12 [==============================] - 0s 667us/step - loss: 0.0081 - accuracy: 1.0000\n",
      "Epoch 430/500\n",
      "12/12 [==============================] - 0s 667us/step - loss: 0.0082 - accuracy: 1.0000\n",
      "Epoch 431/500\n",
      "12/12 [==============================] - 0s 445us/step - loss: 0.0080 - accuracy: 1.0000\n",
      "Epoch 432/500\n",
      "12/12 [==============================] - 0s 882us/step - loss: 0.0079 - accuracy: 1.0000\n",
      "Epoch 433/500\n",
      "12/12 [==============================] - 0s 397us/step - loss: 0.0081 - accuracy: 1.0000\n",
      "Epoch 434/500\n",
      "12/12 [==============================] - 0s 941us/step - loss: 0.0078 - accuracy: 1.0000\n",
      "Epoch 435/500\n",
      "12/12 [==============================] - 0s 619us/step - loss: 0.0077 - accuracy: 1.0000\n",
      "Epoch 436/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0076 - accuracy: 1.0000\n",
      "Epoch 437/500\n",
      "12/12 [==============================] - 0s 678us/step - loss: 0.0076 - accuracy: 1.0000\n",
      "Epoch 438/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0077 - accuracy: 1.0000\n",
      "Epoch 439/500\n",
      "12/12 [==============================] - 0s 305us/step - loss: 0.0074 - accuracy: 1.0000\n",
      "Epoch 440/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0075 - accuracy: 1.0000\n",
      "Epoch 441/500\n",
      "12/12 [==============================] - 0s 656us/step - loss: 0.0078 - accuracy: 1.0000\n",
      "Epoch 442/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0075 - accuracy: 1.0000\n",
      "Epoch 443/500\n",
      "12/12 [==============================] - 0s 587us/step - loss: 0.0073 - accuracy: 1.0000\n",
      "Epoch 444/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0072 - accuracy: 1.0000\n",
      "Epoch 445/500\n",
      "12/12 [==============================] - 0s 680us/step - loss: 0.0070 - accuracy: 1.0000\n",
      "Epoch 446/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0070 - accuracy: 1.0000\n",
      "Epoch 447/500\n",
      "12/12 [==============================] - 0s 546us/step - loss: 0.0069 - accuracy: 1.0000\n",
      "Epoch 448/500\n",
      "12/12 [==============================] - 0s 765us/step - loss: 0.0075 - accuracy: 1.0000\n",
      "Epoch 449/500\n",
      "12/12 [==============================] - 0s 667us/step - loss: 0.0067 - accuracy: 1.0000\n",
      "Epoch 450/500\n",
      "12/12 [==============================] - 0s 326us/step - loss: 0.0072 - accuracy: 1.0000\n",
      "Epoch 451/500\n",
      "12/12 [==============================] - 0s 525us/step - loss: 0.0066 - accuracy: 1.0000\n",
      "Epoch 452/500\n",
      "12/12 [==============================] - 0s 641us/step - loss: 0.0065 - accuracy: 1.0000\n",
      "Epoch 453/500\n",
      "12/12 [==============================] - 0s 667us/step - loss: 0.0065 - accuracy: 1.0000\n",
      "Epoch 454/500\n",
      "12/12 [==============================] - 0s 314us/step - loss: 0.0066 - accuracy: 1.0000\n",
      "Epoch 455/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0064 - accuracy: 1.0000\n",
      "Epoch 456/500\n",
      "12/12 [==============================] - 0s 494us/step - loss: 0.0064 - accuracy: 1.0000\n",
      "Epoch 457/500\n",
      "12/12 [==============================] - 0s 680us/step - loss: 0.0064 - accuracy: 1.0000\n",
      "Epoch 458/500\n",
      "12/12 [==============================] - 0s 853us/step - loss: 0.0064 - accuracy: 1.0000\n",
      "Epoch 459/500\n",
      "12/12 [==============================] - 0s 677us/step - loss: 0.0063 - accuracy: 1.0000\n",
      "Epoch 460/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0063 - accuracy: 1.0000\n",
      "Epoch 461/500\n",
      "12/12 [==============================] - 0s 625us/step - loss: 0.0060 - accuracy: 1.0000\n",
      "Epoch 462/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0060 - accuracy: 1.0000\n",
      "Epoch 463/500\n",
      "12/12 [==============================] - 0s 638us/step - loss: 0.0060 - accuracy: 1.0000\n",
      "Epoch 464/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0059 - accuracy: 1.0000\n",
      "Epoch 465/500\n",
      "12/12 [==============================] - 0s 581us/step - loss: 0.0059 - accuracy: 1.0000\n",
      "Epoch 466/500\n",
      "12/12 [==============================] - 0s 773us/step - loss: 0.0058 - accuracy: 1.0000\n",
      "Epoch 467/500\n",
      "12/12 [==============================] - 0s 667us/step - loss: 0.0058 - accuracy: 1.0000\n",
      "Epoch 468/500\n",
      "12/12 [==============================] - 0s 346us/step - loss: 0.0057 - accuracy: 1.0000\n",
      "Epoch 469/500\n",
      "12/12 [==============================] - 0s 591us/step - loss: 0.0056 - accuracy: 1.0000\n",
      "Epoch 470/500\n",
      "12/12 [==============================] - 0s 708us/step - loss: 0.0057 - accuracy: 1.0000\n",
      "Epoch 471/500\n",
      "12/12 [==============================] - 0s 667us/step - loss: 0.0057 - accuracy: 1.0000\n",
      "Epoch 472/500\n",
      "12/12 [==============================] - 0s 354us/step - loss: 0.0058 - accuracy: 1.0000\n",
      "Epoch 473/500\n",
      "12/12 [==============================] - 0s 654us/step - loss: 0.0063 - accuracy: 1.0000\n",
      "Epoch 474/500\n",
      "12/12 [==============================] - 0s 581us/step - loss: 0.0059 - accuracy: 1.0000\n",
      "Epoch 475/500\n",
      "12/12 [==============================] - 0s 667us/step - loss: 0.0056 - accuracy: 1.0000\n",
      "Epoch 476/500\n",
      "12/12 [==============================] - 0s 342us/step - loss: 0.0055 - accuracy: 1.0000\n",
      "Epoch 477/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0054 - accuracy: 1.0000\n",
      "Epoch 478/500\n",
      "12/12 [==============================] - 0s 466us/step - loss: 0.0052 - accuracy: 1.0000\n",
      "Epoch 479/500\n",
      "12/12 [==============================] - 0s 667us/step - loss: 0.0051 - accuracy: 1.0000\n",
      "Epoch 480/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 350us/step - loss: 0.0050 - accuracy: 1.0000\n",
      "Epoch 481/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0051 - accuracy: 1.0000\n",
      "Epoch 482/500\n",
      "12/12 [==============================] - 0s 436us/step - loss: 0.0050 - accuracy: 1.0000\n",
      "Epoch 483/500\n",
      "12/12 [==============================] - 0s 667us/step - loss: 0.0051 - accuracy: 1.0000\n",
      "Epoch 484/500\n",
      "12/12 [==============================] - 0s 169us/step - loss: 0.0049 - accuracy: 1.0000\n",
      "Epoch 485/500\n",
      "12/12 [==============================] - 0s 407us/step - loss: 0.0048 - accuracy: 1.0000\n",
      "Epoch 486/500\n",
      "12/12 [==============================] - 0s 678us/step - loss: 0.0048 - accuracy: 1.0000\n",
      "Epoch 487/500\n",
      "12/12 [==============================] - 0s 982us/step - loss: 0.0047 - accuracy: 1.0000\n",
      "Epoch 488/500\n",
      "12/12 [==============================] - 0s 610us/step - loss: 0.0047 - accuracy: 1.0000\n",
      "Epoch 489/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0047 - accuracy: 1.0000\n",
      "Epoch 490/500\n",
      "12/12 [==============================] - 0s 504us/step - loss: 0.0047 - accuracy: 1.0000\n",
      "Epoch 491/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0047 - accuracy: 1.0000\n",
      "Epoch 492/500\n",
      "12/12 [==============================] - 0s 250us/step - loss: 0.0047 - accuracy: 1.0000\n",
      "Epoch 493/500\n",
      "12/12 [==============================] - 0s 973us/step - loss: 0.0045 - accuracy: 1.0000\n",
      "Epoch 494/500\n",
      "12/12 [==============================] - 0s 429us/step - loss: 0.0046 - accuracy: 1.0000\n",
      "Epoch 495/500\n",
      "12/12 [==============================] - 0s 938us/step - loss: 0.0044 - accuracy: 1.0000\n",
      "Epoch 496/500\n",
      "12/12 [==============================] - 0s 387us/step - loss: 0.0045 - accuracy: 1.0000\n",
      "Epoch 497/500\n",
      "12/12 [==============================] - 0s 602us/step - loss: 0.0044 - accuracy: 1.0000\n",
      "Epoch 498/500\n",
      "12/12 [==============================] - 0s 141us/step - loss: 0.0043 - accuracy: 1.0000\n",
      "Epoch 499/500\n",
      "12/12 [==============================] - 0s 572us/step - loss: 0.0043 - accuracy: 1.0000\n",
      "Epoch 500/500\n",
      "12/12 [==============================] - 0s 298us/step - loss: 0.0048 - accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 500\n",
    "BATCH_SIZE = 32\n",
    "history = model.fit(X_train, y_train, epochs=EPOCHS, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.57      0.54        30\n",
      "           1       0.54      0.63      0.58        30\n",
      "           2       0.68      0.50      0.58        30\n",
      "\n",
      "    accuracy                           0.57        90\n",
      "   macro avg       0.58      0.57      0.57        90\n",
      "weighted avg       0.58      0.57      0.57        90\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred_test = model.predict(X_test)\n",
    "predictions_categorical = np.argmax(pred_test, axis=1)\n",
    "print(classification_report(y_test, predictions_categorical))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Valutazione Inferance Rate medio (|X_test| = 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEGCAYAAACKB4k+AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAUCklEQVR4nO3df5AlZX3v8ffHRTTIzRplExNgXXQRswpBHNAoEZLgrbUqC/4gCSt1jSnDFkSSuvEmJf6oSMxNRSumrJsEr66RQr2ElSQG3WQTY1RY8KICSmAXQlxQLitJAXLvxB/IKnzvH6enZxhmZs/sTk/PmXm/qk7tOU+f7v6eZg6f0/10P52qQpIkgCf0XYAkaekwFCRJLUNBktQyFCRJLUNBktQ6pO8CDsYRRxxR69at67sMSRopN9100wNVtWamaSMdCuvWrePGG2/suwxJGilJ7p5tmoePJEktQ0GS1FoyoZDkJ5O8P8lfJbmg73okaSXqNBSSXJrkviS7prVvTHJHkj1JLgKoqtur6nzgl4CxLuuSJM2s6z2Fy4CNUxuSrAIuAV4BbAA2J9nQTDsTuA74TMd1SZJm0GkoVNVO4MFpzacAe6rqrqraB2wDzmre/8mqeglwbpd1SZJm1scpqUcC90x5vRd4UZLTgVcDTwJ2zDZzki3AFoC1a9d2VqQkrUR9hEJmaKuquhq4en8zV9VWYCvA2NiY435L0gLqIxT2AkdPeX0UcG8PdUgr2jUvO63vEhbcaTuv6buEkdfHKak3AMcmOSbJocA5wCfns4Akm5JsHR8f76RASVqpuj4l9QrgeuC4JHuTvKGqfgBcCHwKuB24sqp2z2e5VbW9qrasXr164YuWpBWs08NHVbV5lvYdzNGZLEnqx5K5onk+PHwkSd0YyVDw8JEkdWMkQ0GS1A1DQZLUGslQsE9BkroxkqFgn4IkdWMkQ0GS1A1DQZLUMhQkSa2RDAU7miWpGyMZCnY0S1I3RjIUJEndMBQkSS1DQZLUGslQsKNZkroxkqFgR7MkdWMkQ0GS1A1DQZLUMhQkSS1DQZLUGslQ8OwjSerGSIaCZx9JUjdGMhQkSd0wFCRJLUNBktQyFCRJLUNBktQyFCRJLUNBktQayVDw4jVJ6sZIhoIXr0lSN0YyFCRJ3TAUJEktQ0GS1DIUJEktQ0GS1DIUJEktQ0GS1DIUJEktQ0GS1BrJUHCYC0nqxkiGgsNcSFI3RjIUJEndMBQkSS1DQZLUMhQkSS1DQZLUMhQkSS1DQZLUMhQkSS1DQZLUMhQkSS1DQZLUMhQkSS1DQZLUMhQkSS1DQZLUWlKhkOSVST6Y5BNJ/nPf9UjSStN5KCS5NMl9SXZNa9+Y5I4ke5JcBFBVV1XVecDrgV/uujZJ0mMtxp7CZcDGqQ1JVgGXAK8ANgCbk2yY8pa3N9MlSYtov6GQ5DlJPjPxSz/JCUnePuwKqmon8OC05lOAPVV1V1XtA7YBZ2Xg3cDfV9WXZ6lnS5Ibk9x4//33D1uGJGkIw+wpfBB4C/B9gKq6BTjnINd7JHDPlNd7m7bfAM4Azk5y/kwzVtXWqhqrqrE1a9YcZBmSpKkOGeI9h1XVl5JMbfvBQa43M7RVVf0J8CcHuWxJ0gEaZk/hgSTPBgogydnAvx3kevcCR095fRRw77AzJ9mUZOv4+PhBliFJmmqYUHgj8AHguUm+AfxX4IKDXO8NwLFJjklyKIPDUZ8cduaq2l5VW1avXn2QZUiSptrv4aOqugs4I8lTgCdU1bfms4IkVwCnA0ck2Qu8o6o+lORC4FPAKuDSqto97+olSQtqv6GQ5KnA64B1wCETfQtV9ZvDrKCqNs/SvgPYMWSdkqRFMExH8w7gC8CtwKPdljOcJJuATevXr++7FElaVoYJhSdX1Zs6r2Qeqmo7sH1sbOy8vmuRpOVkmI7mjyY5L8mPJ3naxKPzyiRJi26YPYV9wB8Bb6M5LbX591ldFSVJ6scwofAmYH1VPdB1McOyT0GSujHM4aPdwHe7LmQ+vE5BkroxzJ7CI8DNST4HPDzROOwpqZKk0TFMKFzVPCRJy9wwVzR/eDEKmQ/7FCSpG7P2KSS5svn31iS3TH8sXomPZ5+CJHVjrj2F9zb//sJiFCJJ6t9coXAJcFJV3b1YxUiS+jXXKakz3QhHkrSMzbWncGSSWe+C5impkrT8zBUKDwE3LVYh8+HZR5IW0p/9t+19l7DgLvzjTQc031yh8M2leDoqOEqqJHVlrj6FfYtWhSRpSZg1FKrqxYtZiCSpf8MMiCdJWiEMBUlSa6hQSHJqkl9tnq9Jcky3Ze23nk1Jto6Pj/dZhiQtO/sNhSTvAN4MvKVpeiLwv7osan8c+0iSujHMnsKrgDOB7wBU1b3Af+qyKElSP4YJhX1VVTT3Z07ylG5LkiT1ZZhQuDLJB4CnJjkP+Cfgg92WJUnqwzA32XlPkpcD/wEcB/xuVX2688okSYtuv6HQnGl07UQQJPmhJOuq6utdFydJWlzDHD76S+DRKa8fadokScvMMKFwSFW14yA1zw/trqT98zoFSerGMKFwf5IzJ14kOQt4oLuS9s/rFCSpG/vtUwDOBy5P8mcM7sZ2D/C6TquSJPVimLOP7gRenORwIFX1re7LkiT1YZizj54EvAZYBxySDG7dXFXv7LQySdKiG+bw0SeAcQa35ny423IkSX0aJhSOqqqNnVciSerdMGcf/e8kx3deiSSpd8PsKZwKvD7J1xgcPgpQVXVCp5VJkhbdMKHwis6rkCQtCfs9fFRVdwNHAz/XPP/uMPNJkkbPSN55TZLUjZG885pjH0lSN0byzmuOfSRJ3fDOa5Kk1pxnH2UwpsXHgOfindckadmbMxSqqpJcVVUvBAwCSVrmhjl89IUkJ3deiSSpd8NcvPazwPlJvs7gDCSvaJakZcormiVJLa9oliS1vKJZktQaySuaJUndGMkrmiVJ3fCKZklSa9azj5I8qaoerqr3JHk5XtEsScveXKekXg+clOSjVfVf8IpmSVr25gqFQ5P8CvCSJK+ePrGqPt5dWZKkPswVCucD5wJPBTZNm1aAoSBJy8ysoVBV1wHXJbmxqj7UdSFJngW8DVhdVWd3vT5J0uMNc0Xzh5K8JMlrk7xu4jHMwpNcmuS+JLumtW9MckeSPUkuatZzV1W94cA+hiRpIQxzRfNHgfcApwInN4+xIZd/GbBx2vJWAZcwGFNpA7A5yYbhS5YkdWWYAfHGgA3NBWzzUlU7k6yb1nwKsKeq7gJIsg04C7htmGUm2QJsAVi7du18S5IkzWGYi9d2Ac9YwHUeCdwz5fVe4MgkT0/yfuAFSd4y86xQVVuraqyqxtasWbOAZUmShtlTOAK4LcmXgIcnGqvqzANcZ2Zoq6r6JoMzniRJPRkmFC5e4HXuZTAU94SjgHvns4Akm4BN69evX8i6JGnF228oVNU1C7zOG4BjkxwDfAM4B3jtfBZQVduB7WNjY+ctcG2StKLNNfbRt2hGRp0+icHhnh/e38KTXAGcDhyRZC/wjuYU1wuBTwGrgEuraveBFC9JWlhzXbx20PdMqKrNs7TvAHYc7PIlSQtrmD6FJWeYPoUX/s5HFq+gRXLTHw11zaAkHbCRvNdyVW2vqi2rV6/uuxRJWlZGMhQkSd0wFCRJrZEMhSSbkmwdHx/vuxRJWlZGMhTsU5CkboxkKEiSumEoSJJaIxkK9ilIUjdGMhTsU5CkboxkKEiSumEoSJJahoIkqTWSoWBHsyR1YyRDwY5mSerGSIaCJKkbhoIkqWUoSJJahoIkqWUoSJJaIxkKnpIqSd0YyVDwlFRJ6sZIhoIkqRuGgiSpZShIklqGgiSpZShIklqGgiSpNZKh4HUKktSNkQwFr1OQpG6MZChIkrphKEiSWoaCJKllKEiSWoaCJKllKEiSWoaCJKllKEiSWoaCJKllKEiSWiMZCo59JEndGMlQcOwjSerGSIaCJKkbhoIkqWUoSJJahoIkqWUoSJJahoIkqWUoSJJahoIkqWUoSJJahoIkqWUoSJJahoIkqWUoSJJahoIkqWUoSJJah/RdwIQkTwHeB+wDrq6qy3suSZJWnE73FJJcmuS+JLumtW9MckeSPUkuappfDfxVVZ0HnNllXZKkmXV9+OgyYOPUhiSrgEuAVwAbgM1JNgBHAfc0b3uk47okSTPo9PBRVe1Msm5a8ynAnqq6CyDJNuAsYC+DYLiZOcIqyRZgC8DatWsXvuhl6P+88/i+S1hwa3/31gOa76V/+tIFrqR/n/+Nz/ddgpaRPjqaj2RyjwAGYXAk8HHgNUn+J7B9tpmramtVjVXV2Jo1a7qtVJJWmD46mjNDW1XVd4BfXexiJEmT+thT2AscPeX1UcC981lAkk1Jto6Pjy9oYZK00vURCjcAxyY5JsmhwDnAJ+ezgKraXlVbVq9e3UmBkrRSdX1K6hXA9cBxSfYmeUNV/QC4EPgUcDtwZVXt7rIOSdJwuj77aPMs7TuAHQe63CSbgE3r168/0EVIkmYwksNcePhIkroxkqEgSeqGoSBJaqWq+q7hgCW5H7i77zqAI4AH+i5iCXA7THJbTHJbTFoq2+KZVTXj1b8jHQpLRZIbq2qs7zr65naY5LaY5LaYNArbwsNHkqSWoSBJahkKC2Nr3wUsEW6HSW6LSW6LSUt+W9inIElquacgSWoZCpKklqEwD0keSXJzkl1Jtid5atO+LslDzbSJx6E9l7sgkjwjybYkdya5LcmOJM9ppv1Wku8lWT3l/acnGU/ylST/kuQ9SY6fsl0eTPK15vk/9ffJFk6Sb8/QdnGSbzSf87YkM44DthwkeVuS3UluaT7v3yf5w2nvOTHJ7c3zw5N8oPmb2p1kZ5IX9VP9wknyY0n+IsldSW5Kcn2SVzXfiWrGbJt4798mOb15fnVzz/qbk9ze3F2yN4bC/DxUVSdW1fOBB4E3Tpl2ZzNt4rGvpxoXTJIAfwNcXVXPrqoNwFuBH2vespnBUOivmjbrtVX1AuAFwC8APzyxXRgMk/47zeszFuNz9Oi9zWc+C/hAkif2XM+CS/LTDP4bn1RVJwBnAO8CfnnaW88B/qJ5/ucMvj/HVtXzgNczuKhrZDXflauAnVX1rKp6IYPPfFTzlr3A2+ZYxLnN38pLgXf3+aPSUDhw1zO4jehy9rPA96vq/RMNVXVzVV2b5NnA4cDbGYTD41TVQwzuub3ct9OcquqrwHeBH+m7lg78OPBAVT0MUFUPVNU1wP+b9uv/l4Btzd/Ni4C3V9WjzTx3VdXfLXbhC+zngH3Tvit3V9WfNi//GRhP8vL9LOdw4DvAI92UuX+GwgFIsgr4eR57c6BnTzlEcklPpS205wM3zTJtM3AFcC2D+2X86PQ3JPkR4FhgZ2cVjoAkJwFfrar7+q6lA/8IHJ3kX5O8L8lpTfsVDH4pk+TFwDebcHwecHNV9fY/vY48D/jyft7z3xn8iJrJ5UluAe4Afr/P7WMozM8PJbkZ+CbwNODTU6ZNPXz0xhnnXl7OAbY1v/Y+DvzilGk/0/yB/zvwt1X1730UuAT8VpI7gC8CF/dcSyeq6tvAC4EtwP3Ax5K8HtgGnJ3kCQz+Vq7orcgeJLkkyT8nuWGiraqubab9zAyznNscflsL/HaSZy5SqY9jKMzPQ81xv2cCh/LYPoXlaDeDL/xjJDmBwR7Ap5N8ncGXfuohpGubP/DjgQuSnNh9qUvSe6vqOAbH1z+S5Ml9F9SFqnqkqq6uqncwuKvia6rqHuDrwGnAa4Arm7fvBn6qCYvlZDdw0sSL5ofhzwPTB537A+boW6iq+xnscfTW8b7c/sMsiqoaB36TQaIvu87DKT4LPCnJeRMNSU4G/gdwcVWtax4/ARw5/ddNVf0r8IfAmxez6KWmqj4O3Aj8St+1LLQkxyU5dkrTiUyOXHwF8F4Ge9F7AarqTgbb4veazlmSHJvkrMWruhOfBZ6c5IIpbYdNf1NV/SODvqWfmmkhSQ5jcILGnV0UOQxD4QBV1VcYdB6d03ctXanB5e6vAl4+cfogg8MgpzM4K2mqv2HmbfF+4GVJjumw1L4dlsE9yCceb5rhPe8E3rQMfyEfDny4Oe32FmADk4fK/pLBsfZt0+b5NeAZwJ4ktwIfBO5dnHK70XxXXgmc1pxy/SXgw8z8g+gPmDwracLlzaHpm4DLqmq2vrzOOcyFJKm13H61SJIOgqEgSWoZCpKklqEgSWoZCpKklqGgFa0ZxbKSPLd5vS7JrgVc/p8n2dA8f+tCLVfqiqGglW4zcB0dXG+SZFVV/VpV3dY0GQpa8gwFrVhJDmcwVPEbmCEUkhyW5MrmPgEfS/LFJGPNtM1Jbs3g3hrvnjLPt5O8M8kXgZ9uxsofS/IumrGzklze7JH8S7MnsatpOyPJ55N8NckpzfKeluSqpoYvNEOMSJ0xFLSSvRL4h2Y4jgeb0Uyn+nXg/zbjOP0+zThQSX4CeDeD4ZJPBE5O8spmnqcAu6rqRVV13cSCquoiJu/HcW7TvJ7BkCEnAM8FXgucCvw2k3sVvwd8panhrcBHFuajSzMzFLSSbWZyCIZtPP6+EKdOTK+qXcAtTfvJDG48dH9V/QC4HHhZM+0R4K+HXP/XqurWZqTZ3cBnmuESbgXWTanho00NnwWenil3upMW2iF9FyD1IcnTGfzSf36SAlYBBbxv6ttmm32ORX9vHmPhPzzl+aNTXj/K5HdzpnU5No06456CVqqzgY9U1TObkV6PBr7GYwcqu47BHcNoziA6vmn/IoOBz45obri0GbhmiHV+/wBG1d0JnNvUcDqDu5z9xzyXIQ3NUNBKtZnHj/T61zz2DKH3AWua0T/fzODw0XhV/RvwFuBzDEbK/XJVfWKIdW4Fbkly+TzqvBgYa2p4F8tw+G0tLY6SKs2i2Qt4YlV9r7m38GeA51TVvp5Lkzpjn4I0u8OAzzWHfAJcYCBouXNPQZLUsk9BktQyFCRJLUNBktQyFCRJLUNBktT6/yRmGeRn/aWJAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "csv = read_csv(\"InfTimeReport.csv\")\n",
    "g = sbs.barplot(x=csv['Algoritmo'], y=csv['InfTime'])\n",
    "g.set_yscale(\"log\")\n",
    "plt.ylabel(\"Inference Time\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Memoria occupata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "csv = read_csv(\"MemOccupationReport.csv\")\n",
    "sbs.barplot(x=csv['Algoritmo'], y=csv['MemOccupata2'])\n",
    "plt.ylabel(\"MemOccupata in Byte\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export Models in C code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\luigi.borriello2\\.conda\\envs\\ts\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From C:\\Users\\luigi.borriello2\\.conda\\envs\\ts\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "INFO:tensorflow:Assets written to: C:\\Users\\LUIGI~1.BOR\\AppData\\Local\\Temp\\tmp3oo9kle8\\assets\n"
     ]
    }
   ],
   "source": [
    "with open('exportedModels/NNmodel.h', 'w') as f:\n",
    "    f.write(tiny.port(model, optimize=False))\n",
    "for name, model in models:\n",
    "    prepath = 'exportedModels/' + str(labels) + \"/\"\n",
    "    path = prepath + name + '.h'\n",
    "    x = port(model, optimize=True)\n",
    "    with open(path, 'w') as f:\n",
    "        f.write(port(model, optimize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

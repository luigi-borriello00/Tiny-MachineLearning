{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models Comparison for TinyML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Load libraries\n",
    "import numpy as np\n",
    "from numpy import arange\n",
    "import pickle\n",
    "from pandas import read_csv\n",
    "#\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#\n",
    "import pandas as pd\n",
    "from pandas import read_csv\n",
    "\n",
    "from sklearn.metrics import confusion_matrix,  classification_report, f1_score\n",
    "from sklearn.model_selection import train_test_split, KFold,StratifiedKFold, cross_val_score, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from keras.models import Sequential, Model \n",
    "from keras.layers import Dense, Input, concatenate, Activation, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import tensorflow\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "import m2cgen as m2c\n",
    "from micromlgen import port\n",
    "\n",
    "import warnings\n",
    "import seaborn as sbs\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "tensorflow.random.set_seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/X_paper.pkl', 'rb') as f:\n",
    "    X = pickle.load(f)\n",
    "\n",
    "with open('../data/y_paper.pkl', 'rb') as f:\n",
    "    y = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X = np.concatenate((X[:250], X[750:1000], X[1500:]), axis=0)\n",
    " #y = np.concatenate((y[:250], y[750:1000], y[1500:]), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 5 6]\n"
     ]
    }
   ],
   "source": [
    "print(np.unique(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Spotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test options and evaluation metric\n",
    "num_folds = 10\n",
    "seed = 42\n",
    "scoring = 'f1_macro'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spot-Check Algorithms\n",
    "models = []\n",
    "\n",
    "#models.append(('XGB', XGBClassifier(random_state=seed)))\n",
    "models.append(('GNB', GaussianNB(var_smoothing=2e-9)))\n",
    "models.append(('LR', Pipeline([('Scaler', StandardScaler()),('LR', LogisticRegression(random_state=seed))])))\n",
    "models.append(('CART' , DecisionTreeClassifier(random_state=seed)))\n",
    "models.append(('SVC' , SVC(gamma=0.5, random_state=seed)))\n",
    "models.append(('RF', RandomForestClassifier(random_state=seed, n_estimators = 50)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GNB - 0,39 0,03\n",
      "LR - 0,34 0,03\n",
      "CART - 0,67 0,02\n",
      "SVC - 0,64 0,04\n",
      "RF - 0,66 0,04\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "names = []\n",
    "for name, model in models:\n",
    "    # Dividere dati in n = num_folds\n",
    "    kf = StratifiedKFold(n_splits=num_folds, random_state=seed, shuffle=True)\n",
    "    cv_results = np.array([])\n",
    "    for train_idx, test_idx, in kf.split(X_train, y_train):\n",
    "        X_cross_train, y_cross_train = X_train[train_idx], y_train[train_idx]\n",
    "        X_cross_test, y_cross_test = X_train[test_idx], y_train[test_idx]\n",
    "        model.fit(X_cross_train, y_cross_train)  \n",
    "        y_pred = model.predict(X_cross_test)\n",
    "        f1s = f1_score(y_cross_test, y_pred, average=\"weighted\")\n",
    "        cv_results = np.append(cv_results, [f1s])\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    #msg = \"%s - %f - %f\" % (name, cv_results.mean(), cv_results.std())\n",
    "    msg = \"{} - {:.2f} {:.2f}\".format(name, cv_results.mean(), cv_results.std()).replace('.', ',')\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compare Algorithms\n",
    "fig = plt.figure(figsize=(10,5))\n",
    "fig.suptitle('Algorithms Comparison')\n",
    "ax = fig.add_subplot(111)\n",
    "plt.boxplot(results)\n",
    "ax.set_xticklabels(names)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Valutazione dei migliori algoritmi su test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Valutazione Inferance Rate medio (|X_test| = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "csv = read_csv(\"InfTimeReport.csv\")\n",
    "g = sbs.barplot(x=csv['Algoritmo'], y=csv['InfTime'])\n",
    "g.set_yscale(\"log\")\n",
    "plt.ylabel(\"Inference Time\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Memoria occupata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "csv = read_csv(\"MemOccupationReport.csv\")\n",
    "sbs.barplot(x=csv['Algoritmo'], y=csv['MemOccupata'])\n",
    "plt.ylabel(\"MemOccupata in Byte\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Sequential-NN\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_33 (Dense)             (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 700)               4200      \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 7)                 4907      \n",
      "=================================================================\n",
      "Total params: 9,137\n",
      "Trainable params: 9,137\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "n = 100\n",
    "model = Sequential(name=\"Sequential-NN\")\n",
    "model.add(layers.Dense(X.shape[1], activation='relu', input_shape=(X.shape[1],)))\n",
    "model.add(layers.Dense(np.unique(y).size * n, activation='relu'))\n",
    "model.add(layers.Dense(np.unique(y).size, activation='softmax'))\n",
    "opt = Adam(learning_rate=0.0005)\n",
    "model.compile(optimizer=opt, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "\n",
    "# Convert to array[int]\n",
    "y_train = np.array([int(num) for num in y_train])\n",
    "y_test = np.array([int(num) for num in y_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/750\n",
      "162/162 [==============================] - 0s 1ms/step - loss: 7.0702 - accuracy: 0.2370 - val_loss: 5.1659 - val_accuracy: 0.2926\n",
      "Epoch 2/750\n",
      "162/162 [==============================] - 0s 743us/step - loss: 5.2881 - accuracy: 0.2630 - val_loss: 2.4003 - val_accuracy: 0.2778\n",
      "Epoch 3/750\n",
      "162/162 [==============================] - 0s 691us/step - loss: 4.3335 - accuracy: 0.2852 - val_loss: 4.3108 - val_accuracy: 0.3185\n",
      "Epoch 4/750\n",
      "162/162 [==============================] - 0s 642us/step - loss: 3.5210 - accuracy: 0.2889 - val_loss: 4.1625 - val_accuracy: 0.3037\n",
      "Epoch 5/750\n",
      "162/162 [==============================] - 0s 650us/step - loss: 3.1891 - accuracy: 0.3025 - val_loss: 2.1473 - val_accuracy: 0.3963\n",
      "Epoch 6/750\n",
      "162/162 [==============================] - 0s 692us/step - loss: 3.7109 - accuracy: 0.2975 - val_loss: 4.9469 - val_accuracy: 0.3370\n",
      "Epoch 7/750\n",
      "162/162 [==============================] - 0s 642us/step - loss: 3.4640 - accuracy: 0.2679 - val_loss: 3.1404 - val_accuracy: 0.1889\n",
      "Epoch 8/750\n",
      "162/162 [==============================] - 0s 642us/step - loss: 3.0647 - accuracy: 0.3160 - val_loss: 2.7396 - val_accuracy: 0.3889\n",
      "Epoch 9/750\n",
      "162/162 [==============================] - 0s 662us/step - loss: 3.4580 - accuracy: 0.3185 - val_loss: 3.3016 - val_accuracy: 0.2815\n",
      "Epoch 10/750\n",
      "162/162 [==============================] - 0s 653us/step - loss: 3.0764 - accuracy: 0.2938 - val_loss: 2.5070 - val_accuracy: 0.3815\n",
      "Epoch 11/750\n",
      "162/162 [==============================] - 0s 623us/step - loss: 2.9025 - accuracy: 0.3136 - val_loss: 2.9441 - val_accuracy: 0.2778\n",
      "Epoch 12/750\n",
      "162/162 [==============================] - 0s 652us/step - loss: 2.8157 - accuracy: 0.3272 - val_loss: 3.0027 - val_accuracy: 0.3296\n",
      "Epoch 13/750\n",
      "162/162 [==============================] - 0s 623us/step - loss: 2.4617 - accuracy: 0.3099 - val_loss: 2.2651 - val_accuracy: 0.3704\n",
      "Epoch 14/750\n",
      "162/162 [==============================] - 0s 642us/step - loss: 2.5443 - accuracy: 0.3272 - val_loss: 3.0159 - val_accuracy: 0.3667\n",
      "Epoch 15/750\n",
      "162/162 [==============================] - 0s 653us/step - loss: 2.3823 - accuracy: 0.3432 - val_loss: 1.7310 - val_accuracy: 0.3296\n",
      "Epoch 16/750\n",
      "162/162 [==============================] - 0s 642us/step - loss: 2.5375 - accuracy: 0.3333 - val_loss: 2.4785 - val_accuracy: 0.3481\n",
      "Epoch 17/750\n",
      "162/162 [==============================] - 0s 643us/step - loss: 2.3034 - accuracy: 0.3519 - val_loss: 2.6241 - val_accuracy: 0.2889\n",
      "Epoch 18/750\n",
      "162/162 [==============================] - 0s 642us/step - loss: 2.1879 - accuracy: 0.3728 - val_loss: 2.0437 - val_accuracy: 0.4074\n",
      "Epoch 19/750\n",
      "162/162 [==============================] - 0s 642us/step - loss: 2.3088 - accuracy: 0.3296 - val_loss: 1.9626 - val_accuracy: 0.4185\n",
      "Epoch 20/750\n",
      "162/162 [==============================] - 0s 623us/step - loss: 2.0397 - accuracy: 0.3407 - val_loss: 1.6454 - val_accuracy: 0.3333\n",
      "Epoch 21/750\n",
      "162/162 [==============================] - 0s 662us/step - loss: 2.2960 - accuracy: 0.3407 - val_loss: 2.0683 - val_accuracy: 0.3444\n",
      "Epoch 22/750\n",
      "162/162 [==============================] - 0s 623us/step - loss: 2.0169 - accuracy: 0.3457 - val_loss: 1.6584 - val_accuracy: 0.4407\n",
      "Epoch 23/750\n",
      "162/162 [==============================] - 0s 633us/step - loss: 1.8236 - accuracy: 0.3519 - val_loss: 1.7929 - val_accuracy: 0.4037\n",
      "Epoch 24/750\n",
      "162/162 [==============================] - 0s 642us/step - loss: 1.8862 - accuracy: 0.3654 - val_loss: 2.0319 - val_accuracy: 0.3148\n",
      "Epoch 25/750\n",
      "162/162 [==============================] - 0s 653us/step - loss: 1.8816 - accuracy: 0.3617 - val_loss: 1.8775 - val_accuracy: 0.3630\n",
      "Epoch 26/750\n",
      "162/162 [==============================] - 0s 642us/step - loss: 1.8093 - accuracy: 0.3827 - val_loss: 1.6361 - val_accuracy: 0.4259\n",
      "Epoch 27/750\n",
      "162/162 [==============================] - 0s 642us/step - loss: 1.8274 - accuracy: 0.3827 - val_loss: 1.5000 - val_accuracy: 0.3926\n",
      "Epoch 28/750\n",
      "162/162 [==============================] - 0s 643us/step - loss: 1.8416 - accuracy: 0.3605 - val_loss: 1.6152 - val_accuracy: 0.4630\n",
      "Epoch 29/750\n",
      "162/162 [==============================] - 0s 673us/step - loss: 1.8216 - accuracy: 0.3802 - val_loss: 1.9573 - val_accuracy: 0.4111\n",
      "Epoch 30/750\n",
      "162/162 [==============================] - 0s 632us/step - loss: 1.8645 - accuracy: 0.3432 - val_loss: 1.7477 - val_accuracy: 0.3778\n",
      "Epoch 31/750\n",
      "162/162 [==============================] - 0s 662us/step - loss: 1.9254 - accuracy: 0.3605 - val_loss: 1.6060 - val_accuracy: 0.4481\n",
      "Epoch 32/750\n",
      "162/162 [==============================] - 0s 623us/step - loss: 1.7189 - accuracy: 0.3901 - val_loss: 1.5804 - val_accuracy: 0.3852\n",
      "Epoch 33/750\n",
      "162/162 [==============================] - 0s 652us/step - loss: 1.6678 - accuracy: 0.4012 - val_loss: 1.5103 - val_accuracy: 0.3630\n",
      "Epoch 34/750\n",
      "162/162 [==============================] - 0s 642us/step - loss: 1.6557 - accuracy: 0.3938 - val_loss: 1.4881 - val_accuracy: 0.4000\n",
      "Epoch 35/750\n",
      "162/162 [==============================] - 0s 642us/step - loss: 1.6983 - accuracy: 0.3914 - val_loss: 1.5351 - val_accuracy: 0.3630\n",
      "Epoch 36/750\n",
      "162/162 [==============================] - 0s 643us/step - loss: 1.6123 - accuracy: 0.3840 - val_loss: 1.5853 - val_accuracy: 0.4370\n",
      "Epoch 37/750\n",
      "162/162 [==============================] - 0s 642us/step - loss: 1.5609 - accuracy: 0.3716 - val_loss: 1.5343 - val_accuracy: 0.4556\n",
      "Epoch 38/750\n",
      "162/162 [==============================] - 0s 642us/step - loss: 1.6279 - accuracy: 0.3864 - val_loss: 1.4228 - val_accuracy: 0.4370\n",
      "Epoch 39/750\n",
      "162/162 [==============================] - 0s 642us/step - loss: 1.5606 - accuracy: 0.3951 - val_loss: 1.5223 - val_accuracy: 0.3000\n",
      "Epoch 40/750\n",
      "162/162 [==============================] - 0s 623us/step - loss: 1.6038 - accuracy: 0.4099 - val_loss: 1.5027 - val_accuracy: 0.4741\n",
      "Epoch 41/750\n",
      "162/162 [==============================] - 0s 643us/step - loss: 1.5531 - accuracy: 0.4210 - val_loss: 1.4749 - val_accuracy: 0.4370\n",
      "Epoch 42/750\n",
      "162/162 [==============================] - 0s 632us/step - loss: 1.6180 - accuracy: 0.3728 - val_loss: 1.3832 - val_accuracy: 0.4630\n",
      "Epoch 43/750\n",
      "162/162 [==============================] - 0s 653us/step - loss: 1.5066 - accuracy: 0.4222 - val_loss: 1.3772 - val_accuracy: 0.4000\n",
      "Epoch 44/750\n",
      "162/162 [==============================] - 0s 632us/step - loss: 1.5082 - accuracy: 0.4062 - val_loss: 1.4236 - val_accuracy: 0.3889\n",
      "Epoch 45/750\n",
      "162/162 [==============================] - 0s 691us/step - loss: 1.5961 - accuracy: 0.3802 - val_loss: 1.7285 - val_accuracy: 0.3704\n",
      "Epoch 46/750\n",
      "162/162 [==============================] - 0s 653us/step - loss: 1.5548 - accuracy: 0.4222 - val_loss: 1.4843 - val_accuracy: 0.4111\n",
      "Epoch 47/750\n",
      "162/162 [==============================] - 0s 623us/step - loss: 1.5189 - accuracy: 0.4111 - val_loss: 1.4299 - val_accuracy: 0.4148\n",
      "Epoch 48/750\n",
      "162/162 [==============================] - 0s 692us/step - loss: 1.4652 - accuracy: 0.4247 - val_loss: 1.3935 - val_accuracy: 0.4815\n",
      "Epoch 49/750\n",
      "162/162 [==============================] - 0s 682us/step - loss: 1.4590 - accuracy: 0.4198 - val_loss: 1.3619 - val_accuracy: 0.4556\n",
      "Epoch 50/750\n",
      "162/162 [==============================] - 0s 636us/step - loss: 1.5001 - accuracy: 0.4012 - val_loss: 1.4405 - val_accuracy: 0.4630\n",
      "Epoch 51/750\n",
      "162/162 [==============================] - 0s 642us/step - loss: 1.4575 - accuracy: 0.3877 - val_loss: 1.3944 - val_accuracy: 0.3704\n",
      "Epoch 52/750\n",
      "162/162 [==============================] - 0s 693us/step - loss: 1.5072 - accuracy: 0.3914 - val_loss: 1.4435 - val_accuracy: 0.3889\n",
      "Epoch 53/750\n",
      "162/162 [==============================] - 0s 651us/step - loss: 1.4566 - accuracy: 0.4086 - val_loss: 1.6947 - val_accuracy: 0.4148\n",
      "Epoch 54/750\n",
      "162/162 [==============================] - 0s 623us/step - loss: 1.4633 - accuracy: 0.4407 - val_loss: 1.4053 - val_accuracy: 0.4259\n",
      "Epoch 55/750\n",
      "162/162 [==============================] - 0s 653us/step - loss: 1.3868 - accuracy: 0.4531 - val_loss: 1.5482 - val_accuracy: 0.4185\n",
      "Epoch 56/750\n",
      "162/162 [==============================] - 0s 642us/step - loss: 1.4096 - accuracy: 0.4432 - val_loss: 1.3560 - val_accuracy: 0.4889\n",
      "Epoch 57/750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 0s 643us/step - loss: 1.3915 - accuracy: 0.4432 - val_loss: 1.3776 - val_accuracy: 0.4185\n",
      "Epoch 58/750\n",
      "162/162 [==============================] - 0s 642us/step - loss: 1.3685 - accuracy: 0.4395 - val_loss: 1.3710 - val_accuracy: 0.4741\n",
      "Epoch 59/750\n",
      "162/162 [==============================] - 0s 643us/step - loss: 1.3836 - accuracy: 0.4519 - val_loss: 1.3565 - val_accuracy: 0.4407\n",
      "Epoch 60/750\n",
      "162/162 [==============================] - 0s 623us/step - loss: 1.3703 - accuracy: 0.4272 - val_loss: 1.3004 - val_accuracy: 0.5185\n",
      "Epoch 61/750\n",
      "162/162 [==============================] - 0s 643us/step - loss: 1.3507 - accuracy: 0.4395 - val_loss: 1.3352 - val_accuracy: 0.4556\n",
      "Epoch 62/750\n",
      "162/162 [==============================] - 0s 642us/step - loss: 1.3824 - accuracy: 0.4333 - val_loss: 1.3536 - val_accuracy: 0.4481\n",
      "Epoch 63/750\n",
      "162/162 [==============================] - 0s 652us/step - loss: 1.3572 - accuracy: 0.4444 - val_loss: 1.3666 - val_accuracy: 0.4778\n",
      "Epoch 64/750\n",
      "162/162 [==============================] - 0s 633us/step - loss: 1.3424 - accuracy: 0.4679 - val_loss: 1.3222 - val_accuracy: 0.4556\n",
      "Epoch 65/750\n",
      "162/162 [==============================] - 0s 643us/step - loss: 1.3382 - accuracy: 0.4691 - val_loss: 1.2815 - val_accuracy: 0.4630\n",
      "Epoch 66/750\n",
      "162/162 [==============================] - 0s 632us/step - loss: 1.3741 - accuracy: 0.4370 - val_loss: 1.3408 - val_accuracy: 0.4593\n",
      "Epoch 67/750\n",
      "162/162 [==============================] - 0s 642us/step - loss: 1.3566 - accuracy: 0.4395 - val_loss: 1.5346 - val_accuracy: 0.3444\n",
      "Epoch 68/750\n",
      "162/162 [==============================] - 0s 692us/step - loss: 1.3499 - accuracy: 0.4531 - val_loss: 1.3255 - val_accuracy: 0.4778\n",
      "Epoch 69/750\n",
      "162/162 [==============================] - 0s 653us/step - loss: 1.3622 - accuracy: 0.4531 - val_loss: 1.2672 - val_accuracy: 0.5074\n",
      "Epoch 70/750\n",
      "162/162 [==============================] - 0s 643us/step - loss: 1.3220 - accuracy: 0.4630 - val_loss: 1.3126 - val_accuracy: 0.4852\n",
      "Epoch 71/750\n",
      "162/162 [==============================] - 0s 642us/step - loss: 1.3374 - accuracy: 0.4593 - val_loss: 1.4188 - val_accuracy: 0.4370\n",
      "Epoch 72/750\n",
      "162/162 [==============================] - 0s 643us/step - loss: 1.3377 - accuracy: 0.4457 - val_loss: 1.3157 - val_accuracy: 0.4593\n",
      "Epoch 73/750\n",
      "162/162 [==============================] - 0s 642us/step - loss: 1.3419 - accuracy: 0.4321 - val_loss: 1.3299 - val_accuracy: 0.4519\n",
      "Epoch 74/750\n",
      "162/162 [==============================] - ETA: 0s - loss: 1.3906 - accuracy: 0.43 - 0s 642us/step - loss: 1.3792 - accuracy: 0.4457 - val_loss: 1.3495 - val_accuracy: 0.4963\n",
      "Epoch 75/750\n",
      "162/162 [==============================] - 0s 623us/step - loss: 1.3405 - accuracy: 0.4667 - val_loss: 1.3479 - val_accuracy: 0.4889\n",
      "Epoch 76/750\n",
      "162/162 [==============================] - 0s 652us/step - loss: 1.3325 - accuracy: 0.4568 - val_loss: 1.2472 - val_accuracy: 0.4926\n",
      "Epoch 77/750\n",
      "162/162 [==============================] - 0s 623us/step - loss: 1.3013 - accuracy: 0.4827 - val_loss: 1.3731 - val_accuracy: 0.3852\n",
      "Epoch 78/750\n",
      "162/162 [==============================] - 0s 643us/step - loss: 1.3182 - accuracy: 0.4741 - val_loss: 1.4692 - val_accuracy: 0.3667\n",
      "Epoch 79/750\n",
      "162/162 [==============================] - 0s 642us/step - loss: 1.3149 - accuracy: 0.4827 - val_loss: 1.2978 - val_accuracy: 0.5037\n",
      "Epoch 80/750\n",
      "162/162 [==============================] - 0s 652us/step - loss: 1.3168 - accuracy: 0.4506 - val_loss: 1.2569 - val_accuracy: 0.5333\n",
      "Epoch 81/750\n",
      "162/162 [==============================] - 0s 643us/step - loss: 1.3142 - accuracy: 0.4420 - val_loss: 1.2483 - val_accuracy: 0.4333\n",
      "Epoch 82/750\n",
      "162/162 [==============================] - 0s 624us/step - loss: 1.2967 - accuracy: 0.4704 - val_loss: 1.3609 - val_accuracy: 0.4815\n",
      "Epoch 83/750\n",
      "162/162 [==============================] - 0s 661us/step - loss: 1.3070 - accuracy: 0.4753 - val_loss: 1.2139 - val_accuracy: 0.5185\n",
      "Epoch 84/750\n",
      "162/162 [==============================] - 0s 642us/step - loss: 1.3088 - accuracy: 0.4654 - val_loss: 1.3015 - val_accuracy: 0.5185\n",
      "Epoch 85/750\n",
      "162/162 [==============================] - 0s 672us/step - loss: 1.3005 - accuracy: 0.4679 - val_loss: 1.2488 - val_accuracy: 0.5111\n",
      "Epoch 86/750\n",
      "162/162 [==============================] - 0s 643us/step - loss: 1.2844 - accuracy: 0.4741 - val_loss: 1.2906 - val_accuracy: 0.5074\n",
      "Epoch 87/750\n",
      "162/162 [==============================] - 0s 632us/step - loss: 1.2822 - accuracy: 0.4901 - val_loss: 1.2402 - val_accuracy: 0.5259\n",
      "Epoch 88/750\n",
      "162/162 [==============================] - 0s 662us/step - loss: 1.3029 - accuracy: 0.4556 - val_loss: 1.4109 - val_accuracy: 0.3926\n",
      "Epoch 89/750\n",
      "162/162 [==============================] - 0s 623us/step - loss: 1.2877 - accuracy: 0.4765 - val_loss: 1.2237 - val_accuracy: 0.5185\n",
      "Epoch 90/750\n",
      "162/162 [==============================] - 0s 603us/step - loss: 1.2932 - accuracy: 0.4926 - val_loss: 1.2130 - val_accuracy: 0.5444\n",
      "Epoch 91/750\n",
      "162/162 [==============================] - 0s 594us/step - loss: 1.2758 - accuracy: 0.4975 - val_loss: 1.2852 - val_accuracy: 0.5259\n",
      "Epoch 92/750\n",
      "162/162 [==============================] - 0s 622us/step - loss: 1.2926 - accuracy: 0.4778 - val_loss: 1.2188 - val_accuracy: 0.5630\n",
      "Epoch 93/750\n",
      "162/162 [==============================] - 0s 692us/step - loss: 1.2698 - accuracy: 0.4975 - val_loss: 1.2851 - val_accuracy: 0.5148\n",
      "Epoch 94/750\n",
      "162/162 [==============================] - 0s 642us/step - loss: 1.2681 - accuracy: 0.4790 - val_loss: 1.1945 - val_accuracy: 0.5222\n",
      "Epoch 95/750\n",
      "162/162 [==============================] - 0s 643us/step - loss: 1.2628 - accuracy: 0.4901 - val_loss: 1.2355 - val_accuracy: 0.5148\n",
      "Epoch 96/750\n",
      "162/162 [==============================] - 0s 682us/step - loss: 1.2703 - accuracy: 0.4654 - val_loss: 1.2991 - val_accuracy: 0.4074\n",
      "Epoch 97/750\n",
      "162/162 [==============================] - 0s 635us/step - loss: 1.2621 - accuracy: 0.4802 - val_loss: 1.3212 - val_accuracy: 0.5037\n",
      "Epoch 98/750\n",
      "162/162 [==============================] - 0s 642us/step - loss: 1.2951 - accuracy: 0.4765 - val_loss: 1.2942 - val_accuracy: 0.4630\n",
      "Epoch 99/750\n",
      "162/162 [==============================] - 0s 643us/step - loss: 1.2838 - accuracy: 0.4951 - val_loss: 1.2231 - val_accuracy: 0.5593\n",
      "Epoch 100/750\n",
      "162/162 [==============================] - 0s 624us/step - loss: 1.2470 - accuracy: 0.4901 - val_loss: 1.1941 - val_accuracy: 0.5926\n",
      "Epoch 101/750\n",
      "162/162 [==============================] - 0s 661us/step - loss: 1.2718 - accuracy: 0.4778 - val_loss: 1.2340 - val_accuracy: 0.5148\n",
      "Epoch 102/750\n",
      "162/162 [==============================] - 0s 642us/step - loss: 1.2650 - accuracy: 0.4815 - val_loss: 1.2451 - val_accuracy: 0.4556\n",
      "Epoch 103/750\n",
      "162/162 [==============================] - 0s 643us/step - loss: 1.2495 - accuracy: 0.4901 - val_loss: 1.2037 - val_accuracy: 0.5222\n",
      "Epoch 104/750\n",
      "162/162 [==============================] - 0s 624us/step - loss: 1.2462 - accuracy: 0.5012 - val_loss: 1.1959 - val_accuracy: 0.5630\n",
      "Epoch 105/750\n",
      "162/162 [==============================] - 0s 691us/step - loss: 1.2525 - accuracy: 0.4926 - val_loss: 1.2799 - val_accuracy: 0.4963\n",
      "Epoch 106/750\n",
      "162/162 [==============================] - 0s 643us/step - loss: 1.2592 - accuracy: 0.4926 - val_loss: 1.2038 - val_accuracy: 0.5111\n",
      "Epoch 107/750\n",
      "162/162 [==============================] - 0s 632us/step - loss: 1.2544 - accuracy: 0.4802 - val_loss: 1.1739 - val_accuracy: 0.5630\n",
      "Epoch 108/750\n",
      "162/162 [==============================] - 0s 603us/step - loss: 1.2359 - accuracy: 0.5086 - val_loss: 1.2274 - val_accuracy: 0.4630\n",
      "Epoch 109/750\n",
      "162/162 [==============================] - 0s 632us/step - loss: 1.2487 - accuracy: 0.5025 - val_loss: 1.2476 - val_accuracy: 0.5185\n",
      "Epoch 110/750\n",
      "162/162 [==============================] - 0s 653us/step - loss: 1.2279 - accuracy: 0.5123 - val_loss: 1.2426 - val_accuracy: 0.5222\n",
      "Epoch 111/750\n",
      "162/162 [==============================] - 0s 632us/step - loss: 1.2426 - accuracy: 0.5074 - val_loss: 1.2035 - val_accuracy: 0.5296\n",
      "Epoch 112/750\n",
      "162/162 [==============================] - 0s 653us/step - loss: 1.2593 - accuracy: 0.5049 - val_loss: 1.2207 - val_accuracy: 0.5667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 113/750\n",
      "162/162 [==============================] - 0s 623us/step - loss: 1.2618 - accuracy: 0.4765 - val_loss: 1.2374 - val_accuracy: 0.4667\n",
      "Epoch 114/750\n",
      "162/162 [==============================] - 0s 711us/step - loss: 1.2362 - accuracy: 0.5012 - val_loss: 1.2119 - val_accuracy: 0.5704\n",
      "Epoch 115/750\n",
      "162/162 [==============================] - 0s 623us/step - loss: 1.2587 - accuracy: 0.5012 - val_loss: 1.2483 - val_accuracy: 0.5185\n",
      "Epoch 116/750\n",
      "162/162 [==============================] - 0s 642us/step - loss: 1.2632 - accuracy: 0.4765 - val_loss: 1.2887 - val_accuracy: 0.4444\n",
      "Epoch 117/750\n",
      "162/162 [==============================] - 0s 632us/step - loss: 1.2266 - accuracy: 0.5198 - val_loss: 1.2822 - val_accuracy: 0.4000\n",
      "Epoch 118/750\n",
      "162/162 [==============================] - 0s 643us/step - loss: 1.2524 - accuracy: 0.5062 - val_loss: 1.1922 - val_accuracy: 0.5667\n",
      "Epoch 119/750\n",
      "162/162 [==============================] - 0s 643us/step - loss: 1.2423 - accuracy: 0.4840 - val_loss: 1.2580 - val_accuracy: 0.5111\n",
      "Epoch 120/750\n",
      "162/162 [==============================] - 0s 652us/step - loss: 1.2392 - accuracy: 0.5000 - val_loss: 1.1685 - val_accuracy: 0.5259\n",
      "Epoch 121/750\n",
      "162/162 [==============================] - 0s 642us/step - loss: 1.2188 - accuracy: 0.5062 - val_loss: 1.1791 - val_accuracy: 0.5630\n",
      "Epoch 122/750\n",
      "162/162 [==============================] - 0s 642us/step - loss: 1.2368 - accuracy: 0.5222 - val_loss: 1.1475 - val_accuracy: 0.5667\n",
      "Epoch 123/750\n",
      "162/162 [==============================] - 0s 643us/step - loss: 1.2303 - accuracy: 0.5037 - val_loss: 1.2029 - val_accuracy: 0.5370\n",
      "Epoch 124/750\n",
      "162/162 [==============================] - 0s 643us/step - loss: 1.2274 - accuracy: 0.4877 - val_loss: 1.3597 - val_accuracy: 0.4259\n",
      "Epoch 125/750\n",
      "162/162 [==============================] - 0s 642us/step - loss: 1.2159 - accuracy: 0.5074 - val_loss: 1.1847 - val_accuracy: 0.5148\n",
      "Epoch 126/750\n",
      "162/162 [==============================] - 0s 642us/step - loss: 1.2124 - accuracy: 0.5049 - val_loss: 1.1772 - val_accuracy: 0.5889\n",
      "Epoch 127/750\n",
      "162/162 [==============================] - 0s 642us/step - loss: 1.2340 - accuracy: 0.4938 - val_loss: 1.1612 - val_accuracy: 0.5296\n",
      "Epoch 128/750\n",
      "162/162 [==============================] - 0s 643us/step - loss: 1.2292 - accuracy: 0.5037 - val_loss: 1.1565 - val_accuracy: 0.5519\n",
      "Epoch 129/750\n",
      "162/162 [==============================] - 0s 642us/step - loss: 1.2292 - accuracy: 0.4889 - val_loss: 1.1491 - val_accuracy: 0.5889\n",
      "Epoch 130/750\n",
      "162/162 [==============================] - 0s 642us/step - loss: 1.2335 - accuracy: 0.4988 - val_loss: 1.1617 - val_accuracy: 0.5519\n",
      "Epoch 131/750\n",
      "162/162 [==============================] - 0s 642us/step - loss: 1.2199 - accuracy: 0.5012 - val_loss: 1.2146 - val_accuracy: 0.5407\n",
      "Epoch 132/750\n",
      "162/162 [==============================] - 0s 643us/step - loss: 1.2121 - accuracy: 0.5160 - val_loss: 1.1904 - val_accuracy: 0.5815\n",
      "Epoch 133/750\n",
      "162/162 [==============================] - 0s 642us/step - loss: 1.1930 - accuracy: 0.5321 - val_loss: 1.1633 - val_accuracy: 0.5667\n",
      "Epoch 134/750\n",
      "162/162 [==============================] - 0s 643us/step - loss: 1.2031 - accuracy: 0.5222 - val_loss: 1.1657 - val_accuracy: 0.5519\n",
      "Epoch 135/750\n",
      "162/162 [==============================] - 0s 643us/step - loss: 1.2245 - accuracy: 0.5025 - val_loss: 1.1690 - val_accuracy: 0.5519\n",
      "Epoch 136/750\n",
      "162/162 [==============================] - 0s 623us/step - loss: 1.1991 - accuracy: 0.5111 - val_loss: 1.1941 - val_accuracy: 0.5000\n",
      "Epoch 137/750\n",
      "162/162 [==============================] - 0s 643us/step - loss: 1.2027 - accuracy: 0.5148 - val_loss: 1.1790 - val_accuracy: 0.5963\n",
      "Epoch 138/750\n",
      "162/162 [==============================] - 0s 642us/step - loss: 1.1962 - accuracy: 0.5037 - val_loss: 1.2680 - val_accuracy: 0.4852\n",
      "Epoch 139/750\n",
      "162/162 [==============================] - 0s 613us/step - loss: 1.1953 - accuracy: 0.5025 - val_loss: 1.2006 - val_accuracy: 0.5185\n",
      "Epoch 140/750\n",
      "162/162 [==============================] - 0s 623us/step - loss: 1.2109 - accuracy: 0.5123 - val_loss: 1.1731 - val_accuracy: 0.5111\n",
      "Epoch 141/750\n",
      "162/162 [==============================] - 0s 643us/step - loss: 1.2210 - accuracy: 0.5037 - val_loss: 1.1867 - val_accuracy: 0.5222\n",
      "Epoch 142/750\n",
      "162/162 [==============================] - 0s 632us/step - loss: 1.2169 - accuracy: 0.4901 - val_loss: 1.1761 - val_accuracy: 0.5296\n",
      "Epoch 143/750\n",
      "162/162 [==============================] - 0s 702us/step - loss: 1.2043 - accuracy: 0.5086 - val_loss: 1.2229 - val_accuracy: 0.4926\n",
      "Epoch 144/750\n",
      "162/162 [==============================] - 0s 624us/step - loss: 1.2001 - accuracy: 0.5148 - val_loss: 1.1825 - val_accuracy: 0.5296\n",
      "Epoch 145/750\n",
      "162/162 [==============================] - 0s 691us/step - loss: 1.2047 - accuracy: 0.5062 - val_loss: 1.1332 - val_accuracy: 0.5852\n",
      "Epoch 146/750\n",
      "162/162 [==============================] - 0s 662us/step - loss: 1.1884 - accuracy: 0.5259 - val_loss: 1.1972 - val_accuracy: 0.5519\n",
      "Epoch 147/750\n",
      "162/162 [==============================] - 0s 623us/step - loss: 1.1905 - accuracy: 0.5111 - val_loss: 1.1729 - val_accuracy: 0.5074\n",
      "Epoch 148/750\n",
      "162/162 [==============================] - 0s 612us/step - loss: 1.2174 - accuracy: 0.4975 - val_loss: 1.1504 - val_accuracy: 0.5519\n",
      "Epoch 149/750\n",
      "162/162 [==============================] - 0s 592us/step - loss: 1.1931 - accuracy: 0.5185 - val_loss: 1.1529 - val_accuracy: 0.5111\n",
      "Epoch 150/750\n",
      "162/162 [==============================] - 0s 642us/step - loss: 1.2025 - accuracy: 0.4951 - val_loss: 1.1703 - val_accuracy: 0.5444\n",
      "Epoch 151/750\n",
      "162/162 [==============================] - 0s 625us/step - loss: 1.2092 - accuracy: 0.5185 - val_loss: 1.1576 - val_accuracy: 0.5926\n",
      "Epoch 152/750\n",
      "162/162 [==============================] - 0s 595us/step - loss: 1.2061 - accuracy: 0.5198 - val_loss: 1.1643 - val_accuracy: 0.5963\n",
      "Epoch 153/750\n",
      "162/162 [==============================] - 0s 644us/step - loss: 1.1865 - accuracy: 0.5173 - val_loss: 1.1520 - val_accuracy: 0.5593\n",
      "Epoch 154/750\n",
      "162/162 [==============================] - 0s 639us/step - loss: 1.2035 - accuracy: 0.5099 - val_loss: 1.1573 - val_accuracy: 0.6037\n",
      "Epoch 155/750\n",
      "162/162 [==============================] - 0s 624us/step - loss: 1.1846 - accuracy: 0.5358 - val_loss: 1.1216 - val_accuracy: 0.5963\n",
      "Epoch 156/750\n",
      "162/162 [==============================] - 0s 661us/step - loss: 1.2026 - accuracy: 0.5185 - val_loss: 1.2647 - val_accuracy: 0.5074\n",
      "Epoch 157/750\n",
      "162/162 [==============================] - 0s 643us/step - loss: 1.2095 - accuracy: 0.5160 - val_loss: 1.1609 - val_accuracy: 0.5852\n",
      "Epoch 158/750\n",
      "162/162 [==============================] - 0s 642us/step - loss: 1.1997 - accuracy: 0.5123 - val_loss: 1.3202 - val_accuracy: 0.4519\n",
      "Epoch 159/750\n",
      "162/162 [==============================] - 0s 624us/step - loss: 1.2297 - accuracy: 0.5136 - val_loss: 1.2632 - val_accuracy: 0.4889\n",
      "Epoch 160/750\n",
      "162/162 [==============================] - 0s 691us/step - loss: 1.2129 - accuracy: 0.5086 - val_loss: 1.1606 - val_accuracy: 0.5407\n",
      "Epoch 161/750\n",
      "162/162 [==============================] - 0s 642us/step - loss: 1.2284 - accuracy: 0.4790 - val_loss: 1.1537 - val_accuracy: 0.5259\n",
      "Epoch 162/750\n",
      "162/162 [==============================] - 0s 652us/step - loss: 1.1888 - accuracy: 0.5222 - val_loss: 1.1816 - val_accuracy: 0.5852\n",
      "Epoch 163/750\n",
      "162/162 [==============================] - 0s 686us/step - loss: 1.1891 - accuracy: 0.5123 - val_loss: 1.1255 - val_accuracy: 0.5556\n",
      "Epoch 164/750\n",
      "162/162 [==============================] - 0s 609us/step - loss: 1.1792 - accuracy: 0.5185 - val_loss: 1.1566 - val_accuracy: 0.5370\n",
      "Epoch 165/750\n",
      "162/162 [==============================] - 0s 627us/step - loss: 1.1667 - accuracy: 0.5235 - val_loss: 1.1353 - val_accuracy: 0.5370\n",
      "Epoch 166/750\n",
      "162/162 [==============================] - 0s 609us/step - loss: 1.1856 - accuracy: 0.5099 - val_loss: 1.1433 - val_accuracy: 0.5963\n",
      "Epoch 167/750\n",
      "162/162 [==============================] - 0s 623us/step - loss: 1.1820 - accuracy: 0.5370 - val_loss: 1.1516 - val_accuracy: 0.5630\n",
      "Epoch 168/750\n",
      "162/162 [==============================] - 0s 662us/step - loss: 1.1945 - accuracy: 0.5111 - val_loss: 1.1596 - val_accuracy: 0.5556\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 169/750\n",
      "162/162 [==============================] - 0s 607us/step - loss: 1.1769 - accuracy: 0.5284 - val_loss: 1.1563 - val_accuracy: 0.5593\n",
      "Epoch 170/750\n",
      "162/162 [==============================] - 0s 662us/step - loss: 1.1730 - accuracy: 0.5235 - val_loss: 1.1798 - val_accuracy: 0.5519\n",
      "Epoch 171/750\n",
      "162/162 [==============================] - 0s 642us/step - loss: 1.1805 - accuracy: 0.5321 - val_loss: 1.1421 - val_accuracy: 0.5519\n",
      "Epoch 172/750\n",
      "162/162 [==============================] - 0s 642us/step - loss: 1.1726 - accuracy: 0.5383 - val_loss: 1.1143 - val_accuracy: 0.6185\n",
      "Epoch 173/750\n",
      "162/162 [==============================] - 0s 643us/step - loss: 1.1889 - accuracy: 0.5198 - val_loss: 1.1295 - val_accuracy: 0.6185\n",
      "Epoch 174/750\n",
      "162/162 [==============================] - 0s 642us/step - loss: 1.1855 - accuracy: 0.5185 - val_loss: 1.1287 - val_accuracy: 0.5556\n",
      "Epoch 175/750\n",
      "162/162 [==============================] - 0s 642us/step - loss: 1.2024 - accuracy: 0.5272 - val_loss: 1.1571 - val_accuracy: 0.5519\n",
      "Epoch 176/750\n",
      "162/162 [==============================] - 0s 612us/step - loss: 1.1742 - accuracy: 0.5284 - val_loss: 1.2983 - val_accuracy: 0.4444\n",
      "Epoch 177/750\n",
      "162/162 [==============================] - 0s 633us/step - loss: 1.1986 - accuracy: 0.5148 - val_loss: 1.1283 - val_accuracy: 0.6000\n",
      "Epoch 178/750\n",
      "162/162 [==============================] - 0s 642us/step - loss: 1.1585 - accuracy: 0.5272 - val_loss: 1.1498 - val_accuracy: 0.5556\n",
      "Epoch 179/750\n",
      "162/162 [==============================] - 0s 649us/step - loss: 1.1686 - accuracy: 0.5123 - val_loss: 1.1615 - val_accuracy: 0.5259\n",
      "Epoch 180/750\n",
      "162/162 [==============================] - 0s 606us/step - loss: 1.1753 - accuracy: 0.5086 - val_loss: 1.1301 - val_accuracy: 0.5593\n",
      "Epoch 181/750\n",
      "162/162 [==============================] - 0s 643us/step - loss: 1.1856 - accuracy: 0.5136 - val_loss: 1.1301 - val_accuracy: 0.5556\n",
      "Epoch 182/750\n",
      "162/162 [==============================] - 0s 642us/step - loss: 1.1761 - accuracy: 0.5136 - val_loss: 1.1747 - val_accuracy: 0.5370\n",
      "Epoch 183/750\n",
      "162/162 [==============================] - 0s 643us/step - loss: 1.1872 - accuracy: 0.5333 - val_loss: 1.1730 - val_accuracy: 0.5667\n",
      "Epoch 184/750\n",
      "162/162 [==============================] - 0s 642us/step - loss: 1.2128 - accuracy: 0.5000 - val_loss: 1.1379 - val_accuracy: 0.6074\n",
      "Epoch 185/750\n",
      "162/162 [==============================] - 0s 643us/step - loss: 1.1808 - accuracy: 0.5309 - val_loss: 1.1633 - val_accuracy: 0.5444\n",
      "Epoch 186/750\n",
      "162/162 [==============================] - 0s 642us/step - loss: 1.1602 - accuracy: 0.5296 - val_loss: 1.1860 - val_accuracy: 0.5444\n",
      "Epoch 187/750\n",
      "162/162 [==============================] - 0s 642us/step - loss: 1.1710 - accuracy: 0.5272 - val_loss: 1.2215 - val_accuracy: 0.5593\n",
      "Epoch 188/750\n",
      "162/162 [==============================] - 0s 643us/step - loss: 1.1821 - accuracy: 0.5136 - val_loss: 1.2578 - val_accuracy: 0.4222\n",
      "Epoch 189/750\n",
      "162/162 [==============================] - 0s 646us/step - loss: 1.2029 - accuracy: 0.5198 - val_loss: 1.2987 - val_accuracy: 0.4815\n",
      "Epoch 190/750\n",
      "162/162 [==============================] - 0s 642us/step - loss: 1.1718 - accuracy: 0.5086 - val_loss: 1.1802 - val_accuracy: 0.5407\n",
      "Epoch 191/750\n",
      "162/162 [==============================] - 0s 642us/step - loss: 1.1675 - accuracy: 0.5346 - val_loss: 1.2032 - val_accuracy: 0.5222\n",
      "Epoch 192/750\n",
      "162/162 [==============================] - 0s 689us/step - loss: 1.1688 - accuracy: 0.5321 - val_loss: 1.1315 - val_accuracy: 0.6111\n",
      "Epoch 193/750\n",
      "162/162 [==============================] - 0s 623us/step - loss: 1.1719 - accuracy: 0.5235 - val_loss: 1.1270 - val_accuracy: 0.5593\n",
      "Epoch 194/750\n",
      "162/162 [==============================] - 0s 642us/step - loss: 1.1555 - accuracy: 0.5432 - val_loss: 1.1107 - val_accuracy: 0.5333\n",
      "Epoch 195/750\n",
      "162/162 [==============================] - 0s 630us/step - loss: 1.1590 - accuracy: 0.5235 - val_loss: 1.2044 - val_accuracy: 0.5074\n",
      "Epoch 196/750\n",
      "162/162 [==============================] - 0s 606us/step - loss: 1.1611 - accuracy: 0.5247 - val_loss: 1.1351 - val_accuracy: 0.5259\n",
      "Epoch 197/750\n",
      "162/162 [==============================] - 0s 612us/step - loss: 1.1613 - accuracy: 0.5383 - val_loss: 1.1808 - val_accuracy: 0.4926\n",
      "Epoch 198/750\n",
      "162/162 [==============================] - 0s 672us/step - loss: 1.1508 - accuracy: 0.5333 - val_loss: 1.1550 - val_accuracy: 0.5741\n",
      "Epoch 199/750\n",
      "162/162 [==============================] - 0s 614us/step - loss: 1.1602 - accuracy: 0.5247 - val_loss: 1.1021 - val_accuracy: 0.5926\n",
      "Epoch 200/750\n",
      "162/162 [==============================] - 0s 592us/step - loss: 1.1596 - accuracy: 0.5346 - val_loss: 1.1049 - val_accuracy: 0.6037\n",
      "Epoch 201/750\n",
      "162/162 [==============================] - 0s 593us/step - loss: 1.1640 - accuracy: 0.5321 - val_loss: 1.2695 - val_accuracy: 0.4889\n",
      "Epoch 202/750\n",
      "162/162 [==============================] - 0s 643us/step - loss: 1.1491 - accuracy: 0.5210 - val_loss: 1.1195 - val_accuracy: 0.6037\n",
      "Epoch 203/750\n",
      "162/162 [==============================] - 0s 642us/step - loss: 1.1690 - accuracy: 0.5358 - val_loss: 1.1380 - val_accuracy: 0.5222\n",
      "Epoch 204/750\n",
      "162/162 [==============================] - 0s 604us/step - loss: 1.1469 - accuracy: 0.5309 - val_loss: 1.1255 - val_accuracy: 0.5519\n",
      "Epoch 205/750\n",
      "162/162 [==============================] - 0s 662us/step - loss: 1.1736 - accuracy: 0.5148 - val_loss: 1.1508 - val_accuracy: 0.6074\n",
      "Epoch 206/750\n",
      "162/162 [==============================] - 0s 642us/step - loss: 1.1813 - accuracy: 0.5148 - val_loss: 1.1243 - val_accuracy: 0.5630\n",
      "Epoch 207/750\n",
      "162/162 [==============================] - 0s 642us/step - loss: 1.1402 - accuracy: 0.5494 - val_loss: 1.1282 - val_accuracy: 0.5407\n",
      "Epoch 208/750\n",
      "162/162 [==============================] - 0s 643us/step - loss: 1.1416 - accuracy: 0.5370 - val_loss: 1.1713 - val_accuracy: 0.5037\n",
      "Epoch 209/750\n",
      "162/162 [==============================] - 0s 692us/step - loss: 1.1509 - accuracy: 0.5420 - val_loss: 1.1251 - val_accuracy: 0.5667\n",
      "Epoch 210/750\n",
      "162/162 [==============================] - 0s 623us/step - loss: 1.1631 - accuracy: 0.5420 - val_loss: 1.1132 - val_accuracy: 0.5556\n",
      "Epoch 211/750\n",
      "162/162 [==============================] - 0s 711us/step - loss: 1.1472 - accuracy: 0.5395 - val_loss: 1.1534 - val_accuracy: 0.5593\n",
      "Epoch 212/750\n",
      "162/162 [==============================] - 0s 643us/step - loss: 1.1546 - accuracy: 0.5432 - val_loss: 1.1000 - val_accuracy: 0.6111\n",
      "Epoch 213/750\n",
      "162/162 [==============================] - 0s 642us/step - loss: 1.1488 - accuracy: 0.5494 - val_loss: 1.1127 - val_accuracy: 0.6000\n",
      "Epoch 214/750\n",
      "162/162 [==============================] - 0s 623us/step - loss: 1.1565 - accuracy: 0.5309 - val_loss: 1.1370 - val_accuracy: 0.6037\n",
      "Epoch 215/750\n",
      "162/162 [==============================] - 0s 642us/step - loss: 1.1893 - accuracy: 0.5198 - val_loss: 1.1344 - val_accuracy: 0.5667\n",
      "Epoch 216/750\n",
      "162/162 [==============================] - 0s 642us/step - loss: 1.1617 - accuracy: 0.5383 - val_loss: 1.0889 - val_accuracy: 0.5926\n",
      "Epoch 217/750\n",
      "162/162 [==============================] - 0s 624us/step - loss: 1.1705 - accuracy: 0.5407 - val_loss: 1.1142 - val_accuracy: 0.6111\n",
      "Epoch 218/750\n",
      "162/162 [==============================] - 0s 661us/step - loss: 1.1539 - accuracy: 0.5346 - val_loss: 1.1329 - val_accuracy: 0.5852\n",
      "Epoch 219/750\n",
      "162/162 [==============================] - 0s 623us/step - loss: 1.1754 - accuracy: 0.5136 - val_loss: 1.1566 - val_accuracy: 0.5259\n",
      "Epoch 220/750\n",
      "162/162 [==============================] - 0s 643us/step - loss: 1.1773 - accuracy: 0.5160 - val_loss: 1.0989 - val_accuracy: 0.5926\n",
      "Epoch 221/750\n",
      "162/162 [==============================] - 0s 612us/step - loss: 1.1398 - accuracy: 0.5494 - val_loss: 1.1432 - val_accuracy: 0.5556\n",
      "Epoch 222/750\n",
      "162/162 [==============================] - 0s 642us/step - loss: 1.1460 - accuracy: 0.5296 - val_loss: 1.0909 - val_accuracy: 0.5593\n",
      "Epoch 223/750\n",
      "162/162 [==============================] - 0s 642us/step - loss: 1.1362 - accuracy: 0.5420 - val_loss: 1.1019 - val_accuracy: 0.6000\n",
      "Epoch 224/750\n",
      "162/162 [==============================] - 0s 672us/step - loss: 1.1427 - accuracy: 0.5444 - val_loss: 1.1513 - val_accuracy: 0.5370\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 225/750\n",
      "162/162 [==============================] - 0s 623us/step - loss: 1.1390 - accuracy: 0.5395 - val_loss: 1.1414 - val_accuracy: 0.5481\n",
      "Epoch 226/750\n",
      "162/162 [==============================] - 0s 662us/step - loss: 1.1511 - accuracy: 0.5321 - val_loss: 1.1436 - val_accuracy: 0.5704\n",
      "Epoch 227/750\n",
      "162/162 [==============================] - 0s 643us/step - loss: 1.1415 - accuracy: 0.5420 - val_loss: 1.1051 - val_accuracy: 0.6296\n",
      "Epoch 228/750\n",
      "162/162 [==============================] - 0s 632us/step - loss: 1.1419 - accuracy: 0.5160 - val_loss: 1.1171 - val_accuracy: 0.5852\n",
      "Epoch 229/750\n",
      "162/162 [==============================] - 0s 584us/step - loss: 1.1458 - accuracy: 0.5296 - val_loss: 1.1265 - val_accuracy: 0.5926\n",
      "Epoch 230/750\n",
      "162/162 [==============================] - 0s 642us/step - loss: 1.1371 - accuracy: 0.5494 - val_loss: 1.2016 - val_accuracy: 0.4370\n",
      "Epoch 231/750\n",
      "162/162 [==============================] - 0s 643us/step - loss: 1.1509 - accuracy: 0.5407 - val_loss: 1.1082 - val_accuracy: 0.5444\n",
      "Epoch 232/750\n",
      "162/162 [==============================] - 0s 642us/step - loss: 1.1206 - accuracy: 0.5420 - val_loss: 1.1371 - val_accuracy: 0.5519\n",
      "Epoch 233/750\n",
      "162/162 [==============================] - 0s 694us/step - loss: 1.1363 - accuracy: 0.5333 - val_loss: 1.0836 - val_accuracy: 0.6000\n",
      "Epoch 234/750\n",
      "162/162 [==============================] - 0s 710us/step - loss: 1.1319 - accuracy: 0.5494 - val_loss: 1.1511 - val_accuracy: 0.4778\n",
      "Epoch 235/750\n",
      "162/162 [==============================] - 0s 672us/step - loss: 1.1902 - accuracy: 0.5136 - val_loss: 1.0660 - val_accuracy: 0.6037\n",
      "Epoch 236/750\n",
      "162/162 [==============================] - 0s 672us/step - loss: 1.1433 - accuracy: 0.5506 - val_loss: 1.1239 - val_accuracy: 0.5444\n",
      "Epoch 237/750\n",
      "162/162 [==============================] - 0s 662us/step - loss: 1.1410 - accuracy: 0.5395 - val_loss: 1.1157 - val_accuracy: 0.5889\n",
      "Epoch 238/750\n",
      "162/162 [==============================] - 0s 643us/step - loss: 1.1470 - accuracy: 0.5346 - val_loss: 1.1811 - val_accuracy: 0.5519\n",
      "Epoch 239/750\n",
      "162/162 [==============================] - 0s 636us/step - loss: 1.1532 - accuracy: 0.5346 - val_loss: 1.1500 - val_accuracy: 0.5630\n",
      "Epoch 240/750\n",
      "162/162 [==============================] - 0s 642us/step - loss: 1.1687 - accuracy: 0.5247 - val_loss: 1.1191 - val_accuracy: 0.5481\n",
      "Epoch 241/750\n",
      "162/162 [==============================] - 0s 623us/step - loss: 1.1292 - accuracy: 0.5420 - val_loss: 1.0877 - val_accuracy: 0.5852\n",
      "Epoch 242/750\n",
      "162/162 [==============================] - 0s 642us/step - loss: 1.1316 - accuracy: 0.5432 - val_loss: 1.1018 - val_accuracy: 0.5741\n",
      "Epoch 243/750\n",
      "162/162 [==============================] - 0s 652us/step - loss: 1.1358 - accuracy: 0.5469 - val_loss: 1.1295 - val_accuracy: 0.5556\n",
      "Epoch 244/750\n",
      "162/162 [==============================] - 0s 633us/step - loss: 1.1421 - accuracy: 0.5432 - val_loss: 1.0958 - val_accuracy: 0.5926\n",
      "Epoch 245/750\n",
      "162/162 [==============================] - 0s 692us/step - loss: 1.1416 - accuracy: 0.5444 - val_loss: 1.1273 - val_accuracy: 0.5519\n",
      "Epoch 246/750\n",
      "162/162 [==============================] - 0s 719us/step - loss: 1.1554 - accuracy: 0.5309 - val_loss: 1.1158 - val_accuracy: 0.6222\n",
      "Epoch 247/750\n",
      "162/162 [==============================] - 0s 714us/step - loss: 1.1301 - accuracy: 0.5531 - val_loss: 1.0918 - val_accuracy: 0.6037\n",
      "Epoch 248/750\n",
      "162/162 [==============================] - 0s 642us/step - loss: 1.1441 - accuracy: 0.5321 - val_loss: 1.1516 - val_accuracy: 0.6222\n",
      "Epoch 249/750\n",
      "162/162 [==============================] - 0s 642us/step - loss: 1.1363 - accuracy: 0.5358 - val_loss: 1.1590 - val_accuracy: 0.5593\n",
      "Epoch 250/750\n",
      "162/162 [==============================] - 0s 643us/step - loss: 1.1505 - accuracy: 0.5444 - val_loss: 1.1496 - val_accuracy: 0.5296\n",
      "Epoch 251/750\n",
      "162/162 [==============================] - 0s 590us/step - loss: 1.1286 - accuracy: 0.5506 - val_loss: 1.1650 - val_accuracy: 0.5519\n",
      "Epoch 252/750\n",
      "162/162 [==============================] - 0s 642us/step - loss: 1.1364 - accuracy: 0.5617 - val_loss: 1.1537 - val_accuracy: 0.5370\n",
      "Epoch 253/750\n",
      "162/162 [==============================] - 0s 642us/step - loss: 1.1927 - accuracy: 0.5210 - val_loss: 1.1140 - val_accuracy: 0.5815\n",
      "Epoch 254/750\n",
      "162/162 [==============================] - 0s 662us/step - loss: 1.1233 - accuracy: 0.5457 - val_loss: 1.0899 - val_accuracy: 0.6185\n",
      "Epoch 255/750\n",
      "162/162 [==============================] - 0s 623us/step - loss: 1.1341 - accuracy: 0.5333 - val_loss: 1.1012 - val_accuracy: 0.5778\n",
      "Epoch 256/750\n",
      "162/162 [==============================] - 0s 624us/step - loss: 1.1384 - accuracy: 0.5494 - val_loss: 1.1316 - val_accuracy: 0.5407\n",
      "Epoch 257/750\n",
      "162/162 [==============================] - 0s 613us/step - loss: 1.1395 - accuracy: 0.5420 - val_loss: 1.1893 - val_accuracy: 0.4963\n",
      "Epoch 258/750\n",
      "162/162 [==============================] - 0s 661us/step - loss: 1.1316 - accuracy: 0.5494 - val_loss: 1.0932 - val_accuracy: 0.5593\n",
      "Epoch 259/750\n",
      "162/162 [==============================] - 0s 642us/step - loss: 1.1369 - accuracy: 0.5444 - val_loss: 1.1669 - val_accuracy: 0.5407\n",
      "Epoch 260/750\n",
      "162/162 [==============================] - 0s 642us/step - loss: 1.1424 - accuracy: 0.5358 - val_loss: 1.1203 - val_accuracy: 0.5667\n",
      "Epoch 261/750\n",
      "162/162 [==============================] - 0s 643us/step - loss: 1.1663 - accuracy: 0.5432 - val_loss: 1.0988 - val_accuracy: 0.5370\n",
      "Epoch 262/750\n",
      "162/162 [==============================] - 0s 642us/step - loss: 1.1126 - accuracy: 0.5531 - val_loss: 1.0778 - val_accuracy: 0.6037\n",
      "Epoch 263/750\n",
      "162/162 [==============================] - 0s 599us/step - loss: 1.1348 - accuracy: 0.5247 - val_loss: 1.0889 - val_accuracy: 0.6185\n",
      "Epoch 264/750\n",
      "162/162 [==============================] - 0s 659us/step - loss: 1.1269 - accuracy: 0.5543 - val_loss: 1.1156 - val_accuracy: 0.5037\n",
      "Epoch 265/750\n",
      "162/162 [==============================] - 0s 645us/step - loss: 1.1701 - accuracy: 0.5111 - val_loss: 1.1794 - val_accuracy: 0.5222\n",
      "Epoch 266/750\n",
      "162/162 [==============================] - 0s 672us/step - loss: 1.1419 - accuracy: 0.5346 - val_loss: 1.1561 - val_accuracy: 0.5296\n",
      "Epoch 267/750\n",
      "162/162 [==============================] - 0s 593us/step - loss: 1.1247 - accuracy: 0.5432 - val_loss: 1.0759 - val_accuracy: 0.6037\n",
      "Epoch 268/750\n",
      "162/162 [==============================] - 0s 672us/step - loss: 1.1983 - accuracy: 0.5136 - val_loss: 1.2589 - val_accuracy: 0.5333\n",
      "Epoch 269/750\n",
      "162/162 [==============================] - 0s 612us/step - loss: 1.1651 - accuracy: 0.5395 - val_loss: 1.0812 - val_accuracy: 0.6259\n",
      "Epoch 270/750\n",
      "162/162 [==============================] - 0s 593us/step - loss: 1.1561 - accuracy: 0.5321 - val_loss: 1.1284 - val_accuracy: 0.5741\n",
      "Epoch 271/750\n",
      "162/162 [==============================] - 0s 662us/step - loss: 1.1158 - accuracy: 0.5321 - val_loss: 1.1068 - val_accuracy: 0.5407\n",
      "Epoch 272/750\n",
      "162/162 [==============================] - 0s 642us/step - loss: 1.1367 - accuracy: 0.5370 - val_loss: 1.0999 - val_accuracy: 0.5926\n",
      "Epoch 273/750\n",
      "162/162 [==============================] - 0s 643us/step - loss: 1.1276 - accuracy: 0.5469 - val_loss: 1.0961 - val_accuracy: 0.5963\n",
      "Epoch 274/750\n",
      "162/162 [==============================] - 0s 642us/step - loss: 1.1163 - accuracy: 0.5420 - val_loss: 1.1605 - val_accuracy: 0.5333\n",
      "Epoch 275/750\n",
      "162/162 [==============================] - 0s 642us/step - loss: 1.1500 - accuracy: 0.5407 - val_loss: 1.0878 - val_accuracy: 0.6074\n",
      "Epoch 276/750\n",
      "162/162 [==============================] - 0s 603us/step - loss: 1.1165 - accuracy: 0.5568 - val_loss: 1.1994 - val_accuracy: 0.4963\n",
      "Epoch 277/750\n",
      "162/162 [==============================] - 0s 642us/step - loss: 1.1240 - accuracy: 0.5543 - val_loss: 1.1882 - val_accuracy: 0.4852\n",
      "Epoch 278/750\n",
      "162/162 [==============================] - 0s 642us/step - loss: 1.1301 - accuracy: 0.5346 - val_loss: 1.2421 - val_accuracy: 0.4852\n",
      "Epoch 279/750\n",
      "162/162 [==============================] - 0s 692us/step - loss: 1.1448 - accuracy: 0.5506 - val_loss: 1.0693 - val_accuracy: 0.5815\n",
      "Epoch 280/750\n",
      "162/162 [==============================] - 0s 612us/step - loss: 1.1229 - accuracy: 0.5296 - val_loss: 1.1142 - val_accuracy: 0.5778\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 281/750\n",
      "162/162 [==============================] - 0s 642us/step - loss: 1.1218 - accuracy: 0.5494 - val_loss: 1.0603 - val_accuracy: 0.5963\n",
      "Epoch 282/750\n",
      "162/162 [==============================] - 0s 611us/step - loss: 1.1559 - accuracy: 0.5333 - val_loss: 1.1268 - val_accuracy: 0.5259\n",
      "Epoch 283/750\n",
      "162/162 [==============================] - 0s 662us/step - loss: 1.1325 - accuracy: 0.5407 - val_loss: 1.1186 - val_accuracy: 0.5630\n",
      "Epoch 284/750\n",
      "162/162 [==============================] - 0s 643us/step - loss: 1.1172 - accuracy: 0.5494 - val_loss: 1.1351 - val_accuracy: 0.5148\n",
      "Epoch 285/750\n",
      "162/162 [==============================] - 0s 643us/step - loss: 1.1461 - accuracy: 0.5444 - val_loss: 1.1190 - val_accuracy: 0.5593\n",
      "Epoch 286/750\n",
      "162/162 [==============================] - 0s 692us/step - loss: 1.1242 - accuracy: 0.5296 - val_loss: 1.0746 - val_accuracy: 0.5852\n",
      "Epoch 287/750\n",
      "162/162 [==============================] - 0s 672us/step - loss: 1.1256 - accuracy: 0.5765 - val_loss: 1.1639 - val_accuracy: 0.4778\n",
      "Epoch 288/750\n",
      "162/162 [==============================] - 0s 623us/step - loss: 1.1283 - accuracy: 0.5580 - val_loss: 1.1358 - val_accuracy: 0.5333\n",
      "Epoch 289/750\n",
      "162/162 [==============================] - 0s 643us/step - loss: 1.1176 - accuracy: 0.5506 - val_loss: 1.1424 - val_accuracy: 0.5481\n",
      "Epoch 290/750\n",
      "162/162 [==============================] - 0s 643us/step - loss: 1.1307 - accuracy: 0.5420 - val_loss: 1.0855 - val_accuracy: 0.5519\n",
      "Epoch 291/750\n",
      "162/162 [==============================] - 0s 612us/step - loss: 1.1375 - accuracy: 0.5296 - val_loss: 1.3537 - val_accuracy: 0.4407\n",
      "Epoch 292/750\n",
      "162/162 [==============================] - 0s 676us/step - loss: 1.1070 - accuracy: 0.5395 - val_loss: 1.0727 - val_accuracy: 0.5926\n",
      "Epoch 293/750\n",
      "162/162 [==============================] - 0s 609us/step - loss: 1.1139 - accuracy: 0.5494 - val_loss: 1.0846 - val_accuracy: 0.5926\n",
      "Epoch 294/750\n",
      "162/162 [==============================] - 0s 593us/step - loss: 1.0964 - accuracy: 0.5568 - val_loss: 1.1011 - val_accuracy: 0.5519\n",
      "Epoch 295/750\n",
      "162/162 [==============================] - 0s 593us/step - loss: 1.1325 - accuracy: 0.5346 - val_loss: 1.1057 - val_accuracy: 0.6000\n",
      "Epoch 296/750\n",
      "162/162 [==============================] - 0s 673us/step - loss: 1.1538 - accuracy: 0.5136 - val_loss: 1.1660 - val_accuracy: 0.5370\n",
      "Epoch 297/750\n",
      "162/162 [==============================] - 0s 611us/step - loss: 1.1312 - accuracy: 0.5494 - val_loss: 1.0923 - val_accuracy: 0.5444\n",
      "Epoch 298/750\n",
      "162/162 [==============================] - 0s 642us/step - loss: 1.1184 - accuracy: 0.5506 - val_loss: 1.0893 - val_accuracy: 0.6148\n",
      "Epoch 299/750\n",
      "162/162 [==============================] - 0s 643us/step - loss: 1.1178 - accuracy: 0.5457 - val_loss: 1.1063 - val_accuracy: 0.5667\n",
      "Epoch 300/750\n",
      "162/162 [==============================] - 0s 593us/step - loss: 1.1033 - accuracy: 0.5506 - val_loss: 1.1014 - val_accuracy: 0.5519\n",
      "Epoch 301/750\n",
      "162/162 [==============================] - 0s 642us/step - loss: 1.1195 - accuracy: 0.5309 - val_loss: 1.0481 - val_accuracy: 0.6074\n",
      "Epoch 302/750\n",
      "162/162 [==============================] - 0s 699us/step - loss: 1.1282 - accuracy: 0.5407 - val_loss: 1.1018 - val_accuracy: 0.5667\n",
      "Epoch 303/750\n",
      "162/162 [==============================] - 0s 770us/step - loss: 1.1146 - accuracy: 0.5568 - val_loss: 1.0661 - val_accuracy: 0.5926\n",
      "Epoch 304/750\n",
      "162/162 [==============================] - 0s 741us/step - loss: 1.1043 - accuracy: 0.5444 - val_loss: 1.1840 - val_accuracy: 0.5259\n",
      "Epoch 305/750\n",
      "162/162 [==============================] - 0s 646us/step - loss: 1.1036 - accuracy: 0.5568 - val_loss: 1.0906 - val_accuracy: 0.5630\n",
      "Epoch 306/750\n",
      "162/162 [==============================] - 0s 642us/step - loss: 1.1362 - accuracy: 0.5370 - val_loss: 1.0826 - val_accuracy: 0.5926\n",
      "Epoch 307/750\n",
      "162/162 [==============================] - 0s 593us/step - loss: 1.1300 - accuracy: 0.5272 - val_loss: 1.1847 - val_accuracy: 0.5593\n",
      "Epoch 308/750\n",
      "162/162 [==============================] - 0s 593us/step - loss: 1.1317 - accuracy: 0.5333 - val_loss: 1.0818 - val_accuracy: 0.5815\n",
      "Epoch 309/750\n",
      "162/162 [==============================] - 0s 593us/step - loss: 1.1348 - accuracy: 0.5198 - val_loss: 1.0718 - val_accuracy: 0.5407\n",
      "Epoch 310/750\n",
      "162/162 [==============================] - 0s 612us/step - loss: 1.1224 - accuracy: 0.5420 - val_loss: 1.1483 - val_accuracy: 0.5963\n",
      "Epoch 311/750\n",
      "162/162 [==============================] - 0s 623us/step - loss: 1.1086 - accuracy: 0.5469 - val_loss: 1.1343 - val_accuracy: 0.4852\n",
      "Epoch 312/750\n",
      "162/162 [==============================] - 0s 593us/step - loss: 1.1143 - accuracy: 0.5481 - val_loss: 1.0530 - val_accuracy: 0.5926\n",
      "Epoch 313/750\n",
      "162/162 [==============================] - 0s 612us/step - loss: 1.1419 - accuracy: 0.5358 - val_loss: 1.1323 - val_accuracy: 0.5630\n",
      "Epoch 314/750\n",
      "162/162 [==============================] - 0s 593us/step - loss: 1.1159 - accuracy: 0.5481 - val_loss: 1.0612 - val_accuracy: 0.6037\n",
      "Epoch 315/750\n",
      "162/162 [==============================] - 0s 593us/step - loss: 1.1325 - accuracy: 0.5444 - val_loss: 1.0507 - val_accuracy: 0.6074\n",
      "Epoch 316/750\n",
      "162/162 [==============================] - 0s 642us/step - loss: 1.1178 - accuracy: 0.5704 - val_loss: 1.1532 - val_accuracy: 0.4667\n",
      "Epoch 317/750\n",
      "162/162 [==============================] - 0s 640us/step - loss: 1.1249 - accuracy: 0.5383 - val_loss: 1.2685 - val_accuracy: 0.4333\n",
      "Epoch 318/750\n",
      "162/162 [==============================] - 0s 645us/step - loss: 1.1293 - accuracy: 0.5469 - val_loss: 1.0858 - val_accuracy: 0.5667\n",
      "Epoch 319/750\n",
      "162/162 [==============================] - 0s 642us/step - loss: 1.1095 - accuracy: 0.5593 - val_loss: 1.0566 - val_accuracy: 0.5370\n",
      "Epoch 320/750\n",
      "162/162 [==============================] - 0s 643us/step - loss: 1.1223 - accuracy: 0.5358 - val_loss: 1.0674 - val_accuracy: 0.5889\n",
      "Epoch 321/750\n",
      "162/162 [==============================] - 0s 672us/step - loss: 1.1271 - accuracy: 0.5556 - val_loss: 1.0832 - val_accuracy: 0.5778\n",
      "Epoch 322/750\n",
      "162/162 [==============================] - 0s 642us/step - loss: 1.1191 - accuracy: 0.5395 - val_loss: 1.0463 - val_accuracy: 0.5333\n",
      "Epoch 323/750\n",
      "162/162 [==============================] - 0s 642us/step - loss: 1.1352 - accuracy: 0.5494 - val_loss: 1.0552 - val_accuracy: 0.5704\n",
      "Epoch 324/750\n",
      "162/162 [==============================] - 0s 643us/step - loss: 1.1035 - accuracy: 0.5519 - val_loss: 1.0528 - val_accuracy: 0.5815\n",
      "Epoch 325/750\n",
      "162/162 [==============================] - 0s 642us/step - loss: 1.0999 - accuracy: 0.5556 - val_loss: 1.1182 - val_accuracy: 0.5296\n",
      "Epoch 326/750\n",
      "162/162 [==============================] - 0s 595us/step - loss: 1.1223 - accuracy: 0.5383 - val_loss: 1.0786 - val_accuracy: 0.6148\n",
      "Epoch 327/750\n",
      "162/162 [==============================] - 0s 592us/step - loss: 1.1121 - accuracy: 0.5568 - val_loss: 1.1046 - val_accuracy: 0.5481\n",
      "Epoch 328/750\n",
      "162/162 [==============================] - 0s 593us/step - loss: 1.1346 - accuracy: 0.5395 - val_loss: 1.0689 - val_accuracy: 0.6222\n",
      "Epoch 329/750\n",
      "162/162 [==============================] - 0s 596us/step - loss: 1.1265 - accuracy: 0.5580 - val_loss: 1.0764 - val_accuracy: 0.5370\n",
      "Epoch 330/750\n",
      "162/162 [==============================] - 0s 641us/step - loss: 1.1097 - accuracy: 0.5321 - val_loss: 1.0537 - val_accuracy: 0.6185\n",
      "Epoch 331/750\n",
      "162/162 [==============================] - 0s 690us/step - loss: 1.1040 - accuracy: 0.5481 - val_loss: 1.1333 - val_accuracy: 0.5667\n",
      "Epoch 332/750\n",
      "162/162 [==============================] - 0s 623us/step - loss: 1.1046 - accuracy: 0.5556 - val_loss: 1.1421 - val_accuracy: 0.4889\n",
      "Epoch 333/750\n",
      "162/162 [==============================] - 0s 642us/step - loss: 1.1075 - accuracy: 0.5617 - val_loss: 1.1044 - val_accuracy: 0.5741\n",
      "Epoch 334/750\n",
      "162/162 [==============================] - 0s 613us/step - loss: 1.1242 - accuracy: 0.5358 - val_loss: 1.1972 - val_accuracy: 0.5111\n",
      "Epoch 335/750\n",
      "162/162 [==============================] - 0s 643us/step - loss: 1.1099 - accuracy: 0.5481 - val_loss: 1.0754 - val_accuracy: 0.5926\n",
      "Epoch 336/750\n",
      "162/162 [==============================] - 0s 642us/step - loss: 1.1119 - accuracy: 0.5593 - val_loss: 1.0536 - val_accuracy: 0.5630\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 337/750\n",
      "162/162 [==============================] - 0s 643us/step - loss: 1.1075 - accuracy: 0.5580 - val_loss: 1.1535 - val_accuracy: 0.5852\n",
      "Epoch 338/750\n",
      "162/162 [==============================] - 0s 643us/step - loss: 1.1110 - accuracy: 0.5469 - val_loss: 1.0835 - val_accuracy: 0.5889\n",
      "Epoch 339/750\n",
      "162/162 [==============================] - 0s 643us/step - loss: 1.1238 - accuracy: 0.5210 - val_loss: 1.0887 - val_accuracy: 0.5370\n",
      "Epoch 340/750\n",
      "162/162 [==============================] - 0s 642us/step - loss: 1.1027 - accuracy: 0.5531 - val_loss: 1.1192 - val_accuracy: 0.6000\n",
      "Epoch 341/750\n",
      "162/162 [==============================] - 0s 642us/step - loss: 1.0987 - accuracy: 0.5654 - val_loss: 1.1108 - val_accuracy: 0.5333\n",
      "Epoch 342/750\n",
      "162/162 [==============================] - 0s 642us/step - loss: 1.1054 - accuracy: 0.5593 - val_loss: 1.1021 - val_accuracy: 0.5556\n",
      "Epoch 343/750\n",
      "162/162 [==============================] - 0s 643us/step - loss: 1.1101 - accuracy: 0.5383 - val_loss: 1.0555 - val_accuracy: 0.6037\n",
      "Epoch 344/750\n",
      "162/162 [==============================] - 0s 642us/step - loss: 1.1306 - accuracy: 0.5407 - val_loss: 1.1043 - val_accuracy: 0.5667\n",
      "Epoch 345/750\n",
      "162/162 [==============================] - 0s 643us/step - loss: 1.0996 - accuracy: 0.5432 - val_loss: 1.0946 - val_accuracy: 0.6037\n",
      "Epoch 346/750\n",
      "162/162 [==============================] - 0s 643us/step - loss: 1.1024 - accuracy: 0.5383 - val_loss: 1.0475 - val_accuracy: 0.5815\n",
      "Epoch 347/750\n",
      "162/162 [==============================] - 0s 642us/step - loss: 1.1195 - accuracy: 0.5494 - val_loss: 1.0540 - val_accuracy: 0.5963\n",
      "Epoch 348/750\n",
      "162/162 [==============================] - 0s 643us/step - loss: 1.1098 - accuracy: 0.5593 - val_loss: 1.0784 - val_accuracy: 0.5667\n",
      "Epoch 349/750\n",
      "162/162 [==============================] - 0s 690us/step - loss: 1.1061 - accuracy: 0.5580 - val_loss: 1.0605 - val_accuracy: 0.6000\n",
      "Epoch 350/750\n",
      "162/162 [==============================] - 0s 643us/step - loss: 1.0901 - accuracy: 0.5753 - val_loss: 1.0702 - val_accuracy: 0.5852\n",
      "Epoch 351/750\n",
      "162/162 [==============================] - 0s 642us/step - loss: 1.1210 - accuracy: 0.5420 - val_loss: 1.0339 - val_accuracy: 0.5926\n",
      "Epoch 352/750\n",
      "162/162 [==============================] - 0s 642us/step - loss: 1.1192 - accuracy: 0.5531 - val_loss: 1.2093 - val_accuracy: 0.4963\n",
      "Epoch 353/750\n",
      "162/162 [==============================] - 0s 643us/step - loss: 1.1077 - accuracy: 0.5383 - val_loss: 1.0640 - val_accuracy: 0.6074\n",
      "Epoch 354/750\n",
      "162/162 [==============================] - 0s 642us/step - loss: 1.1522 - accuracy: 0.5383 - val_loss: 1.0526 - val_accuracy: 0.5815\n",
      "Epoch 355/750\n",
      "162/162 [==============================] - 0s 642us/step - loss: 1.0930 - accuracy: 0.5630 - val_loss: 1.0704 - val_accuracy: 0.5889\n",
      "Epoch 356/750\n",
      "162/162 [==============================] - 0s 643us/step - loss: 1.0997 - accuracy: 0.5630 - val_loss: 1.0543 - val_accuracy: 0.6148\n",
      "Epoch 357/750\n",
      "162/162 [==============================] - 0s 642us/step - loss: 1.1022 - accuracy: 0.5605 - val_loss: 1.0656 - val_accuracy: 0.5926\n",
      "Epoch 358/750\n",
      "162/162 [==============================] - 0s 642us/step - loss: 1.0906 - accuracy: 0.5593 - val_loss: 1.0549 - val_accuracy: 0.5889\n",
      "Epoch 359/750\n",
      "162/162 [==============================] - 0s 676us/step - loss: 1.0943 - accuracy: 0.5580 - val_loss: 1.0674 - val_accuracy: 0.5519\n",
      "Epoch 360/750\n",
      "162/162 [==============================] - 0s 639us/step - loss: 1.0926 - accuracy: 0.5481 - val_loss: 1.0889 - val_accuracy: 0.5444\n",
      "Epoch 361/750\n",
      "162/162 [==============================] - 0s 645us/step - loss: 1.0909 - accuracy: 0.5494 - val_loss: 1.0756 - val_accuracy: 0.5704\n",
      "Epoch 362/750\n",
      "162/162 [==============================] - 0s 640us/step - loss: 1.0920 - accuracy: 0.5593 - val_loss: 1.0469 - val_accuracy: 0.5963\n",
      "Epoch 363/750\n",
      "162/162 [==============================] - 0s 643us/step - loss: 1.1231 - accuracy: 0.5457 - val_loss: 1.0214 - val_accuracy: 0.5889\n",
      "Epoch 364/750\n",
      "162/162 [==============================] - 0s 642us/step - loss: 1.0900 - accuracy: 0.5556 - val_loss: 1.0655 - val_accuracy: 0.5407\n",
      "Epoch 365/750\n",
      "162/162 [==============================] - 0s 623us/step - loss: 1.1009 - accuracy: 0.5481 - val_loss: 1.0811 - val_accuracy: 0.5778\n",
      "Epoch 366/750\n",
      "162/162 [==============================] - 0s 662us/step - loss: 1.1050 - accuracy: 0.5469 - val_loss: 1.1561 - val_accuracy: 0.4741\n",
      "Epoch 367/750\n",
      "162/162 [==============================] - 0s 642us/step - loss: 1.0988 - accuracy: 0.5679 - val_loss: 1.0596 - val_accuracy: 0.5889\n",
      "Epoch 368/750\n",
      "162/162 [==============================] - 0s 646us/step - loss: 1.1017 - accuracy: 0.5543 - val_loss: 1.0197 - val_accuracy: 0.6111\n",
      "Epoch 369/750\n",
      "162/162 [==============================] - 0s 639us/step - loss: 1.1148 - accuracy: 0.5519 - val_loss: 1.0685 - val_accuracy: 0.6074\n",
      "Epoch 370/750\n",
      "162/162 [==============================] - 0s 692us/step - loss: 1.1017 - accuracy: 0.5568 - val_loss: 1.0531 - val_accuracy: 0.5556\n",
      "Epoch 371/750\n",
      "162/162 [==============================] - 0s 623us/step - loss: 1.0698 - accuracy: 0.5642 - val_loss: 1.0691 - val_accuracy: 0.6037\n",
      "Epoch 372/750\n",
      "162/162 [==============================] - 0s 643us/step - loss: 1.1522 - accuracy: 0.5494 - val_loss: 1.6269 - val_accuracy: 0.4963\n",
      "Epoch 373/750\n",
      "162/162 [==============================] - 0s 661us/step - loss: 1.1417 - accuracy: 0.5420 - val_loss: 1.1623 - val_accuracy: 0.5556\n",
      "Epoch 374/750\n",
      "162/162 [==============================] - 0s 642us/step - loss: 1.1141 - accuracy: 0.5407 - val_loss: 1.0819 - val_accuracy: 0.5926\n",
      "Epoch 375/750\n",
      "162/162 [==============================] - 0s 643us/step - loss: 1.1244 - accuracy: 0.5420 - val_loss: 1.0745 - val_accuracy: 0.6148\n",
      "Epoch 376/750\n",
      "162/162 [==============================] - 0s 623us/step - loss: 1.0839 - accuracy: 0.5679 - val_loss: 1.0826 - val_accuracy: 0.6000\n",
      "Epoch 377/750\n",
      "162/162 [==============================] - 0s 642us/step - loss: 1.1065 - accuracy: 0.5519 - val_loss: 1.0950 - val_accuracy: 0.5407\n",
      "Epoch 378/750\n",
      "162/162 [==============================] - 0s 692us/step - loss: 1.0995 - accuracy: 0.5568 - val_loss: 1.0606 - val_accuracy: 0.6037\n",
      "Epoch 379/750\n",
      "162/162 [==============================] - 0s 623us/step - loss: 1.0887 - accuracy: 0.5358 - val_loss: 1.1395 - val_accuracy: 0.5222\n",
      "Epoch 380/750\n",
      "162/162 [==============================] - 0s 688us/step - loss: 1.1239 - accuracy: 0.5494 - val_loss: 1.2726 - val_accuracy: 0.4926\n",
      "Epoch 381/750\n",
      "162/162 [==============================] - 0s 668us/step - loss: 1.0921 - accuracy: 0.5605 - val_loss: 1.4098 - val_accuracy: 0.4630\n",
      "Epoch 382/750\n",
      "162/162 [==============================] - 0s 689us/step - loss: 1.0905 - accuracy: 0.5556 - val_loss: 1.0828 - val_accuracy: 0.5815\n",
      "Epoch 383/750\n",
      "162/162 [==============================] - 0s 635us/step - loss: 1.1037 - accuracy: 0.5333 - val_loss: 1.0900 - val_accuracy: 0.6037\n",
      "Epoch 384/750\n",
      "162/162 [==============================] - 0s 643us/step - loss: 1.1130 - accuracy: 0.5481 - val_loss: 1.2165 - val_accuracy: 0.5148\n",
      "Epoch 385/750\n",
      "162/162 [==============================] - 0s 662us/step - loss: 1.0988 - accuracy: 0.5568 - val_loss: 1.0553 - val_accuracy: 0.5630\n",
      "Epoch 386/750\n",
      "162/162 [==============================] - 0s 673us/step - loss: 1.0963 - accuracy: 0.5420 - val_loss: 1.1758 - val_accuracy: 0.5704\n",
      "Epoch 387/750\n",
      "162/162 [==============================] - 0s 612us/step - loss: 1.0886 - accuracy: 0.5556 - val_loss: 1.0657 - val_accuracy: 0.5889\n",
      "Epoch 388/750\n",
      "162/162 [==============================] - 0s 623us/step - loss: 1.0960 - accuracy: 0.5556 - val_loss: 1.0808 - val_accuracy: 0.6148\n",
      "Epoch 389/750\n",
      "162/162 [==============================] - 0s 666us/step - loss: 1.0928 - accuracy: 0.5642 - val_loss: 1.0912 - val_accuracy: 0.5481\n",
      "Epoch 390/750\n",
      "162/162 [==============================] - 0s 638us/step - loss: 1.0822 - accuracy: 0.5506 - val_loss: 1.0637 - val_accuracy: 0.5815\n",
      "Epoch 391/750\n",
      "162/162 [==============================] - 0s 623us/step - loss: 1.0723 - accuracy: 0.5593 - val_loss: 1.0951 - val_accuracy: 0.6000\n",
      "Epoch 392/750\n",
      "162/162 [==============================] - 0s 643us/step - loss: 1.1030 - accuracy: 0.5543 - val_loss: 1.1793 - val_accuracy: 0.5111\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 393/750\n",
      "162/162 [==============================] - 0s 642us/step - loss: 1.0947 - accuracy: 0.5506 - val_loss: 1.1368 - val_accuracy: 0.5296\n",
      "Epoch 394/750\n",
      "162/162 [==============================] - 0s 643us/step - loss: 1.0935 - accuracy: 0.5593 - val_loss: 1.0452 - val_accuracy: 0.5778\n",
      "Epoch 395/750\n",
      "162/162 [==============================] - 0s 623us/step - loss: 1.0960 - accuracy: 0.5481 - val_loss: 1.0488 - val_accuracy: 0.5926\n",
      "Epoch 396/750\n",
      "162/162 [==============================] - 0s 642us/step - loss: 1.1138 - accuracy: 0.5469 - val_loss: 1.0972 - val_accuracy: 0.5593\n",
      "Epoch 397/750\n",
      "162/162 [==============================] - 0s 642us/step - loss: 1.0992 - accuracy: 0.5481 - val_loss: 1.0411 - val_accuracy: 0.5889\n",
      "Epoch 398/750\n",
      "162/162 [==============================] - 0s 693us/step - loss: 1.0837 - accuracy: 0.5728 - val_loss: 1.0339 - val_accuracy: 0.5926\n",
      "Epoch 399/750\n",
      "162/162 [==============================] - 0s 611us/step - loss: 1.1202 - accuracy: 0.5383 - val_loss: 1.0389 - val_accuracy: 0.5815\n",
      "Epoch 400/750\n",
      "162/162 [==============================] - 0s 643us/step - loss: 1.1056 - accuracy: 0.5469 - val_loss: 1.0338 - val_accuracy: 0.6037\n",
      "Epoch 401/750\n",
      "162/162 [==============================] - 0s 643us/step - loss: 1.0805 - accuracy: 0.5494 - val_loss: 1.0596 - val_accuracy: 0.5889\n",
      "Epoch 402/750\n",
      "162/162 [==============================] - 0s 642us/step - loss: 1.0687 - accuracy: 0.5802 - val_loss: 1.1923 - val_accuracy: 0.5222\n",
      "Epoch 403/750\n",
      "162/162 [==============================] - 0s 643us/step - loss: 1.0890 - accuracy: 0.5765 - val_loss: 1.0705 - val_accuracy: 0.5815\n",
      "Epoch 404/750\n",
      "162/162 [==============================] - 0s 622us/step - loss: 1.0937 - accuracy: 0.5667 - val_loss: 1.1024 - val_accuracy: 0.5889\n",
      "Epoch 405/750\n",
      "162/162 [==============================] - 0s 642us/step - loss: 1.1033 - accuracy: 0.5469 - val_loss: 1.0298 - val_accuracy: 0.6148\n",
      "Epoch 406/750\n",
      "162/162 [==============================] - 0s 623us/step - loss: 1.0950 - accuracy: 0.5531 - val_loss: 1.0379 - val_accuracy: 0.5556\n",
      "Epoch 407/750\n",
      "162/162 [==============================] - 0s 642us/step - loss: 1.0871 - accuracy: 0.5531 - val_loss: 1.1407 - val_accuracy: 0.5111\n",
      "Epoch 408/750\n",
      "162/162 [==============================] - 0s 612us/step - loss: 1.0901 - accuracy: 0.5691 - val_loss: 1.0639 - val_accuracy: 0.6037\n",
      "Epoch 409/750\n",
      "162/162 [==============================] - 0s 673us/step - loss: 1.0768 - accuracy: 0.5383 - val_loss: 1.0396 - val_accuracy: 0.5778\n",
      "Epoch 410/750\n",
      "162/162 [==============================] - 0s 661us/step - loss: 1.0990 - accuracy: 0.5531 - val_loss: 1.0200 - val_accuracy: 0.5852\n",
      "Epoch 411/750\n",
      "162/162 [==============================] - 0s 642us/step - loss: 1.0741 - accuracy: 0.5679 - val_loss: 1.0464 - val_accuracy: 0.6000\n",
      "Epoch 412/750\n",
      "162/162 [==============================] - 0s 603us/step - loss: 1.1027 - accuracy: 0.5568 - val_loss: 1.0031 - val_accuracy: 0.6000\n",
      "Epoch 413/750\n",
      "162/162 [==============================] - 0s 662us/step - loss: 1.0854 - accuracy: 0.5543 - val_loss: 1.0266 - val_accuracy: 0.5963\n",
      "Epoch 414/750\n",
      "162/162 [==============================] - 0s 642us/step - loss: 1.1403 - accuracy: 0.5272 - val_loss: 1.0359 - val_accuracy: 0.6222\n",
      "Epoch 415/750\n",
      "162/162 [==============================] - 0s 642us/step - loss: 1.0870 - accuracy: 0.5506 - val_loss: 1.0480 - val_accuracy: 0.6037\n",
      "Epoch 416/750\n",
      "162/162 [==============================] - 0s 643us/step - loss: 1.0766 - accuracy: 0.5543 - val_loss: 1.0973 - val_accuracy: 0.5407\n",
      "Epoch 417/750\n",
      "162/162 [==============================] - 0s 642us/step - loss: 1.1055 - accuracy: 0.5568 - val_loss: 1.0620 - val_accuracy: 0.5889\n",
      "Epoch 418/750\n",
      "162/162 [==============================] - 0s 692us/step - loss: 1.0886 - accuracy: 0.5617 - val_loss: 1.0788 - val_accuracy: 0.5815\n",
      "Epoch 419/750\n",
      "162/162 [==============================] - 0s 622us/step - loss: 1.0638 - accuracy: 0.5728 - val_loss: 1.0842 - val_accuracy: 0.5741\n",
      "Epoch 420/750\n",
      "162/162 [==============================] - 0s 643us/step - loss: 1.0941 - accuracy: 0.5494 - val_loss: 1.0795 - val_accuracy: 0.6111\n",
      "Epoch 421/750\n",
      "162/162 [==============================] - 0s 642us/step - loss: 1.1343 - accuracy: 0.5469 - val_loss: 1.1189 - val_accuracy: 0.5407\n",
      "Epoch 422/750\n",
      "162/162 [==============================] - 0s 642us/step - loss: 1.1192 - accuracy: 0.5444 - val_loss: 1.3216 - val_accuracy: 0.4222\n",
      "Epoch 423/750\n",
      "162/162 [==============================] - 0s 642us/step - loss: 1.1207 - accuracy: 0.5506 - val_loss: 1.0574 - val_accuracy: 0.6074\n",
      "Epoch 424/750\n",
      "162/162 [==============================] - 0s 643us/step - loss: 1.0867 - accuracy: 0.5802 - val_loss: 1.0592 - val_accuracy: 0.5926\n",
      "Epoch 425/750\n",
      "162/162 [==============================] - 0s 642us/step - loss: 1.0881 - accuracy: 0.5556 - val_loss: 1.1271 - val_accuracy: 0.5593\n",
      "Epoch 426/750\n",
      "162/162 [==============================] - 0s 642us/step - loss: 1.1037 - accuracy: 0.5531 - val_loss: 1.1188 - val_accuracy: 0.5259\n",
      "Epoch 427/750\n",
      "162/162 [==============================] - 0s 642us/step - loss: 1.1018 - accuracy: 0.5420 - val_loss: 1.0772 - val_accuracy: 0.6000\n",
      "Epoch 428/750\n",
      "162/162 [==============================] - 0s 643us/step - loss: 1.1121 - accuracy: 0.5469 - val_loss: 1.1493 - val_accuracy: 0.5148\n",
      "Epoch 429/750\n",
      "162/162 [==============================] - 0s 692us/step - loss: 1.1019 - accuracy: 0.5704 - val_loss: 1.0876 - val_accuracy: 0.5667\n",
      "Epoch 430/750\n",
      "162/162 [==============================] - 0s 623us/step - loss: 1.0980 - accuracy: 0.5593 - val_loss: 1.0575 - val_accuracy: 0.6037\n",
      "Epoch 431/750\n",
      "162/162 [==============================] - 0s 613us/step - loss: 1.1131 - accuracy: 0.5605 - val_loss: 1.2306 - val_accuracy: 0.4889\n",
      "Epoch 432/750\n",
      "162/162 [==============================] - 0s 673us/step - loss: 1.1200 - accuracy: 0.5346 - val_loss: 1.0897 - val_accuracy: 0.5593\n",
      "Epoch 433/750\n",
      "162/162 [==============================] - 0s 661us/step - loss: 1.0875 - accuracy: 0.5704 - val_loss: 1.0544 - val_accuracy: 0.6074\n",
      "Epoch 434/750\n",
      "162/162 [==============================] - 0s 642us/step - loss: 1.0887 - accuracy: 0.5469 - val_loss: 1.0855 - val_accuracy: 0.5519\n",
      "Epoch 435/750\n",
      "162/162 [==============================] - 0s 643us/step - loss: 1.0762 - accuracy: 0.5617 - val_loss: 1.1276 - val_accuracy: 0.5963\n",
      "Epoch 436/750\n",
      "162/162 [==============================] - 0s 692us/step - loss: 1.0876 - accuracy: 0.5556 - val_loss: 1.1679 - val_accuracy: 0.5074\n",
      "Epoch 437/750\n",
      "162/162 [==============================] - 0s 623us/step - loss: 1.1017 - accuracy: 0.5556 - val_loss: 1.0497 - val_accuracy: 0.5852\n",
      "Epoch 438/750\n",
      "162/162 [==============================] - 0s 623us/step - loss: 1.0739 - accuracy: 0.5630 - val_loss: 1.1214 - val_accuracy: 0.5185\n",
      "Epoch 439/750\n",
      "162/162 [==============================] - 0s 643us/step - loss: 1.0853 - accuracy: 0.5444 - val_loss: 1.0950 - val_accuracy: 0.5519\n",
      "Epoch 440/750\n",
      "162/162 [==============================] - 0s 612us/step - loss: 1.0943 - accuracy: 0.5617 - val_loss: 1.1291 - val_accuracy: 0.5222\n",
      "Epoch 441/750\n",
      "162/162 [==============================] - 0s 643us/step - loss: 1.0836 - accuracy: 0.5593 - val_loss: 1.0390 - val_accuracy: 0.6074\n",
      "Epoch 442/750\n",
      "162/162 [==============================] - 0s 643us/step - loss: 1.0995 - accuracy: 0.5519 - val_loss: 1.0752 - val_accuracy: 0.5556\n",
      "Epoch 443/750\n",
      "162/162 [==============================] - 0s 603us/step - loss: 1.0765 - accuracy: 0.5457 - val_loss: 1.1384 - val_accuracy: 0.5630\n",
      "Epoch 444/750\n",
      "162/162 [==============================] - 0s 641us/step - loss: 1.0869 - accuracy: 0.5494 - val_loss: 1.0646 - val_accuracy: 0.6000\n",
      "Epoch 445/750\n",
      "162/162 [==============================] - 0s 642us/step - loss: 1.1167 - accuracy: 0.5432 - val_loss: 1.0438 - val_accuracy: 0.6148\n",
      "Epoch 446/750\n",
      "162/162 [==============================] - 0s 623us/step - loss: 1.0780 - accuracy: 0.5494 - val_loss: 1.4501 - val_accuracy: 0.4185\n",
      "Epoch 447/750\n",
      "162/162 [==============================] - 0s 642us/step - loss: 1.1164 - accuracy: 0.5370 - val_loss: 1.0483 - val_accuracy: 0.6074\n",
      "Epoch 448/750\n",
      "162/162 [==============================] - 0s 642us/step - loss: 1.0795 - accuracy: 0.5580 - val_loss: 1.0305 - val_accuracy: 0.6259\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 449/750\n",
      "162/162 [==============================] - 0s 662us/step - loss: 1.1157 - accuracy: 0.5395 - val_loss: 1.0878 - val_accuracy: 0.5778\n",
      "Epoch 450/750\n",
      "162/162 [==============================] - 0s 623us/step - loss: 1.0710 - accuracy: 0.5457 - val_loss: 1.1058 - val_accuracy: 0.5556\n",
      "Epoch 451/750\n",
      "162/162 [==============================] - 0s 642us/step - loss: 1.0842 - accuracy: 0.5617 - val_loss: 1.1068 - val_accuracy: 0.6000\n",
      "Epoch 452/750\n",
      "162/162 [==============================] - 0s 642us/step - loss: 1.0777 - accuracy: 0.5543 - val_loss: 1.0663 - val_accuracy: 0.5296\n",
      "Epoch 453/750\n",
      "162/162 [==============================] - 0s 643us/step - loss: 1.0921 - accuracy: 0.5494 - val_loss: 1.0748 - val_accuracy: 0.5741\n",
      "Epoch 454/750\n",
      "162/162 [==============================] - 0s 643us/step - loss: 1.0716 - accuracy: 0.5679 - val_loss: 1.0500 - val_accuracy: 0.6037\n",
      "Epoch 455/750\n",
      "162/162 [==============================] - 0s 612us/step - loss: 1.0581 - accuracy: 0.5827 - val_loss: 1.0225 - val_accuracy: 0.6222\n",
      "Epoch 456/750\n",
      "162/162 [==============================] - 0s 593us/step - loss: 1.0699 - accuracy: 0.5741 - val_loss: 1.0117 - val_accuracy: 0.6000\n",
      "Epoch 457/750\n",
      "162/162 [==============================] - 0s 593us/step - loss: 1.0654 - accuracy: 0.5691 - val_loss: 1.0517 - val_accuracy: 0.5556\n",
      "Epoch 458/750\n",
      "162/162 [==============================] - 0s 593us/step - loss: 1.0786 - accuracy: 0.5531 - val_loss: 1.0434 - val_accuracy: 0.5815\n",
      "Epoch 459/750\n",
      "162/162 [==============================] - 0s 642us/step - loss: 1.0892 - accuracy: 0.5543 - val_loss: 1.3353 - val_accuracy: 0.4074\n",
      "Epoch 460/750\n",
      "162/162 [==============================] - 0s 642us/step - loss: 1.0799 - accuracy: 0.5654 - val_loss: 1.0442 - val_accuracy: 0.5815\n",
      "Epoch 461/750\n",
      "162/162 [==============================] - 0s 642us/step - loss: 1.0933 - accuracy: 0.5395 - val_loss: 1.0896 - val_accuracy: 0.5444\n",
      "Epoch 462/750\n",
      "162/162 [==============================] - 0s 593us/step - loss: 1.0603 - accuracy: 0.5679 - val_loss: 1.0218 - val_accuracy: 0.6037\n",
      "Epoch 463/750\n",
      "162/162 [==============================] - 0s 593us/step - loss: 1.0856 - accuracy: 0.5654 - val_loss: 1.0305 - val_accuracy: 0.5963\n",
      "Epoch 464/750\n",
      "162/162 [==============================] - 0s 692us/step - loss: 1.0849 - accuracy: 0.5481 - val_loss: 1.1493 - val_accuracy: 0.5333\n",
      "Epoch 465/750\n",
      "162/162 [==============================] - 0s 672us/step - loss: 1.0923 - accuracy: 0.5568 - val_loss: 1.0148 - val_accuracy: 0.6111\n",
      "Epoch 466/750\n",
      "162/162 [==============================] - 0s 623us/step - loss: 1.0989 - accuracy: 0.5506 - val_loss: 1.0741 - val_accuracy: 0.6111\n",
      "Epoch 467/750\n",
      "162/162 [==============================] - 0s 642us/step - loss: 1.0845 - accuracy: 0.5617 - val_loss: 1.1040 - val_accuracy: 0.5889\n",
      "Epoch 468/750\n",
      "162/162 [==============================] - 0s 643us/step - loss: 1.0808 - accuracy: 0.5568 - val_loss: 1.0476 - val_accuracy: 0.5481\n",
      "Epoch 469/750\n",
      "162/162 [==============================] - 0s 612us/step - loss: 1.0762 - accuracy: 0.5630 - val_loss: 1.1165 - val_accuracy: 0.5333\n",
      "Epoch 470/750\n",
      "162/162 [==============================] - 0s 593us/step - loss: 1.0880 - accuracy: 0.5568 - val_loss: 1.0849 - val_accuracy: 0.5926\n",
      "Epoch 471/750\n",
      "162/162 [==============================] - 0s 623us/step - loss: 1.0629 - accuracy: 0.5630 - val_loss: 1.1500 - val_accuracy: 0.5630\n",
      "Epoch 472/750\n",
      "162/162 [==============================] - 0s 644us/step - loss: 1.0850 - accuracy: 0.5605 - val_loss: 1.0330 - val_accuracy: 0.5852\n",
      "Epoch 473/750\n",
      "162/162 [==============================] - 0s 641us/step - loss: 1.0701 - accuracy: 0.5654 - val_loss: 1.0271 - val_accuracy: 0.6000\n",
      "Epoch 474/750\n",
      "162/162 [==============================] - 0s 642us/step - loss: 1.0718 - accuracy: 0.5568 - val_loss: 1.0203 - val_accuracy: 0.6185\n",
      "Epoch 475/750\n",
      "162/162 [==============================] - 0s 642us/step - loss: 1.1111 - accuracy: 0.5370 - val_loss: 1.0393 - val_accuracy: 0.6185\n",
      "Epoch 476/750\n",
      "162/162 [==============================] - 0s 643us/step - loss: 1.1109 - accuracy: 0.5469 - val_loss: 1.1085 - val_accuracy: 0.5704\n",
      "Epoch 477/750\n",
      "162/162 [==============================] - 0s 643us/step - loss: 1.0803 - accuracy: 0.5630 - val_loss: 1.0558 - val_accuracy: 0.5852\n",
      "Epoch 478/750\n",
      "162/162 [==============================] - 0s 622us/step - loss: 1.0699 - accuracy: 0.5593 - val_loss: 1.0268 - val_accuracy: 0.6074\n",
      "Epoch 479/750\n",
      "162/162 [==============================] - 0s 643us/step - loss: 1.0601 - accuracy: 0.5778 - val_loss: 1.0387 - val_accuracy: 0.5963\n",
      "Epoch 480/750\n",
      "162/162 [==============================] - 0s 612us/step - loss: 1.0794 - accuracy: 0.5519 - val_loss: 1.1346 - val_accuracy: 0.5556\n",
      "Epoch 481/750\n",
      "162/162 [==============================] - 0s 642us/step - loss: 1.1460 - accuracy: 0.5247 - val_loss: 1.0561 - val_accuracy: 0.5481\n",
      "Epoch 482/750\n",
      "162/162 [==============================] - 0s 643us/step - loss: 1.0750 - accuracy: 0.5556 - val_loss: 1.0171 - val_accuracy: 0.5963\n",
      "Epoch 483/750\n",
      "162/162 [==============================] - 0s 643us/step - loss: 1.0616 - accuracy: 0.5790 - val_loss: 1.0605 - val_accuracy: 0.6111\n",
      "Epoch 484/750\n",
      "162/162 [==============================] - 0s 642us/step - loss: 1.0679 - accuracy: 0.5877 - val_loss: 1.0561 - val_accuracy: 0.6074\n",
      "Epoch 485/750\n",
      "162/162 [==============================] - 0s 642us/step - loss: 1.0613 - accuracy: 0.5691 - val_loss: 1.0748 - val_accuracy: 0.5333\n",
      "Epoch 486/750\n",
      "162/162 [==============================] - 0s 632us/step - loss: 1.0650 - accuracy: 0.5753 - val_loss: 1.1596 - val_accuracy: 0.5778\n",
      "Epoch 487/750\n",
      "162/162 [==============================] - 0s 641us/step - loss: 1.1038 - accuracy: 0.5568 - val_loss: 1.0269 - val_accuracy: 0.5852\n",
      "Epoch 488/750\n",
      "162/162 [==============================] - 0s 641us/step - loss: 1.0681 - accuracy: 0.5617 - val_loss: 1.0221 - val_accuracy: 0.5778\n",
      "Epoch 489/750\n",
      "162/162 [==============================] - 0s 643us/step - loss: 1.0652 - accuracy: 0.5568 - val_loss: 1.0228 - val_accuracy: 0.5926\n",
      "Epoch 490/750\n",
      "162/162 [==============================] - 0s 642us/step - loss: 1.0591 - accuracy: 0.5716 - val_loss: 1.0609 - val_accuracy: 0.5741\n",
      "Epoch 491/750\n",
      "162/162 [==============================] - 0s 643us/step - loss: 1.0924 - accuracy: 0.5506 - val_loss: 1.0812 - val_accuracy: 0.5926\n",
      "Epoch 492/750\n",
      "162/162 [==============================] - 0s 596us/step - loss: 1.0738 - accuracy: 0.5642 - val_loss: 1.0500 - val_accuracy: 0.5926\n",
      "Epoch 493/750\n",
      "162/162 [==============================] - 0s 643us/step - loss: 1.0972 - accuracy: 0.5568 - val_loss: 1.0735 - val_accuracy: 0.5630\n",
      "Epoch 494/750\n",
      "162/162 [==============================] - 0s 589us/step - loss: 1.0876 - accuracy: 0.5506 - val_loss: 1.1365 - val_accuracy: 0.5148\n",
      "Epoch 495/750\n",
      "162/162 [==============================] - 0s 593us/step - loss: 1.0806 - accuracy: 0.5654 - val_loss: 1.0488 - val_accuracy: 0.5815\n",
      "Epoch 496/750\n",
      "162/162 [==============================] - 0s 593us/step - loss: 1.1038 - accuracy: 0.5593 - val_loss: 1.0726 - val_accuracy: 0.5926\n",
      "Epoch 497/750\n",
      "162/162 [==============================] - 0s 593us/step - loss: 1.0855 - accuracy: 0.5556 - val_loss: 1.0337 - val_accuracy: 0.5815\n",
      "Epoch 498/750\n",
      "162/162 [==============================] - 0s 662us/step - loss: 1.0706 - accuracy: 0.5593 - val_loss: 1.0347 - val_accuracy: 0.6148\n",
      "Epoch 499/750\n",
      "162/162 [==============================] - 0s 672us/step - loss: 1.0558 - accuracy: 0.5667 - val_loss: 1.0198 - val_accuracy: 0.6222\n",
      "Epoch 500/750\n",
      "162/162 [==============================] - 0s 643us/step - loss: 1.0717 - accuracy: 0.5568 - val_loss: 1.0229 - val_accuracy: 0.6074\n",
      "Epoch 501/750\n",
      "162/162 [==============================] - 0s 642us/step - loss: 1.0792 - accuracy: 0.5333 - val_loss: 1.0133 - val_accuracy: 0.6111\n",
      "Epoch 502/750\n",
      "162/162 [==============================] - 0s 643us/step - loss: 1.0715 - accuracy: 0.5617 - val_loss: 1.0905 - val_accuracy: 0.5481\n",
      "Epoch 503/750\n",
      "162/162 [==============================] - 0s 642us/step - loss: 1.0751 - accuracy: 0.5654 - val_loss: 1.0448 - val_accuracy: 0.6111\n",
      "Epoch 504/750\n",
      "162/162 [==============================] - 0s 643us/step - loss: 1.0684 - accuracy: 0.5667 - val_loss: 1.0432 - val_accuracy: 0.5852\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 505/750\n",
      "162/162 [==============================] - 0s 623us/step - loss: 1.0544 - accuracy: 0.5753 - val_loss: 1.0196 - val_accuracy: 0.6222\n",
      "Epoch 506/750\n",
      "162/162 [==============================] - 0s 643us/step - loss: 1.0605 - accuracy: 0.5716 - val_loss: 1.0476 - val_accuracy: 0.6185\n",
      "Epoch 507/750\n",
      "162/162 [==============================] - 0s 642us/step - loss: 1.0676 - accuracy: 0.5679 - val_loss: 1.0359 - val_accuracy: 0.6111\n",
      "Epoch 508/750\n",
      "162/162 [==============================] - 0s 642us/step - loss: 1.0655 - accuracy: 0.5580 - val_loss: 1.0269 - val_accuracy: 0.5852\n",
      "Epoch 509/750\n",
      "162/162 [==============================] - 0s 643us/step - loss: 1.0756 - accuracy: 0.5741 - val_loss: 1.0633 - val_accuracy: 0.5778\n",
      "Epoch 510/750\n",
      "162/162 [==============================] - 0s 643us/step - loss: 1.0916 - accuracy: 0.5691 - val_loss: 1.0433 - val_accuracy: 0.6111\n",
      "Epoch 511/750\n",
      "162/162 [==============================] - 0s 612us/step - loss: 1.0457 - accuracy: 0.5716 - val_loss: 1.0365 - val_accuracy: 0.6037\n",
      "Epoch 512/750\n",
      "162/162 [==============================] - 0s 624us/step - loss: 1.0595 - accuracy: 0.5556 - val_loss: 1.0792 - val_accuracy: 0.5778\n",
      "Epoch 513/750\n",
      "162/162 [==============================] - 0s 612us/step - loss: 1.0552 - accuracy: 0.5667 - val_loss: 1.0904 - val_accuracy: 0.5963\n",
      "Epoch 514/750\n",
      "162/162 [==============================] - 0s 593us/step - loss: 1.0956 - accuracy: 0.5531 - val_loss: 1.0490 - val_accuracy: 0.5630\n",
      "Epoch 515/750\n",
      "162/162 [==============================] - 0s 593us/step - loss: 1.0598 - accuracy: 0.5741 - val_loss: 1.0626 - val_accuracy: 0.5667\n",
      "Epoch 516/750\n",
      "162/162 [==============================] - 0s 593us/step - loss: 1.0744 - accuracy: 0.5580 - val_loss: 1.0541 - val_accuracy: 0.5815\n",
      "Epoch 517/750\n",
      "162/162 [==============================] - 0s 593us/step - loss: 1.1084 - accuracy: 0.5642 - val_loss: 1.2062 - val_accuracy: 0.4889\n",
      "Epoch 518/750\n",
      "162/162 [==============================] - 0s 593us/step - loss: 1.0820 - accuracy: 0.5420 - val_loss: 1.1192 - val_accuracy: 0.5519\n",
      "Epoch 519/750\n",
      "162/162 [==============================] - 0s 593us/step - loss: 1.0842 - accuracy: 0.5580 - val_loss: 1.0652 - val_accuracy: 0.5556\n",
      "Epoch 520/750\n",
      "162/162 [==============================] - 0s 593us/step - loss: 1.0710 - accuracy: 0.5728 - val_loss: 1.0584 - val_accuracy: 0.5815\n",
      "Epoch 521/750\n",
      "162/162 [==============================] - 0s 673us/step - loss: 1.0467 - accuracy: 0.5728 - val_loss: 1.0364 - val_accuracy: 0.6037\n",
      "Epoch 522/750\n",
      "162/162 [==============================] - 0s 661us/step - loss: 1.0574 - accuracy: 0.5506 - val_loss: 1.0929 - val_accuracy: 0.5815\n",
      "Epoch 523/750\n",
      "162/162 [==============================] - 0s 643us/step - loss: 1.0793 - accuracy: 0.5728 - val_loss: 1.0080 - val_accuracy: 0.6222\n",
      "Epoch 524/750\n",
      "162/162 [==============================] - 0s 642us/step - loss: 1.0503 - accuracy: 0.5716 - val_loss: 1.0918 - val_accuracy: 0.5444\n",
      "Epoch 525/750\n",
      "162/162 [==============================] - 0s 692us/step - loss: 1.0692 - accuracy: 0.5605 - val_loss: 0.9907 - val_accuracy: 0.6111\n",
      "Epoch 526/750\n",
      "162/162 [==============================] - 0s 623us/step - loss: 1.0629 - accuracy: 0.5531 - val_loss: 1.0342 - val_accuracy: 0.5963\n",
      "Epoch 527/750\n",
      "162/162 [==============================] - 0s 623us/step - loss: 1.0694 - accuracy: 0.5778 - val_loss: 1.0842 - val_accuracy: 0.6037\n",
      "Epoch 528/750\n",
      "162/162 [==============================] - 0s 643us/step - loss: 1.3698 - accuracy: 0.5432 - val_loss: 1.0092 - val_accuracy: 0.6111\n",
      "Epoch 529/750\n",
      "162/162 [==============================] - 0s 612us/step - loss: 1.0682 - accuracy: 0.5667 - val_loss: 1.1422 - val_accuracy: 0.5630\n",
      "Epoch 530/750\n",
      "162/162 [==============================] - 0s 673us/step - loss: 1.0908 - accuracy: 0.5395 - val_loss: 1.0364 - val_accuracy: 0.6148\n",
      "Epoch 531/750\n",
      "162/162 [==============================] - 0s 612us/step - loss: 1.0711 - accuracy: 0.5790 - val_loss: 1.0061 - val_accuracy: 0.5889\n",
      "Epoch 532/750\n",
      "162/162 [==============================] - 0s 672us/step - loss: 1.0753 - accuracy: 0.5679 - val_loss: 1.0452 - val_accuracy: 0.6037\n",
      "Epoch 533/750\n",
      "162/162 [==============================] - 0s 613us/step - loss: 1.0734 - accuracy: 0.5679 - val_loss: 1.1039 - val_accuracy: 0.6000\n",
      "Epoch 534/750\n",
      "162/162 [==============================] - 0s 623us/step - loss: 1.0891 - accuracy: 0.5617 - val_loss: 1.0289 - val_accuracy: 0.6185\n",
      "Epoch 535/750\n",
      "162/162 [==============================] - 0s 612us/step - loss: 1.0480 - accuracy: 0.5704 - val_loss: 1.0152 - val_accuracy: 0.5926\n",
      "Epoch 536/750\n",
      "162/162 [==============================] - 0s 623us/step - loss: 1.0670 - accuracy: 0.5765 - val_loss: 1.0757 - val_accuracy: 0.5370\n",
      "Epoch 537/750\n",
      "162/162 [==============================] - 0s 663us/step - loss: 1.0761 - accuracy: 0.5679 - val_loss: 1.1051 - val_accuracy: 0.5667\n",
      "Epoch 538/750\n",
      "162/162 [==============================] - 0s 721us/step - loss: 1.0526 - accuracy: 0.5667 - val_loss: 1.0104 - val_accuracy: 0.5926\n",
      "Epoch 539/750\n",
      "162/162 [==============================] - 0s 623us/step - loss: 1.0519 - accuracy: 0.5704 - val_loss: 1.1831 - val_accuracy: 0.5111\n",
      "Epoch 540/750\n",
      "162/162 [==============================] - 0s 612us/step - loss: 1.0891 - accuracy: 0.5679 - val_loss: 1.1059 - val_accuracy: 0.6000\n",
      "Epoch 541/750\n",
      "162/162 [==============================] - 0s 673us/step - loss: 1.0552 - accuracy: 0.5802 - val_loss: 1.1812 - val_accuracy: 0.5111\n",
      "Epoch 542/750\n",
      "162/162 [==============================] - 0s 612us/step - loss: 1.0634 - accuracy: 0.5753 - val_loss: 1.0109 - val_accuracy: 0.6111\n",
      "Epoch 543/750\n",
      "162/162 [==============================] - 0s 593us/step - loss: 1.0817 - accuracy: 0.5395 - val_loss: 1.0301 - val_accuracy: 0.5852\n",
      "Epoch 544/750\n",
      "162/162 [==============================] - 0s 593us/step - loss: 1.0648 - accuracy: 0.5667 - val_loss: 1.0645 - val_accuracy: 0.5333\n",
      "Epoch 545/750\n",
      "162/162 [==============================] - 0s 645us/step - loss: 1.0791 - accuracy: 0.5481 - val_loss: 1.0450 - val_accuracy: 0.6296\n",
      "Epoch 546/750\n",
      "162/162 [==============================] - 0s 639us/step - loss: 1.0558 - accuracy: 0.5741 - val_loss: 1.0123 - val_accuracy: 0.5926\n",
      "Epoch 547/750\n",
      "162/162 [==============================] - 0s 642us/step - loss: 1.0348 - accuracy: 0.5716 - val_loss: 1.0068 - val_accuracy: 0.6259\n",
      "Epoch 548/750\n",
      "162/162 [==============================] - 0s 643us/step - loss: 1.0698 - accuracy: 0.5679 - val_loss: 1.0123 - val_accuracy: 0.6037\n",
      "Epoch 549/750\n",
      "162/162 [==============================] - 0s 642us/step - loss: 1.0590 - accuracy: 0.5654 - val_loss: 1.1147 - val_accuracy: 0.5630\n",
      "Epoch 550/750\n",
      "162/162 [==============================] - 0s 643us/step - loss: 1.0542 - accuracy: 0.5765 - val_loss: 1.0189 - val_accuracy: 0.6074\n",
      "Epoch 551/750\n",
      "162/162 [==============================] - 0s 672us/step - loss: 1.0520 - accuracy: 0.5630 - val_loss: 1.1027 - val_accuracy: 0.5407\n",
      "Epoch 552/750\n",
      "162/162 [==============================] - 0s 642us/step - loss: 1.0590 - accuracy: 0.5593 - val_loss: 1.1176 - val_accuracy: 0.5222\n",
      "Epoch 553/750\n",
      "162/162 [==============================] - 0s 642us/step - loss: 1.0881 - accuracy: 0.5617 - val_loss: 1.1742 - val_accuracy: 0.4778\n",
      "Epoch 554/750\n",
      "162/162 [==============================] - 0s 643us/step - loss: 1.0839 - accuracy: 0.5654 - val_loss: 1.0716 - val_accuracy: 0.6074\n",
      "Epoch 555/750\n",
      "162/162 [==============================] - 0s 642us/step - loss: 1.0924 - accuracy: 0.5556 - val_loss: 1.0834 - val_accuracy: 0.6074\n",
      "Epoch 556/750\n",
      "162/162 [==============================] - 0s 644us/step - loss: 1.0409 - accuracy: 0.5926 - val_loss: 1.1861 - val_accuracy: 0.5481\n",
      "Epoch 557/750\n",
      "162/162 [==============================] - 0s 641us/step - loss: 1.0929 - accuracy: 0.5580 - val_loss: 1.0007 - val_accuracy: 0.6148\n",
      "Epoch 558/750\n",
      "162/162 [==============================] - 0s 643us/step - loss: 1.0655 - accuracy: 0.5642 - val_loss: 1.0406 - val_accuracy: 0.6111\n",
      "Epoch 559/750\n",
      "162/162 [==============================] - 0s 648us/step - loss: 1.0628 - accuracy: 0.5605 - val_loss: 1.0289 - val_accuracy: 0.5852\n",
      "Epoch 560/750\n",
      "162/162 [==============================] - 0s 623us/step - loss: 1.0472 - accuracy: 0.5667 - val_loss: 1.0020 - val_accuracy: 0.5926\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 561/750\n",
      "162/162 [==============================] - 0s 660us/step - loss: 1.0740 - accuracy: 0.5605 - val_loss: 1.0578 - val_accuracy: 0.5815\n",
      "Epoch 562/750\n",
      "162/162 [==============================] - 0s 639us/step - loss: 1.0527 - accuracy: 0.5556 - val_loss: 1.0458 - val_accuracy: 0.6185\n",
      "Epoch 563/750\n",
      "162/162 [==============================] - 0s 643us/step - loss: 1.0549 - accuracy: 0.5753 - val_loss: 1.1147 - val_accuracy: 0.5778\n",
      "Epoch 564/750\n",
      "162/162 [==============================] - 0s 642us/step - loss: 1.0560 - accuracy: 0.5580 - val_loss: 1.0772 - val_accuracy: 0.5333\n",
      "Epoch 565/750\n",
      "162/162 [==============================] - 0s 692us/step - loss: 1.0659 - accuracy: 0.5753 - val_loss: 1.1326 - val_accuracy: 0.5593\n",
      "Epoch 566/750\n",
      "162/162 [==============================] - 0s 623us/step - loss: 1.0599 - accuracy: 0.5716 - val_loss: 1.0483 - val_accuracy: 0.6074\n",
      "Epoch 567/750\n",
      "162/162 [==============================] - 0s 643us/step - loss: 1.0669 - accuracy: 0.5704 - val_loss: 1.1311 - val_accuracy: 0.5741\n",
      "Epoch 568/750\n",
      "162/162 [==============================] - 0s 642us/step - loss: 1.0802 - accuracy: 0.5358 - val_loss: 1.0176 - val_accuracy: 0.5852\n",
      "Epoch 569/750\n",
      "162/162 [==============================] - 0s 613us/step - loss: 1.0509 - accuracy: 0.5728 - val_loss: 1.0018 - val_accuracy: 0.6111\n",
      "Epoch 570/750\n",
      "162/162 [==============================] - 0s 642us/step - loss: 1.0601 - accuracy: 0.5617 - val_loss: 1.0377 - val_accuracy: 0.6074\n",
      "Epoch 571/750\n",
      "162/162 [==============================] - 0s 642us/step - loss: 1.1138 - accuracy: 0.5481 - val_loss: 1.0897 - val_accuracy: 0.6074\n",
      "Epoch 572/750\n",
      "162/162 [==============================] - 0s 643us/step - loss: 1.0886 - accuracy: 0.5679 - val_loss: 1.0523 - val_accuracy: 0.5556\n",
      "Epoch 573/750\n",
      "162/162 [==============================] - 0s 647us/step - loss: 1.0853 - accuracy: 0.5457 - val_loss: 1.0497 - val_accuracy: 0.5630\n",
      "Epoch 574/750\n",
      "162/162 [==============================] - 0s 643us/step - loss: 1.0881 - accuracy: 0.5395 - val_loss: 1.0221 - val_accuracy: 0.6259\n",
      "Epoch 575/750\n",
      "162/162 [==============================] - 0s 642us/step - loss: 1.0470 - accuracy: 0.5840 - val_loss: 1.0431 - val_accuracy: 0.6111\n",
      "Epoch 576/750\n",
      "162/162 [==============================] - 0s 642us/step - loss: 1.0711 - accuracy: 0.5691 - val_loss: 1.0578 - val_accuracy: 0.5889\n",
      "Epoch 577/750\n",
      "162/162 [==============================] - 0s 643us/step - loss: 1.0713 - accuracy: 0.5506 - val_loss: 1.0305 - val_accuracy: 0.6148\n",
      "Epoch 578/750\n",
      "162/162 [==============================] - 0s 642us/step - loss: 1.0587 - accuracy: 0.5556 - val_loss: 1.0566 - val_accuracy: 0.5889\n",
      "Epoch 579/750\n",
      "162/162 [==============================] - 0s 642us/step - loss: 1.0617 - accuracy: 0.5654 - val_loss: 1.2072 - val_accuracy: 0.5185\n",
      "Epoch 580/750\n",
      "162/162 [==============================] - 0s 642us/step - loss: 1.0658 - accuracy: 0.5728 - val_loss: 1.0329 - val_accuracy: 0.6037\n",
      "Epoch 581/750\n",
      "162/162 [==============================] - 0s 643us/step - loss: 1.0410 - accuracy: 0.5728 - val_loss: 1.0226 - val_accuracy: 0.6074\n",
      "Epoch 582/750\n",
      "162/162 [==============================] - 0s 646us/step - loss: 1.0866 - accuracy: 0.5593 - val_loss: 1.0819 - val_accuracy: 0.5630\n",
      "Epoch 583/750\n",
      "162/162 [==============================] - 0s 639us/step - loss: 1.0475 - accuracy: 0.5815 - val_loss: 1.0347 - val_accuracy: 0.6185\n",
      "Epoch 584/750\n",
      "162/162 [==============================] - 0s 646us/step - loss: 1.0646 - accuracy: 0.5728 - val_loss: 1.0373 - val_accuracy: 0.5444\n",
      "Epoch 585/750\n",
      "162/162 [==============================] - 0s 639us/step - loss: 1.0689 - accuracy: 0.5568 - val_loss: 1.0903 - val_accuracy: 0.5889\n",
      "Epoch 586/750\n",
      "162/162 [==============================] - 0s 643us/step - loss: 1.0715 - accuracy: 0.5580 - val_loss: 1.0475 - val_accuracy: 0.6185\n",
      "Epoch 587/750\n",
      "162/162 [==============================] - 0s 642us/step - loss: 1.0811 - accuracy: 0.5716 - val_loss: 1.0705 - val_accuracy: 0.5889\n",
      "Epoch 588/750\n",
      "162/162 [==============================] - 0s 642us/step - loss: 1.0597 - accuracy: 0.5704 - val_loss: 0.9970 - val_accuracy: 0.6074\n",
      "Epoch 589/750\n",
      "162/162 [==============================] - 0s 672us/step - loss: 1.0517 - accuracy: 0.5765 - val_loss: 1.0584 - val_accuracy: 0.5222\n",
      "Epoch 590/750\n",
      "162/162 [==============================] - 0s 643us/step - loss: 1.0451 - accuracy: 0.5630 - val_loss: 1.0859 - val_accuracy: 0.5815\n",
      "Epoch 591/750\n",
      "162/162 [==============================] - 0s 643us/step - loss: 1.0628 - accuracy: 0.5605 - val_loss: 1.0704 - val_accuracy: 0.5630\n",
      "Epoch 592/750\n",
      "162/162 [==============================] - 0s 642us/step - loss: 1.0400 - accuracy: 0.5741 - val_loss: 1.0305 - val_accuracy: 0.5593\n",
      "Epoch 593/750\n",
      "162/162 [==============================] - 0s 612us/step - loss: 1.0798 - accuracy: 0.5630 - val_loss: 1.0099 - val_accuracy: 0.6185\n",
      "Epoch 594/750\n",
      "162/162 [==============================] - 0s 673us/step - loss: 1.0788 - accuracy: 0.5481 - val_loss: 0.9977 - val_accuracy: 0.6074\n",
      "Epoch 595/750\n",
      "162/162 [==============================] - 0s 681us/step - loss: 1.1036 - accuracy: 0.5420 - val_loss: 1.1368 - val_accuracy: 0.5148\n",
      "Epoch 596/750\n",
      "162/162 [==============================] - 0s 644us/step - loss: 1.0838 - accuracy: 0.5469 - val_loss: 1.0622 - val_accuracy: 0.5704\n",
      "Epoch 597/750\n",
      "162/162 [==============================] - 0s 601us/step - loss: 1.0711 - accuracy: 0.5580 - val_loss: 1.0821 - val_accuracy: 0.5593\n",
      "Epoch 598/750\n",
      "162/162 [==============================] - 0s 643us/step - loss: 1.0668 - accuracy: 0.5679 - val_loss: 1.0132 - val_accuracy: 0.6259\n",
      "Epoch 599/750\n",
      "162/162 [==============================] - 0s 612us/step - loss: 1.0380 - accuracy: 0.5840 - val_loss: 1.0116 - val_accuracy: 0.6185\n",
      "Epoch 600/750\n",
      "162/162 [==============================] - 0s 624us/step - loss: 1.1005 - accuracy: 0.5630 - val_loss: 1.0542 - val_accuracy: 0.6148\n",
      "Epoch 601/750\n",
      "162/162 [==============================] - 0s 661us/step - loss: 1.0626 - accuracy: 0.5630 - val_loss: 1.0531 - val_accuracy: 0.5815\n",
      "Epoch 602/750\n",
      "162/162 [==============================] - 0s 593us/step - loss: 1.0523 - accuracy: 0.5667 - val_loss: 1.0419 - val_accuracy: 0.6296\n",
      "Epoch 603/750\n",
      "162/162 [==============================] - 0s 642us/step - loss: 1.0671 - accuracy: 0.5741 - val_loss: 1.0801 - val_accuracy: 0.5667\n",
      "Epoch 604/750\n",
      "162/162 [==============================] - 0s 643us/step - loss: 1.0715 - accuracy: 0.5506 - val_loss: 1.0977 - val_accuracy: 0.5296\n",
      "Epoch 605/750\n",
      "162/162 [==============================] - 0s 642us/step - loss: 1.0598 - accuracy: 0.5556 - val_loss: 1.0272 - val_accuracy: 0.6074\n",
      "Epoch 606/750\n",
      "162/162 [==============================] - 0s 623us/step - loss: 1.0627 - accuracy: 0.5728 - val_loss: 1.0035 - val_accuracy: 0.6111\n",
      "Epoch 607/750\n",
      "162/162 [==============================] - 0s 623us/step - loss: 1.0712 - accuracy: 0.5531 - val_loss: 1.0359 - val_accuracy: 0.6037\n",
      "Epoch 608/750\n",
      "162/162 [==============================] - 0s 643us/step - loss: 1.0563 - accuracy: 0.5543 - val_loss: 1.1210 - val_accuracy: 0.5259\n",
      "Epoch 609/750\n",
      "162/162 [==============================] - 0s 692us/step - loss: 1.0694 - accuracy: 0.5679 - val_loss: 1.0063 - val_accuracy: 0.6222\n",
      "Epoch 610/750\n",
      "162/162 [==============================] - 0s 612us/step - loss: 1.0705 - accuracy: 0.5395 - val_loss: 1.0647 - val_accuracy: 0.5852\n",
      "Epoch 611/750\n",
      "162/162 [==============================] - 0s 574us/step - loss: 1.0790 - accuracy: 0.5617 - val_loss: 1.1122 - val_accuracy: 0.5815\n",
      "Epoch 612/750\n",
      "162/162 [==============================] - 0s 612us/step - loss: 1.0654 - accuracy: 0.5654 - val_loss: 1.1115 - val_accuracy: 0.5222\n",
      "Epoch 613/750\n",
      "162/162 [==============================] - 0s 676us/step - loss: 1.0582 - accuracy: 0.5642 - val_loss: 1.0103 - val_accuracy: 0.6222\n",
      "Epoch 614/750\n",
      "162/162 [==============================] - 0s 609us/step - loss: 1.0672 - accuracy: 0.5481 - val_loss: 1.0768 - val_accuracy: 0.6000\n",
      "Epoch 615/750\n",
      "162/162 [==============================] - 0s 667us/step - loss: 1.0929 - accuracy: 0.5642 - val_loss: 1.1109 - val_accuracy: 0.5259\n",
      "Epoch 616/750\n",
      "162/162 [==============================] - 0s 609us/step - loss: 1.0755 - accuracy: 0.5704 - val_loss: 1.0137 - val_accuracy: 0.6185\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 617/750\n",
      "162/162 [==============================] - 0s 642us/step - loss: 1.0578 - accuracy: 0.5741 - val_loss: 1.0585 - val_accuracy: 0.5741\n",
      "Epoch 618/750\n",
      "162/162 [==============================] - 0s 643us/step - loss: 1.0542 - accuracy: 0.5704 - val_loss: 1.0722 - val_accuracy: 0.5481\n",
      "Epoch 619/750\n",
      "162/162 [==============================] - 0s 642us/step - loss: 1.0588 - accuracy: 0.5790 - val_loss: 1.0106 - val_accuracy: 0.5926\n",
      "Epoch 620/750\n",
      "162/162 [==============================] - 0s 643us/step - loss: 1.0693 - accuracy: 0.5531 - val_loss: 1.0026 - val_accuracy: 0.6185\n",
      "Epoch 621/750\n",
      "162/162 [==============================] - 0s 662us/step - loss: 1.0441 - accuracy: 0.5852 - val_loss: 1.0226 - val_accuracy: 0.6111\n",
      "Epoch 622/750\n",
      "162/162 [==============================] - 0s 642us/step - loss: 1.0564 - accuracy: 0.5778 - val_loss: 1.0275 - val_accuracy: 0.5852\n",
      "Epoch 623/750\n",
      "162/162 [==============================] - 0s 640us/step - loss: 1.0457 - accuracy: 0.5642 - val_loss: 1.0691 - val_accuracy: 0.6000\n",
      "Epoch 624/750\n",
      "162/162 [==============================] - 0s 645us/step - loss: 1.0546 - accuracy: 0.5765 - val_loss: 1.0258 - val_accuracy: 0.6370\n",
      "Epoch 625/750\n",
      "162/162 [==============================] - 0s 623us/step - loss: 1.0713 - accuracy: 0.5481 - val_loss: 1.0542 - val_accuracy: 0.6000\n",
      "Epoch 626/750\n",
      "162/162 [==============================] - 0s 643us/step - loss: 1.0547 - accuracy: 0.5704 - val_loss: 1.0414 - val_accuracy: 0.6074\n",
      "Epoch 627/750\n",
      "162/162 [==============================] - 0s 597us/step - loss: 1.0525 - accuracy: 0.5741 - val_loss: 1.0585 - val_accuracy: 0.6000\n",
      "Epoch 628/750\n",
      "162/162 [==============================] - 0s 589us/step - loss: 1.0900 - accuracy: 0.5691 - val_loss: 1.0131 - val_accuracy: 0.6111\n",
      "Epoch 629/750\n",
      "162/162 [==============================] - 0s 593us/step - loss: 1.0368 - accuracy: 0.5790 - val_loss: 1.0178 - val_accuracy: 0.6074\n",
      "Epoch 630/750\n",
      "162/162 [==============================] - 0s 662us/step - loss: 1.0569 - accuracy: 0.5679 - val_loss: 1.0229 - val_accuracy: 0.6111\n",
      "Epoch 631/750\n",
      "162/162 [==============================] - 0s 623us/step - loss: 1.0416 - accuracy: 0.5753 - val_loss: 1.0044 - val_accuracy: 0.6111\n",
      "Epoch 632/750\n",
      "162/162 [==============================] - 0s 594us/step - loss: 1.0612 - accuracy: 0.5568 - val_loss: 1.0364 - val_accuracy: 0.6185\n",
      "Epoch 633/750\n",
      "162/162 [==============================] - 0s 595us/step - loss: 1.0403 - accuracy: 0.5741 - val_loss: 1.0136 - val_accuracy: 0.6222\n",
      "Epoch 634/750\n",
      "162/162 [==============================] - 0s 640us/step - loss: 1.0404 - accuracy: 0.5679 - val_loss: 0.9856 - val_accuracy: 0.6222\n",
      "Epoch 635/750\n",
      "162/162 [==============================] - 0s 642us/step - loss: 1.0366 - accuracy: 0.5815 - val_loss: 1.0882 - val_accuracy: 0.5778\n",
      "Epoch 636/750\n",
      "162/162 [==============================] - 0s 616us/step - loss: 1.0898 - accuracy: 0.5716 - val_loss: 1.0730 - val_accuracy: 0.5333\n",
      "Epoch 637/750\n",
      "162/162 [==============================] - 0s 639us/step - loss: 1.0356 - accuracy: 0.5679 - val_loss: 1.0474 - val_accuracy: 0.6111\n",
      "Epoch 638/750\n",
      "162/162 [==============================] - 0s 673us/step - loss: 1.0532 - accuracy: 0.5765 - val_loss: 1.0171 - val_accuracy: 0.6111\n",
      "Epoch 639/750\n",
      "162/162 [==============================] - 0s 642us/step - loss: 1.0409 - accuracy: 0.5716 - val_loss: 1.0267 - val_accuracy: 0.6333\n",
      "Epoch 640/750\n",
      "162/162 [==============================] - 0s 642us/step - loss: 1.0562 - accuracy: 0.5790 - val_loss: 1.0562 - val_accuracy: 0.5222\n",
      "Epoch 641/750\n",
      "162/162 [==============================] - 0s 643us/step - loss: 1.0433 - accuracy: 0.5691 - val_loss: 1.0083 - val_accuracy: 0.6222\n",
      "Epoch 642/750\n",
      "162/162 [==============================] - 0s 646us/step - loss: 1.0565 - accuracy: 0.5728 - val_loss: 1.1051 - val_accuracy: 0.5926\n",
      "Epoch 643/750\n",
      "162/162 [==============================] - 0s 639us/step - loss: 1.1736 - accuracy: 0.5296 - val_loss: 1.0453 - val_accuracy: 0.6037\n",
      "Epoch 644/750\n",
      "162/162 [==============================] - 0s 642us/step - loss: 1.0507 - accuracy: 0.5802 - val_loss: 1.0242 - val_accuracy: 0.6037\n",
      "Epoch 645/750\n",
      "162/162 [==============================] - 0s 642us/step - loss: 1.0408 - accuracy: 0.5864 - val_loss: 1.1141 - val_accuracy: 0.5370\n",
      "Epoch 646/750\n",
      "162/162 [==============================] - 0s 643us/step - loss: 1.0455 - accuracy: 0.5630 - val_loss: 1.0023 - val_accuracy: 0.6037\n",
      "Epoch 647/750\n",
      "162/162 [==============================] - 0s 646us/step - loss: 1.0491 - accuracy: 0.5605 - val_loss: 1.0521 - val_accuracy: 0.6000\n",
      "Epoch 648/750\n",
      "162/162 [==============================] - 0s 639us/step - loss: 1.0568 - accuracy: 0.5691 - val_loss: 1.0333 - val_accuracy: 0.6037\n",
      "Epoch 649/750\n",
      "162/162 [==============================] - 0s 672us/step - loss: 1.0688 - accuracy: 0.5679 - val_loss: 1.0277 - val_accuracy: 0.6074\n",
      "Epoch 650/750\n",
      "162/162 [==============================] - 0s 643us/step - loss: 1.0721 - accuracy: 0.5654 - val_loss: 1.0284 - val_accuracy: 0.5926\n",
      "Epoch 651/750\n",
      "162/162 [==============================] - 0s 692us/step - loss: 1.0663 - accuracy: 0.5840 - val_loss: 1.0336 - val_accuracy: 0.5852\n",
      "Epoch 652/750\n",
      "162/162 [==============================] - 0s 612us/step - loss: 1.0790 - accuracy: 0.5852 - val_loss: 0.9973 - val_accuracy: 0.5852\n",
      "Epoch 653/750\n",
      "162/162 [==============================] - 0s 643us/step - loss: 1.0518 - accuracy: 0.5691 - val_loss: 0.9907 - val_accuracy: 0.6185\n",
      "Epoch 654/750\n",
      "162/162 [==============================] - 0s 642us/step - loss: 1.0517 - accuracy: 0.5827 - val_loss: 1.0664 - val_accuracy: 0.5556\n",
      "Epoch 655/750\n",
      "162/162 [==============================] - 0s 642us/step - loss: 1.0856 - accuracy: 0.5605 - val_loss: 1.0757 - val_accuracy: 0.6037\n",
      "Epoch 656/750\n",
      "162/162 [==============================] - 0s 643us/step - loss: 1.0627 - accuracy: 0.5765 - val_loss: 1.0293 - val_accuracy: 0.6185\n",
      "Epoch 657/750\n",
      "162/162 [==============================] - 0s 623us/step - loss: 1.0594 - accuracy: 0.5642 - val_loss: 1.0150 - val_accuracy: 0.6074\n",
      "Epoch 658/750\n",
      "162/162 [==============================] - 0s 643us/step - loss: 1.0599 - accuracy: 0.5679 - val_loss: 1.0614 - val_accuracy: 0.5667\n",
      "Epoch 659/750\n",
      "162/162 [==============================] - 0s 642us/step - loss: 1.0267 - accuracy: 0.5728 - val_loss: 0.9957 - val_accuracy: 0.6111\n",
      "Epoch 660/750\n",
      "162/162 [==============================] - 0s 643us/step - loss: 1.0497 - accuracy: 0.5815 - val_loss: 1.0441 - val_accuracy: 0.6037\n",
      "Epoch 661/750\n",
      "162/162 [==============================] - 0s 642us/step - loss: 1.0543 - accuracy: 0.5716 - val_loss: 0.9945 - val_accuracy: 0.6148\n",
      "Epoch 662/750\n",
      "162/162 [==============================] - 0s 642us/step - loss: 1.0648 - accuracy: 0.5679 - val_loss: 1.1034 - val_accuracy: 0.5667\n",
      "Epoch 663/750\n",
      "162/162 [==============================] - 0s 643us/step - loss: 1.0444 - accuracy: 0.5617 - val_loss: 1.0176 - val_accuracy: 0.5852\n",
      "Epoch 664/750\n",
      "162/162 [==============================] - 0s 623us/step - loss: 1.0606 - accuracy: 0.5704 - val_loss: 1.1222 - val_accuracy: 0.5741\n",
      "Epoch 665/750\n",
      "162/162 [==============================] - 0s 643us/step - loss: 1.0530 - accuracy: 0.5951 - val_loss: 1.1453 - val_accuracy: 0.5630\n",
      "Epoch 666/750\n",
      "162/162 [==============================] - 0s 612us/step - loss: 1.0361 - accuracy: 0.5815 - val_loss: 1.0019 - val_accuracy: 0.5926\n",
      "Epoch 667/750\n",
      "162/162 [==============================] - 0s 673us/step - loss: 1.0268 - accuracy: 0.5815 - val_loss: 1.1022 - val_accuracy: 0.5556\n",
      "Epoch 668/750\n",
      "162/162 [==============================] - 0s 661us/step - loss: 1.0625 - accuracy: 0.5877 - val_loss: 1.1076 - val_accuracy: 0.5481\n",
      "Epoch 669/750\n",
      "162/162 [==============================] - 0s 692us/step - loss: 1.0459 - accuracy: 0.5790 - val_loss: 1.0168 - val_accuracy: 0.6074\n",
      "Epoch 670/750\n",
      "162/162 [==============================] - 0s 623us/step - loss: 1.0675 - accuracy: 0.5728 - val_loss: 1.0375 - val_accuracy: 0.5815\n",
      "Epoch 671/750\n",
      "162/162 [==============================] - 0s 642us/step - loss: 1.0615 - accuracy: 0.5593 - val_loss: 1.1252 - val_accuracy: 0.5370\n",
      "Epoch 672/750\n",
      "162/162 [==============================] - 0s 643us/step - loss: 1.0682 - accuracy: 0.5741 - val_loss: 1.1747 - val_accuracy: 0.5074\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 673/750\n",
      "162/162 [==============================] - 0s 646us/step - loss: 1.0468 - accuracy: 0.5704 - val_loss: 1.1164 - val_accuracy: 0.5889\n",
      "Epoch 674/750\n",
      "162/162 [==============================] - 0s 639us/step - loss: 1.1191 - accuracy: 0.5259 - val_loss: 1.0114 - val_accuracy: 0.5926\n",
      "Epoch 675/750\n",
      "162/162 [==============================] - 0s 623us/step - loss: 1.0501 - accuracy: 0.5704 - val_loss: 1.0131 - val_accuracy: 0.5963\n",
      "Epoch 676/750\n",
      "162/162 [==============================] - 0s 642us/step - loss: 1.0502 - accuracy: 0.5802 - val_loss: 1.0016 - val_accuracy: 0.6000\n",
      "Epoch 677/750\n",
      "162/162 [==============================] - 0s 643us/step - loss: 1.0580 - accuracy: 0.5864 - val_loss: 1.1558 - val_accuracy: 0.5593\n",
      "Epoch 678/750\n",
      "162/162 [==============================] - 0s 642us/step - loss: 1.0736 - accuracy: 0.5741 - val_loss: 1.0337 - val_accuracy: 0.6148\n",
      "Epoch 679/750\n",
      "162/162 [==============================] - 0s 593us/step - loss: 1.0559 - accuracy: 0.5642 - val_loss: 0.9908 - val_accuracy: 0.6185\n",
      "Epoch 680/750\n",
      "162/162 [==============================] - 0s 642us/step - loss: 1.0339 - accuracy: 0.5679 - val_loss: 1.0118 - val_accuracy: 0.5926\n",
      "Epoch 681/750\n",
      "162/162 [==============================] - 0s 662us/step - loss: 1.0494 - accuracy: 0.5728 - val_loss: 1.0267 - val_accuracy: 0.5815\n",
      "Epoch 682/750\n",
      "162/162 [==============================] - 0s 642us/step - loss: 1.0284 - accuracy: 0.5704 - val_loss: 1.0352 - val_accuracy: 0.6148\n",
      "Epoch 683/750\n",
      "162/162 [==============================] - 0s 643us/step - loss: 1.0767 - accuracy: 0.5654 - val_loss: 1.0654 - val_accuracy: 0.5148\n",
      "Epoch 684/750\n",
      "162/162 [==============================] - 0s 642us/step - loss: 1.0436 - accuracy: 0.5716 - val_loss: 1.0003 - val_accuracy: 0.5889\n",
      "Epoch 685/750\n",
      "162/162 [==============================] - 0s 593us/step - loss: 1.0551 - accuracy: 0.5679 - val_loss: 1.0459 - val_accuracy: 0.5815\n",
      "Epoch 686/750\n",
      "162/162 [==============================] - 0s 643us/step - loss: 1.0302 - accuracy: 0.5741 - val_loss: 1.0545 - val_accuracy: 0.6037\n",
      "Epoch 687/750\n",
      "162/162 [==============================] - 0s 642us/step - loss: 1.0220 - accuracy: 0.5778 - val_loss: 1.0491 - val_accuracy: 0.6037\n",
      "Epoch 688/750\n",
      "162/162 [==============================] - 0s 642us/step - loss: 1.0457 - accuracy: 0.5704 - val_loss: 1.0427 - val_accuracy: 0.6000\n",
      "Epoch 689/750\n",
      "162/162 [==============================] - 0s 643us/step - loss: 1.0334 - accuracy: 0.5815 - val_loss: 0.9997 - val_accuracy: 0.6185\n",
      "Epoch 690/750\n",
      "162/162 [==============================] - 0s 642us/step - loss: 1.0715 - accuracy: 0.5704 - val_loss: 1.0498 - val_accuracy: 0.5481\n",
      "Epoch 691/750\n",
      "162/162 [==============================] - 0s 640us/step - loss: 1.0597 - accuracy: 0.5654 - val_loss: 1.3144 - val_accuracy: 0.4593\n",
      "Epoch 692/750\n",
      "162/162 [==============================] - 0s 625us/step - loss: 1.0530 - accuracy: 0.5679 - val_loss: 1.0050 - val_accuracy: 0.5852\n",
      "Epoch 693/750\n",
      "162/162 [==============================] - 0s 646us/step - loss: 1.0442 - accuracy: 0.5815 - val_loss: 1.0474 - val_accuracy: 0.6148\n",
      "Epoch 694/750\n",
      "162/162 [==============================] - 0s 639us/step - loss: 1.0325 - accuracy: 0.5852 - val_loss: 1.0232 - val_accuracy: 0.5889\n",
      "Epoch 695/750\n",
      "162/162 [==============================] - 0s 593us/step - loss: 1.0151 - accuracy: 0.5852 - val_loss: 1.0503 - val_accuracy: 0.6074\n",
      "Epoch 696/750\n",
      "162/162 [==============================] - 0s 643us/step - loss: 1.0669 - accuracy: 0.5580 - val_loss: 1.0611 - val_accuracy: 0.5926\n",
      "Epoch 697/750\n",
      "162/162 [==============================] - 0s 583us/step - loss: 1.0375 - accuracy: 0.5667 - val_loss: 0.9909 - val_accuracy: 0.5926\n",
      "Epoch 698/750\n",
      "162/162 [==============================] - 0s 593us/step - loss: 1.0755 - accuracy: 0.5654 - val_loss: 1.2475 - val_accuracy: 0.4259\n",
      "Epoch 699/750\n",
      "162/162 [==============================] - 0s 662us/step - loss: 1.0504 - accuracy: 0.5531 - val_loss: 0.9807 - val_accuracy: 0.6037\n",
      "Epoch 700/750\n",
      "162/162 [==============================] - 0s 623us/step - loss: 1.0342 - accuracy: 0.5679 - val_loss: 1.0006 - val_accuracy: 0.6111\n",
      "Epoch 701/750\n",
      "162/162 [==============================] - 0s 662us/step - loss: 1.0562 - accuracy: 0.5741 - val_loss: 1.0212 - val_accuracy: 0.5852\n",
      "Epoch 702/750\n",
      "162/162 [==============================] - 0s 601us/step - loss: 1.0251 - accuracy: 0.5926 - val_loss: 1.0838 - val_accuracy: 0.5481\n",
      "Epoch 703/750\n",
      "162/162 [==============================] - 0s 590us/step - loss: 1.0664 - accuracy: 0.5667 - val_loss: 1.0920 - val_accuracy: 0.5556\n",
      "Epoch 704/750\n",
      "162/162 [==============================] - 0s 662us/step - loss: 1.0654 - accuracy: 0.5667 - val_loss: 1.0089 - val_accuracy: 0.6148\n",
      "Epoch 705/750\n",
      "162/162 [==============================] - 0s 642us/step - loss: 1.0393 - accuracy: 0.5815 - val_loss: 1.0987 - val_accuracy: 0.5148\n",
      "Epoch 706/750\n",
      "162/162 [==============================] - 0s 642us/step - loss: 1.0332 - accuracy: 0.5704 - val_loss: 1.0338 - val_accuracy: 0.5889\n",
      "Epoch 707/750\n",
      "162/162 [==============================] - 0s 642us/step - loss: 1.0522 - accuracy: 0.5568 - val_loss: 1.0020 - val_accuracy: 0.6296\n",
      "Epoch 708/750\n",
      "162/162 [==============================] - 0s 623us/step - loss: 1.0434 - accuracy: 0.5741 - val_loss: 1.0248 - val_accuracy: 0.5704\n",
      "Epoch 709/750\n",
      "162/162 [==============================] - 0s 643us/step - loss: 1.0306 - accuracy: 0.5815 - val_loss: 1.0053 - val_accuracy: 0.5815\n",
      "Epoch 710/750\n",
      "162/162 [==============================] - 0s 644us/step - loss: 1.0598 - accuracy: 0.5654 - val_loss: 1.2619 - val_accuracy: 0.4630\n",
      "Epoch 711/750\n",
      "162/162 [==============================] - 0s 621us/step - loss: 1.0789 - accuracy: 0.5630 - val_loss: 0.9817 - val_accuracy: 0.6222\n",
      "Epoch 712/750\n",
      "162/162 [==============================] - 0s 642us/step - loss: 1.0901 - accuracy: 0.5593 - val_loss: 1.0132 - val_accuracy: 0.6259\n",
      "Epoch 713/750\n",
      "162/162 [==============================] - 0s 692us/step - loss: 1.0370 - accuracy: 0.5827 - val_loss: 1.0455 - val_accuracy: 0.6185\n",
      "Epoch 714/750\n",
      "162/162 [==============================] - 0s 612us/step - loss: 1.0474 - accuracy: 0.5765 - val_loss: 1.0055 - val_accuracy: 0.5889\n",
      "Epoch 715/750\n",
      "162/162 [==============================] - 0s 624us/step - loss: 1.0632 - accuracy: 0.5704 - val_loss: 1.1704 - val_accuracy: 0.4704\n",
      "Epoch 716/750\n",
      "162/162 [==============================] - 0s 661us/step - loss: 1.0712 - accuracy: 0.5506 - val_loss: 1.0470 - val_accuracy: 0.5815\n",
      "Epoch 717/750\n",
      "162/162 [==============================] - 0s 623us/step - loss: 1.0242 - accuracy: 0.5815 - val_loss: 1.0815 - val_accuracy: 0.5444\n",
      "Epoch 718/750\n",
      "162/162 [==============================] - 0s 642us/step - loss: 1.0482 - accuracy: 0.5753 - val_loss: 0.9920 - val_accuracy: 0.5926\n",
      "Epoch 719/750\n",
      "162/162 [==============================] - 0s 643us/step - loss: 1.0413 - accuracy: 0.5691 - val_loss: 0.9810 - val_accuracy: 0.6222\n",
      "Epoch 720/750\n",
      "162/162 [==============================] - 0s 642us/step - loss: 1.0451 - accuracy: 0.5765 - val_loss: 1.1258 - val_accuracy: 0.5667\n",
      "Epoch 721/750\n",
      "162/162 [==============================] - 0s 623us/step - loss: 1.0735 - accuracy: 0.5605 - val_loss: 1.0121 - val_accuracy: 0.5852\n",
      "Epoch 722/750\n",
      "162/162 [==============================] - 0s 652us/step - loss: 1.0654 - accuracy: 0.5716 - val_loss: 1.0360 - val_accuracy: 0.6222\n",
      "Epoch 723/750\n",
      "162/162 [==============================] - 0s 653us/step - loss: 1.0232 - accuracy: 0.5827 - val_loss: 1.0084 - val_accuracy: 0.6148\n",
      "Epoch 724/750\n",
      "162/162 [==============================] - 0s 626us/step - loss: 1.0428 - accuracy: 0.5753 - val_loss: 1.0164 - val_accuracy: 0.5852\n",
      "Epoch 725/750\n",
      "162/162 [==============================] - 0s 663us/step - loss: 1.0498 - accuracy: 0.5642 - val_loss: 1.0268 - val_accuracy: 0.6074\n",
      "Epoch 726/750\n",
      "162/162 [==============================] - 0s 650us/step - loss: 1.0430 - accuracy: 0.5716 - val_loss: 1.0023 - val_accuracy: 0.6185\n",
      "Epoch 727/750\n",
      "162/162 [==============================] - 0s 592us/step - loss: 1.0365 - accuracy: 0.5827 - val_loss: 1.0322 - val_accuracy: 0.5815\n",
      "Epoch 728/750\n",
      "162/162 [==============================] - 0s 641us/step - loss: 1.0402 - accuracy: 0.5605 - val_loss: 1.0426 - val_accuracy: 0.6074\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 729/750\n",
      "162/162 [==============================] - 0s 642us/step - loss: 1.0709 - accuracy: 0.5531 - val_loss: 1.0728 - val_accuracy: 0.6148\n",
      "Epoch 730/750\n",
      "162/162 [==============================] - 0s 646us/step - loss: 1.0605 - accuracy: 0.5716 - val_loss: 1.0208 - val_accuracy: 0.6185\n",
      "Epoch 731/750\n",
      "162/162 [==============================] - 0s 638us/step - loss: 1.0513 - accuracy: 0.5741 - val_loss: 1.1404 - val_accuracy: 0.5741\n",
      "Epoch 732/750\n",
      "162/162 [==============================] - 0s 643us/step - loss: 1.0372 - accuracy: 0.5840 - val_loss: 1.0553 - val_accuracy: 0.5667\n",
      "Epoch 733/750\n",
      "162/162 [==============================] - 0s 692us/step - loss: 1.0385 - accuracy: 0.5642 - val_loss: 1.0924 - val_accuracy: 0.5481\n",
      "Epoch 734/750\n",
      "162/162 [==============================] - 0s 623us/step - loss: 1.0551 - accuracy: 0.5716 - val_loss: 1.1951 - val_accuracy: 0.5593\n",
      "Epoch 735/750\n",
      "162/162 [==============================] - 0s 642us/step - loss: 1.0493 - accuracy: 0.5926 - val_loss: 1.0153 - val_accuracy: 0.6037\n",
      "Epoch 736/750\n",
      "162/162 [==============================] - 0s 594us/step - loss: 1.0401 - accuracy: 0.5728 - val_loss: 1.0812 - val_accuracy: 0.5815\n",
      "Epoch 737/750\n",
      "162/162 [==============================] - 0s 642us/step - loss: 1.0533 - accuracy: 0.5691 - val_loss: 1.0333 - val_accuracy: 0.6074\n",
      "Epoch 738/750\n",
      "162/162 [==============================] - 0s 612us/step - loss: 1.0433 - accuracy: 0.5852 - val_loss: 0.9920 - val_accuracy: 0.6148\n",
      "Epoch 739/750\n",
      "162/162 [==============================] - 0s 593us/step - loss: 1.0273 - accuracy: 0.5889 - val_loss: 1.0236 - val_accuracy: 0.6000\n",
      "Epoch 740/750\n",
      "162/162 [==============================] - 0s 643us/step - loss: 1.0564 - accuracy: 0.5679 - val_loss: 1.0045 - val_accuracy: 0.5778\n",
      "Epoch 741/750\n",
      "162/162 [==============================] - 0s 593us/step - loss: 1.0532 - accuracy: 0.5642 - val_loss: 1.0651 - val_accuracy: 0.5889\n",
      "Epoch 742/750\n",
      "162/162 [==============================] - 0s 643us/step - loss: 1.0376 - accuracy: 0.5765 - val_loss: 1.0305 - val_accuracy: 0.5926\n",
      "Epoch 743/750\n",
      "162/162 [==============================] - 0s 642us/step - loss: 1.0438 - accuracy: 0.5765 - val_loss: 1.0697 - val_accuracy: 0.5444\n",
      "Epoch 744/750\n",
      "162/162 [==============================] - 0s 628us/step - loss: 1.0516 - accuracy: 0.5802 - val_loss: 1.0703 - val_accuracy: 0.5926\n",
      "Epoch 745/750\n",
      "162/162 [==============================] - 0s 639us/step - loss: 1.0460 - accuracy: 0.5778 - val_loss: 1.0438 - val_accuracy: 0.5667\n",
      "Epoch 746/750\n",
      "162/162 [==============================] - 0s 593us/step - loss: 1.0724 - accuracy: 0.5642 - val_loss: 1.1203 - val_accuracy: 0.5333\n",
      "Epoch 747/750\n",
      "162/162 [==============================] - 0s 593us/step - loss: 1.1459 - accuracy: 0.5420 - val_loss: 1.0106 - val_accuracy: 0.6037\n",
      "Epoch 748/750\n",
      "162/162 [==============================] - 0s 593us/step - loss: 1.0262 - accuracy: 0.5790 - val_loss: 1.0545 - val_accuracy: 0.5815\n",
      "Epoch 749/750\n",
      "162/162 [==============================] - 0s 593us/step - loss: 1.0485 - accuracy: 0.5728 - val_loss: 1.0109 - val_accuracy: 0.5852\n",
      "Epoch 750/750\n",
      "162/162 [==============================] - 0s 643us/step - loss: 1.0396 - accuracy: 0.5605 - val_loss: 1.0224 - val_accuracy: 0.6074\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 750\n",
    "BATCH_SIZE = 5\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=EPOCHS, batch_size=BATCH_SIZE, validation_split=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.10      0.18        30\n",
      "           1       0.61      0.95      0.75        40\n",
      "           2       0.44      0.28      0.34        40\n",
      "           3       0.69      0.45      0.55        40\n",
      "           4       0.49      0.72      0.59        40\n",
      "           5       0.43      0.53      0.47        40\n",
      "           6       0.87      0.97      0.92        40\n",
      "\n",
      "    accuracy                           0.59       270\n",
      "   macro avg       0.61      0.57      0.54       270\n",
      "weighted avg       0.61      0.59      0.55       270\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(X_test)\n",
    "pred = np.argmax(pred, axis=1)\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export Models in C code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Models in Pipeline\n",
    "modelsInPipeline = []\n",
    "modelsInPipeline.append('LR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, model in models:\n",
    "    prepath = 'exportedModels/'\n",
    "    path = prepath + name + '.h'\n",
    "    if name in modelsInPipeline:\n",
    "        model = model[1]\n",
    "    with open(path, 'w') as f:\n",
    "        f.write(port(model, optimize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models Comparison for TinyML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "import numpy as np\n",
    "from numpy import arange\n",
    "import pickle\n",
    "from pandas import read_csv\n",
    "#\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#\n",
    "import pandas as pd\n",
    "from pandas import read_csv\n",
    "\n",
    "from sklearn.metrics import confusion_matrix,  classification_report, f1_score\n",
    "from sklearn.model_selection import train_test_split, KFold,StratifiedKFold, cross_val_score, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from keras.models import Sequential, Model \n",
    "from keras.layers import Dense, Input, concatenate, Activation, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import tensorflow\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from micromlgen import port\n",
    "import tinymlgen as tiny\n",
    "\n",
    "import warnings\n",
    "import seaborn as sbs\n",
    "import sys\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "tensorflow.random.set_seed(RANDOM_SEED)\n",
    "np.set_printoptions(threshold=sys.maxsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = ['../data/X-intensity.pkl', '../data/X-all.pkl', '../data/X-10-25.pkl', '../data/X-1-2.pkl', '../data/X-25_50-50_25.pkl']\n",
    "labels = ['../data/y-intensity.pkl', '../data/y-all.pkl', '../data/y-10-25.pkl', '../data/y-1-2.pkl', '../data/y-25_50-50_25.pkl']\n",
    "choosenIndex = 0\n",
    "tasks = ['intensity', 'all','10-25','1-2', '25-50']\n",
    "with open(data[choosenIndex], 'rb') as f:\n",
    "    X = pickle.load(f)\n",
    "\n",
    "with open(labels[choosenIndex], 'rb') as f:\n",
    "    y = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "if choosenIndex == 1:\n",
    "    X = X[165:-13]\n",
    "    y = y[165:-13]\n",
    "if choosenIndex == 2:\n",
    "    X = X[146:-13]\n",
    "    y = y[146:-13]\n",
    "if choosenIndex == 3:\n",
    "    X = X[101:-13]\n",
    "    y = y[101:-13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3900, 60)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=RANDOM_SEED)\n",
    "uniques = np.unique(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(780, 60)\n",
      "[0 0 0 3 4 3 4 2 3 4 3 3 3 1 4 3 1 3 1 4 0 2 1 4 4 1 2 0 4 0 3 1 2 0 4 0 0\n",
      " 2 3 0 0 1 1 3 3 2 2 4 2 4 4 4 2 0 1 3 0 2 0 2 4 1 0 4 4 3 4 1 4 2 2 1 2 2\n",
      " 4 1 4 1 1 3 0 3 3 1 2 1 3 2 4 3 2 1 4 2 0 2 0 2 1 0 3 3 1 0 2 3 4 4 3 3 4\n",
      " 0 3 1 4 4 2 3 4 0 3 3 3 2 2 1 2 3 3 0 4 3 1 4 3 4 0 4 3 3 1 0 3 3 3 0 2 2\n",
      " 1 3 2 3 1 4 1 0 1 1 3 1 0 0 2 4 2 2 1 0 3 2 4 2 2 3 4 2 2 4 2 0 3 1 0 4 1\n",
      " 0 1 1 1 4 1 3 4 3 3 3 1 2 2 0 2 1 1 1 2 4 1 2 0 3 3 2 1 4 2 4 1 3 1 1 0 1\n",
      " 1 1 4 0 2 1 1 0 1 2 1 1 0 0 3 2 0 4 4 0 4 3 2 0 4 2 0 0 3 4 0 0 1 0 1 2 3\n",
      " 1 0 4 2 2 4 4 3 2 3 1 0 3 0 1 0 1 0 2 3 0 4 0 2 1 4 1 4 4 4 1 1 2 3 4 3 3\n",
      " 0 2 0 2 3 3 0 4 3 2 4 4 0 4 0 2 3 4 0 3 2 2 0 3 4 0 1 0 2 4 1 4 0 4 0 2 1\n",
      " 4 2 4 0 0 3 4 3 1 3 3 0 0 3 2 1 0 1 0 1 3 2 2 1 1 1 3 0 0 2 1 2 3 3 0 1 4\n",
      " 2 4 2 2 1 0 2 0 4 4 1 3 4 4 0 0 3 3 3 0 2 3 2 1 4 3 1 0 2 0 4 2 3 4 0 4 4\n",
      " 2 3 3 4 4 4 2 4 3 3 0 3 3 2 4 4 3 0 2 0 3 2 4 3 4 1 1 0 0 0 0 2 1 0 0 1 0\n",
      " 4 4 1 2 2 1 4 1 4 4 1 1 3 2 4 2 3 4 1 3 2 2 3 0 1 4 4 3 2 2 0 4 4 2 1 1 3\n",
      " 1 0 4 0 3 4 4 0 1 0 2 2 3 3 2 4 0 4 0 4 2 0 0 0 4 4 1 2 0 0 4 3 2 1 1 1 1\n",
      " 2 1 1 2 1 3 0 0 4 3 1 1 1 2 4 2 0 3 2 2 3 3 1 1 0 2 2 3 0 3 1 1 2 3 1 3 2\n",
      " 2 1 4 1 0 2 4 3 0 2 3 1 1 2 2 1 3 2 4 0 3 3 0 0 3 2 1 4 0 0 3 1 4 1 0 1 2\n",
      " 3 4 4 1 3 0 3 1 1 2 3 3 0 4 4 0 0 0 0 3 1 2 2 0 2 2 4 2 2 1 1 4 0 2 3 3 3\n",
      " 0 2 0 4 4 0 2 4 0 1 2 0 2 2 2 0 0 1 3 0 4 0 1 2 0 3 1 4 4 3 0 2 1 4 3 2 2\n",
      " 3 4 4 0 3 2 4 0 3 1 2 1 2 1 3 4 4 1 0 2 0 0 1 2 3 0 1 4 1 4 1 3 0 4 3 4 4\n",
      " 0 1 2 2 4 2 4 4 4 0 3 4 1 3 4 4 2 3 1 1 0 2 3 4 1 3 1 2 4 4 2 4 3 1 0 1 0\n",
      " 3 0 3 1 2 0 0 3 3 2 2 3 3 1 3 1 0 1 1 4 4 3 3 4 2 1 2 3 1 2 4 2 3 0 1 1 0\n",
      " 4 4 2]\n"
     ]
    }
   ],
   "source": [
    "print(X_test.shape)\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Spotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test options and evaluation metric\n",
    "num_folds = 10\n",
    "seed = 42\n",
    "scoring = 'f1_macro'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spot-Check Algorithms\n",
    "models = []\n",
    "\n",
    "#models.append(('XGB', XGBClassifier(random_state=seed)))\n",
    "models.append(('GNB', GaussianNB(var_smoothing=2e-9)))\n",
    "models.append(('LR',  LogisticRegression(random_state=seed)))\n",
    "models.append(('CART' , DecisionTreeClassifier(random_state=seed)))\n",
    "models.append(('SVC' , SVC(gamma=0.5, random_state=seed)))\n",
    "models.append(('RF', RandomForestClassifier(random_state=seed, n_estimators = 50)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GNB - 0,78 0,03\n",
      "LR - 0,48 0,02\n",
      "CART - 0,78 0,03\n",
      "SVC - 0,96 0,01\n",
      "RF - 0,99 0,01\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "names = []\n",
    "for name, model in models:\n",
    "    # Dividere dati in n = num_folds\n",
    "    kf = StratifiedKFold(n_splits=num_folds, random_state=seed, shuffle=True)\n",
    "    cv_results = np.array([])\n",
    "    for train_idx, test_idx, in kf.split(X_train, y_train):\n",
    "        X_cross_train, y_cross_train = X_train[train_idx], y_train[train_idx]\n",
    "        X_cross_test, y_cross_test = X_train[test_idx], y_train[test_idx]\n",
    "        model.fit(X_cross_train, y_cross_train)  \n",
    "        y_pred = model.predict(X_cross_test)\n",
    "        f1s = f1_score(y_cross_test, y_pred, average=\"weighted\")\n",
    "        cv_results = np.append(cv_results, [f1s])\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    #msg = \"%s - %f - %f\" % (name, cv_results.mean(), cv_results.std())\n",
    "    msg = \"{} - {:.2f} {:.2f}\".format(name, cv_results.mean(), cv_results.std()).replace('.', ',')\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compare Algorithms\n",
    "fig = plt.figure(figsize=(10,5))\n",
    "fig.suptitle('Algorithms Comparison')\n",
    "ax = fig.add_subplot(111)\n",
    "plt.boxplot(results)\n",
    "ax.set_xticklabels(names)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Valutazione dei modelli sul Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model GNB: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.68      0.70       156\n",
      "           1       0.69      0.72      0.71       156\n",
      "           2       0.99      0.97      0.98       156\n",
      "           3       0.84      0.76      0.80       156\n",
      "           4       0.79      0.87      0.83       156\n",
      "\n",
      "    accuracy                           0.80       780\n",
      "   macro avg       0.80      0.80      0.80       780\n",
      "weighted avg       0.80      0.80      0.80       780\n",
      "\n",
      "-------------------------------------------------------------\n",
      "Model LR: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      0.30      0.34       156\n",
      "           1       0.38      0.51      0.43       156\n",
      "           2       0.86      0.98      0.92       156\n",
      "           3       0.18      0.08      0.11       156\n",
      "           4       0.55      0.71      0.62       156\n",
      "\n",
      "    accuracy                           0.52       780\n",
      "   macro avg       0.47      0.52      0.48       780\n",
      "weighted avg       0.47      0.52      0.48       780\n",
      "\n",
      "-------------------------------------------------------------\n",
      "Model CART: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.87      0.85       156\n",
      "           1       0.80      0.78      0.79       156\n",
      "           2       0.83      0.75      0.79       156\n",
      "           3       0.72      0.74      0.73       156\n",
      "           4       0.79      0.82      0.81       156\n",
      "\n",
      "    accuracy                           0.79       780\n",
      "   macro avg       0.79      0.79      0.79       780\n",
      "weighted avg       0.79      0.79      0.79       780\n",
      "\n",
      "-------------------------------------------------------------\n",
      "Model SVC: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.97       156\n",
      "           1       0.97      0.99      0.98       156\n",
      "           2       0.99      0.99      0.99       156\n",
      "           3       0.99      0.88      0.93       156\n",
      "           4       0.92      0.98      0.95       156\n",
      "\n",
      "    accuracy                           0.97       780\n",
      "   macro avg       0.97      0.97      0.97       780\n",
      "weighted avg       0.97      0.97      0.97       780\n",
      "\n",
      "-------------------------------------------------------------\n",
      "Model RF: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00       156\n",
      "           1       0.99      1.00      1.00       156\n",
      "           2       1.00      0.99      1.00       156\n",
      "           3       0.99      0.97      0.98       156\n",
      "           4       0.97      0.99      0.98       156\n",
      "\n",
      "    accuracy                           0.99       780\n",
      "   macro avg       0.99      0.99      0.99       780\n",
      "weighted avg       0.99      0.99      0.99       780\n",
      "\n",
      "-------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def classification_report_csv(report, model_name):\n",
    "    report_data = []\n",
    "    lines = report.split('\\n')\n",
    "    index = 0\n",
    "    row = lines[-4].split('    ')\n",
    "    accuracy = row[-2]\n",
    "    for line in lines[2:-5]:\n",
    "        row = {}\n",
    "        row_data = line.split('      ')\n",
    "        row['class'] = uniques[index]\n",
    "        row['precision'] = float(row_data[2]) \n",
    "        row['recall'] = float(row_data[3]) \n",
    "        row['f1_score'] = float(row_data[4])\n",
    "        row['accuracy'] = accuracy\n",
    "        report_data.append(row)\n",
    "        index += 1\n",
    "    dataframe = pd.DataFrame.from_dict(report_data)\n",
    "    dataframe.to_csv(tasks[choosenIndex]+ '/classificationReports'+ '/'+'classification_report' + model_name +  '.csv', index = False)\n",
    "    \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=RANDOM_SEED)\n",
    "\n",
    "for name, model in models:\n",
    "    model.fit(X_train,  y_train)\n",
    "    pred_train = model.predict(X_train)\n",
    "    pred_test = model.predict(X_test)\n",
    "    print(f\"Model {name}: \")\n",
    "    report = classification_report(y_test, pred_test)\n",
    "    print(report)\n",
    "    classification_report_csv(report, name)\n",
    "    print(\"-------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNetwork():\n",
    "    n = 50\n",
    "    model = Sequential(name=\"Sequential-NN\")\n",
    "    model.add(layers.Dense(X.shape[1], activation='relu', input_shape=(X.shape[1],)))\n",
    "    model.add(layers.Dense(np.unique(y).size * n, activation='relu'))\n",
    "    model.add(layers.Dense(np.unique(y).size, activation='softmax'))\n",
    "    opt = Adam(learning_rate=0.0001)\n",
    "    model.compile(optimizer=opt, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross-Validation NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Sequential-NN\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_42 (Dense)             (None, 60)                3660      \n",
      "_________________________________________________________________\n",
      "dense_43 (Dense)             (None, 250)               15250     \n",
      "_________________________________________________________________\n",
      "dense_44 (Dense)             (None, 5)                 1255      \n",
      "=================================================================\n",
      "Total params: 20,165\n",
      "Trainable params: 20,165\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "281/281 [==============================] - 0s 519us/step - loss: 1.6089 - accuracy: 0.2176\n",
      "Epoch 2/100\n",
      "281/281 [==============================] - 0s 557us/step - loss: 1.5890 - accuracy: 0.3020\n",
      "Epoch 3/100\n",
      "281/281 [==============================] - 0s 531us/step - loss: 1.5633 - accuracy: 0.3590\n",
      "Epoch 4/100\n",
      "281/281 [==============================] - 0s 511us/step - loss: 1.5227 - accuracy: 0.4124\n",
      "Epoch 5/100\n",
      "281/281 [==============================] - 0s 495us/step - loss: 1.4641 - accuracy: 0.4679\n",
      "Epoch 6/100\n",
      "281/281 [==============================] - 0s 495us/step - loss: 1.3927 - accuracy: 0.4672\n",
      "Epoch 7/100\n",
      "281/281 [==============================] - 0s 532us/step - loss: 1.3187 - accuracy: 0.5100\n",
      "Epoch 8/100\n",
      "281/281 [==============================] - 0s 516us/step - loss: 1.2494 - accuracy: 0.5345\n",
      "Epoch 9/100\n",
      "281/281 [==============================] - 0s 509us/step - loss: 1.1915 - accuracy: 0.5637\n",
      "Epoch 10/100\n",
      "281/281 [==============================] - 0s 502us/step - loss: 1.1448 - accuracy: 0.5819\n",
      "Epoch 11/100\n",
      "281/281 [==============================] - 0s 529us/step - loss: 1.1041 - accuracy: 0.5929\n",
      "Epoch 12/100\n",
      "281/281 [==============================] - 0s 503us/step - loss: 1.0691 - accuracy: 0.6075\n",
      "Epoch 13/100\n",
      "281/281 [==============================] - 0s 512us/step - loss: 1.0392 - accuracy: 0.6204\n",
      "Epoch 14/100\n",
      "281/281 [==============================] - 0s 499us/step - loss: 1.0083 - accuracy: 0.6321\n",
      "Epoch 15/100\n",
      "281/281 [==============================] - 0s 487us/step - loss: 0.9790 - accuracy: 0.6439\n",
      "Epoch 16/100\n",
      "281/281 [==============================] - 0s 517us/step - loss: 0.9527 - accuracy: 0.6489\n",
      "Epoch 17/100\n",
      "281/281 [==============================] - 0s 526us/step - loss: 0.9271 - accuracy: 0.6656\n",
      "Epoch 18/100\n",
      "281/281 [==============================] - 0s 533us/step - loss: 0.9021 - accuracy: 0.6734\n",
      "Epoch 19/100\n",
      "281/281 [==============================] - 0s 530us/step - loss: 0.8771 - accuracy: 0.6774\n",
      "Epoch 20/100\n",
      "281/281 [==============================] - 0s 529us/step - loss: 0.8516 - accuracy: 0.6976\n",
      "Epoch 21/100\n",
      "281/281 [==============================] - 0s 513us/step - loss: 0.8290 - accuracy: 0.7044\n",
      "Epoch 22/100\n",
      "281/281 [==============================] - 0s 487us/step - loss: 0.8057 - accuracy: 0.7194\n",
      "Epoch 23/100\n",
      "281/281 [==============================] - 0s 492us/step - loss: 0.7862 - accuracy: 0.7258\n",
      "Epoch 24/100\n",
      "281/281 [==============================] - 0s 486us/step - loss: 0.7655 - accuracy: 0.7382\n",
      "Epoch 25/100\n",
      "281/281 [==============================] - 0s 503us/step - loss: 0.7454 - accuracy: 0.7468\n",
      "Epoch 26/100\n",
      "281/281 [==============================] - 0s 485us/step - loss: 0.7251 - accuracy: 0.7564\n",
      "Epoch 27/100\n",
      "281/281 [==============================] - 0s 496us/step - loss: 0.7068 - accuracy: 0.7642\n",
      "Epoch 28/100\n",
      "281/281 [==============================] - 0s 497us/step - loss: 0.6901 - accuracy: 0.7653\n",
      "Epoch 29/100\n",
      "281/281 [==============================] - 0s 500us/step - loss: 0.6722 - accuracy: 0.7810\n",
      "Epoch 30/100\n",
      "281/281 [==============================] - 0s 489us/step - loss: 0.6550 - accuracy: 0.7867\n",
      "Epoch 31/100\n",
      "281/281 [==============================] - 0s 498us/step - loss: 0.6391 - accuracy: 0.7934\n",
      "Epoch 32/100\n",
      "281/281 [==============================] - 0s 515us/step - loss: 0.6249 - accuracy: 0.7981\n",
      "Epoch 33/100\n",
      "281/281 [==============================] - 0s 517us/step - loss: 0.6098 - accuracy: 0.7974\n",
      "Epoch 34/100\n",
      "281/281 [==============================] - 0s 498us/step - loss: 0.5925 - accuracy: 0.8077\n",
      "Epoch 35/100\n",
      "281/281 [==============================] - 0s 554us/step - loss: 0.5776 - accuracy: 0.8113\n",
      "Epoch 36/100\n",
      "281/281 [==============================] - 0s 565us/step - loss: 0.5642 - accuracy: 0.8198\n",
      "Epoch 37/100\n",
      "281/281 [==============================] - 0s 506us/step - loss: 0.5500 - accuracy: 0.8216\n",
      "Epoch 38/100\n",
      "281/281 [==============================] - 0s 506us/step - loss: 0.5366 - accuracy: 0.8294\n",
      "Epoch 39/100\n",
      "281/281 [==============================] - 0s 503us/step - loss: 0.5249 - accuracy: 0.8330\n",
      "Epoch 40/100\n",
      "281/281 [==============================] - 0s 499us/step - loss: 0.5110 - accuracy: 0.8337\n",
      "Epoch 41/100\n",
      "281/281 [==============================] - 0s 532us/step - loss: 0.5000 - accuracy: 0.8369\n",
      "Epoch 42/100\n",
      "281/281 [==============================] - 0s 540us/step - loss: 0.4873 - accuracy: 0.8437\n",
      "Epoch 43/100\n",
      "281/281 [==============================] - 0s 516us/step - loss: 0.4778 - accuracy: 0.8483\n",
      "Epoch 44/100\n",
      "281/281 [==============================] - 0s 498us/step - loss: 0.4655 - accuracy: 0.8522\n",
      "Epoch 45/100\n",
      "281/281 [==============================] - 0s 501us/step - loss: 0.4548 - accuracy: 0.8551\n",
      "Epoch 46/100\n",
      "281/281 [==============================] - 0s 528us/step - loss: 0.4446 - accuracy: 0.8572\n",
      "Epoch 47/100\n",
      "281/281 [==============================] - 0s 512us/step - loss: 0.4344 - accuracy: 0.8547\n",
      "Epoch 48/100\n",
      "281/281 [==============================] - 0s 555us/step - loss: 0.4268 - accuracy: 0.8650\n",
      "Epoch 49/100\n",
      "281/281 [==============================] - 0s 514us/step - loss: 0.4160 - accuracy: 0.8657\n",
      "Epoch 50/100\n",
      "281/281 [==============================] - 0s 488us/step - loss: 0.4067 - accuracy: 0.8714\n",
      "Epoch 51/100\n",
      "281/281 [==============================] - 0s 497us/step - loss: 0.4014 - accuracy: 0.8689\n",
      "Epoch 52/100\n",
      "281/281 [==============================] - 0s 501us/step - loss: 0.3885 - accuracy: 0.8736\n",
      "Epoch 53/100\n",
      "281/281 [==============================] - 0s 516us/step - loss: 0.3807 - accuracy: 0.8778\n",
      "Epoch 54/100\n",
      "281/281 [==============================] - 0s 518us/step - loss: 0.3747 - accuracy: 0.8807\n",
      "Epoch 55/100\n",
      "281/281 [==============================] - 0s 517us/step - loss: 0.3668 - accuracy: 0.8803\n",
      "Epoch 56/100\n",
      "281/281 [==============================] - 0s 501us/step - loss: 0.3589 - accuracy: 0.8832\n",
      "Epoch 57/100\n",
      "281/281 [==============================] - 0s 502us/step - loss: 0.3526 - accuracy: 0.8907\n",
      "Epoch 58/100\n",
      "281/281 [==============================] - 0s 561us/step - loss: 0.3456 - accuracy: 0.8857\n",
      "Epoch 59/100\n",
      "281/281 [==============================] - 0s 535us/step - loss: 0.3380 - accuracy: 0.8878\n",
      "Epoch 60/100\n",
      "281/281 [==============================] - 0s 517us/step - loss: 0.3341 - accuracy: 0.8892\n",
      "Epoch 61/100\n",
      "281/281 [==============================] - 0s 504us/step - loss: 0.3258 - accuracy: 0.8935\n",
      "Epoch 62/100\n",
      "281/281 [==============================] - 0s 568us/step - loss: 0.3189 - accuracy: 0.8917\n",
      "Epoch 63/100\n",
      "281/281 [==============================] - 0s 613us/step - loss: 0.3150 - accuracy: 0.8971\n",
      "Epoch 64/100\n",
      "281/281 [==============================] - 0s 533us/step - loss: 0.3099 - accuracy: 0.9031\n",
      "Epoch 65/100\n",
      "281/281 [==============================] - 0s 567us/step - loss: 0.3036 - accuracy: 0.9049\n",
      "Epoch 66/100\n",
      "281/281 [==============================] - 0s 546us/step - loss: 0.2999 - accuracy: 0.8999\n",
      "Epoch 67/100\n",
      "281/281 [==============================] - 0s 564us/step - loss: 0.2919 - accuracy: 0.9078\n",
      "Epoch 68/100\n",
      "281/281 [==============================] - 0s 535us/step - loss: 0.2896 - accuracy: 0.9060\n",
      "Epoch 69/100\n",
      "281/281 [==============================] - 0s 544us/step - loss: 0.2827 - accuracy: 0.9138\n",
      "Epoch 70/100\n",
      "281/281 [==============================] - 0s 564us/step - loss: 0.2756 - accuracy: 0.9142\n",
      "Epoch 71/100\n",
      "281/281 [==============================] - 0s 522us/step - loss: 0.2728 - accuracy: 0.9085\n",
      "Epoch 72/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "281/281 [==============================] - 0s 521us/step - loss: 0.2690 - accuracy: 0.9163\n",
      "Epoch 73/100\n",
      "281/281 [==============================] - 0s 509us/step - loss: 0.2620 - accuracy: 0.9149\n",
      "Epoch 74/100\n",
      "281/281 [==============================] - 0s 531us/step - loss: 0.2597 - accuracy: 0.9149\n",
      "Epoch 75/100\n",
      "281/281 [==============================] - 0s 517us/step - loss: 0.2541 - accuracy: 0.9149\n",
      "Epoch 76/100\n",
      "281/281 [==============================] - 0s 501us/step - loss: 0.2513 - accuracy: 0.9170\n",
      "Epoch 77/100\n",
      "281/281 [==============================] - 0s 523us/step - loss: 0.2468 - accuracy: 0.9224\n",
      "Epoch 78/100\n",
      "281/281 [==============================] - 0s 547us/step - loss: 0.2431 - accuracy: 0.9241\n",
      "Epoch 79/100\n",
      "281/281 [==============================] - 0s 556us/step - loss: 0.2382 - accuracy: 0.9241\n",
      "Epoch 80/100\n",
      "281/281 [==============================] - 0s 507us/step - loss: 0.2355 - accuracy: 0.9266\n",
      "Epoch 81/100\n",
      "281/281 [==============================] - 0s 513us/step - loss: 0.2305 - accuracy: 0.9302\n",
      "Epoch 82/100\n",
      "281/281 [==============================] - 0s 505us/step - loss: 0.2258 - accuracy: 0.9327\n",
      "Epoch 83/100\n",
      "281/281 [==============================] - 0s 501us/step - loss: 0.2250 - accuracy: 0.9288\n",
      "Epoch 84/100\n",
      "281/281 [==============================] - 0s 532us/step - loss: 0.2203 - accuracy: 0.9334\n",
      "Epoch 85/100\n",
      "281/281 [==============================] - 0s 547us/step - loss: 0.2156 - accuracy: 0.9295\n",
      "Epoch 86/100\n",
      "281/281 [==============================] - 0s 530us/step - loss: 0.2134 - accuracy: 0.9309\n",
      "Epoch 87/100\n",
      "281/281 [==============================] - 0s 494us/step - loss: 0.2098 - accuracy: 0.9341\n",
      "Epoch 88/100\n",
      "281/281 [==============================] - 0s 485us/step - loss: 0.2064 - accuracy: 0.9345\n",
      "Epoch 89/100\n",
      "281/281 [==============================] - 0s 511us/step - loss: 0.2034 - accuracy: 0.9391\n",
      "Epoch 90/100\n",
      "281/281 [==============================] - 0s 514us/step - loss: 0.1981 - accuracy: 0.9391\n",
      "Epoch 91/100\n",
      "281/281 [==============================] - 0s 510us/step - loss: 0.1958 - accuracy: 0.9391\n",
      "Epoch 92/100\n",
      "281/281 [==============================] - 0s 495us/step - loss: 0.1931 - accuracy: 0.9420\n",
      "Epoch 93/100\n",
      "281/281 [==============================] - 0s 544us/step - loss: 0.1911 - accuracy: 0.9437\n",
      "Epoch 94/100\n",
      "281/281 [==============================] - 0s 558us/step - loss: 0.1887 - accuracy: 0.9473\n",
      "Epoch 95/100\n",
      "281/281 [==============================] - 0s 540us/step - loss: 0.1848 - accuracy: 0.9427\n",
      "Epoch 96/100\n",
      "281/281 [==============================] - 0s 568us/step - loss: 0.1811 - accuracy: 0.9473\n",
      "Epoch 97/100\n",
      "281/281 [==============================] - 0s 576us/step - loss: 0.1799 - accuracy: 0.9466\n",
      "Epoch 98/100\n",
      "281/281 [==============================] - 0s 600us/step - loss: 0.1768 - accuracy: 0.9480\n",
      "Epoch 99/100\n",
      "281/281 [==============================] - 0s 617us/step - loss: 0.1747 - accuracy: 0.9501\n",
      "Epoch 100/100\n",
      "281/281 [==============================] - 0s 614us/step - loss: 0.1720 - accuracy: 0.9466\n",
      "Model: \"Sequential-NN\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_45 (Dense)             (None, 60)                3660      \n",
      "_________________________________________________________________\n",
      "dense_46 (Dense)             (None, 250)               15250     \n",
      "_________________________________________________________________\n",
      "dense_47 (Dense)             (None, 5)                 1255      \n",
      "=================================================================\n",
      "Total params: 20,165\n",
      "Trainable params: 20,165\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "281/281 [==============================] - 0s 766us/step - loss: 1.6077 - accuracy: 0.2183\n",
      "Epoch 2/100\n",
      "281/281 [==============================] - 0s 602us/step - loss: 1.5729 - accuracy: 0.3376\n",
      "Epoch 3/100\n",
      "281/281 [==============================] - 0s 566us/step - loss: 1.5239 - accuracy: 0.3711\n",
      "Epoch 4/100\n",
      "281/281 [==============================] - 0s 616us/step - loss: 1.4604 - accuracy: 0.4021\n",
      "Epoch 5/100\n",
      "281/281 [==============================] - 0s 544us/step - loss: 1.3883 - accuracy: 0.4505\n",
      "Epoch 6/100\n",
      "281/281 [==============================] - 0s 542us/step - loss: 1.3178 - accuracy: 0.4662\n",
      "Epoch 7/100\n",
      "281/281 [==============================] - 0s 535us/step - loss: 1.2540 - accuracy: 0.5110\n",
      "Epoch 8/100\n",
      "281/281 [==============================] - 0s 536us/step - loss: 1.2013 - accuracy: 0.5321\n",
      "Epoch 9/100\n",
      "281/281 [==============================] - 0s 482us/step - loss: 1.1594 - accuracy: 0.5442\n",
      "Epoch 10/100\n",
      "281/281 [==============================] - 0s 499us/step - loss: 1.1220 - accuracy: 0.5580\n",
      "Epoch 11/100\n",
      "281/281 [==============================] - 0s 552us/step - loss: 1.0913 - accuracy: 0.5759\n",
      "Epoch 12/100\n",
      "281/281 [==============================] - 0s 572us/step - loss: 1.0628 - accuracy: 0.5687\n",
      "Epoch 13/100\n",
      "281/281 [==============================] - 0s 577us/step - loss: 1.0382 - accuracy: 0.5894\n",
      "Epoch 14/100\n",
      "281/281 [==============================] - 0s 572us/step - loss: 1.0158 - accuracy: 0.6129\n",
      "Epoch 15/100\n",
      "281/281 [==============================] - 0s 580us/step - loss: 0.9903 - accuracy: 0.6243\n",
      "Epoch 16/100\n",
      "281/281 [==============================] - 0s 582us/step - loss: 0.9687 - accuracy: 0.6375\n",
      "Epoch 17/100\n",
      "281/281 [==============================] - 0s 571us/step - loss: 0.9477 - accuracy: 0.6389\n",
      "Epoch 18/100\n",
      "281/281 [==============================] - 0s 567us/step - loss: 0.9286 - accuracy: 0.6414\n",
      "Epoch 19/100\n",
      "281/281 [==============================] - 0s 567us/step - loss: 0.9094 - accuracy: 0.6627\n",
      "Epoch 20/100\n",
      "281/281 [==============================] - 0s 539us/step - loss: 0.8911 - accuracy: 0.6731\n",
      "Epoch 21/100\n",
      "281/281 [==============================] - 0s 566us/step - loss: 0.8707 - accuracy: 0.6766\n",
      "Epoch 22/100\n",
      "281/281 [==============================] - 0s 590us/step - loss: 0.8530 - accuracy: 0.6923\n",
      "Epoch 23/100\n",
      "281/281 [==============================] - 0s 520us/step - loss: 0.8357 - accuracy: 0.7087\n",
      "Epoch 24/100\n",
      "281/281 [==============================] - 0s 540us/step - loss: 0.8196 - accuracy: 0.7137\n",
      "Epoch 25/100\n",
      "281/281 [==============================] - 0s 556us/step - loss: 0.8039 - accuracy: 0.7222\n",
      "Epoch 26/100\n",
      "281/281 [==============================] - 0s 520us/step - loss: 0.7884 - accuracy: 0.7219\n",
      "Epoch 27/100\n",
      "281/281 [==============================] - 0s 525us/step - loss: 0.7728 - accuracy: 0.7343\n",
      "Epoch 28/100\n",
      "281/281 [==============================] - 0s 531us/step - loss: 0.7585 - accuracy: 0.7368\n",
      "Epoch 29/100\n",
      "281/281 [==============================] - 0s 498us/step - loss: 0.7465 - accuracy: 0.7468\n",
      "Epoch 30/100\n",
      "281/281 [==============================] - 0s 524us/step - loss: 0.7321 - accuracy: 0.7550\n",
      "Epoch 31/100\n",
      "281/281 [==============================] - 0s 504us/step - loss: 0.7189 - accuracy: 0.7546\n",
      "Epoch 32/100\n",
      "281/281 [==============================] - 0s 517us/step - loss: 0.7065 - accuracy: 0.7593\n",
      "Epoch 33/100\n",
      "281/281 [==============================] - 0s 499us/step - loss: 0.6966 - accuracy: 0.7682\n",
      "Epoch 34/100\n",
      "281/281 [==============================] - 0s 494us/step - loss: 0.6842 - accuracy: 0.7724\n",
      "Epoch 35/100\n",
      "281/281 [==============================] - 0s 660us/step - loss: 0.6720 - accuracy: 0.7756\n",
      "Epoch 36/100\n",
      "281/281 [==============================] - 0s 575us/step - loss: 0.6611 - accuracy: 0.7838\n",
      "Epoch 37/100\n",
      "281/281 [==============================] - 0s 539us/step - loss: 0.6511 - accuracy: 0.7835\n",
      "Epoch 38/100\n",
      "281/281 [==============================] - 0s 777us/step - loss: 0.6403 - accuracy: 0.7949\n",
      "Epoch 39/100\n",
      "281/281 [==============================] - 0s 593us/step - loss: 0.6320 - accuracy: 0.7863\n",
      "Epoch 40/100\n",
      "281/281 [==============================] - 0s 585us/step - loss: 0.6202 - accuracy: 0.7988\n",
      "Epoch 41/100\n",
      "281/281 [==============================] - 0s 618us/step - loss: 0.6103 - accuracy: 0.7963\n",
      "Epoch 42/100\n",
      "281/281 [==============================] - 0s 596us/step - loss: 0.6032 - accuracy: 0.8048\n",
      "Epoch 43/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "281/281 [==============================] - 0s 605us/step - loss: 0.5933 - accuracy: 0.8027\n",
      "Epoch 44/100\n",
      "281/281 [==============================] - 0s 617us/step - loss: 0.5830 - accuracy: 0.8073\n",
      "Epoch 45/100\n",
      "281/281 [==============================] - 0s 600us/step - loss: 0.5739 - accuracy: 0.8141\n",
      "Epoch 46/100\n",
      "281/281 [==============================] - 0s 598us/step - loss: 0.5647 - accuracy: 0.8180\n",
      "Epoch 47/100\n",
      "281/281 [==============================] - 0s 590us/step - loss: 0.5580 - accuracy: 0.8234\n",
      "Epoch 48/100\n",
      "281/281 [==============================] - 0s 564us/step - loss: 0.5454 - accuracy: 0.8152\n",
      "Epoch 49/100\n",
      "281/281 [==============================] - 0s 568us/step - loss: 0.5382 - accuracy: 0.8291\n",
      "Epoch 50/100\n",
      "281/281 [==============================] - 0s 534us/step - loss: 0.5294 - accuracy: 0.8298\n",
      "Epoch 51/100\n",
      "281/281 [==============================] - 0s 643us/step - loss: 0.5231 - accuracy: 0.8344\n",
      "Epoch 52/100\n",
      "281/281 [==============================] - 0s 563us/step - loss: 0.5152 - accuracy: 0.8308\n",
      "Epoch 53/100\n",
      "281/281 [==============================] - 0s 566us/step - loss: 0.5062 - accuracy: 0.8365\n",
      "Epoch 54/100\n",
      "281/281 [==============================] - 0s 611us/step - loss: 0.5000 - accuracy: 0.8390\n",
      "Epoch 55/100\n",
      "281/281 [==============================] - 0s 621us/step - loss: 0.4920 - accuracy: 0.8394\n",
      "Epoch 56/100\n",
      "281/281 [==============================] - 0s 530us/step - loss: 0.4848 - accuracy: 0.8390\n",
      "Epoch 57/100\n",
      "281/281 [==============================] - 0s 527us/step - loss: 0.4760 - accuracy: 0.8483\n",
      "Epoch 58/100\n",
      "281/281 [==============================] - 0s 527us/step - loss: 0.4695 - accuracy: 0.8465\n",
      "Epoch 59/100\n",
      "281/281 [==============================] - 0s 633us/step - loss: 0.4617 - accuracy: 0.8494\n",
      "Epoch 60/100\n",
      "281/281 [==============================] - 0s 666us/step - loss: 0.4555 - accuracy: 0.8494\n",
      "Epoch 61/100\n",
      "281/281 [==============================] - 0s 588us/step - loss: 0.4452 - accuracy: 0.8590\n",
      "Epoch 62/100\n",
      "281/281 [==============================] - 0s 545us/step - loss: 0.4397 - accuracy: 0.8600\n",
      "Epoch 63/100\n",
      "281/281 [==============================] - 0s 558us/step - loss: 0.4332 - accuracy: 0.8611\n",
      "Epoch 64/100\n",
      "281/281 [==============================] - 0s 525us/step - loss: 0.4236 - accuracy: 0.8643\n",
      "Epoch 65/100\n",
      "281/281 [==============================] - 0s 520us/step - loss: 0.4177 - accuracy: 0.8654\n",
      "Epoch 66/100\n",
      "281/281 [==============================] - 0s 505us/step - loss: 0.4108 - accuracy: 0.8679\n",
      "Epoch 67/100\n",
      "281/281 [==============================] - 0s 513us/step - loss: 0.4045 - accuracy: 0.8768\n",
      "Epoch 68/100\n",
      "281/281 [==============================] - 0s 499us/step - loss: 0.3983 - accuracy: 0.8750\n",
      "Epoch 69/100\n",
      "281/281 [==============================] - 0s 492us/step - loss: 0.3898 - accuracy: 0.8793\n",
      "Epoch 70/100\n",
      "281/281 [==============================] - 0s 498us/step - loss: 0.3823 - accuracy: 0.8800\n",
      "Epoch 71/100\n",
      "281/281 [==============================] - 0s 513us/step - loss: 0.3787 - accuracy: 0.8807\n",
      "Epoch 72/100\n",
      "281/281 [==============================] - 0s 548us/step - loss: 0.3721 - accuracy: 0.8889\n",
      "Epoch 73/100\n",
      "281/281 [==============================] - 0s 552us/step - loss: 0.3621 - accuracy: 0.8871\n",
      "Epoch 74/100\n",
      "281/281 [==============================] - 0s 518us/step - loss: 0.3587 - accuracy: 0.8853\n",
      "Epoch 75/100\n",
      "281/281 [==============================] - 0s 506us/step - loss: 0.3510 - accuracy: 0.8896\n",
      "Epoch 76/100\n",
      "281/281 [==============================] - 0s 497us/step - loss: 0.3463 - accuracy: 0.8903\n",
      "Epoch 77/100\n",
      "281/281 [==============================] - 0s 467us/step - loss: 0.3394 - accuracy: 0.8949\n",
      "Epoch 78/100\n",
      "281/281 [==============================] - 0s 481us/step - loss: 0.3309 - accuracy: 0.9010\n",
      "Epoch 79/100\n",
      "281/281 [==============================] - 0s 486us/step - loss: 0.3269 - accuracy: 0.8989\n",
      "Epoch 80/100\n",
      "281/281 [==============================] - 0s 503us/step - loss: 0.3191 - accuracy: 0.9042\n",
      "Epoch 81/100\n",
      "281/281 [==============================] - 0s 453us/step - loss: 0.3129 - accuracy: 0.9046\n",
      "Epoch 82/100\n",
      "281/281 [==============================] - 0s 468us/step - loss: 0.3072 - accuracy: 0.9049\n",
      "Epoch 83/100\n",
      "281/281 [==============================] - 0s 499us/step - loss: 0.3026 - accuracy: 0.9088\n",
      "Epoch 84/100\n",
      "281/281 [==============================] - 0s 522us/step - loss: 0.2947 - accuracy: 0.9095\n",
      "Epoch 85/100\n",
      "281/281 [==============================] - 0s 497us/step - loss: 0.2907 - accuracy: 0.9142\n",
      "Epoch 86/100\n",
      "281/281 [==============================] - 0s 470us/step - loss: 0.2856 - accuracy: 0.9174\n",
      "Epoch 87/100\n",
      "281/281 [==============================] - 0s 488us/step - loss: 0.2801 - accuracy: 0.9124\n",
      "Epoch 88/100\n",
      "281/281 [==============================] - 0s 476us/step - loss: 0.2734 - accuracy: 0.9184\n",
      "Epoch 89/100\n",
      "281/281 [==============================] - 0s 523us/step - loss: 0.2689 - accuracy: 0.9209\n",
      "Epoch 90/100\n",
      "281/281 [==============================] - 0s 541us/step - loss: 0.2638 - accuracy: 0.9220\n",
      "Epoch 91/100\n",
      "281/281 [==============================] - 0s 512us/step - loss: 0.2608 - accuracy: 0.9252\n",
      "Epoch 92/100\n",
      "281/281 [==============================] - 0s 501us/step - loss: 0.2541 - accuracy: 0.9209\n",
      "Epoch 93/100\n",
      "281/281 [==============================] - 0s 533us/step - loss: 0.2504 - accuracy: 0.9284\n",
      "Epoch 94/100\n",
      "281/281 [==============================] - 0s 498us/step - loss: 0.2452 - accuracy: 0.9270\n",
      "Epoch 95/100\n",
      "281/281 [==============================] - 0s 483us/step - loss: 0.2415 - accuracy: 0.9245\n",
      "Epoch 96/100\n",
      "281/281 [==============================] - 0s 491us/step - loss: 0.2360 - accuracy: 0.9313\n",
      "Epoch 97/100\n",
      "281/281 [==============================] - 0s 525us/step - loss: 0.2337 - accuracy: 0.9320\n",
      "Epoch 98/100\n",
      "281/281 [==============================] - 0s 519us/step - loss: 0.2303 - accuracy: 0.9323\n",
      "Epoch 99/100\n",
      "281/281 [==============================] - 0s 519us/step - loss: 0.2251 - accuracy: 0.9345\n",
      "Epoch 100/100\n",
      "281/281 [==============================] - 0s 490us/step - loss: 0.2197 - accuracy: 0.9402\n",
      "Model: \"Sequential-NN\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_48 (Dense)             (None, 60)                3660      \n",
      "_________________________________________________________________\n",
      "dense_49 (Dense)             (None, 250)               15250     \n",
      "_________________________________________________________________\n",
      "dense_50 (Dense)             (None, 5)                 1255      \n",
      "=================================================================\n",
      "Total params: 20,165\n",
      "Trainable params: 20,165\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "281/281 [==============================] - 0s 478us/step - loss: 1.6032 - accuracy: 0.2472\n",
      "Epoch 2/100\n",
      "281/281 [==============================] - 0s 527us/step - loss: 1.5757 - accuracy: 0.3462\n",
      "Epoch 3/100\n",
      "281/281 [==============================] - 0s 537us/step - loss: 1.5380 - accuracy: 0.4088\n",
      "Epoch 4/100\n",
      "281/281 [==============================] - 0s 470us/step - loss: 1.4807 - accuracy: 0.4387\n",
      "Epoch 5/100\n",
      "281/281 [==============================] - 0s 473us/step - loss: 1.4052 - accuracy: 0.4573\n",
      "Epoch 6/100\n",
      "281/281 [==============================] - 0s 525us/step - loss: 1.3253 - accuracy: 0.5242\n",
      "Epoch 7/100\n",
      "281/281 [==============================] - 0s 506us/step - loss: 1.2499 - accuracy: 0.5627\n",
      "Epoch 8/100\n",
      "281/281 [==============================] - 0s 548us/step - loss: 1.1892 - accuracy: 0.5890\n",
      "Epoch 9/100\n",
      "281/281 [==============================] - 0s 561us/step - loss: 1.1373 - accuracy: 0.6086\n",
      "Epoch 10/100\n",
      "281/281 [==============================] - 0s 604us/step - loss: 1.0936 - accuracy: 0.6332\n",
      "Epoch 11/100\n",
      "281/281 [==============================] - 0s 598us/step - loss: 1.0559 - accuracy: 0.6610\n",
      "Epoch 12/100\n",
      "281/281 [==============================] - 0s 613us/step - loss: 1.0202 - accuracy: 0.6770\n",
      "Epoch 13/100\n",
      "281/281 [==============================] - 0s 578us/step - loss: 0.9880 - accuracy: 0.6802\n",
      "Epoch 14/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "281/281 [==============================] - 0s 539us/step - loss: 0.9584 - accuracy: 0.6941\n",
      "Epoch 15/100\n",
      "281/281 [==============================] - 0s 487us/step - loss: 0.9289 - accuracy: 0.7058\n",
      "Epoch 16/100\n",
      "281/281 [==============================] - 0s 519us/step - loss: 0.8990 - accuracy: 0.7169\n",
      "Epoch 17/100\n",
      "281/281 [==============================] - 0s 474us/step - loss: 0.8747 - accuracy: 0.7390\n",
      "Epoch 18/100\n",
      "281/281 [==============================] - 0s 534us/step - loss: 0.8510 - accuracy: 0.7407\n",
      "Epoch 19/100\n",
      "281/281 [==============================] - 0s 558us/step - loss: 0.8279 - accuracy: 0.7379\n",
      "Epoch 20/100\n",
      "281/281 [==============================] - 0s 564us/step - loss: 0.8067 - accuracy: 0.7411\n",
      "Epoch 21/100\n",
      "281/281 [==============================] - 0s 551us/step - loss: 0.7882 - accuracy: 0.7493\n",
      "Epoch 22/100\n",
      "281/281 [==============================] - 0s 518us/step - loss: 0.7692 - accuracy: 0.7582\n",
      "Epoch 23/100\n",
      "281/281 [==============================] - 0s 531us/step - loss: 0.7530 - accuracy: 0.7646\n",
      "Epoch 24/100\n",
      "281/281 [==============================] - 0s 547us/step - loss: 0.7350 - accuracy: 0.7660\n",
      "Epoch 25/100\n",
      "281/281 [==============================] - 0s 552us/step - loss: 0.7192 - accuracy: 0.7771\n",
      "Epoch 26/100\n",
      "281/281 [==============================] - 0s 473us/step - loss: 0.7055 - accuracy: 0.7817\n",
      "Epoch 27/100\n",
      "281/281 [==============================] - 0s 493us/step - loss: 0.6924 - accuracy: 0.7788\n",
      "Epoch 28/100\n",
      "281/281 [==============================] - 0s 534us/step - loss: 0.6786 - accuracy: 0.7849\n",
      "Epoch 29/100\n",
      "281/281 [==============================] - 0s 553us/step - loss: 0.6672 - accuracy: 0.7877\n",
      "Epoch 30/100\n",
      "281/281 [==============================] - 0s 481us/step - loss: 0.6547 - accuracy: 0.7899\n",
      "Epoch 31/100\n",
      "281/281 [==============================] - 0s 453us/step - loss: 0.6428 - accuracy: 0.7934\n",
      "Epoch 32/100\n",
      "281/281 [==============================] - 0s 513us/step - loss: 0.6323 - accuracy: 0.7895\n",
      "Epoch 33/100\n",
      "281/281 [==============================] - 0s 455us/step - loss: 0.6200 - accuracy: 0.7949\n",
      "Epoch 34/100\n",
      "281/281 [==============================] - 0s 457us/step - loss: 0.6094 - accuracy: 0.8027\n",
      "Epoch 35/100\n",
      "281/281 [==============================] - 0s 575us/step - loss: 0.6011 - accuracy: 0.8002\n",
      "Epoch 36/100\n",
      "281/281 [==============================] - 0s 524us/step - loss: 0.5912 - accuracy: 0.8066\n",
      "Epoch 37/100\n",
      "281/281 [==============================] - 0s 456us/step - loss: 0.5816 - accuracy: 0.8073\n",
      "Epoch 38/100\n",
      "281/281 [==============================] - 0s 477us/step - loss: 0.5709 - accuracy: 0.8145\n",
      "Epoch 39/100\n",
      "281/281 [==============================] - 0s 477us/step - loss: 0.5622 - accuracy: 0.8198\n",
      "Epoch 40/100\n",
      "281/281 [==============================] - 0s 546us/step - loss: 0.5511 - accuracy: 0.8244\n",
      "Epoch 41/100\n",
      "281/281 [==============================] - 0s 535us/step - loss: 0.5437 - accuracy: 0.8248\n",
      "Epoch 42/100\n",
      "281/281 [==============================] - 0s 507us/step - loss: 0.5343 - accuracy: 0.8283\n",
      "Epoch 43/100\n",
      "281/281 [==============================] - 0s 521us/step - loss: 0.5230 - accuracy: 0.8319\n",
      "Epoch 44/100\n",
      "281/281 [==============================] - 0s 528us/step - loss: 0.5166 - accuracy: 0.8383\n",
      "Epoch 45/100\n",
      "281/281 [==============================] - 0s 533us/step - loss: 0.5083 - accuracy: 0.8408\n",
      "Epoch 46/100\n",
      "281/281 [==============================] - 0s 471us/step - loss: 0.4990 - accuracy: 0.8429\n",
      "Epoch 47/100\n",
      "281/281 [==============================] - 0s 476us/step - loss: 0.4894 - accuracy: 0.8533\n",
      "Epoch 48/100\n",
      "281/281 [==============================] - 0s 456us/step - loss: 0.4803 - accuracy: 0.8486\n",
      "Epoch 49/100\n",
      "281/281 [==============================] - 0s 472us/step - loss: 0.4739 - accuracy: 0.8593\n",
      "Epoch 50/100\n",
      "281/281 [==============================] - 0s 477us/step - loss: 0.4659 - accuracy: 0.8558\n",
      "Epoch 51/100\n",
      "281/281 [==============================] - 0s 479us/step - loss: 0.4590 - accuracy: 0.8590\n",
      "Epoch 52/100\n",
      "281/281 [==============================] - 0s 477us/step - loss: 0.4502 - accuracy: 0.8654\n",
      "Epoch 53/100\n",
      "281/281 [==============================] - 0s 455us/step - loss: 0.4416 - accuracy: 0.8675\n",
      "Epoch 54/100\n",
      "281/281 [==============================] - 0s 474us/step - loss: 0.4347 - accuracy: 0.8661\n",
      "Epoch 55/100\n",
      "281/281 [==============================] - 0s 485us/step - loss: 0.4296 - accuracy: 0.8700\n",
      "Epoch 56/100\n",
      "281/281 [==============================] - 0s 463us/step - loss: 0.4243 - accuracy: 0.8725\n",
      "Epoch 57/100\n",
      "281/281 [==============================] - 0s 457us/step - loss: 0.4145 - accuracy: 0.8757\n",
      "Epoch 58/100\n",
      "281/281 [==============================] - 0s 476us/step - loss: 0.4096 - accuracy: 0.8761\n",
      "Epoch 59/100\n",
      "281/281 [==============================] - 0s 481us/step - loss: 0.4032 - accuracy: 0.8807\n",
      "Epoch 60/100\n",
      "281/281 [==============================] - 0s 476us/step - loss: 0.3991 - accuracy: 0.8803\n",
      "Epoch 61/100\n",
      "281/281 [==============================] - 0s 456us/step - loss: 0.3899 - accuracy: 0.8843\n",
      "Epoch 62/100\n",
      "281/281 [==============================] - 0s 484us/step - loss: 0.3869 - accuracy: 0.8821\n",
      "Epoch 63/100\n",
      "281/281 [==============================] - 0s 489us/step - loss: 0.3793 - accuracy: 0.8843\n",
      "Epoch 64/100\n",
      "281/281 [==============================] - 0s 481us/step - loss: 0.3724 - accuracy: 0.8935\n",
      "Epoch 65/100\n",
      "281/281 [==============================] - 0s 511us/step - loss: 0.3689 - accuracy: 0.8914\n",
      "Epoch 66/100\n",
      "281/281 [==============================] - 0s 470us/step - loss: 0.3627 - accuracy: 0.8942\n",
      "Epoch 67/100\n",
      "281/281 [==============================] - 0s 492us/step - loss: 0.3585 - accuracy: 0.8900\n",
      "Epoch 68/100\n",
      "281/281 [==============================] - 0s 467us/step - loss: 0.3521 - accuracy: 0.8978\n",
      "Epoch 69/100\n",
      "281/281 [==============================] - 0s 456us/step - loss: 0.3505 - accuracy: 0.8935\n",
      "Epoch 70/100\n",
      "281/281 [==============================] - 0s 460us/step - loss: 0.3457 - accuracy: 0.8989\n",
      "Epoch 71/100\n",
      "281/281 [==============================] - 0s 479us/step - loss: 0.3391 - accuracy: 0.9021\n",
      "Epoch 72/100\n",
      "281/281 [==============================] - 0s 481us/step - loss: 0.3349 - accuracy: 0.9003\n",
      "Epoch 73/100\n",
      "281/281 [==============================] - 0s 473us/step - loss: 0.3306 - accuracy: 0.8989\n",
      "Epoch 74/100\n",
      "281/281 [==============================] - 0s 512us/step - loss: 0.3250 - accuracy: 0.9035\n",
      "Epoch 75/100\n",
      "281/281 [==============================] - 0s 502us/step - loss: 0.3210 - accuracy: 0.9063\n",
      "Epoch 76/100\n",
      "281/281 [==============================] - 0s 461us/step - loss: 0.3162 - accuracy: 0.9092\n",
      "Epoch 77/100\n",
      "281/281 [==============================] - 0s 457us/step - loss: 0.3114 - accuracy: 0.9106\n",
      "Epoch 78/100\n",
      "281/281 [==============================] - 0s 459us/step - loss: 0.3085 - accuracy: 0.9110\n",
      "Epoch 79/100\n",
      "281/281 [==============================] - 0s 468us/step - loss: 0.3030 - accuracy: 0.9106\n",
      "Epoch 80/100\n",
      "281/281 [==============================] - 0s 480us/step - loss: 0.3014 - accuracy: 0.9103\n",
      "Epoch 81/100\n",
      "281/281 [==============================] - 0s 473us/step - loss: 0.2971 - accuracy: 0.9106\n",
      "Epoch 82/100\n",
      "281/281 [==============================] - 0s 470us/step - loss: 0.2921 - accuracy: 0.9106\n",
      "Epoch 83/100\n",
      "281/281 [==============================] - 0s 458us/step - loss: 0.2877 - accuracy: 0.9177\n",
      "Epoch 84/100\n",
      "281/281 [==============================] - 0s 476us/step - loss: 0.2836 - accuracy: 0.9167\n",
      "Epoch 85/100\n",
      "281/281 [==============================] - 0s 473us/step - loss: 0.2805 - accuracy: 0.9170\n",
      "Epoch 86/100\n",
      "281/281 [==============================] - 0s 495us/step - loss: 0.2792 - accuracy: 0.9156\n",
      "Epoch 87/100\n",
      "281/281 [==============================] - 0s 463us/step - loss: 0.2736 - accuracy: 0.9167\n",
      "Epoch 88/100\n",
      "281/281 [==============================] - 0s 468us/step - loss: 0.2713 - accuracy: 0.9181\n",
      "Epoch 89/100\n",
      "281/281 [==============================] - 0s 471us/step - loss: 0.2693 - accuracy: 0.9177\n",
      "Epoch 90/100\n",
      "281/281 [==============================] - 0s 469us/step - loss: 0.2660 - accuracy: 0.9174\n",
      "Epoch 91/100\n",
      "281/281 [==============================] - 0s 477us/step - loss: 0.2617 - accuracy: 0.9256\n",
      "Epoch 92/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "281/281 [==============================] - 0s 474us/step - loss: 0.2595 - accuracy: 0.9199\n",
      "Epoch 93/100\n",
      "281/281 [==============================] - 0s 479us/step - loss: 0.2563 - accuracy: 0.9252\n",
      "Epoch 94/100\n",
      "281/281 [==============================] - 0s 484us/step - loss: 0.2533 - accuracy: 0.9241\n",
      "Epoch 95/100\n",
      "281/281 [==============================] - 0s 467us/step - loss: 0.2496 - accuracy: 0.9249\n",
      "Epoch 96/100\n",
      "281/281 [==============================] - 0s 475us/step - loss: 0.2467 - accuracy: 0.9249\n",
      "Epoch 97/100\n",
      "281/281 [==============================] - 0s 472us/step - loss: 0.2457 - accuracy: 0.9231\n",
      "Epoch 98/100\n",
      "281/281 [==============================] - 0s 462us/step - loss: 0.2422 - accuracy: 0.9259\n",
      "Epoch 99/100\n",
      "281/281 [==============================] - 0s 480us/step - loss: 0.2402 - accuracy: 0.9274\n",
      "Epoch 100/100\n",
      "281/281 [==============================] - 0s 472us/step - loss: 0.2362 - accuracy: 0.9284\n",
      "Model: \"Sequential-NN\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_51 (Dense)             (None, 60)                3660      \n",
      "_________________________________________________________________\n",
      "dense_52 (Dense)             (None, 250)               15250     \n",
      "_________________________________________________________________\n",
      "dense_53 (Dense)             (None, 5)                 1255      \n",
      "=================================================================\n",
      "Total params: 20,165\n",
      "Trainable params: 20,165\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "281/281 [==============================] - 0s 482us/step - loss: 1.6037 - accuracy: 0.2632\n",
      "Epoch 2/100\n",
      "281/281 [==============================] - 0s 473us/step - loss: 1.5711 - accuracy: 0.3415\n",
      "Epoch 3/100\n",
      "281/281 [==============================] - 0s 472us/step - loss: 1.5268 - accuracy: 0.3764\n",
      "Epoch 4/100\n",
      "281/281 [==============================] - 0s 472us/step - loss: 1.4658 - accuracy: 0.4384\n",
      "Epoch 5/100\n",
      "281/281 [==============================] - 0s 474us/step - loss: 1.3888 - accuracy: 0.4630\n",
      "Epoch 6/100\n",
      "281/281 [==============================] - 0s 530us/step - loss: 1.3149 - accuracy: 0.4957\n",
      "Epoch 7/100\n",
      "281/281 [==============================] - 0s 527us/step - loss: 1.2449 - accuracy: 0.5288\n",
      "Epoch 8/100\n",
      "281/281 [==============================] - 0s 465us/step - loss: 1.1873 - accuracy: 0.5705\n",
      "Epoch 9/100\n",
      "281/281 [==============================] - 0s 476us/step - loss: 1.1412 - accuracy: 0.5890\n",
      "Epoch 10/100\n",
      "281/281 [==============================] - 0s 463us/step - loss: 1.1011 - accuracy: 0.6154\n",
      "Epoch 11/100\n",
      "281/281 [==============================] - 0s 460us/step - loss: 1.0645 - accuracy: 0.6332\n",
      "Epoch 12/100\n",
      "281/281 [==============================] - 0s 471us/step - loss: 1.0343 - accuracy: 0.6481\n",
      "Epoch 13/100\n",
      "281/281 [==============================] - 0s 482us/step - loss: 1.0024 - accuracy: 0.6617\n",
      "Epoch 14/100\n",
      "281/281 [==============================] - 0s 496us/step - loss: 0.9748 - accuracy: 0.6745\n",
      "Epoch 15/100\n",
      "281/281 [==============================] - 0s 560us/step - loss: 0.9456 - accuracy: 0.6848\n",
      "Epoch 16/100\n",
      "281/281 [==============================] - 0s 558us/step - loss: 0.9158 - accuracy: 0.6952\n",
      "Epoch 17/100\n",
      "281/281 [==============================] - 0s 541us/step - loss: 0.8853 - accuracy: 0.7090\n",
      "Epoch 18/100\n",
      "281/281 [==============================] - 0s 512us/step - loss: 0.8555 - accuracy: 0.7215\n",
      "Epoch 19/100\n",
      "281/281 [==============================] - 0s 507us/step - loss: 0.8306 - accuracy: 0.7343\n",
      "Epoch 20/100\n",
      "281/281 [==============================] - 0s 496us/step - loss: 0.8036 - accuracy: 0.7393\n",
      "Epoch 21/100\n",
      "281/281 [==============================] - 0s 466us/step - loss: 0.7768 - accuracy: 0.7582\n",
      "Epoch 22/100\n",
      "281/281 [==============================] - 0s 462us/step - loss: 0.7508 - accuracy: 0.7632\n",
      "Epoch 23/100\n",
      "281/281 [==============================] - 0s 516us/step - loss: 0.7271 - accuracy: 0.7678\n",
      "Epoch 24/100\n",
      "281/281 [==============================] - 0s 488us/step - loss: 0.7025 - accuracy: 0.7753\n",
      "Epoch 25/100\n",
      "281/281 [==============================] - 0s 459us/step - loss: 0.6813 - accuracy: 0.7874\n",
      "Epoch 26/100\n",
      "281/281 [==============================] - 0s 520us/step - loss: 0.6595 - accuracy: 0.7913\n",
      "Epoch 27/100\n",
      "281/281 [==============================] - 0s 482us/step - loss: 0.6392 - accuracy: 0.7942\n",
      "Epoch 28/100\n",
      "281/281 [==============================] - 0s 464us/step - loss: 0.6189 - accuracy: 0.8045\n",
      "Epoch 29/100\n",
      "281/281 [==============================] - 0s 465us/step - loss: 0.6011 - accuracy: 0.8077\n",
      "Epoch 30/100\n",
      "281/281 [==============================] - 0s 477us/step - loss: 0.5826 - accuracy: 0.8159\n",
      "Epoch 31/100\n",
      "281/281 [==============================] - 0s 476us/step - loss: 0.5639 - accuracy: 0.8180\n",
      "Epoch 32/100\n",
      "281/281 [==============================] - 0s 523us/step - loss: 0.5476 - accuracy: 0.8276\n",
      "Epoch 33/100\n",
      "281/281 [==============================] - 0s 466us/step - loss: 0.5312 - accuracy: 0.8312\n",
      "Epoch 34/100\n",
      "281/281 [==============================] - 0s 462us/step - loss: 0.5171 - accuracy: 0.8308\n",
      "Epoch 35/100\n",
      "281/281 [==============================] - 0s 464us/step - loss: 0.5007 - accuracy: 0.8422\n",
      "Epoch 36/100\n",
      "281/281 [==============================] - 0s 529us/step - loss: 0.4881 - accuracy: 0.8426\n",
      "Epoch 37/100\n",
      "281/281 [==============================] - 0s 499us/step - loss: 0.4743 - accuracy: 0.8511\n",
      "Epoch 38/100\n",
      "281/281 [==============================] - 0s 457us/step - loss: 0.4609 - accuracy: 0.8526\n",
      "Epoch 39/100\n",
      "281/281 [==============================] - 0s 469us/step - loss: 0.4480 - accuracy: 0.8604\n",
      "Epoch 40/100\n",
      "281/281 [==============================] - 0s 541us/step - loss: 0.4368 - accuracy: 0.8625\n",
      "Epoch 41/100\n",
      "281/281 [==============================] - 0s 515us/step - loss: 0.4278 - accuracy: 0.8647\n",
      "Epoch 42/100\n",
      "281/281 [==============================] - 0s 467us/step - loss: 0.4167 - accuracy: 0.8697\n",
      "Epoch 43/100\n",
      "281/281 [==============================] - 0s 463us/step - loss: 0.4037 - accuracy: 0.8750\n",
      "Epoch 44/100\n",
      "281/281 [==============================] - 0s 495us/step - loss: 0.3959 - accuracy: 0.8782\n",
      "Epoch 45/100\n",
      "281/281 [==============================] - 0s 488us/step - loss: 0.3889 - accuracy: 0.8764\n",
      "Epoch 46/100\n",
      "281/281 [==============================] - 0s 469us/step - loss: 0.3759 - accuracy: 0.8839\n",
      "Epoch 47/100\n",
      "281/281 [==============================] - 0s 473us/step - loss: 0.3666 - accuracy: 0.8868\n",
      "Epoch 48/100\n",
      "281/281 [==============================] - 0s 454us/step - loss: 0.3588 - accuracy: 0.8896\n",
      "Epoch 49/100\n",
      "281/281 [==============================] - 0s 473us/step - loss: 0.3505 - accuracy: 0.8882\n",
      "Epoch 50/100\n",
      "281/281 [==============================] - 0s 460us/step - loss: 0.3413 - accuracy: 0.8910\n",
      "Epoch 51/100\n",
      "281/281 [==============================] - 0s 496us/step - loss: 0.3347 - accuracy: 0.8910\n",
      "Epoch 52/100\n",
      "281/281 [==============================] - 0s 462us/step - loss: 0.3273 - accuracy: 0.8921\n",
      "Epoch 53/100\n",
      "281/281 [==============================] - 0s 460us/step - loss: 0.3205 - accuracy: 0.8971\n",
      "Epoch 54/100\n",
      "281/281 [==============================] - 0s 460us/step - loss: 0.3147 - accuracy: 0.9006\n",
      "Epoch 55/100\n",
      "281/281 [==============================] - 0s 506us/step - loss: 0.3077 - accuracy: 0.9014\n",
      "Epoch 56/100\n",
      "281/281 [==============================] - 0s 471us/step - loss: 0.3003 - accuracy: 0.9031\n",
      "Epoch 57/100\n",
      "281/281 [==============================] - 0s 467us/step - loss: 0.2960 - accuracy: 0.9063\n",
      "Epoch 58/100\n",
      "281/281 [==============================] - 0s 455us/step - loss: 0.2886 - accuracy: 0.9106\n",
      "Epoch 59/100\n",
      "281/281 [==============================] - 0s 466us/step - loss: 0.2825 - accuracy: 0.9110\n",
      "Epoch 60/100\n",
      "281/281 [==============================] - 0s 482us/step - loss: 0.2782 - accuracy: 0.9113\n",
      "Epoch 61/100\n",
      "281/281 [==============================] - 0s 479us/step - loss: 0.2714 - accuracy: 0.9149\n",
      "Epoch 62/100\n",
      "281/281 [==============================] - 0s 486us/step - loss: 0.2687 - accuracy: 0.9131\n",
      "Epoch 63/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "281/281 [==============================] - 0s 568us/step - loss: 0.2624 - accuracy: 0.9177\n",
      "Epoch 64/100\n",
      "281/281 [==============================] - 0s 471us/step - loss: 0.2600 - accuracy: 0.9167\n",
      "Epoch 65/100\n",
      "281/281 [==============================] - 0s 460us/step - loss: 0.2543 - accuracy: 0.9192\n",
      "Epoch 66/100\n",
      "281/281 [==============================] - 0s 463us/step - loss: 0.2506 - accuracy: 0.9245\n",
      "Epoch 67/100\n",
      "281/281 [==============================] - 0s 468us/step - loss: 0.2468 - accuracy: 0.9209\n",
      "Epoch 68/100\n",
      "281/281 [==============================] - 0s 484us/step - loss: 0.2417 - accuracy: 0.9238\n",
      "Epoch 69/100\n",
      "281/281 [==============================] - 0s 466us/step - loss: 0.2386 - accuracy: 0.9249\n",
      "Epoch 70/100\n",
      "281/281 [==============================] - 0s 468us/step - loss: 0.2353 - accuracy: 0.9270\n",
      "Epoch 71/100\n",
      "281/281 [==============================] - 0s 485us/step - loss: 0.2300 - accuracy: 0.9277\n",
      "Epoch 72/100\n",
      "281/281 [==============================] - 0s 462us/step - loss: 0.2269 - accuracy: 0.9306\n",
      "Epoch 73/100\n",
      "281/281 [==============================] - 0s 495us/step - loss: 0.2221 - accuracy: 0.9327\n",
      "Epoch 74/100\n",
      "281/281 [==============================] - 0s 529us/step - loss: 0.2208 - accuracy: 0.9281\n",
      "Epoch 75/100\n",
      "281/281 [==============================] - 0s 550us/step - loss: 0.2189 - accuracy: 0.9306\n",
      "Epoch 76/100\n",
      "281/281 [==============================] - 0s 555us/step - loss: 0.2142 - accuracy: 0.9320\n",
      "Epoch 77/100\n",
      "281/281 [==============================] - 0s 466us/step - loss: 0.2112 - accuracy: 0.9338\n",
      "Epoch 78/100\n",
      "281/281 [==============================] - 0s 507us/step - loss: 0.2071 - accuracy: 0.9355\n",
      "Epoch 79/100\n",
      "281/281 [==============================] - 0s 553us/step - loss: 0.2044 - accuracy: 0.9373\n",
      "Epoch 80/100\n",
      "281/281 [==============================] - 0s 506us/step - loss: 0.2024 - accuracy: 0.9387\n",
      "Epoch 81/100\n",
      "281/281 [==============================] - 0s 492us/step - loss: 0.1979 - accuracy: 0.9409\n",
      "Epoch 82/100\n",
      "281/281 [==============================] - 0s 505us/step - loss: 0.1966 - accuracy: 0.9416\n",
      "Epoch 83/100\n",
      "281/281 [==============================] - 0s 508us/step - loss: 0.1925 - accuracy: 0.9423\n",
      "Epoch 84/100\n",
      "281/281 [==============================] - 0s 497us/step - loss: 0.1912 - accuracy: 0.9430\n",
      "Epoch 85/100\n",
      "281/281 [==============================] - 0s 506us/step - loss: 0.1881 - accuracy: 0.9412\n",
      "Epoch 86/100\n",
      "281/281 [==============================] - 0s 491us/step - loss: 0.1853 - accuracy: 0.9405\n",
      "Epoch 87/100\n",
      "281/281 [==============================] - 0s 497us/step - loss: 0.1823 - accuracy: 0.9448\n",
      "Epoch 88/100\n",
      "281/281 [==============================] - 0s 481us/step - loss: 0.1797 - accuracy: 0.9494\n",
      "Epoch 89/100\n",
      "281/281 [==============================] - 0s 490us/step - loss: 0.1783 - accuracy: 0.9441\n",
      "Epoch 90/100\n",
      "281/281 [==============================] - 0s 500us/step - loss: 0.1757 - accuracy: 0.9437\n",
      "Epoch 91/100\n",
      "281/281 [==============================] - 0s 590us/step - loss: 0.1749 - accuracy: 0.9473\n",
      "Epoch 92/100\n",
      "281/281 [==============================] - 0s 493us/step - loss: 0.1728 - accuracy: 0.9462\n",
      "Epoch 93/100\n",
      "281/281 [==============================] - 0s 504us/step - loss: 0.1713 - accuracy: 0.9455\n",
      "Epoch 94/100\n",
      "281/281 [==============================] - 0s 497us/step - loss: 0.1682 - accuracy: 0.9501\n",
      "Epoch 95/100\n",
      "281/281 [==============================] - 0s 475us/step - loss: 0.1654 - accuracy: 0.9473\n",
      "Epoch 96/100\n",
      "281/281 [==============================] - 0s 520us/step - loss: 0.1651 - accuracy: 0.9494\n",
      "Epoch 97/100\n",
      "281/281 [==============================] - 0s 520us/step - loss: 0.1622 - accuracy: 0.9480\n",
      "Epoch 98/100\n",
      "281/281 [==============================] - 0s 508us/step - loss: 0.1587 - accuracy: 0.9526\n",
      "Epoch 99/100\n",
      "281/281 [==============================] - 0s 505us/step - loss: 0.1576 - accuracy: 0.9533\n",
      "Epoch 100/100\n",
      "281/281 [==============================] - 0s 518us/step - loss: 0.1553 - accuracy: 0.9537\n",
      "Model: \"Sequential-NN\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_54 (Dense)             (None, 60)                3660      \n",
      "_________________________________________________________________\n",
      "dense_55 (Dense)             (None, 250)               15250     \n",
      "_________________________________________________________________\n",
      "dense_56 (Dense)             (None, 5)                 1255      \n",
      "=================================================================\n",
      "Total params: 20,165\n",
      "Trainable params: 20,165\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "281/281 [==============================] - 0s 477us/step - loss: 1.6035 - accuracy: 0.2375\n",
      "Epoch 2/100\n",
      "281/281 [==============================] - 0s 467us/step - loss: 1.5753 - accuracy: 0.3412\n",
      "Epoch 3/100\n",
      "281/281 [==============================] - 0s 483us/step - loss: 1.5364 - accuracy: 0.3704\n",
      "Epoch 4/100\n",
      "281/281 [==============================] - 0s 499us/step - loss: 1.4811 - accuracy: 0.4063\n",
      "Epoch 5/100\n",
      "281/281 [==============================] - 0s 474us/step - loss: 1.4080 - accuracy: 0.4291\n",
      "Epoch 6/100\n",
      "281/281 [==============================] - 0s 488us/step - loss: 1.3283 - accuracy: 0.4647\n",
      "Epoch 7/100\n",
      "281/281 [==============================] - 0s 461us/step - loss: 1.2600 - accuracy: 0.4918\n",
      "Epoch 8/100\n",
      "281/281 [==============================] - 0s 471us/step - loss: 1.2064 - accuracy: 0.5164\n",
      "Epoch 9/100\n",
      "281/281 [==============================] - 0s 474us/step - loss: 1.1618 - accuracy: 0.5434\n",
      "Epoch 10/100\n",
      "281/281 [==============================] - 0s 483us/step - loss: 1.1264 - accuracy: 0.5641\n",
      "Epoch 11/100\n",
      "281/281 [==============================] - 0s 489us/step - loss: 1.0907 - accuracy: 0.5776\n",
      "Epoch 12/100\n",
      "281/281 [==============================] - 0s 456us/step - loss: 1.0634 - accuracy: 0.5894\n",
      "Epoch 13/100\n",
      "281/281 [==============================] - 0s 460us/step - loss: 1.0362 - accuracy: 0.6068\n",
      "Epoch 14/100\n",
      "281/281 [==============================] - 0s 482us/step - loss: 1.0131 - accuracy: 0.6143\n",
      "Epoch 15/100\n",
      "281/281 [==============================] - 0s 468us/step - loss: 0.9885 - accuracy: 0.6254\n",
      "Epoch 16/100\n",
      "281/281 [==============================] - 0s 472us/step - loss: 0.9668 - accuracy: 0.6229\n",
      "Epoch 17/100\n",
      "281/281 [==============================] - 0s 473us/step - loss: 0.9473 - accuracy: 0.6474\n",
      "Epoch 18/100\n",
      "281/281 [==============================] - 0s 460us/step - loss: 0.9270 - accuracy: 0.6645\n",
      "Epoch 19/100\n",
      "281/281 [==============================] - 0s 470us/step - loss: 0.9047 - accuracy: 0.6642\n",
      "Epoch 20/100\n",
      "281/281 [==============================] - 0s 469us/step - loss: 0.8848 - accuracy: 0.6930\n",
      "Epoch 21/100\n",
      "281/281 [==============================] - 0s 460us/step - loss: 0.8648 - accuracy: 0.6827\n",
      "Epoch 22/100\n",
      "281/281 [==============================] - 0s 481us/step - loss: 0.8469 - accuracy: 0.7172\n",
      "Epoch 23/100\n",
      "281/281 [==============================] - 0s 483us/step - loss: 0.8267 - accuracy: 0.7151\n",
      "Epoch 24/100\n",
      "281/281 [==============================] - 0s 455us/step - loss: 0.8093 - accuracy: 0.7236\n",
      "Epoch 25/100\n",
      "281/281 [==============================] - 0s 514us/step - loss: 0.7912 - accuracy: 0.7333\n",
      "Epoch 26/100\n",
      "281/281 [==============================] - 0s 505us/step - loss: 0.7734 - accuracy: 0.7372\n",
      "Epoch 27/100\n",
      "281/281 [==============================] - 0s 458us/step - loss: 0.7574 - accuracy: 0.7518\n",
      "Epoch 28/100\n",
      "281/281 [==============================] - 0s 462us/step - loss: 0.7429 - accuracy: 0.7543\n",
      "Epoch 29/100\n",
      "281/281 [==============================] - 0s 490us/step - loss: 0.7255 - accuracy: 0.7621\n",
      "Epoch 30/100\n",
      "281/281 [==============================] - 0s 494us/step - loss: 0.7100 - accuracy: 0.7696\n",
      "Epoch 31/100\n",
      "281/281 [==============================] - 0s 466us/step - loss: 0.6951 - accuracy: 0.7753\n",
      "Epoch 32/100\n",
      "281/281 [==============================] - 0s 473us/step - loss: 0.6804 - accuracy: 0.7756\n",
      "Epoch 33/100\n",
      "281/281 [==============================] - 0s 487us/step - loss: 0.6643 - accuracy: 0.7842\n",
      "Epoch 34/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "281/281 [==============================] - 0s 515us/step - loss: 0.6529 - accuracy: 0.7877\n",
      "Epoch 35/100\n",
      "281/281 [==============================] - 0s 474us/step - loss: 0.6386 - accuracy: 0.7959\n",
      "Epoch 36/100\n",
      "281/281 [==============================] - 0s 481us/step - loss: 0.6239 - accuracy: 0.8020\n",
      "Epoch 37/100\n",
      "281/281 [==============================] - 0s 474us/step - loss: 0.6115 - accuracy: 0.8070\n",
      "Epoch 38/100\n",
      "281/281 [==============================] - 0s 491us/step - loss: 0.5990 - accuracy: 0.8116\n",
      "Epoch 39/100\n",
      "281/281 [==============================] - 0s 471us/step - loss: 0.5883 - accuracy: 0.8180\n",
      "Epoch 40/100\n",
      "281/281 [==============================] - 0s 464us/step - loss: 0.5771 - accuracy: 0.8162\n",
      "Epoch 41/100\n",
      "281/281 [==============================] - 0s 459us/step - loss: 0.5641 - accuracy: 0.8248\n",
      "Epoch 42/100\n",
      "281/281 [==============================] - 0s 460us/step - loss: 0.5530 - accuracy: 0.8291\n",
      "Epoch 43/100\n",
      "281/281 [==============================] - 0s 495us/step - loss: 0.5410 - accuracy: 0.8298\n",
      "Epoch 44/100\n",
      "281/281 [==============================] - 0s 480us/step - loss: 0.5296 - accuracy: 0.8348\n",
      "Epoch 45/100\n",
      "281/281 [==============================] - 0s 464us/step - loss: 0.5195 - accuracy: 0.8348\n",
      "Epoch 46/100\n",
      "281/281 [==============================] - 0s 463us/step - loss: 0.5091 - accuracy: 0.8426\n",
      "Epoch 47/100\n",
      "281/281 [==============================] - 0s 465us/step - loss: 0.4990 - accuracy: 0.8447\n",
      "Epoch 48/100\n",
      "281/281 [==============================] - 0s 479us/step - loss: 0.4877 - accuracy: 0.8504\n",
      "Epoch 49/100\n",
      "281/281 [==============================] - 0s 567us/step - loss: 0.4796 - accuracy: 0.8522\n",
      "Epoch 50/100\n",
      "281/281 [==============================] - 0s 508us/step - loss: 0.4709 - accuracy: 0.8558\n",
      "Epoch 51/100\n",
      "281/281 [==============================] - 0s 558us/step - loss: 0.4597 - accuracy: 0.8593\n",
      "Epoch 52/100\n",
      "281/281 [==============================] - 0s 573us/step - loss: 0.4533 - accuracy: 0.8604\n",
      "Epoch 53/100\n",
      "281/281 [==============================] - 0s 496us/step - loss: 0.4426 - accuracy: 0.8600\n",
      "Epoch 54/100\n",
      "281/281 [==============================] - 0s 511us/step - loss: 0.4352 - accuracy: 0.8668\n",
      "Epoch 55/100\n",
      "281/281 [==============================] - 0s 595us/step - loss: 0.4291 - accuracy: 0.8704\n",
      "Epoch 56/100\n",
      "281/281 [==============================] - 0s 556us/step - loss: 0.4243 - accuracy: 0.8597\n",
      "Epoch 57/100\n",
      "281/281 [==============================] - 0s 524us/step - loss: 0.4137 - accuracy: 0.8750\n",
      "Epoch 58/100\n",
      "281/281 [==============================] - 0s 503us/step - loss: 0.4069 - accuracy: 0.8711\n",
      "Epoch 59/100\n",
      "281/281 [==============================] - 0s 511us/step - loss: 0.4010 - accuracy: 0.8768\n",
      "Epoch 60/100\n",
      "281/281 [==============================] - 0s 517us/step - loss: 0.3954 - accuracy: 0.8768\n",
      "Epoch 61/100\n",
      "281/281 [==============================] - 0s 515us/step - loss: 0.3901 - accuracy: 0.8750\n",
      "Epoch 62/100\n",
      "281/281 [==============================] - 0s 512us/step - loss: 0.3857 - accuracy: 0.8775\n",
      "Epoch 63/100\n",
      "281/281 [==============================] - 0s 513us/step - loss: 0.3778 - accuracy: 0.8800\n",
      "Epoch 64/100\n",
      "281/281 [==============================] - 0s 594us/step - loss: 0.3734 - accuracy: 0.8839\n",
      "Epoch 65/100\n",
      "281/281 [==============================] - 0s 563us/step - loss: 0.3692 - accuracy: 0.8871\n",
      "Epoch 66/100\n",
      "281/281 [==============================] - 0s 505us/step - loss: 0.3615 - accuracy: 0.8846\n",
      "Epoch 67/100\n",
      "281/281 [==============================] - 0s 517us/step - loss: 0.3562 - accuracy: 0.8900\n",
      "Epoch 68/100\n",
      "281/281 [==============================] - 0s 529us/step - loss: 0.3528 - accuracy: 0.8875\n",
      "Epoch 69/100\n",
      "281/281 [==============================] - 0s 556us/step - loss: 0.3498 - accuracy: 0.8850\n",
      "Epoch 70/100\n",
      "281/281 [==============================] - 0s 493us/step - loss: 0.3446 - accuracy: 0.8885\n",
      "Epoch 71/100\n",
      "281/281 [==============================] - 0s 472us/step - loss: 0.3395 - accuracy: 0.8928\n",
      "Epoch 72/100\n",
      "281/281 [==============================] - 0s 498us/step - loss: 0.3347 - accuracy: 0.8921\n",
      "Epoch 73/100\n",
      "281/281 [==============================] - 0s 474us/step - loss: 0.3288 - accuracy: 0.8992\n",
      "Epoch 74/100\n",
      "281/281 [==============================] - 0s 479us/step - loss: 0.3285 - accuracy: 0.8942\n",
      "Epoch 75/100\n",
      "281/281 [==============================] - 0s 477us/step - loss: 0.3238 - accuracy: 0.8992\n",
      "Epoch 76/100\n",
      "281/281 [==============================] - 0s 526us/step - loss: 0.3233 - accuracy: 0.8939\n",
      "Epoch 77/100\n",
      "281/281 [==============================] - 0s 527us/step - loss: 0.3144 - accuracy: 0.9028\n",
      "Epoch 78/100\n",
      "281/281 [==============================] - 0s 461us/step - loss: 0.3133 - accuracy: 0.9003\n",
      "Epoch 79/100\n",
      "281/281 [==============================] - 0s 494us/step - loss: 0.3081 - accuracy: 0.9017\n",
      "Epoch 80/100\n",
      "281/281 [==============================] - 0s 456us/step - loss: 0.3071 - accuracy: 0.9021\n",
      "Epoch 81/100\n",
      "281/281 [==============================] - 0s 463us/step - loss: 0.3027 - accuracy: 0.9074\n",
      "Epoch 82/100\n",
      "281/281 [==============================] - 0s 517us/step - loss: 0.3007 - accuracy: 0.9063\n",
      "Epoch 83/100\n",
      "281/281 [==============================] - 0s 461us/step - loss: 0.2950 - accuracy: 0.9056\n",
      "Epoch 84/100\n",
      "281/281 [==============================] - 0s 461us/step - loss: 0.2931 - accuracy: 0.9071\n",
      "Epoch 85/100\n",
      "281/281 [==============================] - 0s 464us/step - loss: 0.2903 - accuracy: 0.9060\n",
      "Epoch 86/100\n",
      "281/281 [==============================] - 0s 468us/step - loss: 0.2873 - accuracy: 0.9081\n",
      "Epoch 87/100\n",
      "281/281 [==============================] - 0s 456us/step - loss: 0.2845 - accuracy: 0.9124\n",
      "Epoch 88/100\n",
      "281/281 [==============================] - 0s 456us/step - loss: 0.2825 - accuracy: 0.9078\n",
      "Epoch 89/100\n",
      "281/281 [==============================] - 0s 455us/step - loss: 0.2785 - accuracy: 0.9103\n",
      "Epoch 90/100\n",
      "281/281 [==============================] - 0s 455us/step - loss: 0.2742 - accuracy: 0.9192\n",
      "Epoch 91/100\n",
      "281/281 [==============================] - 0s 458us/step - loss: 0.2716 - accuracy: 0.9106\n",
      "Epoch 92/100\n",
      "281/281 [==============================] - 0s 472us/step - loss: 0.2694 - accuracy: 0.9224\n",
      "Epoch 93/100\n",
      "281/281 [==============================] - 0s 471us/step - loss: 0.2663 - accuracy: 0.9142\n",
      "Epoch 94/100\n",
      "281/281 [==============================] - 0s 467us/step - loss: 0.2651 - accuracy: 0.9149\n",
      "Epoch 95/100\n",
      "281/281 [==============================] - 0s 475us/step - loss: 0.2622 - accuracy: 0.9177\n",
      "Epoch 96/100\n",
      "281/281 [==============================] - 0s 482us/step - loss: 0.2596 - accuracy: 0.9192\n",
      "Epoch 97/100\n",
      "281/281 [==============================] - 0s 495us/step - loss: 0.2590 - accuracy: 0.9181\n",
      "Epoch 98/100\n",
      "281/281 [==============================] - 0s 481us/step - loss: 0.2524 - accuracy: 0.9224\n",
      "Epoch 99/100\n",
      "281/281 [==============================] - 0s 458us/step - loss: 0.2558 - accuracy: 0.9177\n",
      "Epoch 100/100\n",
      "281/281 [==============================] - 0s 482us/step - loss: 0.2490 - accuracy: 0.9206\n",
      "Model: \"Sequential-NN\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_57 (Dense)             (None, 60)                3660      \n",
      "_________________________________________________________________\n",
      "dense_58 (Dense)             (None, 250)               15250     \n",
      "_________________________________________________________________\n",
      "dense_59 (Dense)             (None, 5)                 1255      \n",
      "=================================================================\n",
      "Total params: 20,165\n",
      "Trainable params: 20,165\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "281/281 [==============================] - 0s 541us/step - loss: 1.6057 - accuracy: 0.2340\n",
      "Epoch 2/100\n",
      "281/281 [==============================] - 0s 515us/step - loss: 1.5816 - accuracy: 0.3134\n",
      "Epoch 3/100\n",
      "281/281 [==============================] - 0s 551us/step - loss: 1.5482 - accuracy: 0.3586\n",
      "Epoch 4/100\n",
      "281/281 [==============================] - 0s 492us/step - loss: 1.4991 - accuracy: 0.4060\n",
      "Epoch 5/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "281/281 [==============================] - 0s 475us/step - loss: 1.4308 - accuracy: 0.4491\n",
      "Epoch 6/100\n",
      "281/281 [==============================] - 0s 494us/step - loss: 1.3529 - accuracy: 0.4950\n",
      "Epoch 7/100\n",
      "281/281 [==============================] - 0s 487us/step - loss: 1.2779 - accuracy: 0.5281\n",
      "Epoch 8/100\n",
      "281/281 [==============================] - 0s 500us/step - loss: 1.2135 - accuracy: 0.5467\n",
      "Epoch 9/100\n",
      "281/281 [==============================] - 0s 525us/step - loss: 1.1613 - accuracy: 0.5698\n",
      "Epoch 10/100\n",
      "281/281 [==============================] - 0s 505us/step - loss: 1.1179 - accuracy: 0.5801\n",
      "Epoch 11/100\n",
      "281/281 [==============================] - 0s 494us/step - loss: 1.0819 - accuracy: 0.5976\n",
      "Epoch 12/100\n",
      "281/281 [==============================] - 0s 516us/step - loss: 1.0485 - accuracy: 0.6022\n",
      "Epoch 13/100\n",
      "281/281 [==============================] - 0s 468us/step - loss: 1.0191 - accuracy: 0.6129\n",
      "Epoch 14/100\n",
      "281/281 [==============================] - 0s 466us/step - loss: 0.9923 - accuracy: 0.6222\n",
      "Epoch 15/100\n",
      "281/281 [==============================] - 0s 470us/step - loss: 0.9654 - accuracy: 0.6296\n",
      "Epoch 16/100\n",
      "281/281 [==============================] - 0s 470us/step - loss: 0.9381 - accuracy: 0.6524\n",
      "Epoch 17/100\n",
      "281/281 [==============================] - 0s 462us/step - loss: 0.9134 - accuracy: 0.6695\n",
      "Epoch 18/100\n",
      "281/281 [==============================] - 0s 466us/step - loss: 0.8908 - accuracy: 0.6667\n",
      "Epoch 19/100\n",
      "281/281 [==============================] - 0s 466us/step - loss: 0.8663 - accuracy: 0.6991\n",
      "Epoch 20/100\n",
      "281/281 [==============================] - 0s 474us/step - loss: 0.8420 - accuracy: 0.6994\n",
      "Epoch 21/100\n",
      "281/281 [==============================] - 0s 460us/step - loss: 0.8216 - accuracy: 0.7155\n",
      "Epoch 22/100\n",
      "281/281 [==============================] - 0s 468us/step - loss: 0.7993 - accuracy: 0.7315\n",
      "Epoch 23/100\n",
      "281/281 [==============================] - 0s 464us/step - loss: 0.7802 - accuracy: 0.7358\n",
      "Epoch 24/100\n",
      "281/281 [==============================] - 0s 478us/step - loss: 0.7581 - accuracy: 0.7461\n",
      "Epoch 25/100\n",
      "281/281 [==============================] - 0s 506us/step - loss: 0.7391 - accuracy: 0.7610\n",
      "Epoch 26/100\n",
      "281/281 [==============================] - 0s 463us/step - loss: 0.7174 - accuracy: 0.7678\n",
      "Epoch 27/100\n",
      "281/281 [==============================] - 0s 575us/step - loss: 0.7007 - accuracy: 0.7703\n",
      "Epoch 28/100\n",
      "281/281 [==============================] - 0s 667us/step - loss: 0.6829 - accuracy: 0.7817\n",
      "Epoch 29/100\n",
      "281/281 [==============================] - 0s 556us/step - loss: 0.6641 - accuracy: 0.7856\n",
      "Epoch 30/100\n",
      "281/281 [==============================] - 0s 550us/step - loss: 0.6477 - accuracy: 0.7952\n",
      "Epoch 31/100\n",
      "281/281 [==============================] - 0s 511us/step - loss: 0.6298 - accuracy: 0.7991\n",
      "Epoch 32/100\n",
      "281/281 [==============================] - 0s 478us/step - loss: 0.6137 - accuracy: 0.8070\n",
      "Epoch 33/100\n",
      "281/281 [==============================] - 0s 483us/step - loss: 0.5976 - accuracy: 0.8155\n",
      "Epoch 34/100\n",
      "281/281 [==============================] - 0s 524us/step - loss: 0.5834 - accuracy: 0.8148\n",
      "Epoch 35/100\n",
      "281/281 [==============================] - 0s 525us/step - loss: 0.5680 - accuracy: 0.8209\n",
      "Epoch 36/100\n",
      "281/281 [==============================] - 0s 500us/step - loss: 0.5551 - accuracy: 0.8291\n",
      "Epoch 37/100\n",
      "281/281 [==============================] - 0s 536us/step - loss: 0.5402 - accuracy: 0.8301\n",
      "Epoch 38/100\n",
      "281/281 [==============================] - 0s 498us/step - loss: 0.5270 - accuracy: 0.8351\n",
      "Epoch 39/100\n",
      "281/281 [==============================] - 0s 459us/step - loss: 0.5159 - accuracy: 0.8383\n",
      "Epoch 40/100\n",
      "281/281 [==============================] - 0s 477us/step - loss: 0.5027 - accuracy: 0.8476\n",
      "Epoch 41/100\n",
      "281/281 [==============================] - 0s 498us/step - loss: 0.4907 - accuracy: 0.8483\n",
      "Epoch 42/100\n",
      "281/281 [==============================] - 0s 461us/step - loss: 0.4798 - accuracy: 0.8490\n",
      "Epoch 43/100\n",
      "281/281 [==============================] - 0s 459us/step - loss: 0.4679 - accuracy: 0.8561\n",
      "Epoch 44/100\n",
      "281/281 [==============================] - 0s 465us/step - loss: 0.4559 - accuracy: 0.8554\n",
      "Epoch 45/100\n",
      "281/281 [==============================] - 0s 459us/step - loss: 0.4454 - accuracy: 0.8657\n",
      "Epoch 46/100\n",
      "281/281 [==============================] - 0s 477us/step - loss: 0.4358 - accuracy: 0.8693\n",
      "Epoch 47/100\n",
      "281/281 [==============================] - 0s 491us/step - loss: 0.4229 - accuracy: 0.8689\n",
      "Epoch 48/100\n",
      "281/281 [==============================] - 0s 520us/step - loss: 0.4158 - accuracy: 0.8711\n",
      "Epoch 49/100\n",
      "281/281 [==============================] - 0s 485us/step - loss: 0.4076 - accuracy: 0.8711\n",
      "Epoch 50/100\n",
      "281/281 [==============================] - 0s 500us/step - loss: 0.3959 - accuracy: 0.8761\n",
      "Epoch 51/100\n",
      "281/281 [==============================] - 0s 473us/step - loss: 0.3883 - accuracy: 0.8832\n",
      "Epoch 52/100\n",
      "281/281 [==============================] - 0s 586us/step - loss: 0.3783 - accuracy: 0.8821\n",
      "Epoch 53/100\n",
      "281/281 [==============================] - 0s 510us/step - loss: 0.3712 - accuracy: 0.8832\n",
      "Epoch 54/100\n",
      "281/281 [==============================] - 0s 493us/step - loss: 0.3618 - accuracy: 0.8871\n",
      "Epoch 55/100\n",
      "281/281 [==============================] - 0s 501us/step - loss: 0.3564 - accuracy: 0.8803\n",
      "Epoch 56/100\n",
      "281/281 [==============================] - 0s 474us/step - loss: 0.3485 - accuracy: 0.8868\n",
      "Epoch 57/100\n",
      "281/281 [==============================] - 0s 497us/step - loss: 0.3414 - accuracy: 0.8892\n",
      "Epoch 58/100\n",
      "281/281 [==============================] - 0s 456us/step - loss: 0.3357 - accuracy: 0.8910\n",
      "Epoch 59/100\n",
      "281/281 [==============================] - 0s 468us/step - loss: 0.3276 - accuracy: 0.8960\n",
      "Epoch 60/100\n",
      "281/281 [==============================] - 0s 475us/step - loss: 0.3209 - accuracy: 0.8942\n",
      "Epoch 61/100\n",
      "281/281 [==============================] - 0s 515us/step - loss: 0.3133 - accuracy: 0.8964\n",
      "Epoch 62/100\n",
      "281/281 [==============================] - 0s 487us/step - loss: 0.3091 - accuracy: 0.8971\n",
      "Epoch 63/100\n",
      "281/281 [==============================] - 0s 515us/step - loss: 0.3046 - accuracy: 0.8978\n",
      "Epoch 64/100\n",
      "281/281 [==============================] - 0s 490us/step - loss: 0.2978 - accuracy: 0.8992\n",
      "Epoch 65/100\n",
      "281/281 [==============================] - 0s 464us/step - loss: 0.2918 - accuracy: 0.9046\n",
      "Epoch 66/100\n",
      "281/281 [==============================] - 0s 508us/step - loss: 0.2878 - accuracy: 0.9046\n",
      "Epoch 67/100\n",
      "281/281 [==============================] - 0s 481us/step - loss: 0.2816 - accuracy: 0.9010\n",
      "Epoch 68/100\n",
      "281/281 [==============================] - 0s 476us/step - loss: 0.2762 - accuracy: 0.9028\n",
      "Epoch 69/100\n",
      "281/281 [==============================] - 0s 521us/step - loss: 0.2728 - accuracy: 0.9088\n",
      "Epoch 70/100\n",
      "281/281 [==============================] - 0s 508us/step - loss: 0.2685 - accuracy: 0.9053\n",
      "Epoch 71/100\n",
      "281/281 [==============================] - 0s 526us/step - loss: 0.2619 - accuracy: 0.9103\n",
      "Epoch 72/100\n",
      "281/281 [==============================] - 0s 497us/step - loss: 0.2603 - accuracy: 0.9103\n",
      "Epoch 73/100\n",
      "281/281 [==============================] - 0s 514us/step - loss: 0.2551 - accuracy: 0.9110\n",
      "Epoch 74/100\n",
      "281/281 [==============================] - 0s 489us/step - loss: 0.2506 - accuracy: 0.9127\n",
      "Epoch 75/100\n",
      "281/281 [==============================] - 0s 464us/step - loss: 0.2462 - accuracy: 0.9188\n",
      "Epoch 76/100\n",
      "281/281 [==============================] - 0s 477us/step - loss: 0.2427 - accuracy: 0.9192\n",
      "Epoch 77/100\n",
      "281/281 [==============================] - 0s 469us/step - loss: 0.2400 - accuracy: 0.9202\n",
      "Epoch 78/100\n",
      "281/281 [==============================] - 0s 470us/step - loss: 0.2331 - accuracy: 0.9188\n",
      "Epoch 79/100\n",
      "281/281 [==============================] - 0s 458us/step - loss: 0.2284 - accuracy: 0.9227\n",
      "Epoch 80/100\n",
      "281/281 [==============================] - 0s 469us/step - loss: 0.2263 - accuracy: 0.9281\n",
      "Epoch 81/100\n",
      "281/281 [==============================] - 0s 468us/step - loss: 0.2234 - accuracy: 0.9195\n",
      "Epoch 82/100\n",
      "281/281 [==============================] - 0s 482us/step - loss: 0.2216 - accuracy: 0.9217\n",
      "Epoch 83/100\n",
      "281/281 [==============================] - 0s 496us/step - loss: 0.2164 - accuracy: 0.9270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 84/100\n",
      "281/281 [==============================] - 0s 484us/step - loss: 0.2135 - accuracy: 0.9241\n",
      "Epoch 85/100\n",
      "281/281 [==============================] - 0s 483us/step - loss: 0.2104 - accuracy: 0.9298\n",
      "Epoch 86/100\n",
      "281/281 [==============================] - 0s 458us/step - loss: 0.2078 - accuracy: 0.9266\n",
      "Epoch 87/100\n",
      "281/281 [==============================] - 0s 485us/step - loss: 0.2029 - accuracy: 0.9323\n",
      "Epoch 88/100\n",
      "281/281 [==============================] - 0s 472us/step - loss: 0.2005 - accuracy: 0.9327\n",
      "Epoch 89/100\n",
      "281/281 [==============================] - 0s 462us/step - loss: 0.1970 - accuracy: 0.9380\n",
      "Epoch 90/100\n",
      "281/281 [==============================] - 0s 471us/step - loss: 0.1960 - accuracy: 0.9366\n",
      "Epoch 91/100\n",
      "281/281 [==============================] - 0s 474us/step - loss: 0.1923 - accuracy: 0.9323\n",
      "Epoch 92/100\n",
      "281/281 [==============================] - 0s 480us/step - loss: 0.1899 - accuracy: 0.9363\n",
      "Epoch 93/100\n",
      "281/281 [==============================] - 0s 492us/step - loss: 0.1869 - accuracy: 0.9341\n",
      "Epoch 94/100\n",
      "281/281 [==============================] - 0s 460us/step - loss: 0.1828 - accuracy: 0.9387\n",
      "Epoch 95/100\n",
      "281/281 [==============================] - 0s 488us/step - loss: 0.1806 - accuracy: 0.9409\n",
      "Epoch 96/100\n",
      "281/281 [==============================] - 0s 478us/step - loss: 0.1766 - accuracy: 0.9444\n",
      "Epoch 97/100\n",
      "281/281 [==============================] - 0s 470us/step - loss: 0.1745 - accuracy: 0.9412\n",
      "Epoch 98/100\n",
      "281/281 [==============================] - 0s 478us/step - loss: 0.1731 - accuracy: 0.9398\n",
      "Epoch 99/100\n",
      "281/281 [==============================] - 0s 489us/step - loss: 0.1689 - accuracy: 0.9444\n",
      "Epoch 100/100\n",
      "281/281 [==============================] - 0s 480us/step - loss: 0.1686 - accuracy: 0.9469\n",
      "Model: \"Sequential-NN\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_60 (Dense)             (None, 60)                3660      \n",
      "_________________________________________________________________\n",
      "dense_61 (Dense)             (None, 250)               15250     \n",
      "_________________________________________________________________\n",
      "dense_62 (Dense)             (None, 5)                 1255      \n",
      "=================================================================\n",
      "Total params: 20,165\n",
      "Trainable params: 20,165\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "281/281 [==============================] - 0s 474us/step - loss: 1.6059 - accuracy: 0.2365\n",
      "Epoch 2/100\n",
      "281/281 [==============================] - 0s 481us/step - loss: 1.5745 - accuracy: 0.3376\n",
      "Epoch 3/100\n",
      "281/281 [==============================] - 0s 476us/step - loss: 1.5345 - accuracy: 0.3860\n",
      "Epoch 4/100\n",
      "281/281 [==============================] - 0s 469us/step - loss: 1.4723 - accuracy: 0.4252\n",
      "Epoch 5/100\n",
      "281/281 [==============================] - 0s 472us/step - loss: 1.3993 - accuracy: 0.4576\n",
      "Epoch 6/100\n",
      "281/281 [==============================] - 0s 466us/step - loss: 1.3226 - accuracy: 0.4719\n",
      "Epoch 7/100\n",
      "281/281 [==============================] - 0s 457us/step - loss: 1.2576 - accuracy: 0.5082\n",
      "Epoch 8/100\n",
      "281/281 [==============================] - 0s 459us/step - loss: 1.2054 - accuracy: 0.5331\n",
      "Epoch 9/100\n",
      "281/281 [==============================] - 0s 481us/step - loss: 1.1636 - accuracy: 0.5509\n",
      "Epoch 10/100\n",
      "281/281 [==============================] - 0s 473us/step - loss: 1.1293 - accuracy: 0.5819\n",
      "Epoch 11/100\n",
      "281/281 [==============================] - 0s 472us/step - loss: 1.0999 - accuracy: 0.5833\n",
      "Epoch 12/100\n",
      "281/281 [==============================] - 0s 484us/step - loss: 1.0730 - accuracy: 0.6097\n",
      "Epoch 13/100\n",
      "281/281 [==============================] - 0s 456us/step - loss: 1.0488 - accuracy: 0.6001\n",
      "Epoch 14/100\n",
      "281/281 [==============================] - 0s 484us/step - loss: 1.0260 - accuracy: 0.6150\n",
      "Epoch 15/100\n",
      "281/281 [==============================] - 0s 462us/step - loss: 1.0028 - accuracy: 0.6307\n",
      "Epoch 16/100\n",
      "281/281 [==============================] - 0s 493us/step - loss: 0.9814 - accuracy: 0.6328\n",
      "Epoch 17/100\n",
      "281/281 [==============================] - 0s 470us/step - loss: 0.9604 - accuracy: 0.6599\n",
      "Epoch 18/100\n",
      "281/281 [==============================] - 0s 473us/step - loss: 0.9376 - accuracy: 0.6642\n",
      "Epoch 19/100\n",
      "281/281 [==============================] - 0s 519us/step - loss: 0.9185 - accuracy: 0.6692\n",
      "Epoch 20/100\n",
      "281/281 [==============================] - 0s 516us/step - loss: 0.8958 - accuracy: 0.6806\n",
      "Epoch 21/100\n",
      "281/281 [==============================] - 0s 459us/step - loss: 0.8749 - accuracy: 0.7041\n",
      "Epoch 22/100\n",
      "281/281 [==============================] - 0s 457us/step - loss: 0.8556 - accuracy: 0.7026\n",
      "Epoch 23/100\n",
      "281/281 [==============================] - 0s 469us/step - loss: 0.8355 - accuracy: 0.7155\n",
      "Epoch 24/100\n",
      "281/281 [==============================] - 0s 454us/step - loss: 0.8124 - accuracy: 0.7147\n",
      "Epoch 25/100\n",
      "281/281 [==============================] - 0s 454us/step - loss: 0.7956 - accuracy: 0.7325\n",
      "Epoch 26/100\n",
      "281/281 [==============================] - 0s 454us/step - loss: 0.7772 - accuracy: 0.7333\n",
      "Epoch 27/100\n",
      "281/281 [==============================] - 0s 468us/step - loss: 0.7566 - accuracy: 0.7368\n",
      "Epoch 28/100\n",
      "281/281 [==============================] - 0s 453us/step - loss: 0.7390 - accuracy: 0.7504\n",
      "Epoch 29/100\n",
      "281/281 [==============================] - 0s 454us/step - loss: 0.7239 - accuracy: 0.7543\n",
      "Epoch 30/100\n",
      "281/281 [==============================] - 0s 456us/step - loss: 0.7069 - accuracy: 0.7561\n",
      "Epoch 31/100\n",
      "281/281 [==============================] - 0s 465us/step - loss: 0.6925 - accuracy: 0.7610\n",
      "Epoch 32/100\n",
      "281/281 [==============================] - 0s 455us/step - loss: 0.6767 - accuracy: 0.7682\n",
      "Epoch 33/100\n",
      "281/281 [==============================] - 0s 457us/step - loss: 0.6622 - accuracy: 0.7664\n",
      "Epoch 34/100\n",
      "281/281 [==============================] - 0s 455us/step - loss: 0.6494 - accuracy: 0.7717\n",
      "Epoch 35/100\n",
      "281/281 [==============================] - 0s 479us/step - loss: 0.6345 - accuracy: 0.7781\n",
      "Epoch 36/100\n",
      "281/281 [==============================] - 0s 480us/step - loss: 0.6227 - accuracy: 0.7817\n",
      "Epoch 37/100\n",
      "281/281 [==============================] - 0s 465us/step - loss: 0.6095 - accuracy: 0.7874\n",
      "Epoch 38/100\n",
      "281/281 [==============================] - 0s 457us/step - loss: 0.5968 - accuracy: 0.7888\n",
      "Epoch 39/100\n",
      "281/281 [==============================] - 0s 475us/step - loss: 0.5872 - accuracy: 0.7892\n",
      "Epoch 40/100\n",
      "281/281 [==============================] - 0s 457us/step - loss: 0.5747 - accuracy: 0.7974\n",
      "Epoch 41/100\n",
      "281/281 [==============================] - 0s 491us/step - loss: 0.5639 - accuracy: 0.8009\n",
      "Epoch 42/100\n",
      "281/281 [==============================] - 0s 530us/step - loss: 0.5529 - accuracy: 0.8038\n",
      "Epoch 43/100\n",
      "281/281 [==============================] - 0s 482us/step - loss: 0.5432 - accuracy: 0.8098\n",
      "Epoch 44/100\n",
      "281/281 [==============================] - 0s 453us/step - loss: 0.5332 - accuracy: 0.8148\n",
      "Epoch 45/100\n",
      "281/281 [==============================] - 0s 501us/step - loss: 0.5222 - accuracy: 0.8184\n",
      "Epoch 46/100\n",
      "281/281 [==============================] - 0s 521us/step - loss: 0.5132 - accuracy: 0.8202\n",
      "Epoch 47/100\n",
      "281/281 [==============================] - 0s 493us/step - loss: 0.5051 - accuracy: 0.8223\n",
      "Epoch 48/100\n",
      "281/281 [==============================] - 0s 461us/step - loss: 0.4956 - accuracy: 0.8266\n",
      "Epoch 49/100\n",
      "281/281 [==============================] - 0s 478us/step - loss: 0.4863 - accuracy: 0.8269\n",
      "Epoch 50/100\n",
      "281/281 [==============================] - 0s 473us/step - loss: 0.4770 - accuracy: 0.8312\n",
      "Epoch 51/100\n",
      "281/281 [==============================] - 0s 467us/step - loss: 0.4690 - accuracy: 0.8362\n",
      "Epoch 52/100\n",
      "281/281 [==============================] - 0s 483us/step - loss: 0.4599 - accuracy: 0.8437\n",
      "Epoch 53/100\n",
      "281/281 [==============================] - 0s 470us/step - loss: 0.4511 - accuracy: 0.8465\n",
      "Epoch 54/100\n",
      "281/281 [==============================] - 0s 458us/step - loss: 0.4447 - accuracy: 0.8444\n",
      "Epoch 55/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "281/281 [==============================] - 0s 452us/step - loss: 0.4373 - accuracy: 0.8494\n",
      "Epoch 56/100\n",
      "281/281 [==============================] - 0s 485us/step - loss: 0.4290 - accuracy: 0.8558\n",
      "Epoch 57/100\n",
      "281/281 [==============================] - 0s 469us/step - loss: 0.4216 - accuracy: 0.8533\n",
      "Epoch 58/100\n",
      "281/281 [==============================] - 0s 455us/step - loss: 0.4139 - accuracy: 0.8554\n",
      "Epoch 59/100\n",
      "281/281 [==============================] - 0s 463us/step - loss: 0.4076 - accuracy: 0.8579\n",
      "Epoch 60/100\n",
      "281/281 [==============================] - 0s 457us/step - loss: 0.4013 - accuracy: 0.8625\n",
      "Epoch 61/100\n",
      "281/281 [==============================] - 0s 465us/step - loss: 0.3946 - accuracy: 0.8643\n",
      "Epoch 62/100\n",
      "281/281 [==============================] - 0s 462us/step - loss: 0.3886 - accuracy: 0.8672\n",
      "Epoch 63/100\n",
      "281/281 [==============================] - 0s 449us/step - loss: 0.3813 - accuracy: 0.8697\n",
      "Epoch 64/100\n",
      "281/281 [==============================] - 0s 465us/step - loss: 0.3757 - accuracy: 0.8661\n",
      "Epoch 65/100\n",
      "281/281 [==============================] - 0s 513us/step - loss: 0.3681 - accuracy: 0.8739\n",
      "Epoch 66/100\n",
      "281/281 [==============================] - 0s 453us/step - loss: 0.3636 - accuracy: 0.8761\n",
      "Epoch 67/100\n",
      "281/281 [==============================] - 0s 453us/step - loss: 0.3587 - accuracy: 0.8796\n",
      "Epoch 68/100\n",
      "281/281 [==============================] - 0s 467us/step - loss: 0.3534 - accuracy: 0.8828\n",
      "Epoch 69/100\n",
      "281/281 [==============================] - 0s 457us/step - loss: 0.3457 - accuracy: 0.8875\n",
      "Epoch 70/100\n",
      "281/281 [==============================] - 0s 461us/step - loss: 0.3397 - accuracy: 0.8857\n",
      "Epoch 71/100\n",
      "281/281 [==============================] - 0s 450us/step - loss: 0.3347 - accuracy: 0.8868\n",
      "Epoch 72/100\n",
      "281/281 [==============================] - 0s 496us/step - loss: 0.3298 - accuracy: 0.8932\n",
      "Epoch 73/100\n",
      "281/281 [==============================] - 0s 476us/step - loss: 0.3267 - accuracy: 0.8917\n",
      "Epoch 74/100\n",
      "281/281 [==============================] - 0s 467us/step - loss: 0.3189 - accuracy: 0.8960\n",
      "Epoch 75/100\n",
      "281/281 [==============================] - 0s 465us/step - loss: 0.3150 - accuracy: 0.8910\n",
      "Epoch 76/100\n",
      "281/281 [==============================] - 0s 475us/step - loss: 0.3102 - accuracy: 0.9003\n",
      "Epoch 77/100\n",
      "281/281 [==============================] - 0s 476us/step - loss: 0.3053 - accuracy: 0.8971\n",
      "Epoch 78/100\n",
      "281/281 [==============================] - 0s 467us/step - loss: 0.3005 - accuracy: 0.8978\n",
      "Epoch 79/100\n",
      "281/281 [==============================] - 0s 460us/step - loss: 0.2951 - accuracy: 0.9031\n",
      "Epoch 80/100\n",
      "281/281 [==============================] - 0s 470us/step - loss: 0.2912 - accuracy: 0.9021\n",
      "Epoch 81/100\n",
      "281/281 [==============================] - 0s 490us/step - loss: 0.2863 - accuracy: 0.9063\n",
      "Epoch 82/100\n",
      "281/281 [==============================] - 0s 454us/step - loss: 0.2829 - accuracy: 0.9103\n",
      "Epoch 83/100\n",
      "281/281 [==============================] - 0s 459us/step - loss: 0.2785 - accuracy: 0.9106\n",
      "Epoch 84/100\n",
      "281/281 [==============================] - 0s 451us/step - loss: 0.2744 - accuracy: 0.9124\n",
      "Epoch 85/100\n",
      "281/281 [==============================] - 0s 460us/step - loss: 0.2693 - accuracy: 0.9174\n",
      "Epoch 86/100\n",
      "281/281 [==============================] - 0s 455us/step - loss: 0.2663 - accuracy: 0.9145\n",
      "Epoch 87/100\n",
      "281/281 [==============================] - 0s 471us/step - loss: 0.2616 - accuracy: 0.9167\n",
      "Epoch 88/100\n",
      "281/281 [==============================] - 0s 496us/step - loss: 0.2590 - accuracy: 0.9209\n",
      "Epoch 89/100\n",
      "281/281 [==============================] - 0s 463us/step - loss: 0.2541 - accuracy: 0.9224\n",
      "Epoch 90/100\n",
      "281/281 [==============================] - 0s 476us/step - loss: 0.2505 - accuracy: 0.9188\n",
      "Epoch 91/100\n",
      "281/281 [==============================] - 0s 487us/step - loss: 0.2471 - accuracy: 0.9209\n",
      "Epoch 92/100\n",
      "281/281 [==============================] - 0s 474us/step - loss: 0.2429 - accuracy: 0.9256\n",
      "Epoch 93/100\n",
      "281/281 [==============================] - 0s 492us/step - loss: 0.2393 - accuracy: 0.9281\n",
      "Epoch 94/100\n",
      "281/281 [==============================] - 0s 482us/step - loss: 0.2354 - accuracy: 0.9295\n",
      "Epoch 95/100\n",
      "281/281 [==============================] - 0s 468us/step - loss: 0.2330 - accuracy: 0.9284\n",
      "Epoch 96/100\n",
      "281/281 [==============================] - 0s 479us/step - loss: 0.2285 - accuracy: 0.9291\n",
      "Epoch 97/100\n",
      "281/281 [==============================] - 0s 476us/step - loss: 0.2274 - accuracy: 0.9320\n",
      "Epoch 98/100\n",
      "281/281 [==============================] - 0s 485us/step - loss: 0.2233 - accuracy: 0.9323\n",
      "Epoch 99/100\n",
      "281/281 [==============================] - 0s 475us/step - loss: 0.2185 - accuracy: 0.9320\n",
      "Epoch 100/100\n",
      "281/281 [==============================] - 0s 463us/step - loss: 0.2162 - accuracy: 0.9341\n",
      "Model: \"Sequential-NN\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_63 (Dense)             (None, 60)                3660      \n",
      "_________________________________________________________________\n",
      "dense_64 (Dense)             (None, 250)               15250     \n",
      "_________________________________________________________________\n",
      "dense_65 (Dense)             (None, 5)                 1255      \n",
      "=================================================================\n",
      "Total params: 20,165\n",
      "Trainable params: 20,165\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "281/281 [==============================] - 0s 468us/step - loss: 1.6094 - accuracy: 0.2525\n",
      "Epoch 2/100\n",
      "281/281 [==============================] - 0s 463us/step - loss: 1.5645 - accuracy: 0.3451\n",
      "Epoch 3/100\n",
      "281/281 [==============================] - 0s 464us/step - loss: 1.5089 - accuracy: 0.3704\n",
      "Epoch 4/100\n",
      "281/281 [==============================] - 0s 492us/step - loss: 1.4302 - accuracy: 0.4199\n",
      "Epoch 5/100\n",
      "281/281 [==============================] - 0s 468us/step - loss: 1.3468 - accuracy: 0.4758\n",
      "Epoch 6/100\n",
      "281/281 [==============================] - 0s 458us/step - loss: 1.2707 - accuracy: 0.5153\n",
      "Epoch 7/100\n",
      "281/281 [==============================] - 0s 472us/step - loss: 1.2087 - accuracy: 0.5395\n",
      "Epoch 8/100\n",
      "281/281 [==============================] - 0s 471us/step - loss: 1.1592 - accuracy: 0.5541\n",
      "Epoch 9/100\n",
      "281/281 [==============================] - 0s 474us/step - loss: 1.1209 - accuracy: 0.5798\n",
      "Epoch 10/100\n",
      "281/281 [==============================] - 0s 468us/step - loss: 1.0840 - accuracy: 0.6011\n",
      "Epoch 11/100\n",
      "281/281 [==============================] - 0s 496us/step - loss: 1.0514 - accuracy: 0.6264\n",
      "Epoch 12/100\n",
      "281/281 [==============================] - 0s 530us/step - loss: 1.0231 - accuracy: 0.6421\n",
      "Epoch 13/100\n",
      "281/281 [==============================] - 0s 635us/step - loss: 0.9911 - accuracy: 0.6339\n",
      "Epoch 14/100\n",
      "281/281 [==============================] - 0s 518us/step - loss: 0.9613 - accuracy: 0.6624\n",
      "Epoch 15/100\n",
      "281/281 [==============================] - 0s 527us/step - loss: 0.9331 - accuracy: 0.6827\n",
      "Epoch 16/100\n",
      "281/281 [==============================] - 0s 546us/step - loss: 0.9050 - accuracy: 0.6866\n",
      "Epoch 17/100\n",
      "281/281 [==============================] - 0s 642us/step - loss: 0.8778 - accuracy: 0.7087\n",
      "Epoch 18/100\n",
      "281/281 [==============================] - 0s 516us/step - loss: 0.8498 - accuracy: 0.7123\n",
      "Epoch 19/100\n",
      "281/281 [==============================] - 0s 500us/step - loss: 0.8215 - accuracy: 0.7407\n",
      "Epoch 20/100\n",
      "281/281 [==============================] - 0s 503us/step - loss: 0.7930 - accuracy: 0.7379\n",
      "Epoch 21/100\n",
      "281/281 [==============================] - 0s 483us/step - loss: 0.7687 - accuracy: 0.7650\n",
      "Epoch 22/100\n",
      "281/281 [==============================] - 0s 467us/step - loss: 0.7436 - accuracy: 0.7714\n",
      "Epoch 23/100\n",
      "281/281 [==============================] - 0s 495us/step - loss: 0.7173 - accuracy: 0.8002\n",
      "Epoch 24/100\n",
      "281/281 [==============================] - 0s 477us/step - loss: 0.6931 - accuracy: 0.7860\n",
      "Epoch 25/100\n",
      "281/281 [==============================] - 0s 455us/step - loss: 0.6713 - accuracy: 0.8038\n",
      "Epoch 26/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "281/281 [==============================] - 0s 499us/step - loss: 0.6482 - accuracy: 0.8170\n",
      "Epoch 27/100\n",
      "281/281 [==============================] - 0s 484us/step - loss: 0.6276 - accuracy: 0.8198\n",
      "Epoch 28/100\n",
      "281/281 [==============================] - 0s 626us/step - loss: 0.6048 - accuracy: 0.8319\n",
      "Epoch 29/100\n",
      "281/281 [==============================] - 0s 507us/step - loss: 0.5858 - accuracy: 0.8362\n",
      "Epoch 30/100\n",
      "281/281 [==============================] - 0s 497us/step - loss: 0.5664 - accuracy: 0.8426\n",
      "Epoch 31/100\n",
      "281/281 [==============================] - 0s 521us/step - loss: 0.5477 - accuracy: 0.8458\n",
      "Epoch 32/100\n",
      "281/281 [==============================] - 0s 488us/step - loss: 0.5309 - accuracy: 0.8536\n",
      "Epoch 33/100\n",
      "281/281 [==============================] - 0s 503us/step - loss: 0.5137 - accuracy: 0.8558\n",
      "Epoch 34/100\n",
      "281/281 [==============================] - 0s 475us/step - loss: 0.4989 - accuracy: 0.8579\n",
      "Epoch 35/100\n",
      "281/281 [==============================] - 0s 491us/step - loss: 0.4837 - accuracy: 0.8718\n",
      "Epoch 36/100\n",
      "281/281 [==============================] - 0s 513us/step - loss: 0.4682 - accuracy: 0.8707\n",
      "Epoch 37/100\n",
      "281/281 [==============================] - 0s 497us/step - loss: 0.4548 - accuracy: 0.8746\n",
      "Epoch 38/100\n",
      "281/281 [==============================] - 0s 457us/step - loss: 0.4405 - accuracy: 0.8786\n",
      "Epoch 39/100\n",
      "281/281 [==============================] - 0s 471us/step - loss: 0.4282 - accuracy: 0.8786\n",
      "Epoch 40/100\n",
      "281/281 [==============================] - 0s 500us/step - loss: 0.4162 - accuracy: 0.8821\n",
      "Epoch 41/100\n",
      "281/281 [==============================] - 0s 454us/step - loss: 0.4040 - accuracy: 0.8850\n",
      "Epoch 42/100\n",
      "281/281 [==============================] - 0s 495us/step - loss: 0.3933 - accuracy: 0.8889\n",
      "Epoch 43/100\n",
      "281/281 [==============================] - 0s 589us/step - loss: 0.3839 - accuracy: 0.8882\n",
      "Epoch 44/100\n",
      "281/281 [==============================] - 0s 516us/step - loss: 0.3718 - accuracy: 0.8942\n",
      "Epoch 45/100\n",
      "281/281 [==============================] - 0s 473us/step - loss: 0.3637 - accuracy: 0.8996\n",
      "Epoch 46/100\n",
      "281/281 [==============================] - 0s 502us/step - loss: 0.3558 - accuracy: 0.8935\n",
      "Epoch 47/100\n",
      "281/281 [==============================] - 0s 464us/step - loss: 0.3450 - accuracy: 0.8992\n",
      "Epoch 48/100\n",
      "281/281 [==============================] - 0s 495us/step - loss: 0.3363 - accuracy: 0.9006\n",
      "Epoch 49/100\n",
      "281/281 [==============================] - 0s 483us/step - loss: 0.3287 - accuracy: 0.9046\n",
      "Epoch 50/100\n",
      "281/281 [==============================] - 0s 491us/step - loss: 0.3180 - accuracy: 0.9056\n",
      "Epoch 51/100\n",
      "281/281 [==============================] - 0s 485us/step - loss: 0.3119 - accuracy: 0.9071\n",
      "Epoch 52/100\n",
      "281/281 [==============================] - 0s 463us/step - loss: 0.3042 - accuracy: 0.9120\n",
      "Epoch 53/100\n",
      "281/281 [==============================] - 0s 467us/step - loss: 0.2946 - accuracy: 0.9124\n",
      "Epoch 54/100\n",
      "281/281 [==============================] - 0s 488us/step - loss: 0.2913 - accuracy: 0.9127\n",
      "Epoch 55/100\n",
      "281/281 [==============================] - 0s 486us/step - loss: 0.2820 - accuracy: 0.9181\n",
      "Epoch 56/100\n",
      "281/281 [==============================] - 0s 465us/step - loss: 0.2784 - accuracy: 0.9170\n",
      "Epoch 57/100\n",
      "281/281 [==============================] - 0s 491us/step - loss: 0.2714 - accuracy: 0.9188\n",
      "Epoch 58/100\n",
      "281/281 [==============================] - 0s 468us/step - loss: 0.2629 - accuracy: 0.9206\n",
      "Epoch 59/100\n",
      "281/281 [==============================] - 0s 478us/step - loss: 0.2574 - accuracy: 0.9209\n",
      "Epoch 60/100\n",
      "281/281 [==============================] - 0s 474us/step - loss: 0.2514 - accuracy: 0.9249\n",
      "Epoch 61/100\n",
      "281/281 [==============================] - 0s 489us/step - loss: 0.2476 - accuracy: 0.9263\n",
      "Epoch 62/100\n",
      "281/281 [==============================] - 0s 460us/step - loss: 0.2398 - accuracy: 0.9291\n",
      "Epoch 63/100\n",
      "281/281 [==============================] - 0s 494us/step - loss: 0.2347 - accuracy: 0.9298\n",
      "Epoch 64/100\n",
      "281/281 [==============================] - 0s 458us/step - loss: 0.2304 - accuracy: 0.9302\n",
      "Epoch 65/100\n",
      "281/281 [==============================] - 0s 454us/step - loss: 0.2256 - accuracy: 0.9313\n",
      "Epoch 66/100\n",
      "281/281 [==============================] - 0s 460us/step - loss: 0.2191 - accuracy: 0.9355\n",
      "Epoch 67/100\n",
      "281/281 [==============================] - 0s 455us/step - loss: 0.2150 - accuracy: 0.9359\n",
      "Epoch 68/100\n",
      "281/281 [==============================] - 0s 462us/step - loss: 0.2098 - accuracy: 0.9380\n",
      "Epoch 69/100\n",
      "281/281 [==============================] - 0s 467us/step - loss: 0.2051 - accuracy: 0.9402\n",
      "Epoch 70/100\n",
      "281/281 [==============================] - 0s 471us/step - loss: 0.1999 - accuracy: 0.9384\n",
      "Epoch 71/100\n",
      "281/281 [==============================] - 0s 480us/step - loss: 0.1975 - accuracy: 0.9395\n",
      "Epoch 72/100\n",
      "281/281 [==============================] - 0s 477us/step - loss: 0.1932 - accuracy: 0.9448\n",
      "Epoch 73/100\n",
      "281/281 [==============================] - 0s 468us/step - loss: 0.1869 - accuracy: 0.9462\n",
      "Epoch 74/100\n",
      "281/281 [==============================] - 0s 457us/step - loss: 0.1852 - accuracy: 0.9441\n",
      "Epoch 75/100\n",
      "281/281 [==============================] - 0s 453us/step - loss: 0.1789 - accuracy: 0.9480\n",
      "Epoch 76/100\n",
      "281/281 [==============================] - 0s 470us/step - loss: 0.1758 - accuracy: 0.9487\n",
      "Epoch 77/100\n",
      "281/281 [==============================] - 0s 458us/step - loss: 0.1719 - accuracy: 0.9512\n",
      "Epoch 78/100\n",
      "281/281 [==============================] - 0s 493us/step - loss: 0.1678 - accuracy: 0.9519\n",
      "Epoch 79/100\n",
      "281/281 [==============================] - 0s 489us/step - loss: 0.1641 - accuracy: 0.9544\n",
      "Epoch 80/100\n",
      "281/281 [==============================] - 0s 474us/step - loss: 0.1615 - accuracy: 0.9551\n",
      "Epoch 81/100\n",
      "281/281 [==============================] - 0s 467us/step - loss: 0.1586 - accuracy: 0.9569\n",
      "Epoch 82/100\n",
      "281/281 [==============================] - 0s 463us/step - loss: 0.1553 - accuracy: 0.9562\n",
      "Epoch 83/100\n",
      "281/281 [==============================] - 0s 479us/step - loss: 0.1516 - accuracy: 0.9576\n",
      "Epoch 84/100\n",
      "281/281 [==============================] - 0s 576us/step - loss: 0.1474 - accuracy: 0.9601\n",
      "Epoch 85/100\n",
      "281/281 [==============================] - 0s 503us/step - loss: 0.1456 - accuracy: 0.9583\n",
      "Epoch 86/100\n",
      "281/281 [==============================] - 0s 563us/step - loss: 0.1429 - accuracy: 0.9623\n",
      "Epoch 87/100\n",
      "281/281 [==============================] - 0s 553us/step - loss: 0.1394 - accuracy: 0.9623\n",
      "Epoch 88/100\n",
      "281/281 [==============================] - 0s 486us/step - loss: 0.1389 - accuracy: 0.9598\n",
      "Epoch 89/100\n",
      "281/281 [==============================] - 0s 502us/step - loss: 0.1344 - accuracy: 0.9633\n",
      "Epoch 90/100\n",
      "281/281 [==============================] - 0s 607us/step - loss: 0.1303 - accuracy: 0.9637\n",
      "Epoch 91/100\n",
      "281/281 [==============================] - 0s 532us/step - loss: 0.1288 - accuracy: 0.9647\n",
      "Epoch 92/100\n",
      "281/281 [==============================] - 0s 472us/step - loss: 0.1266 - accuracy: 0.9647\n",
      "Epoch 93/100\n",
      "281/281 [==============================] - 0s 492us/step - loss: 0.1222 - accuracy: 0.9683\n",
      "Epoch 94/100\n",
      "281/281 [==============================] - 0s 507us/step - loss: 0.1232 - accuracy: 0.9687\n",
      "Epoch 95/100\n",
      "281/281 [==============================] - 0s 505us/step - loss: 0.1208 - accuracy: 0.9701\n",
      "Epoch 96/100\n",
      "281/281 [==============================] - 0s 580us/step - loss: 0.1173 - accuracy: 0.9683\n",
      "Epoch 97/100\n",
      "281/281 [==============================] - 0s 575us/step - loss: 0.1130 - accuracy: 0.9719\n",
      "Epoch 98/100\n",
      "281/281 [==============================] - 0s 518us/step - loss: 0.1117 - accuracy: 0.9701\n",
      "Epoch 99/100\n",
      "281/281 [==============================] - 0s 552us/step - loss: 0.1113 - accuracy: 0.9701\n",
      "Epoch 100/100\n",
      "281/281 [==============================] - 0s 565us/step - loss: 0.1075 - accuracy: 0.9708\n",
      "Model: \"Sequential-NN\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_66 (Dense)             (None, 60)                3660      \n",
      "_________________________________________________________________\n",
      "dense_67 (Dense)             (None, 250)               15250     \n",
      "_________________________________________________________________\n",
      "dense_68 (Dense)             (None, 5)                 1255      \n",
      "=================================================================\n",
      "Total params: 20,165\n",
      "Trainable params: 20,165\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "281/281 [==============================] - 0s 471us/step - loss: 1.5995 - accuracy: 0.2464\n",
      "Epoch 2/100\n",
      "281/281 [==============================] - 0s 491us/step - loss: 1.5685 - accuracy: 0.3725\n",
      "Epoch 3/100\n",
      "281/281 [==============================] - 0s 477us/step - loss: 1.5252 - accuracy: 0.4099\n",
      "Epoch 4/100\n",
      "281/281 [==============================] - 0s 503us/step - loss: 1.4619 - accuracy: 0.4366\n",
      "Epoch 5/100\n",
      "281/281 [==============================] - 0s 507us/step - loss: 1.3845 - accuracy: 0.4726\n",
      "Epoch 6/100\n",
      "281/281 [==============================] - 0s 506us/step - loss: 1.3065 - accuracy: 0.5071\n",
      "Epoch 7/100\n",
      "281/281 [==============================] - 0s 518us/step - loss: 1.2383 - accuracy: 0.5477\n",
      "Epoch 8/100\n",
      "281/281 [==============================] - 0s 499us/step - loss: 1.1846 - accuracy: 0.5734\n",
      "Epoch 9/100\n",
      "281/281 [==============================] - 0s 461us/step - loss: 1.1412 - accuracy: 0.5969\n",
      "Epoch 10/100\n",
      "281/281 [==============================] - 0s 472us/step - loss: 1.1065 - accuracy: 0.5890\n",
      "Epoch 11/100\n",
      "281/281 [==============================] - 0s 464us/step - loss: 1.0770 - accuracy: 0.6093\n",
      "Epoch 12/100\n",
      "281/281 [==============================] - 0s 460us/step - loss: 1.0460 - accuracy: 0.6232\n",
      "Epoch 13/100\n",
      "281/281 [==============================] - 0s 477us/step - loss: 1.0201 - accuracy: 0.6300\n",
      "Epoch 14/100\n",
      "281/281 [==============================] - 0s 457us/step - loss: 0.9935 - accuracy: 0.6524\n",
      "Epoch 15/100\n",
      "281/281 [==============================] - 0s 483us/step - loss: 0.9691 - accuracy: 0.6567\n",
      "Epoch 16/100\n",
      "281/281 [==============================] - 0s 486us/step - loss: 0.9444 - accuracy: 0.6784\n",
      "Epoch 17/100\n",
      "281/281 [==============================] - 0s 496us/step - loss: 0.9182 - accuracy: 0.6834\n",
      "Epoch 18/100\n",
      "281/281 [==============================] - 0s 494us/step - loss: 0.8979 - accuracy: 0.6984\n",
      "Epoch 19/100\n",
      "281/281 [==============================] - 0s 491us/step - loss: 0.8721 - accuracy: 0.6976\n",
      "Epoch 20/100\n",
      "281/281 [==============================] - 0s 485us/step - loss: 0.8496 - accuracy: 0.7222\n",
      "Epoch 21/100\n",
      "281/281 [==============================] - 0s 480us/step - loss: 0.8255 - accuracy: 0.7283\n",
      "Epoch 22/100\n",
      "281/281 [==============================] - 0s 464us/step - loss: 0.8045 - accuracy: 0.7304\n",
      "Epoch 23/100\n",
      "281/281 [==============================] - 0s 477us/step - loss: 0.7826 - accuracy: 0.7486\n",
      "Epoch 24/100\n",
      "281/281 [==============================] - 0s 584us/step - loss: 0.7597 - accuracy: 0.7571\n",
      "Epoch 25/100\n",
      "281/281 [==============================] - 0s 555us/step - loss: 0.7403 - accuracy: 0.7667\n",
      "Epoch 26/100\n",
      "281/281 [==============================] - 0s 500us/step - loss: 0.7206 - accuracy: 0.7717\n",
      "Epoch 27/100\n",
      "281/281 [==============================] - 0s 475us/step - loss: 0.7017 - accuracy: 0.7721\n",
      "Epoch 28/100\n",
      "281/281 [==============================] - 0s 495us/step - loss: 0.6822 - accuracy: 0.7799\n",
      "Epoch 29/100\n",
      "281/281 [==============================] - 0s 520us/step - loss: 0.6666 - accuracy: 0.7874\n",
      "Epoch 30/100\n",
      "281/281 [==============================] - 0s 476us/step - loss: 0.6501 - accuracy: 0.7949\n",
      "Epoch 31/100\n",
      "281/281 [==============================] - 0s 469us/step - loss: 0.6361 - accuracy: 0.7991\n",
      "Epoch 32/100\n",
      "281/281 [==============================] - 0s 516us/step - loss: 0.6182 - accuracy: 0.8020\n",
      "Epoch 33/100\n",
      "281/281 [==============================] - 0s 485us/step - loss: 0.6062 - accuracy: 0.8070\n",
      "Epoch 34/100\n",
      "281/281 [==============================] - 0s 467us/step - loss: 0.5880 - accuracy: 0.8155\n",
      "Epoch 35/100\n",
      "281/281 [==============================] - 0s 464us/step - loss: 0.5762 - accuracy: 0.8159\n",
      "Epoch 36/100\n",
      "281/281 [==============================] - 0s 471us/step - loss: 0.5600 - accuracy: 0.8234\n",
      "Epoch 37/100\n",
      "281/281 [==============================] - 0s 525us/step - loss: 0.5485 - accuracy: 0.8244\n",
      "Epoch 38/100\n",
      "281/281 [==============================] - 0s 542us/step - loss: 0.5344 - accuracy: 0.8294\n",
      "Epoch 39/100\n",
      "281/281 [==============================] - 0s 567us/step - loss: 0.5219 - accuracy: 0.8312\n",
      "Epoch 40/100\n",
      "281/281 [==============================] - 0s 478us/step - loss: 0.5129 - accuracy: 0.8351\n",
      "Epoch 41/100\n",
      "281/281 [==============================] - 0s 466us/step - loss: 0.4985 - accuracy: 0.8429\n",
      "Epoch 42/100\n",
      "281/281 [==============================] - 0s 471us/step - loss: 0.4885 - accuracy: 0.8422\n",
      "Epoch 43/100\n",
      "281/281 [==============================] - 0s 469us/step - loss: 0.4772 - accuracy: 0.8540\n",
      "Epoch 44/100\n",
      "281/281 [==============================] - 0s 496us/step - loss: 0.4652 - accuracy: 0.8540\n",
      "Epoch 45/100\n",
      "281/281 [==============================] - 0s 490us/step - loss: 0.4577 - accuracy: 0.8554\n",
      "Epoch 46/100\n",
      "281/281 [==============================] - 0s 479us/step - loss: 0.4454 - accuracy: 0.8643\n",
      "Epoch 47/100\n",
      "281/281 [==============================] - 0s 474us/step - loss: 0.4351 - accuracy: 0.8654\n",
      "Epoch 48/100\n",
      "281/281 [==============================] - 0s 472us/step - loss: 0.4260 - accuracy: 0.8675\n",
      "Epoch 49/100\n",
      "281/281 [==============================] - 0s 461us/step - loss: 0.4178 - accuracy: 0.8714\n",
      "Epoch 50/100\n",
      "281/281 [==============================] - 0s 487us/step - loss: 0.4080 - accuracy: 0.8704\n",
      "Epoch 51/100\n",
      "281/281 [==============================] - 0s 466us/step - loss: 0.3989 - accuracy: 0.8739\n",
      "Epoch 52/100\n",
      "281/281 [==============================] - 0s 459us/step - loss: 0.3896 - accuracy: 0.8839\n",
      "Epoch 53/100\n",
      "281/281 [==============================] - 0s 471us/step - loss: 0.3826 - accuracy: 0.8778\n",
      "Epoch 54/100\n",
      "281/281 [==============================] - 0s 496us/step - loss: 0.3755 - accuracy: 0.8796\n",
      "Epoch 55/100\n",
      "281/281 [==============================] - 0s 459us/step - loss: 0.3663 - accuracy: 0.8892\n",
      "Epoch 56/100\n",
      "281/281 [==============================] - 0s 463us/step - loss: 0.3601 - accuracy: 0.8871\n",
      "Epoch 57/100\n",
      "281/281 [==============================] - 0s 461us/step - loss: 0.3532 - accuracy: 0.8914\n",
      "Epoch 58/100\n",
      "281/281 [==============================] - 0s 462us/step - loss: 0.3452 - accuracy: 0.8949\n",
      "Epoch 59/100\n",
      "281/281 [==============================] - 0s 468us/step - loss: 0.3391 - accuracy: 0.8942\n",
      "Epoch 60/100\n",
      "281/281 [==============================] - 0s 491us/step - loss: 0.3313 - accuracy: 0.8978\n",
      "Epoch 61/100\n",
      "281/281 [==============================] - 0s 462us/step - loss: 0.3252 - accuracy: 0.9021\n",
      "Epoch 62/100\n",
      "281/281 [==============================] - 0s 473us/step - loss: 0.3204 - accuracy: 0.9035\n",
      "Epoch 63/100\n",
      "281/281 [==============================] - 0s 461us/step - loss: 0.3135 - accuracy: 0.9049\n",
      "Epoch 64/100\n",
      "281/281 [==============================] - 0s 460us/step - loss: 0.3056 - accuracy: 0.9074\n",
      "Epoch 65/100\n",
      "281/281 [==============================] - 0s 463us/step - loss: 0.3015 - accuracy: 0.9056\n",
      "Epoch 66/100\n",
      "281/281 [==============================] - 0s 467us/step - loss: 0.2959 - accuracy: 0.9071\n",
      "Epoch 67/100\n",
      "281/281 [==============================] - 0s 462us/step - loss: 0.2890 - accuracy: 0.9135\n",
      "Epoch 68/100\n",
      "281/281 [==============================] - 0s 482us/step - loss: 0.2841 - accuracy: 0.9110\n",
      "Epoch 69/100\n",
      "281/281 [==============================] - 0s 467us/step - loss: 0.2801 - accuracy: 0.9142\n",
      "Epoch 70/100\n",
      "281/281 [==============================] - 0s 460us/step - loss: 0.2744 - accuracy: 0.9156\n",
      "Epoch 71/100\n",
      "281/281 [==============================] - 0s 464us/step - loss: 0.2682 - accuracy: 0.9177\n",
      "Epoch 72/100\n",
      "281/281 [==============================] - 0s 459us/step - loss: 0.2638 - accuracy: 0.9192\n",
      "Epoch 73/100\n",
      "281/281 [==============================] - 0s 484us/step - loss: 0.2585 - accuracy: 0.9209\n",
      "Epoch 74/100\n",
      "281/281 [==============================] - 0s 482us/step - loss: 0.2527 - accuracy: 0.9206\n",
      "Epoch 75/100\n",
      "281/281 [==============================] - 0s 477us/step - loss: 0.2495 - accuracy: 0.9227\n",
      "Epoch 76/100\n",
      "281/281 [==============================] - 0s 473us/step - loss: 0.2449 - accuracy: 0.9227\n",
      "Epoch 77/100\n",
      "281/281 [==============================] - 0s 461us/step - loss: 0.2416 - accuracy: 0.9238\n",
      "Epoch 78/100\n",
      "281/281 [==============================] - 0s 456us/step - loss: 0.2365 - accuracy: 0.9281\n",
      "Epoch 79/100\n",
      "281/281 [==============================] - 0s 460us/step - loss: 0.2324 - accuracy: 0.9266\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/100\n",
      "281/281 [==============================] - 0s 457us/step - loss: 0.2285 - accuracy: 0.9313\n",
      "Epoch 81/100\n",
      "281/281 [==============================] - 0s 460us/step - loss: 0.2226 - accuracy: 0.9363\n",
      "Epoch 82/100\n",
      "281/281 [==============================] - 0s 463us/step - loss: 0.2197 - accuracy: 0.9330\n",
      "Epoch 83/100\n",
      "281/281 [==============================] - 0s 484us/step - loss: 0.2146 - accuracy: 0.9373\n",
      "Epoch 84/100\n",
      "281/281 [==============================] - 0s 481us/step - loss: 0.2116 - accuracy: 0.9359\n",
      "Epoch 85/100\n",
      "281/281 [==============================] - 0s 461us/step - loss: 0.2082 - accuracy: 0.9377\n",
      "Epoch 86/100\n",
      "281/281 [==============================] - 0s 517us/step - loss: 0.2041 - accuracy: 0.9352\n",
      "Epoch 87/100\n",
      "281/281 [==============================] - 0s 474us/step - loss: 0.2007 - accuracy: 0.9377\n",
      "Epoch 88/100\n",
      "281/281 [==============================] - 0s 467us/step - loss: 0.1985 - accuracy: 0.9420\n",
      "Epoch 89/100\n",
      "281/281 [==============================] - 0s 460us/step - loss: 0.1950 - accuracy: 0.9423\n",
      "Epoch 90/100\n",
      "281/281 [==============================] - 0s 476us/step - loss: 0.1899 - accuracy: 0.9434\n",
      "Epoch 91/100\n",
      "281/281 [==============================] - 0s 485us/step - loss: 0.1856 - accuracy: 0.9444\n",
      "Epoch 92/100\n",
      "281/281 [==============================] - 0s 459us/step - loss: 0.1851 - accuracy: 0.9452\n",
      "Epoch 93/100\n",
      "281/281 [==============================] - 0s 463us/step - loss: 0.1799 - accuracy: 0.9444\n",
      "Epoch 94/100\n",
      "281/281 [==============================] - 0s 475us/step - loss: 0.1777 - accuracy: 0.9498\n",
      "Epoch 95/100\n",
      "281/281 [==============================] - 0s 460us/step - loss: 0.1748 - accuracy: 0.9466\n",
      "Epoch 96/100\n",
      "281/281 [==============================] - 0s 584us/step - loss: 0.1716 - accuracy: 0.9516\n",
      "Epoch 97/100\n",
      "281/281 [==============================] - 0s 526us/step - loss: 0.1708 - accuracy: 0.9473\n",
      "Epoch 98/100\n",
      "281/281 [==============================] - 0s 592us/step - loss: 0.1668 - accuracy: 0.9551\n",
      "Epoch 99/100\n",
      "281/281 [==============================] - 0s 506us/step - loss: 0.1633 - accuracy: 0.9530\n",
      "Epoch 100/100\n",
      "281/281 [==============================] - 0s 568us/step - loss: 0.1627 - accuracy: 0.9498\n",
      "Model: \"Sequential-NN\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_69 (Dense)             (None, 60)                3660      \n",
      "_________________________________________________________________\n",
      "dense_70 (Dense)             (None, 250)               15250     \n",
      "_________________________________________________________________\n",
      "dense_71 (Dense)             (None, 5)                 1255      \n",
      "=================================================================\n",
      "Total params: 20,165\n",
      "Trainable params: 20,165\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "281/281 [==============================] - 0s 524us/step - loss: 1.6075 - accuracy: 0.2361\n",
      "Epoch 2/100\n",
      "281/281 [==============================] - 0s 590us/step - loss: 1.5852 - accuracy: 0.3155\n",
      "Epoch 3/100\n",
      "281/281 [==============================] - 0s 527us/step - loss: 1.5524 - accuracy: 0.3750\n",
      "Epoch 4/100\n",
      "281/281 [==============================] - 0s 473us/step - loss: 1.5029 - accuracy: 0.4220\n",
      "Epoch 5/100\n",
      "281/281 [==============================] - 0s 512us/step - loss: 1.4385 - accuracy: 0.4533\n",
      "Epoch 6/100\n",
      "281/281 [==============================] - 0s 517us/step - loss: 1.3662 - accuracy: 0.4975\n",
      "Epoch 7/100\n",
      "281/281 [==============================] - 0s 585us/step - loss: 1.2950 - accuracy: 0.5175\n",
      "Epoch 8/100\n",
      "281/281 [==============================] - 0s 595us/step - loss: 1.2322 - accuracy: 0.5420\n",
      "Epoch 9/100\n",
      "281/281 [==============================] - 0s 524us/step - loss: 1.1821 - accuracy: 0.5527\n",
      "Epoch 10/100\n",
      "281/281 [==============================] - 0s 511us/step - loss: 1.1405 - accuracy: 0.5783\n",
      "Epoch 11/100\n",
      "281/281 [==============================] - 0s 569us/step - loss: 1.1037 - accuracy: 0.5783\n",
      "Epoch 12/100\n",
      "281/281 [==============================] - 0s 507us/step - loss: 1.0727 - accuracy: 0.5812\n",
      "Epoch 13/100\n",
      "281/281 [==============================] - 0s 519us/step - loss: 1.0417 - accuracy: 0.6065\n",
      "Epoch 14/100\n",
      "281/281 [==============================] - 0s 478us/step - loss: 1.0141 - accuracy: 0.6125\n",
      "Epoch 15/100\n",
      "281/281 [==============================] - 0s 480us/step - loss: 0.9895 - accuracy: 0.6218\n",
      "Epoch 16/100\n",
      "281/281 [==============================] - 0s 512us/step - loss: 0.9613 - accuracy: 0.6417\n",
      "Epoch 17/100\n",
      "281/281 [==============================] - 0s 515us/step - loss: 0.9386 - accuracy: 0.6471\n",
      "Epoch 18/100\n",
      "281/281 [==============================] - 0s 476us/step - loss: 0.9143 - accuracy: 0.6528\n",
      "Epoch 19/100\n",
      "281/281 [==============================] - 0s 467us/step - loss: 0.8914 - accuracy: 0.6681\n",
      "Epoch 20/100\n",
      "281/281 [==============================] - 0s 494us/step - loss: 0.8702 - accuracy: 0.6756\n",
      "Epoch 21/100\n",
      "281/281 [==============================] - 0s 467us/step - loss: 0.8509 - accuracy: 0.6816\n",
      "Epoch 22/100\n",
      "281/281 [==============================] - 0s 470us/step - loss: 0.8313 - accuracy: 0.7009\n",
      "Epoch 23/100\n",
      "281/281 [==============================] - 0s 466us/step - loss: 0.8125 - accuracy: 0.7001\n",
      "Epoch 24/100\n",
      "281/281 [==============================] - 0s 475us/step - loss: 0.7953 - accuracy: 0.7151\n",
      "Epoch 25/100\n",
      "281/281 [==============================] - 0s 455us/step - loss: 0.7773 - accuracy: 0.7244\n",
      "Epoch 26/100\n",
      "281/281 [==============================] - 0s 463us/step - loss: 0.7584 - accuracy: 0.7361\n",
      "Epoch 27/100\n",
      "281/281 [==============================] - 0s 480us/step - loss: 0.7420 - accuracy: 0.7361\n",
      "Epoch 28/100\n",
      "281/281 [==============================] - 0s 482us/step - loss: 0.7285 - accuracy: 0.7550\n",
      "Epoch 29/100\n",
      "281/281 [==============================] - 0s 532us/step - loss: 0.7130 - accuracy: 0.7532\n",
      "Epoch 30/100\n",
      "281/281 [==============================] - 0s 490us/step - loss: 0.6989 - accuracy: 0.7632\n",
      "Epoch 31/100\n",
      "281/281 [==============================] - 0s 488us/step - loss: 0.6827 - accuracy: 0.7678\n",
      "Epoch 32/100\n",
      "281/281 [==============================] - 0s 481us/step - loss: 0.6701 - accuracy: 0.7710\n",
      "Epoch 33/100\n",
      "281/281 [==============================] - 0s 477us/step - loss: 0.6572 - accuracy: 0.7714\n",
      "Epoch 34/100\n",
      "281/281 [==============================] - 0s 515us/step - loss: 0.6452 - accuracy: 0.7803\n",
      "Epoch 35/100\n",
      "281/281 [==============================] - 0s 533us/step - loss: 0.6304 - accuracy: 0.7970\n",
      "Epoch 36/100\n",
      "281/281 [==============================] - 0s 527us/step - loss: 0.6170 - accuracy: 0.7924\n",
      "Epoch 37/100\n",
      "281/281 [==============================] - 0s 506us/step - loss: 0.6047 - accuracy: 0.7977\n",
      "Epoch 38/100\n",
      "281/281 [==============================] - 0s 499us/step - loss: 0.5942 - accuracy: 0.7999\n",
      "Epoch 39/100\n",
      "281/281 [==============================] - 0s 475us/step - loss: 0.5808 - accuracy: 0.8120\n",
      "Epoch 40/100\n",
      "281/281 [==============================] - 0s 476us/step - loss: 0.5690 - accuracy: 0.8088\n",
      "Epoch 41/100\n",
      "281/281 [==============================] - 0s 594us/step - loss: 0.5581 - accuracy: 0.8194\n",
      "Epoch 42/100\n",
      "281/281 [==============================] - 0s 501us/step - loss: 0.5454 - accuracy: 0.8312\n",
      "Epoch 43/100\n",
      "281/281 [==============================] - 0s 523us/step - loss: 0.5353 - accuracy: 0.8291\n",
      "Epoch 44/100\n",
      "281/281 [==============================] - 0s 498us/step - loss: 0.5237 - accuracy: 0.8308\n",
      "Epoch 45/100\n",
      "281/281 [==============================] - 0s 489us/step - loss: 0.5133 - accuracy: 0.8365\n",
      "Epoch 46/100\n",
      "281/281 [==============================] - 0s 485us/step - loss: 0.5025 - accuracy: 0.8380\n",
      "Epoch 47/100\n",
      "281/281 [==============================] - 0s 488us/step - loss: 0.4930 - accuracy: 0.8451\n",
      "Epoch 48/100\n",
      "281/281 [==============================] - 0s 484us/step - loss: 0.4828 - accuracy: 0.8469\n",
      "Epoch 49/100\n",
      "281/281 [==============================] - 0s 476us/step - loss: 0.4724 - accuracy: 0.8472\n",
      "Epoch 50/100\n",
      "281/281 [==============================] - 0s 466us/step - loss: 0.4625 - accuracy: 0.8561\n",
      "Epoch 51/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "281/281 [==============================] - 0s 482us/step - loss: 0.4537 - accuracy: 0.8533\n",
      "Epoch 52/100\n",
      "281/281 [==============================] - 0s 526us/step - loss: 0.4437 - accuracy: 0.8657\n",
      "Epoch 53/100\n",
      "281/281 [==============================] - 0s 467us/step - loss: 0.4338 - accuracy: 0.8647\n",
      "Epoch 54/100\n",
      "281/281 [==============================] - 0s 485us/step - loss: 0.4273 - accuracy: 0.8686\n",
      "Epoch 55/100\n",
      "281/281 [==============================] - 0s 487us/step - loss: 0.4163 - accuracy: 0.8714\n",
      "Epoch 56/100\n",
      "281/281 [==============================] - 0s 464us/step - loss: 0.4077 - accuracy: 0.8732\n",
      "Epoch 57/100\n",
      "281/281 [==============================] - 0s 474us/step - loss: 0.3988 - accuracy: 0.8782\n",
      "Epoch 58/100\n",
      "281/281 [==============================] - 0s 499us/step - loss: 0.3916 - accuracy: 0.8818\n",
      "Epoch 59/100\n",
      "281/281 [==============================] - 0s 532us/step - loss: 0.3836 - accuracy: 0.8807\n",
      "Epoch 60/100\n",
      "281/281 [==============================] - 0s 595us/step - loss: 0.3762 - accuracy: 0.8832\n",
      "Epoch 61/100\n",
      "281/281 [==============================] - 0s 511us/step - loss: 0.3686 - accuracy: 0.8853\n",
      "Epoch 62/100\n",
      "281/281 [==============================] - 0s 466us/step - loss: 0.3601 - accuracy: 0.8903\n",
      "Epoch 63/100\n",
      "281/281 [==============================] - 0s 466us/step - loss: 0.3543 - accuracy: 0.8914\n",
      "Epoch 64/100\n",
      "281/281 [==============================] - 0s 472us/step - loss: 0.3481 - accuracy: 0.8953\n",
      "Epoch 65/100\n",
      "281/281 [==============================] - 0s 470us/step - loss: 0.3396 - accuracy: 0.8957\n",
      "Epoch 66/100\n",
      "281/281 [==============================] - 0s 476us/step - loss: 0.3327 - accuracy: 0.8996\n",
      "Epoch 67/100\n",
      "281/281 [==============================] - 0s 485us/step - loss: 0.3241 - accuracy: 0.9021\n",
      "Epoch 68/100\n",
      "281/281 [==============================] - 0s 478us/step - loss: 0.3215 - accuracy: 0.9049\n",
      "Epoch 69/100\n",
      "281/281 [==============================] - 0s 465us/step - loss: 0.3149 - accuracy: 0.9060\n",
      "Epoch 70/100\n",
      "281/281 [==============================] - 0s 472us/step - loss: 0.3090 - accuracy: 0.9113\n",
      "Epoch 71/100\n",
      "281/281 [==============================] - 0s 461us/step - loss: 0.2993 - accuracy: 0.9113\n",
      "Epoch 72/100\n",
      "281/281 [==============================] - 0s 468us/step - loss: 0.2945 - accuracy: 0.9149\n",
      "Epoch 73/100\n",
      "281/281 [==============================] - 0s 467us/step - loss: 0.2899 - accuracy: 0.9170\n",
      "Epoch 74/100\n",
      "281/281 [==============================] - 0s 485us/step - loss: 0.2828 - accuracy: 0.9184\n",
      "Epoch 75/100\n",
      "281/281 [==============================] - 0s 477us/step - loss: 0.2790 - accuracy: 0.9202\n",
      "Epoch 76/100\n",
      "281/281 [==============================] - 0s 458us/step - loss: 0.2730 - accuracy: 0.9206\n",
      "Epoch 77/100\n",
      "281/281 [==============================] - 0s 459us/step - loss: 0.2691 - accuracy: 0.9192\n",
      "Epoch 78/100\n",
      "281/281 [==============================] - 0s 461us/step - loss: 0.2629 - accuracy: 0.9224\n",
      "Epoch 79/100\n",
      "281/281 [==============================] - 0s 466us/step - loss: 0.2572 - accuracy: 0.9259\n",
      "Epoch 80/100\n",
      "281/281 [==============================] - 0s 460us/step - loss: 0.2523 - accuracy: 0.9327\n",
      "Epoch 81/100\n",
      "281/281 [==============================] - 0s 460us/step - loss: 0.2463 - accuracy: 0.9302\n",
      "Epoch 82/100\n",
      "281/281 [==============================] - 0s 463us/step - loss: 0.2414 - accuracy: 0.9288\n",
      "Epoch 83/100\n",
      "281/281 [==============================] - 0s 462us/step - loss: 0.2386 - accuracy: 0.9298\n",
      "Epoch 84/100\n",
      "281/281 [==============================] - 0s 462us/step - loss: 0.2324 - accuracy: 0.9341\n",
      "Epoch 85/100\n",
      "281/281 [==============================] - 0s 463us/step - loss: 0.2278 - accuracy: 0.9352\n",
      "Epoch 86/100\n",
      "281/281 [==============================] - 0s 458us/step - loss: 0.2239 - accuracy: 0.9391\n",
      "Epoch 87/100\n",
      "281/281 [==============================] - 0s 457us/step - loss: 0.2213 - accuracy: 0.9380\n",
      "Epoch 88/100\n",
      "281/281 [==============================] - 0s 459us/step - loss: 0.2163 - accuracy: 0.9355\n",
      "Epoch 89/100\n",
      "281/281 [==============================] - 0s 459us/step - loss: 0.2120 - accuracy: 0.9398\n",
      "Epoch 90/100\n",
      "281/281 [==============================] - 0s 458us/step - loss: 0.2075 - accuracy: 0.9412\n",
      "Epoch 91/100\n",
      "281/281 [==============================] - 0s 467us/step - loss: 0.2056 - accuracy: 0.9409\n",
      "Epoch 92/100\n",
      "281/281 [==============================] - 0s 462us/step - loss: 0.1991 - accuracy: 0.9448\n",
      "Epoch 93/100\n",
      "281/281 [==============================] - 0s 461us/step - loss: 0.1955 - accuracy: 0.9452\n",
      "Epoch 94/100\n",
      "281/281 [==============================] - 0s 462us/step - loss: 0.1934 - accuracy: 0.9473\n",
      "Epoch 95/100\n",
      "281/281 [==============================] - 0s 462us/step - loss: 0.1884 - accuracy: 0.9498\n",
      "Epoch 96/100\n",
      "281/281 [==============================] - 0s 461us/step - loss: 0.1861 - accuracy: 0.9526\n",
      "Epoch 97/100\n",
      "281/281 [==============================] - 0s 459us/step - loss: 0.1802 - accuracy: 0.9501\n",
      "Epoch 98/100\n",
      "281/281 [==============================] - 0s 471us/step - loss: 0.1781 - accuracy: 0.9573\n",
      "Epoch 99/100\n",
      "281/281 [==============================] - 0s 535us/step - loss: 0.1745 - accuracy: 0.9544\n",
      "Epoch 100/100\n",
      "281/281 [==============================] - 0s 511us/step - loss: 0.1703 - accuracy: 0.9573\n",
      "Average score of Cross Validation: 0.9205096177872363\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 100\n",
    "BATCH_SIZE = 10\n",
    "num_folds = 10\n",
    "\n",
    "kf = StratifiedKFold(n_splits=num_folds, random_state=seed, shuffle=True)\n",
    "cv_results = np.array([])\n",
    "for train_idx, test_idx, in kf.split(X_train, y_train):\n",
    "    X_cross_train, y_cross_train = X_train[train_idx], y_train[train_idx]\n",
    "    X_cross_test, y_cross_test = X_train[test_idx], y_train[test_idx]\n",
    "    model = getNetwork()\n",
    "    model.fit(X_cross_train, y_cross_train, epochs=EPOCHS, batch_size=BATCH_SIZE)  \n",
    "    y_pred = model.predict(X_cross_test)\n",
    "    predictions_categorical = np.argmax(y_pred, axis=1)\n",
    "    f1s = f1_score(y_cross_test, predictions_categorical, average=\"weighted\")\n",
    "    cv_results = np.append(cv_results, [f1s])\n",
    "\n",
    "print(f'Average score of Cross Validation: {cv_results.mean()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Sequential-NN\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_39 (Dense)             (None, 60)                3660      \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             (None, 250)               15250     \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (None, 5)                 1255      \n",
      "=================================================================\n",
      "Total params: 20,165\n",
      "Trainable params: 20,165\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "234/234 [==============================] - 0s 782us/step - loss: 1.6025 - accuracy: 0.2491 - val_loss: 1.5986 - val_accuracy: 0.2205\n",
      "Epoch 2/100\n",
      "234/234 [==============================] - 0s 609us/step - loss: 1.5777 - accuracy: 0.3355 - val_loss: 1.5687 - val_accuracy: 0.2859\n",
      "Epoch 3/100\n",
      "234/234 [==============================] - 0s 602us/step - loss: 1.5457 - accuracy: 0.3944 - val_loss: 1.5317 - val_accuracy: 0.3846\n",
      "Epoch 4/100\n",
      "234/234 [==============================] - 0s 585us/step - loss: 1.5009 - accuracy: 0.4239 - val_loss: 1.4851 - val_accuracy: 0.3205\n",
      "Epoch 5/100\n",
      "234/234 [==============================] - 0s 597us/step - loss: 1.4397 - accuracy: 0.4380 - val_loss: 1.4191 - val_accuracy: 0.4449\n",
      "Epoch 6/100\n",
      "234/234 [==============================] - 0s 596us/step - loss: 1.3723 - accuracy: 0.4902 - val_loss: 1.3544 - val_accuracy: 0.4615\n",
      "Epoch 7/100\n",
      "234/234 [==============================] - 0s 613us/step - loss: 1.3040 - accuracy: 0.5167 - val_loss: 1.2916 - val_accuracy: 0.5205\n",
      "Epoch 8/100\n",
      "234/234 [==============================] - 0s 601us/step - loss: 1.2466 - accuracy: 0.5560 - val_loss: 1.2430 - val_accuracy: 0.5372\n",
      "Epoch 9/100\n",
      "234/234 [==============================] - 0s 589us/step - loss: 1.1974 - accuracy: 0.5667 - val_loss: 1.2011 - val_accuracy: 0.5436\n",
      "Epoch 10/100\n",
      "234/234 [==============================] - 0s 606us/step - loss: 1.1573 - accuracy: 0.5735 - val_loss: 1.1582 - val_accuracy: 0.5410\n",
      "Epoch 11/100\n",
      "234/234 [==============================] - 0s 590us/step - loss: 1.1261 - accuracy: 0.5803 - val_loss: 1.1360 - val_accuracy: 0.5577\n",
      "Epoch 12/100\n",
      "234/234 [==============================] - 0s 589us/step - loss: 1.0939 - accuracy: 0.5996 - val_loss: 1.1026 - val_accuracy: 0.5897\n",
      "Epoch 13/100\n",
      "234/234 [==============================] - 0s 587us/step - loss: 1.0676 - accuracy: 0.6145 - val_loss: 1.0750 - val_accuracy: 0.5897\n",
      "Epoch 14/100\n",
      "234/234 [==============================] - 0s 582us/step - loss: 1.0416 - accuracy: 0.6239 - val_loss: 1.0523 - val_accuracy: 0.6038\n",
      "Epoch 15/100\n",
      "234/234 [==============================] - 0s 603us/step - loss: 1.0171 - accuracy: 0.6244 - val_loss: 1.0273 - val_accuracy: 0.6051\n",
      "Epoch 16/100\n",
      "234/234 [==============================] - 0s 589us/step - loss: 0.9942 - accuracy: 0.6244 - val_loss: 1.0106 - val_accuracy: 0.5923\n",
      "Epoch 17/100\n",
      "234/234 [==============================] - 0s 604us/step - loss: 0.9708 - accuracy: 0.6427 - val_loss: 0.9997 - val_accuracy: 0.5859\n",
      "Epoch 18/100\n",
      "234/234 [==============================] - 0s 643us/step - loss: 0.9541 - accuracy: 0.6526 - val_loss: 0.9857 - val_accuracy: 0.5872\n",
      "Epoch 19/100\n",
      "234/234 [==============================] - 0s 607us/step - loss: 0.9324 - accuracy: 0.6667 - val_loss: 0.9557 - val_accuracy: 0.6449\n",
      "Epoch 20/100\n",
      "234/234 [==============================] - 0s 622us/step - loss: 0.9123 - accuracy: 0.6795 - val_loss: 0.9348 - val_accuracy: 0.6603\n",
      "Epoch 21/100\n",
      "234/234 [==============================] - 0s 590us/step - loss: 0.8934 - accuracy: 0.6799 - val_loss: 0.9193 - val_accuracy: 0.6679\n",
      "Epoch 22/100\n",
      "234/234 [==============================] - 0s 597us/step - loss: 0.8754 - accuracy: 0.6923 - val_loss: 0.8974 - val_accuracy: 0.6705\n",
      "Epoch 23/100\n",
      "234/234 [==============================] - 0s 622us/step - loss: 0.8583 - accuracy: 0.6915 - val_loss: 0.8834 - val_accuracy: 0.6718\n",
      "Epoch 24/100\n",
      "234/234 [==============================] - 0s 599us/step - loss: 0.8402 - accuracy: 0.7128 - val_loss: 0.8602 - val_accuracy: 0.7000\n",
      "Epoch 25/100\n",
      "234/234 [==============================] - 0s 609us/step - loss: 0.8223 - accuracy: 0.7167 - val_loss: 0.8584 - val_accuracy: 0.6936\n",
      "Epoch 26/100\n",
      "234/234 [==============================] - 0s 599us/step - loss: 0.8053 - accuracy: 0.7295 - val_loss: 0.8306 - val_accuracy: 0.7218\n",
      "Epoch 27/100\n",
      "234/234 [==============================] - 0s 606us/step - loss: 0.7906 - accuracy: 0.7402 - val_loss: 0.8159 - val_accuracy: 0.7154\n",
      "Epoch 28/100\n",
      "234/234 [==============================] - 0s 596us/step - loss: 0.7730 - accuracy: 0.7513 - val_loss: 0.8009 - val_accuracy: 0.7205\n",
      "Epoch 29/100\n",
      "234/234 [==============================] - 0s 604us/step - loss: 0.7588 - accuracy: 0.7551 - val_loss: 0.7877 - val_accuracy: 0.7333\n",
      "Epoch 30/100\n",
      "234/234 [==============================] - 0s 601us/step - loss: 0.7425 - accuracy: 0.7637 - val_loss: 0.7736 - val_accuracy: 0.7474\n",
      "Epoch 31/100\n",
      "234/234 [==============================] - 0s 615us/step - loss: 0.7273 - accuracy: 0.7701 - val_loss: 0.7620 - val_accuracy: 0.7385\n",
      "Epoch 32/100\n",
      "234/234 [==============================] - 0s 637us/step - loss: 0.7120 - accuracy: 0.7752 - val_loss: 0.7495 - val_accuracy: 0.7551\n",
      "Epoch 33/100\n",
      "234/234 [==============================] - 0s 632us/step - loss: 0.6994 - accuracy: 0.7850 - val_loss: 0.7302 - val_accuracy: 0.7615\n",
      "Epoch 34/100\n",
      "234/234 [==============================] - 0s 604us/step - loss: 0.6829 - accuracy: 0.7940 - val_loss: 0.7158 - val_accuracy: 0.7679\n",
      "Epoch 35/100\n",
      "234/234 [==============================] - 0s 598us/step - loss: 0.6671 - accuracy: 0.7953 - val_loss: 0.7104 - val_accuracy: 0.7679\n",
      "Epoch 36/100\n",
      "234/234 [==============================] - 0s 650us/step - loss: 0.6570 - accuracy: 0.7970 - val_loss: 0.6867 - val_accuracy: 0.7962\n",
      "Epoch 37/100\n",
      "234/234 [==============================] - 0s 600us/step - loss: 0.6389 - accuracy: 0.8085 - val_loss: 0.6887 - val_accuracy: 0.7795\n",
      "Epoch 38/100\n",
      "234/234 [==============================] - 0s 593us/step - loss: 0.6277 - accuracy: 0.8145 - val_loss: 0.6731 - val_accuracy: 0.7872\n",
      "Epoch 39/100\n",
      "234/234 [==============================] - 0s 589us/step - loss: 0.6160 - accuracy: 0.8192 - val_loss: 0.6457 - val_accuracy: 0.7936\n",
      "Epoch 40/100\n",
      "234/234 [==============================] - 0s 584us/step - loss: 0.6036 - accuracy: 0.8184 - val_loss: 0.6461 - val_accuracy: 0.7987\n",
      "Epoch 41/100\n",
      "234/234 [==============================] - 0s 594us/step - loss: 0.5890 - accuracy: 0.8252 - val_loss: 0.6207 - val_accuracy: 0.8128\n",
      "Epoch 42/100\n",
      "234/234 [==============================] - 0s 591us/step - loss: 0.5744 - accuracy: 0.8402 - val_loss: 0.6113 - val_accuracy: 0.8179\n",
      "Epoch 43/100\n",
      "234/234 [==============================] - 0s 611us/step - loss: 0.5626 - accuracy: 0.8359 - val_loss: 0.5988 - val_accuracy: 0.8154\n",
      "Epoch 44/100\n",
      "234/234 [==============================] - 0s 594us/step - loss: 0.5479 - accuracy: 0.8419 - val_loss: 0.5823 - val_accuracy: 0.8282\n",
      "Epoch 45/100\n",
      "234/234 [==============================] - 0s 595us/step - loss: 0.5372 - accuracy: 0.8496 - val_loss: 0.5893 - val_accuracy: 0.8231\n",
      "Epoch 46/100\n",
      "234/234 [==============================] - 0s 585us/step - loss: 0.5250 - accuracy: 0.8466 - val_loss: 0.5608 - val_accuracy: 0.8333\n",
      "Epoch 47/100\n",
      "234/234 [==============================] - 0s 593us/step - loss: 0.5121 - accuracy: 0.8534 - val_loss: 0.5576 - val_accuracy: 0.8269\n",
      "Epoch 48/100\n",
      "234/234 [==============================] - 0s 603us/step - loss: 0.5025 - accuracy: 0.8547 - val_loss: 0.5378 - val_accuracy: 0.8423\n",
      "Epoch 49/100\n",
      "234/234 [==============================] - 0s 600us/step - loss: 0.4896 - accuracy: 0.8585 - val_loss: 0.5493 - val_accuracy: 0.8282\n",
      "Epoch 50/100\n",
      "234/234 [==============================] - 0s 616us/step - loss: 0.4778 - accuracy: 0.8590 - val_loss: 0.5139 - val_accuracy: 0.8526\n",
      "Epoch 51/100\n",
      "234/234 [==============================] - 0s 634us/step - loss: 0.4688 - accuracy: 0.8628 - val_loss: 0.5072 - val_accuracy: 0.8372\n",
      "Epoch 52/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "234/234 [==============================] - 0s 603us/step - loss: 0.4583 - accuracy: 0.8654 - val_loss: 0.4952 - val_accuracy: 0.8500\n",
      "Epoch 53/100\n",
      "234/234 [==============================] - 0s 610us/step - loss: 0.4478 - accuracy: 0.8667 - val_loss: 0.4827 - val_accuracy: 0.8590\n",
      "Epoch 54/100\n",
      "234/234 [==============================] - 0s 601us/step - loss: 0.4344 - accuracy: 0.8714 - val_loss: 0.4841 - val_accuracy: 0.8397\n",
      "Epoch 55/100\n",
      "234/234 [==============================] - 0s 604us/step - loss: 0.4259 - accuracy: 0.8709 - val_loss: 0.4696 - val_accuracy: 0.8564\n",
      "Epoch 56/100\n",
      "234/234 [==============================] - 0s 585us/step - loss: 0.4192 - accuracy: 0.8761 - val_loss: 0.4617 - val_accuracy: 0.8603\n",
      "Epoch 57/100\n",
      "234/234 [==============================] - 0s 615us/step - loss: 0.4075 - accuracy: 0.8812 - val_loss: 0.4613 - val_accuracy: 0.8615\n",
      "Epoch 58/100\n",
      "234/234 [==============================] - 0s 644us/step - loss: 0.3974 - accuracy: 0.8863 - val_loss: 0.4323 - val_accuracy: 0.8782\n",
      "Epoch 59/100\n",
      "234/234 [==============================] - 0s 625us/step - loss: 0.3910 - accuracy: 0.8906 - val_loss: 0.4240 - val_accuracy: 0.8731\n",
      "Epoch 60/100\n",
      "234/234 [==============================] - 0s 663us/step - loss: 0.3810 - accuracy: 0.8863 - val_loss: 0.4338 - val_accuracy: 0.8654\n",
      "Epoch 61/100\n",
      "234/234 [==============================] - 0s 590us/step - loss: 0.3730 - accuracy: 0.8910 - val_loss: 0.4108 - val_accuracy: 0.8821\n",
      "Epoch 62/100\n",
      "234/234 [==============================] - 0s 577us/step - loss: 0.3660 - accuracy: 0.8949 - val_loss: 0.4125 - val_accuracy: 0.8769\n",
      "Epoch 63/100\n",
      "234/234 [==============================] - 0s 622us/step - loss: 0.3559 - accuracy: 0.8983 - val_loss: 0.3964 - val_accuracy: 0.8782\n",
      "Epoch 64/100\n",
      "234/234 [==============================] - 0s 575us/step - loss: 0.3493 - accuracy: 0.9013 - val_loss: 0.3896 - val_accuracy: 0.8872\n",
      "Epoch 65/100\n",
      "234/234 [==============================] - 0s 574us/step - loss: 0.3411 - accuracy: 0.8996 - val_loss: 0.3909 - val_accuracy: 0.8910\n",
      "Epoch 66/100\n",
      "234/234 [==============================] - 0s 622us/step - loss: 0.3363 - accuracy: 0.9056 - val_loss: 0.3695 - val_accuracy: 0.8936\n",
      "Epoch 67/100\n",
      "234/234 [==============================] - 0s 552us/step - loss: 0.3296 - accuracy: 0.9068 - val_loss: 0.3638 - val_accuracy: 0.8923\n",
      "Epoch 68/100\n",
      "234/234 [==============================] - 0s 565us/step - loss: 0.3218 - accuracy: 0.9056 - val_loss: 0.3559 - val_accuracy: 0.8923\n",
      "Epoch 69/100\n",
      "234/234 [==============================] - 0s 611us/step - loss: 0.3168 - accuracy: 0.9077 - val_loss: 0.3610 - val_accuracy: 0.8897\n",
      "Epoch 70/100\n",
      "234/234 [==============================] - 0s 591us/step - loss: 0.3077 - accuracy: 0.9115 - val_loss: 0.3448 - val_accuracy: 0.8962\n",
      "Epoch 71/100\n",
      "234/234 [==============================] - 0s 616us/step - loss: 0.3020 - accuracy: 0.9150 - val_loss: 0.3373 - val_accuracy: 0.9000\n",
      "Epoch 72/100\n",
      "234/234 [==============================] - 0s 600us/step - loss: 0.2982 - accuracy: 0.9137 - val_loss: 0.3326 - val_accuracy: 0.8962\n",
      "Epoch 73/100\n",
      "234/234 [==============================] - 0s 605us/step - loss: 0.2897 - accuracy: 0.9150 - val_loss: 0.3302 - val_accuracy: 0.9013\n",
      "Epoch 74/100\n",
      "234/234 [==============================] - 0s 645us/step - loss: 0.2848 - accuracy: 0.9162 - val_loss: 0.3234 - val_accuracy: 0.9077\n",
      "Epoch 75/100\n",
      "234/234 [==============================] - 0s 632us/step - loss: 0.2809 - accuracy: 0.9175 - val_loss: 0.3248 - val_accuracy: 0.8936\n",
      "Epoch 76/100\n",
      "234/234 [==============================] - 0s 615us/step - loss: 0.2747 - accuracy: 0.9179 - val_loss: 0.3133 - val_accuracy: 0.9090\n",
      "Epoch 77/100\n",
      "234/234 [==============================] - 0s 609us/step - loss: 0.2700 - accuracy: 0.9179 - val_loss: 0.3117 - val_accuracy: 0.9064\n",
      "Epoch 78/100\n",
      "234/234 [==============================] - 0s 619us/step - loss: 0.2639 - accuracy: 0.9231 - val_loss: 0.3059 - val_accuracy: 0.9064\n",
      "Epoch 79/100\n",
      "234/234 [==============================] - 0s 598us/step - loss: 0.2601 - accuracy: 0.9222 - val_loss: 0.3039 - val_accuracy: 0.9051\n",
      "Epoch 80/100\n",
      "234/234 [==============================] - 0s 599us/step - loss: 0.2568 - accuracy: 0.9248 - val_loss: 0.2964 - val_accuracy: 0.9103\n",
      "Epoch 81/100\n",
      "234/234 [==============================] - 0s 607us/step - loss: 0.2509 - accuracy: 0.9265 - val_loss: 0.3022 - val_accuracy: 0.9103\n",
      "Epoch 82/100\n",
      "234/234 [==============================] - 0s 611us/step - loss: 0.2465 - accuracy: 0.9303 - val_loss: 0.2899 - val_accuracy: 0.9090\n",
      "Epoch 83/100\n",
      "234/234 [==============================] - 0s 566us/step - loss: 0.2406 - accuracy: 0.9308 - val_loss: 0.2825 - val_accuracy: 0.9128\n",
      "Epoch 84/100\n",
      "234/234 [==============================] - 0s 614us/step - loss: 0.2384 - accuracy: 0.9308 - val_loss: 0.2822 - val_accuracy: 0.9141\n",
      "Epoch 85/100\n",
      "234/234 [==============================] - 0s 598us/step - loss: 0.2342 - accuracy: 0.9299 - val_loss: 0.2760 - val_accuracy: 0.9154\n",
      "Epoch 86/100\n",
      "234/234 [==============================] - 0s 590us/step - loss: 0.2301 - accuracy: 0.9329 - val_loss: 0.2749 - val_accuracy: 0.9128\n",
      "Epoch 87/100\n",
      "234/234 [==============================] - 0s 624us/step - loss: 0.2258 - accuracy: 0.9321 - val_loss: 0.2713 - val_accuracy: 0.9167\n",
      "Epoch 88/100\n",
      "234/234 [==============================] - 0s 608us/step - loss: 0.2229 - accuracy: 0.9308 - val_loss: 0.2738 - val_accuracy: 0.9154\n",
      "Epoch 89/100\n",
      "234/234 [==============================] - 0s 629us/step - loss: 0.2176 - accuracy: 0.9333 - val_loss: 0.2627 - val_accuracy: 0.9154\n",
      "Epoch 90/100\n",
      "234/234 [==============================] - 0s 628us/step - loss: 0.2143 - accuracy: 0.9372 - val_loss: 0.2727 - val_accuracy: 0.9115\n",
      "Epoch 91/100\n",
      "234/234 [==============================] - 0s 605us/step - loss: 0.2103 - accuracy: 0.9376 - val_loss: 0.2653 - val_accuracy: 0.9179\n",
      "Epoch 92/100\n",
      "234/234 [==============================] - 0s 633us/step - loss: 0.2093 - accuracy: 0.9363 - val_loss: 0.2540 - val_accuracy: 0.9154\n",
      "Epoch 93/100\n",
      "234/234 [==============================] - 0s 630us/step - loss: 0.2052 - accuracy: 0.9385 - val_loss: 0.2519 - val_accuracy: 0.9192\n",
      "Epoch 94/100\n",
      "234/234 [==============================] - 0s 611us/step - loss: 0.2004 - accuracy: 0.9410 - val_loss: 0.2511 - val_accuracy: 0.9141\n",
      "Epoch 95/100\n",
      "234/234 [==============================] - 0s 597us/step - loss: 0.1964 - accuracy: 0.9415 - val_loss: 0.2487 - val_accuracy: 0.9205\n",
      "Epoch 96/100\n",
      "234/234 [==============================] - 0s 590us/step - loss: 0.1977 - accuracy: 0.9415 - val_loss: 0.2424 - val_accuracy: 0.9205\n",
      "Epoch 97/100\n",
      "234/234 [==============================] - 0s 604us/step - loss: 0.1903 - accuracy: 0.9432 - val_loss: 0.2504 - val_accuracy: 0.9231\n",
      "Epoch 98/100\n",
      "234/234 [==============================] - 0s 631us/step - loss: 0.1863 - accuracy: 0.9457 - val_loss: 0.2402 - val_accuracy: 0.9218\n",
      "Epoch 99/100\n",
      "234/234 [==============================] - 0s 666us/step - loss: 0.1852 - accuracy: 0.9440 - val_loss: 0.2337 - val_accuracy: 0.9244\n",
      "Epoch 100/100\n",
      "234/234 [==============================] - 0s 645us/step - loss: 0.1817 - accuracy: 0.9483 - val_loss: 0.2346 - val_accuracy: 0.9205\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.97      0.95       156\n",
      "           1       0.93      0.97      0.95       156\n",
      "           2       0.94      0.97      0.96       156\n",
      "           3       0.85      0.70      0.77       156\n",
      "           4       0.83      0.90      0.86       156\n",
      "\n",
      "    accuracy                           0.90       780\n",
      "   macro avg       0.90      0.90      0.90       780\n",
      "weighted avg       0.90      0.90      0.90       780\n",
      "\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 100\n",
    "BATCH_SIZE = 10\n",
    "model = getNetwork()\n",
    "history = model.fit(X_train, y_train, epochs=EPOCHS, batch_size=BATCH_SIZE, validation_split=0.25)\n",
    "pred = model.predict(X_test)\n",
    "pred = np.argmax(pred, axis=1)\n",
    "report = classification_report(y_test, pred)\n",
    "classification_report_csv(report, \"NN\")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export Models in C code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural network with TinyMLGen\n",
    "with open(tasks[choosenIndex] + '/exportedModels/NNmodel.h', 'w') as f:\n",
    "    f.write(tiny.port(model, optimize=False))\n",
    "\n",
    "# Classifiers with MicroMLGen\n",
    "for name, model in models:\n",
    "    prepath = tasks[choosenIndex] + '/exportedModels/'\n",
    "    path = prepath + name + '.h'\n",
    "    with open(path, 'w') as f:\n",
    "        f.write(port(model, optimize=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Valutazione Inferance Rate medio (Intensità)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "csv = read_csv(\"InfTimeReport.csv\")\n",
    "g = sbs.barplot(x=csv['Algoritmo'], y=csv['InfTime'])\n",
    "g.set_yscale(\"log\")\n",
    "plt.ylabel(\"Inference Time\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Memoria occupata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "csv = read_csv(\"MemOccupationReport.csv\")\n",
    "g = sbs.barplot(x=csv['Algoritmo'], y=csv['MemOccupata'])\n",
    "g.set_yscale('log')\n",
    "plt.ylabel(\"MemOccupata in Byte\")\n",
    "plt.show()\n",
    "# SVC in overflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

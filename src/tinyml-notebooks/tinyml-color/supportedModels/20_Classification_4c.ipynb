{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting BMI from psychological variables - Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\externals\\six.py:31: DeprecationWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
      "  \"(https://pypi.org/project/six/).\", DeprecationWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\externals\\joblib\\__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# Load libraries\n",
    "import numpy as np\n",
    "from numpy import arange\n",
    "#\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#\n",
    "import pandas as pd\n",
    "from pandas import read_csv\n",
    "\n",
    "from imblearn.over_sampling import SMOTE, SMOTENC\n",
    "from sklearn.metrics import confusion_matrix,  classification_report, f1_score\n",
    "from sklearn.model_selection import train_test_split, KFold,StratifiedKFold, cross_val_score, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier, RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y_true, y_pred, classes, normalize=False, title=None, cmap=plt.cm.Blues):\n",
    "    if not title:\n",
    "        if normalize:\n",
    "            title = 'Normalized confusion matrix'\n",
    "        else:\n",
    "            title = 'Confusion matrix, without normalization'\n",
    "\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    classes = classes[unique_labels(y_true, y_pred)]\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "\n",
    "    ax.set(xticks=np.arange(cm.shape[1]),\n",
    "           yticks=np.arange(cm.shape[0]),\n",
    "           xticklabels=classes, yticklabels=classes,\n",
    "           title=title,\n",
    "           ylabel='True label',\n",
    "           xlabel='Predicted label')\n",
    "\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\", rotation_mode=\"anchor\")\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], fmt),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    fig.tight_layout()\n",
    "    return ax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(221, 52)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv(\"data/10_data_all_3c.csv\", sep=';')\n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['genere', 'et√†', 'BMI', 'BDIT0', 'Stai_statoT0', 'Stai_trattoT0',\n",
       "       'TEI_t0', 'Bes_t0', 'Rea_t0', 'Supp_t0', 'Happy_T0', 'BMIClass',\n",
       "       'etnia_0', 'etnia_1', 'etnia_2', 'etnia_3', 'etnia_4', 'etnia_5',\n",
       "       'stato_civile_0.0', 'stato_civile_1.0', 'stato_civile_2.0',\n",
       "       'stato_civile_3.0', 'stato_civile_4.0', 'stato_civile_5.0',\n",
       "       'professione_0.0', 'professione_2.0', 'professione_3.0',\n",
       "       'professione_4.0', 'professione_5.0', 'titolo_studio_0.0',\n",
       "       'titolo_studio_1.0', 'titolo_studio_2.0', 'titolo_studio_3.0',\n",
       "       'titolo_studio_4.0', 'titolo_studio_5.0', 'titolo_studio_6.0',\n",
       "       'titolo_studio_7.0', 'Psicofarmaci_0', 'Psicofarmaci_1',\n",
       "       'Psicofarmaci_2', 'lutti_0.0', 'lutti_1.0', 'lutti_2.0',\n",
       "       'all_sostegno_0.0', 'all_sostegno_1.0', 'all_sostegno_2.0',\n",
       "       'all_sostegno_3.0', 'all_sostegno_4.0', 'disturbi_0.0', 'disturbi_1.0',\n",
       "       'disturbi_2.0', 'disturbi_3.0'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset[[\"BMIClass\", \"TEI_t0\", \"Rea_t0\", \"Happy_T0\", \"BDIT0\", \"Stai_trattoT0\", \"Bes_t0\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BMIClass</th>\n",
       "      <th>TEI_t0</th>\n",
       "      <th>Rea_t0</th>\n",
       "      <th>Happy_T0</th>\n",
       "      <th>BDIT0</th>\n",
       "      <th>Stai_trattoT0</th>\n",
       "      <th>Bes_t0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>6.37</td>\n",
       "      <td>30.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>4.10</td>\n",
       "      <td>23.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5.10</td>\n",
       "      <td>23.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>5.10</td>\n",
       "      <td>33.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>5.30</td>\n",
       "      <td>24.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   BMIClass  TEI_t0  Rea_t0  Happy_T0  BDIT0  Stai_trattoT0  Bes_t0\n",
       "0         2    6.37    30.0      90.0    4.0           27.0     6.0\n",
       "1         2    4.10    23.0      55.0   23.0           65.0    23.0\n",
       "2         2    5.10    23.0      77.0    8.0           45.0     9.0\n",
       "3         3    5.10    33.0      63.0   10.0           46.0    15.0\n",
       "4         2    5.30    24.0      84.0    3.0           31.0     0.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4    136\n",
       "2     60\n",
       "3     25\n",
       "Name: BMIClass, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"BMIClass\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Spotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test options and evaluation metric\n",
    "num_folds = 4\n",
    "seed = 42\n",
    "scoring = 'f1_macro'\n",
    "\n",
    "X = dataset.drop([\"BMIClass\"], axis=1)\n",
    "y = dataset[\"BMIClass\"]\n",
    "y = y - 2\n",
    "#class_names = np.array([\"underweight\", \"normal\", \"overweight\", \"obesity\"])\n",
    "class_names = np.array([\"normal\", \"overweight\", \"obesity\"])\n",
    "\n",
    "sm = SMOTE(random_state=seed, k_neighbors=7, sampling_strategy=\"not majority\")\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state = seed, stratify=y) \n",
    "X_train_res, y_train_res = sm.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18     0\n",
       "115    2\n",
       "211    2\n",
       "83     0\n",
       "209    1\n",
       "132    2\n",
       "86     0\n",
       "194    2\n",
       "52     2\n",
       "77     0\n",
       "198    2\n",
       "172    2\n",
       "81     0\n",
       "10     1\n",
       "176    2\n",
       "93     2\n",
       "200    2\n",
       "217    2\n",
       "22     2\n",
       "54     0\n",
       "35     0\n",
       "49     0\n",
       "88     0\n",
       "99     2\n",
       "29     0\n",
       "20     1\n",
       "109    2\n",
       "118    2\n",
       "0      0\n",
       "146    2\n",
       "      ..\n",
       "156    2\n",
       "183    2\n",
       "166    2\n",
       "63     0\n",
       "104    2\n",
       "39     1\n",
       "169    2\n",
       "192    2\n",
       "119    2\n",
       "180    2\n",
       "219    2\n",
       "184    2\n",
       "62     0\n",
       "210    2\n",
       "92     2\n",
       "201    2\n",
       "218    2\n",
       "202    2\n",
       "25     2\n",
       "207    2\n",
       "112    2\n",
       "98     2\n",
       "90     0\n",
       "68     0\n",
       "197    2\n",
       "212    2\n",
       "47     1\n",
       "163    2\n",
       "105    2\n",
       "187    2\n",
       "Name: BMIClass, Length: 176, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spot-Check Algorithms\n",
    "models = []\n",
    "'''\n",
    "models.append(('KNN' , KNeighborsClassifier()))\n",
    "models.append(('CART' , DecisionTreeClassifier(random_state=seed)))\n",
    "models.append(('SVC' , SVC(gamma='auto', random_state=seed)))\n",
    "models.append(('MLP' , MLPClassifier(hidden_layer_sizes=(100,), max_iter=500, random_state=seed)))\n",
    "models.append(('AB',  AdaBoostClassifier(random_state=seed, n_estimators = 50)))\n",
    "models.append(('GB', GradientBoostingClassifier(random_state=seed, n_estimators = 50)))\n",
    "models.append(('RF',  RandomForestClassifier(random_state=seed, n_estimators = 50)))\n",
    "models.append(('ET',  ExtraTreesClassifier(random_state=seed, n_estimators = 50)))\n",
    "'''\n",
    "models.append(('KNN' , Pipeline([('Scaler', StandardScaler()),('KNN', KNeighborsClassifier())])))\n",
    "models.append(('CART' , Pipeline([('Scaler', StandardScaler()),('CART', DecisionTreeClassifier(random_state=seed))])))\n",
    "models.append(('SVC' , Pipeline([('Scaler', StandardScaler()),('SVC', SVC(gamma='auto', random_state=seed))])))\n",
    "models.append(('MLP' , Pipeline([('Scaler', StandardScaler()),('MLP', MLPClassifier(hidden_layer_sizes=(100,), max_iter=500, random_state=seed))])))\n",
    "models.append(('AB',  Pipeline([('Scaler', StandardScaler()),('AB', AdaBoostClassifier(random_state=seed, n_estimators = 50))])))\n",
    "models.append(('GB', Pipeline([('Scaler', StandardScaler()),('GB', GradientBoostingClassifier(random_state=seed, n_estimators = 50))])))\n",
    "models.append(('RF',  Pipeline([('Scaler', StandardScaler()),('RF', RandomForestClassifier(random_state=seed, n_estimators = 50))])))\n",
    "models.append(('ET',  Pipeline([('Scaler', StandardScaler()),('ET', ExtraTreesClassifier(random_state=seed, n_estimators = 50))])))\n",
    "\n",
    "\n",
    "\n",
    "results = []\n",
    "names = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN - 0,81 0,07\n",
      "CART - 0,78 0,07\n",
      "SVC - 0,85 0,07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP - 0,84 0,05\n",
      "AB - 0,57 0,15\n",
      "GB - 0,80 0,06\n",
      "RF - 0,80 0,07\n",
      "ET - 0,82 0,06\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "names = []\n",
    "for name, model in models:\n",
    "    kf = StratifiedKFold(n_splits=num_folds, random_state=seed)\n",
    "    sm = SMOTE(random_state=seed, k_neighbors=7, sampling_strategy=\"not majority\")\n",
    "    cv_results = np.array([])\n",
    "    for train_idx, test_idx, in kf.split(X_train, y_train):\n",
    "        X_cross_train, y_cross_train = X_train.iloc[train_idx], y_train.iloc[train_idx]\n",
    "        X_cross_test, y_cross_test = X_train.iloc[test_idx], y_train.iloc[test_idx]\n",
    "        X_cross_train, y_cross_train = sm.fit_sample(X_cross_train, y_cross_train)\n",
    "\n",
    "        model.fit(X_cross_train, y_cross_train)  \n",
    "        y_pred = model.predict(X_cross_test)\n",
    "        f1s = f1_score(y_cross_test, y_pred, average=\"weighted\")\n",
    "        cv_results = np.append(cv_results, [f1s])\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    #msg = \"%s - %f - %f\" % (name, cv_results.mean(), cv_results.std())\n",
    "    msg = \"{} - {:.2f} {:.2f}\".format(name, cv_results.mean(), cv_results.std()).replace('.', ',')\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compare Algorithms\n",
    "fig = plt.figure(figsize=(10,5))\n",
    "fig.suptitle('Algorithms Comparison')\n",
    "ax = fig.add_subplot(111)\n",
    "plt.boxplot(results)\n",
    "ax.set_xticklabels(names)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Valutazione dei migliori algoritmi (MLP, GB e RF) su test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.58      0.61        12\n",
      "           1       0.29      0.40      0.33         5\n",
      "           2       0.93      0.89      0.91        28\n",
      "\n",
      "    accuracy                           0.76        45\n",
      "   macro avg       0.62      0.63      0.62        45\n",
      "weighted avg       0.78      0.76      0.77        45\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "model = MLPClassifier(hidden_layer_sizes=(100,), max_iter=500, random_state=seed)\n",
    "pipeline = Pipeline([('Scaler', StandardScaler()),('Model', model)])\n",
    "pipeline.fit(X_train_res, y_train_res) \n",
    "y_pred = pipeline.predict(X_test) \n",
    "print(\"MLP\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GB\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.58      0.58        12\n",
      "           1       0.33      0.40      0.36         5\n",
      "           2       0.96      0.93      0.95        28\n",
      "\n",
      "    accuracy                           0.78        45\n",
      "   macro avg       0.63      0.64      0.63        45\n",
      "weighted avg       0.79      0.78      0.78        45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = GradientBoostingClassifier(random_state=seed, n_estimators = 50)\n",
    "pipeline = Pipeline([('Scaler', StandardScaler()),('Model', model)])\n",
    "pipeline.fit(X_train_res, y_train_res) \n",
    "y_pred = pipeline.predict(X_test) \n",
    "print(\"GB\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.67      0.64        12\n",
      "           1       0.40      0.40      0.40         5\n",
      "           2       0.96      0.93      0.95        28\n",
      "\n",
      "    accuracy                           0.80        45\n",
      "   macro avg       0.66      0.67      0.66        45\n",
      "weighted avg       0.81      0.80      0.80        45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier(random_state=seed, n_estimators = 50)\n",
    "pipeline = Pipeline([('Scaler', StandardScaler()),('Model', model)])\n",
    "pipeline.fit(X_train_res, y_train_res) \n",
    "y_pred = pipeline.predict(X_test) \n",
    "print(\"RF\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improve Results With Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### MLP Tunining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.1   , 0.01  , 0.001 , 0.0001])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "10.0 ** -np.arange(1, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing 1/2880\n",
      "identity lbfgs 500 0.1 17 (50,): Weighted 0.828542 (0.053537)\n",
      "identity lbfgs 500 0.1 17 (50,): Macro 0.727234 (0.071227)\n",
      "Testing 2/2880\n",
      "identity lbfgs 500 0.1 17 (100,): Weighted 0.828542 (0.053537)\n",
      "identity lbfgs 500 0.1 17 (100,): Macro 0.727234 (0.071227)\n",
      "Testing 3/2880\n",
      "identity lbfgs 500 0.1 17 (150,): Weighted 0.828542 (0.053537)\n",
      "identity lbfgs 500 0.1 17 (150,): Macro 0.727234 (0.071227)\n",
      "Testing 4/2880\n",
      "identity lbfgs 500 0.1 17 (200,): Weighted 0.831829 (0.053027)\n",
      "identity lbfgs 500 0.1 17 (200,): Macro 0.731083 (0.070659)\n",
      "Testing 5/2880\n",
      "identity lbfgs 500 0.1 29 (50,): Weighted 0.828542 (0.053537)\n",
      "identity lbfgs 500 0.1 29 (50,): Macro 0.727234 (0.071227)\n",
      "Testing 6/2880\n",
      "identity lbfgs 500 0.1 29 (100,): Weighted 0.828542 (0.053537)\n",
      "identity lbfgs 500 0.1 29 (100,): Macro 0.727234 (0.071227)\n",
      "Testing 7/2880\n",
      "identity lbfgs 500 0.1 29 (150,): Weighted 0.831829 (0.053027)\n",
      "identity lbfgs 500 0.1 29 (150,): Macro 0.731083 (0.070659)\n",
      "Testing 8/2880\n",
      "identity lbfgs 500 0.1 29 (200,): Weighted 0.828542 (0.053537)\n",
      "identity lbfgs 500 0.1 29 (200,): Macro 0.727234 (0.071227)\n",
      "Testing 9/2880\n",
      "identity lbfgs 500 0.1 42 (50,): Weighted 0.828542 (0.053537)\n",
      "identity lbfgs 500 0.1 42 (50,): Macro 0.727234 (0.071227)\n",
      "Testing 10/2880\n",
      "identity lbfgs 500 0.1 42 (100,): Weighted 0.828542 (0.053537)\n",
      "identity lbfgs 500 0.1 42 (100,): Macro 0.727234 (0.071227)\n",
      "Testing 11/2880\n",
      "identity lbfgs 500 0.1 42 (150,): Weighted 0.828542 (0.053537)\n",
      "identity lbfgs 500 0.1 42 (150,): Macro 0.727234 (0.071227)\n",
      "Testing 12/2880\n",
      "identity lbfgs 500 0.1 42 (200,): Weighted 0.828542 (0.053537)\n",
      "identity lbfgs 500 0.1 42 (200,): Macro 0.727234 (0.071227)\n",
      "Testing 13/2880\n",
      "identity lbfgs 500 0.1 76 (50,): Weighted 0.828542 (0.053537)\n",
      "identity lbfgs 500 0.1 76 (50,): Macro 0.727234 (0.071227)\n",
      "Testing 14/2880\n",
      "identity lbfgs 500 0.1 76 (100,): Weighted 0.828542 (0.053537)\n",
      "identity lbfgs 500 0.1 76 (100,): Macro 0.727234 (0.071227)\n",
      "Testing 15/2880\n",
      "identity lbfgs 500 0.1 76 (150,): Weighted 0.831829 (0.053027)\n",
      "identity lbfgs 500 0.1 76 (150,): Macro 0.731083 (0.070659)\n",
      "Testing 16/2880\n",
      "identity lbfgs 500 0.1 76 (200,): Weighted 0.828542 (0.053537)\n",
      "identity lbfgs 500 0.1 76 (200,): Macro 0.727234 (0.071227)\n",
      "Testing 17/2880\n",
      "identity lbfgs 500 0.1 112 (50,): Weighted 0.828542 (0.053537)\n",
      "identity lbfgs 500 0.1 112 (50,): Macro 0.727234 (0.071227)\n",
      "Testing 18/2880\n",
      "identity lbfgs 500 0.1 112 (100,): Weighted 0.831829 (0.053027)\n",
      "identity lbfgs 500 0.1 112 (100,): Macro 0.731083 (0.070659)\n",
      "Testing 19/2880\n",
      "identity lbfgs 500 0.1 112 (150,): Weighted 0.831829 (0.053027)\n",
      "identity lbfgs 500 0.1 112 (150,): Macro 0.731083 (0.070659)\n",
      "Testing 20/2880\n",
      "identity lbfgs 500 0.1 112 (200,): Weighted 0.831829 (0.053027)\n",
      "identity lbfgs 500 0.1 112 (200,): Macro 0.731083 (0.070659)\n",
      "Testing 21/2880\n",
      "identity lbfgs 500 0.01 17 (50,): Weighted 0.828542 (0.053537)\n",
      "identity lbfgs 500 0.01 17 (50,): Macro 0.727234 (0.071227)\n",
      "Testing 22/2880\n",
      "identity lbfgs 500 0.01 17 (100,): Weighted 0.828542 (0.053537)\n",
      "identity lbfgs 500 0.01 17 (100,): Macro 0.727234 (0.071227)\n",
      "Testing 23/2880\n",
      "identity lbfgs 500 0.01 17 (150,): Weighted 0.828542 (0.053537)\n",
      "identity lbfgs 500 0.01 17 (150,): Macro 0.727234 (0.071227)\n",
      "Testing 24/2880\n",
      "identity lbfgs 500 0.01 17 (200,): Weighted 0.828542 (0.053537)\n",
      "identity lbfgs 500 0.01 17 (200,): Macro 0.727234 (0.071227)\n",
      "Testing 25/2880\n",
      "identity lbfgs 500 0.01 29 (50,): Weighted 0.828542 (0.053537)\n",
      "identity lbfgs 500 0.01 29 (50,): Macro 0.727234 (0.071227)\n",
      "Testing 26/2880\n",
      "identity lbfgs 500 0.01 29 (100,): Weighted 0.828542 (0.053537)\n",
      "identity lbfgs 500 0.01 29 (100,): Macro 0.727234 (0.071227)\n",
      "Testing 27/2880\n",
      "identity lbfgs 500 0.01 29 (150,): Weighted 0.828542 (0.053537)\n",
      "identity lbfgs 500 0.01 29 (150,): Macro 0.727234 (0.071227)\n",
      "Testing 28/2880\n",
      "identity lbfgs 500 0.01 29 (200,): Weighted 0.828542 (0.053537)\n",
      "identity lbfgs 500 0.01 29 (200,): Macro 0.727234 (0.071227)\n",
      "Testing 29/2880\n",
      "identity lbfgs 500 0.01 42 (50,): Weighted 0.828542 (0.053537)\n",
      "identity lbfgs 500 0.01 42 (50,): Macro 0.727234 (0.071227)\n",
      "Testing 30/2880\n",
      "identity lbfgs 500 0.01 42 (100,): Weighted 0.828542 (0.053537)\n",
      "identity lbfgs 500 0.01 42 (100,): Macro 0.727234 (0.071227)\n",
      "Testing 31/2880\n",
      "identity lbfgs 500 0.01 42 (150,): Weighted 0.828542 (0.053537)\n",
      "identity lbfgs 500 0.01 42 (150,): Macro 0.727234 (0.071227)\n",
      "Testing 32/2880\n",
      "identity lbfgs 500 0.01 42 (200,): Weighted 0.828542 (0.053537)\n",
      "identity lbfgs 500 0.01 42 (200,): Macro 0.727234 (0.071227)\n",
      "Testing 33/2880\n",
      "identity lbfgs 500 0.01 76 (50,): Weighted 0.828542 (0.053537)\n",
      "identity lbfgs 500 0.01 76 (50,): Macro 0.727234 (0.071227)\n",
      "Testing 34/2880\n",
      "identity lbfgs 500 0.01 76 (100,): Weighted 0.828542 (0.053537)\n",
      "identity lbfgs 500 0.01 76 (100,): Macro 0.727234 (0.071227)\n",
      "Testing 35/2880\n",
      "identity lbfgs 500 0.01 76 (150,): Weighted 0.828542 (0.053537)\n",
      "identity lbfgs 500 0.01 76 (150,): Macro 0.727234 (0.071227)\n",
      "Testing 36/2880\n",
      "identity lbfgs 500 0.01 76 (200,): Weighted 0.828542 (0.053537)\n",
      "identity lbfgs 500 0.01 76 (200,): Macro 0.727234 (0.071227)\n",
      "Testing 37/2880\n",
      "identity lbfgs 500 0.01 112 (50,): Weighted 0.828542 (0.053537)\n",
      "identity lbfgs 500 0.01 112 (50,): Macro 0.727234 (0.071227)\n",
      "Testing 38/2880\n",
      "identity lbfgs 500 0.01 112 (100,): Weighted 0.828542 (0.053537)\n",
      "identity lbfgs 500 0.01 112 (100,): Macro 0.727234 (0.071227)\n",
      "Testing 39/2880\n",
      "identity lbfgs 500 0.01 112 (150,): Weighted 0.828542 (0.053537)\n",
      "identity lbfgs 500 0.01 112 (150,): Macro 0.727234 (0.071227)\n",
      "Testing 40/2880\n",
      "identity lbfgs 500 0.01 112 (200,): Weighted 0.828542 (0.053537)\n",
      "identity lbfgs 500 0.01 112 (200,): Macro 0.727234 (0.071227)\n",
      "Testing 41/2880\n",
      "identity lbfgs 500 0.001 17 (50,): Weighted 0.828542 (0.053537)\n",
      "identity lbfgs 500 0.001 17 (50,): Macro 0.727234 (0.071227)\n",
      "Testing 42/2880\n",
      "identity lbfgs 500 0.001 17 (100,): Weighted 0.828542 (0.053537)\n",
      "identity lbfgs 500 0.001 17 (100,): Macro 0.727234 (0.071227)\n",
      "Testing 43/2880\n",
      "identity lbfgs 500 0.001 17 (150,): Weighted 0.828542 (0.053537)\n",
      "identity lbfgs 500 0.001 17 (150,): Macro 0.727234 (0.071227)\n",
      "Testing 44/2880\n",
      "identity lbfgs 500 0.001 17 (200,): Weighted 0.828542 (0.053537)\n",
      "identity lbfgs 500 0.001 17 (200,): Macro 0.727234 (0.071227)\n",
      "Testing 45/2880\n",
      "identity lbfgs 500 0.001 29 (50,): Weighted 0.828542 (0.053537)\n",
      "identity lbfgs 500 0.001 29 (50,): Macro 0.727234 (0.071227)\n",
      "Testing 46/2880\n",
      "identity lbfgs 500 0.001 29 (100,): Weighted 0.828542 (0.053537)\n",
      "identity lbfgs 500 0.001 29 (100,): Macro 0.727234 (0.071227)\n",
      "Testing 47/2880\n",
      "identity lbfgs 500 0.001 29 (150,): Weighted 0.828542 (0.053537)\n",
      "identity lbfgs 500 0.001 29 (150,): Macro 0.727234 (0.071227)\n",
      "Testing 48/2880\n",
      "identity lbfgs 500 0.001 29 (200,): Weighted 0.828542 (0.053537)\n",
      "identity lbfgs 500 0.001 29 (200,): Macro 0.727234 (0.071227)\n",
      "Testing 49/2880\n",
      "identity lbfgs 500 0.001 42 (50,): Weighted 0.828542 (0.053537)\n",
      "identity lbfgs 500 0.001 42 (50,): Macro 0.727234 (0.071227)\n",
      "Testing 50/2880\n",
      "identity lbfgs 500 0.001 42 (100,): Weighted 0.828542 (0.053537)\n",
      "identity lbfgs 500 0.001 42 (100,): Macro 0.727234 (0.071227)\n",
      "Testing 51/2880\n",
      "identity lbfgs 500 0.001 42 (150,): Weighted 0.828542 (0.053537)\n",
      "identity lbfgs 500 0.001 42 (150,): Macro 0.727234 (0.071227)\n",
      "Testing 52/2880\n",
      "identity lbfgs 500 0.001 42 (200,): Weighted 0.828542 (0.053537)\n",
      "identity lbfgs 500 0.001 42 (200,): Macro 0.727234 (0.071227)\n",
      "Testing 53/2880\n",
      "identity lbfgs 500 0.001 76 (50,): Weighted 0.828542 (0.053537)\n",
      "identity lbfgs 500 0.001 76 (50,): Macro 0.727234 (0.071227)\n",
      "Testing 54/2880\n",
      "identity lbfgs 500 0.001 76 (100,): Weighted 0.828542 (0.053537)\n",
      "identity lbfgs 500 0.001 76 (100,): Macro 0.727234 (0.071227)\n",
      "Testing 55/2880\n",
      "identity lbfgs 500 0.001 76 (150,): Weighted 0.828542 (0.053537)\n",
      "identity lbfgs 500 0.001 76 (150,): Macro 0.727234 (0.071227)\n",
      "Testing 56/2880\n",
      "identity lbfgs 500 0.001 76 (200,): Weighted 0.828542 (0.053537)\n",
      "identity lbfgs 500 0.001 76 (200,): Macro 0.727234 (0.071227)\n",
      "Testing 57/2880\n",
      "identity lbfgs 500 0.001 112 (50,): Weighted 0.828542 (0.053537)\n",
      "identity lbfgs 500 0.001 112 (50,): Macro 0.727234 (0.071227)\n",
      "Testing 58/2880\n",
      "identity lbfgs 500 0.001 112 (100,): Weighted 0.828542 (0.053537)\n",
      "identity lbfgs 500 0.001 112 (100,): Macro 0.727234 (0.071227)\n",
      "Testing 59/2880\n",
      "identity lbfgs 500 0.001 112 (150,): Weighted 0.828542 (0.053537)\n",
      "identity lbfgs 500 0.001 112 (150,): Macro 0.727234 (0.071227)\n",
      "Testing 60/2880\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "identity lbfgs 500 0.001 112 (200,): Weighted 0.828542 (0.053537)\n",
      "identity lbfgs 500 0.001 112 (200,): Macro 0.727234 (0.071227)\n",
      "Testing 61/2880\n",
      "identity lbfgs 500 0.0001 17 (50,): Weighted 0.828542 (0.053537)\n",
      "identity lbfgs 500 0.0001 17 (50,): Macro 0.727234 (0.071227)\n",
      "Testing 62/2880\n",
      "identity lbfgs 500 0.0001 17 (100,): Weighted 0.828542 (0.053537)\n",
      "identity lbfgs 500 0.0001 17 (100,): Macro 0.727234 (0.071227)\n",
      "Testing 63/2880\n",
      "identity lbfgs 500 0.0001 17 (150,): Weighted 0.828542 (0.053537)\n",
      "identity lbfgs 500 0.0001 17 (150,): Macro 0.727234 (0.071227)\n",
      "Testing 64/2880\n",
      "identity lbfgs 500 0.0001 17 (200,): Weighted 0.828542 (0.053537)\n",
      "identity lbfgs 500 0.0001 17 (200,): Macro 0.727234 (0.071227)\n",
      "Testing 65/2880\n",
      "identity lbfgs 500 0.0001 29 (50,): Weighted 0.828542 (0.053537)\n",
      "identity lbfgs 500 0.0001 29 (50,): Macro 0.727234 (0.071227)\n",
      "Testing 66/2880\n",
      "identity lbfgs 500 0.0001 29 (100,): Weighted 0.828542 (0.053537)\n",
      "identity lbfgs 500 0.0001 29 (100,): Macro 0.727234 (0.071227)\n",
      "Testing 67/2880\n",
      "identity lbfgs 500 0.0001 29 (150,): Weighted 0.828542 (0.053537)\n",
      "identity lbfgs 500 0.0001 29 (150,): Macro 0.727234 (0.071227)\n",
      "Testing 68/2880\n",
      "identity lbfgs 500 0.0001 29 (200,): Weighted 0.828542 (0.053537)\n",
      "identity lbfgs 500 0.0001 29 (200,): Macro 0.727234 (0.071227)\n",
      "Testing 69/2880\n",
      "identity lbfgs 500 0.0001 42 (50,): Weighted 0.828542 (0.053537)\n",
      "identity lbfgs 500 0.0001 42 (50,): Macro 0.727234 (0.071227)\n",
      "Testing 70/2880\n",
      "identity lbfgs 500 0.0001 42 (100,): Weighted 0.828542 (0.053537)\n",
      "identity lbfgs 500 0.0001 42 (100,): Macro 0.727234 (0.071227)\n",
      "Testing 71/2880\n",
      "identity lbfgs 500 0.0001 42 (150,): Weighted 0.828542 (0.053537)\n",
      "identity lbfgs 500 0.0001 42 (150,): Macro 0.727234 (0.071227)\n",
      "Testing 72/2880\n",
      "identity lbfgs 500 0.0001 42 (200,): Weighted 0.828542 (0.053537)\n",
      "identity lbfgs 500 0.0001 42 (200,): Macro 0.727234 (0.071227)\n",
      "Testing 73/2880\n",
      "identity lbfgs 500 0.0001 76 (50,): Weighted 0.828542 (0.053537)\n",
      "identity lbfgs 500 0.0001 76 (50,): Macro 0.727234 (0.071227)\n",
      "Testing 74/2880\n",
      "identity lbfgs 500 0.0001 76 (100,): Weighted 0.828542 (0.053537)\n",
      "identity lbfgs 500 0.0001 76 (100,): Macro 0.727234 (0.071227)\n",
      "Testing 75/2880\n",
      "identity lbfgs 500 0.0001 76 (150,): Weighted 0.828542 (0.053537)\n",
      "identity lbfgs 500 0.0001 76 (150,): Macro 0.727234 (0.071227)\n",
      "Testing 76/2880\n",
      "identity lbfgs 500 0.0001 76 (200,): Weighted 0.828542 (0.053537)\n",
      "identity lbfgs 500 0.0001 76 (200,): Macro 0.727234 (0.071227)\n",
      "Testing 77/2880\n",
      "identity lbfgs 500 0.0001 112 (50,): Weighted 0.828542 (0.053537)\n",
      "identity lbfgs 500 0.0001 112 (50,): Macro 0.727234 (0.071227)\n",
      "Testing 78/2880\n",
      "identity lbfgs 500 0.0001 112 (100,): Weighted 0.828542 (0.053537)\n",
      "identity lbfgs 500 0.0001 112 (100,): Macro 0.727234 (0.071227)\n",
      "Testing 79/2880\n",
      "identity lbfgs 500 0.0001 112 (150,): Weighted 0.828542 (0.053537)\n",
      "identity lbfgs 500 0.0001 112 (150,): Macro 0.727234 (0.071227)\n",
      "Testing 80/2880\n",
      "identity lbfgs 500 0.0001 112 (200,): Weighted 0.828542 (0.053537)\n",
      "identity lbfgs 500 0.0001 112 (200,): Macro 0.727234 (0.071227)\n",
      "Testing 81/2880\n",
      "identity lbfgs 1000 0.1 17 (50,): Weighted 0.828542 (0.053537)\n",
      "identity lbfgs 1000 0.1 17 (50,): Macro 0.727234 (0.071227)\n",
      "Testing 82/2880\n",
      "identity lbfgs 1000 0.1 17 (100,): Weighted 0.828542 (0.053537)\n",
      "identity lbfgs 1000 0.1 17 (100,): Macro 0.727234 (0.071227)\n",
      "Testing 83/2880\n",
      "identity lbfgs 1000 0.1 17 (150,): Weighted 0.828542 (0.053537)\n",
      "identity lbfgs 1000 0.1 17 (150,): Macro 0.727234 (0.071227)\n",
      "Testing 84/2880\n",
      "identity lbfgs 1000 0.1 17 (200,): Weighted 0.831829 (0.053027)\n",
      "identity lbfgs 1000 0.1 17 (200,): Macro 0.731083 (0.070659)\n",
      "Testing 85/2880\n",
      "identity lbfgs 1000 0.1 29 (50,): Weighted 0.828542 (0.053537)\n",
      "identity lbfgs 1000 0.1 29 (50,): Macro 0.727234 (0.071227)\n",
      "Testing 86/2880\n",
      "identity lbfgs 1000 0.1 29 (100,): Weighted 0.828542 (0.053537)\n",
      "identity lbfgs 1000 0.1 29 (100,): Macro 0.727234 (0.071227)\n",
      "Testing 87/2880\n",
      "identity lbfgs 1000 0.1 29 (150,): Weighted 0.831829 (0.053027)\n",
      "identity lbfgs 1000 0.1 29 (150,): Macro 0.731083 (0.070659)\n",
      "Testing 88/2880\n",
      "identity lbfgs 1000 0.1 29 (200,): Weighted 0.828542 (0.053537)\n",
      "identity lbfgs 1000 0.1 29 (200,): Macro 0.727234 (0.071227)\n",
      "Testing 89/2880\n",
      "identity lbfgs 1000 0.1 42 (50,): Weighted 0.828542 (0.053537)\n",
      "identity lbfgs 1000 0.1 42 (50,): Macro 0.727234 (0.071227)\n",
      "Testing 90/2880\n",
      "identity lbfgs 1000 0.1 42 (100,): Weighted 0.828542 (0.053537)\n",
      "identity lbfgs 1000 0.1 42 (100,): Macro 0.727234 (0.071227)\n",
      "Testing 91/2880\n",
      "identity lbfgs 1000 0.1 42 (150,): Weighted 0.828542 (0.053537)\n",
      "identity lbfgs 1000 0.1 42 (150,): Macro 0.727234 (0.071227)\n",
      "Testing 92/2880\n",
      "identity lbfgs 1000 0.1 42 (200,): Weighted 0.828542 (0.053537)\n",
      "identity lbfgs 1000 0.1 42 (200,): Macro 0.727234 (0.071227)\n",
      "Testing 93/2880\n",
      "identity lbfgs 1000 0.1 76 (50,): Weighted 0.828542 (0.053537)\n",
      "identity lbfgs 1000 0.1 76 (50,): Macro 0.727234 (0.071227)\n",
      "Testing 94/2880\n",
      "identity lbfgs 1000 0.1 76 (100,): Weighted 0.828542 (0.053537)\n",
      "identity lbfgs 1000 0.1 76 (100,): Macro 0.727234 (0.071227)\n",
      "Testing 95/2880\n",
      "identity lbfgs 1000 0.1 76 (150,): Weighted 0.831829 (0.053027)\n",
      "identity lbfgs 1000 0.1 76 (150,): Macro 0.731083 (0.070659)\n",
      "Testing 96/2880\n",
      "identity lbfgs 1000 0.1 76 (200,): Weighted 0.828542 (0.053537)\n",
      "identity lbfgs 1000 0.1 76 (200,): Macro 0.727234 (0.071227)\n",
      "Testing 97/2880\n",
      "identity lbfgs 1000 0.1 112 (50,): Weighted 0.828542 (0.053537)\n",
      "identity lbfgs 1000 0.1 112 (50,): Macro 0.727234 (0.071227)\n",
      "Testing 98/2880\n",
      "identity lbfgs 1000 0.1 112 (100,): Weighted 0.831829 (0.053027)\n",
      "identity lbfgs 1000 0.1 112 (100,): Macro 0.731083 (0.070659)\n",
      "Testing 99/2880\n",
      "identity lbfgs 1000 0.1 112 (150,): Weighted 0.831829 (0.053027)\n",
      "identity lbfgs 1000 0.1 112 (150,): Macro 0.731083 (0.070659)\n",
      "Testing 100/2880\n",
      "identity lbfgs 1000 0.1 112 (200,): Weighted 0.831829 (0.053027)\n",
      "identity lbfgs 1000 0.1 112 (200,): Macro 0.731083 (0.070659)\n",
      "Testing 101/2880\n",
      "identity lbfgs 1000 0.01 17 (50,): Weighted 0.828542 (0.053537)\n",
      "identity lbfgs 1000 0.01 17 (50,): Macro 0.727234 (0.071227)\n",
      "Testing 102/2880\n",
      "identity lbfgs 1000 0.01 17 (100,): Weighted 0.828542 (0.053537)\n",
      "identity lbfgs 1000 0.01 17 (100,): Macro 0.727234 (0.071227)\n",
      "Testing 103/2880\n",
      "identity lbfgs 1000 0.01 17 (150,): Weighted 0.828542 (0.053537)\n",
      "identity lbfgs 1000 0.01 17 (150,): Macro 0.727234 (0.071227)\n",
      "Testing 104/2880\n",
      "identity lbfgs 1000 0.01 17 (200,): Weighted 0.828542 (0.053537)\n",
      "identity lbfgs 1000 0.01 17 (200,): Macro 0.727234 (0.071227)\n",
      "Testing 105/2880\n",
      "identity lbfgs 1000 0.01 29 (50,): Weighted 0.828542 (0.053537)\n",
      "identity lbfgs 1000 0.01 29 (50,): Macro 0.727234 (0.071227)\n",
      "Testing 106/2880\n",
      "identity lbfgs 1000 0.01 29 (100,): Weighted 0.828542 (0.053537)\n",
      "identity lbfgs 1000 0.01 29 (100,): Macro 0.727234 (0.071227)\n",
      "Testing 107/2880\n",
      "identity lbfgs 1000 0.01 29 (150,): Weighted 0.828542 (0.053537)\n",
      "identity lbfgs 1000 0.01 29 (150,): Macro 0.727234 (0.071227)\n",
      "Testing 108/2880\n",
      "identity lbfgs 1000 0.01 29 (200,): Weighted 0.828542 (0.053537)\n",
      "identity lbfgs 1000 0.01 29 (200,): Macro 0.727234 (0.071227)\n",
      "Testing 109/2880\n",
      "identity lbfgs 1000 0.01 42 (50,): Weighted 0.828542 (0.053537)\n",
      "identity lbfgs 1000 0.01 42 (50,): Macro 0.727234 (0.071227)\n",
      "Testing 110/2880\n",
      "identity lbfgs 1000 0.01 42 (100,): Weighted 0.828542 (0.053537)\n",
      "identity lbfgs 1000 0.01 42 (100,): Macro 0.727234 (0.071227)\n",
      "Testing 111/2880\n",
      "identity lbfgs 1000 0.01 42 (150,): Weighted 0.828542 (0.053537)\n",
      "identity lbfgs 1000 0.01 42 (150,): Macro 0.727234 (0.071227)\n",
      "Testing 112/2880\n",
      "identity lbfgs 1000 0.01 42 (200,): Weighted 0.828542 (0.053537)\n",
      "identity lbfgs 1000 0.01 42 (200,): Macro 0.727234 (0.071227)\n",
      "Testing 113/2880\n",
      "identity lbfgs 1000 0.01 76 (50,): Weighted 0.828542 (0.053537)\n",
      "identity lbfgs 1000 0.01 76 (50,): Macro 0.727234 (0.071227)\n",
      "Testing 114/2880\n",
      "identity lbfgs 1000 0.01 76 (100,): Weighted 0.828542 (0.053537)\n",
      "identity lbfgs 1000 0.01 76 (100,): Macro 0.727234 (0.071227)\n",
      "Testing 115/2880\n",
      "identity lbfgs 1000 0.01 76 (150,): Weighted 0.828542 (0.053537)\n",
      "identity lbfgs 1000 0.01 76 (150,): Macro 0.727234 (0.071227)\n",
      "Testing 116/2880\n",
      "identity lbfgs 1000 0.01 76 (200,): Weighted 0.828542 (0.053537)\n",
      "identity lbfgs 1000 0.01 76 (200,): Macro 0.727234 (0.071227)\n",
      "Testing 117/2880\n",
      "identity lbfgs 1000 0.01 112 (50,): Weighted 0.828542 (0.053537)\n",
      "identity lbfgs 1000 0.01 112 (50,): Macro 0.727234 (0.071227)\n",
      "Testing 118/2880\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "identity lbfgs 1000 0.01 112 (100,): Weighted 0.828542 (0.053537)\n",
      "identity lbfgs 1000 0.01 112 (100,): Macro 0.727234 (0.071227)\n",
      "Testing 119/2880\n",
      "identity lbfgs 1000 0.01 112 (150,): Weighted 0.828542 (0.053537)\n",
      "identity lbfgs 1000 0.01 112 (150,): Macro 0.727234 (0.071227)\n",
      "Testing 120/2880\n",
      "identity lbfgs 1000 0.01 112 (200,): Weighted 0.828542 (0.053537)\n",
      "identity lbfgs 1000 0.01 112 (200,): Macro 0.727234 (0.071227)\n",
      "Testing 121/2880\n",
      "identity lbfgs 1000 0.001 17 (50,): Weighted 0.828542 (0.053537)\n",
      "identity lbfgs 1000 0.001 17 (50,): Macro 0.727234 (0.071227)\n",
      "Testing 122/2880\n",
      "identity lbfgs 1000 0.001 17 (100,): Weighted 0.828542 (0.053537)\n",
      "identity lbfgs 1000 0.001 17 (100,): Macro 0.727234 (0.071227)\n",
      "Testing 123/2880\n",
      "identity lbfgs 1000 0.001 17 (150,): Weighted 0.828542 (0.053537)\n",
      "identity lbfgs 1000 0.001 17 (150,): Macro 0.727234 (0.071227)\n",
      "Testing 124/2880\n",
      "identity lbfgs 1000 0.001 17 (200,): Weighted 0.828542 (0.053537)\n",
      "identity lbfgs 1000 0.001 17 (200,): Macro 0.727234 (0.071227)\n",
      "Testing 125/2880\n",
      "identity lbfgs 1000 0.001 29 (50,): Weighted 0.828542 (0.053537)\n",
      "identity lbfgs 1000 0.001 29 (50,): Macro 0.727234 (0.071227)\n",
      "Testing 126/2880\n",
      "identity lbfgs 1000 0.001 29 (100,): Weighted 0.828542 (0.053537)\n",
      "identity lbfgs 1000 0.001 29 (100,): Macro 0.727234 (0.071227)\n",
      "Testing 127/2880\n",
      "identity lbfgs 1000 0.001 29 (150,): Weighted 0.828542 (0.053537)\n",
      "identity lbfgs 1000 0.001 29 (150,): Macro 0.727234 (0.071227)\n",
      "Testing 128/2880\n",
      "identity lbfgs 1000 0.001 29 (200,): Weighted 0.828542 (0.053537)\n",
      "identity lbfgs 1000 0.001 29 (200,): Macro 0.727234 (0.071227)\n",
      "Testing 129/2880\n",
      "identity lbfgs 1000 0.001 42 (50,): Weighted 0.828542 (0.053537)\n",
      "identity lbfgs 1000 0.001 42 (50,): Macro 0.727234 (0.071227)\n",
      "Testing 130/2880\n",
      "identity lbfgs 1000 0.001 42 (100,): Weighted 0.828542 (0.053537)\n",
      "identity lbfgs 1000 0.001 42 (100,): Macro 0.727234 (0.071227)\n",
      "Testing 131/2880\n",
      "identity lbfgs 1000 0.001 42 (150,): Weighted 0.828542 (0.053537)\n",
      "identity lbfgs 1000 0.001 42 (150,): Macro 0.727234 (0.071227)\n",
      "Testing 132/2880\n",
      "identity lbfgs 1000 0.001 42 (200,): Weighted 0.828542 (0.053537)\n",
      "identity lbfgs 1000 0.001 42 (200,): Macro 0.727234 (0.071227)\n",
      "Testing 133/2880\n",
      "identity lbfgs 1000 0.001 76 (50,): Weighted 0.828542 (0.053537)\n",
      "identity lbfgs 1000 0.001 76 (50,): Macro 0.727234 (0.071227)\n",
      "Testing 134/2880\n",
      "identity lbfgs 1000 0.001 76 (100,): Weighted 0.828542 (0.053537)\n",
      "identity lbfgs 1000 0.001 76 (100,): Macro 0.727234 (0.071227)\n",
      "Testing 135/2880\n",
      "identity lbfgs 1000 0.001 76 (150,): Weighted 0.828542 (0.053537)\n",
      "identity lbfgs 1000 0.001 76 (150,): Macro 0.727234 (0.071227)\n",
      "Testing 136/2880\n",
      "identity lbfgs 1000 0.001 76 (200,): Weighted 0.828542 (0.053537)\n",
      "identity lbfgs 1000 0.001 76 (200,): Macro 0.727234 (0.071227)\n",
      "Testing 137/2880\n",
      "identity lbfgs 1000 0.001 112 (50,): Weighted 0.828542 (0.053537)\n",
      "identity lbfgs 1000 0.001 112 (50,): Macro 0.727234 (0.071227)\n",
      "Testing 138/2880\n",
      "identity lbfgs 1000 0.001 112 (100,): Weighted 0.828542 (0.053537)\n",
      "identity lbfgs 1000 0.001 112 (100,): Macro 0.727234 (0.071227)\n",
      "Testing 139/2880\n",
      "identity lbfgs 1000 0.001 112 (150,): Weighted 0.828542 (0.053537)\n",
      "identity lbfgs 1000 0.001 112 (150,): Macro 0.727234 (0.071227)\n",
      "Testing 140/2880\n",
      "identity lbfgs 1000 0.001 112 (200,): Weighted 0.828542 (0.053537)\n",
      "identity lbfgs 1000 0.001 112 (200,): Macro 0.727234 (0.071227)\n",
      "Testing 141/2880\n",
      "identity lbfgs 1000 0.0001 17 (50,): Weighted 0.828542 (0.053537)\n",
      "identity lbfgs 1000 0.0001 17 (50,): Macro 0.727234 (0.071227)\n",
      "Testing 142/2880\n",
      "identity lbfgs 1000 0.0001 17 (100,): Weighted 0.828542 (0.053537)\n",
      "identity lbfgs 1000 0.0001 17 (100,): Macro 0.727234 (0.071227)\n",
      "Testing 143/2880\n",
      "identity lbfgs 1000 0.0001 17 (150,): Weighted 0.828542 (0.053537)\n",
      "identity lbfgs 1000 0.0001 17 (150,): Macro 0.727234 (0.071227)\n",
      "Testing 144/2880\n",
      "identity lbfgs 1000 0.0001 17 (200,): Weighted 0.828542 (0.053537)\n",
      "identity lbfgs 1000 0.0001 17 (200,): Macro 0.727234 (0.071227)\n",
      "Testing 145/2880\n",
      "identity lbfgs 1000 0.0001 29 (50,): Weighted 0.828542 (0.053537)\n",
      "identity lbfgs 1000 0.0001 29 (50,): Macro 0.727234 (0.071227)\n",
      "Testing 146/2880\n",
      "identity lbfgs 1000 0.0001 29 (100,): Weighted 0.828542 (0.053537)\n",
      "identity lbfgs 1000 0.0001 29 (100,): Macro 0.727234 (0.071227)\n",
      "Testing 147/2880\n",
      "identity lbfgs 1000 0.0001 29 (150,): Weighted 0.828542 (0.053537)\n",
      "identity lbfgs 1000 0.0001 29 (150,): Macro 0.727234 (0.071227)\n",
      "Testing 148/2880\n",
      "identity lbfgs 1000 0.0001 29 (200,): Weighted 0.828542 (0.053537)\n",
      "identity lbfgs 1000 0.0001 29 (200,): Macro 0.727234 (0.071227)\n",
      "Testing 149/2880\n",
      "identity lbfgs 1000 0.0001 42 (50,): Weighted 0.828542 (0.053537)\n",
      "identity lbfgs 1000 0.0001 42 (50,): Macro 0.727234 (0.071227)\n",
      "Testing 150/2880\n",
      "identity lbfgs 1000 0.0001 42 (100,): Weighted 0.828542 (0.053537)\n",
      "identity lbfgs 1000 0.0001 42 (100,): Macro 0.727234 (0.071227)\n",
      "Testing 151/2880\n",
      "identity lbfgs 1000 0.0001 42 (150,): Weighted 0.828542 (0.053537)\n",
      "identity lbfgs 1000 0.0001 42 (150,): Macro 0.727234 (0.071227)\n",
      "Testing 152/2880\n",
      "identity lbfgs 1000 0.0001 42 (200,): Weighted 0.828542 (0.053537)\n",
      "identity lbfgs 1000 0.0001 42 (200,): Macro 0.727234 (0.071227)\n",
      "Testing 153/2880\n",
      "identity lbfgs 1000 0.0001 76 (50,): Weighted 0.828542 (0.053537)\n",
      "identity lbfgs 1000 0.0001 76 (50,): Macro 0.727234 (0.071227)\n",
      "Testing 154/2880\n",
      "identity lbfgs 1000 0.0001 76 (100,): Weighted 0.828542 (0.053537)\n",
      "identity lbfgs 1000 0.0001 76 (100,): Macro 0.727234 (0.071227)\n",
      "Testing 155/2880\n",
      "identity lbfgs 1000 0.0001 76 (150,): Weighted 0.828542 (0.053537)\n",
      "identity lbfgs 1000 0.0001 76 (150,): Macro 0.727234 (0.071227)\n",
      "Testing 156/2880\n",
      "identity lbfgs 1000 0.0001 76 (200,): Weighted 0.828542 (0.053537)\n",
      "identity lbfgs 1000 0.0001 76 (200,): Macro 0.727234 (0.071227)\n",
      "Testing 157/2880\n",
      "identity lbfgs 1000 0.0001 112 (50,): Weighted 0.828542 (0.053537)\n",
      "identity lbfgs 1000 0.0001 112 (50,): Macro 0.727234 (0.071227)\n",
      "Testing 158/2880\n",
      "identity lbfgs 1000 0.0001 112 (100,): Weighted 0.828542 (0.053537)\n",
      "identity lbfgs 1000 0.0001 112 (100,): Macro 0.727234 (0.071227)\n",
      "Testing 159/2880\n",
      "identity lbfgs 1000 0.0001 112 (150,): Weighted 0.828542 (0.053537)\n",
      "identity lbfgs 1000 0.0001 112 (150,): Macro 0.727234 (0.071227)\n",
      "Testing 160/2880\n",
      "identity lbfgs 1000 0.0001 112 (200,): Weighted 0.828542 (0.053537)\n",
      "identity lbfgs 1000 0.0001 112 (200,): Macro 0.727234 (0.071227)\n",
      "Testing 161/2880\n",
      "identity lbfgs 1500 0.1 17 (50,): Weighted 0.828542 (0.053537)\n",
      "identity lbfgs 1500 0.1 17 (50,): Macro 0.727234 (0.071227)\n",
      "Testing 162/2880\n",
      "identity lbfgs 1500 0.1 17 (100,): Weighted 0.828542 (0.053537)\n",
      "identity lbfgs 1500 0.1 17 (100,): Macro 0.727234 (0.071227)\n",
      "Testing 163/2880\n",
      "identity lbfgs 1500 0.1 17 (150,): Weighted 0.828542 (0.053537)\n",
      "identity lbfgs 1500 0.1 17 (150,): Macro 0.727234 (0.071227)\n",
      "Testing 164/2880\n",
      "identity lbfgs 1500 0.1 17 (200,): Weighted 0.831829 (0.053027)\n",
      "identity lbfgs 1500 0.1 17 (200,): Macro 0.731083 (0.070659)\n",
      "Testing 165/2880\n",
      "identity lbfgs 1500 0.1 29 (50,): Weighted 0.828542 (0.053537)\n",
      "identity lbfgs 1500 0.1 29 (50,): Macro 0.727234 (0.071227)\n",
      "Testing 166/2880\n",
      "identity lbfgs 1500 0.1 29 (100,): Weighted 0.828542 (0.053537)\n",
      "identity lbfgs 1500 0.1 29 (100,): Macro 0.727234 (0.071227)\n",
      "Testing 167/2880\n",
      "identity lbfgs 1500 0.1 29 (150,): Weighted 0.831829 (0.053027)\n",
      "identity lbfgs 1500 0.1 29 (150,): Macro 0.731083 (0.070659)\n",
      "Testing 168/2880\n",
      "identity lbfgs 1500 0.1 29 (200,): Weighted 0.828542 (0.053537)\n",
      "identity lbfgs 1500 0.1 29 (200,): Macro 0.727234 (0.071227)\n",
      "Testing 169/2880\n",
      "identity lbfgs 1500 0.1 42 (50,): Weighted 0.828542 (0.053537)\n",
      "identity lbfgs 1500 0.1 42 (50,): Macro 0.727234 (0.071227)\n",
      "Testing 170/2880\n",
      "identity lbfgs 1500 0.1 42 (100,): Weighted 0.828542 (0.053537)\n",
      "identity lbfgs 1500 0.1 42 (100,): Macro 0.727234 (0.071227)\n",
      "Testing 171/2880\n",
      "identity lbfgs 1500 0.1 42 (150,): Weighted 0.828542 (0.053537)\n",
      "identity lbfgs 1500 0.1 42 (150,): Macro 0.727234 (0.071227)\n",
      "Testing 172/2880\n",
      "identity lbfgs 1500 0.1 42 (200,): Weighted 0.828542 (0.053537)\n",
      "identity lbfgs 1500 0.1 42 (200,): Macro 0.727234 (0.071227)\n",
      "Testing 173/2880\n",
      "identity lbfgs 1500 0.1 76 (50,): Weighted 0.828542 (0.053537)\n",
      "identity lbfgs 1500 0.1 76 (50,): Macro 0.727234 (0.071227)\n",
      "Testing 174/2880\n",
      "identity lbfgs 1500 0.1 76 (100,): Weighted 0.828542 (0.053537)\n",
      "identity lbfgs 1500 0.1 76 (100,): Macro 0.727234 (0.071227)\n",
      "Testing 175/2880\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "identity lbfgs 1500 0.1 76 (150,): Weighted 0.831829 (0.053027)\n",
      "identity lbfgs 1500 0.1 76 (150,): Macro 0.731083 (0.070659)\n",
      "Testing 176/2880\n",
      "identity lbfgs 1500 0.1 76 (200,): Weighted 0.828542 (0.053537)\n",
      "identity lbfgs 1500 0.1 76 (200,): Macro 0.727234 (0.071227)\n",
      "Testing 177/2880\n",
      "identity lbfgs 1500 0.1 112 (50,): Weighted 0.828542 (0.053537)\n",
      "identity lbfgs 1500 0.1 112 (50,): Macro 0.727234 (0.071227)\n",
      "Testing 178/2880\n",
      "identity lbfgs 1500 0.1 112 (100,): Weighted 0.831829 (0.053027)\n",
      "identity lbfgs 1500 0.1 112 (100,): Macro 0.731083 (0.070659)\n",
      "Testing 179/2880\n",
      "identity lbfgs 1500 0.1 112 (150,): Weighted 0.831829 (0.053027)\n",
      "identity lbfgs 1500 0.1 112 (150,): Macro 0.731083 (0.070659)\n",
      "Testing 180/2880\n",
      "identity lbfgs 1500 0.1 112 (200,): Weighted 0.831829 (0.053027)\n",
      "identity lbfgs 1500 0.1 112 (200,): Macro 0.731083 (0.070659)\n",
      "Testing 181/2880\n",
      "identity lbfgs 1500 0.01 17 (50,): Weighted 0.828542 (0.053537)\n",
      "identity lbfgs 1500 0.01 17 (50,): Macro 0.727234 (0.071227)\n",
      "Testing 182/2880\n",
      "identity lbfgs 1500 0.01 17 (100,): Weighted 0.828542 (0.053537)\n",
      "identity lbfgs 1500 0.01 17 (100,): Macro 0.727234 (0.071227)\n",
      "Testing 183/2880\n",
      "identity lbfgs 1500 0.01 17 (150,): Weighted 0.828542 (0.053537)\n",
      "identity lbfgs 1500 0.01 17 (150,): Macro 0.727234 (0.071227)\n",
      "Testing 184/2880\n",
      "identity lbfgs 1500 0.01 17 (200,): Weighted 0.828542 (0.053537)\n",
      "identity lbfgs 1500 0.01 17 (200,): Macro 0.727234 (0.071227)\n",
      "Testing 185/2880\n",
      "identity lbfgs 1500 0.01 29 (50,): Weighted 0.828542 (0.053537)\n",
      "identity lbfgs 1500 0.01 29 (50,): Macro 0.727234 (0.071227)\n",
      "Testing 186/2880\n",
      "identity lbfgs 1500 0.01 29 (100,): Weighted 0.828542 (0.053537)\n",
      "identity lbfgs 1500 0.01 29 (100,): Macro 0.727234 (0.071227)\n",
      "Testing 187/2880\n",
      "identity lbfgs 1500 0.01 29 (150,): Weighted 0.828542 (0.053537)\n",
      "identity lbfgs 1500 0.01 29 (150,): Macro 0.727234 (0.071227)\n",
      "Testing 188/2880\n",
      "identity lbfgs 1500 0.01 29 (200,): Weighted 0.828542 (0.053537)\n",
      "identity lbfgs 1500 0.01 29 (200,): Macro 0.727234 (0.071227)\n",
      "Testing 189/2880\n",
      "identity lbfgs 1500 0.01 42 (50,): Weighted 0.828542 (0.053537)\n",
      "identity lbfgs 1500 0.01 42 (50,): Macro 0.727234 (0.071227)\n",
      "Testing 190/2880\n",
      "identity lbfgs 1500 0.01 42 (100,): Weighted 0.828542 (0.053537)\n",
      "identity lbfgs 1500 0.01 42 (100,): Macro 0.727234 (0.071227)\n",
      "Testing 191/2880\n",
      "identity lbfgs 1500 0.01 42 (150,): Weighted 0.828542 (0.053537)\n",
      "identity lbfgs 1500 0.01 42 (150,): Macro 0.727234 (0.071227)\n",
      "Testing 192/2880\n",
      "identity lbfgs 1500 0.01 42 (200,): Weighted 0.828542 (0.053537)\n",
      "identity lbfgs 1500 0.01 42 (200,): Macro 0.727234 (0.071227)\n",
      "Testing 193/2880\n",
      "identity lbfgs 1500 0.01 76 (50,): Weighted 0.828542 (0.053537)\n",
      "identity lbfgs 1500 0.01 76 (50,): Macro 0.727234 (0.071227)\n",
      "Testing 194/2880\n",
      "identity lbfgs 1500 0.01 76 (100,): Weighted 0.828542 (0.053537)\n",
      "identity lbfgs 1500 0.01 76 (100,): Macro 0.727234 (0.071227)\n",
      "Testing 195/2880\n",
      "identity lbfgs 1500 0.01 76 (150,): Weighted 0.828542 (0.053537)\n",
      "identity lbfgs 1500 0.01 76 (150,): Macro 0.727234 (0.071227)\n",
      "Testing 196/2880\n",
      "identity lbfgs 1500 0.01 76 (200,): Weighted 0.828542 (0.053537)\n",
      "identity lbfgs 1500 0.01 76 (200,): Macro 0.727234 (0.071227)\n",
      "Testing 197/2880\n",
      "identity lbfgs 1500 0.01 112 (50,): Weighted 0.828542 (0.053537)\n",
      "identity lbfgs 1500 0.01 112 (50,): Macro 0.727234 (0.071227)\n",
      "Testing 198/2880\n",
      "identity lbfgs 1500 0.01 112 (100,): Weighted 0.828542 (0.053537)\n",
      "identity lbfgs 1500 0.01 112 (100,): Macro 0.727234 (0.071227)\n",
      "Testing 199/2880\n",
      "identity lbfgs 1500 0.01 112 (150,): Weighted 0.828542 (0.053537)\n",
      "identity lbfgs 1500 0.01 112 (150,): Macro 0.727234 (0.071227)\n",
      "Testing 200/2880\n",
      "identity lbfgs 1500 0.01 112 (200,): Weighted 0.828542 (0.053537)\n",
      "identity lbfgs 1500 0.01 112 (200,): Macro 0.727234 (0.071227)\n",
      "Testing 201/2880\n",
      "identity lbfgs 1500 0.001 17 (50,): Weighted 0.828542 (0.053537)\n",
      "identity lbfgs 1500 0.001 17 (50,): Macro 0.727234 (0.071227)\n",
      "Testing 202/2880\n",
      "identity lbfgs 1500 0.001 17 (100,): Weighted 0.828542 (0.053537)\n",
      "identity lbfgs 1500 0.001 17 (100,): Macro 0.727234 (0.071227)\n",
      "Testing 203/2880\n",
      "identity lbfgs 1500 0.001 17 (150,): Weighted 0.828542 (0.053537)\n",
      "identity lbfgs 1500 0.001 17 (150,): Macro 0.727234 (0.071227)\n",
      "Testing 204/2880\n",
      "identity lbfgs 1500 0.001 17 (200,): Weighted 0.828542 (0.053537)\n",
      "identity lbfgs 1500 0.001 17 (200,): Macro 0.727234 (0.071227)\n",
      "Testing 205/2880\n",
      "identity lbfgs 1500 0.001 29 (50,): Weighted 0.828542 (0.053537)\n",
      "identity lbfgs 1500 0.001 29 (50,): Macro 0.727234 (0.071227)\n",
      "Testing 206/2880\n",
      "identity lbfgs 1500 0.001 29 (100,): Weighted 0.828542 (0.053537)\n",
      "identity lbfgs 1500 0.001 29 (100,): Macro 0.727234 (0.071227)\n",
      "Testing 207/2880\n",
      "identity lbfgs 1500 0.001 29 (150,): Weighted 0.828542 (0.053537)\n",
      "identity lbfgs 1500 0.001 29 (150,): Macro 0.727234 (0.071227)\n",
      "Testing 208/2880\n",
      "identity lbfgs 1500 0.001 29 (200,): Weighted 0.828542 (0.053537)\n",
      "identity lbfgs 1500 0.001 29 (200,): Macro 0.727234 (0.071227)\n",
      "Testing 209/2880\n",
      "identity lbfgs 1500 0.001 42 (50,): Weighted 0.828542 (0.053537)\n",
      "identity lbfgs 1500 0.001 42 (50,): Macro 0.727234 (0.071227)\n",
      "Testing 210/2880\n",
      "identity lbfgs 1500 0.001 42 (100,): Weighted 0.828542 (0.053537)\n",
      "identity lbfgs 1500 0.001 42 (100,): Macro 0.727234 (0.071227)\n",
      "Testing 211/2880\n",
      "identity lbfgs 1500 0.001 42 (150,): Weighted 0.828542 (0.053537)\n",
      "identity lbfgs 1500 0.001 42 (150,): Macro 0.727234 (0.071227)\n",
      "Testing 212/2880\n",
      "identity lbfgs 1500 0.001 42 (200,): Weighted 0.828542 (0.053537)\n",
      "identity lbfgs 1500 0.001 42 (200,): Macro 0.727234 (0.071227)\n",
      "Testing 213/2880\n",
      "identity lbfgs 1500 0.001 76 (50,): Weighted 0.828542 (0.053537)\n",
      "identity lbfgs 1500 0.001 76 (50,): Macro 0.727234 (0.071227)\n",
      "Testing 214/2880\n",
      "identity lbfgs 1500 0.001 76 (100,): Weighted 0.828542 (0.053537)\n",
      "identity lbfgs 1500 0.001 76 (100,): Macro 0.727234 (0.071227)\n",
      "Testing 215/2880\n",
      "identity lbfgs 1500 0.001 76 (150,): Weighted 0.828542 (0.053537)\n",
      "identity lbfgs 1500 0.001 76 (150,): Macro 0.727234 (0.071227)\n",
      "Testing 216/2880\n",
      "identity lbfgs 1500 0.001 76 (200,): Weighted 0.828542 (0.053537)\n",
      "identity lbfgs 1500 0.001 76 (200,): Macro 0.727234 (0.071227)\n",
      "Testing 217/2880\n",
      "identity lbfgs 1500 0.001 112 (50,): Weighted 0.828542 (0.053537)\n",
      "identity lbfgs 1500 0.001 112 (50,): Macro 0.727234 (0.071227)\n",
      "Testing 218/2880\n",
      "identity lbfgs 1500 0.001 112 (100,): Weighted 0.828542 (0.053537)\n",
      "identity lbfgs 1500 0.001 112 (100,): Macro 0.727234 (0.071227)\n",
      "Testing 219/2880\n",
      "identity lbfgs 1500 0.001 112 (150,): Weighted 0.828542 (0.053537)\n",
      "identity lbfgs 1500 0.001 112 (150,): Macro 0.727234 (0.071227)\n",
      "Testing 220/2880\n",
      "identity lbfgs 1500 0.001 112 (200,): Weighted 0.828542 (0.053537)\n",
      "identity lbfgs 1500 0.001 112 (200,): Macro 0.727234 (0.071227)\n",
      "Testing 221/2880\n",
      "identity lbfgs 1500 0.0001 17 (50,): Weighted 0.828542 (0.053537)\n",
      "identity lbfgs 1500 0.0001 17 (50,): Macro 0.727234 (0.071227)\n",
      "Testing 222/2880\n",
      "identity lbfgs 1500 0.0001 17 (100,): Weighted 0.828542 (0.053537)\n",
      "identity lbfgs 1500 0.0001 17 (100,): Macro 0.727234 (0.071227)\n",
      "Testing 223/2880\n",
      "identity lbfgs 1500 0.0001 17 (150,): Weighted 0.828542 (0.053537)\n",
      "identity lbfgs 1500 0.0001 17 (150,): Macro 0.727234 (0.071227)\n",
      "Testing 224/2880\n",
      "identity lbfgs 1500 0.0001 17 (200,): Weighted 0.828542 (0.053537)\n",
      "identity lbfgs 1500 0.0001 17 (200,): Macro 0.727234 (0.071227)\n",
      "Testing 225/2880\n",
      "identity lbfgs 1500 0.0001 29 (50,): Weighted 0.828542 (0.053537)\n",
      "identity lbfgs 1500 0.0001 29 (50,): Macro 0.727234 (0.071227)\n",
      "Testing 226/2880\n",
      "identity lbfgs 1500 0.0001 29 (100,): Weighted 0.828542 (0.053537)\n",
      "identity lbfgs 1500 0.0001 29 (100,): Macro 0.727234 (0.071227)\n",
      "Testing 227/2880\n",
      "identity lbfgs 1500 0.0001 29 (150,): Weighted 0.828542 (0.053537)\n",
      "identity lbfgs 1500 0.0001 29 (150,): Macro 0.727234 (0.071227)\n",
      "Testing 228/2880\n",
      "identity lbfgs 1500 0.0001 29 (200,): Weighted 0.828542 (0.053537)\n",
      "identity lbfgs 1500 0.0001 29 (200,): Macro 0.727234 (0.071227)\n",
      "Testing 229/2880\n",
      "identity lbfgs 1500 0.0001 42 (50,): Weighted 0.828542 (0.053537)\n",
      "identity lbfgs 1500 0.0001 42 (50,): Macro 0.727234 (0.071227)\n",
      "Testing 230/2880\n",
      "identity lbfgs 1500 0.0001 42 (100,): Weighted 0.828542 (0.053537)\n",
      "identity lbfgs 1500 0.0001 42 (100,): Macro 0.727234 (0.071227)\n",
      "Testing 231/2880\n",
      "identity lbfgs 1500 0.0001 42 (150,): Weighted 0.828542 (0.053537)\n",
      "identity lbfgs 1500 0.0001 42 (150,): Macro 0.727234 (0.071227)\n",
      "Testing 232/2880\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "identity lbfgs 1500 0.0001 42 (200,): Weighted 0.828542 (0.053537)\n",
      "identity lbfgs 1500 0.0001 42 (200,): Macro 0.727234 (0.071227)\n",
      "Testing 233/2880\n",
      "identity lbfgs 1500 0.0001 76 (50,): Weighted 0.828542 (0.053537)\n",
      "identity lbfgs 1500 0.0001 76 (50,): Macro 0.727234 (0.071227)\n",
      "Testing 234/2880\n",
      "identity lbfgs 1500 0.0001 76 (100,): Weighted 0.828542 (0.053537)\n",
      "identity lbfgs 1500 0.0001 76 (100,): Macro 0.727234 (0.071227)\n",
      "Testing 235/2880\n",
      "identity lbfgs 1500 0.0001 76 (150,): Weighted 0.828542 (0.053537)\n",
      "identity lbfgs 1500 0.0001 76 (150,): Macro 0.727234 (0.071227)\n",
      "Testing 236/2880\n",
      "identity lbfgs 1500 0.0001 76 (200,): Weighted 0.828542 (0.053537)\n",
      "identity lbfgs 1500 0.0001 76 (200,): Macro 0.727234 (0.071227)\n",
      "Testing 237/2880\n",
      "identity lbfgs 1500 0.0001 112 (50,): Weighted 0.828542 (0.053537)\n",
      "identity lbfgs 1500 0.0001 112 (50,): Macro 0.727234 (0.071227)\n",
      "Testing 238/2880\n",
      "identity lbfgs 1500 0.0001 112 (100,): Weighted 0.828542 (0.053537)\n",
      "identity lbfgs 1500 0.0001 112 (100,): Macro 0.727234 (0.071227)\n",
      "Testing 239/2880\n",
      "identity lbfgs 1500 0.0001 112 (150,): Weighted 0.828542 (0.053537)\n",
      "identity lbfgs 1500 0.0001 112 (150,): Macro 0.727234 (0.071227)\n",
      "Testing 240/2880\n",
      "identity lbfgs 1500 0.0001 112 (200,): Weighted 0.828542 (0.053537)\n",
      "identity lbfgs 1500 0.0001 112 (200,): Macro 0.727234 (0.071227)\n",
      "Testing 241/2880\n",
      "identity sgd 500 0.1 17 (50,): Weighted 0.798041 (0.076849)\n",
      "identity sgd 500 0.1 17 (50,): Macro 0.681160 (0.089146)\n",
      "Testing 242/2880\n",
      "identity sgd 500 0.1 17 (100,): Weighted 0.827820 (0.033504)\n",
      "identity sgd 500 0.1 17 (100,): Macro 0.716342 (0.054395)\n",
      "Testing 243/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "identity sgd 500 0.1 17 (150,): Weighted 0.774621 (0.066585)\n",
      "identity sgd 500 0.1 17 (150,): Macro 0.627033 (0.075695)\n",
      "Testing 244/2880\n",
      "identity sgd 500 0.1 17 (200,): Weighted 0.825226 (0.028922)\n",
      "identity sgd 500 0.1 17 (200,): Macro 0.701073 (0.030654)\n",
      "Testing 245/2880\n",
      "identity sgd 500 0.1 29 (50,): Weighted 0.792112 (0.018799)\n",
      "identity sgd 500 0.1 29 (50,): Macro 0.672446 (0.033605)\n",
      "Testing 246/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "identity sgd 500 0.1 29 (100,): Weighted 0.744469 (0.095323)\n",
      "identity sgd 500 0.1 29 (100,): Macro 0.608846 (0.093717)\n",
      "Testing 247/2880\n",
      "identity sgd 500 0.1 29 (150,): Weighted 0.842721 (0.053206)\n",
      "identity sgd 500 0.1 29 (150,): Macro 0.739196 (0.075896)\n",
      "Testing 248/2880\n",
      "identity sgd 500 0.1 29 (200,): Weighted 0.827534 (0.031094)\n",
      "identity sgd 500 0.1 29 (200,): Macro 0.724254 (0.049655)\n",
      "Testing 249/2880\n",
      "identity sgd 500 0.1 42 (50,): Weighted 0.793519 (0.072322)\n",
      "identity sgd 500 0.1 42 (50,): Macro 0.654632 (0.067294)\n",
      "Testing 250/2880\n",
      "identity sgd 500 0.1 42 (100,): Weighted 0.799299 (0.073565)\n",
      "identity sgd 500 0.1 42 (100,): Macro 0.682452 (0.091159)\n",
      "Testing 251/2880\n",
      "identity sgd 500 0.1 42 (150,): Weighted 0.761645 (0.064015)\n",
      "identity sgd 500 0.1 42 (150,): Macro 0.621661 (0.059008)\n",
      "Testing 252/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "identity sgd 500 0.1 42 (200,): Weighted 0.738267 (0.083410)\n",
      "identity sgd 500 0.1 42 (200,): Macro 0.613311 (0.101042)\n",
      "Testing 253/2880\n",
      "identity sgd 500 0.1 76 (50,): Weighted 0.839807 (0.041719)\n",
      "identity sgd 500 0.1 76 (50,): Macro 0.733157 (0.042704)\n",
      "Testing 254/2880\n",
      "identity sgd 500 0.1 76 (100,): Weighted 0.809693 (0.071613)\n",
      "identity sgd 500 0.1 76 (100,): Macro 0.708912 (0.093388)\n",
      "Testing 255/2880\n",
      "identity sgd 500 0.1 76 (150,): Weighted 0.833693 (0.039245)\n",
      "identity sgd 500 0.1 76 (150,): Macro 0.724810 (0.043496)\n",
      "Testing 256/2880\n",
      "identity sgd 500 0.1 76 (200,): Weighted 0.815669 (0.036343)\n",
      "identity sgd 500 0.1 76 (200,): Macro 0.672267 (0.032133)\n",
      "Testing 257/2880\n",
      "identity sgd 500 0.1 112 (50,): Weighted 0.772379 (0.084887)\n",
      "identity sgd 500 0.1 112 (50,): Macro 0.653504 (0.104493)\n",
      "Testing 258/2880\n",
      "identity sgd 500 0.1 112 (100,): Weighted 0.794962 (0.080096)\n",
      "identity sgd 500 0.1 112 (100,): Macro 0.674963 (0.093295)\n",
      "Testing 259/2880\n",
      "identity sgd 500 0.1 112 (150,): Weighted 0.806921 (0.084701)\n",
      "identity sgd 500 0.1 112 (150,): Macro 0.698530 (0.098102)\n",
      "Testing 260/2880\n",
      "identity sgd 500 0.1 112 (200,): Weighted 0.791300 (0.053764)\n",
      "identity sgd 500 0.1 112 (200,): Macro 0.661102 (0.043030)\n",
      "Testing 261/2880\n",
      "identity sgd 500 0.01 17 (50,): Weighted 0.798041 (0.076849)\n",
      "identity sgd 500 0.01 17 (50,): Macro 0.681160 (0.089146)\n",
      "Testing 262/2880\n",
      "identity sgd 500 0.01 17 (100,): Weighted 0.827820 (0.033504)\n",
      "identity sgd 500 0.01 17 (100,): Macro 0.716342 (0.054395)\n",
      "Testing 263/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "identity sgd 500 0.01 17 (150,): Weighted 0.774621 (0.066585)\n",
      "identity sgd 500 0.01 17 (150,): Macro 0.627033 (0.075695)\n",
      "Testing 264/2880\n",
      "identity sgd 500 0.01 17 (200,): Weighted 0.825226 (0.028922)\n",
      "identity sgd 500 0.01 17 (200,): Macro 0.701073 (0.030654)\n",
      "Testing 265/2880\n",
      "identity sgd 500 0.01 29 (50,): Weighted 0.786625 (0.014808)\n",
      "identity sgd 500 0.01 29 (50,): Macro 0.665148 (0.026513)\n",
      "Testing 266/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "identity sgd 500 0.01 29 (100,): Weighted 0.744469 (0.095323)\n",
      "identity sgd 500 0.01 29 (100,): Macro 0.608846 (0.093717)\n",
      "Testing 267/2880\n",
      "identity sgd 500 0.01 29 (150,): Weighted 0.842721 (0.053206)\n",
      "identity sgd 500 0.01 29 (150,): Macro 0.739196 (0.075896)\n",
      "Testing 268/2880\n",
      "identity sgd 500 0.01 29 (200,): Weighted 0.827534 (0.031094)\n",
      "identity sgd 500 0.01 29 (200,): Macro 0.724254 (0.049655)\n",
      "Testing 269/2880\n",
      "identity sgd 500 0.01 42 (50,): Weighted 0.793519 (0.072322)\n",
      "identity sgd 500 0.01 42 (50,): Macro 0.654632 (0.067294)\n",
      "Testing 270/2880\n",
      "identity sgd 500 0.01 42 (100,): Weighted 0.799299 (0.073565)\n",
      "identity sgd 500 0.01 42 (100,): Macro 0.682452 (0.091159)\n",
      "Testing 271/2880\n",
      "identity sgd 500 0.01 42 (150,): Weighted 0.761645 (0.064015)\n",
      "identity sgd 500 0.01 42 (150,): Macro 0.621661 (0.059008)\n",
      "Testing 272/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "identity sgd 500 0.01 42 (200,): Weighted 0.738267 (0.083410)\n",
      "identity sgd 500 0.01 42 (200,): Macro 0.613311 (0.101042)\n",
      "Testing 273/2880\n",
      "identity sgd 500 0.01 76 (50,): Weighted 0.839807 (0.041719)\n",
      "identity sgd 500 0.01 76 (50,): Macro 0.733157 (0.042704)\n",
      "Testing 274/2880\n",
      "identity sgd 500 0.01 76 (100,): Weighted 0.809693 (0.071613)\n",
      "identity sgd 500 0.01 76 (100,): Macro 0.708912 (0.093388)\n",
      "Testing 275/2880\n",
      "identity sgd 500 0.01 76 (150,): Weighted 0.833693 (0.039245)\n",
      "identity sgd 500 0.01 76 (150,): Macro 0.724810 (0.043496)\n",
      "Testing 276/2880\n",
      "identity sgd 500 0.01 76 (200,): Weighted 0.824168 (0.024805)\n",
      "identity sgd 500 0.01 76 (200,): Macro 0.685244 (0.012808)\n",
      "Testing 277/2880\n",
      "identity sgd 500 0.01 112 (50,): Weighted 0.772379 (0.084887)\n",
      "identity sgd 500 0.01 112 (50,): Macro 0.653504 (0.104493)\n",
      "Testing 278/2880\n",
      "identity sgd 500 0.01 112 (100,): Weighted 0.794962 (0.080096)\n",
      "identity sgd 500 0.01 112 (100,): Macro 0.674963 (0.093295)\n",
      "Testing 279/2880\n",
      "identity sgd 500 0.01 112 (150,): Weighted 0.806921 (0.084701)\n",
      "identity sgd 500 0.01 112 (150,): Macro 0.698530 (0.098102)\n",
      "Testing 280/2880\n",
      "identity sgd 500 0.01 112 (200,): Weighted 0.791300 (0.053764)\n",
      "identity sgd 500 0.01 112 (200,): Macro 0.661102 (0.043030)\n",
      "Testing 281/2880\n",
      "identity sgd 500 0.001 17 (50,): Weighted 0.798041 (0.076849)\n",
      "identity sgd 500 0.001 17 (50,): Macro 0.681160 (0.089146)\n",
      "Testing 282/2880\n",
      "identity sgd 500 0.001 17 (100,): Weighted 0.827820 (0.033504)\n",
      "identity sgd 500 0.001 17 (100,): Macro 0.716342 (0.054395)\n",
      "Testing 283/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "identity sgd 500 0.001 17 (150,): Weighted 0.774621 (0.066585)\n",
      "identity sgd 500 0.001 17 (150,): Macro 0.627033 (0.075695)\n",
      "Testing 284/2880\n",
      "identity sgd 500 0.001 17 (200,): Weighted 0.825226 (0.028922)\n",
      "identity sgd 500 0.001 17 (200,): Macro 0.701073 (0.030654)\n",
      "Testing 285/2880\n",
      "identity sgd 500 0.001 29 (50,): Weighted 0.786625 (0.014808)\n",
      "identity sgd 500 0.001 29 (50,): Macro 0.665148 (0.026513)\n",
      "Testing 286/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "identity sgd 500 0.001 29 (100,): Weighted 0.744469 (0.095323)\n",
      "identity sgd 500 0.001 29 (100,): Macro 0.608846 (0.093717)\n",
      "Testing 287/2880\n",
      "identity sgd 500 0.001 29 (150,): Weighted 0.842721 (0.053206)\n",
      "identity sgd 500 0.001 29 (150,): Macro 0.739196 (0.075896)\n",
      "Testing 288/2880\n",
      "identity sgd 500 0.001 29 (200,): Weighted 0.827534 (0.031094)\n",
      "identity sgd 500 0.001 29 (200,): Macro 0.724254 (0.049655)\n",
      "Testing 289/2880\n",
      "identity sgd 500 0.001 42 (50,): Weighted 0.793519 (0.072322)\n",
      "identity sgd 500 0.001 42 (50,): Macro 0.654632 (0.067294)\n",
      "Testing 290/2880\n",
      "identity sgd 500 0.001 42 (100,): Weighted 0.799299 (0.073565)\n",
      "identity sgd 500 0.001 42 (100,): Macro 0.682452 (0.091159)\n",
      "Testing 291/2880\n",
      "identity sgd 500 0.001 42 (150,): Weighted 0.761645 (0.064015)\n",
      "identity sgd 500 0.001 42 (150,): Macro 0.621661 (0.059008)\n",
      "Testing 292/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "identity sgd 500 0.001 42 (200,): Weighted 0.738267 (0.083410)\n",
      "identity sgd 500 0.001 42 (200,): Macro 0.613311 (0.101042)\n",
      "Testing 293/2880\n",
      "identity sgd 500 0.001 76 (50,): Weighted 0.839807 (0.041719)\n",
      "identity sgd 500 0.001 76 (50,): Macro 0.733157 (0.042704)\n",
      "Testing 294/2880\n",
      "identity sgd 500 0.001 76 (100,): Weighted 0.809693 (0.071613)\n",
      "identity sgd 500 0.001 76 (100,): Macro 0.708912 (0.093388)\n",
      "Testing 295/2880\n",
      "identity sgd 500 0.001 76 (150,): Weighted 0.833693 (0.039245)\n",
      "identity sgd 500 0.001 76 (150,): Macro 0.724810 (0.043496)\n",
      "Testing 296/2880\n",
      "identity sgd 500 0.001 76 (200,): Weighted 0.824168 (0.024805)\n",
      "identity sgd 500 0.001 76 (200,): Macro 0.685244 (0.012808)\n",
      "Testing 297/2880\n",
      "identity sgd 500 0.001 112 (50,): Weighted 0.772379 (0.084887)\n",
      "identity sgd 500 0.001 112 (50,): Macro 0.653504 (0.104493)\n",
      "Testing 298/2880\n",
      "identity sgd 500 0.001 112 (100,): Weighted 0.794962 (0.080096)\n",
      "identity sgd 500 0.001 112 (100,): Macro 0.674963 (0.093295)\n",
      "Testing 299/2880\n",
      "identity sgd 500 0.001 112 (150,): Weighted 0.806921 (0.084701)\n",
      "identity sgd 500 0.001 112 (150,): Macro 0.698530 (0.098102)\n",
      "Testing 300/2880\n",
      "identity sgd 500 0.001 112 (200,): Weighted 0.791300 (0.053764)\n",
      "identity sgd 500 0.001 112 (200,): Macro 0.661102 (0.043030)\n",
      "Testing 301/2880\n",
      "identity sgd 500 0.0001 17 (50,): Weighted 0.798041 (0.076849)\n",
      "identity sgd 500 0.0001 17 (50,): Macro 0.681160 (0.089146)\n",
      "Testing 302/2880\n",
      "identity sgd 500 0.0001 17 (100,): Weighted 0.827820 (0.033504)\n",
      "identity sgd 500 0.0001 17 (100,): Macro 0.716342 (0.054395)\n",
      "Testing 303/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "identity sgd 500 0.0001 17 (150,): Weighted 0.774621 (0.066585)\n",
      "identity sgd 500 0.0001 17 (150,): Macro 0.627033 (0.075695)\n",
      "Testing 304/2880\n",
      "identity sgd 500 0.0001 17 (200,): Weighted 0.825226 (0.028922)\n",
      "identity sgd 500 0.0001 17 (200,): Macro 0.701073 (0.030654)\n",
      "Testing 305/2880\n",
      "identity sgd 500 0.0001 29 (50,): Weighted 0.786625 (0.014808)\n",
      "identity sgd 500 0.0001 29 (50,): Macro 0.665148 (0.026513)\n",
      "Testing 306/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "identity sgd 500 0.0001 29 (100,): Weighted 0.744469 (0.095323)\n",
      "identity sgd 500 0.0001 29 (100,): Macro 0.608846 (0.093717)\n",
      "Testing 307/2880\n",
      "identity sgd 500 0.0001 29 (150,): Weighted 0.842721 (0.053206)\n",
      "identity sgd 500 0.0001 29 (150,): Macro 0.739196 (0.075896)\n",
      "Testing 308/2880\n",
      "identity sgd 500 0.0001 29 (200,): Weighted 0.827534 (0.031094)\n",
      "identity sgd 500 0.0001 29 (200,): Macro 0.724254 (0.049655)\n",
      "Testing 309/2880\n",
      "identity sgd 500 0.0001 42 (50,): Weighted 0.793519 (0.072322)\n",
      "identity sgd 500 0.0001 42 (50,): Macro 0.654632 (0.067294)\n",
      "Testing 310/2880\n",
      "identity sgd 500 0.0001 42 (100,): Weighted 0.799299 (0.073565)\n",
      "identity sgd 500 0.0001 42 (100,): Macro 0.682452 (0.091159)\n",
      "Testing 311/2880\n",
      "identity sgd 500 0.0001 42 (150,): Weighted 0.761645 (0.064015)\n",
      "identity sgd 500 0.0001 42 (150,): Macro 0.621661 (0.059008)\n",
      "Testing 312/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "identity sgd 500 0.0001 42 (200,): Weighted 0.738267 (0.083410)\n",
      "identity sgd 500 0.0001 42 (200,): Macro 0.613311 (0.101042)\n",
      "Testing 313/2880\n",
      "identity sgd 500 0.0001 76 (50,): Weighted 0.839807 (0.041719)\n",
      "identity sgd 500 0.0001 76 (50,): Macro 0.733157 (0.042704)\n",
      "Testing 314/2880\n",
      "identity sgd 500 0.0001 76 (100,): Weighted 0.809693 (0.071613)\n",
      "identity sgd 500 0.0001 76 (100,): Macro 0.708912 (0.093388)\n",
      "Testing 315/2880\n",
      "identity sgd 500 0.0001 76 (150,): Weighted 0.833693 (0.039245)\n",
      "identity sgd 500 0.0001 76 (150,): Macro 0.724810 (0.043496)\n",
      "Testing 316/2880\n",
      "identity sgd 500 0.0001 76 (200,): Weighted 0.824168 (0.024805)\n",
      "identity sgd 500 0.0001 76 (200,): Macro 0.685244 (0.012808)\n",
      "Testing 317/2880\n",
      "identity sgd 500 0.0001 112 (50,): Weighted 0.772379 (0.084887)\n",
      "identity sgd 500 0.0001 112 (50,): Macro 0.653504 (0.104493)\n",
      "Testing 318/2880\n",
      "identity sgd 500 0.0001 112 (100,): Weighted 0.794962 (0.080096)\n",
      "identity sgd 500 0.0001 112 (100,): Macro 0.674963 (0.093295)\n",
      "Testing 319/2880\n",
      "identity sgd 500 0.0001 112 (150,): Weighted 0.806921 (0.084701)\n",
      "identity sgd 500 0.0001 112 (150,): Macro 0.698530 (0.098102)\n",
      "Testing 320/2880\n",
      "identity sgd 500 0.0001 112 (200,): Weighted 0.791300 (0.053764)\n",
      "identity sgd 500 0.0001 112 (200,): Macro 0.661102 (0.043030)\n",
      "Testing 321/2880\n",
      "identity sgd 1000 0.1 17 (50,): Weighted 0.798041 (0.076849)\n",
      "identity sgd 1000 0.1 17 (50,): Macro 0.681160 (0.089146)\n",
      "Testing 322/2880\n",
      "identity sgd 1000 0.1 17 (100,): Weighted 0.827820 (0.033504)\n",
      "identity sgd 1000 0.1 17 (100,): Macro 0.716342 (0.054395)\n",
      "Testing 323/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "identity sgd 1000 0.1 17 (150,): Weighted 0.774621 (0.066585)\n",
      "identity sgd 1000 0.1 17 (150,): Macro 0.627033 (0.075695)\n",
      "Testing 324/2880\n",
      "identity sgd 1000 0.1 17 (200,): Weighted 0.825226 (0.028922)\n",
      "identity sgd 1000 0.1 17 (200,): Macro 0.701073 (0.030654)\n",
      "Testing 325/2880\n",
      "identity sgd 1000 0.1 29 (50,): Weighted 0.792112 (0.018799)\n",
      "identity sgd 1000 0.1 29 (50,): Macro 0.672446 (0.033605)\n",
      "Testing 326/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "identity sgd 1000 0.1 29 (100,): Weighted 0.744469 (0.095323)\n",
      "identity sgd 1000 0.1 29 (100,): Macro 0.608846 (0.093717)\n",
      "Testing 327/2880\n",
      "identity sgd 1000 0.1 29 (150,): Weighted 0.842721 (0.053206)\n",
      "identity sgd 1000 0.1 29 (150,): Macro 0.739196 (0.075896)\n",
      "Testing 328/2880\n",
      "identity sgd 1000 0.1 29 (200,): Weighted 0.827534 (0.031094)\n",
      "identity sgd 1000 0.1 29 (200,): Macro 0.724254 (0.049655)\n",
      "Testing 329/2880\n",
      "identity sgd 1000 0.1 42 (50,): Weighted 0.793519 (0.072322)\n",
      "identity sgd 1000 0.1 42 (50,): Macro 0.654632 (0.067294)\n",
      "Testing 330/2880\n",
      "identity sgd 1000 0.1 42 (100,): Weighted 0.799299 (0.073565)\n",
      "identity sgd 1000 0.1 42 (100,): Macro 0.682452 (0.091159)\n",
      "Testing 331/2880\n",
      "identity sgd 1000 0.1 42 (150,): Weighted 0.761645 (0.064015)\n",
      "identity sgd 1000 0.1 42 (150,): Macro 0.621661 (0.059008)\n",
      "Testing 332/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "identity sgd 1000 0.1 42 (200,): Weighted 0.738267 (0.083410)\n",
      "identity sgd 1000 0.1 42 (200,): Macro 0.613311 (0.101042)\n",
      "Testing 333/2880\n",
      "identity sgd 1000 0.1 76 (50,): Weighted 0.839807 (0.041719)\n",
      "identity sgd 1000 0.1 76 (50,): Macro 0.733157 (0.042704)\n",
      "Testing 334/2880\n",
      "identity sgd 1000 0.1 76 (100,): Weighted 0.809693 (0.071613)\n",
      "identity sgd 1000 0.1 76 (100,): Macro 0.708912 (0.093388)\n",
      "Testing 335/2880\n",
      "identity sgd 1000 0.1 76 (150,): Weighted 0.833693 (0.039245)\n",
      "identity sgd 1000 0.1 76 (150,): Macro 0.724810 (0.043496)\n",
      "Testing 336/2880\n",
      "identity sgd 1000 0.1 76 (200,): Weighted 0.815669 (0.036343)\n",
      "identity sgd 1000 0.1 76 (200,): Macro 0.672267 (0.032133)\n",
      "Testing 337/2880\n",
      "identity sgd 1000 0.1 112 (50,): Weighted 0.772379 (0.084887)\n",
      "identity sgd 1000 0.1 112 (50,): Macro 0.653504 (0.104493)\n",
      "Testing 338/2880\n",
      "identity sgd 1000 0.1 112 (100,): Weighted 0.794962 (0.080096)\n",
      "identity sgd 1000 0.1 112 (100,): Macro 0.674963 (0.093295)\n",
      "Testing 339/2880\n",
      "identity sgd 1000 0.1 112 (150,): Weighted 0.806921 (0.084701)\n",
      "identity sgd 1000 0.1 112 (150,): Macro 0.698530 (0.098102)\n",
      "Testing 340/2880\n",
      "identity sgd 1000 0.1 112 (200,): Weighted 0.791300 (0.053764)\n",
      "identity sgd 1000 0.1 112 (200,): Macro 0.661102 (0.043030)\n",
      "Testing 341/2880\n",
      "identity sgd 1000 0.01 17 (50,): Weighted 0.798041 (0.076849)\n",
      "identity sgd 1000 0.01 17 (50,): Macro 0.681160 (0.089146)\n",
      "Testing 342/2880\n",
      "identity sgd 1000 0.01 17 (100,): Weighted 0.827820 (0.033504)\n",
      "identity sgd 1000 0.01 17 (100,): Macro 0.716342 (0.054395)\n",
      "Testing 343/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "identity sgd 1000 0.01 17 (150,): Weighted 0.774621 (0.066585)\n",
      "identity sgd 1000 0.01 17 (150,): Macro 0.627033 (0.075695)\n",
      "Testing 344/2880\n",
      "identity sgd 1000 0.01 17 (200,): Weighted 0.825226 (0.028922)\n",
      "identity sgd 1000 0.01 17 (200,): Macro 0.701073 (0.030654)\n",
      "Testing 345/2880\n",
      "identity sgd 1000 0.01 29 (50,): Weighted 0.786625 (0.014808)\n",
      "identity sgd 1000 0.01 29 (50,): Macro 0.665148 (0.026513)\n",
      "Testing 346/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "identity sgd 1000 0.01 29 (100,): Weighted 0.744469 (0.095323)\n",
      "identity sgd 1000 0.01 29 (100,): Macro 0.608846 (0.093717)\n",
      "Testing 347/2880\n",
      "identity sgd 1000 0.01 29 (150,): Weighted 0.842721 (0.053206)\n",
      "identity sgd 1000 0.01 29 (150,): Macro 0.739196 (0.075896)\n",
      "Testing 348/2880\n",
      "identity sgd 1000 0.01 29 (200,): Weighted 0.827534 (0.031094)\n",
      "identity sgd 1000 0.01 29 (200,): Macro 0.724254 (0.049655)\n",
      "Testing 349/2880\n",
      "identity sgd 1000 0.01 42 (50,): Weighted 0.793519 (0.072322)\n",
      "identity sgd 1000 0.01 42 (50,): Macro 0.654632 (0.067294)\n",
      "Testing 350/2880\n",
      "identity sgd 1000 0.01 42 (100,): Weighted 0.799299 (0.073565)\n",
      "identity sgd 1000 0.01 42 (100,): Macro 0.682452 (0.091159)\n",
      "Testing 351/2880\n",
      "identity sgd 1000 0.01 42 (150,): Weighted 0.761645 (0.064015)\n",
      "identity sgd 1000 0.01 42 (150,): Macro 0.621661 (0.059008)\n",
      "Testing 352/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "identity sgd 1000 0.01 42 (200,): Weighted 0.738267 (0.083410)\n",
      "identity sgd 1000 0.01 42 (200,): Macro 0.613311 (0.101042)\n",
      "Testing 353/2880\n",
      "identity sgd 1000 0.01 76 (50,): Weighted 0.839807 (0.041719)\n",
      "identity sgd 1000 0.01 76 (50,): Macro 0.733157 (0.042704)\n",
      "Testing 354/2880\n",
      "identity sgd 1000 0.01 76 (100,): Weighted 0.809693 (0.071613)\n",
      "identity sgd 1000 0.01 76 (100,): Macro 0.708912 (0.093388)\n",
      "Testing 355/2880\n",
      "identity sgd 1000 0.01 76 (150,): Weighted 0.833693 (0.039245)\n",
      "identity sgd 1000 0.01 76 (150,): Macro 0.724810 (0.043496)\n",
      "Testing 356/2880\n",
      "identity sgd 1000 0.01 76 (200,): Weighted 0.824168 (0.024805)\n",
      "identity sgd 1000 0.01 76 (200,): Macro 0.685244 (0.012808)\n",
      "Testing 357/2880\n",
      "identity sgd 1000 0.01 112 (50,): Weighted 0.772379 (0.084887)\n",
      "identity sgd 1000 0.01 112 (50,): Macro 0.653504 (0.104493)\n",
      "Testing 358/2880\n",
      "identity sgd 1000 0.01 112 (100,): Weighted 0.794962 (0.080096)\n",
      "identity sgd 1000 0.01 112 (100,): Macro 0.674963 (0.093295)\n",
      "Testing 359/2880\n",
      "identity sgd 1000 0.01 112 (150,): Weighted 0.806921 (0.084701)\n",
      "identity sgd 1000 0.01 112 (150,): Macro 0.698530 (0.098102)\n",
      "Testing 360/2880\n",
      "identity sgd 1000 0.01 112 (200,): Weighted 0.791300 (0.053764)\n",
      "identity sgd 1000 0.01 112 (200,): Macro 0.661102 (0.043030)\n",
      "Testing 361/2880\n",
      "identity sgd 1000 0.001 17 (50,): Weighted 0.798041 (0.076849)\n",
      "identity sgd 1000 0.001 17 (50,): Macro 0.681160 (0.089146)\n",
      "Testing 362/2880\n",
      "identity sgd 1000 0.001 17 (100,): Weighted 0.827820 (0.033504)\n",
      "identity sgd 1000 0.001 17 (100,): Macro 0.716342 (0.054395)\n",
      "Testing 363/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "identity sgd 1000 0.001 17 (150,): Weighted 0.774621 (0.066585)\n",
      "identity sgd 1000 0.001 17 (150,): Macro 0.627033 (0.075695)\n",
      "Testing 364/2880\n",
      "identity sgd 1000 0.001 17 (200,): Weighted 0.825226 (0.028922)\n",
      "identity sgd 1000 0.001 17 (200,): Macro 0.701073 (0.030654)\n",
      "Testing 365/2880\n",
      "identity sgd 1000 0.001 29 (50,): Weighted 0.786625 (0.014808)\n",
      "identity sgd 1000 0.001 29 (50,): Macro 0.665148 (0.026513)\n",
      "Testing 366/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "identity sgd 1000 0.001 29 (100,): Weighted 0.744469 (0.095323)\n",
      "identity sgd 1000 0.001 29 (100,): Macro 0.608846 (0.093717)\n",
      "Testing 367/2880\n",
      "identity sgd 1000 0.001 29 (150,): Weighted 0.842721 (0.053206)\n",
      "identity sgd 1000 0.001 29 (150,): Macro 0.739196 (0.075896)\n",
      "Testing 368/2880\n",
      "identity sgd 1000 0.001 29 (200,): Weighted 0.827534 (0.031094)\n",
      "identity sgd 1000 0.001 29 (200,): Macro 0.724254 (0.049655)\n",
      "Testing 369/2880\n",
      "identity sgd 1000 0.001 42 (50,): Weighted 0.793519 (0.072322)\n",
      "identity sgd 1000 0.001 42 (50,): Macro 0.654632 (0.067294)\n",
      "Testing 370/2880\n",
      "identity sgd 1000 0.001 42 (100,): Weighted 0.799299 (0.073565)\n",
      "identity sgd 1000 0.001 42 (100,): Macro 0.682452 (0.091159)\n",
      "Testing 371/2880\n",
      "identity sgd 1000 0.001 42 (150,): Weighted 0.761645 (0.064015)\n",
      "identity sgd 1000 0.001 42 (150,): Macro 0.621661 (0.059008)\n",
      "Testing 372/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "identity sgd 1000 0.001 42 (200,): Weighted 0.738267 (0.083410)\n",
      "identity sgd 1000 0.001 42 (200,): Macro 0.613311 (0.101042)\n",
      "Testing 373/2880\n",
      "identity sgd 1000 0.001 76 (50,): Weighted 0.839807 (0.041719)\n",
      "identity sgd 1000 0.001 76 (50,): Macro 0.733157 (0.042704)\n",
      "Testing 374/2880\n",
      "identity sgd 1000 0.001 76 (100,): Weighted 0.809693 (0.071613)\n",
      "identity sgd 1000 0.001 76 (100,): Macro 0.708912 (0.093388)\n",
      "Testing 375/2880\n",
      "identity sgd 1000 0.001 76 (150,): Weighted 0.833693 (0.039245)\n",
      "identity sgd 1000 0.001 76 (150,): Macro 0.724810 (0.043496)\n",
      "Testing 376/2880\n",
      "identity sgd 1000 0.001 76 (200,): Weighted 0.824168 (0.024805)\n",
      "identity sgd 1000 0.001 76 (200,): Macro 0.685244 (0.012808)\n",
      "Testing 377/2880\n",
      "identity sgd 1000 0.001 112 (50,): Weighted 0.772379 (0.084887)\n",
      "identity sgd 1000 0.001 112 (50,): Macro 0.653504 (0.104493)\n",
      "Testing 378/2880\n",
      "identity sgd 1000 0.001 112 (100,): Weighted 0.794962 (0.080096)\n",
      "identity sgd 1000 0.001 112 (100,): Macro 0.674963 (0.093295)\n",
      "Testing 379/2880\n",
      "identity sgd 1000 0.001 112 (150,): Weighted 0.806921 (0.084701)\n",
      "identity sgd 1000 0.001 112 (150,): Macro 0.698530 (0.098102)\n",
      "Testing 380/2880\n",
      "identity sgd 1000 0.001 112 (200,): Weighted 0.791300 (0.053764)\n",
      "identity sgd 1000 0.001 112 (200,): Macro 0.661102 (0.043030)\n",
      "Testing 381/2880\n",
      "identity sgd 1000 0.0001 17 (50,): Weighted 0.798041 (0.076849)\n",
      "identity sgd 1000 0.0001 17 (50,): Macro 0.681160 (0.089146)\n",
      "Testing 382/2880\n",
      "identity sgd 1000 0.0001 17 (100,): Weighted 0.827820 (0.033504)\n",
      "identity sgd 1000 0.0001 17 (100,): Macro 0.716342 (0.054395)\n",
      "Testing 383/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "identity sgd 1000 0.0001 17 (150,): Weighted 0.774621 (0.066585)\n",
      "identity sgd 1000 0.0001 17 (150,): Macro 0.627033 (0.075695)\n",
      "Testing 384/2880\n",
      "identity sgd 1000 0.0001 17 (200,): Weighted 0.825226 (0.028922)\n",
      "identity sgd 1000 0.0001 17 (200,): Macro 0.701073 (0.030654)\n",
      "Testing 385/2880\n",
      "identity sgd 1000 0.0001 29 (50,): Weighted 0.786625 (0.014808)\n",
      "identity sgd 1000 0.0001 29 (50,): Macro 0.665148 (0.026513)\n",
      "Testing 386/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "identity sgd 1000 0.0001 29 (100,): Weighted 0.744469 (0.095323)\n",
      "identity sgd 1000 0.0001 29 (100,): Macro 0.608846 (0.093717)\n",
      "Testing 387/2880\n",
      "identity sgd 1000 0.0001 29 (150,): Weighted 0.842721 (0.053206)\n",
      "identity sgd 1000 0.0001 29 (150,): Macro 0.739196 (0.075896)\n",
      "Testing 388/2880\n",
      "identity sgd 1000 0.0001 29 (200,): Weighted 0.827534 (0.031094)\n",
      "identity sgd 1000 0.0001 29 (200,): Macro 0.724254 (0.049655)\n",
      "Testing 389/2880\n",
      "identity sgd 1000 0.0001 42 (50,): Weighted 0.793519 (0.072322)\n",
      "identity sgd 1000 0.0001 42 (50,): Macro 0.654632 (0.067294)\n",
      "Testing 390/2880\n",
      "identity sgd 1000 0.0001 42 (100,): Weighted 0.799299 (0.073565)\n",
      "identity sgd 1000 0.0001 42 (100,): Macro 0.682452 (0.091159)\n",
      "Testing 391/2880\n",
      "identity sgd 1000 0.0001 42 (150,): Weighted 0.761645 (0.064015)\n",
      "identity sgd 1000 0.0001 42 (150,): Macro 0.621661 (0.059008)\n",
      "Testing 392/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "identity sgd 1000 0.0001 42 (200,): Weighted 0.738267 (0.083410)\n",
      "identity sgd 1000 0.0001 42 (200,): Macro 0.613311 (0.101042)\n",
      "Testing 393/2880\n",
      "identity sgd 1000 0.0001 76 (50,): Weighted 0.839807 (0.041719)\n",
      "identity sgd 1000 0.0001 76 (50,): Macro 0.733157 (0.042704)\n",
      "Testing 394/2880\n",
      "identity sgd 1000 0.0001 76 (100,): Weighted 0.809693 (0.071613)\n",
      "identity sgd 1000 0.0001 76 (100,): Macro 0.708912 (0.093388)\n",
      "Testing 395/2880\n",
      "identity sgd 1000 0.0001 76 (150,): Weighted 0.833693 (0.039245)\n",
      "identity sgd 1000 0.0001 76 (150,): Macro 0.724810 (0.043496)\n",
      "Testing 396/2880\n",
      "identity sgd 1000 0.0001 76 (200,): Weighted 0.824168 (0.024805)\n",
      "identity sgd 1000 0.0001 76 (200,): Macro 0.685244 (0.012808)\n",
      "Testing 397/2880\n",
      "identity sgd 1000 0.0001 112 (50,): Weighted 0.772379 (0.084887)\n",
      "identity sgd 1000 0.0001 112 (50,): Macro 0.653504 (0.104493)\n",
      "Testing 398/2880\n",
      "identity sgd 1000 0.0001 112 (100,): Weighted 0.794962 (0.080096)\n",
      "identity sgd 1000 0.0001 112 (100,): Macro 0.674963 (0.093295)\n",
      "Testing 399/2880\n",
      "identity sgd 1000 0.0001 112 (150,): Weighted 0.806921 (0.084701)\n",
      "identity sgd 1000 0.0001 112 (150,): Macro 0.698530 (0.098102)\n",
      "Testing 400/2880\n",
      "identity sgd 1000 0.0001 112 (200,): Weighted 0.791300 (0.053764)\n",
      "identity sgd 1000 0.0001 112 (200,): Macro 0.661102 (0.043030)\n",
      "Testing 401/2880\n",
      "identity sgd 1500 0.1 17 (50,): Weighted 0.798041 (0.076849)\n",
      "identity sgd 1500 0.1 17 (50,): Macro 0.681160 (0.089146)\n",
      "Testing 402/2880\n",
      "identity sgd 1500 0.1 17 (100,): Weighted 0.827820 (0.033504)\n",
      "identity sgd 1500 0.1 17 (100,): Macro 0.716342 (0.054395)\n",
      "Testing 403/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "identity sgd 1500 0.1 17 (150,): Weighted 0.774621 (0.066585)\n",
      "identity sgd 1500 0.1 17 (150,): Macro 0.627033 (0.075695)\n",
      "Testing 404/2880\n",
      "identity sgd 1500 0.1 17 (200,): Weighted 0.825226 (0.028922)\n",
      "identity sgd 1500 0.1 17 (200,): Macro 0.701073 (0.030654)\n",
      "Testing 405/2880\n",
      "identity sgd 1500 0.1 29 (50,): Weighted 0.792112 (0.018799)\n",
      "identity sgd 1500 0.1 29 (50,): Macro 0.672446 (0.033605)\n",
      "Testing 406/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "identity sgd 1500 0.1 29 (100,): Weighted 0.744469 (0.095323)\n",
      "identity sgd 1500 0.1 29 (100,): Macro 0.608846 (0.093717)\n",
      "Testing 407/2880\n",
      "identity sgd 1500 0.1 29 (150,): Weighted 0.842721 (0.053206)\n",
      "identity sgd 1500 0.1 29 (150,): Macro 0.739196 (0.075896)\n",
      "Testing 408/2880\n",
      "identity sgd 1500 0.1 29 (200,): Weighted 0.827534 (0.031094)\n",
      "identity sgd 1500 0.1 29 (200,): Macro 0.724254 (0.049655)\n",
      "Testing 409/2880\n",
      "identity sgd 1500 0.1 42 (50,): Weighted 0.793519 (0.072322)\n",
      "identity sgd 1500 0.1 42 (50,): Macro 0.654632 (0.067294)\n",
      "Testing 410/2880\n",
      "identity sgd 1500 0.1 42 (100,): Weighted 0.799299 (0.073565)\n",
      "identity sgd 1500 0.1 42 (100,): Macro 0.682452 (0.091159)\n",
      "Testing 411/2880\n",
      "identity sgd 1500 0.1 42 (150,): Weighted 0.761645 (0.064015)\n",
      "identity sgd 1500 0.1 42 (150,): Macro 0.621661 (0.059008)\n",
      "Testing 412/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "identity sgd 1500 0.1 42 (200,): Weighted 0.738267 (0.083410)\n",
      "identity sgd 1500 0.1 42 (200,): Macro 0.613311 (0.101042)\n",
      "Testing 413/2880\n",
      "identity sgd 1500 0.1 76 (50,): Weighted 0.839807 (0.041719)\n",
      "identity sgd 1500 0.1 76 (50,): Macro 0.733157 (0.042704)\n",
      "Testing 414/2880\n",
      "identity sgd 1500 0.1 76 (100,): Weighted 0.809693 (0.071613)\n",
      "identity sgd 1500 0.1 76 (100,): Macro 0.708912 (0.093388)\n",
      "Testing 415/2880\n",
      "identity sgd 1500 0.1 76 (150,): Weighted 0.833693 (0.039245)\n",
      "identity sgd 1500 0.1 76 (150,): Macro 0.724810 (0.043496)\n",
      "Testing 416/2880\n",
      "identity sgd 1500 0.1 76 (200,): Weighted 0.815669 (0.036343)\n",
      "identity sgd 1500 0.1 76 (200,): Macro 0.672267 (0.032133)\n",
      "Testing 417/2880\n",
      "identity sgd 1500 0.1 112 (50,): Weighted 0.772379 (0.084887)\n",
      "identity sgd 1500 0.1 112 (50,): Macro 0.653504 (0.104493)\n",
      "Testing 418/2880\n",
      "identity sgd 1500 0.1 112 (100,): Weighted 0.794962 (0.080096)\n",
      "identity sgd 1500 0.1 112 (100,): Macro 0.674963 (0.093295)\n",
      "Testing 419/2880\n",
      "identity sgd 1500 0.1 112 (150,): Weighted 0.806921 (0.084701)\n",
      "identity sgd 1500 0.1 112 (150,): Macro 0.698530 (0.098102)\n",
      "Testing 420/2880\n",
      "identity sgd 1500 0.1 112 (200,): Weighted 0.791300 (0.053764)\n",
      "identity sgd 1500 0.1 112 (200,): Macro 0.661102 (0.043030)\n",
      "Testing 421/2880\n",
      "identity sgd 1500 0.01 17 (50,): Weighted 0.798041 (0.076849)\n",
      "identity sgd 1500 0.01 17 (50,): Macro 0.681160 (0.089146)\n",
      "Testing 422/2880\n",
      "identity sgd 1500 0.01 17 (100,): Weighted 0.827820 (0.033504)\n",
      "identity sgd 1500 0.01 17 (100,): Macro 0.716342 (0.054395)\n",
      "Testing 423/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "identity sgd 1500 0.01 17 (150,): Weighted 0.774621 (0.066585)\n",
      "identity sgd 1500 0.01 17 (150,): Macro 0.627033 (0.075695)\n",
      "Testing 424/2880\n",
      "identity sgd 1500 0.01 17 (200,): Weighted 0.825226 (0.028922)\n",
      "identity sgd 1500 0.01 17 (200,): Macro 0.701073 (0.030654)\n",
      "Testing 425/2880\n",
      "identity sgd 1500 0.01 29 (50,): Weighted 0.786625 (0.014808)\n",
      "identity sgd 1500 0.01 29 (50,): Macro 0.665148 (0.026513)\n",
      "Testing 426/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "identity sgd 1500 0.01 29 (100,): Weighted 0.744469 (0.095323)\n",
      "identity sgd 1500 0.01 29 (100,): Macro 0.608846 (0.093717)\n",
      "Testing 427/2880\n",
      "identity sgd 1500 0.01 29 (150,): Weighted 0.842721 (0.053206)\n",
      "identity sgd 1500 0.01 29 (150,): Macro 0.739196 (0.075896)\n",
      "Testing 428/2880\n",
      "identity sgd 1500 0.01 29 (200,): Weighted 0.827534 (0.031094)\n",
      "identity sgd 1500 0.01 29 (200,): Macro 0.724254 (0.049655)\n",
      "Testing 429/2880\n",
      "identity sgd 1500 0.01 42 (50,): Weighted 0.793519 (0.072322)\n",
      "identity sgd 1500 0.01 42 (50,): Macro 0.654632 (0.067294)\n",
      "Testing 430/2880\n",
      "identity sgd 1500 0.01 42 (100,): Weighted 0.799299 (0.073565)\n",
      "identity sgd 1500 0.01 42 (100,): Macro 0.682452 (0.091159)\n",
      "Testing 431/2880\n",
      "identity sgd 1500 0.01 42 (150,): Weighted 0.761645 (0.064015)\n",
      "identity sgd 1500 0.01 42 (150,): Macro 0.621661 (0.059008)\n",
      "Testing 432/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "identity sgd 1500 0.01 42 (200,): Weighted 0.738267 (0.083410)\n",
      "identity sgd 1500 0.01 42 (200,): Macro 0.613311 (0.101042)\n",
      "Testing 433/2880\n",
      "identity sgd 1500 0.01 76 (50,): Weighted 0.839807 (0.041719)\n",
      "identity sgd 1500 0.01 76 (50,): Macro 0.733157 (0.042704)\n",
      "Testing 434/2880\n",
      "identity sgd 1500 0.01 76 (100,): Weighted 0.809693 (0.071613)\n",
      "identity sgd 1500 0.01 76 (100,): Macro 0.708912 (0.093388)\n",
      "Testing 435/2880\n",
      "identity sgd 1500 0.01 76 (150,): Weighted 0.833693 (0.039245)\n",
      "identity sgd 1500 0.01 76 (150,): Macro 0.724810 (0.043496)\n",
      "Testing 436/2880\n",
      "identity sgd 1500 0.01 76 (200,): Weighted 0.824168 (0.024805)\n",
      "identity sgd 1500 0.01 76 (200,): Macro 0.685244 (0.012808)\n",
      "Testing 437/2880\n",
      "identity sgd 1500 0.01 112 (50,): Weighted 0.772379 (0.084887)\n",
      "identity sgd 1500 0.01 112 (50,): Macro 0.653504 (0.104493)\n",
      "Testing 438/2880\n",
      "identity sgd 1500 0.01 112 (100,): Weighted 0.794962 (0.080096)\n",
      "identity sgd 1500 0.01 112 (100,): Macro 0.674963 (0.093295)\n",
      "Testing 439/2880\n",
      "identity sgd 1500 0.01 112 (150,): Weighted 0.806921 (0.084701)\n",
      "identity sgd 1500 0.01 112 (150,): Macro 0.698530 (0.098102)\n",
      "Testing 440/2880\n",
      "identity sgd 1500 0.01 112 (200,): Weighted 0.791300 (0.053764)\n",
      "identity sgd 1500 0.01 112 (200,): Macro 0.661102 (0.043030)\n",
      "Testing 441/2880\n",
      "identity sgd 1500 0.001 17 (50,): Weighted 0.798041 (0.076849)\n",
      "identity sgd 1500 0.001 17 (50,): Macro 0.681160 (0.089146)\n",
      "Testing 442/2880\n",
      "identity sgd 1500 0.001 17 (100,): Weighted 0.827820 (0.033504)\n",
      "identity sgd 1500 0.001 17 (100,): Macro 0.716342 (0.054395)\n",
      "Testing 443/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "identity sgd 1500 0.001 17 (150,): Weighted 0.774621 (0.066585)\n",
      "identity sgd 1500 0.001 17 (150,): Macro 0.627033 (0.075695)\n",
      "Testing 444/2880\n",
      "identity sgd 1500 0.001 17 (200,): Weighted 0.825226 (0.028922)\n",
      "identity sgd 1500 0.001 17 (200,): Macro 0.701073 (0.030654)\n",
      "Testing 445/2880\n",
      "identity sgd 1500 0.001 29 (50,): Weighted 0.786625 (0.014808)\n",
      "identity sgd 1500 0.001 29 (50,): Macro 0.665148 (0.026513)\n",
      "Testing 446/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "identity sgd 1500 0.001 29 (100,): Weighted 0.744469 (0.095323)\n",
      "identity sgd 1500 0.001 29 (100,): Macro 0.608846 (0.093717)\n",
      "Testing 447/2880\n",
      "identity sgd 1500 0.001 29 (150,): Weighted 0.842721 (0.053206)\n",
      "identity sgd 1500 0.001 29 (150,): Macro 0.739196 (0.075896)\n",
      "Testing 448/2880\n",
      "identity sgd 1500 0.001 29 (200,): Weighted 0.827534 (0.031094)\n",
      "identity sgd 1500 0.001 29 (200,): Macro 0.724254 (0.049655)\n",
      "Testing 449/2880\n",
      "identity sgd 1500 0.001 42 (50,): Weighted 0.793519 (0.072322)\n",
      "identity sgd 1500 0.001 42 (50,): Macro 0.654632 (0.067294)\n",
      "Testing 450/2880\n",
      "identity sgd 1500 0.001 42 (100,): Weighted 0.799299 (0.073565)\n",
      "identity sgd 1500 0.001 42 (100,): Macro 0.682452 (0.091159)\n",
      "Testing 451/2880\n",
      "identity sgd 1500 0.001 42 (150,): Weighted 0.761645 (0.064015)\n",
      "identity sgd 1500 0.001 42 (150,): Macro 0.621661 (0.059008)\n",
      "Testing 452/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "identity sgd 1500 0.001 42 (200,): Weighted 0.738267 (0.083410)\n",
      "identity sgd 1500 0.001 42 (200,): Macro 0.613311 (0.101042)\n",
      "Testing 453/2880\n",
      "identity sgd 1500 0.001 76 (50,): Weighted 0.839807 (0.041719)\n",
      "identity sgd 1500 0.001 76 (50,): Macro 0.733157 (0.042704)\n",
      "Testing 454/2880\n",
      "identity sgd 1500 0.001 76 (100,): Weighted 0.809693 (0.071613)\n",
      "identity sgd 1500 0.001 76 (100,): Macro 0.708912 (0.093388)\n",
      "Testing 455/2880\n",
      "identity sgd 1500 0.001 76 (150,): Weighted 0.833693 (0.039245)\n",
      "identity sgd 1500 0.001 76 (150,): Macro 0.724810 (0.043496)\n",
      "Testing 456/2880\n",
      "identity sgd 1500 0.001 76 (200,): Weighted 0.824168 (0.024805)\n",
      "identity sgd 1500 0.001 76 (200,): Macro 0.685244 (0.012808)\n",
      "Testing 457/2880\n",
      "identity sgd 1500 0.001 112 (50,): Weighted 0.772379 (0.084887)\n",
      "identity sgd 1500 0.001 112 (50,): Macro 0.653504 (0.104493)\n",
      "Testing 458/2880\n",
      "identity sgd 1500 0.001 112 (100,): Weighted 0.794962 (0.080096)\n",
      "identity sgd 1500 0.001 112 (100,): Macro 0.674963 (0.093295)\n",
      "Testing 459/2880\n",
      "identity sgd 1500 0.001 112 (150,): Weighted 0.806921 (0.084701)\n",
      "identity sgd 1500 0.001 112 (150,): Macro 0.698530 (0.098102)\n",
      "Testing 460/2880\n",
      "identity sgd 1500 0.001 112 (200,): Weighted 0.791300 (0.053764)\n",
      "identity sgd 1500 0.001 112 (200,): Macro 0.661102 (0.043030)\n",
      "Testing 461/2880\n",
      "identity sgd 1500 0.0001 17 (50,): Weighted 0.798041 (0.076849)\n",
      "identity sgd 1500 0.0001 17 (50,): Macro 0.681160 (0.089146)\n",
      "Testing 462/2880\n",
      "identity sgd 1500 0.0001 17 (100,): Weighted 0.827820 (0.033504)\n",
      "identity sgd 1500 0.0001 17 (100,): Macro 0.716342 (0.054395)\n",
      "Testing 463/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "identity sgd 1500 0.0001 17 (150,): Weighted 0.774621 (0.066585)\n",
      "identity sgd 1500 0.0001 17 (150,): Macro 0.627033 (0.075695)\n",
      "Testing 464/2880\n",
      "identity sgd 1500 0.0001 17 (200,): Weighted 0.825226 (0.028922)\n",
      "identity sgd 1500 0.0001 17 (200,): Macro 0.701073 (0.030654)\n",
      "Testing 465/2880\n",
      "identity sgd 1500 0.0001 29 (50,): Weighted 0.786625 (0.014808)\n",
      "identity sgd 1500 0.0001 29 (50,): Macro 0.665148 (0.026513)\n",
      "Testing 466/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "identity sgd 1500 0.0001 29 (100,): Weighted 0.744469 (0.095323)\n",
      "identity sgd 1500 0.0001 29 (100,): Macro 0.608846 (0.093717)\n",
      "Testing 467/2880\n",
      "identity sgd 1500 0.0001 29 (150,): Weighted 0.842721 (0.053206)\n",
      "identity sgd 1500 0.0001 29 (150,): Macro 0.739196 (0.075896)\n",
      "Testing 468/2880\n",
      "identity sgd 1500 0.0001 29 (200,): Weighted 0.827534 (0.031094)\n",
      "identity sgd 1500 0.0001 29 (200,): Macro 0.724254 (0.049655)\n",
      "Testing 469/2880\n",
      "identity sgd 1500 0.0001 42 (50,): Weighted 0.793519 (0.072322)\n",
      "identity sgd 1500 0.0001 42 (50,): Macro 0.654632 (0.067294)\n",
      "Testing 470/2880\n",
      "identity sgd 1500 0.0001 42 (100,): Weighted 0.799299 (0.073565)\n",
      "identity sgd 1500 0.0001 42 (100,): Macro 0.682452 (0.091159)\n",
      "Testing 471/2880\n",
      "identity sgd 1500 0.0001 42 (150,): Weighted 0.761645 (0.064015)\n",
      "identity sgd 1500 0.0001 42 (150,): Macro 0.621661 (0.059008)\n",
      "Testing 472/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "identity sgd 1500 0.0001 42 (200,): Weighted 0.738267 (0.083410)\n",
      "identity sgd 1500 0.0001 42 (200,): Macro 0.613311 (0.101042)\n",
      "Testing 473/2880\n",
      "identity sgd 1500 0.0001 76 (50,): Weighted 0.839807 (0.041719)\n",
      "identity sgd 1500 0.0001 76 (50,): Macro 0.733157 (0.042704)\n",
      "Testing 474/2880\n",
      "identity sgd 1500 0.0001 76 (100,): Weighted 0.809693 (0.071613)\n",
      "identity sgd 1500 0.0001 76 (100,): Macro 0.708912 (0.093388)\n",
      "Testing 475/2880\n",
      "identity sgd 1500 0.0001 76 (150,): Weighted 0.833693 (0.039245)\n",
      "identity sgd 1500 0.0001 76 (150,): Macro 0.724810 (0.043496)\n",
      "Testing 476/2880\n",
      "identity sgd 1500 0.0001 76 (200,): Weighted 0.824168 (0.024805)\n",
      "identity sgd 1500 0.0001 76 (200,): Macro 0.685244 (0.012808)\n",
      "Testing 477/2880\n",
      "identity sgd 1500 0.0001 112 (50,): Weighted 0.772379 (0.084887)\n",
      "identity sgd 1500 0.0001 112 (50,): Macro 0.653504 (0.104493)\n",
      "Testing 478/2880\n",
      "identity sgd 1500 0.0001 112 (100,): Weighted 0.794962 (0.080096)\n",
      "identity sgd 1500 0.0001 112 (100,): Macro 0.674963 (0.093295)\n",
      "Testing 479/2880\n",
      "identity sgd 1500 0.0001 112 (150,): Weighted 0.806921 (0.084701)\n",
      "identity sgd 1500 0.0001 112 (150,): Macro 0.698530 (0.098102)\n",
      "Testing 480/2880\n",
      "identity sgd 1500 0.0001 112 (200,): Weighted 0.791300 (0.053764)\n",
      "identity sgd 1500 0.0001 112 (200,): Macro 0.661102 (0.043030)\n",
      "Testing 481/2880\n",
      "identity adam 500 0.1 17 (50,): Weighted 0.834422 (0.055612)\n",
      "identity adam 500 0.1 17 (50,): Macro 0.727776 (0.071500)\n",
      "Testing 482/2880\n",
      "identity adam 500 0.1 17 (100,): Weighted 0.839125 (0.068253)\n",
      "identity adam 500 0.1 17 (100,): Macro 0.734879 (0.093691)\n",
      "Testing 483/2880\n",
      "identity adam 500 0.1 17 (150,): Weighted 0.837025 (0.062367)\n",
      "identity adam 500 0.1 17 (150,): Macro 0.726094 (0.081334)\n",
      "Testing 484/2880\n",
      "identity adam 500 0.1 17 (200,): Weighted 0.838398 (0.058099)\n",
      "identity adam 500 0.1 17 (200,): Macro 0.736715 (0.078337)\n",
      "Testing 485/2880\n",
      "identity adam 500 0.1 29 (50,): Weighted 0.841356 (0.075253)\n",
      "identity adam 500 0.1 29 (50,): Macro 0.744836 (0.109097)\n",
      "Testing 486/2880\n",
      "identity adam 500 0.1 29 (100,): Weighted 0.821737 (0.058741)\n",
      "identity adam 500 0.1 29 (100,): Macro 0.715107 (0.076722)\n",
      "Testing 487/2880\n",
      "identity adam 500 0.1 29 (150,): Weighted 0.821336 (0.051270)\n",
      "identity adam 500 0.1 29 (150,): Macro 0.706723 (0.065262)\n",
      "Testing 488/2880\n",
      "identity adam 500 0.1 29 (200,): Weighted 0.842079 (0.060805)\n",
      "identity adam 500 0.1 29 (200,): Macro 0.745742 (0.084501)\n",
      "Testing 489/2880\n",
      "identity adam 500 0.1 42 (50,): Weighted 0.820174 (0.052532)\n",
      "identity adam 500 0.1 42 (50,): Macro 0.700651 (0.059261)\n",
      "Testing 490/2880\n",
      "identity adam 500 0.1 42 (100,): Weighted 0.840739 (0.039074)\n",
      "identity adam 500 0.1 42 (100,): Macro 0.739436 (0.051953)\n",
      "Testing 491/2880\n",
      "identity adam 500 0.1 42 (150,): Weighted 0.836578 (0.061903)\n",
      "identity adam 500 0.1 42 (150,): Macro 0.740263 (0.089580)\n",
      "Testing 492/2880\n",
      "identity adam 500 0.1 42 (200,): Weighted 0.822574 (0.059569)\n",
      "identity adam 500 0.1 42 (200,): Macro 0.704945 (0.072077)\n",
      "Testing 493/2880\n",
      "identity adam 500 0.1 76 (50,): Weighted 0.827111 (0.058437)\n",
      "identity adam 500 0.1 76 (50,): Macro 0.720610 (0.082709)\n",
      "Testing 494/2880\n",
      "identity adam 500 0.1 76 (100,): Weighted 0.833179 (0.052295)\n",
      "identity adam 500 0.1 76 (100,): Macro 0.729152 (0.074302)\n",
      "Testing 495/2880\n",
      "identity adam 500 0.1 76 (150,): Weighted 0.836903 (0.069694)\n",
      "identity adam 500 0.1 76 (150,): Macro 0.732472 (0.095196)\n",
      "Testing 496/2880\n",
      "identity adam 500 0.1 76 (200,): Weighted 0.830930 (0.051817)\n",
      "identity adam 500 0.1 76 (200,): Macro 0.718506 (0.059186)\n",
      "Testing 497/2880\n",
      "identity adam 500 0.1 112 (50,): Weighted 0.829335 (0.069587)\n",
      "identity adam 500 0.1 112 (50,): Macro 0.720950 (0.094275)\n",
      "Testing 498/2880\n",
      "identity adam 500 0.1 112 (100,): Weighted 0.830930 (0.051817)\n",
      "identity adam 500 0.1 112 (100,): Macro 0.718506 (0.059186)\n",
      "Testing 499/2880\n",
      "identity adam 500 0.1 112 (150,): Weighted 0.831384 (0.068543)\n",
      "identity adam 500 0.1 112 (150,): Macro 0.722189 (0.094227)\n",
      "Testing 500/2880\n",
      "identity adam 500 0.1 112 (200,): Weighted 0.828196 (0.059630)\n",
      "identity adam 500 0.1 112 (200,): Macro 0.724141 (0.085694)\n",
      "Testing 501/2880\n",
      "identity adam 500 0.01 17 (50,): Weighted 0.834422 (0.055612)\n",
      "identity adam 500 0.01 17 (50,): Macro 0.727776 (0.071500)\n",
      "Testing 502/2880\n",
      "identity adam 500 0.01 17 (100,): Weighted 0.839125 (0.068253)\n",
      "identity adam 500 0.01 17 (100,): Macro 0.734879 (0.093691)\n",
      "Testing 503/2880\n",
      "identity adam 500 0.01 17 (150,): Weighted 0.837025 (0.062367)\n",
      "identity adam 500 0.01 17 (150,): Macro 0.726094 (0.081334)\n",
      "Testing 504/2880\n",
      "identity adam 500 0.01 17 (200,): Weighted 0.838398 (0.058099)\n",
      "identity adam 500 0.01 17 (200,): Macro 0.736715 (0.078337)\n",
      "Testing 505/2880\n",
      "identity adam 500 0.01 29 (50,): Weighted 0.841356 (0.075253)\n",
      "identity adam 500 0.01 29 (50,): Macro 0.744836 (0.109097)\n",
      "Testing 506/2880\n",
      "identity adam 500 0.01 29 (100,): Weighted 0.821737 (0.058741)\n",
      "identity adam 500 0.01 29 (100,): Macro 0.715107 (0.076722)\n",
      "Testing 507/2880\n",
      "identity adam 500 0.01 29 (150,): Weighted 0.821336 (0.051270)\n",
      "identity adam 500 0.01 29 (150,): Macro 0.706723 (0.065262)\n",
      "Testing 508/2880\n",
      "identity adam 500 0.01 29 (200,): Weighted 0.842079 (0.060805)\n",
      "identity adam 500 0.01 29 (200,): Macro 0.745742 (0.084501)\n",
      "Testing 509/2880\n",
      "identity adam 500 0.01 42 (50,): Weighted 0.820174 (0.052532)\n",
      "identity adam 500 0.01 42 (50,): Macro 0.700651 (0.059261)\n",
      "Testing 510/2880\n",
      "identity adam 500 0.01 42 (100,): Weighted 0.840739 (0.039074)\n",
      "identity adam 500 0.01 42 (100,): Macro 0.739436 (0.051953)\n",
      "Testing 511/2880\n",
      "identity adam 500 0.01 42 (150,): Weighted 0.836578 (0.061903)\n",
      "identity adam 500 0.01 42 (150,): Macro 0.740263 (0.089580)\n",
      "Testing 512/2880\n",
      "identity adam 500 0.01 42 (200,): Weighted 0.822574 (0.059569)\n",
      "identity adam 500 0.01 42 (200,): Macro 0.704945 (0.072077)\n",
      "Testing 513/2880\n",
      "identity adam 500 0.01 76 (50,): Weighted 0.827111 (0.058437)\n",
      "identity adam 500 0.01 76 (50,): Macro 0.720610 (0.082709)\n",
      "Testing 514/2880\n",
      "identity adam 500 0.01 76 (100,): Weighted 0.833179 (0.052295)\n",
      "identity adam 500 0.01 76 (100,): Macro 0.729152 (0.074302)\n",
      "Testing 515/2880\n",
      "identity adam 500 0.01 76 (150,): Weighted 0.836903 (0.069694)\n",
      "identity adam 500 0.01 76 (150,): Macro 0.732472 (0.095196)\n",
      "Testing 516/2880\n",
      "identity adam 500 0.01 76 (200,): Weighted 0.830930 (0.051817)\n",
      "identity adam 500 0.01 76 (200,): Macro 0.718506 (0.059186)\n",
      "Testing 517/2880\n",
      "identity adam 500 0.01 112 (50,): Weighted 0.829335 (0.069587)\n",
      "identity adam 500 0.01 112 (50,): Macro 0.720950 (0.094275)\n",
      "Testing 518/2880\n",
      "identity adam 500 0.01 112 (100,): Weighted 0.830930 (0.051817)\n",
      "identity adam 500 0.01 112 (100,): Macro 0.718506 (0.059186)\n",
      "Testing 519/2880\n",
      "identity adam 500 0.01 112 (150,): Weighted 0.831384 (0.068543)\n",
      "identity adam 500 0.01 112 (150,): Macro 0.722189 (0.094227)\n",
      "Testing 520/2880\n",
      "identity adam 500 0.01 112 (200,): Weighted 0.828196 (0.059630)\n",
      "identity adam 500 0.01 112 (200,): Macro 0.724141 (0.085694)\n",
      "Testing 521/2880\n",
      "identity adam 500 0.001 17 (50,): Weighted 0.834422 (0.055612)\n",
      "identity adam 500 0.001 17 (50,): Macro 0.727776 (0.071500)\n",
      "Testing 522/2880\n",
      "identity adam 500 0.001 17 (100,): Weighted 0.839125 (0.068253)\n",
      "identity adam 500 0.001 17 (100,): Macro 0.734879 (0.093691)\n",
      "Testing 523/2880\n",
      "identity adam 500 0.001 17 (150,): Weighted 0.837025 (0.062367)\n",
      "identity adam 500 0.001 17 (150,): Macro 0.726094 (0.081334)\n",
      "Testing 524/2880\n",
      "identity adam 500 0.001 17 (200,): Weighted 0.838398 (0.058099)\n",
      "identity adam 500 0.001 17 (200,): Macro 0.736715 (0.078337)\n",
      "Testing 525/2880\n",
      "identity adam 500 0.001 29 (50,): Weighted 0.841356 (0.075253)\n",
      "identity adam 500 0.001 29 (50,): Macro 0.744836 (0.109097)\n",
      "Testing 526/2880\n",
      "identity adam 500 0.001 29 (100,): Weighted 0.821737 (0.058741)\n",
      "identity adam 500 0.001 29 (100,): Macro 0.715107 (0.076722)\n",
      "Testing 527/2880\n",
      "identity adam 500 0.001 29 (150,): Weighted 0.821336 (0.051270)\n",
      "identity adam 500 0.001 29 (150,): Macro 0.706723 (0.065262)\n",
      "Testing 528/2880\n",
      "identity adam 500 0.001 29 (200,): Weighted 0.842079 (0.060805)\n",
      "identity adam 500 0.001 29 (200,): Macro 0.745742 (0.084501)\n",
      "Testing 529/2880\n",
      "identity adam 500 0.001 42 (50,): Weighted 0.820174 (0.052532)\n",
      "identity adam 500 0.001 42 (50,): Macro 0.700651 (0.059261)\n",
      "Testing 530/2880\n",
      "identity adam 500 0.001 42 (100,): Weighted 0.840739 (0.039074)\n",
      "identity adam 500 0.001 42 (100,): Macro 0.739436 (0.051953)\n",
      "Testing 531/2880\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "identity adam 500 0.001 42 (150,): Weighted 0.836578 (0.061903)\n",
      "identity adam 500 0.001 42 (150,): Macro 0.740263 (0.089580)\n",
      "Testing 532/2880\n",
      "identity adam 500 0.001 42 (200,): Weighted 0.822574 (0.059569)\n",
      "identity adam 500 0.001 42 (200,): Macro 0.704945 (0.072077)\n",
      "Testing 533/2880\n",
      "identity adam 500 0.001 76 (50,): Weighted 0.827111 (0.058437)\n",
      "identity adam 500 0.001 76 (50,): Macro 0.720610 (0.082709)\n",
      "Testing 534/2880\n",
      "identity adam 500 0.001 76 (100,): Weighted 0.833179 (0.052295)\n",
      "identity adam 500 0.001 76 (100,): Macro 0.729152 (0.074302)\n",
      "Testing 535/2880\n",
      "identity adam 500 0.001 76 (150,): Weighted 0.836903 (0.069694)\n",
      "identity adam 500 0.001 76 (150,): Macro 0.732472 (0.095196)\n",
      "Testing 536/2880\n",
      "identity adam 500 0.001 76 (200,): Weighted 0.830930 (0.051817)\n",
      "identity adam 500 0.001 76 (200,): Macro 0.718506 (0.059186)\n",
      "Testing 537/2880\n",
      "identity adam 500 0.001 112 (50,): Weighted 0.829335 (0.069587)\n",
      "identity adam 500 0.001 112 (50,): Macro 0.720950 (0.094275)\n",
      "Testing 538/2880\n",
      "identity adam 500 0.001 112 (100,): Weighted 0.830930 (0.051817)\n",
      "identity adam 500 0.001 112 (100,): Macro 0.718506 (0.059186)\n",
      "Testing 539/2880\n",
      "identity adam 500 0.001 112 (150,): Weighted 0.831384 (0.068543)\n",
      "identity adam 500 0.001 112 (150,): Macro 0.722189 (0.094227)\n",
      "Testing 540/2880\n",
      "identity adam 500 0.001 112 (200,): Weighted 0.828196 (0.059630)\n",
      "identity adam 500 0.001 112 (200,): Macro 0.724141 (0.085694)\n",
      "Testing 541/2880\n",
      "identity adam 500 0.0001 17 (50,): Weighted 0.834422 (0.055612)\n",
      "identity adam 500 0.0001 17 (50,): Macro 0.727776 (0.071500)\n",
      "Testing 542/2880\n",
      "identity adam 500 0.0001 17 (100,): Weighted 0.839125 (0.068253)\n",
      "identity adam 500 0.0001 17 (100,): Macro 0.734879 (0.093691)\n",
      "Testing 543/2880\n",
      "identity adam 500 0.0001 17 (150,): Weighted 0.837025 (0.062367)\n",
      "identity adam 500 0.0001 17 (150,): Macro 0.726094 (0.081334)\n",
      "Testing 544/2880\n",
      "identity adam 500 0.0001 17 (200,): Weighted 0.838398 (0.058099)\n",
      "identity adam 500 0.0001 17 (200,): Macro 0.736715 (0.078337)\n",
      "Testing 545/2880\n",
      "identity adam 500 0.0001 29 (50,): Weighted 0.841356 (0.075253)\n",
      "identity adam 500 0.0001 29 (50,): Macro 0.744836 (0.109097)\n",
      "Testing 546/2880\n",
      "identity adam 500 0.0001 29 (100,): Weighted 0.821737 (0.058741)\n",
      "identity adam 500 0.0001 29 (100,): Macro 0.715107 (0.076722)\n",
      "Testing 547/2880\n",
      "identity adam 500 0.0001 29 (150,): Weighted 0.821336 (0.051270)\n",
      "identity adam 500 0.0001 29 (150,): Macro 0.706723 (0.065262)\n",
      "Testing 548/2880\n",
      "identity adam 500 0.0001 29 (200,): Weighted 0.842079 (0.060805)\n",
      "identity adam 500 0.0001 29 (200,): Macro 0.745742 (0.084501)\n",
      "Testing 549/2880\n",
      "identity adam 500 0.0001 42 (50,): Weighted 0.820174 (0.052532)\n",
      "identity adam 500 0.0001 42 (50,): Macro 0.700651 (0.059261)\n",
      "Testing 550/2880\n",
      "identity adam 500 0.0001 42 (100,): Weighted 0.840739 (0.039074)\n",
      "identity adam 500 0.0001 42 (100,): Macro 0.739436 (0.051953)\n",
      "Testing 551/2880\n",
      "identity adam 500 0.0001 42 (150,): Weighted 0.836578 (0.061903)\n",
      "identity adam 500 0.0001 42 (150,): Macro 0.740263 (0.089580)\n",
      "Testing 552/2880\n",
      "identity adam 500 0.0001 42 (200,): Weighted 0.822574 (0.059569)\n",
      "identity adam 500 0.0001 42 (200,): Macro 0.704945 (0.072077)\n",
      "Testing 553/2880\n",
      "identity adam 500 0.0001 76 (50,): Weighted 0.827111 (0.058437)\n",
      "identity adam 500 0.0001 76 (50,): Macro 0.720610 (0.082709)\n",
      "Testing 554/2880\n",
      "identity adam 500 0.0001 76 (100,): Weighted 0.833179 (0.052295)\n",
      "identity adam 500 0.0001 76 (100,): Macro 0.729152 (0.074302)\n",
      "Testing 555/2880\n",
      "identity adam 500 0.0001 76 (150,): Weighted 0.836903 (0.069694)\n",
      "identity adam 500 0.0001 76 (150,): Macro 0.732472 (0.095196)\n",
      "Testing 556/2880\n",
      "identity adam 500 0.0001 76 (200,): Weighted 0.830930 (0.051817)\n",
      "identity adam 500 0.0001 76 (200,): Macro 0.718506 (0.059186)\n",
      "Testing 557/2880\n",
      "identity adam 500 0.0001 112 (50,): Weighted 0.829335 (0.069587)\n",
      "identity adam 500 0.0001 112 (50,): Macro 0.720950 (0.094275)\n",
      "Testing 558/2880\n",
      "identity adam 500 0.0001 112 (100,): Weighted 0.830930 (0.051817)\n",
      "identity adam 500 0.0001 112 (100,): Macro 0.718506 (0.059186)\n",
      "Testing 559/2880\n",
      "identity adam 500 0.0001 112 (150,): Weighted 0.831384 (0.068543)\n",
      "identity adam 500 0.0001 112 (150,): Macro 0.722189 (0.094227)\n",
      "Testing 560/2880\n",
      "identity adam 500 0.0001 112 (200,): Weighted 0.828196 (0.059630)\n",
      "identity adam 500 0.0001 112 (200,): Macro 0.724141 (0.085694)\n",
      "Testing 561/2880\n",
      "identity adam 1000 0.1 17 (50,): Weighted 0.834422 (0.055612)\n",
      "identity adam 1000 0.1 17 (50,): Macro 0.727776 (0.071500)\n",
      "Testing 562/2880\n",
      "identity adam 1000 0.1 17 (100,): Weighted 0.839125 (0.068253)\n",
      "identity adam 1000 0.1 17 (100,): Macro 0.734879 (0.093691)\n",
      "Testing 563/2880\n",
      "identity adam 1000 0.1 17 (150,): Weighted 0.837025 (0.062367)\n",
      "identity adam 1000 0.1 17 (150,): Macro 0.726094 (0.081334)\n",
      "Testing 564/2880\n",
      "identity adam 1000 0.1 17 (200,): Weighted 0.838398 (0.058099)\n",
      "identity adam 1000 0.1 17 (200,): Macro 0.736715 (0.078337)\n",
      "Testing 565/2880\n",
      "identity adam 1000 0.1 29 (50,): Weighted 0.841356 (0.075253)\n",
      "identity adam 1000 0.1 29 (50,): Macro 0.744836 (0.109097)\n",
      "Testing 566/2880\n",
      "identity adam 1000 0.1 29 (100,): Weighted 0.821737 (0.058741)\n",
      "identity adam 1000 0.1 29 (100,): Macro 0.715107 (0.076722)\n",
      "Testing 567/2880\n",
      "identity adam 1000 0.1 29 (150,): Weighted 0.821336 (0.051270)\n",
      "identity adam 1000 0.1 29 (150,): Macro 0.706723 (0.065262)\n",
      "Testing 568/2880\n",
      "identity adam 1000 0.1 29 (200,): Weighted 0.842079 (0.060805)\n",
      "identity adam 1000 0.1 29 (200,): Macro 0.745742 (0.084501)\n",
      "Testing 569/2880\n",
      "identity adam 1000 0.1 42 (50,): Weighted 0.820174 (0.052532)\n",
      "identity adam 1000 0.1 42 (50,): Macro 0.700651 (0.059261)\n",
      "Testing 570/2880\n",
      "identity adam 1000 0.1 42 (100,): Weighted 0.840739 (0.039074)\n",
      "identity adam 1000 0.1 42 (100,): Macro 0.739436 (0.051953)\n",
      "Testing 571/2880\n",
      "identity adam 1000 0.1 42 (150,): Weighted 0.836578 (0.061903)\n",
      "identity adam 1000 0.1 42 (150,): Macro 0.740263 (0.089580)\n",
      "Testing 572/2880\n",
      "identity adam 1000 0.1 42 (200,): Weighted 0.822574 (0.059569)\n",
      "identity adam 1000 0.1 42 (200,): Macro 0.704945 (0.072077)\n",
      "Testing 573/2880\n",
      "identity adam 1000 0.1 76 (50,): Weighted 0.827111 (0.058437)\n",
      "identity adam 1000 0.1 76 (50,): Macro 0.720610 (0.082709)\n",
      "Testing 574/2880\n",
      "identity adam 1000 0.1 76 (100,): Weighted 0.833179 (0.052295)\n",
      "identity adam 1000 0.1 76 (100,): Macro 0.729152 (0.074302)\n",
      "Testing 575/2880\n",
      "identity adam 1000 0.1 76 (150,): Weighted 0.836903 (0.069694)\n",
      "identity adam 1000 0.1 76 (150,): Macro 0.732472 (0.095196)\n",
      "Testing 576/2880\n",
      "identity adam 1000 0.1 76 (200,): Weighted 0.830930 (0.051817)\n",
      "identity adam 1000 0.1 76 (200,): Macro 0.718506 (0.059186)\n",
      "Testing 577/2880\n",
      "identity adam 1000 0.1 112 (50,): Weighted 0.829335 (0.069587)\n",
      "identity adam 1000 0.1 112 (50,): Macro 0.720950 (0.094275)\n",
      "Testing 578/2880\n",
      "identity adam 1000 0.1 112 (100,): Weighted 0.830930 (0.051817)\n",
      "identity adam 1000 0.1 112 (100,): Macro 0.718506 (0.059186)\n",
      "Testing 579/2880\n",
      "identity adam 1000 0.1 112 (150,): Weighted 0.831384 (0.068543)\n",
      "identity adam 1000 0.1 112 (150,): Macro 0.722189 (0.094227)\n",
      "Testing 580/2880\n",
      "identity adam 1000 0.1 112 (200,): Weighted 0.828196 (0.059630)\n",
      "identity adam 1000 0.1 112 (200,): Macro 0.724141 (0.085694)\n",
      "Testing 581/2880\n",
      "identity adam 1000 0.01 17 (50,): Weighted 0.834422 (0.055612)\n",
      "identity adam 1000 0.01 17 (50,): Macro 0.727776 (0.071500)\n",
      "Testing 582/2880\n",
      "identity adam 1000 0.01 17 (100,): Weighted 0.839125 (0.068253)\n",
      "identity adam 1000 0.01 17 (100,): Macro 0.734879 (0.093691)\n",
      "Testing 583/2880\n",
      "identity adam 1000 0.01 17 (150,): Weighted 0.837025 (0.062367)\n",
      "identity adam 1000 0.01 17 (150,): Macro 0.726094 (0.081334)\n",
      "Testing 584/2880\n",
      "identity adam 1000 0.01 17 (200,): Weighted 0.838398 (0.058099)\n",
      "identity adam 1000 0.01 17 (200,): Macro 0.736715 (0.078337)\n",
      "Testing 585/2880\n",
      "identity adam 1000 0.01 29 (50,): Weighted 0.841356 (0.075253)\n",
      "identity adam 1000 0.01 29 (50,): Macro 0.744836 (0.109097)\n",
      "Testing 586/2880\n",
      "identity adam 1000 0.01 29 (100,): Weighted 0.821737 (0.058741)\n",
      "identity adam 1000 0.01 29 (100,): Macro 0.715107 (0.076722)\n",
      "Testing 587/2880\n",
      "identity adam 1000 0.01 29 (150,): Weighted 0.821336 (0.051270)\n",
      "identity adam 1000 0.01 29 (150,): Macro 0.706723 (0.065262)\n",
      "Testing 588/2880\n",
      "identity adam 1000 0.01 29 (200,): Weighted 0.842079 (0.060805)\n",
      "identity adam 1000 0.01 29 (200,): Macro 0.745742 (0.084501)\n",
      "Testing 589/2880\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "identity adam 1000 0.01 42 (50,): Weighted 0.820174 (0.052532)\n",
      "identity adam 1000 0.01 42 (50,): Macro 0.700651 (0.059261)\n",
      "Testing 590/2880\n",
      "identity adam 1000 0.01 42 (100,): Weighted 0.840739 (0.039074)\n",
      "identity adam 1000 0.01 42 (100,): Macro 0.739436 (0.051953)\n",
      "Testing 591/2880\n",
      "identity adam 1000 0.01 42 (150,): Weighted 0.836578 (0.061903)\n",
      "identity adam 1000 0.01 42 (150,): Macro 0.740263 (0.089580)\n",
      "Testing 592/2880\n",
      "identity adam 1000 0.01 42 (200,): Weighted 0.822574 (0.059569)\n",
      "identity adam 1000 0.01 42 (200,): Macro 0.704945 (0.072077)\n",
      "Testing 593/2880\n",
      "identity adam 1000 0.01 76 (50,): Weighted 0.827111 (0.058437)\n",
      "identity adam 1000 0.01 76 (50,): Macro 0.720610 (0.082709)\n",
      "Testing 594/2880\n",
      "identity adam 1000 0.01 76 (100,): Weighted 0.833179 (0.052295)\n",
      "identity adam 1000 0.01 76 (100,): Macro 0.729152 (0.074302)\n",
      "Testing 595/2880\n",
      "identity adam 1000 0.01 76 (150,): Weighted 0.836903 (0.069694)\n",
      "identity adam 1000 0.01 76 (150,): Macro 0.732472 (0.095196)\n",
      "Testing 596/2880\n",
      "identity adam 1000 0.01 76 (200,): Weighted 0.830930 (0.051817)\n",
      "identity adam 1000 0.01 76 (200,): Macro 0.718506 (0.059186)\n",
      "Testing 597/2880\n",
      "identity adam 1000 0.01 112 (50,): Weighted 0.829335 (0.069587)\n",
      "identity adam 1000 0.01 112 (50,): Macro 0.720950 (0.094275)\n",
      "Testing 598/2880\n",
      "identity adam 1000 0.01 112 (100,): Weighted 0.830930 (0.051817)\n",
      "identity adam 1000 0.01 112 (100,): Macro 0.718506 (0.059186)\n",
      "Testing 599/2880\n",
      "identity adam 1000 0.01 112 (150,): Weighted 0.831384 (0.068543)\n",
      "identity adam 1000 0.01 112 (150,): Macro 0.722189 (0.094227)\n",
      "Testing 600/2880\n",
      "identity adam 1000 0.01 112 (200,): Weighted 0.828196 (0.059630)\n",
      "identity adam 1000 0.01 112 (200,): Macro 0.724141 (0.085694)\n",
      "Testing 601/2880\n",
      "identity adam 1000 0.001 17 (50,): Weighted 0.834422 (0.055612)\n",
      "identity adam 1000 0.001 17 (50,): Macro 0.727776 (0.071500)\n",
      "Testing 602/2880\n",
      "identity adam 1000 0.001 17 (100,): Weighted 0.839125 (0.068253)\n",
      "identity adam 1000 0.001 17 (100,): Macro 0.734879 (0.093691)\n",
      "Testing 603/2880\n",
      "identity adam 1000 0.001 17 (150,): Weighted 0.837025 (0.062367)\n",
      "identity adam 1000 0.001 17 (150,): Macro 0.726094 (0.081334)\n",
      "Testing 604/2880\n",
      "identity adam 1000 0.001 17 (200,): Weighted 0.838398 (0.058099)\n",
      "identity adam 1000 0.001 17 (200,): Macro 0.736715 (0.078337)\n",
      "Testing 605/2880\n",
      "identity adam 1000 0.001 29 (50,): Weighted 0.841356 (0.075253)\n",
      "identity adam 1000 0.001 29 (50,): Macro 0.744836 (0.109097)\n",
      "Testing 606/2880\n",
      "identity adam 1000 0.001 29 (100,): Weighted 0.821737 (0.058741)\n",
      "identity adam 1000 0.001 29 (100,): Macro 0.715107 (0.076722)\n",
      "Testing 607/2880\n",
      "identity adam 1000 0.001 29 (150,): Weighted 0.821336 (0.051270)\n",
      "identity adam 1000 0.001 29 (150,): Macro 0.706723 (0.065262)\n",
      "Testing 608/2880\n",
      "identity adam 1000 0.001 29 (200,): Weighted 0.842079 (0.060805)\n",
      "identity adam 1000 0.001 29 (200,): Macro 0.745742 (0.084501)\n",
      "Testing 609/2880\n",
      "identity adam 1000 0.001 42 (50,): Weighted 0.820174 (0.052532)\n",
      "identity adam 1000 0.001 42 (50,): Macro 0.700651 (0.059261)\n",
      "Testing 610/2880\n",
      "identity adam 1000 0.001 42 (100,): Weighted 0.840739 (0.039074)\n",
      "identity adam 1000 0.001 42 (100,): Macro 0.739436 (0.051953)\n",
      "Testing 611/2880\n",
      "identity adam 1000 0.001 42 (150,): Weighted 0.836578 (0.061903)\n",
      "identity adam 1000 0.001 42 (150,): Macro 0.740263 (0.089580)\n",
      "Testing 612/2880\n",
      "identity adam 1000 0.001 42 (200,): Weighted 0.822574 (0.059569)\n",
      "identity adam 1000 0.001 42 (200,): Macro 0.704945 (0.072077)\n",
      "Testing 613/2880\n",
      "identity adam 1000 0.001 76 (50,): Weighted 0.827111 (0.058437)\n",
      "identity adam 1000 0.001 76 (50,): Macro 0.720610 (0.082709)\n",
      "Testing 614/2880\n",
      "identity adam 1000 0.001 76 (100,): Weighted 0.833179 (0.052295)\n",
      "identity adam 1000 0.001 76 (100,): Macro 0.729152 (0.074302)\n",
      "Testing 615/2880\n",
      "identity adam 1000 0.001 76 (150,): Weighted 0.836903 (0.069694)\n",
      "identity adam 1000 0.001 76 (150,): Macro 0.732472 (0.095196)\n",
      "Testing 616/2880\n",
      "identity adam 1000 0.001 76 (200,): Weighted 0.830930 (0.051817)\n",
      "identity adam 1000 0.001 76 (200,): Macro 0.718506 (0.059186)\n",
      "Testing 617/2880\n",
      "identity adam 1000 0.001 112 (50,): Weighted 0.829335 (0.069587)\n",
      "identity adam 1000 0.001 112 (50,): Macro 0.720950 (0.094275)\n",
      "Testing 618/2880\n",
      "identity adam 1000 0.001 112 (100,): Weighted 0.830930 (0.051817)\n",
      "identity adam 1000 0.001 112 (100,): Macro 0.718506 (0.059186)\n",
      "Testing 619/2880\n",
      "identity adam 1000 0.001 112 (150,): Weighted 0.831384 (0.068543)\n",
      "identity adam 1000 0.001 112 (150,): Macro 0.722189 (0.094227)\n",
      "Testing 620/2880\n",
      "identity adam 1000 0.001 112 (200,): Weighted 0.828196 (0.059630)\n",
      "identity adam 1000 0.001 112 (200,): Macro 0.724141 (0.085694)\n",
      "Testing 621/2880\n",
      "identity adam 1000 0.0001 17 (50,): Weighted 0.834422 (0.055612)\n",
      "identity adam 1000 0.0001 17 (50,): Macro 0.727776 (0.071500)\n",
      "Testing 622/2880\n",
      "identity adam 1000 0.0001 17 (100,): Weighted 0.839125 (0.068253)\n",
      "identity adam 1000 0.0001 17 (100,): Macro 0.734879 (0.093691)\n",
      "Testing 623/2880\n",
      "identity adam 1000 0.0001 17 (150,): Weighted 0.837025 (0.062367)\n",
      "identity adam 1000 0.0001 17 (150,): Macro 0.726094 (0.081334)\n",
      "Testing 624/2880\n",
      "identity adam 1000 0.0001 17 (200,): Weighted 0.838398 (0.058099)\n",
      "identity adam 1000 0.0001 17 (200,): Macro 0.736715 (0.078337)\n",
      "Testing 625/2880\n",
      "identity adam 1000 0.0001 29 (50,): Weighted 0.841356 (0.075253)\n",
      "identity adam 1000 0.0001 29 (50,): Macro 0.744836 (0.109097)\n",
      "Testing 626/2880\n",
      "identity adam 1000 0.0001 29 (100,): Weighted 0.821737 (0.058741)\n",
      "identity adam 1000 0.0001 29 (100,): Macro 0.715107 (0.076722)\n",
      "Testing 627/2880\n",
      "identity adam 1000 0.0001 29 (150,): Weighted 0.821336 (0.051270)\n",
      "identity adam 1000 0.0001 29 (150,): Macro 0.706723 (0.065262)\n",
      "Testing 628/2880\n",
      "identity adam 1000 0.0001 29 (200,): Weighted 0.842079 (0.060805)\n",
      "identity adam 1000 0.0001 29 (200,): Macro 0.745742 (0.084501)\n",
      "Testing 629/2880\n",
      "identity adam 1000 0.0001 42 (50,): Weighted 0.820174 (0.052532)\n",
      "identity adam 1000 0.0001 42 (50,): Macro 0.700651 (0.059261)\n",
      "Testing 630/2880\n",
      "identity adam 1000 0.0001 42 (100,): Weighted 0.840739 (0.039074)\n",
      "identity adam 1000 0.0001 42 (100,): Macro 0.739436 (0.051953)\n",
      "Testing 631/2880\n",
      "identity adam 1000 0.0001 42 (150,): Weighted 0.836578 (0.061903)\n",
      "identity adam 1000 0.0001 42 (150,): Macro 0.740263 (0.089580)\n",
      "Testing 632/2880\n",
      "identity adam 1000 0.0001 42 (200,): Weighted 0.822574 (0.059569)\n",
      "identity adam 1000 0.0001 42 (200,): Macro 0.704945 (0.072077)\n",
      "Testing 633/2880\n",
      "identity adam 1000 0.0001 76 (50,): Weighted 0.827111 (0.058437)\n",
      "identity adam 1000 0.0001 76 (50,): Macro 0.720610 (0.082709)\n",
      "Testing 634/2880\n",
      "identity adam 1000 0.0001 76 (100,): Weighted 0.833179 (0.052295)\n",
      "identity adam 1000 0.0001 76 (100,): Macro 0.729152 (0.074302)\n",
      "Testing 635/2880\n",
      "identity adam 1000 0.0001 76 (150,): Weighted 0.836903 (0.069694)\n",
      "identity adam 1000 0.0001 76 (150,): Macro 0.732472 (0.095196)\n",
      "Testing 636/2880\n",
      "identity adam 1000 0.0001 76 (200,): Weighted 0.830930 (0.051817)\n",
      "identity adam 1000 0.0001 76 (200,): Macro 0.718506 (0.059186)\n",
      "Testing 637/2880\n",
      "identity adam 1000 0.0001 112 (50,): Weighted 0.829335 (0.069587)\n",
      "identity adam 1000 0.0001 112 (50,): Macro 0.720950 (0.094275)\n",
      "Testing 638/2880\n",
      "identity adam 1000 0.0001 112 (100,): Weighted 0.830930 (0.051817)\n",
      "identity adam 1000 0.0001 112 (100,): Macro 0.718506 (0.059186)\n",
      "Testing 639/2880\n",
      "identity adam 1000 0.0001 112 (150,): Weighted 0.831384 (0.068543)\n",
      "identity adam 1000 0.0001 112 (150,): Macro 0.722189 (0.094227)\n",
      "Testing 640/2880\n",
      "identity adam 1000 0.0001 112 (200,): Weighted 0.828196 (0.059630)\n",
      "identity adam 1000 0.0001 112 (200,): Macro 0.724141 (0.085694)\n",
      "Testing 641/2880\n",
      "identity adam 1500 0.1 17 (50,): Weighted 0.834422 (0.055612)\n",
      "identity adam 1500 0.1 17 (50,): Macro 0.727776 (0.071500)\n",
      "Testing 642/2880\n",
      "identity adam 1500 0.1 17 (100,): Weighted 0.839125 (0.068253)\n",
      "identity adam 1500 0.1 17 (100,): Macro 0.734879 (0.093691)\n",
      "Testing 643/2880\n",
      "identity adam 1500 0.1 17 (150,): Weighted 0.837025 (0.062367)\n",
      "identity adam 1500 0.1 17 (150,): Macro 0.726094 (0.081334)\n",
      "Testing 644/2880\n",
      "identity adam 1500 0.1 17 (200,): Weighted 0.838398 (0.058099)\n",
      "identity adam 1500 0.1 17 (200,): Macro 0.736715 (0.078337)\n",
      "Testing 645/2880\n",
      "identity adam 1500 0.1 29 (50,): Weighted 0.841356 (0.075253)\n",
      "identity adam 1500 0.1 29 (50,): Macro 0.744836 (0.109097)\n",
      "Testing 646/2880\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "identity adam 1500 0.1 29 (100,): Weighted 0.821737 (0.058741)\n",
      "identity adam 1500 0.1 29 (100,): Macro 0.715107 (0.076722)\n",
      "Testing 647/2880\n",
      "identity adam 1500 0.1 29 (150,): Weighted 0.821336 (0.051270)\n",
      "identity adam 1500 0.1 29 (150,): Macro 0.706723 (0.065262)\n",
      "Testing 648/2880\n",
      "identity adam 1500 0.1 29 (200,): Weighted 0.842079 (0.060805)\n",
      "identity adam 1500 0.1 29 (200,): Macro 0.745742 (0.084501)\n",
      "Testing 649/2880\n",
      "identity adam 1500 0.1 42 (50,): Weighted 0.820174 (0.052532)\n",
      "identity adam 1500 0.1 42 (50,): Macro 0.700651 (0.059261)\n",
      "Testing 650/2880\n",
      "identity adam 1500 0.1 42 (100,): Weighted 0.840739 (0.039074)\n",
      "identity adam 1500 0.1 42 (100,): Macro 0.739436 (0.051953)\n",
      "Testing 651/2880\n",
      "identity adam 1500 0.1 42 (150,): Weighted 0.836578 (0.061903)\n",
      "identity adam 1500 0.1 42 (150,): Macro 0.740263 (0.089580)\n",
      "Testing 652/2880\n",
      "identity adam 1500 0.1 42 (200,): Weighted 0.822574 (0.059569)\n",
      "identity adam 1500 0.1 42 (200,): Macro 0.704945 (0.072077)\n",
      "Testing 653/2880\n",
      "identity adam 1500 0.1 76 (50,): Weighted 0.827111 (0.058437)\n",
      "identity adam 1500 0.1 76 (50,): Macro 0.720610 (0.082709)\n",
      "Testing 654/2880\n",
      "identity adam 1500 0.1 76 (100,): Weighted 0.833179 (0.052295)\n",
      "identity adam 1500 0.1 76 (100,): Macro 0.729152 (0.074302)\n",
      "Testing 655/2880\n",
      "identity adam 1500 0.1 76 (150,): Weighted 0.836903 (0.069694)\n",
      "identity adam 1500 0.1 76 (150,): Macro 0.732472 (0.095196)\n",
      "Testing 656/2880\n",
      "identity adam 1500 0.1 76 (200,): Weighted 0.830930 (0.051817)\n",
      "identity adam 1500 0.1 76 (200,): Macro 0.718506 (0.059186)\n",
      "Testing 657/2880\n",
      "identity adam 1500 0.1 112 (50,): Weighted 0.829335 (0.069587)\n",
      "identity adam 1500 0.1 112 (50,): Macro 0.720950 (0.094275)\n",
      "Testing 658/2880\n",
      "identity adam 1500 0.1 112 (100,): Weighted 0.830930 (0.051817)\n",
      "identity adam 1500 0.1 112 (100,): Macro 0.718506 (0.059186)\n",
      "Testing 659/2880\n",
      "identity adam 1500 0.1 112 (150,): Weighted 0.831384 (0.068543)\n",
      "identity adam 1500 0.1 112 (150,): Macro 0.722189 (0.094227)\n",
      "Testing 660/2880\n",
      "identity adam 1500 0.1 112 (200,): Weighted 0.828196 (0.059630)\n",
      "identity adam 1500 0.1 112 (200,): Macro 0.724141 (0.085694)\n",
      "Testing 661/2880\n",
      "identity adam 1500 0.01 17 (50,): Weighted 0.834422 (0.055612)\n",
      "identity adam 1500 0.01 17 (50,): Macro 0.727776 (0.071500)\n",
      "Testing 662/2880\n",
      "identity adam 1500 0.01 17 (100,): Weighted 0.839125 (0.068253)\n",
      "identity adam 1500 0.01 17 (100,): Macro 0.734879 (0.093691)\n",
      "Testing 663/2880\n",
      "identity adam 1500 0.01 17 (150,): Weighted 0.837025 (0.062367)\n",
      "identity adam 1500 0.01 17 (150,): Macro 0.726094 (0.081334)\n",
      "Testing 664/2880\n",
      "identity adam 1500 0.01 17 (200,): Weighted 0.838398 (0.058099)\n",
      "identity adam 1500 0.01 17 (200,): Macro 0.736715 (0.078337)\n",
      "Testing 665/2880\n",
      "identity adam 1500 0.01 29 (50,): Weighted 0.841356 (0.075253)\n",
      "identity adam 1500 0.01 29 (50,): Macro 0.744836 (0.109097)\n",
      "Testing 666/2880\n",
      "identity adam 1500 0.01 29 (100,): Weighted 0.821737 (0.058741)\n",
      "identity adam 1500 0.01 29 (100,): Macro 0.715107 (0.076722)\n",
      "Testing 667/2880\n",
      "identity adam 1500 0.01 29 (150,): Weighted 0.821336 (0.051270)\n",
      "identity adam 1500 0.01 29 (150,): Macro 0.706723 (0.065262)\n",
      "Testing 668/2880\n",
      "identity adam 1500 0.01 29 (200,): Weighted 0.842079 (0.060805)\n",
      "identity adam 1500 0.01 29 (200,): Macro 0.745742 (0.084501)\n",
      "Testing 669/2880\n",
      "identity adam 1500 0.01 42 (50,): Weighted 0.820174 (0.052532)\n",
      "identity adam 1500 0.01 42 (50,): Macro 0.700651 (0.059261)\n",
      "Testing 670/2880\n",
      "identity adam 1500 0.01 42 (100,): Weighted 0.840739 (0.039074)\n",
      "identity adam 1500 0.01 42 (100,): Macro 0.739436 (0.051953)\n",
      "Testing 671/2880\n",
      "identity adam 1500 0.01 42 (150,): Weighted 0.836578 (0.061903)\n",
      "identity adam 1500 0.01 42 (150,): Macro 0.740263 (0.089580)\n",
      "Testing 672/2880\n",
      "identity adam 1500 0.01 42 (200,): Weighted 0.822574 (0.059569)\n",
      "identity adam 1500 0.01 42 (200,): Macro 0.704945 (0.072077)\n",
      "Testing 673/2880\n",
      "identity adam 1500 0.01 76 (50,): Weighted 0.827111 (0.058437)\n",
      "identity adam 1500 0.01 76 (50,): Macro 0.720610 (0.082709)\n",
      "Testing 674/2880\n",
      "identity adam 1500 0.01 76 (100,): Weighted 0.833179 (0.052295)\n",
      "identity adam 1500 0.01 76 (100,): Macro 0.729152 (0.074302)\n",
      "Testing 675/2880\n",
      "identity adam 1500 0.01 76 (150,): Weighted 0.836903 (0.069694)\n",
      "identity adam 1500 0.01 76 (150,): Macro 0.732472 (0.095196)\n",
      "Testing 676/2880\n",
      "identity adam 1500 0.01 76 (200,): Weighted 0.830930 (0.051817)\n",
      "identity adam 1500 0.01 76 (200,): Macro 0.718506 (0.059186)\n",
      "Testing 677/2880\n",
      "identity adam 1500 0.01 112 (50,): Weighted 0.829335 (0.069587)\n",
      "identity adam 1500 0.01 112 (50,): Macro 0.720950 (0.094275)\n",
      "Testing 678/2880\n",
      "identity adam 1500 0.01 112 (100,): Weighted 0.830930 (0.051817)\n",
      "identity adam 1500 0.01 112 (100,): Macro 0.718506 (0.059186)\n",
      "Testing 679/2880\n",
      "identity adam 1500 0.01 112 (150,): Weighted 0.831384 (0.068543)\n",
      "identity adam 1500 0.01 112 (150,): Macro 0.722189 (0.094227)\n",
      "Testing 680/2880\n",
      "identity adam 1500 0.01 112 (200,): Weighted 0.828196 (0.059630)\n",
      "identity adam 1500 0.01 112 (200,): Macro 0.724141 (0.085694)\n",
      "Testing 681/2880\n",
      "identity adam 1500 0.001 17 (50,): Weighted 0.834422 (0.055612)\n",
      "identity adam 1500 0.001 17 (50,): Macro 0.727776 (0.071500)\n",
      "Testing 682/2880\n",
      "identity adam 1500 0.001 17 (100,): Weighted 0.839125 (0.068253)\n",
      "identity adam 1500 0.001 17 (100,): Macro 0.734879 (0.093691)\n",
      "Testing 683/2880\n",
      "identity adam 1500 0.001 17 (150,): Weighted 0.837025 (0.062367)\n",
      "identity adam 1500 0.001 17 (150,): Macro 0.726094 (0.081334)\n",
      "Testing 684/2880\n",
      "identity adam 1500 0.001 17 (200,): Weighted 0.838398 (0.058099)\n",
      "identity adam 1500 0.001 17 (200,): Macro 0.736715 (0.078337)\n",
      "Testing 685/2880\n",
      "identity adam 1500 0.001 29 (50,): Weighted 0.841356 (0.075253)\n",
      "identity adam 1500 0.001 29 (50,): Macro 0.744836 (0.109097)\n",
      "Testing 686/2880\n",
      "identity adam 1500 0.001 29 (100,): Weighted 0.821737 (0.058741)\n",
      "identity adam 1500 0.001 29 (100,): Macro 0.715107 (0.076722)\n",
      "Testing 687/2880\n",
      "identity adam 1500 0.001 29 (150,): Weighted 0.821336 (0.051270)\n",
      "identity adam 1500 0.001 29 (150,): Macro 0.706723 (0.065262)\n",
      "Testing 688/2880\n",
      "identity adam 1500 0.001 29 (200,): Weighted 0.842079 (0.060805)\n",
      "identity adam 1500 0.001 29 (200,): Macro 0.745742 (0.084501)\n",
      "Testing 689/2880\n",
      "identity adam 1500 0.001 42 (50,): Weighted 0.820174 (0.052532)\n",
      "identity adam 1500 0.001 42 (50,): Macro 0.700651 (0.059261)\n",
      "Testing 690/2880\n",
      "identity adam 1500 0.001 42 (100,): Weighted 0.840739 (0.039074)\n",
      "identity adam 1500 0.001 42 (100,): Macro 0.739436 (0.051953)\n",
      "Testing 691/2880\n",
      "identity adam 1500 0.001 42 (150,): Weighted 0.836578 (0.061903)\n",
      "identity adam 1500 0.001 42 (150,): Macro 0.740263 (0.089580)\n",
      "Testing 692/2880\n",
      "identity adam 1500 0.001 42 (200,): Weighted 0.822574 (0.059569)\n",
      "identity adam 1500 0.001 42 (200,): Macro 0.704945 (0.072077)\n",
      "Testing 693/2880\n",
      "identity adam 1500 0.001 76 (50,): Weighted 0.827111 (0.058437)\n",
      "identity adam 1500 0.001 76 (50,): Macro 0.720610 (0.082709)\n",
      "Testing 694/2880\n",
      "identity adam 1500 0.001 76 (100,): Weighted 0.833179 (0.052295)\n",
      "identity adam 1500 0.001 76 (100,): Macro 0.729152 (0.074302)\n",
      "Testing 695/2880\n",
      "identity adam 1500 0.001 76 (150,): Weighted 0.836903 (0.069694)\n",
      "identity adam 1500 0.001 76 (150,): Macro 0.732472 (0.095196)\n",
      "Testing 696/2880\n",
      "identity adam 1500 0.001 76 (200,): Weighted 0.830930 (0.051817)\n",
      "identity adam 1500 0.001 76 (200,): Macro 0.718506 (0.059186)\n",
      "Testing 697/2880\n",
      "identity adam 1500 0.001 112 (50,): Weighted 0.829335 (0.069587)\n",
      "identity adam 1500 0.001 112 (50,): Macro 0.720950 (0.094275)\n",
      "Testing 698/2880\n",
      "identity adam 1500 0.001 112 (100,): Weighted 0.830930 (0.051817)\n",
      "identity adam 1500 0.001 112 (100,): Macro 0.718506 (0.059186)\n",
      "Testing 699/2880\n",
      "identity adam 1500 0.001 112 (150,): Weighted 0.831384 (0.068543)\n",
      "identity adam 1500 0.001 112 (150,): Macro 0.722189 (0.094227)\n",
      "Testing 700/2880\n",
      "identity adam 1500 0.001 112 (200,): Weighted 0.828196 (0.059630)\n",
      "identity adam 1500 0.001 112 (200,): Macro 0.724141 (0.085694)\n",
      "Testing 701/2880\n",
      "identity adam 1500 0.0001 17 (50,): Weighted 0.834422 (0.055612)\n",
      "identity adam 1500 0.0001 17 (50,): Macro 0.727776 (0.071500)\n",
      "Testing 702/2880\n",
      "identity adam 1500 0.0001 17 (100,): Weighted 0.839125 (0.068253)\n",
      "identity adam 1500 0.0001 17 (100,): Macro 0.734879 (0.093691)\n",
      "Testing 703/2880\n",
      "identity adam 1500 0.0001 17 (150,): Weighted 0.837025 (0.062367)\n",
      "identity adam 1500 0.0001 17 (150,): Macro 0.726094 (0.081334)\n",
      "Testing 704/2880\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "identity adam 1500 0.0001 17 (200,): Weighted 0.838398 (0.058099)\n",
      "identity adam 1500 0.0001 17 (200,): Macro 0.736715 (0.078337)\n",
      "Testing 705/2880\n",
      "identity adam 1500 0.0001 29 (50,): Weighted 0.841356 (0.075253)\n",
      "identity adam 1500 0.0001 29 (50,): Macro 0.744836 (0.109097)\n",
      "Testing 706/2880\n",
      "identity adam 1500 0.0001 29 (100,): Weighted 0.821737 (0.058741)\n",
      "identity adam 1500 0.0001 29 (100,): Macro 0.715107 (0.076722)\n",
      "Testing 707/2880\n",
      "identity adam 1500 0.0001 29 (150,): Weighted 0.821336 (0.051270)\n",
      "identity adam 1500 0.0001 29 (150,): Macro 0.706723 (0.065262)\n",
      "Testing 708/2880\n",
      "identity adam 1500 0.0001 29 (200,): Weighted 0.842079 (0.060805)\n",
      "identity adam 1500 0.0001 29 (200,): Macro 0.745742 (0.084501)\n",
      "Testing 709/2880\n",
      "identity adam 1500 0.0001 42 (50,): Weighted 0.820174 (0.052532)\n",
      "identity adam 1500 0.0001 42 (50,): Macro 0.700651 (0.059261)\n",
      "Testing 710/2880\n",
      "identity adam 1500 0.0001 42 (100,): Weighted 0.840739 (0.039074)\n",
      "identity adam 1500 0.0001 42 (100,): Macro 0.739436 (0.051953)\n",
      "Testing 711/2880\n",
      "identity adam 1500 0.0001 42 (150,): Weighted 0.836578 (0.061903)\n",
      "identity adam 1500 0.0001 42 (150,): Macro 0.740263 (0.089580)\n",
      "Testing 712/2880\n",
      "identity adam 1500 0.0001 42 (200,): Weighted 0.822574 (0.059569)\n",
      "identity adam 1500 0.0001 42 (200,): Macro 0.704945 (0.072077)\n",
      "Testing 713/2880\n",
      "identity adam 1500 0.0001 76 (50,): Weighted 0.827111 (0.058437)\n",
      "identity adam 1500 0.0001 76 (50,): Macro 0.720610 (0.082709)\n",
      "Testing 714/2880\n",
      "identity adam 1500 0.0001 76 (100,): Weighted 0.833179 (0.052295)\n",
      "identity adam 1500 0.0001 76 (100,): Macro 0.729152 (0.074302)\n",
      "Testing 715/2880\n",
      "identity adam 1500 0.0001 76 (150,): Weighted 0.836903 (0.069694)\n",
      "identity adam 1500 0.0001 76 (150,): Macro 0.732472 (0.095196)\n",
      "Testing 716/2880\n",
      "identity adam 1500 0.0001 76 (200,): Weighted 0.830930 (0.051817)\n",
      "identity adam 1500 0.0001 76 (200,): Macro 0.718506 (0.059186)\n",
      "Testing 717/2880\n",
      "identity adam 1500 0.0001 112 (50,): Weighted 0.829335 (0.069587)\n",
      "identity adam 1500 0.0001 112 (50,): Macro 0.720950 (0.094275)\n",
      "Testing 718/2880\n",
      "identity adam 1500 0.0001 112 (100,): Weighted 0.830930 (0.051817)\n",
      "identity adam 1500 0.0001 112 (100,): Macro 0.718506 (0.059186)\n",
      "Testing 719/2880\n",
      "identity adam 1500 0.0001 112 (150,): Weighted 0.831384 (0.068543)\n",
      "identity adam 1500 0.0001 112 (150,): Macro 0.722189 (0.094227)\n",
      "Testing 720/2880\n",
      "identity adam 1500 0.0001 112 (200,): Weighted 0.828196 (0.059630)\n",
      "identity adam 1500 0.0001 112 (200,): Macro 0.724141 (0.085694)\n",
      "Testing 721/2880\n",
      "logistic lbfgs 500 0.1 17 (50,): Weighted 0.803518 (0.048306)\n",
      "logistic lbfgs 500 0.1 17 (50,): Macro 0.671645 (0.062441)\n",
      "Testing 722/2880\n",
      "logistic lbfgs 500 0.1 17 (100,): Weighted 0.832772 (0.025154)\n",
      "logistic lbfgs 500 0.1 17 (100,): Macro 0.720183 (0.011028)\n",
      "Testing 723/2880\n",
      "logistic lbfgs 500 0.1 17 (150,): Weighted 0.810198 (0.054520)\n",
      "logistic lbfgs 500 0.1 17 (150,): Macro 0.690078 (0.073053)\n",
      "Testing 724/2880\n",
      "logistic lbfgs 500 0.1 17 (200,): Weighted 0.813444 (0.032012)\n",
      "logistic lbfgs 500 0.1 17 (200,): Macro 0.700059 (0.036892)\n",
      "Testing 725/2880\n",
      "logistic lbfgs 500 0.1 29 (50,): Weighted 0.826643 (0.071819)\n",
      "logistic lbfgs 500 0.1 29 (50,): Macro 0.743067 (0.086397)\n",
      "Testing 726/2880\n",
      "logistic lbfgs 500 0.1 29 (100,): Weighted 0.801992 (0.046238)\n",
      "logistic lbfgs 500 0.1 29 (100,): Macro 0.675356 (0.046768)\n",
      "Testing 727/2880\n",
      "logistic lbfgs 500 0.1 29 (150,): Weighted 0.810625 (0.059227)\n",
      "logistic lbfgs 500 0.1 29 (150,): Macro 0.681671 (0.069295)\n",
      "Testing 728/2880\n",
      "logistic lbfgs 500 0.1 29 (200,): Weighted 0.818850 (0.033083)\n",
      "logistic lbfgs 500 0.1 29 (200,): Macro 0.694553 (0.031431)\n",
      "Testing 729/2880\n",
      "logistic lbfgs 500 0.1 42 (50,): Weighted 0.800390 (0.072120)\n",
      "logistic lbfgs 500 0.1 42 (50,): Macro 0.667484 (0.101537)\n",
      "Testing 730/2880\n",
      "logistic lbfgs 500 0.1 42 (100,): Weighted 0.807136 (0.047696)\n",
      "logistic lbfgs 500 0.1 42 (100,): Macro 0.688801 (0.053881)\n",
      "Testing 731/2880\n",
      "logistic lbfgs 500 0.1 42 (150,): Weighted 0.805945 (0.061410)\n",
      "logistic lbfgs 500 0.1 42 (150,): Macro 0.681097 (0.069818)\n",
      "Testing 732/2880\n",
      "logistic lbfgs 500 0.1 42 (200,): Weighted 0.805914 (0.059195)\n",
      "logistic lbfgs 500 0.1 42 (200,): Macro 0.679652 (0.071220)\n",
      "Testing 733/2880\n",
      "logistic lbfgs 500 0.1 76 (50,): Weighted 0.815206 (0.062568)\n",
      "logistic lbfgs 500 0.1 76 (50,): Macro 0.689439 (0.090487)\n",
      "Testing 734/2880\n",
      "logistic lbfgs 500 0.1 76 (100,): Weighted 0.829107 (0.051222)\n",
      "logistic lbfgs 500 0.1 76 (100,): Macro 0.726337 (0.058567)\n",
      "Testing 735/2880\n",
      "logistic lbfgs 500 0.1 76 (150,): Weighted 0.798489 (0.064243)\n",
      "logistic lbfgs 500 0.1 76 (150,): Macro 0.675495 (0.083946)\n",
      "Testing 736/2880\n",
      "logistic lbfgs 500 0.1 76 (200,): Weighted 0.814860 (0.049879)\n",
      "logistic lbfgs 500 0.1 76 (200,): Macro 0.691903 (0.061551)\n",
      "Testing 737/2880\n",
      "logistic lbfgs 500 0.1 112 (50,): Weighted 0.816300 (0.038888)\n",
      "logistic lbfgs 500 0.1 112 (50,): Macro 0.698945 (0.042528)\n",
      "Testing 738/2880\n",
      "logistic lbfgs 500 0.1 112 (100,): Weighted 0.802736 (0.033571)\n",
      "logistic lbfgs 500 0.1 112 (100,): Macro 0.682281 (0.029168)\n",
      "Testing 739/2880\n",
      "logistic lbfgs 500 0.1 112 (150,): Weighted 0.795190 (0.038603)\n",
      "logistic lbfgs 500 0.1 112 (150,): Macro 0.663469 (0.035050)\n",
      "Testing 740/2880\n",
      "logistic lbfgs 500 0.1 112 (200,): Weighted 0.820342 (0.059486)\n",
      "logistic lbfgs 500 0.1 112 (200,): Macro 0.703192 (0.082807)\n",
      "Testing 741/2880\n",
      "logistic lbfgs 500 0.01 17 (50,): Weighted 0.779998 (0.084813)\n",
      "logistic lbfgs 500 0.01 17 (50,): Macro 0.655345 (0.112988)\n",
      "Testing 742/2880\n",
      "logistic lbfgs 500 0.01 17 (100,): Weighted 0.826425 (0.046454)\n",
      "logistic lbfgs 500 0.01 17 (100,): Macro 0.707028 (0.065257)\n",
      "Testing 743/2880\n",
      "logistic lbfgs 500 0.01 17 (150,): Weighted 0.787510 (0.013810)\n",
      "logistic lbfgs 500 0.01 17 (150,): Macro 0.658004 (0.011264)\n",
      "Testing 744/2880\n",
      "logistic lbfgs 500 0.01 17 (200,): Weighted 0.811052 (0.060106)\n",
      "logistic lbfgs 500 0.01 17 (200,): Macro 0.691281 (0.065677)\n",
      "Testing 745/2880\n",
      "logistic lbfgs 500 0.01 29 (50,): Weighted 0.768165 (0.079355)\n",
      "logistic lbfgs 500 0.01 29 (50,): Macro 0.642604 (0.091749)\n",
      "Testing 746/2880\n",
      "logistic lbfgs 500 0.01 29 (100,): Weighted 0.764181 (0.063544)\n",
      "logistic lbfgs 500 0.01 29 (100,): Macro 0.627580 (0.065803)\n",
      "Testing 747/2880\n",
      "logistic lbfgs 500 0.01 29 (150,): Weighted 0.790501 (0.084393)\n",
      "logistic lbfgs 500 0.01 29 (150,): Macro 0.678894 (0.109177)\n",
      "Testing 748/2880\n",
      "logistic lbfgs 500 0.01 29 (200,): Weighted 0.767950 (0.065001)\n",
      "logistic lbfgs 500 0.01 29 (200,): Macro 0.635021 (0.067371)\n",
      "Testing 749/2880\n",
      "logistic lbfgs 500 0.01 42 (50,): Weighted 0.790109 (0.068784)\n",
      "logistic lbfgs 500 0.01 42 (50,): Macro 0.659428 (0.094388)\n",
      "Testing 750/2880\n",
      "logistic lbfgs 500 0.01 42 (100,): Weighted 0.800285 (0.058802)\n",
      "logistic lbfgs 500 0.01 42 (100,): Macro 0.693097 (0.062680)\n",
      "Testing 751/2880\n",
      "logistic lbfgs 500 0.01 42 (150,): Weighted 0.754053 (0.036211)\n",
      "logistic lbfgs 500 0.01 42 (150,): Macro 0.599116 (0.067894)\n",
      "Testing 752/2880\n",
      "logistic lbfgs 500 0.01 42 (200,): Weighted 0.812233 (0.053720)\n",
      "logistic lbfgs 500 0.01 42 (200,): Macro 0.696164 (0.062333)\n",
      "Testing 753/2880\n",
      "logistic lbfgs 500 0.01 76 (50,): Weighted 0.791408 (0.051165)\n",
      "logistic lbfgs 500 0.01 76 (50,): Macro 0.661332 (0.071750)\n",
      "Testing 754/2880\n",
      "logistic lbfgs 500 0.01 76 (100,): Weighted 0.820770 (0.055325)\n",
      "logistic lbfgs 500 0.01 76 (100,): Macro 0.714059 (0.072394)\n",
      "Testing 755/2880\n",
      "logistic lbfgs 500 0.01 76 (150,): Weighted 0.765974 (0.039592)\n",
      "logistic lbfgs 500 0.01 76 (150,): Macro 0.630506 (0.067191)\n",
      "Testing 756/2880\n",
      "logistic lbfgs 500 0.01 76 (200,): Weighted 0.830721 (0.039828)\n",
      "logistic lbfgs 500 0.01 76 (200,): Macro 0.747124 (0.044120)\n",
      "Testing 757/2880\n",
      "logistic lbfgs 500 0.01 112 (50,): Weighted 0.805291 (0.062056)\n",
      "logistic lbfgs 500 0.01 112 (50,): Macro 0.680429 (0.081960)\n",
      "Testing 758/2880\n",
      "logistic lbfgs 500 0.01 112 (100,): Weighted 0.758797 (0.015272)\n",
      "logistic lbfgs 500 0.01 112 (100,): Macro 0.602123 (0.032318)\n",
      "Testing 759/2880\n",
      "logistic lbfgs 500 0.01 112 (150,): Weighted 0.794143 (0.085737)\n",
      "logistic lbfgs 500 0.01 112 (150,): Macro 0.660837 (0.129319)\n",
      "Testing 760/2880\n",
      "logistic lbfgs 500 0.01 112 (200,): Weighted 0.794892 (0.056747)\n",
      "logistic lbfgs 500 0.01 112 (200,): Macro 0.672195 (0.066914)\n",
      "Testing 761/2880\n",
      "logistic lbfgs 500 0.001 17 (50,): Weighted 0.794762 (0.067732)\n",
      "logistic lbfgs 500 0.001 17 (50,): Macro 0.675231 (0.086647)\n",
      "Testing 762/2880\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic lbfgs 500 0.001 17 (100,): Weighted 0.813036 (0.055303)\n",
      "logistic lbfgs 500 0.001 17 (100,): Macro 0.706153 (0.054038)\n",
      "Testing 763/2880\n",
      "logistic lbfgs 500 0.001 17 (150,): Weighted 0.791448 (0.063686)\n",
      "logistic lbfgs 500 0.001 17 (150,): Macro 0.665812 (0.083726)\n",
      "Testing 764/2880\n",
      "logistic lbfgs 500 0.001 17 (200,): Weighted 0.783679 (0.024440)\n",
      "logistic lbfgs 500 0.001 17 (200,): Macro 0.644727 (0.016134)\n",
      "Testing 765/2880\n",
      "logistic lbfgs 500 0.001 29 (50,): Weighted 0.787398 (0.055486)\n",
      "logistic lbfgs 500 0.001 29 (50,): Macro 0.661469 (0.046036)\n",
      "Testing 766/2880\n",
      "logistic lbfgs 500 0.001 29 (100,): Weighted 0.783535 (0.061135)\n",
      "logistic lbfgs 500 0.001 29 (100,): Macro 0.648106 (0.075358)\n",
      "Testing 767/2880\n",
      "logistic lbfgs 500 0.001 29 (150,): Weighted 0.791194 (0.069993)\n",
      "logistic lbfgs 500 0.001 29 (150,): Macro 0.662234 (0.092400)\n",
      "Testing 768/2880\n",
      "logistic lbfgs 500 0.001 29 (200,): Weighted 0.810019 (0.067630)\n",
      "logistic lbfgs 500 0.001 29 (200,): Macro 0.704918 (0.098668)\n",
      "Testing 769/2880\n",
      "logistic lbfgs 500 0.001 42 (50,): Weighted 0.766999 (0.081605)\n",
      "logistic lbfgs 500 0.001 42 (50,): Macro 0.621563 (0.108664)\n",
      "Testing 770/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic lbfgs 500 0.001 42 (100,): Weighted 0.740025 (0.043353)\n",
      "logistic lbfgs 500 0.001 42 (100,): Macro 0.577455 (0.017122)\n",
      "Testing 771/2880\n",
      "logistic lbfgs 500 0.001 42 (150,): Weighted 0.803857 (0.045518)\n",
      "logistic lbfgs 500 0.001 42 (150,): Macro 0.679930 (0.044330)\n",
      "Testing 772/2880\n",
      "logistic lbfgs 500 0.001 42 (200,): Weighted 0.827367 (0.040459)\n",
      "logistic lbfgs 500 0.001 42 (200,): Macro 0.718386 (0.052046)\n",
      "Testing 773/2880\n",
      "logistic lbfgs 500 0.001 76 (50,): Weighted 0.789664 (0.032202)\n",
      "logistic lbfgs 500 0.001 76 (50,): Macro 0.658082 (0.037295)\n",
      "Testing 774/2880\n",
      "logistic lbfgs 500 0.001 76 (100,): Weighted 0.775774 (0.064637)\n",
      "logistic lbfgs 500 0.001 76 (100,): Macro 0.645063 (0.094536)\n",
      "Testing 775/2880\n",
      "logistic lbfgs 500 0.001 76 (150,): Weighted 0.791666 (0.068851)\n",
      "logistic lbfgs 500 0.001 76 (150,): Macro 0.673419 (0.086925)\n",
      "Testing 776/2880\n",
      "logistic lbfgs 500 0.001 76 (200,): Weighted 0.767094 (0.083728)\n",
      "logistic lbfgs 500 0.001 76 (200,): Macro 0.651148 (0.094526)\n",
      "Testing 777/2880\n",
      "logistic lbfgs 500 0.001 112 (50,): Weighted 0.781192 (0.063065)\n",
      "logistic lbfgs 500 0.001 112 (50,): Macro 0.650751 (0.082042)\n",
      "Testing 778/2880\n",
      "logistic lbfgs 500 0.001 112 (100,): Weighted 0.776135 (0.041305)\n",
      "logistic lbfgs 500 0.001 112 (100,): Macro 0.639887 (0.044418)\n",
      "Testing 779/2880\n",
      "logistic lbfgs 500 0.001 112 (150,): Weighted 0.793736 (0.049429)\n",
      "logistic lbfgs 500 0.001 112 (150,): Macro 0.664507 (0.062628)\n",
      "Testing 780/2880\n",
      "logistic lbfgs 500 0.001 112 (200,): Weighted 0.770938 (0.070335)\n",
      "logistic lbfgs 500 0.001 112 (200,): Macro 0.651610 (0.099063)\n",
      "Testing 781/2880\n",
      "logistic lbfgs 500 0.0001 17 (50,): Weighted 0.790996 (0.060323)\n",
      "logistic lbfgs 500 0.0001 17 (50,): Macro 0.661043 (0.076985)\n",
      "Testing 782/2880\n",
      "logistic lbfgs 500 0.0001 17 (100,): Weighted 0.784006 (0.052630)\n",
      "logistic lbfgs 500 0.0001 17 (100,): Macro 0.655567 (0.063648)\n",
      "Testing 783/2880\n",
      "logistic lbfgs 500 0.0001 17 (150,): Weighted 0.757311 (0.075881)\n",
      "logistic lbfgs 500 0.0001 17 (150,): Macro 0.606412 (0.100612)\n",
      "Testing 784/2880\n",
      "logistic lbfgs 500 0.0001 17 (200,): Weighted 0.792038 (0.048160)\n",
      "logistic lbfgs 500 0.0001 17 (200,): Macro 0.648754 (0.057773)\n",
      "Testing 785/2880\n",
      "logistic lbfgs 500 0.0001 29 (50,): Weighted 0.761767 (0.071683)\n",
      "logistic lbfgs 500 0.0001 29 (50,): Macro 0.634032 (0.071478)\n",
      "Testing 786/2880\n",
      "logistic lbfgs 500 0.0001 29 (100,): Weighted 0.772219 (0.064763)\n",
      "logistic lbfgs 500 0.0001 29 (100,): Macro 0.626229 (0.096265)\n",
      "Testing 787/2880\n",
      "logistic lbfgs 500 0.0001 29 (150,): Weighted 0.785337 (0.054598)\n",
      "logistic lbfgs 500 0.0001 29 (150,): Macro 0.660265 (0.072812)\n",
      "Testing 788/2880\n",
      "logistic lbfgs 500 0.0001 29 (200,): Weighted 0.760142 (0.053444)\n",
      "logistic lbfgs 500 0.0001 29 (200,): Macro 0.605432 (0.060883)\n",
      "Testing 789/2880\n",
      "logistic lbfgs 500 0.0001 42 (50,): Weighted 0.768202 (0.070033)\n",
      "logistic lbfgs 500 0.0001 42 (50,): Macro 0.634424 (0.096542)\n",
      "Testing 790/2880\n",
      "logistic lbfgs 500 0.0001 42 (100,): Weighted 0.752940 (0.042246)\n",
      "logistic lbfgs 500 0.0001 42 (100,): Macro 0.590889 (0.039793)\n",
      "Testing 791/2880\n",
      "logistic lbfgs 500 0.0001 42 (150,): Weighted 0.792116 (0.061807)\n",
      "logistic lbfgs 500 0.0001 42 (150,): Macro 0.664028 (0.091527)\n",
      "Testing 792/2880\n",
      "logistic lbfgs 500 0.0001 42 (200,): Weighted 0.757644 (0.040201)\n",
      "logistic lbfgs 500 0.0001 42 (200,): Macro 0.622418 (0.047604)\n",
      "Testing 793/2880\n",
      "logistic lbfgs 500 0.0001 76 (50,): Weighted 0.787093 (0.043670)\n",
      "logistic lbfgs 500 0.0001 76 (50,): Macro 0.650043 (0.044845)\n",
      "Testing 794/2880\n",
      "logistic lbfgs 500 0.0001 76 (100,): Weighted 0.751510 (0.051204)\n",
      "logistic lbfgs 500 0.0001 76 (100,): Macro 0.625118 (0.053658)\n",
      "Testing 795/2880\n",
      "logistic lbfgs 500 0.0001 76 (150,): Weighted 0.773659 (0.063639)\n",
      "logistic lbfgs 500 0.0001 76 (150,): Macro 0.646739 (0.080088)\n",
      "Testing 796/2880\n",
      "logistic lbfgs 500 0.0001 76 (200,): Weighted 0.784742 (0.045993)\n",
      "logistic lbfgs 500 0.0001 76 (200,): Macro 0.653264 (0.059203)\n",
      "Testing 797/2880\n",
      "logistic lbfgs 500 0.0001 112 (50,): Weighted 0.766030 (0.084370)\n",
      "logistic lbfgs 500 0.0001 112 (50,): Macro 0.644005 (0.124363)\n",
      "Testing 798/2880\n",
      "logistic lbfgs 500 0.0001 112 (100,): Weighted 0.783277 (0.029695)\n",
      "logistic lbfgs 500 0.0001 112 (100,): Macro 0.654604 (0.041966)\n",
      "Testing 799/2880\n",
      "logistic lbfgs 500 0.0001 112 (150,): Weighted 0.771096 (0.104746)\n",
      "logistic lbfgs 500 0.0001 112 (150,): Macro 0.649787 (0.134981)\n",
      "Testing 800/2880\n",
      "logistic lbfgs 500 0.0001 112 (200,): Weighted 0.797186 (0.054546)\n",
      "logistic lbfgs 500 0.0001 112 (200,): Macro 0.667701 (0.075751)\n",
      "Testing 801/2880\n",
      "logistic lbfgs 1000 0.1 17 (50,): Weighted 0.810219 (0.035054)\n",
      "logistic lbfgs 1000 0.1 17 (50,): Macro 0.673670 (0.025348)\n",
      "Testing 802/2880\n",
      "logistic lbfgs 1000 0.1 17 (100,): Weighted 0.810911 (0.037816)\n",
      "logistic lbfgs 1000 0.1 17 (100,): Macro 0.685337 (0.039762)\n",
      "Testing 803/2880\n",
      "logistic lbfgs 1000 0.1 17 (150,): Weighted 0.827423 (0.053901)\n",
      "logistic lbfgs 1000 0.1 17 (150,): Macro 0.719111 (0.067946)\n",
      "Testing 804/2880\n",
      "logistic lbfgs 1000 0.1 17 (200,): Weighted 0.831672 (0.041438)\n",
      "logistic lbfgs 1000 0.1 17 (200,): Macro 0.712813 (0.047334)\n",
      "Testing 805/2880\n",
      "logistic lbfgs 1000 0.1 29 (50,): Weighted 0.811954 (0.053249)\n",
      "logistic lbfgs 1000 0.1 29 (50,): Macro 0.695382 (0.067039)\n",
      "Testing 806/2880\n",
      "logistic lbfgs 1000 0.1 29 (100,): Weighted 0.824416 (0.055626)\n",
      "logistic lbfgs 1000 0.1 29 (100,): Macro 0.716662 (0.068999)\n",
      "Testing 807/2880\n",
      "logistic lbfgs 1000 0.1 29 (150,): Weighted 0.818192 (0.061130)\n",
      "logistic lbfgs 1000 0.1 29 (150,): Macro 0.699194 (0.089679)\n",
      "Testing 808/2880\n",
      "logistic lbfgs 1000 0.1 29 (200,): Weighted 0.832747 (0.061622)\n",
      "logistic lbfgs 1000 0.1 29 (200,): Macro 0.725908 (0.082013)\n",
      "Testing 809/2880\n",
      "logistic lbfgs 1000 0.1 42 (50,): Weighted 0.810672 (0.045099)\n",
      "logistic lbfgs 1000 0.1 42 (50,): Macro 0.690051 (0.050345)\n",
      "Testing 810/2880\n",
      "logistic lbfgs 1000 0.1 42 (100,): Weighted 0.831021 (0.050706)\n",
      "logistic lbfgs 1000 0.1 42 (100,): Macro 0.719700 (0.063251)\n",
      "Testing 811/2880\n",
      "logistic lbfgs 1000 0.1 42 (150,): Weighted 0.798612 (0.057129)\n",
      "logistic lbfgs 1000 0.1 42 (150,): Macro 0.664722 (0.063645)\n",
      "Testing 812/2880\n",
      "logistic lbfgs 1000 0.1 42 (200,): Weighted 0.812173 (0.060296)\n",
      "logistic lbfgs 1000 0.1 42 (200,): Macro 0.699893 (0.070520)\n",
      "Testing 813/2880\n",
      "logistic lbfgs 1000 0.1 76 (50,): Weighted 0.838564 (0.034298)\n",
      "logistic lbfgs 1000 0.1 76 (50,): Macro 0.719549 (0.044225)\n",
      "Testing 814/2880\n",
      "logistic lbfgs 1000 0.1 76 (100,): Weighted 0.824021 (0.056348)\n",
      "logistic lbfgs 1000 0.1 76 (100,): Macro 0.709663 (0.072203)\n",
      "Testing 815/2880\n",
      "logistic lbfgs 1000 0.1 76 (150,): Weighted 0.837202 (0.048552)\n",
      "logistic lbfgs 1000 0.1 76 (150,): Macro 0.732771 (0.057915)\n",
      "Testing 816/2880\n",
      "logistic lbfgs 1000 0.1 76 (200,): Weighted 0.801545 (0.061498)\n",
      "logistic lbfgs 1000 0.1 76 (200,): Macro 0.677739 (0.077610)\n",
      "Testing 817/2880\n",
      "logistic lbfgs 1000 0.1 112 (50,): Weighted 0.808522 (0.030588)\n",
      "logistic lbfgs 1000 0.1 112 (50,): Macro 0.677895 (0.036899)\n",
      "Testing 818/2880\n",
      "logistic lbfgs 1000 0.1 112 (100,): Weighted 0.816386 (0.042191)\n",
      "logistic lbfgs 1000 0.1 112 (100,): Macro 0.704338 (0.059074)\n",
      "Testing 819/2880\n",
      "logistic lbfgs 1000 0.1 112 (150,): Weighted 0.811191 (0.037036)\n",
      "logistic lbfgs 1000 0.1 112 (150,): Macro 0.692540 (0.032932)\n",
      "Testing 820/2880\n",
      "logistic lbfgs 1000 0.1 112 (200,): Weighted 0.794544 (0.061031)\n",
      "logistic lbfgs 1000 0.1 112 (200,): Macro 0.657906 (0.078453)\n",
      "Testing 821/2880\n",
      "logistic lbfgs 1000 0.01 17 (50,): Weighted 0.762078 (0.083707)\n",
      "logistic lbfgs 1000 0.01 17 (50,): Macro 0.639142 (0.107174)\n",
      "Testing 822/2880\n",
      "logistic lbfgs 1000 0.01 17 (100,): Weighted 0.816082 (0.064935)\n",
      "logistic lbfgs 1000 0.01 17 (100,): Macro 0.703613 (0.085993)\n",
      "Testing 823/2880\n",
      "logistic lbfgs 1000 0.01 17 (150,): Weighted 0.770599 (0.038352)\n",
      "logistic lbfgs 1000 0.01 17 (150,): Macro 0.630050 (0.045645)\n",
      "Testing 824/2880\n",
      "logistic lbfgs 1000 0.01 17 (200,): Weighted 0.801086 (0.042247)\n",
      "logistic lbfgs 1000 0.01 17 (200,): Macro 0.659164 (0.041961)\n",
      "Testing 825/2880\n",
      "logistic lbfgs 1000 0.01 29 (50,): Weighted 0.769356 (0.061520)\n",
      "logistic lbfgs 1000 0.01 29 (50,): Macro 0.631882 (0.079601)\n",
      "Testing 826/2880\n",
      "logistic lbfgs 1000 0.01 29 (100,): Weighted 0.820368 (0.026526)\n",
      "logistic lbfgs 1000 0.01 29 (100,): Macro 0.702869 (0.019587)\n",
      "Testing 827/2880\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic lbfgs 1000 0.01 29 (150,): Weighted 0.819854 (0.067335)\n",
      "logistic lbfgs 1000 0.01 29 (150,): Macro 0.714746 (0.085867)\n",
      "Testing 828/2880\n",
      "logistic lbfgs 1000 0.01 29 (200,): Weighted 0.795085 (0.059661)\n",
      "logistic lbfgs 1000 0.01 29 (200,): Macro 0.658502 (0.073317)\n",
      "Testing 829/2880\n",
      "logistic lbfgs 1000 0.01 42 (50,): Weighted 0.820720 (0.058963)\n",
      "logistic lbfgs 1000 0.01 42 (50,): Macro 0.702685 (0.077473)\n",
      "Testing 830/2880\n",
      "logistic lbfgs 1000 0.01 42 (100,): Weighted 0.788738 (0.049886)\n",
      "logistic lbfgs 1000 0.01 42 (100,): Macro 0.659599 (0.050773)\n",
      "Testing 831/2880\n",
      "logistic lbfgs 1000 0.01 42 (150,): Weighted 0.795114 (0.059876)\n",
      "logistic lbfgs 1000 0.01 42 (150,): Macro 0.653637 (0.084863)\n",
      "Testing 832/2880\n",
      "logistic lbfgs 1000 0.01 42 (200,): Weighted 0.814581 (0.060958)\n",
      "logistic lbfgs 1000 0.01 42 (200,): Macro 0.700161 (0.082941)\n",
      "Testing 833/2880\n",
      "logistic lbfgs 1000 0.01 76 (50,): Weighted 0.793210 (0.025184)\n",
      "logistic lbfgs 1000 0.01 76 (50,): Macro 0.652370 (0.017041)\n",
      "Testing 834/2880\n",
      "logistic lbfgs 1000 0.01 76 (100,): Weighted 0.792360 (0.068848)\n",
      "logistic lbfgs 1000 0.01 76 (100,): Macro 0.683383 (0.088497)\n",
      "Testing 835/2880\n",
      "logistic lbfgs 1000 0.01 76 (150,): Weighted 0.804155 (0.040742)\n",
      "logistic lbfgs 1000 0.01 76 (150,): Macro 0.679278 (0.043756)\n",
      "Testing 836/2880\n",
      "logistic lbfgs 1000 0.01 76 (200,): Weighted 0.824014 (0.051859)\n",
      "logistic lbfgs 1000 0.01 76 (200,): Macro 0.714453 (0.063451)\n",
      "Testing 837/2880\n",
      "logistic lbfgs 1000 0.01 112 (50,): Weighted 0.800109 (0.068844)\n",
      "logistic lbfgs 1000 0.01 112 (50,): Macro 0.679569 (0.087591)\n",
      "Testing 838/2880\n",
      "logistic lbfgs 1000 0.01 112 (100,): Weighted 0.791432 (0.023455)\n",
      "logistic lbfgs 1000 0.01 112 (100,): Macro 0.660515 (0.035420)\n",
      "Testing 839/2880\n",
      "logistic lbfgs 1000 0.01 112 (150,): Weighted 0.795209 (0.064812)\n",
      "logistic lbfgs 1000 0.01 112 (150,): Macro 0.661216 (0.080240)\n",
      "Testing 840/2880\n",
      "logistic lbfgs 1000 0.01 112 (200,): Weighted 0.841505 (0.038594)\n",
      "logistic lbfgs 1000 0.01 112 (200,): Macro 0.734329 (0.042306)\n",
      "Testing 841/2880\n",
      "logistic lbfgs 1000 0.001 17 (50,): Weighted 0.799693 (0.090386)\n",
      "logistic lbfgs 1000 0.001 17 (50,): Macro 0.686529 (0.117332)\n",
      "Testing 842/2880\n",
      "logistic lbfgs 1000 0.001 17 (100,): Weighted 0.781586 (0.048552)\n",
      "logistic lbfgs 1000 0.001 17 (100,): Macro 0.662042 (0.037597)\n",
      "Testing 843/2880\n",
      "logistic lbfgs 1000 0.001 17 (150,): Weighted 0.759716 (0.053769)\n",
      "logistic lbfgs 1000 0.001 17 (150,): Macro 0.617289 (0.062466)\n",
      "Testing 844/2880\n",
      "logistic lbfgs 1000 0.001 17 (200,): Weighted 0.781161 (0.066624)\n",
      "logistic lbfgs 1000 0.001 17 (200,): Macro 0.661329 (0.081021)\n",
      "Testing 845/2880\n",
      "logistic lbfgs 1000 0.001 29 (50,): Weighted 0.771687 (0.065726)\n",
      "logistic lbfgs 1000 0.001 29 (50,): Macro 0.625123 (0.067621)\n",
      "Testing 846/2880\n",
      "logistic lbfgs 1000 0.001 29 (100,): Weighted 0.779167 (0.044004)\n",
      "logistic lbfgs 1000 0.001 29 (100,): Macro 0.638410 (0.050287)\n",
      "Testing 847/2880\n",
      "logistic lbfgs 1000 0.001 29 (150,): Weighted 0.801294 (0.068170)\n",
      "logistic lbfgs 1000 0.001 29 (150,): Macro 0.685831 (0.085179)\n",
      "Testing 848/2880\n",
      "logistic lbfgs 1000 0.001 29 (200,): Weighted 0.797957 (0.054867)\n",
      "logistic lbfgs 1000 0.001 29 (200,): Macro 0.689291 (0.059677)\n",
      "Testing 849/2880\n",
      "logistic lbfgs 1000 0.001 42 (50,): Weighted 0.798368 (0.060411)\n",
      "logistic lbfgs 1000 0.001 42 (50,): Macro 0.670149 (0.075621)\n",
      "Testing 850/2880\n",
      "logistic lbfgs 1000 0.001 42 (100,): Weighted 0.751468 (0.059252)\n",
      "logistic lbfgs 1000 0.001 42 (100,): Macro 0.592603 (0.050699)\n",
      "Testing 851/2880\n",
      "logistic lbfgs 1000 0.001 42 (150,): Weighted 0.774866 (0.026397)\n",
      "logistic lbfgs 1000 0.001 42 (150,): Macro 0.655071 (0.029600)\n",
      "Testing 852/2880\n",
      "logistic lbfgs 1000 0.001 42 (200,): Weighted 0.811289 (0.047682)\n",
      "logistic lbfgs 1000 0.001 42 (200,): Macro 0.702809 (0.064993)\n",
      "Testing 853/2880\n",
      "logistic lbfgs 1000 0.001 76 (50,): Weighted 0.785672 (0.060081)\n",
      "logistic lbfgs 1000 0.001 76 (50,): Macro 0.646626 (0.072890)\n",
      "Testing 854/2880\n",
      "logistic lbfgs 1000 0.001 76 (100,): Weighted 0.780251 (0.072625)\n",
      "logistic lbfgs 1000 0.001 76 (100,): Macro 0.655939 (0.094304)\n",
      "Testing 855/2880\n",
      "logistic lbfgs 1000 0.001 76 (150,): Weighted 0.774254 (0.081010)\n",
      "logistic lbfgs 1000 0.001 76 (150,): Macro 0.642485 (0.110190)\n",
      "Testing 856/2880\n",
      "logistic lbfgs 1000 0.001 76 (200,): Weighted 0.824589 (0.046926)\n",
      "logistic lbfgs 1000 0.001 76 (200,): Macro 0.720803 (0.048436)\n",
      "Testing 857/2880\n",
      "logistic lbfgs 1000 0.001 112 (50,): Weighted 0.801788 (0.053905)\n",
      "logistic lbfgs 1000 0.001 112 (50,): Macro 0.684310 (0.066494)\n",
      "Testing 858/2880\n",
      "logistic lbfgs 1000 0.001 112 (100,): Weighted 0.777294 (0.041917)\n",
      "logistic lbfgs 1000 0.001 112 (100,): Macro 0.632975 (0.040384)\n",
      "Testing 859/2880\n",
      "logistic lbfgs 1000 0.001 112 (150,): Weighted 0.778183 (0.035832)\n",
      "logistic lbfgs 1000 0.001 112 (150,): Macro 0.637557 (0.041979)\n",
      "Testing 860/2880\n",
      "logistic lbfgs 1000 0.001 112 (200,): Weighted 0.809361 (0.069041)\n",
      "logistic lbfgs 1000 0.001 112 (200,): Macro 0.684855 (0.098966)\n",
      "Testing 861/2880\n",
      "logistic lbfgs 1000 0.0001 17 (50,): Weighted 0.787069 (0.046653)\n",
      "logistic lbfgs 1000 0.0001 17 (50,): Macro 0.664977 (0.058345)\n",
      "Testing 862/2880\n",
      "logistic lbfgs 1000 0.0001 17 (100,): Weighted 0.802496 (0.058786)\n",
      "logistic lbfgs 1000 0.0001 17 (100,): Macro 0.690499 (0.075139)\n",
      "Testing 863/2880\n",
      "logistic lbfgs 1000 0.0001 17 (150,): Weighted 0.766416 (0.069261)\n",
      "logistic lbfgs 1000 0.0001 17 (150,): Macro 0.623890 (0.095764)\n",
      "Testing 864/2880\n",
      "logistic lbfgs 1000 0.0001 17 (200,): Weighted 0.779234 (0.055521)\n",
      "logistic lbfgs 1000 0.0001 17 (200,): Macro 0.627413 (0.056694)\n",
      "Testing 865/2880\n",
      "logistic lbfgs 1000 0.0001 29 (50,): Weighted 0.764852 (0.092792)\n",
      "logistic lbfgs 1000 0.0001 29 (50,): Macro 0.634107 (0.093518)\n",
      "Testing 866/2880\n",
      "logistic lbfgs 1000 0.0001 29 (100,): Weighted 0.772091 (0.071600)\n",
      "logistic lbfgs 1000 0.0001 29 (100,): Macro 0.637445 (0.097794)\n",
      "Testing 867/2880\n",
      "logistic lbfgs 1000 0.0001 29 (150,): Weighted 0.780450 (0.042836)\n",
      "logistic lbfgs 1000 0.0001 29 (150,): Macro 0.654128 (0.077080)\n",
      "Testing 868/2880\n",
      "logistic lbfgs 1000 0.0001 29 (200,): Weighted 0.805614 (0.058718)\n",
      "logistic lbfgs 1000 0.0001 29 (200,): Macro 0.684082 (0.079563)\n",
      "Testing 869/2880\n",
      "logistic lbfgs 1000 0.0001 42 (50,): Weighted 0.756835 (0.064673)\n",
      "logistic lbfgs 1000 0.0001 42 (50,): Macro 0.626418 (0.089724)\n",
      "Testing 870/2880\n",
      "logistic lbfgs 1000 0.0001 42 (100,): Weighted 0.711013 (0.057771)\n",
      "logistic lbfgs 1000 0.0001 42 (100,): Macro 0.549901 (0.049999)\n",
      "Testing 871/2880\n",
      "logistic lbfgs 1000 0.0001 42 (150,): Weighted 0.791375 (0.043331)\n",
      "logistic lbfgs 1000 0.0001 42 (150,): Macro 0.664002 (0.056330)\n",
      "Testing 872/2880\n",
      "logistic lbfgs 1000 0.0001 42 (200,): Weighted 0.787287 (0.029038)\n",
      "logistic lbfgs 1000 0.0001 42 (200,): Macro 0.660185 (0.043696)\n",
      "Testing 873/2880\n",
      "logistic lbfgs 1000 0.0001 76 (50,): Weighted 0.760964 (0.059934)\n",
      "logistic lbfgs 1000 0.0001 76 (50,): Macro 0.618656 (0.065092)\n",
      "Testing 874/2880\n",
      "logistic lbfgs 1000 0.0001 76 (100,): Weighted 0.774494 (0.066958)\n",
      "logistic lbfgs 1000 0.0001 76 (100,): Macro 0.654512 (0.075569)\n",
      "Testing 875/2880\n",
      "logistic lbfgs 1000 0.0001 76 (150,): Weighted 0.754073 (0.045133)\n",
      "logistic lbfgs 1000 0.0001 76 (150,): Macro 0.624673 (0.052740)\n",
      "Testing 876/2880\n",
      "logistic lbfgs 1000 0.0001 76 (200,): Weighted 0.776445 (0.059886)\n",
      "logistic lbfgs 1000 0.0001 76 (200,): Macro 0.646677 (0.083739)\n",
      "Testing 877/2880\n",
      "logistic lbfgs 1000 0.0001 112 (50,): Weighted 0.785121 (0.075771)\n",
      "logistic lbfgs 1000 0.0001 112 (50,): Macro 0.666225 (0.104246)\n",
      "Testing 878/2880\n",
      "logistic lbfgs 1000 0.0001 112 (100,): Weighted 0.775309 (0.056784)\n",
      "logistic lbfgs 1000 0.0001 112 (100,): Macro 0.649373 (0.054822)\n",
      "Testing 879/2880\n",
      "logistic lbfgs 1000 0.0001 112 (150,): Weighted 0.748972 (0.055306)\n",
      "logistic lbfgs 1000 0.0001 112 (150,): Macro 0.594433 (0.078418)\n",
      "Testing 880/2880\n",
      "logistic lbfgs 1000 0.0001 112 (200,): Weighted 0.792505 (0.046209)\n",
      "logistic lbfgs 1000 0.0001 112 (200,): Macro 0.665867 (0.053369)\n",
      "Testing 881/2880\n",
      "logistic lbfgs 1500 0.1 17 (50,): Weighted 0.822993 (0.040952)\n",
      "logistic lbfgs 1500 0.1 17 (50,): Macro 0.697853 (0.042191)\n",
      "Testing 882/2880\n",
      "logistic lbfgs 1500 0.1 17 (100,): Weighted 0.813096 (0.041780)\n",
      "logistic lbfgs 1500 0.1 17 (100,): Macro 0.688937 (0.050303)\n",
      "Testing 883/2880\n",
      "logistic lbfgs 1500 0.1 17 (150,): Weighted 0.815766 (0.053279)\n",
      "logistic lbfgs 1500 0.1 17 (150,): Macro 0.699466 (0.065205)\n",
      "Testing 884/2880\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic lbfgs 1500 0.1 17 (200,): Weighted 0.833476 (0.053576)\n",
      "logistic lbfgs 1500 0.1 17 (200,): Macro 0.723401 (0.070944)\n",
      "Testing 885/2880\n",
      "logistic lbfgs 1500 0.1 29 (50,): Weighted 0.803090 (0.059969)\n",
      "logistic lbfgs 1500 0.1 29 (50,): Macro 0.679153 (0.081486)\n",
      "Testing 886/2880\n",
      "logistic lbfgs 1500 0.1 29 (100,): Weighted 0.812939 (0.051048)\n",
      "logistic lbfgs 1500 0.1 29 (100,): Macro 0.696683 (0.065424)\n",
      "Testing 887/2880\n",
      "logistic lbfgs 1500 0.1 29 (150,): Weighted 0.812719 (0.052129)\n",
      "logistic lbfgs 1500 0.1 29 (150,): Macro 0.688790 (0.067486)\n",
      "Testing 888/2880\n",
      "logistic lbfgs 1500 0.1 29 (200,): Weighted 0.807477 (0.055101)\n",
      "logistic lbfgs 1500 0.1 29 (200,): Macro 0.683561 (0.078968)\n",
      "Testing 889/2880\n",
      "logistic lbfgs 1500 0.1 42 (50,): Weighted 0.820415 (0.067403)\n",
      "logistic lbfgs 1500 0.1 42 (50,): Macro 0.708247 (0.092998)\n",
      "Testing 890/2880\n",
      "logistic lbfgs 1500 0.1 42 (100,): Weighted 0.825732 (0.037177)\n",
      "logistic lbfgs 1500 0.1 42 (100,): Macro 0.713659 (0.041372)\n",
      "Testing 891/2880\n",
      "logistic lbfgs 1500 0.1 42 (150,): Weighted 0.826816 (0.057158)\n",
      "logistic lbfgs 1500 0.1 42 (150,): Macro 0.713992 (0.075439)\n",
      "Testing 892/2880\n",
      "logistic lbfgs 1500 0.1 42 (200,): Weighted 0.822788 (0.071200)\n",
      "logistic lbfgs 1500 0.1 42 (200,): Macro 0.714788 (0.095606)\n",
      "Testing 893/2880\n",
      "logistic lbfgs 1500 0.1 76 (50,): Weighted 0.819394 (0.043687)\n",
      "logistic lbfgs 1500 0.1 76 (50,): Macro 0.693866 (0.052071)\n",
      "Testing 894/2880\n",
      "logistic lbfgs 1500 0.1 76 (100,): Weighted 0.820589 (0.067157)\n",
      "logistic lbfgs 1500 0.1 76 (100,): Macro 0.712752 (0.086057)\n",
      "Testing 895/2880\n",
      "logistic lbfgs 1500 0.1 76 (150,): Weighted 0.795496 (0.057611)\n",
      "logistic lbfgs 1500 0.1 76 (150,): Macro 0.664877 (0.080070)\n",
      "Testing 896/2880\n",
      "logistic lbfgs 1500 0.1 76 (200,): Weighted 0.814486 (0.064340)\n",
      "logistic lbfgs 1500 0.1 76 (200,): Macro 0.697907 (0.083198)\n",
      "Testing 897/2880\n",
      "logistic lbfgs 1500 0.1 112 (50,): Weighted 0.812796 (0.050695)\n",
      "logistic lbfgs 1500 0.1 112 (50,): Macro 0.687287 (0.067918)\n",
      "Testing 898/2880\n",
      "logistic lbfgs 1500 0.1 112 (100,): Weighted 0.816330 (0.048111)\n",
      "logistic lbfgs 1500 0.1 112 (100,): Macro 0.708053 (0.068173)\n",
      "Testing 899/2880\n",
      "logistic lbfgs 1500 0.1 112 (150,): Weighted 0.821486 (0.037525)\n",
      "logistic lbfgs 1500 0.1 112 (150,): Macro 0.707824 (0.048949)\n",
      "Testing 900/2880\n",
      "logistic lbfgs 1500 0.1 112 (200,): Weighted 0.794271 (0.068112)\n",
      "logistic lbfgs 1500 0.1 112 (200,): Macro 0.664142 (0.089795)\n",
      "Testing 901/2880\n",
      "logistic lbfgs 1500 0.01 17 (50,): Weighted 0.787030 (0.084566)\n",
      "logistic lbfgs 1500 0.01 17 (50,): Macro 0.662178 (0.112409)\n",
      "Testing 902/2880\n",
      "logistic lbfgs 1500 0.01 17 (100,): Weighted 0.823371 (0.065288)\n",
      "logistic lbfgs 1500 0.01 17 (100,): Macro 0.719898 (0.083861)\n",
      "Testing 903/2880\n",
      "logistic lbfgs 1500 0.01 17 (150,): Weighted 0.779676 (0.032622)\n",
      "logistic lbfgs 1500 0.01 17 (150,): Macro 0.641084 (0.023638)\n",
      "Testing 904/2880\n",
      "logistic lbfgs 1500 0.01 17 (200,): Weighted 0.814503 (0.054566)\n",
      "logistic lbfgs 1500 0.01 17 (200,): Macro 0.687717 (0.065515)\n",
      "Testing 905/2880\n",
      "logistic lbfgs 1500 0.01 29 (50,): Weighted 0.781557 (0.081438)\n",
      "logistic lbfgs 1500 0.01 29 (50,): Macro 0.658013 (0.100487)\n",
      "Testing 906/2880\n",
      "logistic lbfgs 1500 0.01 29 (100,): Weighted 0.827212 (0.041494)\n",
      "logistic lbfgs 1500 0.01 29 (100,): Macro 0.718330 (0.032367)\n",
      "Testing 907/2880\n",
      "logistic lbfgs 1500 0.01 29 (150,): Weighted 0.817848 (0.056486)\n",
      "logistic lbfgs 1500 0.01 29 (150,): Macro 0.705948 (0.063026)\n",
      "Testing 908/2880\n",
      "logistic lbfgs 1500 0.01 29 (200,): Weighted 0.820531 (0.044922)\n",
      "logistic lbfgs 1500 0.01 29 (200,): Macro 0.692256 (0.055769)\n",
      "Testing 909/2880\n",
      "logistic lbfgs 1500 0.01 42 (50,): Weighted 0.843884 (0.059316)\n",
      "logistic lbfgs 1500 0.01 42 (50,): Macro 0.745438 (0.083603)\n",
      "Testing 910/2880\n",
      "logistic lbfgs 1500 0.01 42 (100,): Weighted 0.815021 (0.034143)\n",
      "logistic lbfgs 1500 0.01 42 (100,): Macro 0.691861 (0.029669)\n",
      "Testing 911/2880\n",
      "logistic lbfgs 1500 0.01 42 (150,): Weighted 0.813533 (0.037552)\n",
      "logistic lbfgs 1500 0.01 42 (150,): Macro 0.682657 (0.047592)\n",
      "Testing 912/2880\n",
      "logistic lbfgs 1500 0.01 42 (200,): Weighted 0.826142 (0.040571)\n",
      "logistic lbfgs 1500 0.01 42 (200,): Macro 0.705874 (0.046080)\n",
      "Testing 913/2880\n",
      "logistic lbfgs 1500 0.01 76 (50,): Weighted 0.788892 (0.035218)\n",
      "logistic lbfgs 1500 0.01 76 (50,): Macro 0.656060 (0.028669)\n",
      "Testing 914/2880\n",
      "logistic lbfgs 1500 0.01 76 (100,): Weighted 0.824257 (0.055527)\n",
      "logistic lbfgs 1500 0.01 76 (100,): Macro 0.719872 (0.076779)\n",
      "Testing 915/2880\n",
      "logistic lbfgs 1500 0.01 76 (150,): Weighted 0.830378 (0.033536)\n",
      "logistic lbfgs 1500 0.01 76 (150,): Macro 0.715993 (0.034633)\n",
      "Testing 916/2880\n",
      "logistic lbfgs 1500 0.01 76 (200,): Weighted 0.829444 (0.051455)\n",
      "logistic lbfgs 1500 0.01 76 (200,): Macro 0.710416 (0.068831)\n",
      "Testing 917/2880\n",
      "logistic lbfgs 1500 0.01 112 (50,): Weighted 0.810076 (0.056756)\n",
      "logistic lbfgs 1500 0.01 112 (50,): Macro 0.689681 (0.082692)\n",
      "Testing 918/2880\n",
      "logistic lbfgs 1500 0.01 112 (100,): Weighted 0.810383 (0.029004)\n",
      "logistic lbfgs 1500 0.01 112 (100,): Macro 0.688492 (0.023962)\n",
      "Testing 919/2880\n",
      "logistic lbfgs 1500 0.01 112 (150,): Weighted 0.810649 (0.030106)\n",
      "logistic lbfgs 1500 0.01 112 (150,): Macro 0.674981 (0.041601)\n",
      "Testing 920/2880\n",
      "logistic lbfgs 1500 0.01 112 (200,): Weighted 0.818905 (0.044400)\n",
      "logistic lbfgs 1500 0.01 112 (200,): Macro 0.689408 (0.054966)\n",
      "Testing 921/2880\n",
      "logistic lbfgs 1500 0.001 17 (50,): Weighted 0.809198 (0.057551)\n",
      "logistic lbfgs 1500 0.001 17 (50,): Macro 0.689260 (0.079382)\n",
      "Testing 922/2880\n",
      "logistic lbfgs 1500 0.001 17 (100,): Weighted 0.776035 (0.049531)\n",
      "logistic lbfgs 1500 0.001 17 (100,): Macro 0.651739 (0.060589)\n",
      "Testing 923/2880\n",
      "logistic lbfgs 1500 0.001 17 (150,): Weighted 0.788720 (0.018397)\n",
      "logistic lbfgs 1500 0.001 17 (150,): Macro 0.657068 (0.016953)\n",
      "Testing 924/2880\n",
      "logistic lbfgs 1500 0.001 17 (200,): Weighted 0.805565 (0.029616)\n",
      "logistic lbfgs 1500 0.001 17 (200,): Macro 0.688399 (0.026663)\n",
      "Testing 925/2880\n",
      "logistic lbfgs 1500 0.001 29 (50,): Weighted 0.798457 (0.046847)\n",
      "logistic lbfgs 1500 0.001 29 (50,): Macro 0.667744 (0.050159)\n",
      "Testing 926/2880\n",
      "logistic lbfgs 1500 0.001 29 (100,): Weighted 0.788962 (0.040703)\n",
      "logistic lbfgs 1500 0.001 29 (100,): Macro 0.646813 (0.022615)\n",
      "Testing 927/2880\n",
      "logistic lbfgs 1500 0.001 29 (150,): Weighted 0.827813 (0.052108)\n",
      "logistic lbfgs 1500 0.001 29 (150,): Macro 0.731023 (0.062358)\n",
      "Testing 928/2880\n",
      "logistic lbfgs 1500 0.001 29 (200,): Weighted 0.807646 (0.042610)\n",
      "logistic lbfgs 1500 0.001 29 (200,): Macro 0.689874 (0.036343)\n",
      "Testing 929/2880\n",
      "logistic lbfgs 1500 0.001 42 (50,): Weighted 0.826349 (0.037992)\n",
      "logistic lbfgs 1500 0.001 42 (50,): Macro 0.696167 (0.066145)\n",
      "Testing 930/2880\n",
      "logistic lbfgs 1500 0.001 42 (100,): Weighted 0.761418 (0.047586)\n",
      "logistic lbfgs 1500 0.001 42 (100,): Macro 0.596951 (0.054288)\n",
      "Testing 931/2880\n",
      "logistic lbfgs 1500 0.001 42 (150,): Weighted 0.837923 (0.027773)\n",
      "logistic lbfgs 1500 0.001 42 (150,): Macro 0.737123 (0.035547)\n",
      "Testing 932/2880\n",
      "logistic lbfgs 1500 0.001 42 (200,): Weighted 0.822986 (0.038414)\n",
      "logistic lbfgs 1500 0.001 42 (200,): Macro 0.723540 (0.041437)\n",
      "Testing 933/2880\n",
      "logistic lbfgs 1500 0.001 76 (50,): Weighted 0.800332 (0.057606)\n",
      "logistic lbfgs 1500 0.001 76 (50,): Macro 0.676640 (0.077670)\n",
      "Testing 934/2880\n",
      "logistic lbfgs 1500 0.001 76 (100,): Weighted 0.788539 (0.072512)\n",
      "logistic lbfgs 1500 0.001 76 (100,): Macro 0.673994 (0.090606)\n",
      "Testing 935/2880\n",
      "logistic lbfgs 1500 0.001 76 (150,): Weighted 0.765277 (0.072074)\n",
      "logistic lbfgs 1500 0.001 76 (150,): Macro 0.632922 (0.085526)\n",
      "Testing 936/2880\n",
      "logistic lbfgs 1500 0.001 76 (200,): Weighted 0.813752 (0.031155)\n",
      "logistic lbfgs 1500 0.001 76 (200,): Macro 0.707391 (0.019007)\n",
      "Testing 937/2880\n",
      "logistic lbfgs 1500 0.001 112 (50,): Weighted 0.774143 (0.047080)\n",
      "logistic lbfgs 1500 0.001 112 (50,): Macro 0.648514 (0.064795)\n",
      "Testing 938/2880\n",
      "logistic lbfgs 1500 0.001 112 (100,): Weighted 0.792896 (0.030872)\n",
      "logistic lbfgs 1500 0.001 112 (100,): Macro 0.663853 (0.021647)\n",
      "Testing 939/2880\n",
      "logistic lbfgs 1500 0.001 112 (150,): Weighted 0.763518 (0.039559)\n",
      "logistic lbfgs 1500 0.001 112 (150,): Macro 0.623792 (0.050785)\n",
      "Testing 940/2880\n",
      "logistic lbfgs 1500 0.001 112 (200,): Weighted 0.803642 (0.044019)\n",
      "logistic lbfgs 1500 0.001 112 (200,): Macro 0.677222 (0.053567)\n",
      "Testing 941/2880\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic lbfgs 1500 0.0001 17 (50,): Weighted 0.799576 (0.040013)\n",
      "logistic lbfgs 1500 0.0001 17 (50,): Macro 0.677267 (0.065615)\n",
      "Testing 942/2880\n",
      "logistic lbfgs 1500 0.0001 17 (100,): Weighted 0.809225 (0.064401)\n",
      "logistic lbfgs 1500 0.0001 17 (100,): Macro 0.704567 (0.082843)\n",
      "Testing 943/2880\n",
      "logistic lbfgs 1500 0.0001 17 (150,): Weighted 0.746853 (0.048943)\n",
      "logistic lbfgs 1500 0.0001 17 (150,): Macro 0.581486 (0.065064)\n",
      "Testing 944/2880\n",
      "logistic lbfgs 1500 0.0001 17 (200,): Weighted 0.771293 (0.057367)\n",
      "logistic lbfgs 1500 0.0001 17 (200,): Macro 0.623788 (0.067852)\n",
      "Testing 945/2880\n",
      "logistic lbfgs 1500 0.0001 29 (50,): Weighted 0.763806 (0.062040)\n",
      "logistic lbfgs 1500 0.0001 29 (50,): Macro 0.629247 (0.072274)\n",
      "Testing 946/2880\n",
      "logistic lbfgs 1500 0.0001 29 (100,): Weighted 0.768952 (0.069301)\n",
      "logistic lbfgs 1500 0.0001 29 (100,): Macro 0.640115 (0.093647)\n",
      "Testing 947/2880\n",
      "logistic lbfgs 1500 0.0001 29 (150,): Weighted 0.774596 (0.025387)\n",
      "logistic lbfgs 1500 0.0001 29 (150,): Macro 0.647295 (0.045151)\n",
      "Testing 948/2880\n",
      "logistic lbfgs 1500 0.0001 29 (200,): Weighted 0.795902 (0.054933)\n",
      "logistic lbfgs 1500 0.0001 29 (200,): Macro 0.671899 (0.072035)\n",
      "Testing 949/2880\n",
      "logistic lbfgs 1500 0.0001 42 (50,): Weighted 0.774350 (0.070474)\n",
      "logistic lbfgs 1500 0.0001 42 (50,): Macro 0.635403 (0.091876)\n",
      "Testing 950/2880\n",
      "logistic lbfgs 1500 0.0001 42 (100,): Weighted 0.741044 (0.051605)\n",
      "logistic lbfgs 1500 0.0001 42 (100,): Macro 0.585739 (0.051647)\n",
      "Testing 951/2880\n",
      "logistic lbfgs 1500 0.0001 42 (150,): Weighted 0.784031 (0.036700)\n",
      "logistic lbfgs 1500 0.0001 42 (150,): Macro 0.651002 (0.041634)\n",
      "Testing 952/2880\n",
      "logistic lbfgs 1500 0.0001 42 (200,): Weighted 0.782563 (0.032731)\n",
      "logistic lbfgs 1500 0.0001 42 (200,): Macro 0.661229 (0.043160)\n",
      "Testing 953/2880\n",
      "logistic lbfgs 1500 0.0001 76 (50,): Weighted 0.769773 (0.070172)\n",
      "logistic lbfgs 1500 0.0001 76 (50,): Macro 0.638691 (0.077738)\n",
      "Testing 954/2880\n",
      "logistic lbfgs 1500 0.0001 76 (100,): Weighted 0.795138 (0.048432)\n",
      "logistic lbfgs 1500 0.0001 76 (100,): Macro 0.682120 (0.048601)\n",
      "Testing 955/2880\n",
      "logistic lbfgs 1500 0.0001 76 (150,): Weighted 0.772588 (0.053404)\n",
      "logistic lbfgs 1500 0.0001 76 (150,): Macro 0.652347 (0.058110)\n",
      "Testing 956/2880\n",
      "logistic lbfgs 1500 0.0001 76 (200,): Weighted 0.781908 (0.055389)\n",
      "logistic lbfgs 1500 0.0001 76 (200,): Macro 0.658034 (0.067931)\n",
      "Testing 957/2880\n",
      "logistic lbfgs 1500 0.0001 112 (50,): Weighted 0.804297 (0.083050)\n",
      "logistic lbfgs 1500 0.0001 112 (50,): Macro 0.686689 (0.113689)\n",
      "Testing 958/2880\n",
      "logistic lbfgs 1500 0.0001 112 (100,): Weighted 0.775293 (0.061557)\n",
      "logistic lbfgs 1500 0.0001 112 (100,): Macro 0.653803 (0.068482)\n",
      "Testing 959/2880\n",
      "logistic lbfgs 1500 0.0001 112 (150,): Weighted 0.763990 (0.059992)\n",
      "logistic lbfgs 1500 0.0001 112 (150,): Macro 0.635748 (0.075579)\n",
      "Testing 960/2880\n",
      "logistic lbfgs 1500 0.0001 112 (200,): Weighted 0.809472 (0.043059)\n",
      "logistic lbfgs 1500 0.0001 112 (200,): Macro 0.702873 (0.042492)\n",
      "Testing 961/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic sgd 500 0.1 17 (50,): Weighted 0.844185 (0.063174)\n",
      "logistic sgd 500 0.1 17 (50,): Macro 0.745049 (0.084795)\n",
      "Testing 962/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic sgd 500 0.1 17 (100,): Weighted 0.841004 (0.062720)\n",
      "logistic sgd 500 0.1 17 (100,): Macro 0.738188 (0.086177)\n",
      "Testing 963/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic sgd 500 0.1 17 (150,): Weighted 0.844466 (0.065587)\n",
      "logistic sgd 500 0.1 17 (150,): Macro 0.744619 (0.089343)\n",
      "Testing 964/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic sgd 500 0.1 17 (200,): Weighted 0.834713 (0.064325)\n",
      "logistic sgd 500 0.1 17 (200,): Macro 0.730437 (0.086566)\n",
      "Testing 965/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic sgd 500 0.1 29 (50,): Weighted 0.834339 (0.066750)\n",
      "logistic sgd 500 0.1 29 (50,): Macro 0.727779 (0.090798)\n",
      "Testing 966/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic sgd 500 0.1 29 (100,): Weighted 0.831554 (0.067942)\n",
      "logistic sgd 500 0.1 29 (100,): Macro 0.722780 (0.093537)\n",
      "Testing 967/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic sgd 500 0.1 29 (150,): Weighted 0.834713 (0.064325)\n",
      "logistic sgd 500 0.1 29 (150,): Macro 0.730437 (0.086566)\n",
      "Testing 968/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic sgd 500 0.1 29 (200,): Weighted 0.839680 (0.064420)\n",
      "logistic sgd 500 0.1 29 (200,): Macro 0.737519 (0.087102)\n",
      "Testing 969/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic sgd 500 0.1 42 (50,): Weighted 0.832396 (0.064016)\n",
      "logistic sgd 500 0.1 42 (50,): Macro 0.727027 (0.086583)\n",
      "Testing 970/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic sgd 500 0.1 42 (100,): Weighted 0.835663 (0.065220)\n",
      "logistic sgd 500 0.1 42 (100,): Macro 0.728448 (0.089984)\n",
      "Testing 971/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic sgd 500 0.1 42 (150,): Weighted 0.845790 (0.063820)\n",
      "logistic sgd 500 0.1 42 (150,): Macro 0.745288 (0.088388)\n",
      "Testing 972/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic sgd 500 0.1 42 (200,): Weighted 0.836765 (0.064603)\n",
      "logistic sgd 500 0.1 42 (200,): Macro 0.732153 (0.088175)\n",
      "Testing 973/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic sgd 500 0.1 76 (50,): Weighted 0.835663 (0.065220)\n",
      "logistic sgd 500 0.1 76 (50,): Macro 0.728448 (0.089984)\n",
      "Testing 974/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic sgd 500 0.1 76 (100,): Weighted 0.839680 (0.064420)\n",
      "logistic sgd 500 0.1 76 (100,): Macro 0.737519 (0.087102)\n",
      "Testing 975/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic sgd 500 0.1 76 (150,): Weighted 0.841004 (0.062720)\n",
      "logistic sgd 500 0.1 76 (150,): Macro 0.738188 (0.086177)\n",
      "Testing 976/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic sgd 500 0.1 76 (200,): Weighted 0.839680 (0.064420)\n",
      "logistic sgd 500 0.1 76 (200,): Macro 0.737519 (0.087102)\n",
      "Testing 977/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic sgd 500 0.1 112 (50,): Weighted 0.820818 (0.061339)\n",
      "logistic sgd 500 0.1 112 (50,): Macro 0.704717 (0.072301)\n",
      "Testing 978/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic sgd 500 0.1 112 (100,): Weighted 0.841004 (0.062720)\n",
      "logistic sgd 500 0.1 112 (100,): Macro 0.738188 (0.086177)\n",
      "Testing 979/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic sgd 500 0.1 112 (150,): Weighted 0.839680 (0.064420)\n",
      "logistic sgd 500 0.1 112 (150,): Macro 0.737519 (0.087102)\n",
      "Testing 980/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic sgd 500 0.1 112 (200,): Weighted 0.834869 (0.061611)\n",
      "logistic sgd 500 0.1 112 (200,): Macro 0.728647 (0.082804)\n",
      "Testing 981/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic sgd 500 0.01 17 (50,): Weighted 0.844185 (0.063174)\n",
      "logistic sgd 500 0.01 17 (50,): Macro 0.745049 (0.084795)\n",
      "Testing 982/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic sgd 500 0.01 17 (100,): Weighted 0.841004 (0.062720)\n",
      "logistic sgd 500 0.01 17 (100,): Macro 0.738188 (0.086177)\n",
      "Testing 983/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic sgd 500 0.01 17 (150,): Weighted 0.839680 (0.064420)\n",
      "logistic sgd 500 0.01 17 (150,): Macro 0.737519 (0.087102)\n",
      "Testing 984/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic sgd 500 0.01 17 (200,): Weighted 0.834713 (0.064325)\n",
      "logistic sgd 500 0.01 17 (200,): Macro 0.730437 (0.086566)\n",
      "Testing 985/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic sgd 500 0.01 29 (50,): Weighted 0.834339 (0.066750)\n",
      "logistic sgd 500 0.01 29 (50,): Macro 0.727779 (0.090798)\n",
      "Testing 986/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic sgd 500 0.01 29 (100,): Weighted 0.831554 (0.067942)\n",
      "logistic sgd 500 0.01 29 (100,): Macro 0.722780 (0.093537)\n",
      "Testing 987/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic sgd 500 0.01 29 (150,): Weighted 0.834713 (0.064325)\n",
      "logistic sgd 500 0.01 29 (150,): Macro 0.730437 (0.086566)\n",
      "Testing 988/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic sgd 500 0.01 29 (200,): Weighted 0.839680 (0.064420)\n",
      "logistic sgd 500 0.01 29 (200,): Macro 0.737519 (0.087102)\n",
      "Testing 989/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic sgd 500 0.01 42 (50,): Weighted 0.832396 (0.064016)\n",
      "logistic sgd 500 0.01 42 (50,): Macro 0.727027 (0.086583)\n",
      "Testing 990/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic sgd 500 0.01 42 (100,): Weighted 0.835663 (0.065220)\n",
      "logistic sgd 500 0.01 42 (100,): Macro 0.728448 (0.089984)\n",
      "Testing 991/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic sgd 500 0.01 42 (150,): Weighted 0.845790 (0.063820)\n",
      "logistic sgd 500 0.01 42 (150,): Macro 0.745288 (0.088388)\n",
      "Testing 992/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic sgd 500 0.01 42 (200,): Weighted 0.836765 (0.064603)\n",
      "logistic sgd 500 0.01 42 (200,): Macro 0.732153 (0.088175)\n",
      "Testing 993/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic sgd 500 0.01 76 (50,): Weighted 0.835663 (0.065220)\n",
      "logistic sgd 500 0.01 76 (50,): Macro 0.728448 (0.089984)\n",
      "Testing 994/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic sgd 500 0.01 76 (100,): Weighted 0.839680 (0.064420)\n",
      "logistic sgd 500 0.01 76 (100,): Macro 0.737519 (0.087102)\n",
      "Testing 995/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic sgd 500 0.01 76 (150,): Weighted 0.841004 (0.062720)\n",
      "logistic sgd 500 0.01 76 (150,): Macro 0.738188 (0.086177)\n",
      "Testing 996/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic sgd 500 0.01 76 (200,): Weighted 0.839680 (0.064420)\n",
      "logistic sgd 500 0.01 76 (200,): Macro 0.737519 (0.087102)\n",
      "Testing 997/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic sgd 500 0.01 112 (50,): Weighted 0.820818 (0.061339)\n",
      "logistic sgd 500 0.01 112 (50,): Macro 0.704717 (0.072301)\n",
      "Testing 998/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic sgd 500 0.01 112 (100,): Weighted 0.841004 (0.062720)\n",
      "logistic sgd 500 0.01 112 (100,): Macro 0.738188 (0.086177)\n",
      "Testing 999/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic sgd 500 0.01 112 (150,): Weighted 0.839680 (0.064420)\n",
      "logistic sgd 500 0.01 112 (150,): Macro 0.737519 (0.087102)\n",
      "Testing 1000/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic sgd 500 0.01 112 (200,): Weighted 0.834869 (0.061611)\n",
      "logistic sgd 500 0.01 112 (200,): Macro 0.728647 (0.082804)\n",
      "Testing 1001/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic sgd 500 0.001 17 (50,): Weighted 0.844185 (0.063174)\n",
      "logistic sgd 500 0.001 17 (50,): Macro 0.745049 (0.084795)\n",
      "Testing 1002/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic sgd 500 0.001 17 (100,): Weighted 0.841004 (0.062720)\n",
      "logistic sgd 500 0.001 17 (100,): Macro 0.738188 (0.086177)\n",
      "Testing 1003/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic sgd 500 0.001 17 (150,): Weighted 0.839680 (0.064420)\n",
      "logistic sgd 500 0.001 17 (150,): Macro 0.737519 (0.087102)\n",
      "Testing 1004/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic sgd 500 0.001 17 (200,): Weighted 0.834713 (0.064325)\n",
      "logistic sgd 500 0.001 17 (200,): Macro 0.730437 (0.086566)\n",
      "Testing 1005/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic sgd 500 0.001 29 (50,): Weighted 0.834339 (0.066750)\n",
      "logistic sgd 500 0.001 29 (50,): Macro 0.727779 (0.090798)\n",
      "Testing 1006/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic sgd 500 0.001 29 (100,): Weighted 0.831554 (0.067942)\n",
      "logistic sgd 500 0.001 29 (100,): Macro 0.722780 (0.093537)\n",
      "Testing 1007/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic sgd 500 0.001 29 (150,): Weighted 0.834713 (0.064325)\n",
      "logistic sgd 500 0.001 29 (150,): Macro 0.730437 (0.086566)\n",
      "Testing 1008/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic sgd 500 0.001 29 (200,): Weighted 0.839680 (0.064420)\n",
      "logistic sgd 500 0.001 29 (200,): Macro 0.737519 (0.087102)\n",
      "Testing 1009/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic sgd 500 0.001 42 (50,): Weighted 0.832396 (0.064016)\n",
      "logistic sgd 500 0.001 42 (50,): Macro 0.727027 (0.086583)\n",
      "Testing 1010/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic sgd 500 0.001 42 (100,): Weighted 0.835663 (0.065220)\n",
      "logistic sgd 500 0.001 42 (100,): Macro 0.728448 (0.089984)\n",
      "Testing 1011/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic sgd 500 0.001 42 (150,): Weighted 0.845790 (0.063820)\n",
      "logistic sgd 500 0.001 42 (150,): Macro 0.745288 (0.088388)\n",
      "Testing 1012/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic sgd 500 0.001 42 (200,): Weighted 0.836765 (0.064603)\n",
      "logistic sgd 500 0.001 42 (200,): Macro 0.732153 (0.088175)\n",
      "Testing 1013/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic sgd 500 0.001 76 (50,): Weighted 0.835663 (0.065220)\n",
      "logistic sgd 500 0.001 76 (50,): Macro 0.728448 (0.089984)\n",
      "Testing 1014/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic sgd 500 0.001 76 (100,): Weighted 0.839680 (0.064420)\n",
      "logistic sgd 500 0.001 76 (100,): Macro 0.737519 (0.087102)\n",
      "Testing 1015/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic sgd 500 0.001 76 (150,): Weighted 0.841004 (0.062720)\n",
      "logistic sgd 500 0.001 76 (150,): Macro 0.738188 (0.086177)\n",
      "Testing 1016/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic sgd 500 0.001 76 (200,): Weighted 0.839680 (0.064420)\n",
      "logistic sgd 500 0.001 76 (200,): Macro 0.737519 (0.087102)\n",
      "Testing 1017/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic sgd 500 0.001 112 (50,): Weighted 0.820818 (0.061339)\n",
      "logistic sgd 500 0.001 112 (50,): Macro 0.704717 (0.072301)\n",
      "Testing 1018/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic sgd 500 0.001 112 (100,): Weighted 0.841004 (0.062720)\n",
      "logistic sgd 500 0.001 112 (100,): Macro 0.738188 (0.086177)\n",
      "Testing 1019/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic sgd 500 0.001 112 (150,): Weighted 0.839680 (0.064420)\n",
      "logistic sgd 500 0.001 112 (150,): Macro 0.737519 (0.087102)\n",
      "Testing 1020/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic sgd 500 0.001 112 (200,): Weighted 0.834869 (0.061611)\n",
      "logistic sgd 500 0.001 112 (200,): Macro 0.728647 (0.082804)\n",
      "Testing 1021/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic sgd 500 0.0001 17 (50,): Weighted 0.844185 (0.063174)\n",
      "logistic sgd 500 0.0001 17 (50,): Macro 0.745049 (0.084795)\n",
      "Testing 1022/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic sgd 500 0.0001 17 (100,): Weighted 0.841004 (0.062720)\n",
      "logistic sgd 500 0.0001 17 (100,): Macro 0.738188 (0.086177)\n",
      "Testing 1023/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic sgd 500 0.0001 17 (150,): Weighted 0.839680 (0.064420)\n",
      "logistic sgd 500 0.0001 17 (150,): Macro 0.737519 (0.087102)\n",
      "Testing 1024/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic sgd 500 0.0001 17 (200,): Weighted 0.834713 (0.064325)\n",
      "logistic sgd 500 0.0001 17 (200,): Macro 0.730437 (0.086566)\n",
      "Testing 1025/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic sgd 500 0.0001 29 (50,): Weighted 0.834339 (0.066750)\n",
      "logistic sgd 500 0.0001 29 (50,): Macro 0.727779 (0.090798)\n",
      "Testing 1026/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic sgd 500 0.0001 29 (100,): Weighted 0.831554 (0.067942)\n",
      "logistic sgd 500 0.0001 29 (100,): Macro 0.722780 (0.093537)\n",
      "Testing 1027/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic sgd 500 0.0001 29 (150,): Weighted 0.834713 (0.064325)\n",
      "logistic sgd 500 0.0001 29 (150,): Macro 0.730437 (0.086566)\n",
      "Testing 1028/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic sgd 500 0.0001 29 (200,): Weighted 0.839680 (0.064420)\n",
      "logistic sgd 500 0.0001 29 (200,): Macro 0.737519 (0.087102)\n",
      "Testing 1029/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic sgd 500 0.0001 42 (50,): Weighted 0.832396 (0.064016)\n",
      "logistic sgd 500 0.0001 42 (50,): Macro 0.727027 (0.086583)\n",
      "Testing 1030/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic sgd 500 0.0001 42 (100,): Weighted 0.835663 (0.065220)\n",
      "logistic sgd 500 0.0001 42 (100,): Macro 0.728448 (0.089984)\n",
      "Testing 1031/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic sgd 500 0.0001 42 (150,): Weighted 0.845790 (0.063820)\n",
      "logistic sgd 500 0.0001 42 (150,): Macro 0.745288 (0.088388)\n",
      "Testing 1032/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic sgd 500 0.0001 42 (200,): Weighted 0.836765 (0.064603)\n",
      "logistic sgd 500 0.0001 42 (200,): Macro 0.732153 (0.088175)\n",
      "Testing 1033/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic sgd 500 0.0001 76 (50,): Weighted 0.835663 (0.065220)\n",
      "logistic sgd 500 0.0001 76 (50,): Macro 0.728448 (0.089984)\n",
      "Testing 1034/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic sgd 500 0.0001 76 (100,): Weighted 0.839680 (0.064420)\n",
      "logistic sgd 500 0.0001 76 (100,): Macro 0.737519 (0.087102)\n",
      "Testing 1035/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic sgd 500 0.0001 76 (150,): Weighted 0.841004 (0.062720)\n",
      "logistic sgd 500 0.0001 76 (150,): Macro 0.738188 (0.086177)\n",
      "Testing 1036/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic sgd 500 0.0001 76 (200,): Weighted 0.839680 (0.064420)\n",
      "logistic sgd 500 0.0001 76 (200,): Macro 0.737519 (0.087102)\n",
      "Testing 1037/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic sgd 500 0.0001 112 (50,): Weighted 0.820818 (0.061339)\n",
      "logistic sgd 500 0.0001 112 (50,): Macro 0.704717 (0.072301)\n",
      "Testing 1038/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic sgd 500 0.0001 112 (100,): Weighted 0.841004 (0.062720)\n",
      "logistic sgd 500 0.0001 112 (100,): Macro 0.738188 (0.086177)\n",
      "Testing 1039/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic sgd 500 0.0001 112 (150,): Weighted 0.839680 (0.064420)\n",
      "logistic sgd 500 0.0001 112 (150,): Macro 0.737519 (0.087102)\n",
      "Testing 1040/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic sgd 500 0.0001 112 (200,): Weighted 0.834869 (0.061611)\n",
      "logistic sgd 500 0.0001 112 (200,): Macro 0.728647 (0.082804)\n",
      "Testing 1041/2880\n",
      "logistic sgd 1000 0.1 17 (50,): Weighted 0.835441 (0.066169)\n",
      "logistic sgd 1000 0.1 17 (50,): Macro 0.731484 (0.089034)\n",
      "Testing 1042/2880\n",
      "logistic sgd 1000 0.1 17 (100,): Weighted 0.836037 (0.062728)\n",
      "logistic sgd 1000 0.1 17 (100,): Macro 0.731106 (0.085690)\n",
      "Testing 1043/2880\n",
      "logistic sgd 1000 0.1 17 (150,): Weighted 0.845790 (0.063820)\n",
      "logistic sgd 1000 0.1 17 (150,): Macro 0.745288 (0.088388)\n",
      "Testing 1044/2880\n",
      "logistic sgd 1000 0.1 17 (200,): Weighted 0.844466 (0.065587)\n",
      "logistic sgd 1000 0.1 17 (200,): Macro 0.744619 (0.089343)\n",
      "Testing 1045/2880\n",
      "logistic sgd 1000 0.1 29 (50,): Weighted 0.834339 (0.066750)\n",
      "logistic sgd 1000 0.1 29 (50,): Macro 0.727779 (0.090798)\n",
      "Testing 1046/2880\n",
      "logistic sgd 1000 0.1 29 (100,): Weighted 0.832708 (0.067112)\n",
      "logistic sgd 1000 0.1 29 (100,): Macro 0.722858 (0.093482)\n",
      "Testing 1047/2880\n",
      "logistic sgd 1000 0.1 29 (150,): Weighted 0.844466 (0.065587)\n",
      "logistic sgd 1000 0.1 29 (150,): Macro 0.744619 (0.089343)\n",
      "Testing 1048/2880\n",
      "logistic sgd 1000 0.1 29 (200,): Weighted 0.839836 (0.061697)\n",
      "logistic sgd 1000 0.1 29 (200,): Macro 0.735730 (0.083516)\n",
      "Testing 1049/2880\n",
      "logistic sgd 1000 0.1 42 (50,): Weighted 0.831799 (0.064284)\n",
      "logistic sgd 1000 0.1 42 (50,): Macro 0.725070 (0.087211)\n",
      "Testing 1050/2880\n",
      "logistic sgd 1000 0.1 42 (100,): Weighted 0.841004 (0.062720)\n",
      "logistic sgd 1000 0.1 42 (100,): Macro 0.738188 (0.086177)\n",
      "Testing 1051/2880\n",
      "logistic sgd 1000 0.1 42 (150,): Weighted 0.845790 (0.063820)\n",
      "logistic sgd 1000 0.1 42 (150,): Macro 0.745288 (0.088388)\n",
      "Testing 1052/2880\n",
      "logistic sgd 1000 0.1 42 (200,): Weighted 0.836765 (0.064603)\n",
      "logistic sgd 1000 0.1 42 (200,): Macro 0.732153 (0.088175)\n",
      "Testing 1053/2880\n",
      "logistic sgd 1000 0.1 76 (50,): Weighted 0.835663 (0.065220)\n",
      "logistic sgd 1000 0.1 76 (50,): Macro 0.728448 (0.089984)\n",
      "Testing 1054/2880\n",
      "logistic sgd 1000 0.1 76 (100,): Weighted 0.845790 (0.063820)\n",
      "logistic sgd 1000 0.1 76 (100,): Macro 0.745288 (0.088388)\n",
      "Testing 1055/2880\n",
      "logistic sgd 1000 0.1 76 (150,): Weighted 0.836624 (0.056273)\n",
      "logistic sgd 1000 0.1 76 (150,): Macro 0.729971 (0.074980)\n",
      "Testing 1056/2880\n",
      "logistic sgd 1000 0.1 76 (200,): Weighted 0.833074 (0.051523)\n",
      "logistic sgd 1000 0.1 76 (200,): Macro 0.719724 (0.061281)\n",
      "Testing 1057/2880\n",
      "logistic sgd 1000 0.1 112 (50,): Weighted 0.828680 (0.056276)\n",
      "logistic sgd 1000 0.1 112 (50,): Macro 0.715479 (0.067613)\n",
      "Testing 1058/2880\n",
      "logistic sgd 1000 0.1 112 (100,): Weighted 0.841004 (0.062720)\n",
      "logistic sgd 1000 0.1 112 (100,): Macro 0.738188 (0.086177)\n",
      "Testing 1059/2880\n",
      "logistic sgd 1000 0.1 112 (150,): Weighted 0.839680 (0.064420)\n",
      "logistic sgd 1000 0.1 112 (150,): Macro 0.737519 (0.087102)\n",
      "Testing 1060/2880\n",
      "logistic sgd 1000 0.1 112 (200,): Weighted 0.831509 (0.065335)\n",
      "logistic sgd 1000 0.1 112 (200,): Macro 0.724139 (0.088117)\n",
      "Testing 1061/2880\n",
      "logistic sgd 1000 0.01 17 (50,): Weighted 0.835441 (0.066169)\n",
      "logistic sgd 1000 0.01 17 (50,): Macro 0.731484 (0.089034)\n",
      "Testing 1062/2880\n",
      "logistic sgd 1000 0.01 17 (100,): Weighted 0.827952 (0.054004)\n",
      "logistic sgd 1000 0.01 17 (100,): Macro 0.714432 (0.064067)\n",
      "Testing 1063/2880\n",
      "logistic sgd 1000 0.01 17 (150,): Weighted 0.845790 (0.063820)\n",
      "logistic sgd 1000 0.01 17 (150,): Macro 0.745288 (0.088388)\n",
      "Testing 1064/2880\n",
      "logistic sgd 1000 0.01 17 (200,): Weighted 0.844466 (0.065587)\n",
      "logistic sgd 1000 0.01 17 (200,): Macro 0.744619 (0.089343)\n",
      "Testing 1065/2880\n",
      "logistic sgd 1000 0.01 29 (50,): Weighted 0.834339 (0.066750)\n",
      "logistic sgd 1000 0.01 29 (50,): Macro 0.727779 (0.090798)\n",
      "Testing 1066/2880\n",
      "logistic sgd 1000 0.01 29 (100,): Weighted 0.832708 (0.067112)\n",
      "logistic sgd 1000 0.01 29 (100,): Macro 0.722858 (0.093482)\n",
      "Testing 1067/2880\n",
      "logistic sgd 1000 0.01 29 (150,): Weighted 0.844466 (0.065587)\n",
      "logistic sgd 1000 0.01 29 (150,): Macro 0.744619 (0.089343)\n",
      "Testing 1068/2880\n",
      "logistic sgd 1000 0.01 29 (200,): Weighted 0.839836 (0.061697)\n",
      "logistic sgd 1000 0.01 29 (200,): Macro 0.735730 (0.083516)\n",
      "Testing 1069/2880\n",
      "logistic sgd 1000 0.01 42 (50,): Weighted 0.831799 (0.064284)\n",
      "logistic sgd 1000 0.01 42 (50,): Macro 0.725070 (0.087211)\n",
      "Testing 1070/2880\n",
      "logistic sgd 1000 0.01 42 (100,): Weighted 0.841004 (0.062720)\n",
      "logistic sgd 1000 0.01 42 (100,): Macro 0.738188 (0.086177)\n",
      "Testing 1071/2880\n",
      "logistic sgd 1000 0.01 42 (150,): Weighted 0.845790 (0.063820)\n",
      "logistic sgd 1000 0.01 42 (150,): Macro 0.745288 (0.088388)\n",
      "Testing 1072/2880\n",
      "logistic sgd 1000 0.01 42 (200,): Weighted 0.836765 (0.064603)\n",
      "logistic sgd 1000 0.01 42 (200,): Macro 0.732153 (0.088175)\n",
      "Testing 1073/2880\n",
      "logistic sgd 1000 0.01 76 (50,): Weighted 0.835663 (0.065220)\n",
      "logistic sgd 1000 0.01 76 (50,): Macro 0.728448 (0.089984)\n",
      "Testing 1074/2880\n",
      "logistic sgd 1000 0.01 76 (100,): Weighted 0.845790 (0.063820)\n",
      "logistic sgd 1000 0.01 76 (100,): Macro 0.745288 (0.088388)\n",
      "Testing 1075/2880\n",
      "logistic sgd 1000 0.01 76 (150,): Weighted 0.841004 (0.062720)\n",
      "logistic sgd 1000 0.01 76 (150,): Macro 0.738188 (0.086177)\n",
      "Testing 1076/2880\n",
      "logistic sgd 1000 0.01 76 (200,): Weighted 0.839836 (0.061697)\n",
      "logistic sgd 1000 0.01 76 (200,): Macro 0.735730 (0.083516)\n",
      "Testing 1077/2880\n",
      "logistic sgd 1000 0.01 112 (50,): Weighted 0.828680 (0.056276)\n",
      "logistic sgd 1000 0.01 112 (50,): Macro 0.715479 (0.067613)\n",
      "Testing 1078/2880\n",
      "logistic sgd 1000 0.01 112 (100,): Weighted 0.841004 (0.062720)\n",
      "logistic sgd 1000 0.01 112 (100,): Macro 0.738188 (0.086177)\n",
      "Testing 1079/2880\n",
      "logistic sgd 1000 0.01 112 (150,): Weighted 0.840670 (0.064125)\n",
      "logistic sgd 1000 0.01 112 (150,): Macro 0.737040 (0.087211)\n",
      "Testing 1080/2880\n",
      "logistic sgd 1000 0.01 112 (200,): Weighted 0.831509 (0.065335)\n",
      "logistic sgd 1000 0.01 112 (200,): Macro 0.724139 (0.088117)\n",
      "Testing 1081/2880\n",
      "logistic sgd 1000 0.001 17 (50,): Weighted 0.835441 (0.066169)\n",
      "logistic sgd 1000 0.001 17 (50,): Macro 0.731484 (0.089034)\n",
      "Testing 1082/2880\n",
      "logistic sgd 1000 0.001 17 (100,): Weighted 0.827952 (0.054004)\n",
      "logistic sgd 1000 0.001 17 (100,): Macro 0.714432 (0.064067)\n",
      "Testing 1083/2880\n",
      "logistic sgd 1000 0.001 17 (150,): Weighted 0.845790 (0.063820)\n",
      "logistic sgd 1000 0.001 17 (150,): Macro 0.745288 (0.088388)\n",
      "Testing 1084/2880\n",
      "logistic sgd 1000 0.001 17 (200,): Weighted 0.844466 (0.065587)\n",
      "logistic sgd 1000 0.001 17 (200,): Macro 0.744619 (0.089343)\n",
      "Testing 1085/2880\n",
      "logistic sgd 1000 0.001 29 (50,): Weighted 0.834339 (0.066750)\n",
      "logistic sgd 1000 0.001 29 (50,): Macro 0.727779 (0.090798)\n",
      "Testing 1086/2880\n",
      "logistic sgd 1000 0.001 29 (100,): Weighted 0.832708 (0.067112)\n",
      "logistic sgd 1000 0.001 29 (100,): Macro 0.722858 (0.093482)\n",
      "Testing 1087/2880\n",
      "logistic sgd 1000 0.001 29 (150,): Weighted 0.844466 (0.065587)\n",
      "logistic sgd 1000 0.001 29 (150,): Macro 0.744619 (0.089343)\n",
      "Testing 1088/2880\n",
      "logistic sgd 1000 0.001 29 (200,): Weighted 0.839836 (0.061697)\n",
      "logistic sgd 1000 0.001 29 (200,): Macro 0.735730 (0.083516)\n",
      "Testing 1089/2880\n",
      "logistic sgd 1000 0.001 42 (50,): Weighted 0.831799 (0.064284)\n",
      "logistic sgd 1000 0.001 42 (50,): Macro 0.725070 (0.087211)\n",
      "Testing 1090/2880\n",
      "logistic sgd 1000 0.001 42 (100,): Weighted 0.841004 (0.062720)\n",
      "logistic sgd 1000 0.001 42 (100,): Macro 0.738188 (0.086177)\n",
      "Testing 1091/2880\n",
      "logistic sgd 1000 0.001 42 (150,): Weighted 0.840449 (0.066662)\n",
      "logistic sgd 1000 0.001 42 (150,): Macro 0.735547 (0.092851)\n",
      "Testing 1092/2880\n",
      "logistic sgd 1000 0.001 42 (200,): Weighted 0.836765 (0.064603)\n",
      "logistic sgd 1000 0.001 42 (200,): Macro 0.732153 (0.088175)\n",
      "Testing 1093/2880\n",
      "logistic sgd 1000 0.001 76 (50,): Weighted 0.835663 (0.065220)\n",
      "logistic sgd 1000 0.001 76 (50,): Macro 0.728448 (0.089984)\n",
      "Testing 1094/2880\n",
      "logistic sgd 1000 0.001 76 (100,): Weighted 0.845790 (0.063820)\n",
      "logistic sgd 1000 0.001 76 (100,): Macro 0.745288 (0.088388)\n",
      "Testing 1095/2880\n",
      "logistic sgd 1000 0.001 76 (150,): Weighted 0.841004 (0.062720)\n",
      "logistic sgd 1000 0.001 76 (150,): Macro 0.738188 (0.086177)\n",
      "Testing 1096/2880\n",
      "logistic sgd 1000 0.001 76 (200,): Weighted 0.839836 (0.061697)\n",
      "logistic sgd 1000 0.001 76 (200,): Macro 0.735730 (0.083516)\n",
      "Testing 1097/2880\n",
      "logistic sgd 1000 0.001 112 (50,): Weighted 0.828680 (0.056276)\n",
      "logistic sgd 1000 0.001 112 (50,): Macro 0.715479 (0.067613)\n",
      "Testing 1098/2880\n",
      "logistic sgd 1000 0.001 112 (100,): Weighted 0.841004 (0.062720)\n",
      "logistic sgd 1000 0.001 112 (100,): Macro 0.738188 (0.086177)\n",
      "Testing 1099/2880\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic sgd 1000 0.001 112 (150,): Weighted 0.835704 (0.064107)\n",
      "logistic sgd 1000 0.001 112 (150,): Macro 0.729958 (0.086636)\n",
      "Testing 1100/2880\n",
      "logistic sgd 1000 0.001 112 (200,): Weighted 0.831509 (0.065335)\n",
      "logistic sgd 1000 0.001 112 (200,): Macro 0.724139 (0.088117)\n",
      "Testing 1101/2880\n",
      "logistic sgd 1000 0.0001 17 (50,): Weighted 0.835441 (0.066169)\n",
      "logistic sgd 1000 0.0001 17 (50,): Macro 0.731484 (0.089034)\n",
      "Testing 1102/2880\n",
      "logistic sgd 1000 0.0001 17 (100,): Weighted 0.827952 (0.054004)\n",
      "logistic sgd 1000 0.0001 17 (100,): Macro 0.714432 (0.064067)\n",
      "Testing 1103/2880\n",
      "logistic sgd 1000 0.0001 17 (150,): Weighted 0.845790 (0.063820)\n",
      "logistic sgd 1000 0.0001 17 (150,): Macro 0.745288 (0.088388)\n",
      "Testing 1104/2880\n",
      "logistic sgd 1000 0.0001 17 (200,): Weighted 0.844466 (0.065587)\n",
      "logistic sgd 1000 0.0001 17 (200,): Macro 0.744619 (0.089343)\n",
      "Testing 1105/2880\n",
      "logistic sgd 1000 0.0001 29 (50,): Weighted 0.834339 (0.066750)\n",
      "logistic sgd 1000 0.0001 29 (50,): Macro 0.727779 (0.090798)\n",
      "Testing 1106/2880\n",
      "logistic sgd 1000 0.0001 29 (100,): Weighted 0.832708 (0.067112)\n",
      "logistic sgd 1000 0.0001 29 (100,): Macro 0.722858 (0.093482)\n",
      "Testing 1107/2880\n",
      "logistic sgd 1000 0.0001 29 (150,): Weighted 0.844466 (0.065587)\n",
      "logistic sgd 1000 0.0001 29 (150,): Macro 0.744619 (0.089343)\n",
      "Testing 1108/2880\n",
      "logistic sgd 1000 0.0001 29 (200,): Weighted 0.839836 (0.061697)\n",
      "logistic sgd 1000 0.0001 29 (200,): Macro 0.735730 (0.083516)\n",
      "Testing 1109/2880\n",
      "logistic sgd 1000 0.0001 42 (50,): Weighted 0.831799 (0.064284)\n",
      "logistic sgd 1000 0.0001 42 (50,): Macro 0.725070 (0.087211)\n",
      "Testing 1110/2880\n",
      "logistic sgd 1000 0.0001 42 (100,): Weighted 0.841004 (0.062720)\n",
      "logistic sgd 1000 0.0001 42 (100,): Macro 0.738188 (0.086177)\n",
      "Testing 1111/2880\n",
      "logistic sgd 1000 0.0001 42 (150,): Weighted 0.840449 (0.066662)\n",
      "logistic sgd 1000 0.0001 42 (150,): Macro 0.735547 (0.092851)\n",
      "Testing 1112/2880\n",
      "logistic sgd 1000 0.0001 42 (200,): Weighted 0.836765 (0.064603)\n",
      "logistic sgd 1000 0.0001 42 (200,): Macro 0.732153 (0.088175)\n",
      "Testing 1113/2880\n",
      "logistic sgd 1000 0.0001 76 (50,): Weighted 0.835663 (0.065220)\n",
      "logistic sgd 1000 0.0001 76 (50,): Macro 0.728448 (0.089984)\n",
      "Testing 1114/2880\n",
      "logistic sgd 1000 0.0001 76 (100,): Weighted 0.845790 (0.063820)\n",
      "logistic sgd 1000 0.0001 76 (100,): Macro 0.745288 (0.088388)\n",
      "Testing 1115/2880\n",
      "logistic sgd 1000 0.0001 76 (150,): Weighted 0.841004 (0.062720)\n",
      "logistic sgd 1000 0.0001 76 (150,): Macro 0.738188 (0.086177)\n",
      "Testing 1116/2880\n",
      "logistic sgd 1000 0.0001 76 (200,): Weighted 0.839836 (0.061697)\n",
      "logistic sgd 1000 0.0001 76 (200,): Macro 0.735730 (0.083516)\n",
      "Testing 1117/2880\n",
      "logistic sgd 1000 0.0001 112 (50,): Weighted 0.828680 (0.056276)\n",
      "logistic sgd 1000 0.0001 112 (50,): Macro 0.715479 (0.067613)\n",
      "Testing 1118/2880\n",
      "logistic sgd 1000 0.0001 112 (100,): Weighted 0.841004 (0.062720)\n",
      "logistic sgd 1000 0.0001 112 (100,): Macro 0.738188 (0.086177)\n",
      "Testing 1119/2880\n",
      "logistic sgd 1000 0.0001 112 (150,): Weighted 0.835704 (0.064107)\n",
      "logistic sgd 1000 0.0001 112 (150,): Macro 0.729958 (0.086636)\n",
      "Testing 1120/2880\n",
      "logistic sgd 1000 0.0001 112 (200,): Weighted 0.831509 (0.065335)\n",
      "logistic sgd 1000 0.0001 112 (200,): Macro 0.724139 (0.088117)\n",
      "Testing 1121/2880\n",
      "logistic sgd 1500 0.1 17 (50,): Weighted 0.835441 (0.066169)\n",
      "logistic sgd 1500 0.1 17 (50,): Macro 0.731484 (0.089034)\n",
      "Testing 1122/2880\n",
      "logistic sgd 1500 0.1 17 (100,): Weighted 0.836037 (0.062728)\n",
      "logistic sgd 1500 0.1 17 (100,): Macro 0.731106 (0.085690)\n",
      "Testing 1123/2880\n",
      "logistic sgd 1500 0.1 17 (150,): Weighted 0.845790 (0.063820)\n",
      "logistic sgd 1500 0.1 17 (150,): Macro 0.745288 (0.088388)\n",
      "Testing 1124/2880\n",
      "logistic sgd 1500 0.1 17 (200,): Weighted 0.844466 (0.065587)\n",
      "logistic sgd 1500 0.1 17 (200,): Macro 0.744619 (0.089343)\n",
      "Testing 1125/2880\n",
      "logistic sgd 1500 0.1 29 (50,): Weighted 0.834339 (0.066750)\n",
      "logistic sgd 1500 0.1 29 (50,): Macro 0.727779 (0.090798)\n",
      "Testing 1126/2880\n",
      "logistic sgd 1500 0.1 29 (100,): Weighted 0.832708 (0.067112)\n",
      "logistic sgd 1500 0.1 29 (100,): Macro 0.722858 (0.093482)\n",
      "Testing 1127/2880\n",
      "logistic sgd 1500 0.1 29 (150,): Weighted 0.844466 (0.065587)\n",
      "logistic sgd 1500 0.1 29 (150,): Macro 0.744619 (0.089343)\n",
      "Testing 1128/2880\n",
      "logistic sgd 1500 0.1 29 (200,): Weighted 0.839836 (0.061697)\n",
      "logistic sgd 1500 0.1 29 (200,): Macro 0.735730 (0.083516)\n",
      "Testing 1129/2880\n",
      "logistic sgd 1500 0.1 42 (50,): Weighted 0.831799 (0.064284)\n",
      "logistic sgd 1500 0.1 42 (50,): Macro 0.725070 (0.087211)\n",
      "Testing 1130/2880\n",
      "logistic sgd 1500 0.1 42 (100,): Weighted 0.841004 (0.062720)\n",
      "logistic sgd 1500 0.1 42 (100,): Macro 0.738188 (0.086177)\n",
      "Testing 1131/2880\n",
      "logistic sgd 1500 0.1 42 (150,): Weighted 0.845790 (0.063820)\n",
      "logistic sgd 1500 0.1 42 (150,): Macro 0.745288 (0.088388)\n",
      "Testing 1132/2880\n",
      "logistic sgd 1500 0.1 42 (200,): Weighted 0.836765 (0.064603)\n",
      "logistic sgd 1500 0.1 42 (200,): Macro 0.732153 (0.088175)\n",
      "Testing 1133/2880\n",
      "logistic sgd 1500 0.1 76 (50,): Weighted 0.835663 (0.065220)\n",
      "logistic sgd 1500 0.1 76 (50,): Macro 0.728448 (0.089984)\n",
      "Testing 1134/2880\n",
      "logistic sgd 1500 0.1 76 (100,): Weighted 0.845790 (0.063820)\n",
      "logistic sgd 1500 0.1 76 (100,): Macro 0.745288 (0.088388)\n",
      "Testing 1135/2880\n",
      "logistic sgd 1500 0.1 76 (150,): Weighted 0.836624 (0.056273)\n",
      "logistic sgd 1500 0.1 76 (150,): Macro 0.729971 (0.074980)\n",
      "Testing 1136/2880\n",
      "logistic sgd 1500 0.1 76 (200,): Weighted 0.833074 (0.051523)\n",
      "logistic sgd 1500 0.1 76 (200,): Macro 0.719724 (0.061281)\n",
      "Testing 1137/2880\n",
      "logistic sgd 1500 0.1 112 (50,): Weighted 0.828680 (0.056276)\n",
      "logistic sgd 1500 0.1 112 (50,): Macro 0.715479 (0.067613)\n",
      "Testing 1138/2880\n",
      "logistic sgd 1500 0.1 112 (100,): Weighted 0.841004 (0.062720)\n",
      "logistic sgd 1500 0.1 112 (100,): Macro 0.738188 (0.086177)\n",
      "Testing 1139/2880\n",
      "logistic sgd 1500 0.1 112 (150,): Weighted 0.839680 (0.064420)\n",
      "logistic sgd 1500 0.1 112 (150,): Macro 0.737519 (0.087102)\n",
      "Testing 1140/2880\n",
      "logistic sgd 1500 0.1 112 (200,): Weighted 0.831509 (0.065335)\n",
      "logistic sgd 1500 0.1 112 (200,): Macro 0.724139 (0.088117)\n",
      "Testing 1141/2880\n",
      "logistic sgd 1500 0.01 17 (50,): Weighted 0.835441 (0.066169)\n",
      "logistic sgd 1500 0.01 17 (50,): Macro 0.731484 (0.089034)\n",
      "Testing 1142/2880\n",
      "logistic sgd 1500 0.01 17 (100,): Weighted 0.827952 (0.054004)\n",
      "logistic sgd 1500 0.01 17 (100,): Macro 0.714432 (0.064067)\n",
      "Testing 1143/2880\n",
      "logistic sgd 1500 0.01 17 (150,): Weighted 0.845790 (0.063820)\n",
      "logistic sgd 1500 0.01 17 (150,): Macro 0.745288 (0.088388)\n",
      "Testing 1144/2880\n",
      "logistic sgd 1500 0.01 17 (200,): Weighted 0.844466 (0.065587)\n",
      "logistic sgd 1500 0.01 17 (200,): Macro 0.744619 (0.089343)\n",
      "Testing 1145/2880\n",
      "logistic sgd 1500 0.01 29 (50,): Weighted 0.834339 (0.066750)\n",
      "logistic sgd 1500 0.01 29 (50,): Macro 0.727779 (0.090798)\n",
      "Testing 1146/2880\n",
      "logistic sgd 1500 0.01 29 (100,): Weighted 0.832708 (0.067112)\n",
      "logistic sgd 1500 0.01 29 (100,): Macro 0.722858 (0.093482)\n",
      "Testing 1147/2880\n",
      "logistic sgd 1500 0.01 29 (150,): Weighted 0.844466 (0.065587)\n",
      "logistic sgd 1500 0.01 29 (150,): Macro 0.744619 (0.089343)\n",
      "Testing 1148/2880\n",
      "logistic sgd 1500 0.01 29 (200,): Weighted 0.839836 (0.061697)\n",
      "logistic sgd 1500 0.01 29 (200,): Macro 0.735730 (0.083516)\n",
      "Testing 1149/2880\n",
      "logistic sgd 1500 0.01 42 (50,): Weighted 0.831799 (0.064284)\n",
      "logistic sgd 1500 0.01 42 (50,): Macro 0.725070 (0.087211)\n",
      "Testing 1150/2880\n",
      "logistic sgd 1500 0.01 42 (100,): Weighted 0.841004 (0.062720)\n",
      "logistic sgd 1500 0.01 42 (100,): Macro 0.738188 (0.086177)\n",
      "Testing 1151/2880\n",
      "logistic sgd 1500 0.01 42 (150,): Weighted 0.845790 (0.063820)\n",
      "logistic sgd 1500 0.01 42 (150,): Macro 0.745288 (0.088388)\n",
      "Testing 1152/2880\n",
      "logistic sgd 1500 0.01 42 (200,): Weighted 0.836765 (0.064603)\n",
      "logistic sgd 1500 0.01 42 (200,): Macro 0.732153 (0.088175)\n",
      "Testing 1153/2880\n",
      "logistic sgd 1500 0.01 76 (50,): Weighted 0.835663 (0.065220)\n",
      "logistic sgd 1500 0.01 76 (50,): Macro 0.728448 (0.089984)\n",
      "Testing 1154/2880\n",
      "logistic sgd 1500 0.01 76 (100,): Weighted 0.845790 (0.063820)\n",
      "logistic sgd 1500 0.01 76 (100,): Macro 0.745288 (0.088388)\n",
      "Testing 1155/2880\n",
      "logistic sgd 1500 0.01 76 (150,): Weighted 0.841004 (0.062720)\n",
      "logistic sgd 1500 0.01 76 (150,): Macro 0.738188 (0.086177)\n",
      "Testing 1156/2880\n",
      "logistic sgd 1500 0.01 76 (200,): Weighted 0.839836 (0.061697)\n",
      "logistic sgd 1500 0.01 76 (200,): Macro 0.735730 (0.083516)\n",
      "Testing 1157/2880\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic sgd 1500 0.01 112 (50,): Weighted 0.828680 (0.056276)\n",
      "logistic sgd 1500 0.01 112 (50,): Macro 0.715479 (0.067613)\n",
      "Testing 1158/2880\n",
      "logistic sgd 1500 0.01 112 (100,): Weighted 0.841004 (0.062720)\n",
      "logistic sgd 1500 0.01 112 (100,): Macro 0.738188 (0.086177)\n",
      "Testing 1159/2880\n",
      "logistic sgd 1500 0.01 112 (150,): Weighted 0.840670 (0.064125)\n",
      "logistic sgd 1500 0.01 112 (150,): Macro 0.737040 (0.087211)\n",
      "Testing 1160/2880\n",
      "logistic sgd 1500 0.01 112 (200,): Weighted 0.831509 (0.065335)\n",
      "logistic sgd 1500 0.01 112 (200,): Macro 0.724139 (0.088117)\n",
      "Testing 1161/2880\n",
      "logistic sgd 1500 0.001 17 (50,): Weighted 0.835441 (0.066169)\n",
      "logistic sgd 1500 0.001 17 (50,): Macro 0.731484 (0.089034)\n",
      "Testing 1162/2880\n",
      "logistic sgd 1500 0.001 17 (100,): Weighted 0.827952 (0.054004)\n",
      "logistic sgd 1500 0.001 17 (100,): Macro 0.714432 (0.064067)\n",
      "Testing 1163/2880\n",
      "logistic sgd 1500 0.001 17 (150,): Weighted 0.845790 (0.063820)\n",
      "logistic sgd 1500 0.001 17 (150,): Macro 0.745288 (0.088388)\n",
      "Testing 1164/2880\n",
      "logistic sgd 1500 0.001 17 (200,): Weighted 0.844466 (0.065587)\n",
      "logistic sgd 1500 0.001 17 (200,): Macro 0.744619 (0.089343)\n",
      "Testing 1165/2880\n",
      "logistic sgd 1500 0.001 29 (50,): Weighted 0.834339 (0.066750)\n",
      "logistic sgd 1500 0.001 29 (50,): Macro 0.727779 (0.090798)\n",
      "Testing 1166/2880\n",
      "logistic sgd 1500 0.001 29 (100,): Weighted 0.832708 (0.067112)\n",
      "logistic sgd 1500 0.001 29 (100,): Macro 0.722858 (0.093482)\n",
      "Testing 1167/2880\n",
      "logistic sgd 1500 0.001 29 (150,): Weighted 0.844466 (0.065587)\n",
      "logistic sgd 1500 0.001 29 (150,): Macro 0.744619 (0.089343)\n",
      "Testing 1168/2880\n",
      "logistic sgd 1500 0.001 29 (200,): Weighted 0.839836 (0.061697)\n",
      "logistic sgd 1500 0.001 29 (200,): Macro 0.735730 (0.083516)\n",
      "Testing 1169/2880\n",
      "logistic sgd 1500 0.001 42 (50,): Weighted 0.831799 (0.064284)\n",
      "logistic sgd 1500 0.001 42 (50,): Macro 0.725070 (0.087211)\n",
      "Testing 1170/2880\n",
      "logistic sgd 1500 0.001 42 (100,): Weighted 0.841004 (0.062720)\n",
      "logistic sgd 1500 0.001 42 (100,): Macro 0.738188 (0.086177)\n",
      "Testing 1171/2880\n",
      "logistic sgd 1500 0.001 42 (150,): Weighted 0.840449 (0.066662)\n",
      "logistic sgd 1500 0.001 42 (150,): Macro 0.735547 (0.092851)\n",
      "Testing 1172/2880\n",
      "logistic sgd 1500 0.001 42 (200,): Weighted 0.836765 (0.064603)\n",
      "logistic sgd 1500 0.001 42 (200,): Macro 0.732153 (0.088175)\n",
      "Testing 1173/2880\n",
      "logistic sgd 1500 0.001 76 (50,): Weighted 0.835663 (0.065220)\n",
      "logistic sgd 1500 0.001 76 (50,): Macro 0.728448 (0.089984)\n",
      "Testing 1174/2880\n",
      "logistic sgd 1500 0.001 76 (100,): Weighted 0.845790 (0.063820)\n",
      "logistic sgd 1500 0.001 76 (100,): Macro 0.745288 (0.088388)\n",
      "Testing 1175/2880\n",
      "logistic sgd 1500 0.001 76 (150,): Weighted 0.841004 (0.062720)\n",
      "logistic sgd 1500 0.001 76 (150,): Macro 0.738188 (0.086177)\n",
      "Testing 1176/2880\n",
      "logistic sgd 1500 0.001 76 (200,): Weighted 0.839836 (0.061697)\n",
      "logistic sgd 1500 0.001 76 (200,): Macro 0.735730 (0.083516)\n",
      "Testing 1177/2880\n",
      "logistic sgd 1500 0.001 112 (50,): Weighted 0.828680 (0.056276)\n",
      "logistic sgd 1500 0.001 112 (50,): Macro 0.715479 (0.067613)\n",
      "Testing 1178/2880\n",
      "logistic sgd 1500 0.001 112 (100,): Weighted 0.841004 (0.062720)\n",
      "logistic sgd 1500 0.001 112 (100,): Macro 0.738188 (0.086177)\n",
      "Testing 1179/2880\n",
      "logistic sgd 1500 0.001 112 (150,): Weighted 0.835704 (0.064107)\n",
      "logistic sgd 1500 0.001 112 (150,): Macro 0.729958 (0.086636)\n",
      "Testing 1180/2880\n",
      "logistic sgd 1500 0.001 112 (200,): Weighted 0.831509 (0.065335)\n",
      "logistic sgd 1500 0.001 112 (200,): Macro 0.724139 (0.088117)\n",
      "Testing 1181/2880\n",
      "logistic sgd 1500 0.0001 17 (50,): Weighted 0.835441 (0.066169)\n",
      "logistic sgd 1500 0.0001 17 (50,): Macro 0.731484 (0.089034)\n",
      "Testing 1182/2880\n",
      "logistic sgd 1500 0.0001 17 (100,): Weighted 0.827952 (0.054004)\n",
      "logistic sgd 1500 0.0001 17 (100,): Macro 0.714432 (0.064067)\n",
      "Testing 1183/2880\n",
      "logistic sgd 1500 0.0001 17 (150,): Weighted 0.845790 (0.063820)\n",
      "logistic sgd 1500 0.0001 17 (150,): Macro 0.745288 (0.088388)\n",
      "Testing 1184/2880\n",
      "logistic sgd 1500 0.0001 17 (200,): Weighted 0.844466 (0.065587)\n",
      "logistic sgd 1500 0.0001 17 (200,): Macro 0.744619 (0.089343)\n",
      "Testing 1185/2880\n",
      "logistic sgd 1500 0.0001 29 (50,): Weighted 0.834339 (0.066750)\n",
      "logistic sgd 1500 0.0001 29 (50,): Macro 0.727779 (0.090798)\n",
      "Testing 1186/2880\n",
      "logistic sgd 1500 0.0001 29 (100,): Weighted 0.832708 (0.067112)\n",
      "logistic sgd 1500 0.0001 29 (100,): Macro 0.722858 (0.093482)\n",
      "Testing 1187/2880\n",
      "logistic sgd 1500 0.0001 29 (150,): Weighted 0.844466 (0.065587)\n",
      "logistic sgd 1500 0.0001 29 (150,): Macro 0.744619 (0.089343)\n",
      "Testing 1188/2880\n",
      "logistic sgd 1500 0.0001 29 (200,): Weighted 0.839836 (0.061697)\n",
      "logistic sgd 1500 0.0001 29 (200,): Macro 0.735730 (0.083516)\n",
      "Testing 1189/2880\n",
      "logistic sgd 1500 0.0001 42 (50,): Weighted 0.831799 (0.064284)\n",
      "logistic sgd 1500 0.0001 42 (50,): Macro 0.725070 (0.087211)\n",
      "Testing 1190/2880\n",
      "logistic sgd 1500 0.0001 42 (100,): Weighted 0.841004 (0.062720)\n",
      "logistic sgd 1500 0.0001 42 (100,): Macro 0.738188 (0.086177)\n",
      "Testing 1191/2880\n",
      "logistic sgd 1500 0.0001 42 (150,): Weighted 0.840449 (0.066662)\n",
      "logistic sgd 1500 0.0001 42 (150,): Macro 0.735547 (0.092851)\n",
      "Testing 1192/2880\n",
      "logistic sgd 1500 0.0001 42 (200,): Weighted 0.836765 (0.064603)\n",
      "logistic sgd 1500 0.0001 42 (200,): Macro 0.732153 (0.088175)\n",
      "Testing 1193/2880\n",
      "logistic sgd 1500 0.0001 76 (50,): Weighted 0.835663 (0.065220)\n",
      "logistic sgd 1500 0.0001 76 (50,): Macro 0.728448 (0.089984)\n",
      "Testing 1194/2880\n",
      "logistic sgd 1500 0.0001 76 (100,): Weighted 0.845790 (0.063820)\n",
      "logistic sgd 1500 0.0001 76 (100,): Macro 0.745288 (0.088388)\n",
      "Testing 1195/2880\n",
      "logistic sgd 1500 0.0001 76 (150,): Weighted 0.841004 (0.062720)\n",
      "logistic sgd 1500 0.0001 76 (150,): Macro 0.738188 (0.086177)\n",
      "Testing 1196/2880\n",
      "logistic sgd 1500 0.0001 76 (200,): Weighted 0.839836 (0.061697)\n",
      "logistic sgd 1500 0.0001 76 (200,): Macro 0.735730 (0.083516)\n",
      "Testing 1197/2880\n",
      "logistic sgd 1500 0.0001 112 (50,): Weighted 0.828680 (0.056276)\n",
      "logistic sgd 1500 0.0001 112 (50,): Macro 0.715479 (0.067613)\n",
      "Testing 1198/2880\n",
      "logistic sgd 1500 0.0001 112 (100,): Weighted 0.841004 (0.062720)\n",
      "logistic sgd 1500 0.0001 112 (100,): Macro 0.738188 (0.086177)\n",
      "Testing 1199/2880\n",
      "logistic sgd 1500 0.0001 112 (150,): Weighted 0.835704 (0.064107)\n",
      "logistic sgd 1500 0.0001 112 (150,): Macro 0.729958 (0.086636)\n",
      "Testing 1200/2880\n",
      "logistic sgd 1500 0.0001 112 (200,): Weighted 0.831509 (0.065335)\n",
      "logistic sgd 1500 0.0001 112 (200,): Macro 0.724139 (0.088117)\n",
      "Testing 1201/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic adam 500 0.1 17 (50,): Weighted 0.837699 (0.062958)\n",
      "logistic adam 500 0.1 17 (50,): Macro 0.732288 (0.085460)\n",
      "Testing 1202/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic adam 500 0.1 17 (100,): Weighted 0.837630 (0.058181)\n",
      "logistic adam 500 0.1 17 (100,): Macro 0.734685 (0.075431)\n",
      "Testing 1203/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic adam 500 0.1 17 (150,): Weighted 0.833231 (0.061522)\n",
      "logistic adam 500 0.1 17 (150,): Macro 0.722880 (0.084967)\n",
      "Testing 1204/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic adam 500 0.1 17 (200,): Weighted 0.828747 (0.044651)\n",
      "logistic adam 500 0.1 17 (200,): Macro 0.712774 (0.056602)\n",
      "Testing 1205/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic adam 500 0.1 29 (50,): Weighted 0.834090 (0.061367)\n",
      "logistic adam 500 0.1 29 (50,): Macro 0.731169 (0.078507)\n",
      "Testing 1206/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic adam 500 0.1 29 (100,): Weighted 0.837305 (0.058728)\n",
      "logistic adam 500 0.1 29 (100,): Macro 0.728358 (0.081168)\n",
      "Testing 1207/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic adam 500 0.1 29 (150,): Weighted 0.837305 (0.058728)\n",
      "logistic adam 500 0.1 29 (150,): Macro 0.728358 (0.081168)\n",
      "Testing 1208/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic adam 500 0.1 29 (200,): Weighted 0.830632 (0.053782)\n",
      "logistic adam 500 0.1 29 (200,): Macro 0.721158 (0.066919)\n",
      "Testing 1209/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic adam 500 0.1 42 (50,): Weighted 0.832732 (0.062705)\n",
      "logistic adam 500 0.1 42 (50,): Macro 0.725205 (0.084476)\n",
      "Testing 1210/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic adam 500 0.1 42 (100,): Weighted 0.840888 (0.045187)\n",
      "logistic adam 500 0.1 42 (100,): Macro 0.737449 (0.053332)\n",
      "Testing 1211/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic adam 500 0.1 42 (150,): Weighted 0.845885 (0.052286)\n",
      "logistic adam 500 0.1 42 (150,): Macro 0.745179 (0.067592)\n",
      "Testing 1212/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic adam 500 0.1 42 (200,): Weighted 0.842690 (0.055299)\n",
      "logistic adam 500 0.1 42 (200,): Macro 0.740061 (0.071988)\n",
      "Testing 1213/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic adam 500 0.1 76 (50,): Weighted 0.834339 (0.066750)\n",
      "logistic adam 500 0.1 76 (50,): Macro 0.727779 (0.090798)\n",
      "Testing 1214/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic adam 500 0.1 76 (100,): Weighted 0.833250 (0.050876)\n",
      "logistic adam 500 0.1 76 (100,): Macro 0.726468 (0.061869)\n",
      "Testing 1215/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic adam 500 0.1 76 (150,): Weighted 0.825673 (0.037241)\n",
      "logistic adam 500 0.1 76 (150,): Macro 0.711964 (0.041912)\n",
      "Testing 1216/2880\n",
      "logistic adam 500 0.1 76 (200,): Weighted 0.834370 (0.050125)\n",
      "logistic adam 500 0.1 76 (200,): Macro 0.726356 (0.061955)\n",
      "Testing 1217/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic adam 500 0.1 112 (50,): Weighted 0.829933 (0.055679)\n",
      "logistic adam 500 0.1 112 (50,): Macro 0.719936 (0.072110)\n",
      "Testing 1218/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic adam 500 0.1 112 (100,): Weighted 0.833826 (0.040127)\n",
      "logistic adam 500 0.1 112 (100,): Macro 0.724229 (0.045912)\n",
      "Testing 1219/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic adam 500 0.1 112 (150,): Weighted 0.826210 (0.055349)\n",
      "logistic adam 500 0.1 112 (150,): Macro 0.711586 (0.073008)\n",
      "Testing 1220/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic adam 500 0.1 112 (200,): Weighted 0.822038 (0.039829)\n",
      "logistic adam 500 0.1 112 (200,): Macro 0.706724 (0.045074)\n",
      "Testing 1221/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic adam 500 0.01 17 (50,): Weighted 0.841152 (0.059405)\n",
      "logistic adam 500 0.01 17 (50,): Macro 0.735552 (0.081842)\n",
      "Testing 1222/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic adam 500 0.01 17 (100,): Weighted 0.836885 (0.048035)\n",
      "logistic adam 500 0.01 17 (100,): Macro 0.731708 (0.057843)\n",
      "Testing 1223/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic adam 500 0.01 17 (150,): Weighted 0.833231 (0.061522)\n",
      "logistic adam 500 0.01 17 (150,): Macro 0.722880 (0.084967)\n",
      "Testing 1224/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic adam 500 0.01 17 (200,): Weighted 0.830328 (0.044726)\n",
      "logistic adam 500 0.01 17 (200,): Macro 0.715721 (0.057533)\n",
      "Testing 1225/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic adam 500 0.01 29 (50,): Weighted 0.841264 (0.055428)\n",
      "logistic adam 500 0.01 29 (50,): Macro 0.739925 (0.071566)\n",
      "Testing 1226/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic adam 500 0.01 29 (100,): Weighted 0.828747 (0.044651)\n",
      "logistic adam 500 0.01 29 (100,): Macro 0.712774 (0.056602)\n",
      "Testing 1227/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic adam 500 0.01 29 (150,): Weighted 0.825318 (0.048375)\n",
      "logistic adam 500 0.01 29 (150,): Macro 0.708067 (0.062308)\n",
      "Testing 1228/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic adam 500 0.01 29 (200,): Weighted 0.823266 (0.045270)\n",
      "logistic adam 500 0.01 29 (200,): Macro 0.708608 (0.054497)\n",
      "Testing 1229/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic adam 500 0.01 42 (50,): Weighted 0.832732 (0.062705)\n",
      "logistic adam 500 0.01 42 (50,): Macro 0.725205 (0.084476)\n",
      "Testing 1230/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic adam 500 0.01 42 (100,): Weighted 0.837601 (0.046430)\n",
      "logistic adam 500 0.01 42 (100,): Macro 0.733601 (0.054533)\n",
      "Testing 1231/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic adam 500 0.01 42 (150,): Weighted 0.836866 (0.049536)\n",
      "logistic adam 500 0.01 42 (150,): Macro 0.725630 (0.065273)\n",
      "Testing 1232/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic adam 500 0.01 42 (200,): Weighted 0.837816 (0.060424)\n",
      "logistic adam 500 0.01 42 (200,): Macro 0.729140 (0.083745)\n",
      "Testing 1233/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic adam 500 0.01 76 (50,): Weighted 0.834337 (0.062633)\n",
      "logistic adam 500 0.01 76 (50,): Macro 0.726711 (0.086284)\n",
      "Testing 1234/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic adam 500 0.01 76 (100,): Weighted 0.834370 (0.050125)\n",
      "logistic adam 500 0.01 76 (100,): Macro 0.726356 (0.061955)\n",
      "Testing 1235/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic adam 500 0.01 76 (150,): Weighted 0.822038 (0.039829)\n",
      "logistic adam 500 0.01 76 (150,): Macro 0.706724 (0.045074)\n",
      "Testing 1236/2880\n",
      "logistic adam 500 0.01 76 (200,): Weighted 0.833876 (0.062082)\n",
      "logistic adam 500 0.01 76 (200,): Macro 0.723651 (0.086101)\n",
      "Testing 1237/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic adam 500 0.01 112 (50,): Weighted 0.836772 (0.052565)\n",
      "logistic adam 500 0.01 112 (50,): Macro 0.727336 (0.069645)\n",
      "Testing 1238/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic adam 500 0.01 112 (100,): Weighted 0.828747 (0.044651)\n",
      "logistic adam 500 0.01 112 (100,): Macro 0.712774 (0.056602)\n",
      "Testing 1239/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic adam 500 0.01 112 (150,): Weighted 0.830989 (0.065128)\n",
      "logistic adam 500 0.01 112 (150,): Macro 0.720588 (0.089731)\n",
      "Testing 1240/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic adam 500 0.01 112 (200,): Weighted 0.830937 (0.063478)\n",
      "logistic adam 500 0.01 112 (200,): Macro 0.723897 (0.084082)\n",
      "Testing 1241/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic adam 500 0.001 17 (50,): Weighted 0.837723 (0.062932)\n",
      "logistic adam 500 0.001 17 (50,): Macro 0.730846 (0.087126)\n",
      "Testing 1242/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic adam 500 0.001 17 (100,): Weighted 0.836885 (0.048035)\n",
      "logistic adam 500 0.001 17 (100,): Macro 0.731708 (0.057843)\n",
      "Testing 1243/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic adam 500 0.001 17 (150,): Weighted 0.820593 (0.041081)\n",
      "logistic adam 500 0.001 17 (150,): Macro 0.700509 (0.050710)\n",
      "Testing 1244/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic adam 500 0.001 17 (200,): Weighted 0.823358 (0.052921)\n",
      "logistic adam 500 0.001 17 (200,): Macro 0.706311 (0.069676)\n",
      "Testing 1245/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic adam 500 0.001 29 (50,): Weighted 0.836185 (0.059425)\n",
      "logistic adam 500 0.001 29 (50,): Macro 0.728470 (0.081100)\n",
      "Testing 1246/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic adam 500 0.001 29 (100,): Weighted 0.828747 (0.044651)\n",
      "logistic adam 500 0.001 29 (100,): Macro 0.712774 (0.056602)\n",
      "Testing 1247/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic adam 500 0.001 29 (150,): Weighted 0.821778 (0.052649)\n",
      "logistic adam 500 0.001 29 (150,): Macro 0.703364 (0.068505)\n",
      "Testing 1248/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic adam 500 0.001 29 (200,): Weighted 0.818591 (0.050733)\n",
      "logistic adam 500 0.001 29 (200,): Macro 0.698181 (0.066934)\n",
      "Testing 1249/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic adam 500 0.001 42 (50,): Weighted 0.832732 (0.062705)\n",
      "logistic adam 500 0.001 42 (50,): Macro 0.725205 (0.084476)\n",
      "Testing 1250/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic adam 500 0.001 42 (100,): Weighted 0.836885 (0.048035)\n",
      "logistic adam 500 0.001 42 (100,): Macro 0.731708 (0.057843)\n",
      "Testing 1251/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic adam 500 0.001 42 (150,): Weighted 0.836866 (0.049536)\n",
      "logistic adam 500 0.001 42 (150,): Macro 0.725630 (0.065273)\n",
      "Testing 1252/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic adam 500 0.001 42 (200,): Weighted 0.837816 (0.060424)\n",
      "logistic adam 500 0.001 42 (200,): Macro 0.729140 (0.083745)\n",
      "Testing 1253/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic adam 500 0.001 76 (50,): Weighted 0.837723 (0.062932)\n",
      "logistic adam 500 0.001 76 (50,): Macro 0.730846 (0.087126)\n",
      "Testing 1254/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic adam 500 0.001 76 (100,): Weighted 0.834370 (0.050125)\n",
      "logistic adam 500 0.001 76 (100,): Macro 0.726356 (0.061955)\n",
      "Testing 1255/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic adam 500 0.001 76 (150,): Weighted 0.822038 (0.039829)\n",
      "logistic adam 500 0.001 76 (150,): Macro 0.706724 (0.045074)\n",
      "Testing 1256/2880\n",
      "logistic adam 500 0.001 76 (200,): Weighted 0.833876 (0.062082)\n",
      "logistic adam 500 0.001 76 (200,): Macro 0.723651 (0.086101)\n",
      "Testing 1257/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic adam 500 0.001 112 (50,): Weighted 0.837766 (0.059284)\n",
      "logistic adam 500 0.001 112 (50,): Macro 0.731417 (0.081185)\n",
      "Testing 1258/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic adam 500 0.001 112 (100,): Weighted 0.828747 (0.044651)\n",
      "logistic adam 500 0.001 112 (100,): Macro 0.712774 (0.056602)\n",
      "Testing 1259/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic adam 500 0.001 112 (150,): Weighted 0.830989 (0.065128)\n",
      "logistic adam 500 0.001 112 (150,): Macro 0.720588 (0.089731)\n",
      "Testing 1260/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic adam 500 0.001 112 (200,): Weighted 0.831228 (0.068715)\n",
      "logistic adam 500 0.001 112 (200,): Macro 0.720552 (0.096084)\n",
      "Testing 1261/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic adam 500 0.0001 17 (50,): Weighted 0.837723 (0.062932)\n",
      "logistic adam 500 0.0001 17 (50,): Macro 0.730846 (0.087126)\n",
      "Testing 1262/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic adam 500 0.0001 17 (100,): Weighted 0.836885 (0.048035)\n",
      "logistic adam 500 0.0001 17 (100,): Macro 0.731708 (0.057843)\n",
      "Testing 1263/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic adam 500 0.0001 17 (150,): Weighted 0.820593 (0.041081)\n",
      "logistic adam 500 0.0001 17 (150,): Macro 0.700509 (0.050710)\n",
      "Testing 1264/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic adam 500 0.0001 17 (200,): Weighted 0.823358 (0.052921)\n",
      "logistic adam 500 0.0001 17 (200,): Macro 0.706311 (0.069676)\n",
      "Testing 1265/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic adam 500 0.0001 29 (50,): Weighted 0.832756 (0.062681)\n",
      "logistic adam 500 0.0001 29 (50,): Macro 0.723763 (0.086043)\n",
      "Testing 1266/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic adam 500 0.0001 29 (100,): Weighted 0.828747 (0.044651)\n",
      "logistic adam 500 0.0001 29 (100,): Macro 0.712774 (0.056602)\n",
      "Testing 1267/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic adam 500 0.0001 29 (150,): Weighted 0.821778 (0.052649)\n",
      "logistic adam 500 0.0001 29 (150,): Macro 0.703364 (0.068505)\n",
      "Testing 1268/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic adam 500 0.0001 29 (200,): Weighted 0.818591 (0.050733)\n",
      "logistic adam 500 0.0001 29 (200,): Macro 0.698181 (0.066934)\n",
      "Testing 1269/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic adam 500 0.0001 42 (50,): Weighted 0.832732 (0.062705)\n",
      "logistic adam 500 0.0001 42 (50,): Macro 0.725205 (0.084476)\n",
      "Testing 1270/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic adam 500 0.0001 42 (100,): Weighted 0.836885 (0.048035)\n",
      "logistic adam 500 0.0001 42 (100,): Macro 0.731708 (0.057843)\n",
      "Testing 1271/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic adam 500 0.0001 42 (150,): Weighted 0.836866 (0.049536)\n",
      "logistic adam 500 0.0001 42 (150,): Macro 0.725630 (0.065273)\n",
      "Testing 1272/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic adam 500 0.0001 42 (200,): Weighted 0.837816 (0.060424)\n",
      "logistic adam 500 0.0001 42 (200,): Macro 0.729140 (0.083745)\n",
      "Testing 1273/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic adam 500 0.0001 76 (50,): Weighted 0.837723 (0.062932)\n",
      "logistic adam 500 0.0001 76 (50,): Macro 0.730846 (0.087126)\n",
      "Testing 1274/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic adam 500 0.0001 76 (100,): Weighted 0.834370 (0.050125)\n",
      "logistic adam 500 0.0001 76 (100,): Macro 0.726356 (0.061955)\n",
      "Testing 1275/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic adam 500 0.0001 76 (150,): Weighted 0.822038 (0.039829)\n",
      "logistic adam 500 0.0001 76 (150,): Macro 0.706724 (0.045074)\n",
      "Testing 1276/2880\n",
      "logistic adam 500 0.0001 76 (200,): Weighted 0.833876 (0.062082)\n",
      "logistic adam 500 0.0001 76 (200,): Macro 0.723651 (0.086101)\n",
      "Testing 1277/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic adam 500 0.0001 112 (50,): Weighted 0.832281 (0.064819)\n",
      "logistic adam 500 0.0001 112 (50,): Macro 0.718608 (0.096055)\n",
      "Testing 1278/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic adam 500 0.0001 112 (100,): Weighted 0.828747 (0.044651)\n",
      "logistic adam 500 0.0001 112 (100,): Macro 0.712774 (0.056602)\n",
      "Testing 1279/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic adam 500 0.0001 112 (150,): Weighted 0.830989 (0.065128)\n",
      "logistic adam 500 0.0001 112 (150,): Macro 0.720588 (0.089731)\n",
      "Testing 1280/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic adam 500 0.0001 112 (200,): Weighted 0.831228 (0.068715)\n",
      "logistic adam 500 0.0001 112 (200,): Macro 0.720552 (0.096084)\n",
      "Testing 1281/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic adam 1000 0.1 17 (50,): Weighted 0.819459 (0.049218)\n",
      "logistic adam 1000 0.1 17 (50,): Macro 0.699776 (0.061495)\n",
      "Testing 1282/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic adam 1000 0.1 17 (100,): Weighted 0.822238 (0.053402)\n",
      "logistic adam 1000 0.1 17 (100,): Macro 0.706423 (0.069633)\n",
      "Testing 1283/2880\n",
      "logistic adam 1000 0.1 17 (150,): Weighted 0.833231 (0.061522)\n",
      "logistic adam 1000 0.1 17 (150,): Macro 0.722880 (0.084967)\n",
      "Testing 1284/2880\n",
      "logistic adam 1000 0.1 17 (200,): Weighted 0.816997 (0.054155)\n",
      "logistic adam 1000 0.1 17 (200,): Macro 0.697055 (0.069906)\n",
      "Testing 1285/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic adam 1000 0.1 29 (50,): Weighted 0.826262 (0.068011)\n",
      "logistic adam 1000 0.1 29 (50,): Macro 0.713470 (0.094333)\n",
      "Testing 1286/2880\n",
      "logistic adam 1000 0.1 29 (100,): Weighted 0.829885 (0.064306)\n",
      "logistic adam 1000 0.1 29 (100,): Macro 0.719623 (0.087636)\n",
      "Testing 1287/2880\n",
      "logistic adam 1000 0.1 29 (150,): Weighted 0.837816 (0.060424)\n",
      "logistic adam 1000 0.1 29 (150,): Macro 0.729140 (0.083745)\n",
      "Testing 1288/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic adam 1000 0.1 29 (200,): Weighted 0.824758 (0.055690)\n",
      "logistic adam 1000 0.1 29 (200,): Macro 0.707032 (0.073470)\n",
      "Testing 1289/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic adam 1000 0.1 42 (50,): Weighted 0.821091 (0.071582)\n",
      "logistic adam 1000 0.1 42 (50,): Macro 0.707132 (0.095802)\n",
      "Testing 1290/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic adam 1000 0.1 42 (100,): Weighted 0.840775 (0.049984)\n",
      "logistic adam 1000 0.1 42 (100,): Macro 0.733077 (0.066325)\n",
      "Testing 1291/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic adam 1000 0.1 42 (150,): Weighted 0.838803 (0.064862)\n",
      "logistic adam 1000 0.1 42 (150,): Macro 0.731396 (0.090597)\n",
      "Testing 1292/2880\n",
      "logistic adam 1000 0.1 42 (200,): Weighted 0.834276 (0.064585)\n",
      "logistic adam 1000 0.1 42 (200,): Macro 0.724436 (0.089567)\n",
      "Testing 1293/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic adam 1000 0.1 76 (50,): Weighted 0.834231 (0.061841)\n",
      "logistic adam 1000 0.1 76 (50,): Macro 0.729409 (0.078774)\n",
      "Testing 1294/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic adam 1000 0.1 76 (100,): Weighted 0.830336 (0.065927)\n",
      "logistic adam 1000 0.1 76 (100,): Macro 0.718948 (0.091492)\n",
      "Testing 1295/2880\n",
      "logistic adam 1000 0.1 76 (150,): Weighted 0.825673 (0.037241)\n",
      "logistic adam 1000 0.1 76 (150,): Macro 0.711964 (0.041912)\n",
      "Testing 1296/2880\n",
      "logistic adam 1000 0.1 76 (200,): Weighted 0.834370 (0.050125)\n",
      "logistic adam 1000 0.1 76 (200,): Macro 0.726356 (0.061955)\n",
      "Testing 1297/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic adam 1000 0.1 112 (50,): Weighted 0.829957 (0.055653)\n",
      "logistic adam 1000 0.1 112 (50,): Macro 0.718494 (0.073837)\n",
      "Testing 1298/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic adam 1000 0.1 112 (100,): Weighted 0.827298 (0.051772)\n",
      "logistic adam 1000 0.1 112 (100,): Macro 0.711799 (0.068154)\n",
      "Testing 1299/2880\n",
      "logistic adam 1000 0.1 112 (150,): Weighted 0.829497 (0.054995)\n",
      "logistic adam 1000 0.1 112 (150,): Macro 0.715435 (0.073280)\n",
      "Testing 1300/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic adam 1000 0.1 112 (200,): Weighted 0.813624 (0.048499)\n",
      "logistic adam 1000 0.1 112 (200,): Macro 0.691099 (0.061886)\n",
      "Testing 1301/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic adam 1000 0.01 17 (50,): Weighted 0.821378 (0.046816)\n",
      "logistic adam 1000 0.01 17 (50,): Macro 0.705108 (0.055095)\n",
      "Testing 1302/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic adam 1000 0.01 17 (100,): Weighted 0.824914 (0.047563)\n",
      "logistic adam 1000 0.01 17 (100,): Macro 0.710072 (0.059940)\n",
      "Testing 1303/2880\n",
      "logistic adam 1000 0.01 17 (150,): Weighted 0.825063 (0.065130)\n",
      "logistic adam 1000 0.01 17 (150,): Macro 0.709771 (0.089815)\n",
      "Testing 1304/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic adam 1000 0.01 17 (200,): Weighted 0.800926 (0.063524)\n",
      "logistic adam 1000 0.01 17 (200,): Macro 0.677450 (0.077993)\n",
      "Testing 1305/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic adam 1000 0.01 29 (50,): Weighted 0.821007 (0.062195)\n",
      "logistic adam 1000 0.01 29 (50,): Macro 0.704904 (0.080003)\n",
      "Testing 1306/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic adam 1000 0.01 29 (100,): Weighted 0.826022 (0.058186)\n",
      "logistic adam 1000 0.01 29 (100,): Macro 0.710163 (0.077017)\n",
      "Testing 1307/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic adam 1000 0.01 29 (150,): Weighted 0.829630 (0.054993)\n",
      "logistic adam 1000 0.01 29 (150,): Macro 0.713842 (0.073094)\n",
      "Testing 1308/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic adam 1000 0.01 29 (200,): Weighted 0.807312 (0.045235)\n",
      "logistic adam 1000 0.01 29 (200,): Macro 0.680499 (0.053861)\n",
      "Testing 1309/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic adam 1000 0.01 42 (50,): Weighted 0.841005 (0.059388)\n",
      "logistic adam 1000 0.01 42 (50,): Macro 0.733691 (0.081469)\n",
      "Testing 1310/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic adam 1000 0.01 42 (100,): Weighted 0.828880 (0.044651)\n",
      "logistic adam 1000 0.01 42 (100,): Macro 0.711181 (0.056285)\n",
      "Testing 1311/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic adam 1000 0.01 42 (150,): Weighted 0.816505 (0.050765)\n",
      "logistic adam 1000 0.01 42 (150,): Macro 0.694186 (0.064054)\n",
      "Testing 1312/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic adam 1000 0.01 42 (200,): Weighted 0.834276 (0.064585)\n",
      "logistic adam 1000 0.01 42 (200,): Macro 0.724436 (0.089567)\n",
      "Testing 1313/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic adam 1000 0.01 76 (50,): Weighted 0.819322 (0.054565)\n",
      "logistic adam 1000 0.01 76 (50,): Macro 0.703740 (0.066111)\n",
      "Testing 1314/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic adam 1000 0.01 76 (100,): Weighted 0.830469 (0.065924)\n",
      "logistic adam 1000 0.01 76 (100,): Macro 0.717355 (0.091404)\n",
      "Testing 1315/2880\n",
      "logistic adam 1000 0.01 76 (150,): Weighted 0.825179 (0.040862)\n",
      "logistic adam 1000 0.01 76 (150,): Macro 0.706769 (0.051434)\n",
      "Testing 1316/2880\n",
      "logistic adam 1000 0.01 76 (200,): Weighted 0.833876 (0.062082)\n",
      "logistic adam 1000 0.01 76 (200,): Macro 0.723651 (0.086101)\n",
      "Testing 1317/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic adam 1000 0.01 112 (50,): Weighted 0.820013 (0.061743)\n",
      "logistic adam 1000 0.01 112 (50,): Macro 0.704209 (0.081035)\n",
      "Testing 1318/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic adam 1000 0.01 112 (100,): Weighted 0.838257 (0.053646)\n",
      "logistic adam 1000 0.01 112 (100,): Macro 0.726144 (0.072104)\n",
      "Testing 1319/2880\n",
      "logistic adam 1000 0.01 112 (150,): Weighted 0.834276 (0.064585)\n",
      "logistic adam 1000 0.01 112 (150,): Macro 0.724436 (0.089567)\n",
      "Testing 1320/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic adam 1000 0.01 112 (200,): Weighted 0.829802 (0.064514)\n",
      "logistic adam 1000 0.01 112 (200,): Macro 0.718173 (0.089403)\n",
      "Testing 1321/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic adam 1000 0.001 17 (50,): Weighted 0.826064 (0.052134)\n",
      "logistic adam 1000 0.001 17 (50,): Macro 0.707810 (0.067981)\n",
      "Testing 1322/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic adam 1000 0.001 17 (100,): Weighted 0.823462 (0.047921)\n",
      "logistic adam 1000 0.001 17 (100,): Macro 0.705517 (0.060388)\n",
      "Testing 1323/2880\n",
      "logistic adam 1000 0.001 17 (150,): Weighted 0.815854 (0.040990)\n",
      "logistic adam 1000 0.001 17 (150,): Macro 0.692106 (0.048460)\n",
      "Testing 1324/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic adam 1000 0.001 17 (200,): Weighted 0.800926 (0.063524)\n",
      "logistic adam 1000 0.001 17 (200,): Macro 0.677450 (0.077993)\n",
      "Testing 1325/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic adam 1000 0.001 29 (50,): Weighted 0.821889 (0.072980)\n",
      "logistic adam 1000 0.001 29 (50,): Macro 0.708464 (0.097954)\n",
      "Testing 1326/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic adam 1000 0.001 29 (100,): Weighted 0.824283 (0.059945)\n",
      "logistic adam 1000 0.001 29 (100,): Macro 0.710439 (0.076748)\n",
      "Testing 1327/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic adam 1000 0.001 29 (150,): Weighted 0.829630 (0.054993)\n",
      "logistic adam 1000 0.001 29 (150,): Macro 0.713842 (0.073094)\n",
      "Testing 1328/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic adam 1000 0.001 29 (200,): Weighted 0.807312 (0.045235)\n",
      "logistic adam 1000 0.001 29 (200,): Macro 0.680499 (0.053861)\n",
      "Testing 1329/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic adam 1000 0.001 42 (50,): Weighted 0.836641 (0.064563)\n",
      "logistic adam 1000 0.001 42 (50,): Macro 0.720769 (0.096645)\n",
      "Testing 1330/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic adam 1000 0.001 42 (100,): Weighted 0.828880 (0.044651)\n",
      "logistic adam 1000 0.001 42 (100,): Macro 0.711181 (0.056285)\n",
      "Testing 1331/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic adam 1000 0.001 42 (150,): Weighted 0.819933 (0.047865)\n",
      "logistic adam 1000 0.001 42 (150,): Macro 0.698893 (0.059625)\n",
      "Testing 1332/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic adam 1000 0.001 42 (200,): Weighted 0.834276 (0.064585)\n",
      "logistic adam 1000 0.001 42 (200,): Macro 0.724436 (0.089567)\n",
      "Testing 1333/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic adam 1000 0.001 76 (50,): Weighted 0.813515 (0.062455)\n",
      "logistic adam 1000 0.001 76 (50,): Macro 0.697397 (0.079006)\n",
      "Testing 1334/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic adam 1000 0.001 76 (100,): Weighted 0.830469 (0.065924)\n",
      "logistic adam 1000 0.001 76 (100,): Macro 0.717355 (0.091404)\n",
      "Testing 1335/2880\n",
      "logistic adam 1000 0.001 76 (150,): Weighted 0.825179 (0.040862)\n",
      "logistic adam 1000 0.001 76 (150,): Macro 0.706769 (0.051434)\n",
      "Testing 1336/2880\n",
      "logistic adam 1000 0.001 76 (200,): Weighted 0.833876 (0.062082)\n",
      "logistic adam 1000 0.001 76 (200,): Macro 0.723651 (0.086101)\n",
      "Testing 1337/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic adam 1000 0.001 112 (50,): Weighted 0.811510 (0.066042)\n",
      "logistic adam 1000 0.001 112 (50,): Macro 0.688261 (0.092781)\n",
      "Testing 1338/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic adam 1000 0.001 112 (100,): Weighted 0.838257 (0.053646)\n",
      "logistic adam 1000 0.001 112 (100,): Macro 0.726144 (0.072104)\n",
      "Testing 1339/2880\n",
      "logistic adam 1000 0.001 112 (150,): Weighted 0.834276 (0.064585)\n",
      "logistic adam 1000 0.001 112 (150,): Macro 0.724436 (0.089567)\n",
      "Testing 1340/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic adam 1000 0.001 112 (200,): Weighted 0.821353 (0.077938)\n",
      "logistic adam 1000 0.001 112 (200,): Macro 0.708244 (0.106996)\n",
      "Testing 1341/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic adam 1000 0.0001 17 (50,): Weighted 0.824910 (0.053054)\n",
      "logistic adam 1000 0.0001 17 (50,): Macro 0.707733 (0.068039)\n",
      "Testing 1342/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic adam 1000 0.0001 17 (100,): Weighted 0.823462 (0.047921)\n",
      "logistic adam 1000 0.0001 17 (100,): Macro 0.705517 (0.060388)\n",
      "Testing 1343/2880\n",
      "logistic adam 1000 0.0001 17 (150,): Weighted 0.815854 (0.040990)\n",
      "logistic adam 1000 0.0001 17 (150,): Macro 0.692106 (0.048460)\n",
      "Testing 1344/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic adam 1000 0.0001 17 (200,): Weighted 0.800926 (0.063524)\n",
      "logistic adam 1000 0.0001 17 (200,): Macro 0.677450 (0.077993)\n",
      "Testing 1345/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic adam 1000 0.0001 29 (50,): Weighted 0.821889 (0.072980)\n",
      "logistic adam 1000 0.0001 29 (50,): Macro 0.708464 (0.097954)\n",
      "Testing 1346/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic adam 1000 0.0001 29 (100,): Weighted 0.824283 (0.059945)\n",
      "logistic adam 1000 0.0001 29 (100,): Macro 0.710439 (0.076748)\n",
      "Testing 1347/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic adam 1000 0.0001 29 (150,): Weighted 0.826090 (0.059047)\n",
      "logistic adam 1000 0.0001 29 (150,): Macro 0.709139 (0.078790)\n",
      "Testing 1348/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic adam 1000 0.0001 29 (200,): Weighted 0.807312 (0.045235)\n",
      "logistic adam 1000 0.0001 29 (200,): Macro 0.680499 (0.053861)\n",
      "Testing 1349/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic adam 1000 0.0001 42 (50,): Weighted 0.836641 (0.064563)\n",
      "logistic adam 1000 0.0001 42 (50,): Macro 0.720769 (0.096645)\n",
      "Testing 1350/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic adam 1000 0.0001 42 (100,): Weighted 0.833714 (0.045444)\n",
      "logistic adam 1000 0.0001 42 (100,): Macro 0.719856 (0.059557)\n",
      "Testing 1351/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic adam 1000 0.0001 42 (150,): Weighted 0.819933 (0.047865)\n",
      "logistic adam 1000 0.0001 42 (150,): Macro 0.698893 (0.059625)\n",
      "Testing 1352/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic adam 1000 0.0001 42 (200,): Weighted 0.834276 (0.064585)\n",
      "logistic adam 1000 0.0001 42 (200,): Macro 0.724436 (0.089567)\n",
      "Testing 1353/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic adam 1000 0.0001 76 (50,): Weighted 0.813515 (0.062455)\n",
      "logistic adam 1000 0.0001 76 (50,): Macro 0.697397 (0.079006)\n",
      "Testing 1354/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic adam 1000 0.0001 76 (100,): Weighted 0.830469 (0.065924)\n",
      "logistic adam 1000 0.0001 76 (100,): Macro 0.717355 (0.091404)\n",
      "Testing 1355/2880\n",
      "logistic adam 1000 0.0001 76 (150,): Weighted 0.825179 (0.040862)\n",
      "logistic adam 1000 0.0001 76 (150,): Macro 0.706769 (0.051434)\n",
      "Testing 1356/2880\n",
      "logistic adam 1000 0.0001 76 (200,): Weighted 0.833876 (0.062082)\n",
      "logistic adam 1000 0.0001 76 (200,): Macro 0.723651 (0.086101)\n",
      "Testing 1357/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic adam 1000 0.0001 112 (50,): Weighted 0.813004 (0.064587)\n",
      "logistic adam 1000 0.0001 112 (50,): Macro 0.692739 (0.087976)\n",
      "Testing 1358/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic adam 1000 0.0001 112 (100,): Weighted 0.838257 (0.053646)\n",
      "logistic adam 1000 0.0001 112 (100,): Macro 0.726144 (0.072104)\n",
      "Testing 1359/2880\n",
      "logistic adam 1000 0.0001 112 (150,): Weighted 0.834276 (0.064585)\n",
      "logistic adam 1000 0.0001 112 (150,): Macro 0.724436 (0.089567)\n",
      "Testing 1360/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic adam 1000 0.0001 112 (200,): Weighted 0.821353 (0.077938)\n",
      "logistic adam 1000 0.0001 112 (200,): Macro 0.708244 (0.106996)\n",
      "Testing 1361/2880\n",
      "logistic adam 1500 0.1 17 (50,): Weighted 0.824198 (0.048946)\n",
      "logistic adam 1500 0.1 17 (50,): Macro 0.708179 (0.062256)\n",
      "Testing 1362/2880\n",
      "logistic adam 1500 0.1 17 (100,): Weighted 0.817502 (0.052915)\n",
      "logistic adam 1500 0.1 17 (100,): Macro 0.698022 (0.067282)\n",
      "Testing 1363/2880\n",
      "logistic adam 1500 0.1 17 (150,): Weighted 0.833231 (0.061522)\n",
      "logistic adam 1500 0.1 17 (150,): Macro 0.722880 (0.084967)\n",
      "Testing 1364/2880\n",
      "logistic adam 1500 0.1 17 (200,): Weighted 0.816997 (0.054155)\n",
      "logistic adam 1500 0.1 17 (200,): Macro 0.697055 (0.069906)\n",
      "Testing 1365/2880\n",
      "logistic adam 1500 0.1 29 (50,): Weighted 0.825253 (0.069075)\n",
      "logistic adam 1500 0.1 29 (50,): Macro 0.714713 (0.092986)\n",
      "Testing 1366/2880\n",
      "logistic adam 1500 0.1 29 (100,): Weighted 0.829885 (0.064306)\n",
      "logistic adam 1500 0.1 29 (100,): Macro 0.719623 (0.087636)\n",
      "Testing 1367/2880\n",
      "logistic adam 1500 0.1 29 (150,): Weighted 0.837816 (0.060424)\n",
      "logistic adam 1500 0.1 29 (150,): Macro 0.729140 (0.083745)\n",
      "Testing 1368/2880\n",
      "logistic adam 1500 0.1 29 (200,): Weighted 0.820209 (0.060537)\n",
      "logistic adam 1500 0.1 29 (200,): Macro 0.703572 (0.077293)\n",
      "Testing 1369/2880\n",
      "logistic adam 1500 0.1 42 (50,): Weighted 0.822591 (0.069856)\n",
      "logistic adam 1500 0.1 42 (50,): Macro 0.703749 (0.099806)\n",
      "Testing 1370/2880\n",
      "logistic adam 1500 0.1 42 (100,): Weighted 0.837346 (0.054105)\n",
      "logistic adam 1500 0.1 42 (100,): Macro 0.728370 (0.072585)\n",
      "Testing 1371/2880\n",
      "logistic adam 1500 0.1 42 (150,): Weighted 0.818571 (0.071052)\n",
      "logistic adam 1500 0.1 42 (150,): Macro 0.701928 (0.097152)\n",
      "Testing 1372/2880\n",
      "logistic adam 1500 0.1 42 (200,): Weighted 0.834276 (0.064585)\n",
      "logistic adam 1500 0.1 42 (200,): Macro 0.724436 (0.089567)\n",
      "Testing 1373/2880\n",
      "logistic adam 1500 0.1 76 (50,): Weighted 0.829461 (0.067084)\n",
      "logistic adam 1500 0.1 76 (50,): Macro 0.718599 (0.089959)\n",
      "Testing 1374/2880\n",
      "logistic adam 1500 0.1 76 (100,): Weighted 0.830336 (0.065927)\n",
      "logistic adam 1500 0.1 76 (100,): Macro 0.718948 (0.091492)\n",
      "Testing 1375/2880\n",
      "logistic adam 1500 0.1 76 (150,): Weighted 0.825673 (0.037241)\n",
      "logistic adam 1500 0.1 76 (150,): Macro 0.711964 (0.041912)\n",
      "Testing 1376/2880\n",
      "logistic adam 1500 0.1 76 (200,): Weighted 0.834370 (0.050125)\n",
      "logistic adam 1500 0.1 76 (200,): Macro 0.726356 (0.061955)\n",
      "Testing 1377/2880\n",
      "logistic adam 1500 0.1 112 (50,): Weighted 0.829957 (0.055653)\n",
      "logistic adam 1500 0.1 112 (50,): Macro 0.718494 (0.073837)\n",
      "Testing 1378/2880\n",
      "logistic adam 1500 0.1 112 (100,): Weighted 0.827298 (0.051772)\n",
      "logistic adam 1500 0.1 112 (100,): Macro 0.711799 (0.068154)\n",
      "Testing 1379/2880\n",
      "logistic adam 1500 0.1 112 (150,): Weighted 0.829497 (0.054995)\n",
      "logistic adam 1500 0.1 112 (150,): Macro 0.715435 (0.073280)\n",
      "Testing 1380/2880\n",
      "logistic adam 1500 0.1 112 (200,): Weighted 0.820593 (0.041081)\n",
      "logistic adam 1500 0.1 112 (200,): Macro 0.700509 (0.050710)\n",
      "Testing 1381/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic adam 1500 0.01 17 (50,): Weighted 0.811956 (0.055366)\n",
      "logistic adam 1500 0.01 17 (50,): Macro 0.690726 (0.067753)\n",
      "Testing 1382/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic adam 1500 0.01 17 (100,): Weighted 0.818913 (0.053366)\n",
      "logistic adam 1500 0.01 17 (100,): Macro 0.702057 (0.064904)\n",
      "Testing 1383/2880\n",
      "logistic adam 1500 0.01 17 (150,): Weighted 0.825063 (0.065130)\n",
      "logistic adam 1500 0.01 17 (150,): Macro 0.709771 (0.089815)\n",
      "Testing 1384/2880\n",
      "logistic adam 1500 0.01 17 (200,): Weighted 0.804423 (0.060234)\n",
      "logistic adam 1500 0.01 17 (200,): Macro 0.682107 (0.073442)\n",
      "Testing 1385/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic adam 1500 0.01 29 (50,): Weighted 0.817627 (0.062184)\n",
      "logistic adam 1500 0.01 29 (50,): Macro 0.704204 (0.077180)\n",
      "Testing 1386/2880\n",
      "logistic adam 1500 0.01 29 (100,): Weighted 0.831478 (0.052472)\n",
      "logistic adam 1500 0.01 29 (100,): Macro 0.719274 (0.067484)\n",
      "Testing 1387/2880\n",
      "logistic adam 1500 0.01 29 (150,): Weighted 0.829630 (0.054993)\n",
      "logistic adam 1500 0.01 29 (150,): Macro 0.713842 (0.073094)\n",
      "Testing 1388/2880\n",
      "logistic adam 1500 0.01 29 (200,): Weighted 0.802763 (0.049506)\n",
      "logistic adam 1500 0.01 29 (200,): Macro 0.677039 (0.057391)\n",
      "Testing 1389/2880\n",
      "logistic adam 1500 0.01 42 (50,): Weighted 0.835521 (0.065187)\n",
      "logistic adam 1500 0.01 42 (50,): Macro 0.720881 (0.096597)\n",
      "Testing 1390/2880\n",
      "logistic adam 1500 0.01 42 (100,): Weighted 0.820422 (0.051868)\n",
      "logistic adam 1500 0.01 42 (100,): Macro 0.705965 (0.061286)\n",
      "Testing 1391/2880\n",
      "logistic adam 1500 0.01 42 (150,): Weighted 0.805979 (0.055283)\n",
      "logistic adam 1500 0.01 42 (150,): Macro 0.680203 (0.068767)\n",
      "Testing 1392/2880\n",
      "logistic adam 1500 0.01 42 (200,): Weighted 0.834276 (0.064585)\n",
      "logistic adam 1500 0.01 42 (200,): Macro 0.724436 (0.089567)\n",
      "Testing 1393/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic adam 1500 0.01 76 (50,): Weighted 0.814450 (0.054351)\n",
      "logistic adam 1500 0.01 76 (50,): Macro 0.696930 (0.065484)\n",
      "Testing 1394/2880\n",
      "logistic adam 1500 0.01 76 (100,): Weighted 0.830469 (0.065924)\n",
      "logistic adam 1500 0.01 76 (100,): Macro 0.717355 (0.091404)\n",
      "Testing 1395/2880\n",
      "logistic adam 1500 0.01 76 (150,): Weighted 0.825179 (0.040862)\n",
      "logistic adam 1500 0.01 76 (150,): Macro 0.706769 (0.051434)\n",
      "Testing 1396/2880\n",
      "logistic adam 1500 0.01 76 (200,): Weighted 0.833876 (0.062082)\n",
      "logistic adam 1500 0.01 76 (200,): Macro 0.723651 (0.086101)\n",
      "Testing 1397/2880\n",
      "logistic adam 1500 0.01 112 (50,): Weighted 0.822688 (0.059459)\n",
      "logistic adam 1500 0.01 112 (50,): Macro 0.710605 (0.076107)\n",
      "Testing 1398/2880\n",
      "logistic adam 1500 0.01 112 (100,): Weighted 0.817017 (0.061823)\n",
      "logistic adam 1500 0.01 112 (100,): Macro 0.699746 (0.078454)\n",
      "Testing 1399/2880\n",
      "logistic adam 1500 0.01 112 (150,): Weighted 0.834276 (0.064585)\n",
      "logistic adam 1500 0.01 112 (150,): Macro 0.724436 (0.089567)\n",
      "Testing 1400/2880\n",
      "logistic adam 1500 0.01 112 (200,): Weighted 0.829802 (0.064514)\n",
      "logistic adam 1500 0.01 112 (200,): Macro 0.718173 (0.089403)\n",
      "Testing 1401/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic adam 1500 0.001 17 (50,): Weighted 0.813539 (0.055365)\n",
      "logistic adam 1500 0.001 17 (50,): Macro 0.693675 (0.068034)\n",
      "Testing 1402/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic adam 1500 0.001 17 (100,): Weighted 0.812566 (0.064835)\n",
      "logistic adam 1500 0.001 17 (100,): Macro 0.695442 (0.082711)\n",
      "Testing 1403/2880\n",
      "logistic adam 1500 0.001 17 (150,): Weighted 0.815854 (0.040990)\n",
      "logistic adam 1500 0.001 17 (150,): Macro 0.692106 (0.048460)\n",
      "Testing 1404/2880\n",
      "logistic adam 1500 0.001 17 (200,): Weighted 0.799310 (0.060451)\n",
      "logistic adam 1500 0.001 17 (200,): Macro 0.675206 (0.073412)\n",
      "Testing 1405/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic adam 1500 0.001 29 (50,): Weighted 0.823008 (0.068220)\n",
      "logistic adam 1500 0.001 29 (50,): Macro 0.712514 (0.090368)\n",
      "Testing 1406/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic adam 1500 0.001 29 (100,): Weighted 0.831478 (0.052472)\n",
      "logistic adam 1500 0.001 29 (100,): Macro 0.719274 (0.067484)\n",
      "Testing 1407/2880\n",
      "logistic adam 1500 0.001 29 (150,): Weighted 0.829630 (0.054993)\n",
      "logistic adam 1500 0.001 29 (150,): Macro 0.713842 (0.073094)\n",
      "Testing 1408/2880\n",
      "logistic adam 1500 0.001 29 (200,): Weighted 0.791575 (0.055970)\n",
      "logistic adam 1500 0.001 29 (200,): Macro 0.662603 (0.065280)\n",
      "Testing 1409/2880\n",
      "logistic adam 1500 0.001 42 (50,): Weighted 0.836641 (0.064563)\n",
      "logistic adam 1500 0.001 42 (50,): Macro 0.720769 (0.096645)\n",
      "Testing 1410/2880\n",
      "logistic adam 1500 0.001 42 (100,): Weighted 0.810876 (0.060062)\n",
      "logistic adam 1500 0.001 42 (100,): Macro 0.693734 (0.070945)\n",
      "Testing 1411/2880\n",
      "logistic adam 1500 0.001 42 (150,): Weighted 0.805979 (0.055283)\n",
      "logistic adam 1500 0.001 42 (150,): Macro 0.680203 (0.068767)\n",
      "Testing 1412/2880\n",
      "logistic adam 1500 0.001 42 (200,): Weighted 0.834276 (0.064585)\n",
      "logistic adam 1500 0.001 42 (200,): Macro 0.724436 (0.089567)\n",
      "Testing 1413/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic adam 1500 0.001 76 (50,): Weighted 0.818628 (0.061067)\n",
      "logistic adam 1500 0.001 76 (50,): Macro 0.704298 (0.077071)\n",
      "Testing 1414/2880\n",
      "logistic adam 1500 0.001 76 (100,): Weighted 0.824024 (0.065203)\n",
      "logistic adam 1500 0.001 76 (100,): Macro 0.708348 (0.089623)\n",
      "Testing 1415/2880\n",
      "logistic adam 1500 0.001 76 (150,): Weighted 0.825179 (0.040862)\n",
      "logistic adam 1500 0.001 76 (150,): Macro 0.706769 (0.051434)\n",
      "Testing 1416/2880\n",
      "logistic adam 1500 0.001 76 (200,): Weighted 0.833876 (0.062082)\n",
      "logistic adam 1500 0.001 76 (200,): Macro 0.723651 (0.086101)\n",
      "Testing 1417/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic adam 1500 0.001 112 (50,): Weighted 0.814852 (0.063595)\n",
      "logistic adam 1500 0.001 112 (50,): Macro 0.703297 (0.079307)\n",
      "Testing 1418/2880\n",
      "logistic adam 1500 0.001 112 (100,): Weighted 0.818553 (0.061373)\n",
      "logistic adam 1500 0.001 112 (100,): Macro 0.700080 (0.078615)\n",
      "Testing 1419/2880\n",
      "logistic adam 1500 0.001 112 (150,): Weighted 0.834276 (0.064585)\n",
      "logistic adam 1500 0.001 112 (150,): Macro 0.724436 (0.089567)\n",
      "Testing 1420/2880\n",
      "logistic adam 1500 0.001 112 (200,): Weighted 0.817813 (0.080485)\n",
      "logistic adam 1500 0.001 112 (200,): Macro 0.703541 (0.110728)\n",
      "Testing 1421/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic adam 1500 0.0001 17 (50,): Weighted 0.805688 (0.056753)\n",
      "logistic adam 1500 0.0001 17 (50,): Macro 0.683748 (0.068623)\n",
      "Testing 1422/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic adam 1500 0.0001 17 (100,): Weighted 0.812566 (0.064835)\n",
      "logistic adam 1500 0.0001 17 (100,): Macro 0.695442 (0.082711)\n",
      "Testing 1423/2880\n",
      "logistic adam 1500 0.0001 17 (150,): Weighted 0.815854 (0.040990)\n",
      "logistic adam 1500 0.0001 17 (150,): Macro 0.692106 (0.048460)\n",
      "Testing 1424/2880\n",
      "logistic adam 1500 0.0001 17 (200,): Weighted 0.799310 (0.060451)\n",
      "logistic adam 1500 0.0001 17 (200,): Macro 0.675206 (0.073412)\n",
      "Testing 1425/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic adam 1500 0.0001 29 (50,): Weighted 0.823008 (0.068220)\n",
      "logistic adam 1500 0.0001 29 (50,): Macro 0.712514 (0.090368)\n",
      "Testing 1426/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic adam 1500 0.0001 29 (100,): Weighted 0.831478 (0.052472)\n",
      "logistic adam 1500 0.0001 29 (100,): Macro 0.719274 (0.067484)\n",
      "Testing 1427/2880\n",
      "logistic adam 1500 0.0001 29 (150,): Weighted 0.829630 (0.054993)\n",
      "logistic adam 1500 0.0001 29 (150,): Macro 0.713842 (0.073094)\n",
      "Testing 1428/2880\n",
      "logistic adam 1500 0.0001 29 (200,): Weighted 0.791575 (0.055970)\n",
      "logistic adam 1500 0.0001 29 (200,): Macro 0.662603 (0.065280)\n",
      "Testing 1429/2880\n",
      "logistic adam 1500 0.0001 42 (50,): Weighted 0.836641 (0.064563)\n",
      "logistic adam 1500 0.0001 42 (50,): Macro 0.720769 (0.096645)\n",
      "Testing 1430/2880\n",
      "logistic adam 1500 0.0001 42 (100,): Weighted 0.821862 (0.057330)\n",
      "logistic adam 1500 0.0001 42 (100,): Macro 0.709971 (0.071035)\n",
      "Testing 1431/2880\n",
      "logistic adam 1500 0.0001 42 (150,): Weighted 0.805979 (0.055283)\n",
      "logistic adam 1500 0.0001 42 (150,): Macro 0.680203 (0.068767)\n",
      "Testing 1432/2880\n",
      "logistic adam 1500 0.0001 42 (200,): Weighted 0.834276 (0.064585)\n",
      "logistic adam 1500 0.0001 42 (200,): Macro 0.724436 (0.089567)\n",
      "Testing 1433/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic adam 1500 0.0001 76 (50,): Weighted 0.818628 (0.061067)\n",
      "logistic adam 1500 0.0001 76 (50,): Macro 0.704298 (0.077071)\n",
      "Testing 1434/2880\n",
      "logistic adam 1500 0.0001 76 (100,): Weighted 0.815978 (0.072942)\n",
      "logistic adam 1500 0.0001 76 (100,): Macro 0.700231 (0.097566)\n",
      "Testing 1435/2880\n",
      "logistic adam 1500 0.0001 76 (150,): Weighted 0.825179 (0.040862)\n",
      "logistic adam 1500 0.0001 76 (150,): Macro 0.706769 (0.051434)\n",
      "Testing 1436/2880\n",
      "logistic adam 1500 0.0001 76 (200,): Weighted 0.833876 (0.062082)\n",
      "logistic adam 1500 0.0001 76 (200,): Macro 0.723651 (0.086101)\n",
      "Testing 1437/2880\n",
      "logistic adam 1500 0.0001 112 (50,): Weighted 0.825777 (0.054476)\n",
      "logistic adam 1500 0.0001 112 (50,): Macro 0.718865 (0.066681)\n",
      "Testing 1438/2880\n",
      "logistic adam 1500 0.0001 112 (100,): Weighted 0.818553 (0.061373)\n",
      "logistic adam 1500 0.0001 112 (100,): Macro 0.700080 (0.078615)\n",
      "Testing 1439/2880\n",
      "logistic adam 1500 0.0001 112 (150,): Weighted 0.834276 (0.064585)\n",
      "logistic adam 1500 0.0001 112 (150,): Macro 0.724436 (0.089567)\n",
      "Testing 1440/2880\n",
      "logistic adam 1500 0.0001 112 (200,): Weighted 0.817813 (0.080485)\n",
      "logistic adam 1500 0.0001 112 (200,): Macro 0.703541 (0.110728)\n",
      "Testing 1441/2880\n",
      "tanh lbfgs 500 0.1 17 (50,): Weighted 0.811519 (0.057333)\n",
      "tanh lbfgs 500 0.1 17 (50,): Macro 0.691556 (0.063505)\n",
      "Testing 1442/2880\n",
      "tanh lbfgs 500 0.1 17 (100,): Weighted 0.794218 (0.062138)\n",
      "tanh lbfgs 500 0.1 17 (100,): Macro 0.667781 (0.069383)\n",
      "Testing 1443/2880\n",
      "tanh lbfgs 500 0.1 17 (150,): Weighted 0.812504 (0.040348)\n",
      "tanh lbfgs 500 0.1 17 (150,): Macro 0.690639 (0.049884)\n",
      "Testing 1444/2880\n",
      "tanh lbfgs 500 0.1 17 (200,): Weighted 0.796576 (0.057520)\n",
      "tanh lbfgs 500 0.1 17 (200,): Macro 0.667595 (0.059947)\n",
      "Testing 1445/2880\n",
      "tanh lbfgs 500 0.1 29 (50,): Weighted 0.783522 (0.045269)\n",
      "tanh lbfgs 500 0.1 29 (50,): Macro 0.647251 (0.041208)\n",
      "Testing 1446/2880\n",
      "tanh lbfgs 500 0.1 29 (100,): Weighted 0.798777 (0.036893)\n",
      "tanh lbfgs 500 0.1 29 (100,): Macro 0.666196 (0.082948)\n",
      "Testing 1447/2880\n",
      "tanh lbfgs 500 0.1 29 (150,): Weighted 0.813905 (0.036276)\n",
      "tanh lbfgs 500 0.1 29 (150,): Macro 0.680443 (0.031752)\n",
      "Testing 1448/2880\n",
      "tanh lbfgs 500 0.1 29 (200,): Weighted 0.833243 (0.067064)\n",
      "tanh lbfgs 500 0.1 29 (200,): Macro 0.730711 (0.087970)\n",
      "Testing 1449/2880\n",
      "tanh lbfgs 500 0.1 42 (50,): Weighted 0.800382 (0.058733)\n",
      "tanh lbfgs 500 0.1 42 (50,): Macro 0.673359 (0.064661)\n",
      "Testing 1450/2880\n",
      "tanh lbfgs 500 0.1 42 (100,): Weighted 0.794484 (0.056158)\n",
      "tanh lbfgs 500 0.1 42 (100,): Macro 0.659050 (0.067862)\n",
      "Testing 1451/2880\n",
      "tanh lbfgs 500 0.1 42 (150,): Weighted 0.791711 (0.063130)\n",
      "tanh lbfgs 500 0.1 42 (150,): Macro 0.662268 (0.080526)\n",
      "Testing 1452/2880\n",
      "tanh lbfgs 500 0.1 42 (200,): Weighted 0.810293 (0.023663)\n",
      "tanh lbfgs 500 0.1 42 (200,): Macro 0.679529 (0.023605)\n",
      "Testing 1453/2880\n",
      "tanh lbfgs 500 0.1 76 (50,): Weighted 0.771291 (0.081619)\n",
      "tanh lbfgs 500 0.1 76 (50,): Macro 0.649125 (0.102485)\n",
      "Testing 1454/2880\n",
      "tanh lbfgs 500 0.1 76 (100,): Weighted 0.802075 (0.065521)\n",
      "tanh lbfgs 500 0.1 76 (100,): Macro 0.668225 (0.078971)\n",
      "Testing 1455/2880\n",
      "tanh lbfgs 500 0.1 76 (150,): Weighted 0.792158 (0.036404)\n",
      "tanh lbfgs 500 0.1 76 (150,): Macro 0.651564 (0.037928)\n",
      "Testing 1456/2880\n",
      "tanh lbfgs 500 0.1 76 (200,): Weighted 0.827218 (0.047596)\n",
      "tanh lbfgs 500 0.1 76 (200,): Macro 0.722055 (0.053141)\n",
      "Testing 1457/2880\n",
      "tanh lbfgs 500 0.1 112 (50,): Weighted 0.782241 (0.052812)\n",
      "tanh lbfgs 500 0.1 112 (50,): Macro 0.627487 (0.077238)\n",
      "Testing 1458/2880\n",
      "tanh lbfgs 500 0.1 112 (100,): Weighted 0.789033 (0.044316)\n",
      "tanh lbfgs 500 0.1 112 (100,): Macro 0.640335 (0.056743)\n",
      "Testing 1459/2880\n",
      "tanh lbfgs 500 0.1 112 (150,): Weighted 0.783730 (0.079414)\n",
      "tanh lbfgs 500 0.1 112 (150,): Macro 0.671254 (0.103176)\n",
      "Testing 1460/2880\n",
      "tanh lbfgs 500 0.1 112 (200,): Weighted 0.803777 (0.069304)\n",
      "tanh lbfgs 500 0.1 112 (200,): Macro 0.688473 (0.085261)\n",
      "Testing 1461/2880\n",
      "tanh lbfgs 500 0.01 17 (50,): Weighted 0.790435 (0.044047)\n",
      "tanh lbfgs 500 0.01 17 (50,): Macro 0.668445 (0.021594)\n",
      "Testing 1462/2880\n",
      "tanh lbfgs 500 0.01 17 (100,): Weighted 0.801005 (0.076887)\n",
      "tanh lbfgs 500 0.01 17 (100,): Macro 0.679014 (0.100749)\n",
      "Testing 1463/2880\n",
      "tanh lbfgs 500 0.01 17 (150,): Weighted 0.798629 (0.040837)\n",
      "tanh lbfgs 500 0.01 17 (150,): Macro 0.676053 (0.045310)\n",
      "Testing 1464/2880\n",
      "tanh lbfgs 500 0.01 17 (200,): Weighted 0.778744 (0.068265)\n",
      "tanh lbfgs 500 0.01 17 (200,): Macro 0.639389 (0.078560)\n",
      "Testing 1465/2880\n",
      "tanh lbfgs 500 0.01 29 (50,): Weighted 0.802415 (0.066000)\n",
      "tanh lbfgs 500 0.01 29 (50,): Macro 0.660350 (0.085688)\n",
      "Testing 1466/2880\n",
      "tanh lbfgs 500 0.01 29 (100,): Weighted 0.777918 (0.044956)\n",
      "tanh lbfgs 500 0.01 29 (100,): Macro 0.634235 (0.041374)\n",
      "Testing 1467/2880\n",
      "tanh lbfgs 500 0.01 29 (150,): Weighted 0.803053 (0.054681)\n",
      "tanh lbfgs 500 0.01 29 (150,): Macro 0.684868 (0.066234)\n",
      "Testing 1468/2880\n",
      "tanh lbfgs 500 0.01 29 (200,): Weighted 0.789446 (0.058877)\n",
      "tanh lbfgs 500 0.01 29 (200,): Macro 0.649819 (0.068800)\n",
      "Testing 1469/2880\n",
      "tanh lbfgs 500 0.01 42 (50,): Weighted 0.798636 (0.045475)\n",
      "tanh lbfgs 500 0.01 42 (50,): Macro 0.678640 (0.042605)\n",
      "Testing 1470/2880\n",
      "tanh lbfgs 500 0.01 42 (100,): Weighted 0.780665 (0.064994)\n",
      "tanh lbfgs 500 0.01 42 (100,): Macro 0.641917 (0.083256)\n",
      "Testing 1471/2880\n",
      "tanh lbfgs 500 0.01 42 (150,): Weighted 0.803904 (0.059501)\n",
      "tanh lbfgs 500 0.01 42 (150,): Macro 0.672234 (0.079165)\n",
      "Testing 1472/2880\n",
      "tanh lbfgs 500 0.01 42 (200,): Weighted 0.789300 (0.042376)\n",
      "tanh lbfgs 500 0.01 42 (200,): Macro 0.664420 (0.045662)\n",
      "Testing 1473/2880\n",
      "tanh lbfgs 500 0.01 76 (50,): Weighted 0.783705 (0.051809)\n",
      "tanh lbfgs 500 0.01 76 (50,): Macro 0.656103 (0.048448)\n",
      "Testing 1474/2880\n",
      "tanh lbfgs 500 0.01 76 (100,): Weighted 0.802816 (0.072533)\n",
      "tanh lbfgs 500 0.01 76 (100,): Macro 0.696299 (0.094077)\n",
      "Testing 1475/2880\n",
      "tanh lbfgs 500 0.01 76 (150,): Weighted 0.794086 (0.055755)\n",
      "tanh lbfgs 500 0.01 76 (150,): Macro 0.660763 (0.061467)\n",
      "Testing 1476/2880\n",
      "tanh lbfgs 500 0.01 76 (200,): Weighted 0.773960 (0.048908)\n",
      "tanh lbfgs 500 0.01 76 (200,): Macro 0.633104 (0.069920)\n",
      "Testing 1477/2880\n",
      "tanh lbfgs 500 0.01 112 (50,): Weighted 0.801267 (0.030647)\n",
      "tanh lbfgs 500 0.01 112 (50,): Macro 0.685072 (0.025143)\n",
      "Testing 1478/2880\n",
      "tanh lbfgs 500 0.01 112 (100,): Weighted 0.796654 (0.044354)\n",
      "tanh lbfgs 500 0.01 112 (100,): Macro 0.680741 (0.056849)\n",
      "Testing 1479/2880\n",
      "tanh lbfgs 500 0.01 112 (150,): Weighted 0.811573 (0.065003)\n",
      "tanh lbfgs 500 0.01 112 (150,): Macro 0.700182 (0.077402)\n",
      "Testing 1480/2880\n",
      "tanh lbfgs 500 0.01 112 (200,): Weighted 0.796575 (0.060909)\n",
      "tanh lbfgs 500 0.01 112 (200,): Macro 0.667409 (0.071174)\n",
      "Testing 1481/2880\n",
      "tanh lbfgs 500 0.001 17 (50,): Weighted 0.821508 (0.034066)\n",
      "tanh lbfgs 500 0.001 17 (50,): Macro 0.693481 (0.026375)\n",
      "Testing 1482/2880\n",
      "tanh lbfgs 500 0.001 17 (100,): Weighted 0.779572 (0.040321)\n",
      "tanh lbfgs 500 0.001 17 (100,): Macro 0.637793 (0.048316)\n",
      "Testing 1483/2880\n",
      "tanh lbfgs 500 0.001 17 (150,): Weighted 0.766253 (0.043695)\n",
      "tanh lbfgs 500 0.001 17 (150,): Macro 0.628184 (0.044197)\n",
      "Testing 1484/2880\n",
      "tanh lbfgs 500 0.001 17 (200,): Weighted 0.760410 (0.065914)\n",
      "tanh lbfgs 500 0.001 17 (200,): Macro 0.614291 (0.070988)\n",
      "Testing 1485/2880\n",
      "tanh lbfgs 500 0.001 29 (50,): Weighted 0.825408 (0.043407)\n",
      "tanh lbfgs 500 0.001 29 (50,): Macro 0.702384 (0.054659)\n",
      "Testing 1486/2880\n",
      "tanh lbfgs 500 0.001 29 (100,): Weighted 0.779702 (0.018314)\n",
      "tanh lbfgs 500 0.001 29 (100,): Macro 0.632097 (0.045694)\n",
      "Testing 1487/2880\n",
      "tanh lbfgs 500 0.001 29 (150,): Weighted 0.790279 (0.056448)\n",
      "tanh lbfgs 500 0.001 29 (150,): Macro 0.668141 (0.052253)\n",
      "Testing 1488/2880\n",
      "tanh lbfgs 500 0.001 29 (200,): Weighted 0.802216 (0.067759)\n",
      "tanh lbfgs 500 0.001 29 (200,): Macro 0.667185 (0.088949)\n",
      "Testing 1489/2880\n",
      "tanh lbfgs 500 0.001 42 (50,): Weighted 0.798922 (0.051862)\n",
      "tanh lbfgs 500 0.001 42 (50,): Macro 0.687858 (0.046472)\n",
      "Testing 1490/2880\n",
      "tanh lbfgs 500 0.001 42 (100,): Weighted 0.799968 (0.047332)\n",
      "tanh lbfgs 500 0.001 42 (100,): Macro 0.670447 (0.050520)\n",
      "Testing 1491/2880\n",
      "tanh lbfgs 500 0.001 42 (150,): Weighted 0.786958 (0.045301)\n",
      "tanh lbfgs 500 0.001 42 (150,): Macro 0.644964 (0.058893)\n",
      "Testing 1492/2880\n",
      "tanh lbfgs 500 0.001 42 (200,): Weighted 0.777266 (0.081737)\n",
      "tanh lbfgs 500 0.001 42 (200,): Macro 0.650034 (0.116418)\n",
      "Testing 1493/2880\n",
      "tanh lbfgs 500 0.001 76 (50,): Weighted 0.784523 (0.065993)\n",
      "tanh lbfgs 500 0.001 76 (50,): Macro 0.669554 (0.082225)\n",
      "Testing 1494/2880\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh lbfgs 500 0.001 76 (100,): Weighted 0.809071 (0.072467)\n",
      "tanh lbfgs 500 0.001 76 (100,): Macro 0.704398 (0.092233)\n",
      "Testing 1495/2880\n",
      "tanh lbfgs 500 0.001 76 (150,): Weighted 0.786099 (0.072085)\n",
      "tanh lbfgs 500 0.001 76 (150,): Macro 0.648781 (0.096117)\n",
      "Testing 1496/2880\n",
      "tanh lbfgs 500 0.001 76 (200,): Weighted 0.786167 (0.052299)\n",
      "tanh lbfgs 500 0.001 76 (200,): Macro 0.640691 (0.064289)\n",
      "Testing 1497/2880\n",
      "tanh lbfgs 500 0.001 112 (50,): Weighted 0.774985 (0.054153)\n",
      "tanh lbfgs 500 0.001 112 (50,): Macro 0.642860 (0.065709)\n",
      "Testing 1498/2880\n",
      "tanh lbfgs 500 0.001 112 (100,): Weighted 0.780114 (0.038458)\n",
      "tanh lbfgs 500 0.001 112 (100,): Macro 0.632742 (0.049923)\n",
      "Testing 1499/2880\n",
      "tanh lbfgs 500 0.001 112 (150,): Weighted 0.789964 (0.043664)\n",
      "tanh lbfgs 500 0.001 112 (150,): Macro 0.656151 (0.045459)\n",
      "Testing 1500/2880\n",
      "tanh lbfgs 500 0.001 112 (200,): Weighted 0.800786 (0.046475)\n",
      "tanh lbfgs 500 0.001 112 (200,): Macro 0.672340 (0.050598)\n",
      "Testing 1501/2880\n",
      "tanh lbfgs 500 0.0001 17 (50,): Weighted 0.810802 (0.048023)\n",
      "tanh lbfgs 500 0.0001 17 (50,): Macro 0.687782 (0.061024)\n",
      "Testing 1502/2880\n",
      "tanh lbfgs 500 0.0001 17 (100,): Weighted 0.735986 (0.070575)\n",
      "tanh lbfgs 500 0.0001 17 (100,): Macro 0.571090 (0.066710)\n",
      "Testing 1503/2880\n",
      "tanh lbfgs 500 0.0001 17 (150,): Weighted 0.795582 (0.061023)\n",
      "tanh lbfgs 500 0.0001 17 (150,): Macro 0.666653 (0.075764)\n",
      "Testing 1504/2880\n",
      "tanh lbfgs 500 0.0001 17 (200,): Weighted 0.768184 (0.040226)\n",
      "tanh lbfgs 500 0.0001 17 (200,): Macro 0.616114 (0.042457)\n",
      "Testing 1505/2880\n",
      "tanh lbfgs 500 0.0001 29 (50,): Weighted 0.778560 (0.070442)\n",
      "tanh lbfgs 500 0.0001 29 (50,): Macro 0.651525 (0.088025)\n",
      "Testing 1506/2880\n",
      "tanh lbfgs 500 0.0001 29 (100,): Weighted 0.775107 (0.044162)\n",
      "tanh lbfgs 500 0.0001 29 (100,): Macro 0.642296 (0.065881)\n",
      "Testing 1507/2880\n",
      "tanh lbfgs 500 0.0001 29 (150,): Weighted 0.792140 (0.060296)\n",
      "tanh lbfgs 500 0.0001 29 (150,): Macro 0.661197 (0.057531)\n",
      "Testing 1508/2880\n",
      "tanh lbfgs 500 0.0001 29 (200,): Weighted 0.792065 (0.080200)\n",
      "tanh lbfgs 500 0.0001 29 (200,): Macro 0.659266 (0.101187)\n",
      "Testing 1509/2880\n",
      "tanh lbfgs 500 0.0001 42 (50,): Weighted 0.801998 (0.060997)\n",
      "tanh lbfgs 500 0.0001 42 (50,): Macro 0.682340 (0.069532)\n",
      "Testing 1510/2880\n",
      "tanh lbfgs 500 0.0001 42 (100,): Weighted 0.798390 (0.045683)\n",
      "tanh lbfgs 500 0.0001 42 (100,): Macro 0.663987 (0.060363)\n",
      "Testing 1511/2880\n",
      "tanh lbfgs 500 0.0001 42 (150,): Weighted 0.777374 (0.045751)\n",
      "tanh lbfgs 500 0.0001 42 (150,): Macro 0.624960 (0.057804)\n",
      "Testing 1512/2880\n",
      "tanh lbfgs 500 0.0001 42 (200,): Weighted 0.734656 (0.067669)\n",
      "tanh lbfgs 500 0.0001 42 (200,): Macro 0.578545 (0.074558)\n",
      "Testing 1513/2880\n",
      "tanh lbfgs 500 0.0001 76 (50,): Weighted 0.783755 (0.074194)\n",
      "tanh lbfgs 500 0.0001 76 (50,): Macro 0.673800 (0.100119)\n",
      "Testing 1514/2880\n",
      "tanh lbfgs 500 0.0001 76 (100,): Weighted 0.814725 (0.062237)\n",
      "tanh lbfgs 500 0.0001 76 (100,): Macro 0.704156 (0.087035)\n",
      "Testing 1515/2880\n",
      "tanh lbfgs 500 0.0001 76 (150,): Weighted 0.776922 (0.075797)\n",
      "tanh lbfgs 500 0.0001 76 (150,): Macro 0.626777 (0.096917)\n",
      "Testing 1516/2880\n",
      "tanh lbfgs 500 0.0001 76 (200,): Weighted 0.783246 (0.076549)\n",
      "tanh lbfgs 500 0.0001 76 (200,): Macro 0.658820 (0.100069)\n",
      "Testing 1517/2880\n",
      "tanh lbfgs 500 0.0001 112 (50,): Weighted 0.779125 (0.082072)\n",
      "tanh lbfgs 500 0.0001 112 (50,): Macro 0.676566 (0.102361)\n",
      "Testing 1518/2880\n",
      "tanh lbfgs 500 0.0001 112 (100,): Weighted 0.791301 (0.028280)\n",
      "tanh lbfgs 500 0.0001 112 (100,): Macro 0.649616 (0.017096)\n",
      "Testing 1519/2880\n",
      "tanh lbfgs 500 0.0001 112 (150,): Weighted 0.768443 (0.084627)\n",
      "tanh lbfgs 500 0.0001 112 (150,): Macro 0.626847 (0.105031)\n",
      "Testing 1520/2880\n",
      "tanh lbfgs 500 0.0001 112 (200,): Weighted 0.797030 (0.059927)\n",
      "tanh lbfgs 500 0.0001 112 (200,): Macro 0.666618 (0.087941)\n",
      "Testing 1521/2880\n",
      "tanh lbfgs 1000 0.1 17 (50,): Weighted 0.817316 (0.025917)\n",
      "tanh lbfgs 1000 0.1 17 (50,): Macro 0.698648 (0.042571)\n",
      "Testing 1522/2880\n",
      "tanh lbfgs 1000 0.1 17 (100,): Weighted 0.815272 (0.049472)\n",
      "tanh lbfgs 1000 0.1 17 (100,): Macro 0.692151 (0.061747)\n",
      "Testing 1523/2880\n",
      "tanh lbfgs 1000 0.1 17 (150,): Weighted 0.807530 (0.030772)\n",
      "tanh lbfgs 1000 0.1 17 (150,): Macro 0.680761 (0.016962)\n",
      "Testing 1524/2880\n",
      "tanh lbfgs 1000 0.1 17 (200,): Weighted 0.795878 (0.054696)\n",
      "tanh lbfgs 1000 0.1 17 (200,): Macro 0.664815 (0.061516)\n",
      "Testing 1525/2880\n",
      "tanh lbfgs 1000 0.1 29 (50,): Weighted 0.790875 (0.035203)\n",
      "tanh lbfgs 1000 0.1 29 (50,): Macro 0.654275 (0.048277)\n",
      "Testing 1526/2880\n",
      "tanh lbfgs 1000 0.1 29 (100,): Weighted 0.807173 (0.025091)\n",
      "tanh lbfgs 1000 0.1 29 (100,): Macro 0.689040 (0.028856)\n",
      "Testing 1527/2880\n",
      "tanh lbfgs 1000 0.1 29 (150,): Weighted 0.814364 (0.047276)\n",
      "tanh lbfgs 1000 0.1 29 (150,): Macro 0.688142 (0.059196)\n",
      "Testing 1528/2880\n",
      "tanh lbfgs 1000 0.1 29 (200,): Weighted 0.832794 (0.066463)\n",
      "tanh lbfgs 1000 0.1 29 (200,): Macro 0.724208 (0.092797)\n",
      "Testing 1529/2880\n",
      "tanh lbfgs 1000 0.1 42 (50,): Weighted 0.799274 (0.049747)\n",
      "tanh lbfgs 1000 0.1 42 (50,): Macro 0.672508 (0.069962)\n",
      "Testing 1530/2880\n",
      "tanh lbfgs 1000 0.1 42 (100,): Weighted 0.820539 (0.066896)\n",
      "tanh lbfgs 1000 0.1 42 (100,): Macro 0.699675 (0.097230)\n",
      "Testing 1531/2880\n",
      "tanh lbfgs 1000 0.1 42 (150,): Weighted 0.812373 (0.044280)\n",
      "tanh lbfgs 1000 0.1 42 (150,): Macro 0.692166 (0.046018)\n",
      "Testing 1532/2880\n",
      "tanh lbfgs 1000 0.1 42 (200,): Weighted 0.830139 (0.051638)\n",
      "tanh lbfgs 1000 0.1 42 (200,): Macro 0.722370 (0.063262)\n",
      "Testing 1533/2880\n",
      "tanh lbfgs 1000 0.1 76 (50,): Weighted 0.776391 (0.064116)\n",
      "tanh lbfgs 1000 0.1 76 (50,): Macro 0.640083 (0.079864)\n",
      "Testing 1534/2880\n",
      "tanh lbfgs 1000 0.1 76 (100,): Weighted 0.805922 (0.053273)\n",
      "tanh lbfgs 1000 0.1 76 (100,): Macro 0.676384 (0.059762)\n",
      "Testing 1535/2880\n",
      "tanh lbfgs 1000 0.1 76 (150,): Weighted 0.821826 (0.041407)\n",
      "tanh lbfgs 1000 0.1 76 (150,): Macro 0.708940 (0.039140)\n",
      "Testing 1536/2880\n",
      "tanh lbfgs 1000 0.1 76 (200,): Weighted 0.819431 (0.024091)\n",
      "tanh lbfgs 1000 0.1 76 (200,): Macro 0.704331 (0.018999)\n",
      "Testing 1537/2880\n",
      "tanh lbfgs 1000 0.1 112 (50,): Weighted 0.760473 (0.060069)\n",
      "tanh lbfgs 1000 0.1 112 (50,): Macro 0.603394 (0.078134)\n",
      "Testing 1538/2880\n",
      "tanh lbfgs 1000 0.1 112 (100,): Weighted 0.803186 (0.068292)\n",
      "tanh lbfgs 1000 0.1 112 (100,): Macro 0.671841 (0.092049)\n",
      "Testing 1539/2880\n",
      "tanh lbfgs 1000 0.1 112 (150,): Weighted 0.793910 (0.037888)\n",
      "tanh lbfgs 1000 0.1 112 (150,): Macro 0.661342 (0.050643)\n",
      "Testing 1540/2880\n",
      "tanh lbfgs 1000 0.1 112 (200,): Weighted 0.808519 (0.055457)\n",
      "tanh lbfgs 1000 0.1 112 (200,): Macro 0.687716 (0.070457)\n",
      "Testing 1541/2880\n",
      "tanh lbfgs 1000 0.01 17 (50,): Weighted 0.789635 (0.034459)\n",
      "tanh lbfgs 1000 0.01 17 (50,): Macro 0.662506 (0.018819)\n",
      "Testing 1542/2880\n",
      "tanh lbfgs 1000 0.01 17 (100,): Weighted 0.798461 (0.044949)\n",
      "tanh lbfgs 1000 0.01 17 (100,): Macro 0.666171 (0.049616)\n",
      "Testing 1543/2880\n",
      "tanh lbfgs 1000 0.01 17 (150,): Weighted 0.770972 (0.029846)\n",
      "tanh lbfgs 1000 0.01 17 (150,): Macro 0.628221 (0.054260)\n",
      "Testing 1544/2880\n",
      "tanh lbfgs 1000 0.01 17 (200,): Weighted 0.782606 (0.047472)\n",
      "tanh lbfgs 1000 0.01 17 (200,): Macro 0.641814 (0.061086)\n",
      "Testing 1545/2880\n",
      "tanh lbfgs 1000 0.01 29 (50,): Weighted 0.794382 (0.074165)\n",
      "tanh lbfgs 1000 0.01 29 (50,): Macro 0.665855 (0.082049)\n",
      "Testing 1546/2880\n",
      "tanh lbfgs 1000 0.01 29 (100,): Weighted 0.771615 (0.022007)\n",
      "tanh lbfgs 1000 0.01 29 (100,): Macro 0.624855 (0.016974)\n",
      "Testing 1547/2880\n",
      "tanh lbfgs 1000 0.01 29 (150,): Weighted 0.821657 (0.060702)\n",
      "tanh lbfgs 1000 0.01 29 (150,): Macro 0.710613 (0.075304)\n",
      "Testing 1548/2880\n",
      "tanh lbfgs 1000 0.01 29 (200,): Weighted 0.804119 (0.056680)\n",
      "tanh lbfgs 1000 0.01 29 (200,): Macro 0.678311 (0.069647)\n",
      "Testing 1549/2880\n",
      "tanh lbfgs 1000 0.01 42 (50,): Weighted 0.807286 (0.065171)\n",
      "tanh lbfgs 1000 0.01 42 (50,): Macro 0.699848 (0.075662)\n",
      "Testing 1550/2880\n",
      "tanh lbfgs 1000 0.01 42 (100,): Weighted 0.796548 (0.059962)\n",
      "tanh lbfgs 1000 0.01 42 (100,): Macro 0.670286 (0.089038)\n",
      "Testing 1551/2880\n",
      "tanh lbfgs 1000 0.01 42 (150,): Weighted 0.805203 (0.049347)\n",
      "tanh lbfgs 1000 0.01 42 (150,): Macro 0.680303 (0.052037)\n",
      "Testing 1552/2880\n",
      "tanh lbfgs 1000 0.01 42 (200,): Weighted 0.784977 (0.045309)\n",
      "tanh lbfgs 1000 0.01 42 (200,): Macro 0.643175 (0.049566)\n",
      "Testing 1553/2880\n",
      "tanh lbfgs 1000 0.01 76 (50,): Weighted 0.792783 (0.045101)\n",
      "tanh lbfgs 1000 0.01 76 (50,): Macro 0.678859 (0.039740)\n",
      "Testing 1554/2880\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh lbfgs 1000 0.01 76 (100,): Weighted 0.801357 (0.059328)\n",
      "tanh lbfgs 1000 0.01 76 (100,): Macro 0.688145 (0.085646)\n",
      "Testing 1555/2880\n",
      "tanh lbfgs 1000 0.01 76 (150,): Weighted 0.815318 (0.060161)\n",
      "tanh lbfgs 1000 0.01 76 (150,): Macro 0.701434 (0.063219)\n",
      "Testing 1556/2880\n",
      "tanh lbfgs 1000 0.01 76 (200,): Weighted 0.777671 (0.049801)\n",
      "tanh lbfgs 1000 0.01 76 (200,): Macro 0.626794 (0.055299)\n",
      "Testing 1557/2880\n",
      "tanh lbfgs 1000 0.01 112 (50,): Weighted 0.804645 (0.031223)\n",
      "tanh lbfgs 1000 0.01 112 (50,): Macro 0.675793 (0.021282)\n",
      "Testing 1558/2880\n",
      "tanh lbfgs 1000 0.01 112 (100,): Weighted 0.749687 (0.041719)\n",
      "tanh lbfgs 1000 0.01 112 (100,): Macro 0.588761 (0.022451)\n",
      "Testing 1559/2880\n",
      "tanh lbfgs 1000 0.01 112 (150,): Weighted 0.810413 (0.038712)\n",
      "tanh lbfgs 1000 0.01 112 (150,): Macro 0.682486 (0.052681)\n",
      "Testing 1560/2880\n",
      "tanh lbfgs 1000 0.01 112 (200,): Weighted 0.799626 (0.061592)\n",
      "tanh lbfgs 1000 0.01 112 (200,): Macro 0.676331 (0.086514)\n",
      "Testing 1561/2880\n",
      "tanh lbfgs 1000 0.001 17 (50,): Weighted 0.829839 (0.023356)\n",
      "tanh lbfgs 1000 0.001 17 (50,): Macro 0.708814 (0.021928)\n",
      "Testing 1562/2880\n",
      "tanh lbfgs 1000 0.001 17 (100,): Weighted 0.812090 (0.065521)\n",
      "tanh lbfgs 1000 0.001 17 (100,): Macro 0.689039 (0.084060)\n",
      "Testing 1563/2880\n",
      "tanh lbfgs 1000 0.001 17 (150,): Weighted 0.772970 (0.041720)\n",
      "tanh lbfgs 1000 0.001 17 (150,): Macro 0.632314 (0.044607)\n",
      "Testing 1564/2880\n",
      "tanh lbfgs 1000 0.001 17 (200,): Weighted 0.780296 (0.072249)\n",
      "tanh lbfgs 1000 0.001 17 (200,): Macro 0.650038 (0.094235)\n",
      "Testing 1565/2880\n",
      "tanh lbfgs 1000 0.001 29 (50,): Weighted 0.803795 (0.060478)\n",
      "tanh lbfgs 1000 0.001 29 (50,): Macro 0.671584 (0.071231)\n",
      "Testing 1566/2880\n",
      "tanh lbfgs 1000 0.001 29 (100,): Weighted 0.803457 (0.035570)\n",
      "tanh lbfgs 1000 0.001 29 (100,): Macro 0.672483 (0.038135)\n",
      "Testing 1567/2880\n",
      "tanh lbfgs 1000 0.001 29 (150,): Weighted 0.783693 (0.042022)\n",
      "tanh lbfgs 1000 0.001 29 (150,): Macro 0.641022 (0.059594)\n",
      "Testing 1568/2880\n",
      "tanh lbfgs 1000 0.001 29 (200,): Weighted 0.806238 (0.032278)\n",
      "tanh lbfgs 1000 0.001 29 (200,): Macro 0.672858 (0.030080)\n",
      "Testing 1569/2880\n",
      "tanh lbfgs 1000 0.001 42 (50,): Weighted 0.795107 (0.050859)\n",
      "tanh lbfgs 1000 0.001 42 (50,): Macro 0.679994 (0.043188)\n",
      "Testing 1570/2880\n",
      "tanh lbfgs 1000 0.001 42 (100,): Weighted 0.827474 (0.073249)\n",
      "tanh lbfgs 1000 0.001 42 (100,): Macro 0.715766 (0.097960)\n",
      "Testing 1571/2880\n",
      "tanh lbfgs 1000 0.001 42 (150,): Weighted 0.783499 (0.020082)\n",
      "tanh lbfgs 1000 0.001 42 (150,): Macro 0.618832 (0.020580)\n",
      "Testing 1572/2880\n",
      "tanh lbfgs 1000 0.001 42 (200,): Weighted 0.790325 (0.078182)\n",
      "tanh lbfgs 1000 0.001 42 (200,): Macro 0.673685 (0.103892)\n",
      "Testing 1573/2880\n",
      "tanh lbfgs 1000 0.001 76 (50,): Weighted 0.797534 (0.074566)\n",
      "tanh lbfgs 1000 0.001 76 (50,): Macro 0.674459 (0.099611)\n",
      "Testing 1574/2880\n",
      "tanh lbfgs 1000 0.001 76 (100,): Weighted 0.811560 (0.078826)\n",
      "tanh lbfgs 1000 0.001 76 (100,): Macro 0.703038 (0.109769)\n",
      "Testing 1575/2880\n",
      "tanh lbfgs 1000 0.001 76 (150,): Weighted 0.812554 (0.039184)\n",
      "tanh lbfgs 1000 0.001 76 (150,): Macro 0.686538 (0.049674)\n",
      "Testing 1576/2880\n",
      "tanh lbfgs 1000 0.001 76 (200,): Weighted 0.797659 (0.061858)\n",
      "tanh lbfgs 1000 0.001 76 (200,): Macro 0.671996 (0.081813)\n",
      "Testing 1577/2880\n",
      "tanh lbfgs 1000 0.001 112 (50,): Weighted 0.770634 (0.058964)\n",
      "tanh lbfgs 1000 0.001 112 (50,): Macro 0.618725 (0.068097)\n",
      "Testing 1578/2880\n",
      "tanh lbfgs 1000 0.001 112 (100,): Weighted 0.777908 (0.051561)\n",
      "tanh lbfgs 1000 0.001 112 (100,): Macro 0.641347 (0.058224)\n",
      "Testing 1579/2880\n",
      "tanh lbfgs 1000 0.001 112 (150,): Weighted 0.780423 (0.030131)\n",
      "tanh lbfgs 1000 0.001 112 (150,): Macro 0.644079 (0.034214)\n",
      "Testing 1580/2880\n",
      "tanh lbfgs 1000 0.001 112 (200,): Weighted 0.805408 (0.039144)\n",
      "tanh lbfgs 1000 0.001 112 (200,): Macro 0.686634 (0.037660)\n",
      "Testing 1581/2880\n",
      "tanh lbfgs 1000 0.0001 17 (50,): Weighted 0.819694 (0.048808)\n",
      "tanh lbfgs 1000 0.0001 17 (50,): Macro 0.698438 (0.076410)\n",
      "Testing 1582/2880\n",
      "tanh lbfgs 1000 0.0001 17 (100,): Weighted 0.763935 (0.046505)\n",
      "tanh lbfgs 1000 0.0001 17 (100,): Macro 0.621326 (0.053488)\n",
      "Testing 1583/2880\n",
      "tanh lbfgs 1000 0.0001 17 (150,): Weighted 0.788626 (0.050979)\n",
      "tanh lbfgs 1000 0.0001 17 (150,): Macro 0.658782 (0.063389)\n",
      "Testing 1584/2880\n",
      "tanh lbfgs 1000 0.0001 17 (200,): Weighted 0.763375 (0.041662)\n",
      "tanh lbfgs 1000 0.0001 17 (200,): Macro 0.609911 (0.044253)\n",
      "Testing 1585/2880\n",
      "tanh lbfgs 1000 0.0001 29 (50,): Weighted 0.764100 (0.055997)\n",
      "tanh lbfgs 1000 0.0001 29 (50,): Macro 0.635584 (0.067618)\n",
      "Testing 1586/2880\n",
      "tanh lbfgs 1000 0.0001 29 (100,): Weighted 0.754732 (0.041004)\n",
      "tanh lbfgs 1000 0.0001 29 (100,): Macro 0.611019 (0.058505)\n",
      "Testing 1587/2880\n",
      "tanh lbfgs 1000 0.0001 29 (150,): Weighted 0.779500 (0.045351)\n",
      "tanh lbfgs 1000 0.0001 29 (150,): Macro 0.644047 (0.050823)\n",
      "Testing 1588/2880\n",
      "tanh lbfgs 1000 0.0001 29 (200,): Weighted 0.801431 (0.069439)\n",
      "tanh lbfgs 1000 0.0001 29 (200,): Macro 0.668905 (0.091601)\n",
      "Testing 1589/2880\n",
      "tanh lbfgs 1000 0.0001 42 (50,): Weighted 0.801045 (0.044692)\n",
      "tanh lbfgs 1000 0.0001 42 (50,): Macro 0.680448 (0.050663)\n",
      "Testing 1590/2880\n",
      "tanh lbfgs 1000 0.0001 42 (100,): Weighted 0.793277 (0.045292)\n",
      "tanh lbfgs 1000 0.0001 42 (100,): Macro 0.657086 (0.058217)\n",
      "Testing 1591/2880\n",
      "tanh lbfgs 1000 0.0001 42 (150,): Weighted 0.792338 (0.047645)\n",
      "tanh lbfgs 1000 0.0001 42 (150,): Macro 0.651438 (0.040768)\n",
      "Testing 1592/2880\n",
      "tanh lbfgs 1000 0.0001 42 (200,): Weighted 0.782581 (0.047818)\n",
      "tanh lbfgs 1000 0.0001 42 (200,): Macro 0.650156 (0.065378)\n",
      "Testing 1593/2880\n",
      "tanh lbfgs 1000 0.0001 76 (50,): Weighted 0.783317 (0.084729)\n",
      "tanh lbfgs 1000 0.0001 76 (50,): Macro 0.677021 (0.110712)\n",
      "Testing 1594/2880\n",
      "tanh lbfgs 1000 0.0001 76 (100,): Weighted 0.795330 (0.064986)\n",
      "tanh lbfgs 1000 0.0001 76 (100,): Macro 0.678162 (0.093442)\n",
      "Testing 1595/2880\n",
      "tanh lbfgs 1000 0.0001 76 (150,): Weighted 0.763212 (0.072646)\n",
      "tanh lbfgs 1000 0.0001 76 (150,): Macro 0.614360 (0.090378)\n",
      "Testing 1596/2880\n",
      "tanh lbfgs 1000 0.0001 76 (200,): Weighted 0.773736 (0.065905)\n",
      "tanh lbfgs 1000 0.0001 76 (200,): Macro 0.650878 (0.088344)\n",
      "Testing 1597/2880\n",
      "tanh lbfgs 1000 0.0001 112 (50,): Weighted 0.783267 (0.083666)\n",
      "tanh lbfgs 1000 0.0001 112 (50,): Macro 0.683503 (0.104180)\n",
      "Testing 1598/2880\n",
      "tanh lbfgs 1000 0.0001 112 (100,): Weighted 0.805424 (0.031037)\n",
      "tanh lbfgs 1000 0.0001 112 (100,): Macro 0.679179 (0.032862)\n",
      "Testing 1599/2880\n",
      "tanh lbfgs 1000 0.0001 112 (150,): Weighted 0.778829 (0.089656)\n",
      "tanh lbfgs 1000 0.0001 112 (150,): Macro 0.646770 (0.113643)\n",
      "Testing 1600/2880\n",
      "tanh lbfgs 1000 0.0001 112 (200,): Weighted 0.793448 (0.044438)\n",
      "tanh lbfgs 1000 0.0001 112 (200,): Macro 0.656277 (0.053344)\n",
      "Testing 1601/2880\n",
      "tanh lbfgs 1500 0.1 17 (50,): Weighted 0.804811 (0.026745)\n",
      "tanh lbfgs 1500 0.1 17 (50,): Macro 0.671958 (0.037467)\n",
      "Testing 1602/2880\n",
      "tanh lbfgs 1500 0.1 17 (100,): Weighted 0.825975 (0.050504)\n",
      "tanh lbfgs 1500 0.1 17 (100,): Macro 0.706261 (0.061240)\n",
      "Testing 1603/2880\n",
      "tanh lbfgs 1500 0.1 17 (150,): Weighted 0.821218 (0.063961)\n",
      "tanh lbfgs 1500 0.1 17 (150,): Macro 0.702774 (0.086575)\n",
      "Testing 1604/2880\n",
      "tanh lbfgs 1500 0.1 17 (200,): Weighted 0.821768 (0.041435)\n",
      "tanh lbfgs 1500 0.1 17 (200,): Macro 0.706125 (0.049431)\n",
      "Testing 1605/2880\n",
      "tanh lbfgs 1500 0.1 29 (50,): Weighted 0.801149 (0.029182)\n",
      "tanh lbfgs 1500 0.1 29 (50,): Macro 0.663735 (0.056818)\n",
      "Testing 1606/2880\n",
      "tanh lbfgs 1500 0.1 29 (100,): Weighted 0.801571 (0.021030)\n",
      "tanh lbfgs 1500 0.1 29 (100,): Macro 0.674106 (0.026415)\n",
      "Testing 1607/2880\n",
      "tanh lbfgs 1500 0.1 29 (150,): Weighted 0.810067 (0.062772)\n",
      "tanh lbfgs 1500 0.1 29 (150,): Macro 0.683852 (0.086059)\n",
      "Testing 1608/2880\n",
      "tanh lbfgs 1500 0.1 29 (200,): Weighted 0.842521 (0.059907)\n",
      "tanh lbfgs 1500 0.1 29 (200,): Macro 0.744233 (0.077103)\n",
      "Testing 1609/2880\n",
      "tanh lbfgs 1500 0.1 42 (50,): Weighted 0.782374 (0.045934)\n",
      "tanh lbfgs 1500 0.1 42 (50,): Macro 0.645985 (0.044238)\n",
      "Testing 1610/2880\n",
      "tanh lbfgs 1500 0.1 42 (100,): Weighted 0.818648 (0.032521)\n",
      "tanh lbfgs 1500 0.1 42 (100,): Macro 0.698232 (0.028239)\n",
      "Testing 1611/2880\n",
      "tanh lbfgs 1500 0.1 42 (150,): Weighted 0.819350 (0.030454)\n",
      "tanh lbfgs 1500 0.1 42 (150,): Macro 0.704590 (0.039437)\n",
      "Testing 1612/2880\n",
      "tanh lbfgs 1500 0.1 42 (200,): Weighted 0.810230 (0.052967)\n",
      "tanh lbfgs 1500 0.1 42 (200,): Macro 0.689987 (0.072130)\n",
      "Testing 1613/2880\n",
      "tanh lbfgs 1500 0.1 76 (50,): Weighted 0.779819 (0.061611)\n",
      "tanh lbfgs 1500 0.1 76 (50,): Macro 0.648242 (0.072998)\n",
      "Testing 1614/2880\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh lbfgs 1500 0.1 76 (100,): Weighted 0.783895 (0.037301)\n",
      "tanh lbfgs 1500 0.1 76 (100,): Macro 0.649970 (0.033832)\n",
      "Testing 1615/2880\n",
      "tanh lbfgs 1500 0.1 76 (150,): Weighted 0.807116 (0.049536)\n",
      "tanh lbfgs 1500 0.1 76 (150,): Macro 0.682091 (0.053690)\n",
      "Testing 1616/2880\n",
      "tanh lbfgs 1500 0.1 76 (200,): Weighted 0.815768 (0.037642)\n",
      "tanh lbfgs 1500 0.1 76 (200,): Macro 0.694168 (0.035288)\n",
      "Testing 1617/2880\n",
      "tanh lbfgs 1500 0.1 112 (50,): Weighted 0.753185 (0.091137)\n",
      "tanh lbfgs 1500 0.1 112 (50,): Macro 0.607690 (0.115035)\n",
      "Testing 1618/2880\n",
      "tanh lbfgs 1500 0.1 112 (100,): Weighted 0.812484 (0.073041)\n",
      "tanh lbfgs 1500 0.1 112 (100,): Macro 0.696829 (0.095586)\n",
      "Testing 1619/2880\n",
      "tanh lbfgs 1500 0.1 112 (150,): Weighted 0.813551 (0.041899)\n",
      "tanh lbfgs 1500 0.1 112 (150,): Macro 0.692038 (0.048848)\n",
      "Testing 1620/2880\n",
      "tanh lbfgs 1500 0.1 112 (200,): Weighted 0.826434 (0.052364)\n",
      "tanh lbfgs 1500 0.1 112 (200,): Macro 0.707417 (0.062165)\n",
      "Testing 1621/2880\n",
      "tanh lbfgs 1500 0.01 17 (50,): Weighted 0.783066 (0.036753)\n",
      "tanh lbfgs 1500 0.01 17 (50,): Macro 0.656262 (0.014321)\n",
      "Testing 1622/2880\n",
      "tanh lbfgs 1500 0.01 17 (100,): Weighted 0.806164 (0.060874)\n",
      "tanh lbfgs 1500 0.01 17 (100,): Macro 0.688802 (0.073127)\n",
      "Testing 1623/2880\n",
      "tanh lbfgs 1500 0.01 17 (150,): Weighted 0.787647 (0.019757)\n",
      "tanh lbfgs 1500 0.01 17 (150,): Macro 0.654409 (0.046275)\n",
      "Testing 1624/2880\n",
      "tanh lbfgs 1500 0.01 17 (200,): Weighted 0.813414 (0.069960)\n",
      "tanh lbfgs 1500 0.01 17 (200,): Macro 0.691304 (0.097037)\n",
      "Testing 1625/2880\n",
      "tanh lbfgs 1500 0.01 29 (50,): Weighted 0.816326 (0.063950)\n",
      "tanh lbfgs 1500 0.01 29 (50,): Macro 0.704759 (0.064985)\n",
      "Testing 1626/2880\n",
      "tanh lbfgs 1500 0.01 29 (100,): Weighted 0.763229 (0.036739)\n",
      "tanh lbfgs 1500 0.01 29 (100,): Macro 0.613607 (0.054260)\n",
      "Testing 1627/2880\n",
      "tanh lbfgs 1500 0.01 29 (150,): Weighted 0.802577 (0.058031)\n",
      "tanh lbfgs 1500 0.01 29 (150,): Macro 0.675391 (0.075145)\n",
      "Testing 1628/2880\n",
      "tanh lbfgs 1500 0.01 29 (200,): Weighted 0.806869 (0.069478)\n",
      "tanh lbfgs 1500 0.01 29 (200,): Macro 0.687146 (0.097037)\n",
      "Testing 1629/2880\n",
      "tanh lbfgs 1500 0.01 42 (50,): Weighted 0.813659 (0.066673)\n",
      "tanh lbfgs 1500 0.01 42 (50,): Macro 0.712351 (0.083217)\n",
      "Testing 1630/2880\n",
      "tanh lbfgs 1500 0.01 42 (100,): Weighted 0.810555 (0.037784)\n",
      "tanh lbfgs 1500 0.01 42 (100,): Macro 0.682694 (0.044101)\n",
      "Testing 1631/2880\n",
      "tanh lbfgs 1500 0.01 42 (150,): Weighted 0.834148 (0.048909)\n",
      "tanh lbfgs 1500 0.01 42 (150,): Macro 0.735337 (0.053365)\n",
      "Testing 1632/2880\n",
      "tanh lbfgs 1500 0.01 42 (200,): Weighted 0.791451 (0.031978)\n",
      "tanh lbfgs 1500 0.01 42 (200,): Macro 0.649763 (0.016368)\n",
      "Testing 1633/2880\n",
      "tanh lbfgs 1500 0.01 76 (50,): Weighted 0.766261 (0.060876)\n",
      "tanh lbfgs 1500 0.01 76 (50,): Macro 0.628894 (0.069857)\n",
      "Testing 1634/2880\n",
      "tanh lbfgs 1500 0.01 76 (100,): Weighted 0.797491 (0.038223)\n",
      "tanh lbfgs 1500 0.01 76 (100,): Macro 0.677032 (0.057912)\n",
      "Testing 1635/2880\n",
      "tanh lbfgs 1500 0.01 76 (150,): Weighted 0.808601 (0.048168)\n",
      "tanh lbfgs 1500 0.01 76 (150,): Macro 0.702404 (0.039550)\n",
      "Testing 1636/2880\n",
      "tanh lbfgs 1500 0.01 76 (200,): Weighted 0.774655 (0.033681)\n",
      "tanh lbfgs 1500 0.01 76 (200,): Macro 0.630049 (0.038761)\n",
      "Testing 1637/2880\n",
      "tanh lbfgs 1500 0.01 112 (50,): Weighted 0.796811 (0.044936)\n",
      "tanh lbfgs 1500 0.01 112 (50,): Macro 0.677737 (0.039273)\n",
      "Testing 1638/2880\n",
      "tanh lbfgs 1500 0.01 112 (100,): Weighted 0.755303 (0.035086)\n",
      "tanh lbfgs 1500 0.01 112 (100,): Macro 0.604526 (0.013231)\n",
      "Testing 1639/2880\n",
      "tanh lbfgs 1500 0.01 112 (150,): Weighted 0.822557 (0.045499)\n",
      "tanh lbfgs 1500 0.01 112 (150,): Macro 0.704378 (0.056203)\n",
      "Testing 1640/2880\n",
      "tanh lbfgs 1500 0.01 112 (200,): Weighted 0.818965 (0.058558)\n",
      "tanh lbfgs 1500 0.01 112 (200,): Macro 0.694226 (0.079542)\n",
      "Testing 1641/2880\n",
      "tanh lbfgs 1500 0.001 17 (50,): Weighted 0.822579 (0.033014)\n",
      "tanh lbfgs 1500 0.001 17 (50,): Macro 0.699913 (0.033154)\n",
      "Testing 1642/2880\n",
      "tanh lbfgs 1500 0.001 17 (100,): Weighted 0.782493 (0.060976)\n",
      "tanh lbfgs 1500 0.001 17 (100,): Macro 0.649077 (0.087444)\n",
      "Testing 1643/2880\n",
      "tanh lbfgs 1500 0.001 17 (150,): Weighted 0.803839 (0.043952)\n",
      "tanh lbfgs 1500 0.001 17 (150,): Macro 0.667276 (0.061561)\n",
      "Testing 1644/2880\n",
      "tanh lbfgs 1500 0.001 17 (200,): Weighted 0.799190 (0.076703)\n",
      "tanh lbfgs 1500 0.001 17 (200,): Macro 0.673343 (0.099885)\n",
      "Testing 1645/2880\n",
      "tanh lbfgs 1500 0.001 29 (50,): Weighted 0.795324 (0.055017)\n",
      "tanh lbfgs 1500 0.001 29 (50,): Macro 0.658687 (0.056856)\n",
      "Testing 1646/2880\n",
      "tanh lbfgs 1500 0.001 29 (100,): Weighted 0.797654 (0.038467)\n",
      "tanh lbfgs 1500 0.001 29 (100,): Macro 0.666195 (0.040207)\n",
      "Testing 1647/2880\n",
      "tanh lbfgs 1500 0.001 29 (150,): Weighted 0.790229 (0.039523)\n",
      "tanh lbfgs 1500 0.001 29 (150,): Macro 0.646868 (0.054130)\n",
      "Testing 1648/2880\n",
      "tanh lbfgs 1500 0.001 29 (200,): Weighted 0.809625 (0.036729)\n",
      "tanh lbfgs 1500 0.001 29 (200,): Macro 0.677974 (0.031939)\n",
      "Testing 1649/2880\n",
      "tanh lbfgs 1500 0.001 42 (50,): Weighted 0.802037 (0.068730)\n",
      "tanh lbfgs 1500 0.001 42 (50,): Macro 0.694235 (0.073778)\n",
      "Testing 1650/2880\n",
      "tanh lbfgs 1500 0.001 42 (100,): Weighted 0.820897 (0.079238)\n",
      "tanh lbfgs 1500 0.001 42 (100,): Macro 0.704992 (0.116310)\n",
      "Testing 1651/2880\n",
      "tanh lbfgs 1500 0.001 42 (150,): Weighted 0.768259 (0.039416)\n",
      "tanh lbfgs 1500 0.001 42 (150,): Macro 0.609255 (0.039537)\n",
      "Testing 1652/2880\n",
      "tanh lbfgs 1500 0.001 42 (200,): Weighted 0.807595 (0.082398)\n",
      "tanh lbfgs 1500 0.001 42 (200,): Macro 0.687891 (0.114925)\n",
      "Testing 1653/2880\n",
      "tanh lbfgs 1500 0.001 76 (50,): Weighted 0.799427 (0.069225)\n",
      "tanh lbfgs 1500 0.001 76 (50,): Macro 0.694956 (0.081605)\n",
      "Testing 1654/2880\n",
      "tanh lbfgs 1500 0.001 76 (100,): Weighted 0.796167 (0.074812)\n",
      "tanh lbfgs 1500 0.001 76 (100,): Macro 0.678720 (0.098882)\n",
      "Testing 1655/2880\n",
      "tanh lbfgs 1500 0.001 76 (150,): Weighted 0.796405 (0.055981)\n",
      "tanh lbfgs 1500 0.001 76 (150,): Macro 0.672056 (0.074385)\n",
      "Testing 1656/2880\n",
      "tanh lbfgs 1500 0.001 76 (200,): Weighted 0.780251 (0.028275)\n",
      "tanh lbfgs 1500 0.001 76 (200,): Macro 0.643137 (0.030447)\n",
      "Testing 1657/2880\n",
      "tanh lbfgs 1500 0.001 112 (50,): Weighted 0.792322 (0.048211)\n",
      "tanh lbfgs 1500 0.001 112 (50,): Macro 0.646879 (0.065320)\n",
      "Testing 1658/2880\n",
      "tanh lbfgs 1500 0.001 112 (100,): Weighted 0.798571 (0.053240)\n",
      "tanh lbfgs 1500 0.001 112 (100,): Macro 0.668130 (0.063348)\n",
      "Testing 1659/2880\n",
      "tanh lbfgs 1500 0.001 112 (150,): Weighted 0.792717 (0.040720)\n",
      "tanh lbfgs 1500 0.001 112 (150,): Macro 0.658725 (0.025169)\n",
      "Testing 1660/2880\n",
      "tanh lbfgs 1500 0.001 112 (200,): Weighted 0.805596 (0.047353)\n",
      "tanh lbfgs 1500 0.001 112 (200,): Macro 0.689102 (0.055912)\n",
      "Testing 1661/2880\n",
      "tanh lbfgs 1500 0.0001 17 (50,): Weighted 0.820625 (0.039653)\n",
      "tanh lbfgs 1500 0.0001 17 (50,): Macro 0.700959 (0.054386)\n",
      "Testing 1662/2880\n",
      "tanh lbfgs 1500 0.0001 17 (100,): Weighted 0.778362 (0.046201)\n",
      "tanh lbfgs 1500 0.0001 17 (100,): Macro 0.637427 (0.058357)\n",
      "Testing 1663/2880\n",
      "tanh lbfgs 1500 0.0001 17 (150,): Weighted 0.778807 (0.035734)\n",
      "tanh lbfgs 1500 0.0001 17 (150,): Macro 0.635413 (0.035027)\n",
      "Testing 1664/2880\n",
      "tanh lbfgs 1500 0.0001 17 (200,): Weighted 0.761844 (0.042453)\n",
      "tanh lbfgs 1500 0.0001 17 (200,): Macro 0.610296 (0.044067)\n",
      "Testing 1665/2880\n",
      "tanh lbfgs 1500 0.0001 29 (50,): Weighted 0.783284 (0.062100)\n",
      "tanh lbfgs 1500 0.0001 29 (50,): Macro 0.659752 (0.082941)\n",
      "Testing 1666/2880\n",
      "tanh lbfgs 1500 0.0001 29 (100,): Weighted 0.754732 (0.041004)\n",
      "tanh lbfgs 1500 0.0001 29 (100,): Macro 0.611019 (0.058505)\n",
      "Testing 1667/2880\n",
      "tanh lbfgs 1500 0.0001 29 (150,): Weighted 0.779500 (0.045351)\n",
      "tanh lbfgs 1500 0.0001 29 (150,): Macro 0.644047 (0.050823)\n",
      "Testing 1668/2880\n",
      "tanh lbfgs 1500 0.0001 29 (200,): Weighted 0.806593 (0.064492)\n",
      "tanh lbfgs 1500 0.0001 29 (200,): Macro 0.675410 (0.086363)\n",
      "Testing 1669/2880\n",
      "tanh lbfgs 1500 0.0001 42 (50,): Weighted 0.791708 (0.040114)\n",
      "tanh lbfgs 1500 0.0001 42 (50,): Macro 0.660103 (0.040523)\n",
      "Testing 1670/2880\n",
      "tanh lbfgs 1500 0.0001 42 (100,): Weighted 0.793277 (0.045292)\n",
      "tanh lbfgs 1500 0.0001 42 (100,): Macro 0.657086 (0.058217)\n",
      "Testing 1671/2880\n",
      "tanh lbfgs 1500 0.0001 42 (150,): Weighted 0.800967 (0.061274)\n",
      "tanh lbfgs 1500 0.0001 42 (150,): Macro 0.674451 (0.073391)\n",
      "Testing 1672/2880\n",
      "tanh lbfgs 1500 0.0001 42 (200,): Weighted 0.785639 (0.048883)\n",
      "tanh lbfgs 1500 0.0001 42 (200,): Macro 0.654680 (0.059752)\n",
      "Testing 1673/2880\n",
      "tanh lbfgs 1500 0.0001 76 (50,): Weighted 0.778963 (0.079704)\n",
      "tanh lbfgs 1500 0.0001 76 (50,): Macro 0.666964 (0.114643)\n",
      "Testing 1674/2880\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh lbfgs 1500 0.0001 76 (100,): Weighted 0.800091 (0.062247)\n",
      "tanh lbfgs 1500 0.0001 76 (100,): Macro 0.677348 (0.093792)\n",
      "Testing 1675/2880\n",
      "tanh lbfgs 1500 0.0001 76 (150,): Weighted 0.771668 (0.076273)\n",
      "tanh lbfgs 1500 0.0001 76 (150,): Macro 0.625141 (0.097016)\n",
      "Testing 1676/2880\n",
      "tanh lbfgs 1500 0.0001 76 (200,): Weighted 0.771811 (0.066803)\n",
      "tanh lbfgs 1500 0.0001 76 (200,): Macro 0.644355 (0.093216)\n",
      "Testing 1677/2880\n",
      "tanh lbfgs 1500 0.0001 112 (50,): Weighted 0.769281 (0.099464)\n",
      "tanh lbfgs 1500 0.0001 112 (50,): Macro 0.653057 (0.133777)\n",
      "Testing 1678/2880\n",
      "tanh lbfgs 1500 0.0001 112 (100,): Weighted 0.805424 (0.031037)\n",
      "tanh lbfgs 1500 0.0001 112 (100,): Macro 0.679179 (0.032862)\n",
      "Testing 1679/2880\n",
      "tanh lbfgs 1500 0.0001 112 (150,): Weighted 0.778829 (0.089656)\n",
      "tanh lbfgs 1500 0.0001 112 (150,): Macro 0.646770 (0.113643)\n",
      "Testing 1680/2880\n",
      "tanh lbfgs 1500 0.0001 112 (200,): Weighted 0.793448 (0.044438)\n",
      "tanh lbfgs 1500 0.0001 112 (200,): Macro 0.656277 (0.053344)\n",
      "Testing 1681/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh sgd 500 0.1 17 (50,): Weighted 0.841004 (0.062720)\n",
      "tanh sgd 500 0.1 17 (50,): Macro 0.738188 (0.086177)\n",
      "Testing 1682/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh sgd 500 0.1 17 (100,): Weighted 0.836185 (0.059425)\n",
      "tanh sgd 500 0.1 17 (100,): Macro 0.728470 (0.081100)\n",
      "Testing 1683/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh sgd 500 0.1 17 (150,): Weighted 0.836185 (0.059425)\n",
      "tanh sgd 500 0.1 17 (150,): Macro 0.728470 (0.081100)\n",
      "Testing 1684/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh sgd 500 0.1 17 (200,): Weighted 0.825090 (0.055866)\n",
      "tanh sgd 500 0.1 17 (200,): Macro 0.711698 (0.072958)\n",
      "Testing 1685/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh sgd 500 0.1 29 (50,): Weighted 0.830904 (0.064168)\n",
      "tanh sgd 500 0.1 29 (50,): Macro 0.720047 (0.086666)\n",
      "Testing 1686/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh sgd 500 0.1 29 (100,): Weighted 0.819341 (0.067981)\n",
      "tanh sgd 500 0.1 29 (100,): Macro 0.699307 (0.098145)\n",
      "Testing 1687/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh sgd 500 0.1 29 (150,): Weighted 0.821239 (0.069590)\n",
      "tanh sgd 500 0.1 29 (150,): Macro 0.707847 (0.094860)\n",
      "Testing 1688/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh sgd 500 0.1 29 (200,): Weighted 0.824604 (0.058040)\n",
      "tanh sgd 500 0.1 29 (200,): Macro 0.709130 (0.076764)\n",
      "Testing 1689/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh sgd 500 0.1 42 (50,): Weighted 0.831948 (0.050910)\n",
      "tanh sgd 500 0.1 42 (50,): Macro 0.719446 (0.059000)\n",
      "Testing 1690/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh sgd 500 0.1 42 (100,): Weighted 0.830983 (0.060767)\n",
      "tanh sgd 500 0.1 42 (100,): Macro 0.721311 (0.082224)\n",
      "Testing 1691/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh sgd 500 0.1 42 (150,): Weighted 0.816642 (0.072777)\n",
      "tanh sgd 500 0.1 42 (150,): Macro 0.704281 (0.097358)\n",
      "Testing 1692/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh sgd 500 0.1 42 (200,): Weighted 0.825565 (0.054629)\n",
      "tanh sgd 500 0.1 42 (200,): Macro 0.710815 (0.071537)\n",
      "Testing 1693/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh sgd 500 0.1 76 (50,): Weighted 0.817433 (0.070521)\n",
      "tanh sgd 500 0.1 76 (50,): Macro 0.707656 (0.092686)\n",
      "Testing 1694/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh sgd 500 0.1 76 (100,): Weighted 0.825555 (0.067743)\n",
      "tanh sgd 500 0.1 76 (100,): Macro 0.712639 (0.093601)\n",
      "Testing 1695/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh sgd 500 0.1 76 (150,): Weighted 0.836185 (0.059425)\n",
      "tanh sgd 500 0.1 76 (150,): Macro 0.728470 (0.081100)\n",
      "Testing 1696/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh sgd 500 0.1 76 (200,): Weighted 0.820146 (0.062649)\n",
      "tanh sgd 500 0.1 76 (200,): Macro 0.703479 (0.082627)\n",
      "Testing 1697/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh sgd 500 0.1 112 (50,): Weighted 0.832874 (0.060951)\n",
      "tanh sgd 500 0.1 112 (50,): Macro 0.723862 (0.084201)\n",
      "Testing 1698/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh sgd 500 0.1 112 (100,): Weighted 0.825422 (0.057418)\n",
      "tanh sgd 500 0.1 112 (100,): Macro 0.709957 (0.076548)\n",
      "Testing 1699/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh sgd 500 0.1 112 (150,): Weighted 0.811741 (0.063218)\n",
      "tanh sgd 500 0.1 112 (150,): Macro 0.692715 (0.081741)\n",
      "Testing 1700/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh sgd 500 0.1 112 (200,): Weighted 0.831806 (0.052173)\n",
      "tanh sgd 500 0.1 112 (200,): Macro 0.720253 (0.067919)\n",
      "Testing 1701/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh sgd 500 0.01 17 (50,): Weighted 0.841004 (0.062720)\n",
      "tanh sgd 500 0.01 17 (50,): Macro 0.738188 (0.086177)\n",
      "Testing 1702/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh sgd 500 0.01 17 (100,): Weighted 0.836185 (0.059425)\n",
      "tanh sgd 500 0.01 17 (100,): Macro 0.728470 (0.081100)\n",
      "Testing 1703/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh sgd 500 0.01 17 (150,): Weighted 0.836185 (0.059425)\n",
      "tanh sgd 500 0.01 17 (150,): Macro 0.728470 (0.081100)\n",
      "Testing 1704/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh sgd 500 0.01 17 (200,): Weighted 0.825090 (0.055866)\n",
      "tanh sgd 500 0.01 17 (200,): Macro 0.711698 (0.072958)\n",
      "Testing 1705/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh sgd 500 0.01 29 (50,): Weighted 0.830904 (0.064168)\n",
      "tanh sgd 500 0.01 29 (50,): Macro 0.720047 (0.086666)\n",
      "Testing 1706/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh sgd 500 0.01 29 (100,): Weighted 0.819341 (0.067981)\n",
      "tanh sgd 500 0.01 29 (100,): Macro 0.699307 (0.098145)\n",
      "Testing 1707/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh sgd 500 0.01 29 (150,): Weighted 0.821239 (0.069590)\n",
      "tanh sgd 500 0.01 29 (150,): Macro 0.707847 (0.094860)\n",
      "Testing 1708/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh sgd 500 0.01 29 (200,): Weighted 0.824604 (0.058040)\n",
      "tanh sgd 500 0.01 29 (200,): Macro 0.709130 (0.076764)\n",
      "Testing 1709/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh sgd 500 0.01 42 (50,): Weighted 0.831948 (0.050910)\n",
      "tanh sgd 500 0.01 42 (50,): Macro 0.719446 (0.059000)\n",
      "Testing 1710/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh sgd 500 0.01 42 (100,): Weighted 0.830983 (0.060767)\n",
      "tanh sgd 500 0.01 42 (100,): Macro 0.721311 (0.082224)\n",
      "Testing 1711/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh sgd 500 0.01 42 (150,): Weighted 0.816642 (0.072777)\n",
      "tanh sgd 500 0.01 42 (150,): Macro 0.704281 (0.097358)\n",
      "Testing 1712/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh sgd 500 0.01 42 (200,): Weighted 0.825565 (0.054629)\n",
      "tanh sgd 500 0.01 42 (200,): Macro 0.710815 (0.071537)\n",
      "Testing 1713/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh sgd 500 0.01 76 (50,): Weighted 0.817433 (0.070521)\n",
      "tanh sgd 500 0.01 76 (50,): Macro 0.707656 (0.092686)\n",
      "Testing 1714/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh sgd 500 0.01 76 (100,): Weighted 0.825555 (0.067743)\n",
      "tanh sgd 500 0.01 76 (100,): Macro 0.712639 (0.093601)\n",
      "Testing 1715/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh sgd 500 0.01 76 (150,): Weighted 0.836185 (0.059425)\n",
      "tanh sgd 500 0.01 76 (150,): Macro 0.728470 (0.081100)\n",
      "Testing 1716/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh sgd 500 0.01 76 (200,): Weighted 0.820146 (0.062649)\n",
      "tanh sgd 500 0.01 76 (200,): Macro 0.703479 (0.082627)\n",
      "Testing 1717/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh sgd 500 0.01 112 (50,): Weighted 0.826113 (0.049689)\n",
      "tanh sgd 500 0.01 112 (50,): Macro 0.707857 (0.059078)\n",
      "Testing 1718/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh sgd 500 0.01 112 (100,): Weighted 0.825422 (0.057418)\n",
      "tanh sgd 500 0.01 112 (100,): Macro 0.709957 (0.076548)\n",
      "Testing 1719/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh sgd 500 0.01 112 (150,): Weighted 0.811741 (0.063218)\n",
      "tanh sgd 500 0.01 112 (150,): Macro 0.692715 (0.081741)\n",
      "Testing 1720/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh sgd 500 0.01 112 (200,): Weighted 0.831806 (0.052173)\n",
      "tanh sgd 500 0.01 112 (200,): Macro 0.720253 (0.067919)\n",
      "Testing 1721/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh sgd 500 0.001 17 (50,): Weighted 0.841004 (0.062720)\n",
      "tanh sgd 500 0.001 17 (50,): Macro 0.738188 (0.086177)\n",
      "Testing 1722/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh sgd 500 0.001 17 (100,): Weighted 0.836185 (0.059425)\n",
      "tanh sgd 500 0.001 17 (100,): Macro 0.728470 (0.081100)\n",
      "Testing 1723/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh sgd 500 0.001 17 (150,): Weighted 0.836185 (0.059425)\n",
      "tanh sgd 500 0.001 17 (150,): Macro 0.728470 (0.081100)\n",
      "Testing 1724/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh sgd 500 0.001 17 (200,): Weighted 0.825090 (0.055866)\n",
      "tanh sgd 500 0.001 17 (200,): Macro 0.711698 (0.072958)\n",
      "Testing 1725/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh sgd 500 0.001 29 (50,): Weighted 0.830904 (0.064168)\n",
      "tanh sgd 500 0.001 29 (50,): Macro 0.720047 (0.086666)\n",
      "Testing 1726/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh sgd 500 0.001 29 (100,): Weighted 0.819341 (0.067981)\n",
      "tanh sgd 500 0.001 29 (100,): Macro 0.699307 (0.098145)\n",
      "Testing 1727/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh sgd 500 0.001 29 (150,): Weighted 0.821239 (0.069590)\n",
      "tanh sgd 500 0.001 29 (150,): Macro 0.707847 (0.094860)\n",
      "Testing 1728/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh sgd 500 0.001 29 (200,): Weighted 0.824604 (0.058040)\n",
      "tanh sgd 500 0.001 29 (200,): Macro 0.709130 (0.076764)\n",
      "Testing 1729/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh sgd 500 0.001 42 (50,): Weighted 0.831948 (0.050910)\n",
      "tanh sgd 500 0.001 42 (50,): Macro 0.719446 (0.059000)\n",
      "Testing 1730/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh sgd 500 0.001 42 (100,): Weighted 0.830983 (0.060767)\n",
      "tanh sgd 500 0.001 42 (100,): Macro 0.721311 (0.082224)\n",
      "Testing 1731/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh sgd 500 0.001 42 (150,): Weighted 0.816642 (0.072777)\n",
      "tanh sgd 500 0.001 42 (150,): Macro 0.704281 (0.097358)\n",
      "Testing 1732/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh sgd 500 0.001 42 (200,): Weighted 0.825565 (0.054629)\n",
      "tanh sgd 500 0.001 42 (200,): Macro 0.710815 (0.071537)\n",
      "Testing 1733/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh sgd 500 0.001 76 (50,): Weighted 0.817433 (0.070521)\n",
      "tanh sgd 500 0.001 76 (50,): Macro 0.707656 (0.092686)\n",
      "Testing 1734/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh sgd 500 0.001 76 (100,): Weighted 0.825555 (0.067743)\n",
      "tanh sgd 500 0.001 76 (100,): Macro 0.712639 (0.093601)\n",
      "Testing 1735/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh sgd 500 0.001 76 (150,): Weighted 0.836185 (0.059425)\n",
      "tanh sgd 500 0.001 76 (150,): Macro 0.728470 (0.081100)\n",
      "Testing 1736/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh sgd 500 0.001 76 (200,): Weighted 0.820146 (0.062649)\n",
      "tanh sgd 500 0.001 76 (200,): Macro 0.703479 (0.082627)\n",
      "Testing 1737/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh sgd 500 0.001 112 (50,): Weighted 0.830980 (0.049348)\n",
      "tanh sgd 500 0.001 112 (50,): Macro 0.714653 (0.060592)\n",
      "Testing 1738/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh sgd 500 0.001 112 (100,): Weighted 0.825422 (0.057418)\n",
      "tanh sgd 500 0.001 112 (100,): Macro 0.709957 (0.076548)\n",
      "Testing 1739/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh sgd 500 0.001 112 (150,): Weighted 0.811741 (0.063218)\n",
      "tanh sgd 500 0.001 112 (150,): Macro 0.692715 (0.081741)\n",
      "Testing 1740/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh sgd 500 0.001 112 (200,): Weighted 0.831806 (0.052173)\n",
      "tanh sgd 500 0.001 112 (200,): Macro 0.720253 (0.067919)\n",
      "Testing 1741/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh sgd 500 0.0001 17 (50,): Weighted 0.841004 (0.062720)\n",
      "tanh sgd 500 0.0001 17 (50,): Macro 0.738188 (0.086177)\n",
      "Testing 1742/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh sgd 500 0.0001 17 (100,): Weighted 0.836185 (0.059425)\n",
      "tanh sgd 500 0.0001 17 (100,): Macro 0.728470 (0.081100)\n",
      "Testing 1743/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh sgd 500 0.0001 17 (150,): Weighted 0.836185 (0.059425)\n",
      "tanh sgd 500 0.0001 17 (150,): Macro 0.728470 (0.081100)\n",
      "Testing 1744/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh sgd 500 0.0001 17 (200,): Weighted 0.825090 (0.055866)\n",
      "tanh sgd 500 0.0001 17 (200,): Macro 0.711698 (0.072958)\n",
      "Testing 1745/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh sgd 500 0.0001 29 (50,): Weighted 0.830904 (0.064168)\n",
      "tanh sgd 500 0.0001 29 (50,): Macro 0.720047 (0.086666)\n",
      "Testing 1746/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh sgd 500 0.0001 29 (100,): Weighted 0.819341 (0.067981)\n",
      "tanh sgd 500 0.0001 29 (100,): Macro 0.699307 (0.098145)\n",
      "Testing 1747/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh sgd 500 0.0001 29 (150,): Weighted 0.821239 (0.069590)\n",
      "tanh sgd 500 0.0001 29 (150,): Macro 0.707847 (0.094860)\n",
      "Testing 1748/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh sgd 500 0.0001 29 (200,): Weighted 0.824604 (0.058040)\n",
      "tanh sgd 500 0.0001 29 (200,): Macro 0.709130 (0.076764)\n",
      "Testing 1749/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh sgd 500 0.0001 42 (50,): Weighted 0.831948 (0.050910)\n",
      "tanh sgd 500 0.0001 42 (50,): Macro 0.719446 (0.059000)\n",
      "Testing 1750/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh sgd 500 0.0001 42 (100,): Weighted 0.830983 (0.060767)\n",
      "tanh sgd 500 0.0001 42 (100,): Macro 0.721311 (0.082224)\n",
      "Testing 1751/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh sgd 500 0.0001 42 (150,): Weighted 0.816642 (0.072777)\n",
      "tanh sgd 500 0.0001 42 (150,): Macro 0.704281 (0.097358)\n",
      "Testing 1752/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh sgd 500 0.0001 42 (200,): Weighted 0.825565 (0.054629)\n",
      "tanh sgd 500 0.0001 42 (200,): Macro 0.710815 (0.071537)\n",
      "Testing 1753/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh sgd 500 0.0001 76 (50,): Weighted 0.817433 (0.070521)\n",
      "tanh sgd 500 0.0001 76 (50,): Macro 0.707656 (0.092686)\n",
      "Testing 1754/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh sgd 500 0.0001 76 (100,): Weighted 0.825555 (0.067743)\n",
      "tanh sgd 500 0.0001 76 (100,): Macro 0.712639 (0.093601)\n",
      "Testing 1755/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh sgd 500 0.0001 76 (150,): Weighted 0.836185 (0.059425)\n",
      "tanh sgd 500 0.0001 76 (150,): Macro 0.728470 (0.081100)\n",
      "Testing 1756/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh sgd 500 0.0001 76 (200,): Weighted 0.820146 (0.062649)\n",
      "tanh sgd 500 0.0001 76 (200,): Macro 0.703479 (0.082627)\n",
      "Testing 1757/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh sgd 500 0.0001 112 (50,): Weighted 0.830980 (0.049348)\n",
      "tanh sgd 500 0.0001 112 (50,): Macro 0.714653 (0.060592)\n",
      "Testing 1758/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh sgd 500 0.0001 112 (100,): Weighted 0.825422 (0.057418)\n",
      "tanh sgd 500 0.0001 112 (100,): Macro 0.709957 (0.076548)\n",
      "Testing 1759/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh sgd 500 0.0001 112 (150,): Weighted 0.811741 (0.063218)\n",
      "tanh sgd 500 0.0001 112 (150,): Macro 0.692715 (0.081741)\n",
      "Testing 1760/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh sgd 500 0.0001 112 (200,): Weighted 0.831806 (0.052173)\n",
      "tanh sgd 500 0.0001 112 (200,): Macro 0.720253 (0.067919)\n",
      "Testing 1761/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh sgd 1000 0.1 17 (50,): Weighted 0.816568 (0.075451)\n",
      "tanh sgd 1000 0.1 17 (50,): Macro 0.703621 (0.101478)\n",
      "Testing 1762/2880\n",
      "tanh sgd 1000 0.1 17 (100,): Weighted 0.824313 (0.056217)\n",
      "tanh sgd 1000 0.1 17 (100,): Macro 0.707443 (0.071825)\n",
      "Testing 1763/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh sgd 1000 0.1 17 (150,): Weighted 0.809199 (0.064410)\n",
      "tanh sgd 1000 0.1 17 (150,): Macro 0.682476 (0.089961)\n",
      "Testing 1764/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh sgd 1000 0.1 17 (200,): Weighted 0.835598 (0.054270)\n",
      "tanh sgd 1000 0.1 17 (200,): Macro 0.728240 (0.068576)\n",
      "Testing 1765/2880\n",
      "tanh sgd 1000 0.1 29 (50,): Weighted 0.836632 (0.072179)\n",
      "tanh sgd 1000 0.1 29 (50,): Macro 0.732881 (0.103740)\n",
      "Testing 1766/2880\n",
      "tanh sgd 1000 0.1 29 (100,): Weighted 0.819341 (0.067981)\n",
      "tanh sgd 1000 0.1 29 (100,): Macro 0.699307 (0.098145)\n",
      "Testing 1767/2880\n",
      "tanh sgd 1000 0.1 29 (150,): Weighted 0.819120 (0.062539)\n",
      "tanh sgd 1000 0.1 29 (150,): Macro 0.696320 (0.089204)\n",
      "Testing 1768/2880\n",
      "tanh sgd 1000 0.1 29 (200,): Weighted 0.820206 (0.062931)\n",
      "tanh sgd 1000 0.1 29 (200,): Macro 0.697857 (0.090882)\n",
      "Testing 1769/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh sgd 1000 0.1 42 (50,): Weighted 0.826793 (0.050194)\n",
      "tanh sgd 1000 0.1 42 (50,): Macro 0.713627 (0.054529)\n",
      "Testing 1770/2880\n",
      "tanh sgd 1000 0.1 42 (100,): Weighted 0.809440 (0.075188)\n",
      "tanh sgd 1000 0.1 42 (100,): Macro 0.687449 (0.107653)\n",
      "Testing 1771/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh sgd 1000 0.1 42 (150,): Weighted 0.806727 (0.066241)\n",
      "tanh sgd 1000 0.1 42 (150,): Macro 0.678678 (0.091224)\n",
      "Testing 1772/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh sgd 1000 0.1 42 (200,): Weighted 0.820446 (0.056281)\n",
      "tanh sgd 1000 0.1 42 (200,): Macro 0.703900 (0.072516)\n",
      "Testing 1773/2880\n",
      "tanh sgd 1000 0.1 76 (50,): Weighted 0.822552 (0.070439)\n",
      "tanh sgd 1000 0.1 76 (50,): Macro 0.711179 (0.095241)\n",
      "Testing 1774/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh sgd 1000 0.1 76 (100,): Weighted 0.816409 (0.069806)\n",
      "tanh sgd 1000 0.1 76 (100,): Macro 0.698166 (0.095948)\n",
      "Testing 1775/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh sgd 1000 0.1 76 (150,): Weighted 0.833757 (0.061690)\n",
      "tanh sgd 1000 0.1 76 (150,): Macro 0.719639 (0.090756)\n",
      "Testing 1776/2880\n",
      "tanh sgd 1000 0.1 76 (200,): Weighted 0.825225 (0.060238)\n",
      "tanh sgd 1000 0.1 76 (200,): Macro 0.714934 (0.077100)\n",
      "Testing 1777/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh sgd 1000 0.1 112 (50,): Weighted 0.817881 (0.071612)\n",
      "tanh sgd 1000 0.1 112 (50,): Macro 0.705467 (0.096042)\n",
      "Testing 1778/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh sgd 1000 0.1 112 (100,): Weighted 0.810353 (0.063939)\n",
      "tanh sgd 1000 0.1 112 (100,): Macro 0.682553 (0.089939)\n",
      "Testing 1779/2880\n",
      "tanh sgd 1000 0.1 112 (150,): Weighted 0.806727 (0.066241)\n",
      "tanh sgd 1000 0.1 112 (150,): Macro 0.678678 (0.091224)\n",
      "Testing 1780/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh sgd 1000 0.1 112 (200,): Weighted 0.817916 (0.059321)\n",
      "tanh sgd 1000 0.1 112 (200,): Macro 0.696680 (0.083080)\n",
      "Testing 1781/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh sgd 1000 0.01 17 (50,): Weighted 0.816568 (0.075451)\n",
      "tanh sgd 1000 0.01 17 (50,): Macro 0.703621 (0.101478)\n",
      "Testing 1782/2880\n",
      "tanh sgd 1000 0.01 17 (100,): Weighted 0.824313 (0.056217)\n",
      "tanh sgd 1000 0.01 17 (100,): Macro 0.707443 (0.071825)\n",
      "Testing 1783/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh sgd 1000 0.01 17 (150,): Weighted 0.809199 (0.064410)\n",
      "tanh sgd 1000 0.01 17 (150,): Macro 0.682476 (0.089961)\n",
      "Testing 1784/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh sgd 1000 0.01 17 (200,): Weighted 0.821355 (0.056878)\n",
      "tanh sgd 1000 0.01 17 (200,): Macro 0.708521 (0.070928)\n",
      "Testing 1785/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh sgd 1000 0.01 29 (50,): Weighted 0.836632 (0.072179)\n",
      "tanh sgd 1000 0.01 29 (50,): Macro 0.732881 (0.103740)\n",
      "Testing 1786/2880\n",
      "tanh sgd 1000 0.01 29 (100,): Weighted 0.819341 (0.067981)\n",
      "tanh sgd 1000 0.01 29 (100,): Macro 0.699307 (0.098145)\n",
      "Testing 1787/2880\n",
      "tanh sgd 1000 0.01 29 (150,): Weighted 0.819120 (0.062539)\n",
      "tanh sgd 1000 0.01 29 (150,): Macro 0.696320 (0.089204)\n",
      "Testing 1788/2880\n",
      "tanh sgd 1000 0.01 29 (200,): Weighted 0.820206 (0.062931)\n",
      "tanh sgd 1000 0.01 29 (200,): Macro 0.697857 (0.090882)\n",
      "Testing 1789/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh sgd 1000 0.01 42 (50,): Weighted 0.826793 (0.050194)\n",
      "tanh sgd 1000 0.01 42 (50,): Macro 0.713627 (0.054529)\n",
      "Testing 1790/2880\n",
      "tanh sgd 1000 0.01 42 (100,): Weighted 0.821377 (0.065714)\n",
      "tanh sgd 1000 0.01 42 (100,): Macro 0.708318 (0.088063)\n",
      "Testing 1791/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh sgd 1000 0.01 42 (150,): Weighted 0.806727 (0.066241)\n",
      "tanh sgd 1000 0.01 42 (150,): Macro 0.678678 (0.091224)\n",
      "Testing 1792/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh sgd 1000 0.01 42 (200,): Weighted 0.820446 (0.056281)\n",
      "tanh sgd 1000 0.01 42 (200,): Macro 0.703900 (0.072516)\n",
      "Testing 1793/2880\n",
      "tanh sgd 1000 0.01 76 (50,): Weighted 0.822552 (0.070439)\n",
      "tanh sgd 1000 0.01 76 (50,): Macro 0.711179 (0.095241)\n",
      "Testing 1794/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh sgd 1000 0.01 76 (100,): Weighted 0.816409 (0.069806)\n",
      "tanh sgd 1000 0.01 76 (100,): Macro 0.698166 (0.095948)\n",
      "Testing 1795/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh sgd 1000 0.01 76 (150,): Weighted 0.830701 (0.064815)\n",
      "tanh sgd 1000 0.01 76 (150,): Macro 0.715660 (0.095589)\n",
      "Testing 1796/2880\n",
      "tanh sgd 1000 0.01 76 (200,): Weighted 0.816717 (0.064902)\n",
      "tanh sgd 1000 0.01 76 (200,): Macro 0.698772 (0.086129)\n",
      "Testing 1797/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh sgd 1000 0.01 112 (50,): Weighted 0.817881 (0.071612)\n",
      "tanh sgd 1000 0.01 112 (50,): Macro 0.705467 (0.096042)\n",
      "Testing 1798/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh sgd 1000 0.01 112 (100,): Weighted 0.814428 (0.062759)\n",
      "tanh sgd 1000 0.01 112 (100,): Macro 0.688031 (0.088880)\n",
      "Testing 1799/2880\n",
      "tanh sgd 1000 0.01 112 (150,): Weighted 0.801694 (0.067559)\n",
      "tanh sgd 1000 0.01 112 (150,): Macro 0.672006 (0.091971)\n",
      "Testing 1800/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh sgd 1000 0.01 112 (200,): Weighted 0.813353 (0.061577)\n",
      "tanh sgd 1000 0.01 112 (200,): Macro 0.688781 (0.085442)\n",
      "Testing 1801/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh sgd 1000 0.001 17 (50,): Weighted 0.816568 (0.075451)\n",
      "tanh sgd 1000 0.001 17 (50,): Macro 0.703621 (0.101478)\n",
      "Testing 1802/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh sgd 1000 0.001 17 (100,): Weighted 0.824313 (0.056217)\n",
      "tanh sgd 1000 0.001 17 (100,): Macro 0.707443 (0.071825)\n",
      "Testing 1803/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh sgd 1000 0.001 17 (150,): Weighted 0.809199 (0.064410)\n",
      "tanh sgd 1000 0.001 17 (150,): Macro 0.682476 (0.089961)\n",
      "Testing 1804/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh sgd 1000 0.001 17 (200,): Weighted 0.821355 (0.056878)\n",
      "tanh sgd 1000 0.001 17 (200,): Macro 0.708521 (0.070928)\n",
      "Testing 1805/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh sgd 1000 0.001 29 (50,): Weighted 0.836632 (0.072179)\n",
      "tanh sgd 1000 0.001 29 (50,): Macro 0.732881 (0.103740)\n",
      "Testing 1806/2880\n",
      "tanh sgd 1000 0.001 29 (100,): Weighted 0.819341 (0.067981)\n",
      "tanh sgd 1000 0.001 29 (100,): Macro 0.699307 (0.098145)\n",
      "Testing 1807/2880\n",
      "tanh sgd 1000 0.001 29 (150,): Weighted 0.819120 (0.062539)\n",
      "tanh sgd 1000 0.001 29 (150,): Macro 0.696320 (0.089204)\n",
      "Testing 1808/2880\n",
      "tanh sgd 1000 0.001 29 (200,): Weighted 0.820206 (0.062931)\n",
      "tanh sgd 1000 0.001 29 (200,): Macro 0.697857 (0.090882)\n",
      "Testing 1809/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh sgd 1000 0.001 42 (50,): Weighted 0.826793 (0.050194)\n",
      "tanh sgd 1000 0.001 42 (50,): Macro 0.713627 (0.054529)\n",
      "Testing 1810/2880\n",
      "tanh sgd 1000 0.001 42 (100,): Weighted 0.821377 (0.065714)\n",
      "tanh sgd 1000 0.001 42 (100,): Macro 0.708318 (0.088063)\n",
      "Testing 1811/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh sgd 1000 0.001 42 (150,): Weighted 0.806727 (0.066241)\n",
      "tanh sgd 1000 0.001 42 (150,): Macro 0.678678 (0.091224)\n",
      "Testing 1812/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh sgd 1000 0.001 42 (200,): Weighted 0.820446 (0.056281)\n",
      "tanh sgd 1000 0.001 42 (200,): Macro 0.703900 (0.072516)\n",
      "Testing 1813/2880\n",
      "tanh sgd 1000 0.001 76 (50,): Weighted 0.822552 (0.070439)\n",
      "tanh sgd 1000 0.001 76 (50,): Macro 0.711179 (0.095241)\n",
      "Testing 1814/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh sgd 1000 0.001 76 (100,): Weighted 0.816409 (0.069806)\n",
      "tanh sgd 1000 0.001 76 (100,): Macro 0.698166 (0.095948)\n",
      "Testing 1815/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh sgd 1000 0.001 76 (150,): Weighted 0.830701 (0.064815)\n",
      "tanh sgd 1000 0.001 76 (150,): Macro 0.715660 (0.095589)\n",
      "Testing 1816/2880\n",
      "tanh sgd 1000 0.001 76 (200,): Weighted 0.816717 (0.064902)\n",
      "tanh sgd 1000 0.001 76 (200,): Macro 0.698772 (0.086129)\n",
      "Testing 1817/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh sgd 1000 0.001 112 (50,): Weighted 0.817881 (0.071612)\n",
      "tanh sgd 1000 0.001 112 (50,): Macro 0.705467 (0.096042)\n",
      "Testing 1818/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh sgd 1000 0.001 112 (100,): Weighted 0.814428 (0.062759)\n",
      "tanh sgd 1000 0.001 112 (100,): Macro 0.688031 (0.088880)\n",
      "Testing 1819/2880\n",
      "tanh sgd 1000 0.001 112 (150,): Weighted 0.801694 (0.067559)\n",
      "tanh sgd 1000 0.001 112 (150,): Macro 0.672006 (0.091971)\n",
      "Testing 1820/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh sgd 1000 0.001 112 (200,): Weighted 0.813353 (0.061577)\n",
      "tanh sgd 1000 0.001 112 (200,): Macro 0.688781 (0.085442)\n",
      "Testing 1821/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh sgd 1000 0.0001 17 (50,): Weighted 0.816568 (0.075451)\n",
      "tanh sgd 1000 0.0001 17 (50,): Macro 0.703621 (0.101478)\n",
      "Testing 1822/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh sgd 1000 0.0001 17 (100,): Weighted 0.824313 (0.056217)\n",
      "tanh sgd 1000 0.0001 17 (100,): Macro 0.707443 (0.071825)\n",
      "Testing 1823/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh sgd 1000 0.0001 17 (150,): Weighted 0.809199 (0.064410)\n",
      "tanh sgd 1000 0.0001 17 (150,): Macro 0.682476 (0.089961)\n",
      "Testing 1824/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh sgd 1000 0.0001 17 (200,): Weighted 0.821355 (0.056878)\n",
      "tanh sgd 1000 0.0001 17 (200,): Macro 0.708521 (0.070928)\n",
      "Testing 1825/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh sgd 1000 0.0001 29 (50,): Weighted 0.836632 (0.072179)\n",
      "tanh sgd 1000 0.0001 29 (50,): Macro 0.732881 (0.103740)\n",
      "Testing 1826/2880\n",
      "tanh sgd 1000 0.0001 29 (100,): Weighted 0.819341 (0.067981)\n",
      "tanh sgd 1000 0.0001 29 (100,): Macro 0.699307 (0.098145)\n",
      "Testing 1827/2880\n",
      "tanh sgd 1000 0.0001 29 (150,): Weighted 0.819120 (0.062539)\n",
      "tanh sgd 1000 0.0001 29 (150,): Macro 0.696320 (0.089204)\n",
      "Testing 1828/2880\n",
      "tanh sgd 1000 0.0001 29 (200,): Weighted 0.820206 (0.062931)\n",
      "tanh sgd 1000 0.0001 29 (200,): Macro 0.697857 (0.090882)\n",
      "Testing 1829/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh sgd 1000 0.0001 42 (50,): Weighted 0.826793 (0.050194)\n",
      "tanh sgd 1000 0.0001 42 (50,): Macro 0.713627 (0.054529)\n",
      "Testing 1830/2880\n",
      "tanh sgd 1000 0.0001 42 (100,): Weighted 0.821377 (0.065714)\n",
      "tanh sgd 1000 0.0001 42 (100,): Macro 0.708318 (0.088063)\n",
      "Testing 1831/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh sgd 1000 0.0001 42 (150,): Weighted 0.806727 (0.066241)\n",
      "tanh sgd 1000 0.0001 42 (150,): Macro 0.678678 (0.091224)\n",
      "Testing 1832/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh sgd 1000 0.0001 42 (200,): Weighted 0.820446 (0.056281)\n",
      "tanh sgd 1000 0.0001 42 (200,): Macro 0.703900 (0.072516)\n",
      "Testing 1833/2880\n",
      "tanh sgd 1000 0.0001 76 (50,): Weighted 0.822552 (0.070439)\n",
      "tanh sgd 1000 0.0001 76 (50,): Macro 0.711179 (0.095241)\n",
      "Testing 1834/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh sgd 1000 0.0001 76 (100,): Weighted 0.816409 (0.069806)\n",
      "tanh sgd 1000 0.0001 76 (100,): Macro 0.698166 (0.095948)\n",
      "Testing 1835/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh sgd 1000 0.0001 76 (150,): Weighted 0.830701 (0.064815)\n",
      "tanh sgd 1000 0.0001 76 (150,): Macro 0.715660 (0.095589)\n",
      "Testing 1836/2880\n",
      "tanh sgd 1000 0.0001 76 (200,): Weighted 0.816717 (0.064902)\n",
      "tanh sgd 1000 0.0001 76 (200,): Macro 0.698772 (0.086129)\n",
      "Testing 1837/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh sgd 1000 0.0001 112 (50,): Weighted 0.817881 (0.071612)\n",
      "tanh sgd 1000 0.0001 112 (50,): Macro 0.705467 (0.096042)\n",
      "Testing 1838/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh sgd 1000 0.0001 112 (100,): Weighted 0.814428 (0.062759)\n",
      "tanh sgd 1000 0.0001 112 (100,): Macro 0.688031 (0.088880)\n",
      "Testing 1839/2880\n",
      "tanh sgd 1000 0.0001 112 (150,): Weighted 0.801694 (0.067559)\n",
      "tanh sgd 1000 0.0001 112 (150,): Macro 0.672006 (0.091971)\n",
      "Testing 1840/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh sgd 1000 0.0001 112 (200,): Weighted 0.813353 (0.061577)\n",
      "tanh sgd 1000 0.0001 112 (200,): Macro 0.688781 (0.085442)\n",
      "Testing 1841/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh sgd 1500 0.1 17 (50,): Weighted 0.814736 (0.076970)\n",
      "tanh sgd 1500 0.1 17 (50,): Macro 0.694587 (0.110062)\n",
      "Testing 1842/2880\n",
      "tanh sgd 1500 0.1 17 (100,): Weighted 0.824313 (0.056217)\n",
      "tanh sgd 1500 0.1 17 (100,): Macro 0.707443 (0.071825)\n",
      "Testing 1843/2880\n",
      "tanh sgd 1500 0.1 17 (150,): Weighted 0.809199 (0.064410)\n",
      "tanh sgd 1500 0.1 17 (150,): Macro 0.682476 (0.089961)\n",
      "Testing 1844/2880\n",
      "tanh sgd 1500 0.1 17 (200,): Weighted 0.839336 (0.050280)\n",
      "tanh sgd 1500 0.1 17 (200,): Macro 0.733439 (0.063161)\n",
      "Testing 1845/2880\n",
      "tanh sgd 1500 0.1 29 (50,): Weighted 0.836632 (0.072179)\n",
      "tanh sgd 1500 0.1 29 (50,): Macro 0.732881 (0.103740)\n",
      "Testing 1846/2880\n",
      "tanh sgd 1500 0.1 29 (100,): Weighted 0.819341 (0.067981)\n",
      "tanh sgd 1500 0.1 29 (100,): Macro 0.699307 (0.098145)\n",
      "Testing 1847/2880\n",
      "tanh sgd 1500 0.1 29 (150,): Weighted 0.819120 (0.062539)\n",
      "tanh sgd 1500 0.1 29 (150,): Macro 0.696320 (0.089204)\n",
      "Testing 1848/2880\n",
      "tanh sgd 1500 0.1 29 (200,): Weighted 0.820206 (0.062931)\n",
      "tanh sgd 1500 0.1 29 (200,): Macro 0.697857 (0.090882)\n",
      "Testing 1849/2880\n",
      "tanh sgd 1500 0.1 42 (50,): Weighted 0.823529 (0.053290)\n",
      "tanh sgd 1500 0.1 42 (50,): Macro 0.709099 (0.059880)\n",
      "Testing 1850/2880\n",
      "tanh sgd 1500 0.1 42 (100,): Weighted 0.809440 (0.075188)\n",
      "tanh sgd 1500 0.1 42 (100,): Macro 0.687449 (0.107653)\n",
      "Testing 1851/2880\n",
      "tanh sgd 1500 0.1 42 (150,): Weighted 0.808783 (0.064918)\n",
      "tanh sgd 1500 0.1 42 (150,): Macro 0.686781 (0.084778)\n",
      "Testing 1852/2880\n",
      "tanh sgd 1500 0.1 42 (200,): Weighted 0.817018 (0.058797)\n",
      "tanh sgd 1500 0.1 42 (200,): Macro 0.699193 (0.076508)\n",
      "Testing 1853/2880\n",
      "tanh sgd 1500 0.1 76 (50,): Weighted 0.822552 (0.070439)\n",
      "tanh sgd 1500 0.1 76 (50,): Macro 0.711179 (0.095241)\n",
      "Testing 1854/2880\n",
      "tanh sgd 1500 0.1 76 (100,): Weighted 0.825063 (0.065130)\n",
      "tanh sgd 1500 0.1 76 (100,): Macro 0.709771 (0.089815)\n",
      "Testing 1855/2880\n",
      "tanh sgd 1500 0.1 76 (150,): Weighted 0.827539 (0.068329)\n",
      "tanh sgd 1500 0.1 76 (150,): Macro 0.711663 (0.100685)\n",
      "Testing 1856/2880\n",
      "tanh sgd 1500 0.1 76 (200,): Weighted 0.825225 (0.060238)\n",
      "tanh sgd 1500 0.1 76 (200,): Macro 0.714934 (0.077100)\n",
      "Testing 1857/2880\n",
      "tanh sgd 1500 0.1 112 (50,): Weighted 0.815825 (0.073070)\n",
      "tanh sgd 1500 0.1 112 (50,): Macro 0.697364 (0.103254)\n",
      "Testing 1858/2880\n",
      "tanh sgd 1500 0.1 112 (100,): Weighted 0.810353 (0.063939)\n",
      "tanh sgd 1500 0.1 112 (100,): Macro 0.682553 (0.089939)\n",
      "Testing 1859/2880\n",
      "tanh sgd 1500 0.1 112 (150,): Weighted 0.806727 (0.066241)\n",
      "tanh sgd 1500 0.1 112 (150,): Macro 0.678678 (0.091224)\n",
      "Testing 1860/2880\n",
      "tanh sgd 1500 0.1 112 (200,): Weighted 0.820972 (0.056584)\n",
      "tanh sgd 1500 0.1 112 (200,): Macro 0.700659 (0.078440)\n",
      "Testing 1861/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh sgd 1500 0.01 17 (50,): Weighted 0.808476 (0.074308)\n",
      "tanh sgd 1500 0.01 17 (50,): Macro 0.685841 (0.105493)\n",
      "Testing 1862/2880\n",
      "tanh sgd 1500 0.01 17 (100,): Weighted 0.824313 (0.056217)\n",
      "tanh sgd 1500 0.01 17 (100,): Macro 0.707443 (0.071825)\n",
      "Testing 1863/2880\n",
      "tanh sgd 1500 0.01 17 (150,): Weighted 0.809199 (0.064410)\n",
      "tanh sgd 1500 0.01 17 (150,): Macro 0.682476 (0.089961)\n",
      "Testing 1864/2880\n",
      "tanh sgd 1500 0.01 17 (200,): Weighted 0.825093 (0.054078)\n",
      "tanh sgd 1500 0.01 17 (200,): Macro 0.713719 (0.067249)\n",
      "Testing 1865/2880\n",
      "tanh sgd 1500 0.01 29 (50,): Weighted 0.828261 (0.080888)\n",
      "tanh sgd 1500 0.01 29 (50,): Macro 0.716868 (0.121143)\n",
      "Testing 1866/2880\n",
      "tanh sgd 1500 0.01 29 (100,): Weighted 0.819341 (0.067981)\n",
      "tanh sgd 1500 0.01 29 (100,): Macro 0.699307 (0.098145)\n",
      "Testing 1867/2880\n",
      "tanh sgd 1500 0.01 29 (150,): Weighted 0.819120 (0.062539)\n",
      "tanh sgd 1500 0.01 29 (150,): Macro 0.696320 (0.089204)\n",
      "Testing 1868/2880\n",
      "tanh sgd 1500 0.01 29 (200,): Weighted 0.820206 (0.062931)\n",
      "tanh sgd 1500 0.01 29 (200,): Macro 0.697857 (0.090882)\n",
      "Testing 1869/2880\n",
      "tanh sgd 1500 0.01 42 (50,): Weighted 0.823529 (0.053290)\n",
      "tanh sgd 1500 0.01 42 (50,): Macro 0.709099 (0.059880)\n",
      "Testing 1870/2880\n",
      "tanh sgd 1500 0.01 42 (100,): Weighted 0.821377 (0.065714)\n",
      "tanh sgd 1500 0.01 42 (100,): Macro 0.708318 (0.088063)\n",
      "Testing 1871/2880\n",
      "tanh sgd 1500 0.01 42 (150,): Weighted 0.808783 (0.064918)\n",
      "tanh sgd 1500 0.01 42 (150,): Macro 0.686781 (0.084778)\n",
      "Testing 1872/2880\n",
      "tanh sgd 1500 0.01 42 (200,): Weighted 0.817018 (0.058797)\n",
      "tanh sgd 1500 0.01 42 (200,): Macro 0.699193 (0.076508)\n",
      "Testing 1873/2880\n",
      "tanh sgd 1500 0.01 76 (50,): Weighted 0.822552 (0.070439)\n",
      "tanh sgd 1500 0.01 76 (50,): Macro 0.711179 (0.095241)\n",
      "Testing 1874/2880\n",
      "tanh sgd 1500 0.01 76 (100,): Weighted 0.825063 (0.065130)\n",
      "tanh sgd 1500 0.01 76 (100,): Macro 0.709771 (0.089815)\n",
      "Testing 1875/2880\n",
      "tanh sgd 1500 0.01 76 (150,): Weighted 0.827539 (0.068329)\n",
      "tanh sgd 1500 0.01 76 (150,): Macro 0.711663 (0.100685)\n",
      "Testing 1876/2880\n",
      "tanh sgd 1500 0.01 76 (200,): Weighted 0.816717 (0.064902)\n",
      "tanh sgd 1500 0.01 76 (200,): Macro 0.698772 (0.086129)\n",
      "Testing 1877/2880\n",
      "tanh sgd 1500 0.01 112 (50,): Weighted 0.815825 (0.073070)\n",
      "tanh sgd 1500 0.01 112 (50,): Macro 0.697364 (0.103254)\n",
      "Testing 1878/2880\n",
      "tanh sgd 1500 0.01 112 (100,): Weighted 0.814428 (0.062759)\n",
      "tanh sgd 1500 0.01 112 (100,): Macro 0.688031 (0.088880)\n",
      "Testing 1879/2880\n",
      "tanh sgd 1500 0.01 112 (150,): Weighted 0.801694 (0.067559)\n",
      "tanh sgd 1500 0.01 112 (150,): Macro 0.672006 (0.091971)\n",
      "Testing 1880/2880\n",
      "tanh sgd 1500 0.01 112 (200,): Weighted 0.816409 (0.059181)\n",
      "tanh sgd 1500 0.01 112 (200,): Macro 0.692759 (0.081325)\n",
      "Testing 1881/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh sgd 1500 0.001 17 (50,): Weighted 0.808476 (0.074308)\n",
      "tanh sgd 1500 0.001 17 (50,): Macro 0.685841 (0.105493)\n",
      "Testing 1882/2880\n",
      "tanh sgd 1500 0.001 17 (100,): Weighted 0.824313 (0.056217)\n",
      "tanh sgd 1500 0.001 17 (100,): Macro 0.707443 (0.071825)\n",
      "Testing 1883/2880\n",
      "tanh sgd 1500 0.001 17 (150,): Weighted 0.809199 (0.064410)\n",
      "tanh sgd 1500 0.001 17 (150,): Macro 0.682476 (0.089961)\n",
      "Testing 1884/2880\n",
      "tanh sgd 1500 0.001 17 (200,): Weighted 0.825093 (0.054078)\n",
      "tanh sgd 1500 0.001 17 (200,): Macro 0.713719 (0.067249)\n",
      "Testing 1885/2880\n",
      "tanh sgd 1500 0.001 29 (50,): Weighted 0.828261 (0.080888)\n",
      "tanh sgd 1500 0.001 29 (50,): Macro 0.716868 (0.121143)\n",
      "Testing 1886/2880\n",
      "tanh sgd 1500 0.001 29 (100,): Weighted 0.819341 (0.067981)\n",
      "tanh sgd 1500 0.001 29 (100,): Macro 0.699307 (0.098145)\n",
      "Testing 1887/2880\n",
      "tanh sgd 1500 0.001 29 (150,): Weighted 0.819120 (0.062539)\n",
      "tanh sgd 1500 0.001 29 (150,): Macro 0.696320 (0.089204)\n",
      "Testing 1888/2880\n",
      "tanh sgd 1500 0.001 29 (200,): Weighted 0.820206 (0.062931)\n",
      "tanh sgd 1500 0.001 29 (200,): Macro 0.697857 (0.090882)\n",
      "Testing 1889/2880\n",
      "tanh sgd 1500 0.001 42 (50,): Weighted 0.823529 (0.053290)\n",
      "tanh sgd 1500 0.001 42 (50,): Macro 0.709099 (0.059880)\n",
      "Testing 1890/2880\n",
      "tanh sgd 1500 0.001 42 (100,): Weighted 0.821377 (0.065714)\n",
      "tanh sgd 1500 0.001 42 (100,): Macro 0.708318 (0.088063)\n",
      "Testing 1891/2880\n",
      "tanh sgd 1500 0.001 42 (150,): Weighted 0.808783 (0.064918)\n",
      "tanh sgd 1500 0.001 42 (150,): Macro 0.686781 (0.084778)\n",
      "Testing 1892/2880\n",
      "tanh sgd 1500 0.001 42 (200,): Weighted 0.817018 (0.058797)\n",
      "tanh sgd 1500 0.001 42 (200,): Macro 0.699193 (0.076508)\n",
      "Testing 1893/2880\n",
      "tanh sgd 1500 0.001 76 (50,): Weighted 0.822552 (0.070439)\n",
      "tanh sgd 1500 0.001 76 (50,): Macro 0.711179 (0.095241)\n",
      "Testing 1894/2880\n",
      "tanh sgd 1500 0.001 76 (100,): Weighted 0.825063 (0.065130)\n",
      "tanh sgd 1500 0.001 76 (100,): Macro 0.709771 (0.089815)\n",
      "Testing 1895/2880\n",
      "tanh sgd 1500 0.001 76 (150,): Weighted 0.827539 (0.068329)\n",
      "tanh sgd 1500 0.001 76 (150,): Macro 0.711663 (0.100685)\n",
      "Testing 1896/2880\n",
      "tanh sgd 1500 0.001 76 (200,): Weighted 0.816717 (0.064902)\n",
      "tanh sgd 1500 0.001 76 (200,): Macro 0.698772 (0.086129)\n",
      "Testing 1897/2880\n",
      "tanh sgd 1500 0.001 112 (50,): Weighted 0.815825 (0.073070)\n",
      "tanh sgd 1500 0.001 112 (50,): Macro 0.697364 (0.103254)\n",
      "Testing 1898/2880\n",
      "tanh sgd 1500 0.001 112 (100,): Weighted 0.814428 (0.062759)\n",
      "tanh sgd 1500 0.001 112 (100,): Macro 0.688031 (0.088880)\n",
      "Testing 1899/2880\n",
      "tanh sgd 1500 0.001 112 (150,): Weighted 0.801694 (0.067559)\n",
      "tanh sgd 1500 0.001 112 (150,): Macro 0.672006 (0.091971)\n",
      "Testing 1900/2880\n",
      "tanh sgd 1500 0.001 112 (200,): Weighted 0.816409 (0.059181)\n",
      "tanh sgd 1500 0.001 112 (200,): Macro 0.692759 (0.081325)\n",
      "Testing 1901/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh sgd 1500 0.0001 17 (50,): Weighted 0.808476 (0.074308)\n",
      "tanh sgd 1500 0.0001 17 (50,): Macro 0.685841 (0.105493)\n",
      "Testing 1902/2880\n",
      "tanh sgd 1500 0.0001 17 (100,): Weighted 0.824313 (0.056217)\n",
      "tanh sgd 1500 0.0001 17 (100,): Macro 0.707443 (0.071825)\n",
      "Testing 1903/2880\n",
      "tanh sgd 1500 0.0001 17 (150,): Weighted 0.809199 (0.064410)\n",
      "tanh sgd 1500 0.0001 17 (150,): Macro 0.682476 (0.089961)\n",
      "Testing 1904/2880\n",
      "tanh sgd 1500 0.0001 17 (200,): Weighted 0.825093 (0.054078)\n",
      "tanh sgd 1500 0.0001 17 (200,): Macro 0.713719 (0.067249)\n",
      "Testing 1905/2880\n",
      "tanh sgd 1500 0.0001 29 (50,): Weighted 0.828261 (0.080888)\n",
      "tanh sgd 1500 0.0001 29 (50,): Macro 0.716868 (0.121143)\n",
      "Testing 1906/2880\n",
      "tanh sgd 1500 0.0001 29 (100,): Weighted 0.819341 (0.067981)\n",
      "tanh sgd 1500 0.0001 29 (100,): Macro 0.699307 (0.098145)\n",
      "Testing 1907/2880\n",
      "tanh sgd 1500 0.0001 29 (150,): Weighted 0.819120 (0.062539)\n",
      "tanh sgd 1500 0.0001 29 (150,): Macro 0.696320 (0.089204)\n",
      "Testing 1908/2880\n",
      "tanh sgd 1500 0.0001 29 (200,): Weighted 0.820206 (0.062931)\n",
      "tanh sgd 1500 0.0001 29 (200,): Macro 0.697857 (0.090882)\n",
      "Testing 1909/2880\n",
      "tanh sgd 1500 0.0001 42 (50,): Weighted 0.823529 (0.053290)\n",
      "tanh sgd 1500 0.0001 42 (50,): Macro 0.709099 (0.059880)\n",
      "Testing 1910/2880\n",
      "tanh sgd 1500 0.0001 42 (100,): Weighted 0.821377 (0.065714)\n",
      "tanh sgd 1500 0.0001 42 (100,): Macro 0.708318 (0.088063)\n",
      "Testing 1911/2880\n",
      "tanh sgd 1500 0.0001 42 (150,): Weighted 0.808783 (0.064918)\n",
      "tanh sgd 1500 0.0001 42 (150,): Macro 0.686781 (0.084778)\n",
      "Testing 1912/2880\n",
      "tanh sgd 1500 0.0001 42 (200,): Weighted 0.817018 (0.058797)\n",
      "tanh sgd 1500 0.0001 42 (200,): Macro 0.699193 (0.076508)\n",
      "Testing 1913/2880\n",
      "tanh sgd 1500 0.0001 76 (50,): Weighted 0.822552 (0.070439)\n",
      "tanh sgd 1500 0.0001 76 (50,): Macro 0.711179 (0.095241)\n",
      "Testing 1914/2880\n",
      "tanh sgd 1500 0.0001 76 (100,): Weighted 0.825063 (0.065130)\n",
      "tanh sgd 1500 0.0001 76 (100,): Macro 0.709771 (0.089815)\n",
      "Testing 1915/2880\n",
      "tanh sgd 1500 0.0001 76 (150,): Weighted 0.827539 (0.068329)\n",
      "tanh sgd 1500 0.0001 76 (150,): Macro 0.711663 (0.100685)\n",
      "Testing 1916/2880\n",
      "tanh sgd 1500 0.0001 76 (200,): Weighted 0.816717 (0.064902)\n",
      "tanh sgd 1500 0.0001 76 (200,): Macro 0.698772 (0.086129)\n",
      "Testing 1917/2880\n",
      "tanh sgd 1500 0.0001 112 (50,): Weighted 0.815825 (0.073070)\n",
      "tanh sgd 1500 0.0001 112 (50,): Macro 0.697364 (0.103254)\n",
      "Testing 1918/2880\n",
      "tanh sgd 1500 0.0001 112 (100,): Weighted 0.814428 (0.062759)\n",
      "tanh sgd 1500 0.0001 112 (100,): Macro 0.688031 (0.088880)\n",
      "Testing 1919/2880\n",
      "tanh sgd 1500 0.0001 112 (150,): Weighted 0.801694 (0.067559)\n",
      "tanh sgd 1500 0.0001 112 (150,): Macro 0.672006 (0.091971)\n",
      "Testing 1920/2880\n",
      "tanh sgd 1500 0.0001 112 (200,): Weighted 0.816409 (0.059181)\n",
      "tanh sgd 1500 0.0001 112 (200,): Macro 0.692759 (0.081325)\n",
      "Testing 1921/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh adam 500 0.1 17 (50,): Weighted 0.815466 (0.062842)\n",
      "tanh adam 500 0.1 17 (50,): Macro 0.689454 (0.089398)\n",
      "Testing 1922/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh adam 500 0.1 17 (100,): Weighted 0.822445 (0.056180)\n",
      "tanh adam 500 0.1 17 (100,): Macro 0.706741 (0.071635)\n",
      "Testing 1923/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh adam 500 0.1 17 (150,): Weighted 0.814697 (0.062121)\n",
      "tanh adam 500 0.1 17 (150,): Macro 0.696297 (0.079662)\n",
      "Testing 1924/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh adam 500 0.1 17 (200,): Weighted 0.790136 (0.066707)\n",
      "tanh adam 500 0.1 17 (200,): Macro 0.663478 (0.079909)\n",
      "Testing 1925/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh adam 500 0.1 29 (50,): Weighted 0.821308 (0.060734)\n",
      "tanh adam 500 0.1 29 (50,): Macro 0.702830 (0.080465)\n",
      "Testing 1926/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh adam 500 0.1 29 (100,): Weighted 0.819233 (0.047465)\n",
      "tanh adam 500 0.1 29 (100,): Macro 0.701508 (0.057259)\n",
      "Testing 1927/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh adam 500 0.1 29 (150,): Weighted 0.822445 (0.056180)\n",
      "tanh adam 500 0.1 29 (150,): Macro 0.706741 (0.071635)\n",
      "Testing 1928/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh adam 500 0.1 29 (200,): Weighted 0.817332 (0.058023)\n",
      "tanh adam 500 0.1 29 (200,): Macro 0.699840 (0.073940)\n",
      "Testing 1929/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh adam 500 0.1 42 (50,): Weighted 0.824604 (0.058040)\n",
      "tanh adam 500 0.1 42 (50,): Macro 0.709130 (0.076764)\n",
      "Testing 1930/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh adam 500 0.1 42 (100,): Weighted 0.811902 (0.052381)\n",
      "tanh adam 500 0.1 42 (100,): Macro 0.691114 (0.063896)\n",
      "Testing 1931/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh adam 500 0.1 42 (150,): Weighted 0.799884 (0.050024)\n",
      "tanh adam 500 0.1 42 (150,): Macro 0.668905 (0.051347)\n",
      "Testing 1932/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh adam 500 0.1 42 (200,): Weighted 0.803157 (0.056706)\n",
      "tanh adam 500 0.1 42 (200,): Macro 0.681892 (0.067725)\n",
      "Testing 1933/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh adam 500 0.1 76 (50,): Weighted 0.822733 (0.059729)\n",
      "tanh adam 500 0.1 76 (50,): Macro 0.710053 (0.074682)\n",
      "Testing 1934/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh adam 500 0.1 76 (100,): Weighted 0.822833 (0.059463)\n",
      "tanh adam 500 0.1 76 (100,): Macro 0.703073 (0.080261)\n",
      "Testing 1935/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh adam 500 0.1 76 (150,): Weighted 0.797771 (0.060797)\n",
      "tanh adam 500 0.1 76 (150,): Macro 0.672846 (0.073563)\n",
      "Testing 1936/2880\n",
      "tanh adam 500 0.1 76 (200,): Weighted 0.804552 (0.066117)\n",
      "tanh adam 500 0.1 76 (200,): Macro 0.683856 (0.083323)\n",
      "Testing 1937/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh adam 500 0.1 112 (50,): Weighted 0.827084 (0.065367)\n",
      "tanh adam 500 0.1 112 (50,): Macro 0.710820 (0.095251)\n",
      "Testing 1938/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh adam 500 0.1 112 (100,): Weighted 0.816080 (0.059500)\n",
      "tanh adam 500 0.1 112 (100,): Macro 0.698481 (0.076290)\n",
      "Testing 1939/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh adam 500 0.1 112 (150,): Weighted 0.799016 (0.054326)\n",
      "tanh adam 500 0.1 112 (150,): Macro 0.669823 (0.057779)\n",
      "Testing 1940/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh adam 500 0.1 112 (200,): Weighted 0.815821 (0.059587)\n",
      "tanh adam 500 0.1 112 (200,): Macro 0.698446 (0.076539)\n",
      "Testing 1941/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh adam 500 0.01 17 (50,): Weighted 0.819846 (0.070012)\n",
      "tanh adam 500 0.01 17 (50,): Macro 0.697671 (0.102285)\n",
      "Testing 1942/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh adam 500 0.01 17 (100,): Weighted 0.826606 (0.053371)\n",
      "tanh adam 500 0.01 17 (100,): Macro 0.712465 (0.068433)\n",
      "Testing 1943/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh adam 500 0.01 17 (150,): Weighted 0.819016 (0.058817)\n",
      "tanh adam 500 0.01 17 (150,): Macro 0.702035 (0.075850)\n",
      "Testing 1944/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh adam 500 0.01 17 (200,): Weighted 0.799056 (0.054827)\n",
      "tanh adam 500 0.01 17 (200,): Macro 0.673976 (0.063834)\n",
      "Testing 1945/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh adam 500 0.01 29 (50,): Weighted 0.816091 (0.065645)\n",
      "tanh adam 500 0.01 29 (50,): Macro 0.690730 (0.093285)\n",
      "Testing 1946/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh adam 500 0.01 29 (100,): Weighted 0.819233 (0.047465)\n",
      "tanh adam 500 0.01 29 (100,): Macro 0.701508 (0.057259)\n",
      "Testing 1947/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh adam 500 0.01 29 (150,): Weighted 0.819016 (0.058817)\n",
      "tanh adam 500 0.01 29 (150,): Macro 0.702035 (0.075850)\n",
      "Testing 1948/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh adam 500 0.01 29 (200,): Weighted 0.821711 (0.065596)\n",
      "tanh adam 500 0.01 29 (200,): Macro 0.708057 (0.088129)\n",
      "Testing 1949/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh adam 500 0.01 42 (50,): Weighted 0.821175 (0.060718)\n",
      "tanh adam 500 0.01 42 (50,): Macro 0.704423 (0.080851)\n",
      "Testing 1950/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh adam 500 0.01 42 (100,): Weighted 0.811902 (0.052381)\n",
      "tanh adam 500 0.01 42 (100,): Macro 0.691114 (0.063896)\n",
      "Testing 1951/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh adam 500 0.01 42 (150,): Weighted 0.804637 (0.043291)\n",
      "tanh adam 500 0.01 42 (150,): Macro 0.675846 (0.040771)\n",
      "Testing 1952/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh adam 500 0.01 42 (200,): Weighted 0.807318 (0.055393)\n",
      "tanh adam 500 0.01 42 (200,): Macro 0.687615 (0.066503)\n",
      "Testing 1953/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh adam 500 0.01 76 (50,): Weighted 0.826894 (0.057074)\n",
      "tanh adam 500 0.01 76 (50,): Macro 0.715776 (0.071352)\n",
      "Testing 1954/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh adam 500 0.01 76 (100,): Weighted 0.826262 (0.056625)\n",
      "tanh adam 500 0.01 76 (100,): Macro 0.707779 (0.076226)\n",
      "Testing 1955/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh adam 500 0.01 76 (150,): Weighted 0.796125 (0.064842)\n",
      "tanh adam 500 0.01 76 (150,): Macro 0.670232 (0.078541)\n",
      "Testing 1956/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh adam 500 0.01 76 (200,): Weighted 0.814216 (0.059764)\n",
      "tanh adam 500 0.01 76 (200,): Macro 0.696481 (0.075722)\n",
      "Testing 1957/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh adam 500 0.01 112 (50,): Weighted 0.826069 (0.065874)\n",
      "tanh adam 500 0.01 112 (50,): Macro 0.711230 (0.095129)\n",
      "Testing 1958/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh adam 500 0.01 112 (100,): Weighted 0.816080 (0.059500)\n",
      "tanh adam 500 0.01 112 (100,): Macro 0.698481 (0.076290)\n",
      "Testing 1959/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh adam 500 0.01 112 (150,): Weighted 0.794786 (0.039878)\n",
      "tanh adam 500 0.01 112 (150,): Macro 0.662024 (0.034226)\n",
      "Testing 1960/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh adam 500 0.01 112 (200,): Weighted 0.805076 (0.051791)\n",
      "tanh adam 500 0.01 112 (200,): Macro 0.677644 (0.055057)\n",
      "Testing 1961/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh adam 500 0.001 17 (50,): Weighted 0.824585 (0.069795)\n",
      "tanh adam 500 0.001 17 (50,): Macro 0.706073 (0.102916)\n",
      "Testing 1962/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh adam 500 0.001 17 (100,): Weighted 0.828187 (0.052524)\n",
      "tanh adam 500 0.001 17 (100,): Macro 0.711739 (0.068768)\n",
      "Testing 1963/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh adam 500 0.001 17 (150,): Weighted 0.814838 (0.051841)\n",
      "tanh adam 500 0.001 17 (150,): Macro 0.694667 (0.063781)\n",
      "Testing 1964/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh adam 500 0.001 17 (200,): Weighted 0.799056 (0.054827)\n",
      "tanh adam 500 0.001 17 (200,): Macro 0.673976 (0.063834)\n",
      "Testing 1965/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh adam 500 0.001 29 (50,): Weighted 0.811633 (0.069207)\n",
      "tanh adam 500 0.001 29 (50,): Macro 0.685079 (0.097101)\n",
      "Testing 1966/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh adam 500 0.001 29 (100,): Weighted 0.822427 (0.046260)\n",
      "tanh adam 500 0.001 29 (100,): Macro 0.705097 (0.056138)\n",
      "Testing 1967/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh adam 500 0.001 29 (150,): Weighted 0.822445 (0.056180)\n",
      "tanh adam 500 0.001 29 (150,): Macro 0.706741 (0.071635)\n",
      "Testing 1968/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh adam 500 0.001 29 (200,): Weighted 0.821711 (0.065596)\n",
      "tanh adam 500 0.001 29 (200,): Macro 0.708057 (0.088129)\n",
      "Testing 1969/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh adam 500 0.001 42 (50,): Weighted 0.826142 (0.061914)\n",
      "tanh adam 500 0.001 42 (50,): Macro 0.711505 (0.083657)\n",
      "Testing 1970/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh adam 500 0.001 42 (100,): Weighted 0.811902 (0.052381)\n",
      "tanh adam 500 0.001 42 (100,): Macro 0.691114 (0.063896)\n",
      "Testing 1971/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh adam 500 0.001 42 (150,): Weighted 0.800118 (0.048179)\n",
      "tanh adam 500 0.001 42 (150,): Macro 0.670023 (0.047199)\n",
      "Testing 1972/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh adam 500 0.001 42 (200,): Weighted 0.807318 (0.055393)\n",
      "tanh adam 500 0.001 42 (200,): Macro 0.687615 (0.066503)\n",
      "Testing 1973/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh adam 500 0.001 76 (50,): Weighted 0.831478 (0.052472)\n",
      "tanh adam 500 0.001 76 (50,): Macro 0.719274 (0.067484)\n",
      "Testing 1974/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh adam 500 0.001 76 (100,): Weighted 0.826262 (0.056625)\n",
      "tanh adam 500 0.001 76 (100,): Macro 0.707779 (0.076226)\n",
      "Testing 1975/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh adam 500 0.001 76 (150,): Weighted 0.804315 (0.058435)\n",
      "tanh adam 500 0.001 76 (150,): Macro 0.680912 (0.070178)\n",
      "Testing 1976/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh adam 500 0.001 76 (200,): Weighted 0.813161 (0.060407)\n",
      "tanh adam 500 0.001 76 (200,): Macro 0.690709 (0.079163)\n",
      "Testing 1977/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh adam 500 0.001 112 (50,): Weighted 0.815853 (0.047155)\n",
      "tanh adam 500 0.001 112 (50,): Macro 0.688275 (0.062102)\n",
      "Testing 1978/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh adam 500 0.001 112 (100,): Weighted 0.816080 (0.059500)\n",
      "tanh adam 500 0.001 112 (100,): Macro 0.698481 (0.076290)\n",
      "Testing 1979/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh adam 500 0.001 112 (150,): Weighted 0.794786 (0.039878)\n",
      "tanh adam 500 0.001 112 (150,): Macro 0.662024 (0.034226)\n",
      "Testing 1980/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh adam 500 0.001 112 (200,): Weighted 0.800557 (0.055976)\n",
      "tanh adam 500 0.001 112 (200,): Macro 0.671821 (0.060147)\n",
      "Testing 1981/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh adam 500 0.0001 17 (50,): Weighted 0.819950 (0.066926)\n",
      "tanh adam 500 0.0001 17 (50,): Macro 0.702870 (0.091892)\n",
      "Testing 1982/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh adam 500 0.0001 17 (100,): Weighted 0.826606 (0.053371)\n",
      "tanh adam 500 0.0001 17 (100,): Macro 0.712465 (0.068433)\n",
      "Testing 1983/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh adam 500 0.0001 17 (150,): Weighted 0.818999 (0.049428)\n",
      "tanh adam 500 0.0001 17 (150,): Macro 0.700390 (0.061300)\n",
      "Testing 1984/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh adam 500 0.0001 17 (200,): Weighted 0.799056 (0.054827)\n",
      "tanh adam 500 0.0001 17 (200,): Macro 0.673976 (0.063834)\n",
      "Testing 1985/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh adam 500 0.0001 29 (50,): Weighted 0.820338 (0.062949)\n",
      "tanh adam 500 0.0001 29 (50,): Macro 0.696264 (0.090423)\n",
      "Testing 1986/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh adam 500 0.0001 29 (100,): Weighted 0.822427 (0.046260)\n",
      "tanh adam 500 0.0001 29 (100,): Macro 0.705097 (0.056138)\n",
      "Testing 1987/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh adam 500 0.0001 29 (150,): Weighted 0.822445 (0.056180)\n",
      "tanh adam 500 0.0001 29 (150,): Macro 0.706741 (0.071635)\n",
      "Testing 1988/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh adam 500 0.0001 29 (200,): Weighted 0.821711 (0.065596)\n",
      "tanh adam 500 0.0001 29 (200,): Macro 0.708057 (0.088129)\n",
      "Testing 1989/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh adam 500 0.0001 42 (50,): Weighted 0.821175 (0.060718)\n",
      "tanh adam 500 0.0001 42 (50,): Macro 0.704423 (0.080851)\n",
      "Testing 1990/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh adam 500 0.0001 42 (100,): Weighted 0.811902 (0.052381)\n",
      "tanh adam 500 0.0001 42 (100,): Macro 0.691114 (0.063896)\n",
      "Testing 1991/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh adam 500 0.0001 42 (150,): Weighted 0.800118 (0.048179)\n",
      "tanh adam 500 0.0001 42 (150,): Macro 0.670023 (0.047199)\n",
      "Testing 1992/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh adam 500 0.0001 42 (200,): Weighted 0.807318 (0.055393)\n",
      "tanh adam 500 0.0001 42 (200,): Macro 0.687615 (0.066503)\n",
      "Testing 1993/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh adam 500 0.0001 76 (50,): Weighted 0.829050 (0.054815)\n",
      "tanh adam 500 0.0001 76 (50,): Macro 0.710443 (0.077789)\n",
      "Testing 1994/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh adam 500 0.0001 76 (100,): Weighted 0.826262 (0.056625)\n",
      "tanh adam 500 0.0001 76 (100,): Macro 0.707779 (0.076226)\n",
      "Testing 1995/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh adam 500 0.0001 76 (150,): Weighted 0.799553 (0.063704)\n",
      "tanh adam 500 0.0001 76 (150,): Macro 0.674939 (0.076462)\n",
      "Testing 1996/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh adam 500 0.0001 76 (200,): Weighted 0.813161 (0.060407)\n",
      "tanh adam 500 0.0001 76 (200,): Macro 0.690709 (0.079163)\n",
      "Testing 1997/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh adam 500 0.0001 112 (50,): Weighted 0.821953 (0.051045)\n",
      "tanh adam 500 0.0001 112 (50,): Macro 0.699953 (0.066747)\n",
      "Testing 1998/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh adam 500 0.0001 112 (100,): Weighted 0.816080 (0.059500)\n",
      "tanh adam 500 0.0001 112 (100,): Macro 0.698481 (0.076290)\n",
      "Testing 1999/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh adam 500 0.0001 112 (150,): Weighted 0.794786 (0.039878)\n",
      "tanh adam 500 0.0001 112 (150,): Macro 0.662024 (0.034226)\n",
      "Testing 2000/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh adam 500 0.0001 112 (200,): Weighted 0.805076 (0.051791)\n",
      "tanh adam 500 0.0001 112 (200,): Macro 0.677644 (0.055057)\n",
      "Testing 2001/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh adam 1000 0.1 17 (50,): Weighted 0.822022 (0.057514)\n",
      "tanh adam 1000 0.1 17 (50,): Macro 0.708966 (0.071920)\n",
      "Testing 2002/2880\n",
      "tanh adam 1000 0.1 17 (100,): Weighted 0.812807 (0.061118)\n",
      "tanh adam 1000 0.1 17 (100,): Macro 0.694939 (0.077780)\n",
      "Testing 2003/2880\n",
      "tanh adam 1000 0.1 17 (150,): Weighted 0.823888 (0.058636)\n",
      "tanh adam 1000 0.1 17 (150,): Macro 0.708845 (0.075936)\n",
      "Testing 2004/2880\n",
      "tanh adam 1000 0.1 17 (200,): Weighted 0.803639 (0.057268)\n",
      "tanh adam 1000 0.1 17 (200,): Macro 0.676627 (0.072423)\n",
      "Testing 2005/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh adam 1000 0.1 29 (50,): Weighted 0.823177 (0.056393)\n",
      "tanh adam 1000 0.1 29 (50,): Macro 0.707758 (0.073203)\n",
      "Testing 2006/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh adam 1000 0.1 29 (100,): Weighted 0.817811 (0.049488)\n",
      "tanh adam 1000 0.1 29 (100,): Macro 0.701507 (0.057939)\n",
      "Testing 2007/2880\n",
      "tanh adam 1000 0.1 29 (150,): Weighted 0.824509 (0.059746)\n",
      "tanh adam 1000 0.1 29 (150,): Macro 0.709864 (0.078521)\n",
      "Testing 2008/2880\n",
      "tanh adam 1000 0.1 29 (200,): Weighted 0.812870 (0.070746)\n",
      "tanh adam 1000 0.1 29 (200,): Macro 0.696268 (0.095352)\n",
      "Testing 2009/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh adam 1000 0.1 42 (50,): Weighted 0.826606 (0.053371)\n",
      "tanh adam 1000 0.1 42 (50,): Macro 0.712465 (0.068433)\n",
      "Testing 2010/2880\n",
      "tanh adam 1000 0.1 42 (100,): Weighted 0.807514 (0.057478)\n",
      "tanh adam 1000 0.1 42 (100,): Macro 0.688721 (0.068480)\n",
      "Testing 2011/2880\n",
      "tanh adam 1000 0.1 42 (150,): Weighted 0.803307 (0.046230)\n",
      "tanh adam 1000 0.1 42 (150,): Macro 0.674533 (0.045848)\n",
      "Testing 2012/2880\n",
      "tanh adam 1000 0.1 42 (200,): Weighted 0.801148 (0.057817)\n",
      "tanh adam 1000 0.1 42 (200,): Macro 0.676232 (0.070297)\n",
      "Testing 2013/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh adam 1000 0.1 76 (50,): Weighted 0.821493 (0.055691)\n",
      "tanh adam 1000 0.1 76 (50,): Macro 0.705564 (0.071398)\n",
      "Testing 2014/2880\n",
      "tanh adam 1000 0.1 76 (100,): Weighted 0.822998 (0.059774)\n",
      "tanh adam 1000 0.1 76 (100,): Macro 0.707813 (0.076194)\n",
      "Testing 2015/2880\n",
      "tanh adam 1000 0.1 76 (150,): Weighted 0.789358 (0.051299)\n",
      "tanh adam 1000 0.1 76 (150,): Macro 0.654922 (0.050551)\n",
      "Testing 2016/2880\n",
      "tanh adam 1000 0.1 76 (200,): Weighted 0.804552 (0.066117)\n",
      "tanh adam 1000 0.1 76 (200,): Macro 0.683856 (0.083323)\n",
      "Testing 2017/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh adam 1000 0.1 112 (50,): Weighted 0.818414 (0.063240)\n",
      "tanh adam 1000 0.1 112 (50,): Macro 0.704315 (0.079135)\n",
      "Testing 2018/2880\n",
      "tanh adam 1000 0.1 112 (100,): Weighted 0.807770 (0.040815)\n",
      "tanh adam 1000 0.1 112 (100,): Macro 0.679288 (0.040533)\n",
      "Testing 2019/2880\n",
      "tanh adam 1000 0.1 112 (150,): Weighted 0.797075 (0.054908)\n",
      "tanh adam 1000 0.1 112 (150,): Macro 0.662044 (0.061201)\n",
      "Testing 2020/2880\n",
      "tanh adam 1000 0.1 112 (200,): Weighted 0.808490 (0.063177)\n",
      "tanh adam 1000 0.1 112 (200,): Macro 0.688052 (0.081232)\n",
      "Testing 2021/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh adam 1000 0.01 17 (50,): Weighted 0.827833 (0.049802)\n",
      "tanh adam 1000 0.01 17 (50,): Macro 0.712729 (0.053825)\n",
      "Testing 2022/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh adam 1000 0.01 17 (100,): Weighted 0.812107 (0.051442)\n",
      "tanh adam 1000 0.01 17 (100,): Macro 0.692483 (0.061226)\n",
      "Testing 2023/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh adam 1000 0.01 17 (150,): Weighted 0.812847 (0.060921)\n",
      "tanh adam 1000 0.01 17 (150,): Macro 0.689362 (0.080877)\n",
      "Testing 2024/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh adam 1000 0.01 17 (200,): Weighted 0.798196 (0.045409)\n",
      "tanh adam 1000 0.01 17 (200,): Macro 0.666483 (0.044508)\n",
      "Testing 2025/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh adam 1000 0.01 29 (50,): Weighted 0.814641 (0.043871)\n",
      "tanh adam 1000 0.01 29 (50,): Macro 0.691235 (0.047123)\n",
      "Testing 2026/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh adam 1000 0.01 29 (100,): Weighted 0.806211 (0.044109)\n",
      "tanh adam 1000 0.01 29 (100,): Macro 0.674496 (0.052224)\n",
      "Testing 2027/2880\n",
      "tanh adam 1000 0.01 29 (150,): Weighted 0.802459 (0.062018)\n",
      "tanh adam 1000 0.01 29 (150,): Macro 0.678403 (0.076616)\n",
      "Testing 2028/2880\n",
      "tanh adam 1000 0.01 29 (200,): Weighted 0.811919 (0.061322)\n",
      "tanh adam 1000 0.01 29 (200,): Macro 0.692758 (0.078158)\n",
      "Testing 2029/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh adam 1000 0.01 42 (50,): Weighted 0.832004 (0.056422)\n",
      "tanh adam 1000 0.01 42 (50,): Macro 0.720365 (0.072855)\n",
      "Testing 2030/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh adam 1000 0.01 42 (100,): Weighted 0.806087 (0.052921)\n",
      "tanh adam 1000 0.01 42 (100,): Macro 0.682240 (0.054927)\n",
      "Testing 2031/2880\n",
      "tanh adam 1000 0.01 42 (150,): Weighted 0.796568 (0.047612)\n",
      "tanh adam 1000 0.01 42 (150,): Macro 0.668158 (0.044186)\n",
      "Testing 2032/2880\n",
      "tanh adam 1000 0.01 42 (200,): Weighted 0.798707 (0.059629)\n",
      "tanh adam 1000 0.01 42 (200,): Macro 0.671452 (0.073566)\n",
      "Testing 2033/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh adam 1000 0.01 76 (50,): Weighted 0.832021 (0.035497)\n",
      "tanh adam 1000 0.01 76 (50,): Macro 0.715504 (0.037021)\n",
      "Testing 2034/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh adam 1000 0.01 76 (100,): Weighted 0.812694 (0.068564)\n",
      "tanh adam 1000 0.01 76 (100,): Macro 0.694001 (0.089437)\n",
      "Testing 2035/2880\n",
      "tanh adam 1000 0.01 76 (150,): Weighted 0.797140 (0.045884)\n",
      "tanh adam 1000 0.01 76 (150,): Macro 0.660711 (0.046557)\n",
      "Testing 2036/2880\n",
      "tanh adam 1000 0.01 76 (200,): Weighted 0.811795 (0.061925)\n",
      "tanh adam 1000 0.01 76 (200,): Macro 0.696454 (0.076513)\n",
      "Testing 2037/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh adam 1000 0.01 112 (50,): Weighted 0.809849 (0.059109)\n",
      "tanh adam 1000 0.01 112 (50,): Macro 0.681155 (0.076309)\n",
      "Testing 2038/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh adam 1000 0.01 112 (100,): Weighted 0.811095 (0.039836)\n",
      "tanh adam 1000 0.01 112 (100,): Macro 0.679401 (0.041501)\n",
      "Testing 2039/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh adam 1000 0.01 112 (150,): Weighted 0.785234 (0.049030)\n",
      "tanh adam 1000 0.01 112 (150,): Macro 0.642912 (0.038868)\n",
      "Testing 2040/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh adam 1000 0.01 112 (200,): Weighted 0.803352 (0.051321)\n",
      "tanh adam 1000 0.01 112 (200,): Macro 0.679323 (0.051399)\n",
      "Testing 2041/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh adam 1000 0.001 17 (50,): Weighted 0.824512 (0.053311)\n",
      "tanh adam 1000 0.001 17 (50,): Macro 0.707988 (0.059443)\n",
      "Testing 2042/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh adam 1000 0.001 17 (100,): Weighted 0.812107 (0.051442)\n",
      "tanh adam 1000 0.001 17 (100,): Macro 0.692483 (0.061226)\n",
      "Testing 2043/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh adam 1000 0.001 17 (150,): Weighted 0.801546 (0.057545)\n",
      "tanh adam 1000 0.001 17 (150,): Macro 0.675194 (0.070938)\n",
      "Testing 2044/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh adam 1000 0.001 17 (200,): Weighted 0.797140 (0.045884)\n",
      "tanh adam 1000 0.001 17 (200,): Macro 0.660711 (0.046557)\n",
      "Testing 2045/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh adam 1000 0.001 29 (50,): Weighted 0.812785 (0.048934)\n",
      "tanh adam 1000 0.001 29 (50,): Macro 0.688725 (0.056723)\n",
      "Testing 2046/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh adam 1000 0.001 29 (100,): Weighted 0.806211 (0.044109)\n",
      "tanh adam 1000 0.001 29 (100,): Macro 0.674496 (0.052224)\n",
      "Testing 2047/2880\n",
      "tanh adam 1000 0.001 29 (150,): Weighted 0.806308 (0.058649)\n",
      "tanh adam 1000 0.001 29 (150,): Macro 0.679020 (0.076093)\n",
      "Testing 2048/2880\n",
      "tanh adam 1000 0.001 29 (200,): Weighted 0.811919 (0.061322)\n",
      "tanh adam 1000 0.001 29 (200,): Macro 0.692758 (0.078158)\n",
      "Testing 2049/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh adam 1000 0.001 42 (50,): Weighted 0.827317 (0.055692)\n",
      "tanh adam 1000 0.001 42 (50,): Macro 0.713551 (0.071277)\n",
      "Testing 2050/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh adam 1000 0.001 42 (100,): Weighted 0.806087 (0.052921)\n",
      "tanh adam 1000 0.001 42 (100,): Macro 0.682240 (0.054927)\n",
      "Testing 2051/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh adam 1000 0.001 42 (150,): Weighted 0.800152 (0.045105)\n",
      "tanh adam 1000 0.001 42 (150,): Macro 0.673376 (0.040479)\n",
      "Testing 2052/2880\n",
      "tanh adam 1000 0.001 42 (200,): Weighted 0.798707 (0.059629)\n",
      "tanh adam 1000 0.001 42 (200,): Macro 0.671452 (0.073566)\n",
      "Testing 2053/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh adam 1000 0.001 76 (50,): Weighted 0.827148 (0.036884)\n",
      "tanh adam 1000 0.001 76 (50,): Macro 0.708694 (0.038055)\n",
      "Testing 2054/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh adam 1000 0.001 76 (100,): Weighted 0.821281 (0.061163)\n",
      "tanh adam 1000 0.001 76 (100,): Macro 0.702619 (0.081443)\n",
      "Testing 2055/2880\n",
      "tanh adam 1000 0.001 76 (150,): Weighted 0.797140 (0.045884)\n",
      "tanh adam 1000 0.001 76 (150,): Macro 0.660711 (0.046557)\n",
      "Testing 2056/2880\n",
      "tanh adam 1000 0.001 76 (200,): Weighted 0.810739 (0.062504)\n",
      "tanh adam 1000 0.001 76 (200,): Macro 0.690682 (0.079917)\n",
      "Testing 2057/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh adam 1000 0.001 112 (50,): Weighted 0.811009 (0.048486)\n",
      "tanh adam 1000 0.001 112 (50,): Macro 0.688914 (0.051354)\n",
      "Testing 2058/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh adam 1000 0.001 112 (100,): Weighted 0.811199 (0.037944)\n",
      "tanh adam 1000 0.001 112 (100,): Macro 0.683995 (0.035148)\n",
      "Testing 2059/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh adam 1000 0.001 112 (150,): Weighted 0.793337 (0.041381)\n",
      "tanh adam 1000 0.001 112 (150,): Macro 0.651221 (0.030854)\n",
      "Testing 2060/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh adam 1000 0.001 112 (200,): Weighted 0.802203 (0.057367)\n",
      "tanh adam 1000 0.001 112 (200,): Macro 0.682004 (0.067646)\n",
      "Testing 2061/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh adam 1000 0.0001 17 (50,): Weighted 0.824512 (0.053311)\n",
      "tanh adam 1000 0.0001 17 (50,): Macro 0.707988 (0.059443)\n",
      "Testing 2062/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh adam 1000 0.0001 17 (100,): Weighted 0.812107 (0.051442)\n",
      "tanh adam 1000 0.0001 17 (100,): Macro 0.692483 (0.061226)\n",
      "Testing 2063/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh adam 1000 0.0001 17 (150,): Weighted 0.796097 (0.061828)\n",
      "tanh adam 1000 0.0001 17 (150,): Macro 0.662422 (0.081697)\n",
      "Testing 2064/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh adam 1000 0.0001 17 (200,): Weighted 0.793226 (0.057882)\n",
      "tanh adam 1000 0.0001 17 (200,): Macro 0.661427 (0.061681)\n",
      "Testing 2065/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh adam 1000 0.0001 29 (50,): Weighted 0.819637 (0.059973)\n",
      "tanh adam 1000 0.0001 29 (50,): Macro 0.703055 (0.078527)\n",
      "Testing 2066/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh adam 1000 0.0001 29 (100,): Weighted 0.818947 (0.038129)\n",
      "tanh adam 1000 0.0001 29 (100,): Macro 0.699173 (0.032302)\n",
      "Testing 2067/2880\n",
      "tanh adam 1000 0.0001 29 (150,): Weighted 0.806308 (0.058649)\n",
      "tanh adam 1000 0.0001 29 (150,): Macro 0.679020 (0.076093)\n",
      "Testing 2068/2880\n",
      "tanh adam 1000 0.0001 29 (200,): Weighted 0.816299 (0.068876)\n",
      "tanh adam 1000 0.0001 29 (200,): Macro 0.700975 (0.092329)\n",
      "Testing 2069/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh adam 1000 0.0001 42 (50,): Weighted 0.822445 (0.056180)\n",
      "tanh adam 1000 0.0001 42 (50,): Macro 0.706741 (0.071635)\n",
      "Testing 2070/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh adam 1000 0.0001 42 (100,): Weighted 0.800866 (0.059116)\n",
      "tanh adam 1000 0.0001 42 (100,): Macro 0.677720 (0.060735)\n",
      "Testing 2071/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh adam 1000 0.0001 42 (150,): Weighted 0.800152 (0.045105)\n",
      "tanh adam 1000 0.0001 42 (150,): Macro 0.673376 (0.040479)\n",
      "Testing 2072/2880\n",
      "tanh adam 1000 0.0001 42 (200,): Weighted 0.798707 (0.059629)\n",
      "tanh adam 1000 0.0001 42 (200,): Macro 0.671452 (0.073566)\n",
      "Testing 2073/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh adam 1000 0.0001 76 (50,): Weighted 0.828672 (0.039113)\n",
      "tanh adam 1000 0.0001 76 (50,): Macro 0.710731 (0.043627)\n",
      "Testing 2074/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh adam 1000 0.0001 76 (100,): Weighted 0.817282 (0.064951)\n",
      "tanh adam 1000 0.0001 76 (100,): Macro 0.699519 (0.083705)\n",
      "Testing 2075/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh adam 1000 0.0001 76 (150,): Weighted 0.795689 (0.056411)\n",
      "tanh adam 1000 0.0001 76 (150,): Macro 0.662596 (0.061311)\n",
      "Testing 2076/2880\n",
      "tanh adam 1000 0.0001 76 (200,): Weighted 0.810739 (0.062504)\n",
      "tanh adam 1000 0.0001 76 (200,): Macro 0.690682 (0.079917)\n",
      "Testing 2077/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh adam 1000 0.0001 112 (50,): Weighted 0.811380 (0.054786)\n",
      "tanh adam 1000 0.0001 112 (50,): Macro 0.683058 (0.067209)\n",
      "Testing 2078/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh adam 1000 0.0001 112 (100,): Weighted 0.814548 (0.035874)\n",
      "tanh adam 1000 0.0001 112 (100,): Macro 0.688768 (0.030949)\n",
      "Testing 2079/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh adam 1000 0.0001 112 (150,): Weighted 0.785234 (0.049030)\n",
      "tanh adam 1000 0.0001 112 (150,): Macro 0.642912 (0.038868)\n",
      "Testing 2080/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh adam 1000 0.0001 112 (200,): Weighted 0.802203 (0.057367)\n",
      "tanh adam 1000 0.0001 112 (200,): Macro 0.682004 (0.067646)\n",
      "Testing 2081/2880\n",
      "tanh adam 1500 0.1 17 (50,): Weighted 0.813506 (0.067053)\n",
      "tanh adam 1500 0.1 17 (50,): Macro 0.692300 (0.092263)\n",
      "Testing 2082/2880\n",
      "tanh adam 1500 0.1 17 (100,): Weighted 0.812807 (0.061118)\n",
      "tanh adam 1500 0.1 17 (100,): Macro 0.694939 (0.077780)\n",
      "Testing 2083/2880\n",
      "tanh adam 1500 0.1 17 (150,): Weighted 0.823888 (0.058636)\n",
      "tanh adam 1500 0.1 17 (150,): Macro 0.708845 (0.075936)\n",
      "Testing 2084/2880\n",
      "tanh adam 1500 0.1 17 (200,): Weighted 0.803639 (0.057268)\n",
      "tanh adam 1500 0.1 17 (200,): Macro 0.676627 (0.072423)\n",
      "Testing 2085/2880\n",
      "tanh adam 1500 0.1 29 (50,): Weighted 0.801639 (0.051346)\n",
      "tanh adam 1500 0.1 29 (50,): Macro 0.673723 (0.056742)\n",
      "Testing 2086/2880\n",
      "tanh adam 1500 0.1 29 (100,): Weighted 0.812698 (0.051109)\n",
      "tanh adam 1500 0.1 29 (100,): Macro 0.694606 (0.060169)\n",
      "Testing 2087/2880\n",
      "tanh adam 1500 0.1 29 (150,): Weighted 0.824509 (0.059746)\n",
      "tanh adam 1500 0.1 29 (150,): Macro 0.709864 (0.078521)\n",
      "Testing 2088/2880\n",
      "tanh adam 1500 0.1 29 (200,): Weighted 0.812870 (0.070746)\n",
      "tanh adam 1500 0.1 29 (200,): Macro 0.696268 (0.095352)\n",
      "Testing 2089/2880\n",
      "tanh adam 1500 0.1 42 (50,): Weighted 0.822427 (0.046260)\n",
      "tanh adam 1500 0.1 42 (50,): Macro 0.705097 (0.056138)\n",
      "Testing 2090/2880\n",
      "tanh adam 1500 0.1 42 (100,): Weighted 0.807514 (0.057478)\n",
      "tanh adam 1500 0.1 42 (100,): Macro 0.688721 (0.068480)\n",
      "Testing 2091/2880\n",
      "tanh adam 1500 0.1 42 (150,): Weighted 0.803307 (0.046230)\n",
      "tanh adam 1500 0.1 42 (150,): Macro 0.674533 (0.045848)\n",
      "Testing 2092/2880\n",
      "tanh adam 1500 0.1 42 (200,): Weighted 0.801148 (0.057817)\n",
      "tanh adam 1500 0.1 42 (200,): Macro 0.676232 (0.070297)\n",
      "Testing 2093/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh adam 1500 0.1 76 (50,): Weighted 0.803766 (0.038649)\n",
      "tanh adam 1500 0.1 76 (50,): Macro 0.677930 (0.042264)\n",
      "Testing 2094/2880\n",
      "tanh adam 1500 0.1 76 (100,): Weighted 0.822998 (0.059774)\n",
      "tanh adam 1500 0.1 76 (100,): Macro 0.707813 (0.076194)\n",
      "Testing 2095/2880\n",
      "tanh adam 1500 0.1 76 (150,): Weighted 0.789358 (0.051299)\n",
      "tanh adam 1500 0.1 76 (150,): Macro 0.654922 (0.050551)\n",
      "Testing 2096/2880\n",
      "tanh adam 1500 0.1 76 (200,): Weighted 0.804552 (0.066117)\n",
      "tanh adam 1500 0.1 76 (200,): Macro 0.683856 (0.083323)\n",
      "Testing 2097/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh adam 1500 0.1 112 (50,): Weighted 0.821737 (0.060465)\n",
      "tanh adam 1500 0.1 112 (50,): Macro 0.702877 (0.080442)\n",
      "Testing 2098/2880\n",
      "tanh adam 1500 0.1 112 (100,): Weighted 0.807770 (0.040815)\n",
      "tanh adam 1500 0.1 112 (100,): Macro 0.679288 (0.040533)\n",
      "Testing 2099/2880\n",
      "tanh adam 1500 0.1 112 (150,): Weighted 0.797075 (0.054908)\n",
      "tanh adam 1500 0.1 112 (150,): Macro 0.662044 (0.061201)\n",
      "Testing 2100/2880\n",
      "tanh adam 1500 0.1 112 (200,): Weighted 0.808490 (0.063177)\n",
      "tanh adam 1500 0.1 112 (200,): Macro 0.688052 (0.081232)\n",
      "Testing 2101/2880\n",
      "tanh adam 1500 0.01 17 (50,): Weighted 0.824512 (0.053311)\n",
      "tanh adam 1500 0.01 17 (50,): Macro 0.707988 (0.059443)\n",
      "Testing 2102/2880\n",
      "tanh adam 1500 0.01 17 (100,): Weighted 0.820446 (0.056432)\n",
      "tanh adam 1500 0.01 17 (100,): Macro 0.705574 (0.071389)\n",
      "Testing 2103/2880\n",
      "tanh adam 1500 0.01 17 (150,): Weighted 0.812847 (0.060921)\n",
      "tanh adam 1500 0.01 17 (150,): Macro 0.689362 (0.080877)\n",
      "Testing 2104/2880\n",
      "tanh adam 1500 0.01 17 (200,): Weighted 0.798196 (0.045409)\n",
      "tanh adam 1500 0.01 17 (200,): Macro 0.666483 (0.044508)\n",
      "Testing 2105/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh adam 1500 0.01 29 (50,): Weighted 0.810480 (0.046182)\n",
      "tanh adam 1500 0.01 29 (50,): Macro 0.685511 (0.049254)\n",
      "Testing 2106/2880\n",
      "tanh adam 1500 0.01 29 (100,): Weighted 0.797306 (0.038231)\n",
      "tanh adam 1500 0.01 29 (100,): Macro 0.661594 (0.042928)\n",
      "Testing 2107/2880\n",
      "tanh adam 1500 0.01 29 (150,): Weighted 0.802459 (0.062018)\n",
      "tanh adam 1500 0.01 29 (150,): Macro 0.678403 (0.076616)\n",
      "Testing 2108/2880\n",
      "tanh adam 1500 0.01 29 (200,): Weighted 0.811919 (0.061322)\n",
      "tanh adam 1500 0.01 29 (200,): Macro 0.692758 (0.078158)\n",
      "Testing 2109/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh adam 1500 0.01 42 (50,): Weighted 0.823139 (0.048980)\n",
      "tanh adam 1500 0.01 42 (50,): Macro 0.706184 (0.059707)\n",
      "Testing 2110/2880\n",
      "tanh adam 1500 0.01 42 (100,): Weighted 0.809529 (0.049320)\n",
      "tanh adam 1500 0.01 42 (100,): Macro 0.687114 (0.049296)\n",
      "Testing 2111/2880\n",
      "tanh adam 1500 0.01 42 (150,): Weighted 0.796568 (0.047612)\n",
      "tanh adam 1500 0.01 42 (150,): Macro 0.668158 (0.044186)\n",
      "Testing 2112/2880\n",
      "tanh adam 1500 0.01 42 (200,): Weighted 0.798707 (0.059629)\n",
      "tanh adam 1500 0.01 42 (200,): Macro 0.671452 (0.073566)\n",
      "Testing 2113/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh adam 1500 0.01 76 (50,): Weighted 0.826569 (0.036076)\n",
      "tanh adam 1500 0.01 76 (50,): Macro 0.709893 (0.040169)\n",
      "Testing 2114/2880\n",
      "tanh adam 1500 0.01 76 (100,): Weighted 0.812694 (0.068564)\n",
      "tanh adam 1500 0.01 76 (100,): Macro 0.694001 (0.089437)\n",
      "Testing 2115/2880\n",
      "tanh adam 1500 0.01 76 (150,): Weighted 0.797140 (0.045884)\n",
      "tanh adam 1500 0.01 76 (150,): Macro 0.660711 (0.046557)\n",
      "Testing 2116/2880\n",
      "tanh adam 1500 0.01 76 (200,): Weighted 0.811795 (0.061925)\n",
      "tanh adam 1500 0.01 76 (200,): Macro 0.696454 (0.076513)\n",
      "Testing 2117/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh adam 1500 0.01 112 (50,): Weighted 0.814051 (0.060283)\n",
      "tanh adam 1500 0.01 112 (50,): Macro 0.682760 (0.082113)\n",
      "Testing 2118/2880\n",
      "tanh adam 1500 0.01 112 (100,): Weighted 0.805982 (0.041003)\n",
      "tanh adam 1500 0.01 112 (100,): Macro 0.672500 (0.040995)\n",
      "Testing 2119/2880\n",
      "tanh adam 1500 0.01 112 (150,): Weighted 0.792674 (0.060952)\n",
      "tanh adam 1500 0.01 112 (150,): Macro 0.661100 (0.066164)\n",
      "Testing 2120/2880\n",
      "tanh adam 1500 0.01 112 (200,): Weighted 0.787261 (0.061983)\n",
      "tanh adam 1500 0.01 112 (200,): Macro 0.654018 (0.066861)\n",
      "Testing 2121/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh adam 1500 0.001 17 (50,): Weighted 0.821119 (0.057274)\n",
      "tanh adam 1500 0.001 17 (50,): Macro 0.703319 (0.065513)\n",
      "Testing 2122/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh adam 1500 0.001 17 (100,): Weighted 0.820446 (0.056432)\n",
      "tanh adam 1500 0.001 17 (100,): Macro 0.705574 (0.071389)\n",
      "Testing 2123/2880\n",
      "tanh adam 1500 0.001 17 (150,): Weighted 0.806959 (0.055046)\n",
      "tanh adam 1500 0.001 17 (150,): Macro 0.682276 (0.068114)\n",
      "Testing 2124/2880\n",
      "tanh adam 1500 0.001 17 (200,): Weighted 0.797140 (0.045884)\n",
      "tanh adam 1500 0.001 17 (200,): Macro 0.660711 (0.046557)\n",
      "Testing 2125/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh adam 1500 0.001 29 (50,): Weighted 0.809640 (0.051161)\n",
      "tanh adam 1500 0.001 29 (50,): Macro 0.689980 (0.056725)\n",
      "Testing 2126/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh adam 1500 0.001 29 (100,): Weighted 0.801098 (0.044610)\n",
      "tanh adam 1500 0.001 29 (100,): Macro 0.667595 (0.051166)\n",
      "Testing 2127/2880\n",
      "tanh adam 1500 0.001 29 (150,): Weighted 0.806308 (0.058649)\n",
      "tanh adam 1500 0.001 29 (150,): Macro 0.679020 (0.076093)\n",
      "Testing 2128/2880\n",
      "tanh adam 1500 0.001 29 (200,): Weighted 0.811919 (0.061322)\n",
      "tanh adam 1500 0.001 29 (200,): Macro 0.692758 (0.078158)\n",
      "Testing 2129/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh adam 1500 0.001 42 (50,): Weighted 0.827317 (0.055692)\n",
      "tanh adam 1500 0.001 42 (50,): Macro 0.713551 (0.071277)\n",
      "Testing 2130/2880\n",
      "tanh adam 1500 0.001 42 (100,): Weighted 0.800866 (0.059116)\n",
      "tanh adam 1500 0.001 42 (100,): Macro 0.677720 (0.060735)\n",
      "Testing 2131/2880\n",
      "tanh adam 1500 0.001 42 (150,): Weighted 0.796568 (0.047612)\n",
      "tanh adam 1500 0.001 42 (150,): Macro 0.668158 (0.044186)\n",
      "Testing 2132/2880\n",
      "tanh adam 1500 0.001 42 (200,): Weighted 0.798707 (0.059629)\n",
      "tanh adam 1500 0.001 42 (200,): Macro 0.671452 (0.073566)\n",
      "Testing 2133/2880\n",
      "tanh adam 1500 0.001 76 (50,): Weighted 0.820629 (0.037856)\n",
      "tanh adam 1500 0.001 76 (50,): Macro 0.701968 (0.042834)\n",
      "Testing 2134/2880\n",
      "tanh adam 1500 0.001 76 (100,): Weighted 0.816791 (0.064649)\n",
      "tanh adam 1500 0.001 76 (100,): Macro 0.699222 (0.083905)\n",
      "Testing 2135/2880\n",
      "tanh adam 1500 0.001 76 (150,): Weighted 0.797140 (0.045884)\n",
      "tanh adam 1500 0.001 76 (150,): Macro 0.660711 (0.046557)\n",
      "Testing 2136/2880\n",
      "tanh adam 1500 0.001 76 (200,): Weighted 0.810739 (0.062504)\n",
      "tanh adam 1500 0.001 76 (200,): Macro 0.690682 (0.079917)\n",
      "Testing 2137/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh adam 1500 0.001 112 (50,): Weighted 0.823012 (0.048409)\n",
      "tanh adam 1500 0.001 112 (50,): Macro 0.707664 (0.051702)\n",
      "Testing 2138/2880\n",
      "tanh adam 1500 0.001 112 (100,): Weighted 0.799617 (0.044922)\n",
      "tanh adam 1500 0.001 112 (100,): Macro 0.664193 (0.044826)\n",
      "Testing 2139/2880\n",
      "tanh adam 1500 0.001 112 (150,): Weighted 0.795365 (0.055834)\n",
      "tanh adam 1500 0.001 112 (150,): Macro 0.662326 (0.061050)\n",
      "Testing 2140/2880\n",
      "tanh adam 1500 0.001 112 (200,): Weighted 0.790249 (0.065130)\n",
      "tanh adam 1500 0.001 112 (200,): Macro 0.661378 (0.080212)\n",
      "Testing 2141/2880\n",
      "tanh adam 1500 0.0001 17 (50,): Weighted 0.821119 (0.057274)\n",
      "tanh adam 1500 0.0001 17 (50,): Macro 0.703319 (0.065513)\n",
      "Testing 2142/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh adam 1500 0.0001 17 (100,): Weighted 0.820446 (0.056432)\n",
      "tanh adam 1500 0.0001 17 (100,): Macro 0.705574 (0.071389)\n",
      "Testing 2143/2880\n",
      "tanh adam 1500 0.0001 17 (150,): Weighted 0.801510 (0.060002)\n",
      "tanh adam 1500 0.0001 17 (150,): Macro 0.669504 (0.080390)\n",
      "Testing 2144/2880\n",
      "tanh adam 1500 0.0001 17 (200,): Weighted 0.793226 (0.057882)\n",
      "tanh adam 1500 0.0001 17 (200,): Macro 0.661427 (0.061681)\n",
      "Testing 2145/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh adam 1500 0.0001 29 (50,): Weighted 0.806691 (0.051208)\n",
      "tanh adam 1500 0.0001 29 (50,): Macro 0.679132 (0.058716)\n",
      "Testing 2146/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh adam 1500 0.0001 29 (100,): Weighted 0.811695 (0.039302)\n",
      "tanh adam 1500 0.0001 29 (100,): Macro 0.687306 (0.034956)\n",
      "Testing 2147/2880\n",
      "tanh adam 1500 0.0001 29 (150,): Weighted 0.806308 (0.058649)\n",
      "tanh adam 1500 0.0001 29 (150,): Macro 0.679020 (0.076093)\n",
      "Testing 2148/2880\n",
      "tanh adam 1500 0.0001 29 (200,): Weighted 0.816299 (0.068876)\n",
      "tanh adam 1500 0.0001 29 (200,): Macro 0.700975 (0.092329)\n",
      "Testing 2149/2880\n",
      "tanh adam 1500 0.0001 42 (50,): Weighted 0.816295 (0.061239)\n",
      "tanh adam 1500 0.0001 42 (50,): Macro 0.702366 (0.075532)\n",
      "Testing 2150/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh adam 1500 0.0001 42 (100,): Weighted 0.800866 (0.059116)\n",
      "tanh adam 1500 0.0001 42 (100,): Macro 0.677720 (0.060735)\n",
      "Testing 2151/2880\n",
      "tanh adam 1500 0.0001 42 (150,): Weighted 0.796568 (0.047612)\n",
      "tanh adam 1500 0.0001 42 (150,): Macro 0.668158 (0.044186)\n",
      "Testing 2152/2880\n",
      "tanh adam 1500 0.0001 42 (200,): Weighted 0.798707 (0.059629)\n",
      "tanh adam 1500 0.0001 42 (200,): Macro 0.671452 (0.073566)\n",
      "Testing 2153/2880\n",
      "tanh adam 1500 0.0001 76 (50,): Weighted 0.826219 (0.038180)\n",
      "tanh adam 1500 0.0001 76 (50,): Macro 0.710917 (0.043849)\n",
      "Testing 2154/2880\n",
      "tanh adam 1500 0.0001 76 (100,): Weighted 0.820724 (0.061428)\n",
      "tanh adam 1500 0.0001 76 (100,): Macro 0.704393 (0.079065)\n",
      "Testing 2155/2880\n",
      "tanh adam 1500 0.0001 76 (150,): Weighted 0.795689 (0.056411)\n",
      "tanh adam 1500 0.0001 76 (150,): Macro 0.662596 (0.061311)\n",
      "Testing 2156/2880\n",
      "tanh adam 1500 0.0001 76 (200,): Weighted 0.810739 (0.062504)\n",
      "tanh adam 1500 0.0001 76 (200,): Macro 0.690682 (0.079917)\n",
      "Testing 2157/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh adam 1500 0.0001 112 (50,): Weighted 0.817113 (0.048926)\n",
      "tanh adam 1500 0.0001 112 (50,): Macro 0.694110 (0.057461)\n",
      "Testing 2158/2880\n",
      "tanh adam 1500 0.0001 112 (100,): Weighted 0.796852 (0.048958)\n",
      "tanh adam 1500 0.0001 112 (100,): Macro 0.656666 (0.056465)\n",
      "Testing 2159/2880\n",
      "tanh adam 1500 0.0001 112 (150,): Weighted 0.787261 (0.061983)\n",
      "tanh adam 1500 0.0001 112 (150,): Macro 0.654018 (0.066861)\n",
      "Testing 2160/2880\n",
      "tanh adam 1500 0.0001 112 (200,): Weighted 0.790249 (0.065130)\n",
      "tanh adam 1500 0.0001 112 (200,): Macro 0.661378 (0.080212)\n",
      "Testing 2161/2880\n",
      "relu lbfgs 500 0.1 17 (50,): Weighted 0.780959 (0.067507)\n",
      "relu lbfgs 500 0.1 17 (50,): Macro 0.658366 (0.079111)\n",
      "Testing 2162/2880\n",
      "relu lbfgs 500 0.1 17 (100,): Weighted 0.802293 (0.061702)\n",
      "relu lbfgs 500 0.1 17 (100,): Macro 0.688944 (0.077709)\n",
      "Testing 2163/2880\n",
      "relu lbfgs 500 0.1 17 (150,): Weighted 0.784336 (0.057932)\n",
      "relu lbfgs 500 0.1 17 (150,): Macro 0.650234 (0.059030)\n",
      "Testing 2164/2880\n",
      "relu lbfgs 500 0.1 17 (200,): Weighted 0.786045 (0.051021)\n",
      "relu lbfgs 500 0.1 17 (200,): Macro 0.644100 (0.044886)\n",
      "Testing 2165/2880\n",
      "relu lbfgs 500 0.1 29 (50,): Weighted 0.827155 (0.046107)\n",
      "relu lbfgs 500 0.1 29 (50,): Macro 0.715928 (0.050597)\n",
      "Testing 2166/2880\n",
      "relu lbfgs 500 0.1 29 (100,): Weighted 0.773157 (0.049760)\n",
      "relu lbfgs 500 0.1 29 (100,): Macro 0.629273 (0.046361)\n",
      "Testing 2167/2880\n",
      "relu lbfgs 500 0.1 29 (150,): Weighted 0.810831 (0.049474)\n",
      "relu lbfgs 500 0.1 29 (150,): Macro 0.685305 (0.062598)\n",
      "Testing 2168/2880\n",
      "relu lbfgs 500 0.1 29 (200,): Weighted 0.774129 (0.050034)\n",
      "relu lbfgs 500 0.1 29 (200,): Macro 0.644738 (0.048898)\n",
      "Testing 2169/2880\n",
      "relu lbfgs 500 0.1 42 (50,): Weighted 0.781691 (0.035761)\n",
      "relu lbfgs 500 0.1 42 (50,): Macro 0.639657 (0.047612)\n",
      "Testing 2170/2880\n",
      "relu lbfgs 500 0.1 42 (100,): Weighted 0.814849 (0.037714)\n",
      "relu lbfgs 500 0.1 42 (100,): Macro 0.683355 (0.043158)\n",
      "Testing 2171/2880\n",
      "relu lbfgs 500 0.1 42 (150,): Weighted 0.808808 (0.079398)\n",
      "relu lbfgs 500 0.1 42 (150,): Macro 0.689583 (0.112983)\n",
      "Testing 2172/2880\n",
      "relu lbfgs 500 0.1 42 (200,): Weighted 0.795347 (0.053419)\n",
      "relu lbfgs 500 0.1 42 (200,): Macro 0.657258 (0.065213)\n",
      "Testing 2173/2880\n",
      "relu lbfgs 500 0.1 76 (50,): Weighted 0.779238 (0.031116)\n",
      "relu lbfgs 500 0.1 76 (50,): Macro 0.645247 (0.017733)\n",
      "Testing 2174/2880\n",
      "relu lbfgs 500 0.1 76 (100,): Weighted 0.809436 (0.055221)\n",
      "relu lbfgs 500 0.1 76 (100,): Macro 0.683909 (0.069212)\n",
      "Testing 2175/2880\n",
      "relu lbfgs 500 0.1 76 (150,): Weighted 0.790156 (0.047668)\n",
      "relu lbfgs 500 0.1 76 (150,): Macro 0.653496 (0.060767)\n",
      "Testing 2176/2880\n",
      "relu lbfgs 500 0.1 76 (200,): Weighted 0.784598 (0.075888)\n",
      "relu lbfgs 500 0.1 76 (200,): Macro 0.655374 (0.087098)\n",
      "Testing 2177/2880\n",
      "relu lbfgs 500 0.1 112 (50,): Weighted 0.789403 (0.016173)\n",
      "relu lbfgs 500 0.1 112 (50,): Macro 0.676195 (0.018368)\n",
      "Testing 2178/2880\n",
      "relu lbfgs 500 0.1 112 (100,): Weighted 0.795060 (0.082338)\n",
      "relu lbfgs 500 0.1 112 (100,): Macro 0.673067 (0.109797)\n",
      "Testing 2179/2880\n",
      "relu lbfgs 500 0.1 112 (150,): Weighted 0.802890 (0.055165)\n",
      "relu lbfgs 500 0.1 112 (150,): Macro 0.681770 (0.055739)\n",
      "Testing 2180/2880\n",
      "relu lbfgs 500 0.1 112 (200,): Weighted 0.792284 (0.069471)\n",
      "relu lbfgs 500 0.1 112 (200,): Macro 0.656538 (0.089944)\n",
      "Testing 2181/2880\n",
      "relu lbfgs 500 0.01 17 (50,): Weighted 0.805660 (0.056212)\n",
      "relu lbfgs 500 0.01 17 (50,): Macro 0.689502 (0.064066)\n",
      "Testing 2182/2880\n",
      "relu lbfgs 500 0.01 17 (100,): Weighted 0.791557 (0.063181)\n",
      "relu lbfgs 500 0.01 17 (100,): Macro 0.654237 (0.069369)\n",
      "Testing 2183/2880\n",
      "relu lbfgs 500 0.01 17 (150,): Weighted 0.787267 (0.025520)\n",
      "relu lbfgs 500 0.01 17 (150,): Macro 0.628303 (0.030424)\n",
      "Testing 2184/2880\n",
      "relu lbfgs 500 0.01 17 (200,): Weighted 0.789379 (0.042367)\n",
      "relu lbfgs 500 0.01 17 (200,): Macro 0.649776 (0.022619)\n",
      "Testing 2185/2880\n",
      "relu lbfgs 500 0.01 29 (50,): Weighted 0.811456 (0.059045)\n",
      "relu lbfgs 500 0.01 29 (50,): Macro 0.697789 (0.070535)\n",
      "Testing 2186/2880\n",
      "relu lbfgs 500 0.01 29 (100,): Weighted 0.787292 (0.036988)\n",
      "relu lbfgs 500 0.01 29 (100,): Macro 0.649524 (0.024123)\n",
      "Testing 2187/2880\n",
      "relu lbfgs 500 0.01 29 (150,): Weighted 0.796703 (0.047826)\n",
      "relu lbfgs 500 0.01 29 (150,): Macro 0.666924 (0.043955)\n",
      "Testing 2188/2880\n",
      "relu lbfgs 500 0.01 29 (200,): Weighted 0.789799 (0.048391)\n",
      "relu lbfgs 500 0.01 29 (200,): Macro 0.663215 (0.042014)\n",
      "Testing 2189/2880\n",
      "relu lbfgs 500 0.01 42 (50,): Weighted 0.816396 (0.027522)\n",
      "relu lbfgs 500 0.01 42 (50,): Macro 0.686182 (0.030420)\n",
      "Testing 2190/2880\n",
      "relu lbfgs 500 0.01 42 (100,): Weighted 0.801054 (0.047967)\n",
      "relu lbfgs 500 0.01 42 (100,): Macro 0.678562 (0.056121)\n",
      "Testing 2191/2880\n",
      "relu lbfgs 500 0.01 42 (150,): Weighted 0.815377 (0.072862)\n",
      "relu lbfgs 500 0.01 42 (150,): Macro 0.683098 (0.104185)\n",
      "Testing 2192/2880\n",
      "relu lbfgs 500 0.01 42 (200,): Weighted 0.760769 (0.088994)\n",
      "relu lbfgs 500 0.01 42 (200,): Macro 0.611902 (0.097404)\n",
      "Testing 2193/2880\n",
      "relu lbfgs 500 0.01 76 (50,): Weighted 0.803618 (0.061017)\n",
      "relu lbfgs 500 0.01 76 (50,): Macro 0.685216 (0.074498)\n",
      "Testing 2194/2880\n",
      "relu lbfgs 500 0.01 76 (100,): Weighted 0.814455 (0.062811)\n",
      "relu lbfgs 500 0.01 76 (100,): Macro 0.697938 (0.086585)\n",
      "Testing 2195/2880\n",
      "relu lbfgs 500 0.01 76 (150,): Weighted 0.810551 (0.056382)\n",
      "relu lbfgs 500 0.01 76 (150,): Macro 0.676792 (0.072121)\n",
      "Testing 2196/2880\n",
      "relu lbfgs 500 0.01 76 (200,): Weighted 0.787730 (0.052779)\n",
      "relu lbfgs 500 0.01 76 (200,): Macro 0.660452 (0.050802)\n",
      "Testing 2197/2880\n",
      "relu lbfgs 500 0.01 112 (50,): Weighted 0.791928 (0.037344)\n",
      "relu lbfgs 500 0.01 112 (50,): Macro 0.671777 (0.025413)\n",
      "Testing 2198/2880\n",
      "relu lbfgs 500 0.01 112 (100,): Weighted 0.790608 (0.068100)\n",
      "relu lbfgs 500 0.01 112 (100,): Macro 0.661563 (0.081422)\n",
      "Testing 2199/2880\n",
      "relu lbfgs 500 0.01 112 (150,): Weighted 0.796199 (0.060613)\n",
      "relu lbfgs 500 0.01 112 (150,): Macro 0.669753 (0.074169)\n",
      "Testing 2200/2880\n",
      "relu lbfgs 500 0.01 112 (200,): Weighted 0.820773 (0.070485)\n",
      "relu lbfgs 500 0.01 112 (200,): Macro 0.711596 (0.098217)\n",
      "Testing 2201/2880\n",
      "relu lbfgs 500 0.001 17 (50,): Weighted 0.791915 (0.055626)\n",
      "relu lbfgs 500 0.001 17 (50,): Macro 0.659413 (0.062281)\n",
      "Testing 2202/2880\n",
      "relu lbfgs 500 0.001 17 (100,): Weighted 0.781785 (0.027616)\n",
      "relu lbfgs 500 0.001 17 (100,): Macro 0.642770 (0.023226)\n",
      "Testing 2203/2880\n",
      "relu lbfgs 500 0.001 17 (150,): Weighted 0.785945 (0.035181)\n",
      "relu lbfgs 500 0.001 17 (150,): Macro 0.638748 (0.022388)\n",
      "Testing 2204/2880\n",
      "relu lbfgs 500 0.001 17 (200,): Weighted 0.757320 (0.064385)\n",
      "relu lbfgs 500 0.001 17 (200,): Macro 0.610796 (0.058509)\n",
      "Testing 2205/2880\n",
      "relu lbfgs 500 0.001 29 (50,): Weighted 0.811539 (0.053365)\n",
      "relu lbfgs 500 0.001 29 (50,): Macro 0.698748 (0.066788)\n",
      "Testing 2206/2880\n",
      "relu lbfgs 500 0.001 29 (100,): Weighted 0.750456 (0.063329)\n",
      "relu lbfgs 500 0.001 29 (100,): Macro 0.605478 (0.046458)\n",
      "Testing 2207/2880\n",
      "relu lbfgs 500 0.001 29 (150,): Weighted 0.809747 (0.036004)\n",
      "relu lbfgs 500 0.001 29 (150,): Macro 0.667297 (0.042467)\n",
      "Testing 2208/2880\n",
      "relu lbfgs 500 0.001 29 (200,): Weighted 0.777995 (0.056681)\n",
      "relu lbfgs 500 0.001 29 (200,): Macro 0.641449 (0.044196)\n",
      "Testing 2209/2880\n",
      "relu lbfgs 500 0.001 42 (50,): Weighted 0.780912 (0.035968)\n",
      "relu lbfgs 500 0.001 42 (50,): Macro 0.643659 (0.033571)\n",
      "Testing 2210/2880\n",
      "relu lbfgs 500 0.001 42 (100,): Weighted 0.797529 (0.044824)\n",
      "relu lbfgs 500 0.001 42 (100,): Macro 0.660787 (0.035664)\n",
      "Testing 2211/2880\n",
      "relu lbfgs 500 0.001 42 (150,): Weighted 0.795191 (0.066191)\n",
      "relu lbfgs 500 0.001 42 (150,): Macro 0.661514 (0.085201)\n",
      "Testing 2212/2880\n",
      "relu lbfgs 500 0.001 42 (200,): Weighted 0.759797 (0.052932)\n",
      "relu lbfgs 500 0.001 42 (200,): Macro 0.608758 (0.055076)\n",
      "Testing 2213/2880\n",
      "relu lbfgs 500 0.001 76 (50,): Weighted 0.784606 (0.058270)\n",
      "relu lbfgs 500 0.001 76 (50,): Macro 0.661104 (0.054081)\n",
      "Testing 2214/2880\n",
      "relu lbfgs 500 0.001 76 (100,): Weighted 0.780756 (0.055752)\n",
      "relu lbfgs 500 0.001 76 (100,): Macro 0.644578 (0.061355)\n",
      "Testing 2215/2880\n",
      "relu lbfgs 500 0.001 76 (150,): Weighted 0.773442 (0.030073)\n",
      "relu lbfgs 500 0.001 76 (150,): Macro 0.619399 (0.021737)\n",
      "Testing 2216/2880\n",
      "relu lbfgs 500 0.001 76 (200,): Weighted 0.782904 (0.063408)\n",
      "relu lbfgs 500 0.001 76 (200,): Macro 0.649699 (0.063275)\n",
      "Testing 2217/2880\n",
      "relu lbfgs 500 0.001 112 (50,): Weighted 0.786601 (0.053389)\n",
      "relu lbfgs 500 0.001 112 (50,): Macro 0.663551 (0.043802)\n",
      "Testing 2218/2880\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relu lbfgs 500 0.001 112 (100,): Weighted 0.814117 (0.088008)\n",
      "relu lbfgs 500 0.001 112 (100,): Macro 0.710226 (0.124445)\n",
      "Testing 2219/2880\n",
      "relu lbfgs 500 0.001 112 (150,): Weighted 0.797916 (0.032560)\n",
      "relu lbfgs 500 0.001 112 (150,): Macro 0.662227 (0.038521)\n",
      "Testing 2220/2880\n",
      "relu lbfgs 500 0.001 112 (200,): Weighted 0.787100 (0.078638)\n",
      "relu lbfgs 500 0.001 112 (200,): Macro 0.656481 (0.111560)\n",
      "Testing 2221/2880\n",
      "relu lbfgs 500 0.0001 17 (50,): Weighted 0.807591 (0.057851)\n",
      "relu lbfgs 500 0.0001 17 (50,): Macro 0.683892 (0.071187)\n",
      "Testing 2222/2880\n",
      "relu lbfgs 500 0.0001 17 (100,): Weighted 0.790837 (0.057396)\n",
      "relu lbfgs 500 0.0001 17 (100,): Macro 0.665388 (0.070677)\n",
      "Testing 2223/2880\n",
      "relu lbfgs 500 0.0001 17 (150,): Weighted 0.781191 (0.027830)\n",
      "relu lbfgs 500 0.0001 17 (150,): Macro 0.643758 (0.014732)\n",
      "Testing 2224/2880\n",
      "relu lbfgs 500 0.0001 17 (200,): Weighted 0.786581 (0.076921)\n",
      "relu lbfgs 500 0.0001 17 (200,): Macro 0.649299 (0.097894)\n",
      "Testing 2225/2880\n",
      "relu lbfgs 500 0.0001 29 (50,): Weighted 0.814031 (0.080706)\n",
      "relu lbfgs 500 0.0001 29 (50,): Macro 0.715494 (0.102469)\n",
      "Testing 2226/2880\n",
      "relu lbfgs 500 0.0001 29 (100,): Weighted 0.800194 (0.050769)\n",
      "relu lbfgs 500 0.0001 29 (100,): Macro 0.671499 (0.060168)\n",
      "Testing 2227/2880\n",
      "relu lbfgs 500 0.0001 29 (150,): Weighted 0.801680 (0.050088)\n",
      "relu lbfgs 500 0.0001 29 (150,): Macro 0.669537 (0.047130)\n",
      "Testing 2228/2880\n",
      "relu lbfgs 500 0.0001 29 (200,): Weighted 0.775731 (0.065417)\n",
      "relu lbfgs 500 0.0001 29 (200,): Macro 0.646414 (0.080827)\n",
      "Testing 2229/2880\n",
      "relu lbfgs 500 0.0001 42 (50,): Weighted 0.764713 (0.049263)\n",
      "relu lbfgs 500 0.0001 42 (50,): Macro 0.634419 (0.058631)\n",
      "Testing 2230/2880\n",
      "relu lbfgs 500 0.0001 42 (100,): Weighted 0.805860 (0.059056)\n",
      "relu lbfgs 500 0.0001 42 (100,): Macro 0.680529 (0.067609)\n",
      "Testing 2231/2880\n",
      "relu lbfgs 500 0.0001 42 (150,): Weighted 0.786051 (0.052584)\n",
      "relu lbfgs 500 0.0001 42 (150,): Macro 0.641318 (0.060044)\n",
      "Testing 2232/2880\n",
      "relu lbfgs 500 0.0001 42 (200,): Weighted 0.784468 (0.058454)\n",
      "relu lbfgs 500 0.0001 42 (200,): Macro 0.648181 (0.065132)\n",
      "Testing 2233/2880\n",
      "relu lbfgs 500 0.0001 76 (50,): Weighted 0.805861 (0.059764)\n",
      "relu lbfgs 500 0.0001 76 (50,): Macro 0.683945 (0.069027)\n",
      "Testing 2234/2880\n",
      "relu lbfgs 500 0.0001 76 (100,): Weighted 0.796490 (0.029648)\n",
      "relu lbfgs 500 0.0001 76 (100,): Macro 0.653968 (0.014800)\n",
      "Testing 2235/2880\n",
      "relu lbfgs 500 0.0001 76 (150,): Weighted 0.785221 (0.063895)\n",
      "relu lbfgs 500 0.0001 76 (150,): Macro 0.655401 (0.065224)\n",
      "Testing 2236/2880\n",
      "relu lbfgs 500 0.0001 76 (200,): Weighted 0.772358 (0.074774)\n",
      "relu lbfgs 500 0.0001 76 (200,): Macro 0.640837 (0.101911)\n",
      "Testing 2237/2880\n",
      "relu lbfgs 500 0.0001 112 (50,): Weighted 0.814798 (0.066153)\n",
      "relu lbfgs 500 0.0001 112 (50,): Macro 0.703657 (0.080118)\n",
      "Testing 2238/2880\n",
      "relu lbfgs 500 0.0001 112 (100,): Weighted 0.771439 (0.060375)\n",
      "relu lbfgs 500 0.0001 112 (100,): Macro 0.632754 (0.064326)\n",
      "Testing 2239/2880\n",
      "relu lbfgs 500 0.0001 112 (150,): Weighted 0.797317 (0.047935)\n",
      "relu lbfgs 500 0.0001 112 (150,): Macro 0.655732 (0.052378)\n",
      "Testing 2240/2880\n",
      "relu lbfgs 500 0.0001 112 (200,): Weighted 0.770635 (0.057033)\n",
      "relu lbfgs 500 0.0001 112 (200,): Macro 0.635469 (0.053703)\n",
      "Testing 2241/2880\n",
      "relu lbfgs 1000 0.1 17 (50,): Weighted 0.796732 (0.042453)\n",
      "relu lbfgs 1000 0.1 17 (50,): Macro 0.681944 (0.044880)\n",
      "Testing 2242/2880\n",
      "relu lbfgs 1000 0.1 17 (100,): Weighted 0.809635 (0.064808)\n",
      "relu lbfgs 1000 0.1 17 (100,): Macro 0.697440 (0.077181)\n",
      "Testing 2243/2880\n",
      "relu lbfgs 1000 0.1 17 (150,): Weighted 0.778686 (0.047156)\n",
      "relu lbfgs 1000 0.1 17 (150,): Macro 0.643044 (0.050561)\n",
      "Testing 2244/2880\n",
      "relu lbfgs 1000 0.1 17 (200,): Weighted 0.784064 (0.054255)\n",
      "relu lbfgs 1000 0.1 17 (200,): Macro 0.651142 (0.053400)\n",
      "Testing 2245/2880\n",
      "relu lbfgs 1000 0.1 29 (50,): Weighted 0.817550 (0.074311)\n",
      "relu lbfgs 1000 0.1 29 (50,): Macro 0.705435 (0.084125)\n",
      "Testing 2246/2880\n",
      "relu lbfgs 1000 0.1 29 (100,): Weighted 0.775543 (0.047500)\n",
      "relu lbfgs 1000 0.1 29 (100,): Macro 0.620759 (0.044763)\n",
      "Testing 2247/2880\n",
      "relu lbfgs 1000 0.1 29 (150,): Weighted 0.777975 (0.027784)\n",
      "relu lbfgs 1000 0.1 29 (150,): Macro 0.629219 (0.023662)\n",
      "Testing 2248/2880\n",
      "relu lbfgs 1000 0.1 29 (200,): Weighted 0.782626 (0.030404)\n",
      "relu lbfgs 1000 0.1 29 (200,): Macro 0.654702 (0.020085)\n",
      "Testing 2249/2880\n",
      "relu lbfgs 1000 0.1 42 (50,): Weighted 0.776445 (0.036341)\n",
      "relu lbfgs 1000 0.1 42 (50,): Macro 0.650694 (0.050671)\n",
      "Testing 2250/2880\n",
      "relu lbfgs 1000 0.1 42 (100,): Weighted 0.802695 (0.046050)\n",
      "relu lbfgs 1000 0.1 42 (100,): Macro 0.656836 (0.072312)\n",
      "Testing 2251/2880\n",
      "relu lbfgs 1000 0.1 42 (150,): Weighted 0.798482 (0.067395)\n",
      "relu lbfgs 1000 0.1 42 (150,): Macro 0.664401 (0.094557)\n",
      "Testing 2252/2880\n",
      "relu lbfgs 1000 0.1 42 (200,): Weighted 0.776403 (0.060452)\n",
      "relu lbfgs 1000 0.1 42 (200,): Macro 0.632518 (0.061314)\n",
      "Testing 2253/2880\n",
      "relu lbfgs 1000 0.1 76 (50,): Weighted 0.782481 (0.055731)\n",
      "relu lbfgs 1000 0.1 76 (50,): Macro 0.644271 (0.045104)\n",
      "Testing 2254/2880\n",
      "relu lbfgs 1000 0.1 76 (100,): Weighted 0.810116 (0.055951)\n",
      "relu lbfgs 1000 0.1 76 (100,): Macro 0.680443 (0.076068)\n",
      "Testing 2255/2880\n",
      "relu lbfgs 1000 0.1 76 (150,): Weighted 0.806357 (0.039353)\n",
      "relu lbfgs 1000 0.1 76 (150,): Macro 0.672453 (0.032753)\n",
      "Testing 2256/2880\n",
      "relu lbfgs 1000 0.1 76 (200,): Weighted 0.813051 (0.067297)\n",
      "relu lbfgs 1000 0.1 76 (200,): Macro 0.691729 (0.076520)\n",
      "Testing 2257/2880\n",
      "relu lbfgs 1000 0.1 112 (50,): Weighted 0.779718 (0.048004)\n",
      "relu lbfgs 1000 0.1 112 (50,): Macro 0.654930 (0.049174)\n",
      "Testing 2258/2880\n",
      "relu lbfgs 1000 0.1 112 (100,): Weighted 0.791808 (0.071592)\n",
      "relu lbfgs 1000 0.1 112 (100,): Macro 0.680706 (0.071729)\n",
      "Testing 2259/2880\n",
      "relu lbfgs 1000 0.1 112 (150,): Weighted 0.774297 (0.077854)\n",
      "relu lbfgs 1000 0.1 112 (150,): Macro 0.658376 (0.100281)\n",
      "Testing 2260/2880\n",
      "relu lbfgs 1000 0.1 112 (200,): Weighted 0.781807 (0.094435)\n",
      "relu lbfgs 1000 0.1 112 (200,): Macro 0.648164 (0.125834)\n",
      "Testing 2261/2880\n",
      "relu lbfgs 1000 0.01 17 (50,): Weighted 0.812318 (0.026067)\n",
      "relu lbfgs 1000 0.01 17 (50,): Macro 0.705897 (0.051516)\n",
      "Testing 2262/2880\n",
      "relu lbfgs 1000 0.01 17 (100,): Weighted 0.782819 (0.077616)\n",
      "relu lbfgs 1000 0.01 17 (100,): Macro 0.655225 (0.087713)\n",
      "Testing 2263/2880\n",
      "relu lbfgs 1000 0.01 17 (150,): Weighted 0.784341 (0.025901)\n",
      "relu lbfgs 1000 0.01 17 (150,): Macro 0.629212 (0.018896)\n",
      "Testing 2264/2880\n",
      "relu lbfgs 1000 0.01 17 (200,): Weighted 0.786040 (0.037341)\n",
      "relu lbfgs 1000 0.01 17 (200,): Macro 0.643661 (0.029466)\n",
      "Testing 2265/2880\n",
      "relu lbfgs 1000 0.01 29 (50,): Weighted 0.809993 (0.069032)\n",
      "relu lbfgs 1000 0.01 29 (50,): Macro 0.693522 (0.077189)\n",
      "Testing 2266/2880\n",
      "relu lbfgs 1000 0.01 29 (100,): Weighted 0.776508 (0.056637)\n",
      "relu lbfgs 1000 0.01 29 (100,): Macro 0.636412 (0.061359)\n",
      "Testing 2267/2880\n",
      "relu lbfgs 1000 0.01 29 (150,): Weighted 0.801241 (0.043500)\n",
      "relu lbfgs 1000 0.01 29 (150,): Macro 0.660364 (0.047750)\n",
      "Testing 2268/2880\n",
      "relu lbfgs 1000 0.01 29 (200,): Weighted 0.780928 (0.037380)\n",
      "relu lbfgs 1000 0.01 29 (200,): Macro 0.658089 (0.016192)\n",
      "Testing 2269/2880\n",
      "relu lbfgs 1000 0.01 42 (50,): Weighted 0.783514 (0.016450)\n",
      "relu lbfgs 1000 0.01 42 (50,): Macro 0.654181 (0.027611)\n",
      "Testing 2270/2880\n",
      "relu lbfgs 1000 0.01 42 (100,): Weighted 0.803841 (0.035368)\n",
      "relu lbfgs 1000 0.01 42 (100,): Macro 0.667399 (0.036555)\n",
      "Testing 2271/2880\n",
      "relu lbfgs 1000 0.01 42 (150,): Weighted 0.768259 (0.032474)\n",
      "relu lbfgs 1000 0.01 42 (150,): Macro 0.620143 (0.029173)\n",
      "Testing 2272/2880\n",
      "relu lbfgs 1000 0.01 42 (200,): Weighted 0.768997 (0.038325)\n",
      "relu lbfgs 1000 0.01 42 (200,): Macro 0.606286 (0.027092)\n",
      "Testing 2273/2880\n",
      "relu lbfgs 1000 0.01 76 (50,): Weighted 0.795550 (0.064723)\n",
      "relu lbfgs 1000 0.01 76 (50,): Macro 0.681319 (0.081765)\n",
      "Testing 2274/2880\n",
      "relu lbfgs 1000 0.01 76 (100,): Weighted 0.798202 (0.063777)\n",
      "relu lbfgs 1000 0.01 76 (100,): Macro 0.681877 (0.073282)\n",
      "Testing 2275/2880\n",
      "relu lbfgs 1000 0.01 76 (150,): Weighted 0.791640 (0.043500)\n",
      "relu lbfgs 1000 0.01 76 (150,): Macro 0.644481 (0.046620)\n",
      "Testing 2276/2880\n",
      "relu lbfgs 1000 0.01 76 (200,): Weighted 0.806304 (0.039537)\n",
      "relu lbfgs 1000 0.01 76 (200,): Macro 0.683558 (0.035231)\n",
      "Testing 2277/2880\n",
      "relu lbfgs 1000 0.01 112 (50,): Weighted 0.788034 (0.034814)\n",
      "relu lbfgs 1000 0.01 112 (50,): Macro 0.654949 (0.021868)\n",
      "Testing 2278/2880\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relu lbfgs 1000 0.01 112 (100,): Weighted 0.772911 (0.078961)\n",
      "relu lbfgs 1000 0.01 112 (100,): Macro 0.640159 (0.098294)\n",
      "Testing 2279/2880\n",
      "relu lbfgs 1000 0.01 112 (150,): Weighted 0.780240 (0.056430)\n",
      "relu lbfgs 1000 0.01 112 (150,): Macro 0.641215 (0.062026)\n",
      "Testing 2280/2880\n",
      "relu lbfgs 1000 0.01 112 (200,): Weighted 0.809474 (0.057767)\n",
      "relu lbfgs 1000 0.01 112 (200,): Macro 0.695332 (0.066120)\n",
      "Testing 2281/2880\n",
      "relu lbfgs 1000 0.001 17 (50,): Weighted 0.798958 (0.057287)\n",
      "relu lbfgs 1000 0.001 17 (50,): Macro 0.684895 (0.074836)\n",
      "Testing 2282/2880\n",
      "relu lbfgs 1000 0.001 17 (100,): Weighted 0.790342 (0.046798)\n",
      "relu lbfgs 1000 0.001 17 (100,): Macro 0.652009 (0.054057)\n",
      "Testing 2283/2880\n",
      "relu lbfgs 1000 0.001 17 (150,): Weighted 0.771996 (0.048777)\n",
      "relu lbfgs 1000 0.001 17 (150,): Macro 0.623744 (0.051298)\n",
      "Testing 2284/2880\n",
      "relu lbfgs 1000 0.001 17 (200,): Weighted 0.787892 (0.021103)\n",
      "relu lbfgs 1000 0.001 17 (200,): Macro 0.651298 (0.008628)\n",
      "Testing 2285/2880\n",
      "relu lbfgs 1000 0.001 29 (50,): Weighted 0.796264 (0.070037)\n",
      "relu lbfgs 1000 0.001 29 (50,): Macro 0.682863 (0.079640)\n",
      "Testing 2286/2880\n",
      "relu lbfgs 1000 0.001 29 (100,): Weighted 0.753599 (0.043094)\n",
      "relu lbfgs 1000 0.001 29 (100,): Macro 0.589565 (0.025427)\n",
      "Testing 2287/2880\n",
      "relu lbfgs 1000 0.001 29 (150,): Weighted 0.828635 (0.059401)\n",
      "relu lbfgs 1000 0.001 29 (150,): Macro 0.719732 (0.094015)\n",
      "Testing 2288/2880\n",
      "relu lbfgs 1000 0.001 29 (200,): Weighted 0.760413 (0.050468)\n",
      "relu lbfgs 1000 0.001 29 (200,): Macro 0.597009 (0.075458)\n",
      "Testing 2289/2880\n",
      "relu lbfgs 1000 0.001 42 (50,): Weighted 0.777048 (0.025644)\n",
      "relu lbfgs 1000 0.001 42 (50,): Macro 0.624946 (0.048849)\n",
      "Testing 2290/2880\n",
      "relu lbfgs 1000 0.001 42 (100,): Weighted 0.814060 (0.050744)\n",
      "relu lbfgs 1000 0.001 42 (100,): Macro 0.698670 (0.060736)\n",
      "Testing 2291/2880\n",
      "relu lbfgs 1000 0.001 42 (150,): Weighted 0.787453 (0.037120)\n",
      "relu lbfgs 1000 0.001 42 (150,): Macro 0.631353 (0.044963)\n",
      "Testing 2292/2880\n",
      "relu lbfgs 1000 0.001 42 (200,): Weighted 0.800228 (0.043749)\n",
      "relu lbfgs 1000 0.001 42 (200,): Macro 0.662058 (0.053891)\n",
      "Testing 2293/2880\n",
      "relu lbfgs 1000 0.001 76 (50,): Weighted 0.820574 (0.067064)\n",
      "relu lbfgs 1000 0.001 76 (50,): Macro 0.712277 (0.082915)\n",
      "Testing 2294/2880\n",
      "relu lbfgs 1000 0.001 76 (100,): Weighted 0.779223 (0.064260)\n",
      "relu lbfgs 1000 0.001 76 (100,): Macro 0.640998 (0.071754)\n",
      "Testing 2295/2880\n",
      "relu lbfgs 1000 0.001 76 (150,): Weighted 0.785068 (0.040663)\n",
      "relu lbfgs 1000 0.001 76 (150,): Macro 0.635213 (0.055766)\n",
      "Testing 2296/2880\n",
      "relu lbfgs 1000 0.001 76 (200,): Weighted 0.757528 (0.083334)\n",
      "relu lbfgs 1000 0.001 76 (200,): Macro 0.609046 (0.102361)\n",
      "Testing 2297/2880\n",
      "relu lbfgs 1000 0.001 112 (50,): Weighted 0.774129 (0.061513)\n",
      "relu lbfgs 1000 0.001 112 (50,): Macro 0.655404 (0.059759)\n",
      "Testing 2298/2880\n",
      "relu lbfgs 1000 0.001 112 (100,): Weighted 0.811904 (0.071986)\n",
      "relu lbfgs 1000 0.001 112 (100,): Macro 0.705400 (0.090145)\n",
      "Testing 2299/2880\n",
      "relu lbfgs 1000 0.001 112 (150,): Weighted 0.779051 (0.032488)\n",
      "relu lbfgs 1000 0.001 112 (150,): Macro 0.635798 (0.018534)\n",
      "Testing 2300/2880\n",
      "relu lbfgs 1000 0.001 112 (200,): Weighted 0.770417 (0.058452)\n",
      "relu lbfgs 1000 0.001 112 (200,): Macro 0.621564 (0.058753)\n",
      "Testing 2301/2880\n",
      "relu lbfgs 1000 0.0001 17 (50,): Weighted 0.816454 (0.051862)\n",
      "relu lbfgs 1000 0.0001 17 (50,): Macro 0.693403 (0.069107)\n",
      "Testing 2302/2880\n",
      "relu lbfgs 1000 0.0001 17 (100,): Weighted 0.780859 (0.052636)\n",
      "relu lbfgs 1000 0.0001 17 (100,): Macro 0.641238 (0.054329)\n",
      "Testing 2303/2880\n",
      "relu lbfgs 1000 0.0001 17 (150,): Weighted 0.769735 (0.027252)\n",
      "relu lbfgs 1000 0.0001 17 (150,): Macro 0.609344 (0.044892)\n",
      "Testing 2304/2880\n",
      "relu lbfgs 1000 0.0001 17 (200,): Weighted 0.793644 (0.033618)\n",
      "relu lbfgs 1000 0.0001 17 (200,): Macro 0.644583 (0.054437)\n",
      "Testing 2305/2880\n",
      "relu lbfgs 1000 0.0001 29 (50,): Weighted 0.800579 (0.071336)\n",
      "relu lbfgs 1000 0.0001 29 (50,): Macro 0.696785 (0.076521)\n",
      "Testing 2306/2880\n",
      "relu lbfgs 1000 0.0001 29 (100,): Weighted 0.800887 (0.042706)\n",
      "relu lbfgs 1000 0.0001 29 (100,): Macro 0.668386 (0.044388)\n",
      "Testing 2307/2880\n",
      "relu lbfgs 1000 0.0001 29 (150,): Weighted 0.798484 (0.050218)\n",
      "relu lbfgs 1000 0.0001 29 (150,): Macro 0.661562 (0.038481)\n",
      "Testing 2308/2880\n",
      "relu lbfgs 1000 0.0001 29 (200,): Weighted 0.777121 (0.065007)\n",
      "relu lbfgs 1000 0.0001 29 (200,): Macro 0.642449 (0.085671)\n",
      "Testing 2309/2880\n",
      "relu lbfgs 1000 0.0001 42 (50,): Weighted 0.785090 (0.032021)\n",
      "relu lbfgs 1000 0.0001 42 (50,): Macro 0.648257 (0.041176)\n",
      "Testing 2310/2880\n",
      "relu lbfgs 1000 0.0001 42 (100,): Weighted 0.810595 (0.072119)\n",
      "relu lbfgs 1000 0.0001 42 (100,): Macro 0.709290 (0.089262)\n",
      "Testing 2311/2880\n",
      "relu lbfgs 1000 0.0001 42 (150,): Weighted 0.771339 (0.030345)\n",
      "relu lbfgs 1000 0.0001 42 (150,): Macro 0.624128 (0.039056)\n",
      "Testing 2312/2880\n",
      "relu lbfgs 1000 0.0001 42 (200,): Weighted 0.777238 (0.065393)\n",
      "relu lbfgs 1000 0.0001 42 (200,): Macro 0.637982 (0.074358)\n",
      "Testing 2313/2880\n",
      "relu lbfgs 1000 0.0001 76 (50,): Weighted 0.791628 (0.054333)\n",
      "relu lbfgs 1000 0.0001 76 (50,): Macro 0.668238 (0.056171)\n",
      "Testing 2314/2880\n",
      "relu lbfgs 1000 0.0001 76 (100,): Weighted 0.753002 (0.063594)\n",
      "relu lbfgs 1000 0.0001 76 (100,): Macro 0.607374 (0.053865)\n",
      "Testing 2315/2880\n",
      "relu lbfgs 1000 0.0001 76 (150,): Weighted 0.770704 (0.055714)\n",
      "relu lbfgs 1000 0.0001 76 (150,): Macro 0.621707 (0.038785)\n",
      "Testing 2316/2880\n",
      "relu lbfgs 1000 0.0001 76 (200,): Weighted 0.772424 (0.064415)\n",
      "relu lbfgs 1000 0.0001 76 (200,): Macro 0.634315 (0.080289)\n",
      "Testing 2317/2880\n",
      "relu lbfgs 1000 0.0001 112 (50,): Weighted 0.788391 (0.069762)\n",
      "relu lbfgs 1000 0.0001 112 (50,): Macro 0.668530 (0.081068)\n",
      "Testing 2318/2880\n",
      "relu lbfgs 1000 0.0001 112 (100,): Weighted 0.756200 (0.048995)\n",
      "relu lbfgs 1000 0.0001 112 (100,): Macro 0.617525 (0.042231)\n",
      "Testing 2319/2880\n",
      "relu lbfgs 1000 0.0001 112 (150,): Weighted 0.784567 (0.035881)\n",
      "relu lbfgs 1000 0.0001 112 (150,): Macro 0.651245 (0.024878)\n",
      "Testing 2320/2880\n",
      "relu lbfgs 1000 0.0001 112 (200,): Weighted 0.788412 (0.041425)\n",
      "relu lbfgs 1000 0.0001 112 (200,): Macro 0.646566 (0.062332)\n",
      "Testing 2321/2880\n",
      "relu lbfgs 1500 0.1 17 (50,): Weighted 0.800788 (0.049324)\n",
      "relu lbfgs 1500 0.1 17 (50,): Macro 0.688342 (0.054286)\n",
      "Testing 2322/2880\n",
      "relu lbfgs 1500 0.1 17 (100,): Weighted 0.789181 (0.042340)\n",
      "relu lbfgs 1500 0.1 17 (100,): Macro 0.654535 (0.040178)\n",
      "Testing 2323/2880\n",
      "relu lbfgs 1500 0.1 17 (150,): Weighted 0.767507 (0.064388)\n",
      "relu lbfgs 1500 0.1 17 (150,): Macro 0.633512 (0.076620)\n",
      "Testing 2324/2880\n",
      "relu lbfgs 1500 0.1 17 (200,): Weighted 0.780130 (0.049331)\n",
      "relu lbfgs 1500 0.1 17 (200,): Macro 0.628282 (0.045873)\n",
      "Testing 2325/2880\n",
      "relu lbfgs 1500 0.1 29 (50,): Weighted 0.816296 (0.074149)\n",
      "relu lbfgs 1500 0.1 29 (50,): Macro 0.706932 (0.084424)\n",
      "Testing 2326/2880\n",
      "relu lbfgs 1500 0.1 29 (100,): Weighted 0.790660 (0.049200)\n",
      "relu lbfgs 1500 0.1 29 (100,): Macro 0.658587 (0.050208)\n",
      "Testing 2327/2880\n",
      "relu lbfgs 1500 0.1 29 (150,): Weighted 0.780462 (0.059266)\n",
      "relu lbfgs 1500 0.1 29 (150,): Macro 0.638736 (0.058933)\n",
      "Testing 2328/2880\n",
      "relu lbfgs 1500 0.1 29 (200,): Weighted 0.789113 (0.028352)\n",
      "relu lbfgs 1500 0.1 29 (200,): Macro 0.658969 (0.015170)\n",
      "Testing 2329/2880\n",
      "relu lbfgs 1500 0.1 42 (50,): Weighted 0.781884 (0.020955)\n",
      "relu lbfgs 1500 0.1 42 (50,): Macro 0.660330 (0.036974)\n",
      "Testing 2330/2880\n",
      "relu lbfgs 1500 0.1 42 (100,): Weighted 0.798414 (0.044602)\n",
      "relu lbfgs 1500 0.1 42 (100,): Macro 0.649139 (0.073388)\n",
      "Testing 2331/2880\n",
      "relu lbfgs 1500 0.1 42 (150,): Weighted 0.807450 (0.077846)\n",
      "relu lbfgs 1500 0.1 42 (150,): Macro 0.679988 (0.114542)\n",
      "Testing 2332/2880\n",
      "relu lbfgs 1500 0.1 42 (200,): Weighted 0.779762 (0.052003)\n",
      "relu lbfgs 1500 0.1 42 (200,): Macro 0.638966 (0.055117)\n",
      "Testing 2333/2880\n",
      "relu lbfgs 1500 0.1 76 (50,): Weighted 0.788225 (0.042752)\n",
      "relu lbfgs 1500 0.1 76 (50,): Macro 0.647781 (0.035713)\n",
      "Testing 2334/2880\n",
      "relu lbfgs 1500 0.1 76 (100,): Weighted 0.817822 (0.045591)\n",
      "relu lbfgs 1500 0.1 76 (100,): Macro 0.696476 (0.079165)\n",
      "Testing 2335/2880\n",
      "relu lbfgs 1500 0.1 76 (150,): Weighted 0.803458 (0.061085)\n",
      "relu lbfgs 1500 0.1 76 (150,): Macro 0.673155 (0.077957)\n",
      "Testing 2336/2880\n",
      "relu lbfgs 1500 0.1 76 (200,): Weighted 0.814935 (0.060552)\n",
      "relu lbfgs 1500 0.1 76 (200,): Macro 0.696580 (0.061870)\n",
      "Testing 2337/2880\n",
      "relu lbfgs 1500 0.1 112 (50,): Weighted 0.769761 (0.042652)\n",
      "relu lbfgs 1500 0.1 112 (50,): Macro 0.641974 (0.037465)\n",
      "Testing 2338/2880\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relu lbfgs 1500 0.1 112 (100,): Weighted 0.774571 (0.053384)\n",
      "relu lbfgs 1500 0.1 112 (100,): Macro 0.651924 (0.033585)\n",
      "Testing 2339/2880\n",
      "relu lbfgs 1500 0.1 112 (150,): Weighted 0.758656 (0.071892)\n",
      "relu lbfgs 1500 0.1 112 (150,): Macro 0.625950 (0.082699)\n",
      "Testing 2340/2880\n",
      "relu lbfgs 1500 0.1 112 (200,): Weighted 0.783366 (0.076372)\n",
      "relu lbfgs 1500 0.1 112 (200,): Macro 0.650692 (0.097162)\n",
      "Testing 2341/2880\n",
      "relu lbfgs 1500 0.01 17 (50,): Weighted 0.831575 (0.039755)\n",
      "relu lbfgs 1500 0.01 17 (50,): Macro 0.724087 (0.054577)\n",
      "Testing 2342/2880\n",
      "relu lbfgs 1500 0.01 17 (100,): Weighted 0.757755 (0.054242)\n",
      "relu lbfgs 1500 0.01 17 (100,): Macro 0.604730 (0.043239)\n",
      "Testing 2343/2880\n",
      "relu lbfgs 1500 0.01 17 (150,): Weighted 0.784938 (0.036843)\n",
      "relu lbfgs 1500 0.01 17 (150,): Macro 0.640131 (0.019967)\n",
      "Testing 2344/2880\n",
      "relu lbfgs 1500 0.01 17 (200,): Weighted 0.797142 (0.060625)\n",
      "relu lbfgs 1500 0.01 17 (200,): Macro 0.667422 (0.068981)\n",
      "Testing 2345/2880\n",
      "relu lbfgs 1500 0.01 29 (50,): Weighted 0.815362 (0.067353)\n",
      "relu lbfgs 1500 0.01 29 (50,): Macro 0.704953 (0.079432)\n",
      "Testing 2346/2880\n",
      "relu lbfgs 1500 0.01 29 (100,): Weighted 0.788153 (0.098408)\n",
      "relu lbfgs 1500 0.01 29 (100,): Macro 0.674359 (0.134804)\n",
      "Testing 2347/2880\n",
      "relu lbfgs 1500 0.01 29 (150,): Weighted 0.793716 (0.049228)\n",
      "relu lbfgs 1500 0.01 29 (150,): Macro 0.650450 (0.057528)\n",
      "Testing 2348/2880\n",
      "relu lbfgs 1500 0.01 29 (200,): Weighted 0.783780 (0.028911)\n",
      "relu lbfgs 1500 0.01 29 (200,): Macro 0.660018 (0.012656)\n",
      "Testing 2349/2880\n",
      "relu lbfgs 1500 0.01 42 (50,): Weighted 0.773157 (0.014450)\n",
      "relu lbfgs 1500 0.01 42 (50,): Macro 0.641786 (0.024557)\n",
      "Testing 2350/2880\n",
      "relu lbfgs 1500 0.01 42 (100,): Weighted 0.799059 (0.037086)\n",
      "relu lbfgs 1500 0.01 42 (100,): Macro 0.664030 (0.033636)\n",
      "Testing 2351/2880\n",
      "relu lbfgs 1500 0.01 42 (150,): Weighted 0.769038 (0.042104)\n",
      "relu lbfgs 1500 0.01 42 (150,): Macro 0.632296 (0.037731)\n",
      "Testing 2352/2880\n",
      "relu lbfgs 1500 0.01 42 (200,): Weighted 0.754266 (0.041009)\n",
      "relu lbfgs 1500 0.01 42 (200,): Macro 0.585227 (0.020088)\n",
      "Testing 2353/2880\n",
      "relu lbfgs 1500 0.01 76 (50,): Weighted 0.795920 (0.065401)\n",
      "relu lbfgs 1500 0.01 76 (50,): Macro 0.671920 (0.085261)\n",
      "Testing 2354/2880\n",
      "relu lbfgs 1500 0.01 76 (100,): Weighted 0.770391 (0.057683)\n",
      "relu lbfgs 1500 0.01 76 (100,): Macro 0.642349 (0.053837)\n",
      "Testing 2355/2880\n",
      "relu lbfgs 1500 0.01 76 (150,): Weighted 0.790101 (0.034813)\n",
      "relu lbfgs 1500 0.01 76 (150,): Macro 0.642602 (0.024122)\n",
      "Testing 2356/2880\n",
      "relu lbfgs 1500 0.01 76 (200,): Weighted 0.789485 (0.040388)\n",
      "relu lbfgs 1500 0.01 76 (200,): Macro 0.648281 (0.032441)\n",
      "Testing 2357/2880\n",
      "relu lbfgs 1500 0.01 112 (50,): Weighted 0.809493 (0.054883)\n",
      "relu lbfgs 1500 0.01 112 (50,): Macro 0.701110 (0.066653)\n",
      "Testing 2358/2880\n",
      "relu lbfgs 1500 0.01 112 (100,): Weighted 0.769161 (0.060174)\n",
      "relu lbfgs 1500 0.01 112 (100,): Macro 0.623460 (0.061019)\n",
      "Testing 2359/2880\n",
      "relu lbfgs 1500 0.01 112 (150,): Weighted 0.769664 (0.068408)\n",
      "relu lbfgs 1500 0.01 112 (150,): Macro 0.629457 (0.074999)\n",
      "Testing 2360/2880\n",
      "relu lbfgs 1500 0.01 112 (200,): Weighted 0.791531 (0.034026)\n",
      "relu lbfgs 1500 0.01 112 (200,): Macro 0.660419 (0.029223)\n",
      "Testing 2361/2880\n",
      "relu lbfgs 1500 0.001 17 (50,): Weighted 0.797224 (0.048711)\n",
      "relu lbfgs 1500 0.001 17 (50,): Macro 0.688338 (0.056990)\n",
      "Testing 2362/2880\n",
      "relu lbfgs 1500 0.001 17 (100,): Weighted 0.780144 (0.039997)\n",
      "relu lbfgs 1500 0.001 17 (100,): Macro 0.637508 (0.053338)\n",
      "Testing 2363/2880\n",
      "relu lbfgs 1500 0.001 17 (150,): Weighted 0.786085 (0.039137)\n",
      "relu lbfgs 1500 0.001 17 (150,): Macro 0.635444 (0.037563)\n",
      "Testing 2364/2880\n",
      "relu lbfgs 1500 0.001 17 (200,): Weighted 0.760853 (0.014551)\n",
      "relu lbfgs 1500 0.001 17 (200,): Macro 0.603197 (0.030484)\n",
      "Testing 2365/2880\n",
      "relu lbfgs 1500 0.001 29 (50,): Weighted 0.800349 (0.067432)\n",
      "relu lbfgs 1500 0.001 29 (50,): Macro 0.685103 (0.081633)\n",
      "Testing 2366/2880\n",
      "relu lbfgs 1500 0.001 29 (100,): Weighted 0.759878 (0.041883)\n",
      "relu lbfgs 1500 0.001 29 (100,): Macro 0.612953 (0.038376)\n",
      "Testing 2367/2880\n",
      "relu lbfgs 1500 0.001 29 (150,): Weighted 0.808717 (0.046790)\n",
      "relu lbfgs 1500 0.001 29 (150,): Macro 0.688177 (0.059717)\n",
      "Testing 2368/2880\n",
      "relu lbfgs 1500 0.001 29 (200,): Weighted 0.760273 (0.051537)\n",
      "relu lbfgs 1500 0.001 29 (200,): Macro 0.605142 (0.077576)\n",
      "Testing 2369/2880\n",
      "relu lbfgs 1500 0.001 42 (50,): Weighted 0.788298 (0.044292)\n",
      "relu lbfgs 1500 0.001 42 (50,): Macro 0.644828 (0.051739)\n",
      "Testing 2370/2880\n",
      "relu lbfgs 1500 0.001 42 (100,): Weighted 0.797798 (0.025877)\n",
      "relu lbfgs 1500 0.001 42 (100,): Macro 0.670744 (0.017032)\n",
      "Testing 2371/2880\n",
      "relu lbfgs 1500 0.001 42 (150,): Weighted 0.793084 (0.036708)\n",
      "relu lbfgs 1500 0.001 42 (150,): Macro 0.637240 (0.057909)\n",
      "Testing 2372/2880\n",
      "relu lbfgs 1500 0.001 42 (200,): Weighted 0.794888 (0.032968)\n",
      "relu lbfgs 1500 0.001 42 (200,): Macro 0.643926 (0.036743)\n",
      "Testing 2373/2880\n",
      "relu lbfgs 1500 0.001 76 (50,): Weighted 0.808519 (0.055036)\n",
      "relu lbfgs 1500 0.001 76 (50,): Macro 0.685153 (0.056821)\n",
      "Testing 2374/2880\n",
      "relu lbfgs 1500 0.001 76 (100,): Weighted 0.777753 (0.063395)\n",
      "relu lbfgs 1500 0.001 76 (100,): Macro 0.646805 (0.076486)\n",
      "Testing 2375/2880\n",
      "relu lbfgs 1500 0.001 76 (150,): Weighted 0.769031 (0.040443)\n",
      "relu lbfgs 1500 0.001 76 (150,): Macro 0.621552 (0.051992)\n",
      "Testing 2376/2880\n",
      "relu lbfgs 1500 0.001 76 (200,): Weighted 0.791697 (0.071662)\n",
      "relu lbfgs 1500 0.001 76 (200,): Macro 0.658561 (0.087299)\n",
      "Testing 2377/2880\n",
      "relu lbfgs 1500 0.001 112 (50,): Weighted 0.768769 (0.061794)\n",
      "relu lbfgs 1500 0.001 112 (50,): Macro 0.647627 (0.060153)\n",
      "Testing 2378/2880\n",
      "relu lbfgs 1500 0.001 112 (100,): Weighted 0.818211 (0.058576)\n",
      "relu lbfgs 1500 0.001 112 (100,): Macro 0.694486 (0.062588)\n",
      "Testing 2379/2880\n",
      "relu lbfgs 1500 0.001 112 (150,): Weighted 0.789033 (0.062975)\n",
      "relu lbfgs 1500 0.001 112 (150,): Macro 0.665512 (0.071411)\n",
      "Testing 2380/2880\n",
      "relu lbfgs 1500 0.001 112 (200,): Weighted 0.777414 (0.068167)\n",
      "relu lbfgs 1500 0.001 112 (200,): Macro 0.639674 (0.077716)\n",
      "Testing 2381/2880\n",
      "relu lbfgs 1500 0.0001 17 (50,): Weighted 0.815935 (0.052089)\n",
      "relu lbfgs 1500 0.0001 17 (50,): Macro 0.696354 (0.071056)\n",
      "Testing 2382/2880\n",
      "relu lbfgs 1500 0.0001 17 (100,): Weighted 0.775858 (0.030857)\n",
      "relu lbfgs 1500 0.0001 17 (100,): Macro 0.637313 (0.022506)\n",
      "Testing 2383/2880\n",
      "relu lbfgs 1500 0.0001 17 (150,): Weighted 0.770569 (0.019734)\n",
      "relu lbfgs 1500 0.0001 17 (150,): Macro 0.612995 (0.038370)\n",
      "Testing 2384/2880\n",
      "relu lbfgs 1500 0.0001 17 (200,): Weighted 0.806130 (0.032220)\n",
      "relu lbfgs 1500 0.0001 17 (200,): Macro 0.673324 (0.041790)\n",
      "Testing 2385/2880\n",
      "relu lbfgs 1500 0.0001 29 (50,): Weighted 0.786636 (0.045454)\n",
      "relu lbfgs 1500 0.0001 29 (50,): Macro 0.673015 (0.030642)\n",
      "Testing 2386/2880\n",
      "relu lbfgs 1500 0.0001 29 (100,): Weighted 0.804706 (0.040972)\n",
      "relu lbfgs 1500 0.0001 29 (100,): Macro 0.672722 (0.043705)\n",
      "Testing 2387/2880\n",
      "relu lbfgs 1500 0.0001 29 (150,): Weighted 0.817793 (0.047937)\n",
      "relu lbfgs 1500 0.0001 29 (150,): Macro 0.691044 (0.051300)\n",
      "Testing 2388/2880\n",
      "relu lbfgs 1500 0.0001 29 (200,): Weighted 0.776375 (0.065981)\n",
      "relu lbfgs 1500 0.0001 29 (200,): Macro 0.636019 (0.088165)\n",
      "Testing 2389/2880\n",
      "relu lbfgs 1500 0.0001 42 (50,): Weighted 0.787464 (0.056059)\n",
      "relu lbfgs 1500 0.0001 42 (50,): Macro 0.653600 (0.061636)\n",
      "Testing 2390/2880\n",
      "relu lbfgs 1500 0.0001 42 (100,): Weighted 0.784110 (0.072998)\n",
      "relu lbfgs 1500 0.0001 42 (100,): Macro 0.666955 (0.075221)\n",
      "Testing 2391/2880\n",
      "relu lbfgs 1500 0.0001 42 (150,): Weighted 0.765211 (0.039493)\n",
      "relu lbfgs 1500 0.0001 42 (150,): Macro 0.617352 (0.051523)\n",
      "Testing 2392/2880\n",
      "relu lbfgs 1500 0.0001 42 (200,): Weighted 0.775553 (0.063917)\n",
      "relu lbfgs 1500 0.0001 42 (200,): Macro 0.628921 (0.077224)\n",
      "Testing 2393/2880\n",
      "relu lbfgs 1500 0.0001 76 (50,): Weighted 0.789338 (0.068578)\n",
      "relu lbfgs 1500 0.0001 76 (50,): Macro 0.672942 (0.082733)\n",
      "Testing 2394/2880\n",
      "relu lbfgs 1500 0.0001 76 (100,): Weighted 0.779535 (0.040570)\n",
      "relu lbfgs 1500 0.0001 76 (100,): Macro 0.639770 (0.040918)\n",
      "Testing 2395/2880\n",
      "relu lbfgs 1500 0.0001 76 (150,): Weighted 0.774217 (0.058839)\n",
      "relu lbfgs 1500 0.0001 76 (150,): Macro 0.635589 (0.055243)\n",
      "Testing 2396/2880\n",
      "relu lbfgs 1500 0.0001 76 (200,): Weighted 0.790749 (0.052642)\n",
      "relu lbfgs 1500 0.0001 76 (200,): Macro 0.646632 (0.064549)\n",
      "Testing 2397/2880\n",
      "relu lbfgs 1500 0.0001 112 (50,): Weighted 0.794638 (0.057931)\n",
      "relu lbfgs 1500 0.0001 112 (50,): Macro 0.673178 (0.067400)\n",
      "Testing 2398/2880\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relu lbfgs 1500 0.0001 112 (100,): Weighted 0.752880 (0.036456)\n",
      "relu lbfgs 1500 0.0001 112 (100,): Macro 0.625206 (0.041503)\n",
      "Testing 2399/2880\n",
      "relu lbfgs 1500 0.0001 112 (150,): Weighted 0.780617 (0.047239)\n",
      "relu lbfgs 1500 0.0001 112 (150,): Macro 0.637760 (0.044310)\n",
      "Testing 2400/2880\n",
      "relu lbfgs 1500 0.0001 112 (200,): Weighted 0.794642 (0.043114)\n",
      "relu lbfgs 1500 0.0001 112 (200,): Macro 0.664290 (0.049193)\n",
      "Testing 2401/2880\n",
      "relu sgd 500 0.1 17 (50,): Weighted 0.828334 (0.056433)\n",
      "relu sgd 500 0.1 17 (50,): Macro 0.718572 (0.065142)\n",
      "Testing 2402/2880\n",
      "relu sgd 500 0.1 17 (100,): Weighted 0.800930 (0.022719)\n",
      "relu sgd 500 0.1 17 (100,): Macro 0.683934 (0.031174)\n",
      "Testing 2403/2880\n",
      "relu sgd 500 0.1 17 (150,): Weighted 0.805661 (0.035160)\n",
      "relu sgd 500 0.1 17 (150,): Macro 0.670459 (0.031243)\n",
      "Testing 2404/2880\n",
      "relu sgd 500 0.1 17 (200,): Weighted 0.845416 (0.063696)\n",
      "relu sgd 500 0.1 17 (200,): Macro 0.743249 (0.087582)\n",
      "Testing 2405/2880\n",
      "relu sgd 500 0.1 29 (50,): Weighted 0.856659 (0.049825)\n",
      "relu sgd 500 0.1 29 (50,): Macro 0.763794 (0.067055)\n",
      "Testing 2406/2880\n",
      "relu sgd 500 0.1 29 (100,): Weighted 0.822619 (0.066776)\n",
      "relu sgd 500 0.1 29 (100,): Macro 0.709974 (0.089979)\n",
      "Testing 2407/2880\n",
      "relu sgd 500 0.1 29 (150,): Weighted 0.808319 (0.074429)\n",
      "relu sgd 500 0.1 29 (150,): Macro 0.695980 (0.097687)\n",
      "Testing 2408/2880\n",
      "relu sgd 500 0.1 29 (200,): Weighted 0.818502 (0.057897)\n",
      "relu sgd 500 0.1 29 (200,): Macro 0.699024 (0.068522)\n",
      "Testing 2409/2880\n",
      "relu sgd 500 0.1 42 (50,): Weighted 0.849275 (0.052640)\n",
      "relu sgd 500 0.1 42 (50,): Macro 0.753198 (0.065959)\n",
      "Testing 2410/2880\n",
      "relu sgd 500 0.1 42 (100,): Weighted 0.785920 (0.035197)\n",
      "relu sgd 500 0.1 42 (100,): Macro 0.664803 (0.044030)\n",
      "Testing 2411/2880\n",
      "relu sgd 500 0.1 42 (150,): Weighted 0.839492 (0.051433)\n",
      "relu sgd 500 0.1 42 (150,): Macro 0.739008 (0.071628)\n",
      "Testing 2412/2880\n",
      "relu sgd 500 0.1 42 (200,): Weighted 0.815920 (0.083964)\n",
      "relu sgd 500 0.1 42 (200,): Macro 0.704105 (0.116076)\n",
      "Testing 2413/2880\n",
      "relu sgd 500 0.1 76 (50,): Weighted 0.825949 (0.062830)\n",
      "relu sgd 500 0.1 76 (50,): Macro 0.714329 (0.084276)\n",
      "Testing 2414/2880\n",
      "relu sgd 500 0.1 76 (100,): Weighted 0.828901 (0.055184)\n",
      "relu sgd 500 0.1 76 (100,): Macro 0.712442 (0.068149)\n",
      "Testing 2415/2880\n",
      "relu sgd 500 0.1 76 (150,): Weighted 0.838833 (0.048288)\n",
      "relu sgd 500 0.1 76 (150,): Macro 0.735157 (0.058122)\n",
      "Testing 2416/2880\n",
      "relu sgd 500 0.1 76 (200,): Weighted 0.827221 (0.050947)\n",
      "relu sgd 500 0.1 76 (200,): Macro 0.715544 (0.062715)\n",
      "Testing 2417/2880\n",
      "relu sgd 500 0.1 112 (50,): Weighted 0.830203 (0.043747)\n",
      "relu sgd 500 0.1 112 (50,): Macro 0.719601 (0.059620)\n",
      "Testing 2418/2880\n",
      "relu sgd 500 0.1 112 (100,): Weighted 0.823409 (0.061528)\n",
      "relu sgd 500 0.1 112 (100,): Macro 0.708906 (0.078678)\n",
      "Testing 2419/2880\n",
      "relu sgd 500 0.1 112 (150,): Weighted 0.829400 (0.056481)\n",
      "relu sgd 500 0.1 112 (150,): Macro 0.717517 (0.073611)\n",
      "Testing 2420/2880\n",
      "relu sgd 500 0.1 112 (200,): Weighted 0.854934 (0.059000)\n",
      "relu sgd 500 0.1 112 (200,): Macro 0.755213 (0.083393)\n",
      "Testing 2421/2880\n",
      "relu sgd 500 0.01 17 (50,): Weighted 0.828334 (0.056433)\n",
      "relu sgd 500 0.01 17 (50,): Macro 0.718572 (0.065142)\n",
      "Testing 2422/2880\n",
      "relu sgd 500 0.01 17 (100,): Weighted 0.799628 (0.024277)\n",
      "relu sgd 500 0.01 17 (100,): Macro 0.683392 (0.031996)\n",
      "Testing 2423/2880\n",
      "relu sgd 500 0.01 17 (150,): Weighted 0.805661 (0.035160)\n",
      "relu sgd 500 0.01 17 (150,): Macro 0.670459 (0.031243)\n",
      "Testing 2424/2880\n",
      "relu sgd 500 0.01 17 (200,): Weighted 0.845416 (0.063696)\n",
      "relu sgd 500 0.01 17 (200,): Macro 0.743249 (0.087582)\n",
      "Testing 2425/2880\n",
      "relu sgd 500 0.01 29 (50,): Weighted 0.856659 (0.049825)\n",
      "relu sgd 500 0.01 29 (50,): Macro 0.763794 (0.067055)\n",
      "Testing 2426/2880\n",
      "relu sgd 500 0.01 29 (100,): Weighted 0.822619 (0.066776)\n",
      "relu sgd 500 0.01 29 (100,): Macro 0.709974 (0.089979)\n",
      "Testing 2427/2880\n",
      "relu sgd 500 0.01 29 (150,): Weighted 0.808319 (0.074429)\n",
      "relu sgd 500 0.01 29 (150,): Macro 0.695980 (0.097687)\n",
      "Testing 2428/2880\n",
      "relu sgd 500 0.01 29 (200,): Weighted 0.818502 (0.057897)\n",
      "relu sgd 500 0.01 29 (200,): Macro 0.699024 (0.068522)\n",
      "Testing 2429/2880\n",
      "relu sgd 500 0.01 42 (50,): Weighted 0.841156 (0.056676)\n",
      "relu sgd 500 0.01 42 (50,): Macro 0.744149 (0.071172)\n",
      "Testing 2430/2880\n",
      "relu sgd 500 0.01 42 (100,): Weighted 0.785920 (0.035197)\n",
      "relu sgd 500 0.01 42 (100,): Macro 0.664803 (0.044030)\n",
      "Testing 2431/2880\n",
      "relu sgd 500 0.01 42 (150,): Weighted 0.839492 (0.051433)\n",
      "relu sgd 500 0.01 42 (150,): Macro 0.739008 (0.071628)\n",
      "Testing 2432/2880\n",
      "relu sgd 500 0.01 42 (200,): Weighted 0.820914 (0.078107)\n",
      "relu sgd 500 0.01 42 (200,): Macro 0.715963 (0.100967)\n",
      "Testing 2433/2880\n",
      "relu sgd 500 0.01 76 (50,): Weighted 0.825949 (0.062830)\n",
      "relu sgd 500 0.01 76 (50,): Macro 0.714329 (0.084276)\n",
      "Testing 2434/2880\n",
      "relu sgd 500 0.01 76 (100,): Weighted 0.828901 (0.055184)\n",
      "relu sgd 500 0.01 76 (100,): Macro 0.712442 (0.068149)\n",
      "Testing 2435/2880\n",
      "relu sgd 500 0.01 76 (150,): Weighted 0.838833 (0.048288)\n",
      "relu sgd 500 0.01 76 (150,): Macro 0.735157 (0.058122)\n",
      "Testing 2436/2880\n",
      "relu sgd 500 0.01 76 (200,): Weighted 0.817052 (0.049759)\n",
      "relu sgd 500 0.01 76 (200,): Macro 0.701303 (0.058531)\n",
      "Testing 2437/2880\n",
      "relu sgd 500 0.01 112 (50,): Weighted 0.830203 (0.043747)\n",
      "relu sgd 500 0.01 112 (50,): Macro 0.719601 (0.059620)\n",
      "Testing 2438/2880\n",
      "relu sgd 500 0.01 112 (100,): Weighted 0.823204 (0.061270)\n",
      "relu sgd 500 0.01 112 (100,): Macro 0.712760 (0.083195)\n",
      "Testing 2439/2880\n",
      "relu sgd 500 0.01 112 (150,): Weighted 0.826007 (0.060511)\n",
      "relu sgd 500 0.01 112 (150,): Macro 0.712848 (0.079158)\n",
      "Testing 2440/2880\n",
      "relu sgd 500 0.01 112 (200,): Weighted 0.854934 (0.059000)\n",
      "relu sgd 500 0.01 112 (200,): Macro 0.755213 (0.083393)\n",
      "Testing 2441/2880\n",
      "relu sgd 500 0.001 17 (50,): Weighted 0.828334 (0.056433)\n",
      "relu sgd 500 0.001 17 (50,): Macro 0.718572 (0.065142)\n",
      "Testing 2442/2880\n",
      "relu sgd 500 0.001 17 (100,): Weighted 0.799628 (0.024277)\n",
      "relu sgd 500 0.001 17 (100,): Macro 0.683392 (0.031996)\n",
      "Testing 2443/2880\n",
      "relu sgd 500 0.001 17 (150,): Weighted 0.805661 (0.035160)\n",
      "relu sgd 500 0.001 17 (150,): Macro 0.670459 (0.031243)\n",
      "Testing 2444/2880\n",
      "relu sgd 500 0.001 17 (200,): Weighted 0.845416 (0.063696)\n",
      "relu sgd 500 0.001 17 (200,): Macro 0.743249 (0.087582)\n",
      "Testing 2445/2880\n",
      "relu sgd 500 0.001 29 (50,): Weighted 0.856659 (0.049825)\n",
      "relu sgd 500 0.001 29 (50,): Macro 0.763794 (0.067055)\n",
      "Testing 2446/2880\n",
      "relu sgd 500 0.001 29 (100,): Weighted 0.822619 (0.066776)\n",
      "relu sgd 500 0.001 29 (100,): Macro 0.709974 (0.089979)\n",
      "Testing 2447/2880\n",
      "relu sgd 500 0.001 29 (150,): Weighted 0.808319 (0.074429)\n",
      "relu sgd 500 0.001 29 (150,): Macro 0.695980 (0.097687)\n",
      "Testing 2448/2880\n",
      "relu sgd 500 0.001 29 (200,): Weighted 0.818502 (0.057897)\n",
      "relu sgd 500 0.001 29 (200,): Macro 0.699024 (0.068522)\n",
      "Testing 2449/2880\n",
      "relu sgd 500 0.001 42 (50,): Weighted 0.841156 (0.056676)\n",
      "relu sgd 500 0.001 42 (50,): Macro 0.744149 (0.071172)\n",
      "Testing 2450/2880\n",
      "relu sgd 500 0.001 42 (100,): Weighted 0.781204 (0.034078)\n",
      "relu sgd 500 0.001 42 (100,): Macro 0.658422 (0.039361)\n",
      "Testing 2451/2880\n",
      "relu sgd 500 0.001 42 (150,): Weighted 0.839492 (0.051433)\n",
      "relu sgd 500 0.001 42 (150,): Macro 0.739008 (0.071628)\n",
      "Testing 2452/2880\n",
      "relu sgd 500 0.001 42 (200,): Weighted 0.820914 (0.078107)\n",
      "relu sgd 500 0.001 42 (200,): Macro 0.715963 (0.100967)\n",
      "Testing 2453/2880\n",
      "relu sgd 500 0.001 76 (50,): Weighted 0.825949 (0.062830)\n",
      "relu sgd 500 0.001 76 (50,): Macro 0.714329 (0.084276)\n",
      "Testing 2454/2880\n",
      "relu sgd 500 0.001 76 (100,): Weighted 0.828901 (0.055184)\n",
      "relu sgd 500 0.001 76 (100,): Macro 0.712442 (0.068149)\n",
      "Testing 2455/2880\n",
      "relu sgd 500 0.001 76 (150,): Weighted 0.838833 (0.048288)\n",
      "relu sgd 500 0.001 76 (150,): Macro 0.735157 (0.058122)\n",
      "Testing 2456/2880\n",
      "relu sgd 500 0.001 76 (200,): Weighted 0.817052 (0.049759)\n",
      "relu sgd 500 0.001 76 (200,): Macro 0.701303 (0.058531)\n",
      "Testing 2457/2880\n",
      "relu sgd 500 0.001 112 (50,): Weighted 0.830203 (0.043747)\n",
      "relu sgd 500 0.001 112 (50,): Macro 0.719601 (0.059620)\n",
      "Testing 2458/2880\n",
      "relu sgd 500 0.001 112 (100,): Weighted 0.823409 (0.061528)\n",
      "relu sgd 500 0.001 112 (100,): Macro 0.708906 (0.078678)\n",
      "Testing 2459/2880\n",
      "relu sgd 500 0.001 112 (150,): Weighted 0.825321 (0.051541)\n",
      "relu sgd 500 0.001 112 (150,): Macro 0.710730 (0.066818)\n",
      "Testing 2460/2880\n",
      "relu sgd 500 0.001 112 (200,): Weighted 0.854934 (0.059000)\n",
      "relu sgd 500 0.001 112 (200,): Macro 0.755213 (0.083393)\n",
      "Testing 2461/2880\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relu sgd 500 0.0001 17 (50,): Weighted 0.828334 (0.056433)\n",
      "relu sgd 500 0.0001 17 (50,): Macro 0.718572 (0.065142)\n",
      "Testing 2462/2880\n",
      "relu sgd 500 0.0001 17 (100,): Weighted 0.799628 (0.024277)\n",
      "relu sgd 500 0.0001 17 (100,): Macro 0.683392 (0.031996)\n",
      "Testing 2463/2880\n",
      "relu sgd 500 0.0001 17 (150,): Weighted 0.805661 (0.035160)\n",
      "relu sgd 500 0.0001 17 (150,): Macro 0.670459 (0.031243)\n",
      "Testing 2464/2880\n",
      "relu sgd 500 0.0001 17 (200,): Weighted 0.845416 (0.063696)\n",
      "relu sgd 500 0.0001 17 (200,): Macro 0.743249 (0.087582)\n",
      "Testing 2465/2880\n",
      "relu sgd 500 0.0001 29 (50,): Weighted 0.856659 (0.049825)\n",
      "relu sgd 500 0.0001 29 (50,): Macro 0.763794 (0.067055)\n",
      "Testing 2466/2880\n",
      "relu sgd 500 0.0001 29 (100,): Weighted 0.822619 (0.066776)\n",
      "relu sgd 500 0.0001 29 (100,): Macro 0.709974 (0.089979)\n",
      "Testing 2467/2880\n",
      "relu sgd 500 0.0001 29 (150,): Weighted 0.808319 (0.074429)\n",
      "relu sgd 500 0.0001 29 (150,): Macro 0.695980 (0.097687)\n",
      "Testing 2468/2880\n",
      "relu sgd 500 0.0001 29 (200,): Weighted 0.818502 (0.057897)\n",
      "relu sgd 500 0.0001 29 (200,): Macro 0.699024 (0.068522)\n",
      "Testing 2469/2880\n",
      "relu sgd 500 0.0001 42 (50,): Weighted 0.841156 (0.056676)\n",
      "relu sgd 500 0.0001 42 (50,): Macro 0.744149 (0.071172)\n",
      "Testing 2470/2880\n",
      "relu sgd 500 0.0001 42 (100,): Weighted 0.781204 (0.034078)\n",
      "relu sgd 500 0.0001 42 (100,): Macro 0.658422 (0.039361)\n",
      "Testing 2471/2880\n",
      "relu sgd 500 0.0001 42 (150,): Weighted 0.839492 (0.051433)\n",
      "relu sgd 500 0.0001 42 (150,): Macro 0.739008 (0.071628)\n",
      "Testing 2472/2880\n",
      "relu sgd 500 0.0001 42 (200,): Weighted 0.820914 (0.078107)\n",
      "relu sgd 500 0.0001 42 (200,): Macro 0.715963 (0.100967)\n",
      "Testing 2473/2880\n",
      "relu sgd 500 0.0001 76 (50,): Weighted 0.825949 (0.062830)\n",
      "relu sgd 500 0.0001 76 (50,): Macro 0.714329 (0.084276)\n",
      "Testing 2474/2880\n",
      "relu sgd 500 0.0001 76 (100,): Weighted 0.828901 (0.055184)\n",
      "relu sgd 500 0.0001 76 (100,): Macro 0.712442 (0.068149)\n",
      "Testing 2475/2880\n",
      "relu sgd 500 0.0001 76 (150,): Weighted 0.838833 (0.048288)\n",
      "relu sgd 500 0.0001 76 (150,): Macro 0.735157 (0.058122)\n",
      "Testing 2476/2880\n",
      "relu sgd 500 0.0001 76 (200,): Weighted 0.817052 (0.049759)\n",
      "relu sgd 500 0.0001 76 (200,): Macro 0.701303 (0.058531)\n",
      "Testing 2477/2880\n",
      "relu sgd 500 0.0001 112 (50,): Weighted 0.830203 (0.043747)\n",
      "relu sgd 500 0.0001 112 (50,): Macro 0.719601 (0.059620)\n",
      "Testing 2478/2880\n",
      "relu sgd 500 0.0001 112 (100,): Weighted 0.823204 (0.061270)\n",
      "relu sgd 500 0.0001 112 (100,): Macro 0.712760 (0.083195)\n",
      "Testing 2479/2880\n",
      "relu sgd 500 0.0001 112 (150,): Weighted 0.826007 (0.060511)\n",
      "relu sgd 500 0.0001 112 (150,): Macro 0.712848 (0.079158)\n",
      "Testing 2480/2880\n",
      "relu sgd 500 0.0001 112 (200,): Weighted 0.854934 (0.059000)\n",
      "relu sgd 500 0.0001 112 (200,): Macro 0.755213 (0.083393)\n",
      "Testing 2481/2880\n",
      "relu sgd 1000 0.1 17 (50,): Weighted 0.828334 (0.056433)\n",
      "relu sgd 1000 0.1 17 (50,): Macro 0.718572 (0.065142)\n",
      "Testing 2482/2880\n",
      "relu sgd 1000 0.1 17 (100,): Weighted 0.800930 (0.022719)\n",
      "relu sgd 1000 0.1 17 (100,): Macro 0.683934 (0.031174)\n",
      "Testing 2483/2880\n",
      "relu sgd 1000 0.1 17 (150,): Weighted 0.805661 (0.035160)\n",
      "relu sgd 1000 0.1 17 (150,): Macro 0.670459 (0.031243)\n",
      "Testing 2484/2880\n",
      "relu sgd 1000 0.1 17 (200,): Weighted 0.845416 (0.063696)\n",
      "relu sgd 1000 0.1 17 (200,): Macro 0.743249 (0.087582)\n",
      "Testing 2485/2880\n",
      "relu sgd 1000 0.1 29 (50,): Weighted 0.856659 (0.049825)\n",
      "relu sgd 1000 0.1 29 (50,): Macro 0.763794 (0.067055)\n",
      "Testing 2486/2880\n",
      "relu sgd 1000 0.1 29 (100,): Weighted 0.822619 (0.066776)\n",
      "relu sgd 1000 0.1 29 (100,): Macro 0.709974 (0.089979)\n",
      "Testing 2487/2880\n",
      "relu sgd 1000 0.1 29 (150,): Weighted 0.808319 (0.074429)\n",
      "relu sgd 1000 0.1 29 (150,): Macro 0.695980 (0.097687)\n",
      "Testing 2488/2880\n",
      "relu sgd 1000 0.1 29 (200,): Weighted 0.818502 (0.057897)\n",
      "relu sgd 1000 0.1 29 (200,): Macro 0.699024 (0.068522)\n",
      "Testing 2489/2880\n",
      "relu sgd 1000 0.1 42 (50,): Weighted 0.849275 (0.052640)\n",
      "relu sgd 1000 0.1 42 (50,): Macro 0.753198 (0.065959)\n",
      "Testing 2490/2880\n",
      "relu sgd 1000 0.1 42 (100,): Weighted 0.785920 (0.035197)\n",
      "relu sgd 1000 0.1 42 (100,): Macro 0.664803 (0.044030)\n",
      "Testing 2491/2880\n",
      "relu sgd 1000 0.1 42 (150,): Weighted 0.839492 (0.051433)\n",
      "relu sgd 1000 0.1 42 (150,): Macro 0.739008 (0.071628)\n",
      "Testing 2492/2880\n",
      "relu sgd 1000 0.1 42 (200,): Weighted 0.815920 (0.083964)\n",
      "relu sgd 1000 0.1 42 (200,): Macro 0.704105 (0.116076)\n",
      "Testing 2493/2880\n",
      "relu sgd 1000 0.1 76 (50,): Weighted 0.825949 (0.062830)\n",
      "relu sgd 1000 0.1 76 (50,): Macro 0.714329 (0.084276)\n",
      "Testing 2494/2880\n",
      "relu sgd 1000 0.1 76 (100,): Weighted 0.828901 (0.055184)\n",
      "relu sgd 1000 0.1 76 (100,): Macro 0.712442 (0.068149)\n",
      "Testing 2495/2880\n",
      "relu sgd 1000 0.1 76 (150,): Weighted 0.838833 (0.048288)\n",
      "relu sgd 1000 0.1 76 (150,): Macro 0.735157 (0.058122)\n",
      "Testing 2496/2880\n",
      "relu sgd 1000 0.1 76 (200,): Weighted 0.827221 (0.050947)\n",
      "relu sgd 1000 0.1 76 (200,): Macro 0.715544 (0.062715)\n",
      "Testing 2497/2880\n",
      "relu sgd 1000 0.1 112 (50,): Weighted 0.830203 (0.043747)\n",
      "relu sgd 1000 0.1 112 (50,): Macro 0.719601 (0.059620)\n",
      "Testing 2498/2880\n",
      "relu sgd 1000 0.1 112 (100,): Weighted 0.823409 (0.061528)\n",
      "relu sgd 1000 0.1 112 (100,): Macro 0.708906 (0.078678)\n",
      "Testing 2499/2880\n",
      "relu sgd 1000 0.1 112 (150,): Weighted 0.829400 (0.056481)\n",
      "relu sgd 1000 0.1 112 (150,): Macro 0.717517 (0.073611)\n",
      "Testing 2500/2880\n",
      "relu sgd 1000 0.1 112 (200,): Weighted 0.854934 (0.059000)\n",
      "relu sgd 1000 0.1 112 (200,): Macro 0.755213 (0.083393)\n",
      "Testing 2501/2880\n",
      "relu sgd 1000 0.01 17 (50,): Weighted 0.828334 (0.056433)\n",
      "relu sgd 1000 0.01 17 (50,): Macro 0.718572 (0.065142)\n",
      "Testing 2502/2880\n",
      "relu sgd 1000 0.01 17 (100,): Weighted 0.799628 (0.024277)\n",
      "relu sgd 1000 0.01 17 (100,): Macro 0.683392 (0.031996)\n",
      "Testing 2503/2880\n",
      "relu sgd 1000 0.01 17 (150,): Weighted 0.805661 (0.035160)\n",
      "relu sgd 1000 0.01 17 (150,): Macro 0.670459 (0.031243)\n",
      "Testing 2504/2880\n",
      "relu sgd 1000 0.01 17 (200,): Weighted 0.845416 (0.063696)\n",
      "relu sgd 1000 0.01 17 (200,): Macro 0.743249 (0.087582)\n",
      "Testing 2505/2880\n",
      "relu sgd 1000 0.01 29 (50,): Weighted 0.856659 (0.049825)\n",
      "relu sgd 1000 0.01 29 (50,): Macro 0.763794 (0.067055)\n",
      "Testing 2506/2880\n",
      "relu sgd 1000 0.01 29 (100,): Weighted 0.822619 (0.066776)\n",
      "relu sgd 1000 0.01 29 (100,): Macro 0.709974 (0.089979)\n",
      "Testing 2507/2880\n",
      "relu sgd 1000 0.01 29 (150,): Weighted 0.808319 (0.074429)\n",
      "relu sgd 1000 0.01 29 (150,): Macro 0.695980 (0.097687)\n",
      "Testing 2508/2880\n",
      "relu sgd 1000 0.01 29 (200,): Weighted 0.818502 (0.057897)\n",
      "relu sgd 1000 0.01 29 (200,): Macro 0.699024 (0.068522)\n",
      "Testing 2509/2880\n",
      "relu sgd 1000 0.01 42 (50,): Weighted 0.841156 (0.056676)\n",
      "relu sgd 1000 0.01 42 (50,): Macro 0.744149 (0.071172)\n",
      "Testing 2510/2880\n",
      "relu sgd 1000 0.01 42 (100,): Weighted 0.785920 (0.035197)\n",
      "relu sgd 1000 0.01 42 (100,): Macro 0.664803 (0.044030)\n",
      "Testing 2511/2880\n",
      "relu sgd 1000 0.01 42 (150,): Weighted 0.839492 (0.051433)\n",
      "relu sgd 1000 0.01 42 (150,): Macro 0.739008 (0.071628)\n",
      "Testing 2512/2880\n",
      "relu sgd 1000 0.01 42 (200,): Weighted 0.820914 (0.078107)\n",
      "relu sgd 1000 0.01 42 (200,): Macro 0.715963 (0.100967)\n",
      "Testing 2513/2880\n",
      "relu sgd 1000 0.01 76 (50,): Weighted 0.825949 (0.062830)\n",
      "relu sgd 1000 0.01 76 (50,): Macro 0.714329 (0.084276)\n",
      "Testing 2514/2880\n",
      "relu sgd 1000 0.01 76 (100,): Weighted 0.828901 (0.055184)\n",
      "relu sgd 1000 0.01 76 (100,): Macro 0.712442 (0.068149)\n",
      "Testing 2515/2880\n",
      "relu sgd 1000 0.01 76 (150,): Weighted 0.838833 (0.048288)\n",
      "relu sgd 1000 0.01 76 (150,): Macro 0.735157 (0.058122)\n",
      "Testing 2516/2880\n",
      "relu sgd 1000 0.01 76 (200,): Weighted 0.817052 (0.049759)\n",
      "relu sgd 1000 0.01 76 (200,): Macro 0.701303 (0.058531)\n",
      "Testing 2517/2880\n",
      "relu sgd 1000 0.01 112 (50,): Weighted 0.830203 (0.043747)\n",
      "relu sgd 1000 0.01 112 (50,): Macro 0.719601 (0.059620)\n",
      "Testing 2518/2880\n",
      "relu sgd 1000 0.01 112 (100,): Weighted 0.823204 (0.061270)\n",
      "relu sgd 1000 0.01 112 (100,): Macro 0.712760 (0.083195)\n",
      "Testing 2519/2880\n",
      "relu sgd 1000 0.01 112 (150,): Weighted 0.826007 (0.060511)\n",
      "relu sgd 1000 0.01 112 (150,): Macro 0.712848 (0.079158)\n",
      "Testing 2520/2880\n",
      "relu sgd 1000 0.01 112 (200,): Weighted 0.854934 (0.059000)\n",
      "relu sgd 1000 0.01 112 (200,): Macro 0.755213 (0.083393)\n",
      "Testing 2521/2880\n",
      "relu sgd 1000 0.001 17 (50,): Weighted 0.828334 (0.056433)\n",
      "relu sgd 1000 0.001 17 (50,): Macro 0.718572 (0.065142)\n",
      "Testing 2522/2880\n",
      "relu sgd 1000 0.001 17 (100,): Weighted 0.799628 (0.024277)\n",
      "relu sgd 1000 0.001 17 (100,): Macro 0.683392 (0.031996)\n",
      "Testing 2523/2880\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relu sgd 1000 0.001 17 (150,): Weighted 0.805661 (0.035160)\n",
      "relu sgd 1000 0.001 17 (150,): Macro 0.670459 (0.031243)\n",
      "Testing 2524/2880\n",
      "relu sgd 1000 0.001 17 (200,): Weighted 0.845416 (0.063696)\n",
      "relu sgd 1000 0.001 17 (200,): Macro 0.743249 (0.087582)\n",
      "Testing 2525/2880\n",
      "relu sgd 1000 0.001 29 (50,): Weighted 0.856659 (0.049825)\n",
      "relu sgd 1000 0.001 29 (50,): Macro 0.763794 (0.067055)\n",
      "Testing 2526/2880\n",
      "relu sgd 1000 0.001 29 (100,): Weighted 0.822619 (0.066776)\n",
      "relu sgd 1000 0.001 29 (100,): Macro 0.709974 (0.089979)\n",
      "Testing 2527/2880\n",
      "relu sgd 1000 0.001 29 (150,): Weighted 0.808319 (0.074429)\n",
      "relu sgd 1000 0.001 29 (150,): Macro 0.695980 (0.097687)\n",
      "Testing 2528/2880\n",
      "relu sgd 1000 0.001 29 (200,): Weighted 0.818502 (0.057897)\n",
      "relu sgd 1000 0.001 29 (200,): Macro 0.699024 (0.068522)\n",
      "Testing 2529/2880\n",
      "relu sgd 1000 0.001 42 (50,): Weighted 0.841156 (0.056676)\n",
      "relu sgd 1000 0.001 42 (50,): Macro 0.744149 (0.071172)\n",
      "Testing 2530/2880\n",
      "relu sgd 1000 0.001 42 (100,): Weighted 0.781204 (0.034078)\n",
      "relu sgd 1000 0.001 42 (100,): Macro 0.658422 (0.039361)\n",
      "Testing 2531/2880\n",
      "relu sgd 1000 0.001 42 (150,): Weighted 0.839492 (0.051433)\n",
      "relu sgd 1000 0.001 42 (150,): Macro 0.739008 (0.071628)\n",
      "Testing 2532/2880\n",
      "relu sgd 1000 0.001 42 (200,): Weighted 0.820914 (0.078107)\n",
      "relu sgd 1000 0.001 42 (200,): Macro 0.715963 (0.100967)\n",
      "Testing 2533/2880\n",
      "relu sgd 1000 0.001 76 (50,): Weighted 0.825949 (0.062830)\n",
      "relu sgd 1000 0.001 76 (50,): Macro 0.714329 (0.084276)\n",
      "Testing 2534/2880\n",
      "relu sgd 1000 0.001 76 (100,): Weighted 0.828901 (0.055184)\n",
      "relu sgd 1000 0.001 76 (100,): Macro 0.712442 (0.068149)\n",
      "Testing 2535/2880\n",
      "relu sgd 1000 0.001 76 (150,): Weighted 0.838833 (0.048288)\n",
      "relu sgd 1000 0.001 76 (150,): Macro 0.735157 (0.058122)\n",
      "Testing 2536/2880\n",
      "relu sgd 1000 0.001 76 (200,): Weighted 0.817052 (0.049759)\n",
      "relu sgd 1000 0.001 76 (200,): Macro 0.701303 (0.058531)\n",
      "Testing 2537/2880\n",
      "relu sgd 1000 0.001 112 (50,): Weighted 0.830203 (0.043747)\n",
      "relu sgd 1000 0.001 112 (50,): Macro 0.719601 (0.059620)\n",
      "Testing 2538/2880\n",
      "relu sgd 1000 0.001 112 (100,): Weighted 0.823409 (0.061528)\n",
      "relu sgd 1000 0.001 112 (100,): Macro 0.708906 (0.078678)\n",
      "Testing 2539/2880\n",
      "relu sgd 1000 0.001 112 (150,): Weighted 0.825321 (0.051541)\n",
      "relu sgd 1000 0.001 112 (150,): Macro 0.710730 (0.066818)\n",
      "Testing 2540/2880\n",
      "relu sgd 1000 0.001 112 (200,): Weighted 0.854934 (0.059000)\n",
      "relu sgd 1000 0.001 112 (200,): Macro 0.755213 (0.083393)\n",
      "Testing 2541/2880\n",
      "relu sgd 1000 0.0001 17 (50,): Weighted 0.828334 (0.056433)\n",
      "relu sgd 1000 0.0001 17 (50,): Macro 0.718572 (0.065142)\n",
      "Testing 2542/2880\n",
      "relu sgd 1000 0.0001 17 (100,): Weighted 0.799628 (0.024277)\n",
      "relu sgd 1000 0.0001 17 (100,): Macro 0.683392 (0.031996)\n",
      "Testing 2543/2880\n",
      "relu sgd 1000 0.0001 17 (150,): Weighted 0.805661 (0.035160)\n",
      "relu sgd 1000 0.0001 17 (150,): Macro 0.670459 (0.031243)\n",
      "Testing 2544/2880\n",
      "relu sgd 1000 0.0001 17 (200,): Weighted 0.845416 (0.063696)\n",
      "relu sgd 1000 0.0001 17 (200,): Macro 0.743249 (0.087582)\n",
      "Testing 2545/2880\n",
      "relu sgd 1000 0.0001 29 (50,): Weighted 0.856659 (0.049825)\n",
      "relu sgd 1000 0.0001 29 (50,): Macro 0.763794 (0.067055)\n",
      "Testing 2546/2880\n",
      "relu sgd 1000 0.0001 29 (100,): Weighted 0.822619 (0.066776)\n",
      "relu sgd 1000 0.0001 29 (100,): Macro 0.709974 (0.089979)\n",
      "Testing 2547/2880\n",
      "relu sgd 1000 0.0001 29 (150,): Weighted 0.808319 (0.074429)\n",
      "relu sgd 1000 0.0001 29 (150,): Macro 0.695980 (0.097687)\n",
      "Testing 2548/2880\n",
      "relu sgd 1000 0.0001 29 (200,): Weighted 0.818502 (0.057897)\n",
      "relu sgd 1000 0.0001 29 (200,): Macro 0.699024 (0.068522)\n",
      "Testing 2549/2880\n",
      "relu sgd 1000 0.0001 42 (50,): Weighted 0.841156 (0.056676)\n",
      "relu sgd 1000 0.0001 42 (50,): Macro 0.744149 (0.071172)\n",
      "Testing 2550/2880\n",
      "relu sgd 1000 0.0001 42 (100,): Weighted 0.781204 (0.034078)\n",
      "relu sgd 1000 0.0001 42 (100,): Macro 0.658422 (0.039361)\n",
      "Testing 2551/2880\n",
      "relu sgd 1000 0.0001 42 (150,): Weighted 0.839492 (0.051433)\n",
      "relu sgd 1000 0.0001 42 (150,): Macro 0.739008 (0.071628)\n",
      "Testing 2552/2880\n",
      "relu sgd 1000 0.0001 42 (200,): Weighted 0.820914 (0.078107)\n",
      "relu sgd 1000 0.0001 42 (200,): Macro 0.715963 (0.100967)\n",
      "Testing 2553/2880\n",
      "relu sgd 1000 0.0001 76 (50,): Weighted 0.825949 (0.062830)\n",
      "relu sgd 1000 0.0001 76 (50,): Macro 0.714329 (0.084276)\n",
      "Testing 2554/2880\n",
      "relu sgd 1000 0.0001 76 (100,): Weighted 0.828901 (0.055184)\n",
      "relu sgd 1000 0.0001 76 (100,): Macro 0.712442 (0.068149)\n",
      "Testing 2555/2880\n",
      "relu sgd 1000 0.0001 76 (150,): Weighted 0.838833 (0.048288)\n",
      "relu sgd 1000 0.0001 76 (150,): Macro 0.735157 (0.058122)\n",
      "Testing 2556/2880\n",
      "relu sgd 1000 0.0001 76 (200,): Weighted 0.817052 (0.049759)\n",
      "relu sgd 1000 0.0001 76 (200,): Macro 0.701303 (0.058531)\n",
      "Testing 2557/2880\n",
      "relu sgd 1000 0.0001 112 (50,): Weighted 0.830203 (0.043747)\n",
      "relu sgd 1000 0.0001 112 (50,): Macro 0.719601 (0.059620)\n",
      "Testing 2558/2880\n",
      "relu sgd 1000 0.0001 112 (100,): Weighted 0.823204 (0.061270)\n",
      "relu sgd 1000 0.0001 112 (100,): Macro 0.712760 (0.083195)\n",
      "Testing 2559/2880\n",
      "relu sgd 1000 0.0001 112 (150,): Weighted 0.826007 (0.060511)\n",
      "relu sgd 1000 0.0001 112 (150,): Macro 0.712848 (0.079158)\n",
      "Testing 2560/2880\n",
      "relu sgd 1000 0.0001 112 (200,): Weighted 0.854934 (0.059000)\n",
      "relu sgd 1000 0.0001 112 (200,): Macro 0.755213 (0.083393)\n",
      "Testing 2561/2880\n",
      "relu sgd 1500 0.1 17 (50,): Weighted 0.828334 (0.056433)\n",
      "relu sgd 1500 0.1 17 (50,): Macro 0.718572 (0.065142)\n",
      "Testing 2562/2880\n",
      "relu sgd 1500 0.1 17 (100,): Weighted 0.800930 (0.022719)\n",
      "relu sgd 1500 0.1 17 (100,): Macro 0.683934 (0.031174)\n",
      "Testing 2563/2880\n",
      "relu sgd 1500 0.1 17 (150,): Weighted 0.805661 (0.035160)\n",
      "relu sgd 1500 0.1 17 (150,): Macro 0.670459 (0.031243)\n",
      "Testing 2564/2880\n",
      "relu sgd 1500 0.1 17 (200,): Weighted 0.845416 (0.063696)\n",
      "relu sgd 1500 0.1 17 (200,): Macro 0.743249 (0.087582)\n",
      "Testing 2565/2880\n",
      "relu sgd 1500 0.1 29 (50,): Weighted 0.856659 (0.049825)\n",
      "relu sgd 1500 0.1 29 (50,): Macro 0.763794 (0.067055)\n",
      "Testing 2566/2880\n",
      "relu sgd 1500 0.1 29 (100,): Weighted 0.822619 (0.066776)\n",
      "relu sgd 1500 0.1 29 (100,): Macro 0.709974 (0.089979)\n",
      "Testing 2567/2880\n",
      "relu sgd 1500 0.1 29 (150,): Weighted 0.808319 (0.074429)\n",
      "relu sgd 1500 0.1 29 (150,): Macro 0.695980 (0.097687)\n",
      "Testing 2568/2880\n",
      "relu sgd 1500 0.1 29 (200,): Weighted 0.818502 (0.057897)\n",
      "relu sgd 1500 0.1 29 (200,): Macro 0.699024 (0.068522)\n",
      "Testing 2569/2880\n",
      "relu sgd 1500 0.1 42 (50,): Weighted 0.849275 (0.052640)\n",
      "relu sgd 1500 0.1 42 (50,): Macro 0.753198 (0.065959)\n",
      "Testing 2570/2880\n",
      "relu sgd 1500 0.1 42 (100,): Weighted 0.785920 (0.035197)\n",
      "relu sgd 1500 0.1 42 (100,): Macro 0.664803 (0.044030)\n",
      "Testing 2571/2880\n",
      "relu sgd 1500 0.1 42 (150,): Weighted 0.839492 (0.051433)\n",
      "relu sgd 1500 0.1 42 (150,): Macro 0.739008 (0.071628)\n",
      "Testing 2572/2880\n",
      "relu sgd 1500 0.1 42 (200,): Weighted 0.815920 (0.083964)\n",
      "relu sgd 1500 0.1 42 (200,): Macro 0.704105 (0.116076)\n",
      "Testing 2573/2880\n",
      "relu sgd 1500 0.1 76 (50,): Weighted 0.825949 (0.062830)\n",
      "relu sgd 1500 0.1 76 (50,): Macro 0.714329 (0.084276)\n",
      "Testing 2574/2880\n",
      "relu sgd 1500 0.1 76 (100,): Weighted 0.828901 (0.055184)\n",
      "relu sgd 1500 0.1 76 (100,): Macro 0.712442 (0.068149)\n",
      "Testing 2575/2880\n",
      "relu sgd 1500 0.1 76 (150,): Weighted 0.838833 (0.048288)\n",
      "relu sgd 1500 0.1 76 (150,): Macro 0.735157 (0.058122)\n",
      "Testing 2576/2880\n",
      "relu sgd 1500 0.1 76 (200,): Weighted 0.827221 (0.050947)\n",
      "relu sgd 1500 0.1 76 (200,): Macro 0.715544 (0.062715)\n",
      "Testing 2577/2880\n",
      "relu sgd 1500 0.1 112 (50,): Weighted 0.830203 (0.043747)\n",
      "relu sgd 1500 0.1 112 (50,): Macro 0.719601 (0.059620)\n",
      "Testing 2578/2880\n",
      "relu sgd 1500 0.1 112 (100,): Weighted 0.823409 (0.061528)\n",
      "relu sgd 1500 0.1 112 (100,): Macro 0.708906 (0.078678)\n",
      "Testing 2579/2880\n",
      "relu sgd 1500 0.1 112 (150,): Weighted 0.829400 (0.056481)\n",
      "relu sgd 1500 0.1 112 (150,): Macro 0.717517 (0.073611)\n",
      "Testing 2580/2880\n",
      "relu sgd 1500 0.1 112 (200,): Weighted 0.854934 (0.059000)\n",
      "relu sgd 1500 0.1 112 (200,): Macro 0.755213 (0.083393)\n",
      "Testing 2581/2880\n",
      "relu sgd 1500 0.01 17 (50,): Weighted 0.828334 (0.056433)\n",
      "relu sgd 1500 0.01 17 (50,): Macro 0.718572 (0.065142)\n",
      "Testing 2582/2880\n",
      "relu sgd 1500 0.01 17 (100,): Weighted 0.799628 (0.024277)\n",
      "relu sgd 1500 0.01 17 (100,): Macro 0.683392 (0.031996)\n",
      "Testing 2583/2880\n",
      "relu sgd 1500 0.01 17 (150,): Weighted 0.805661 (0.035160)\n",
      "relu sgd 1500 0.01 17 (150,): Macro 0.670459 (0.031243)\n",
      "Testing 2584/2880\n",
      "relu sgd 1500 0.01 17 (200,): Weighted 0.845416 (0.063696)\n",
      "relu sgd 1500 0.01 17 (200,): Macro 0.743249 (0.087582)\n",
      "Testing 2585/2880\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relu sgd 1500 0.01 29 (50,): Weighted 0.856659 (0.049825)\n",
      "relu sgd 1500 0.01 29 (50,): Macro 0.763794 (0.067055)\n",
      "Testing 2586/2880\n",
      "relu sgd 1500 0.01 29 (100,): Weighted 0.822619 (0.066776)\n",
      "relu sgd 1500 0.01 29 (100,): Macro 0.709974 (0.089979)\n",
      "Testing 2587/2880\n",
      "relu sgd 1500 0.01 29 (150,): Weighted 0.808319 (0.074429)\n",
      "relu sgd 1500 0.01 29 (150,): Macro 0.695980 (0.097687)\n",
      "Testing 2588/2880\n",
      "relu sgd 1500 0.01 29 (200,): Weighted 0.818502 (0.057897)\n",
      "relu sgd 1500 0.01 29 (200,): Macro 0.699024 (0.068522)\n",
      "Testing 2589/2880\n",
      "relu sgd 1500 0.01 42 (50,): Weighted 0.841156 (0.056676)\n",
      "relu sgd 1500 0.01 42 (50,): Macro 0.744149 (0.071172)\n",
      "Testing 2590/2880\n",
      "relu sgd 1500 0.01 42 (100,): Weighted 0.785920 (0.035197)\n",
      "relu sgd 1500 0.01 42 (100,): Macro 0.664803 (0.044030)\n",
      "Testing 2591/2880\n",
      "relu sgd 1500 0.01 42 (150,): Weighted 0.839492 (0.051433)\n",
      "relu sgd 1500 0.01 42 (150,): Macro 0.739008 (0.071628)\n",
      "Testing 2592/2880\n",
      "relu sgd 1500 0.01 42 (200,): Weighted 0.820914 (0.078107)\n",
      "relu sgd 1500 0.01 42 (200,): Macro 0.715963 (0.100967)\n",
      "Testing 2593/2880\n",
      "relu sgd 1500 0.01 76 (50,): Weighted 0.825949 (0.062830)\n",
      "relu sgd 1500 0.01 76 (50,): Macro 0.714329 (0.084276)\n",
      "Testing 2594/2880\n",
      "relu sgd 1500 0.01 76 (100,): Weighted 0.828901 (0.055184)\n",
      "relu sgd 1500 0.01 76 (100,): Macro 0.712442 (0.068149)\n",
      "Testing 2595/2880\n",
      "relu sgd 1500 0.01 76 (150,): Weighted 0.838833 (0.048288)\n",
      "relu sgd 1500 0.01 76 (150,): Macro 0.735157 (0.058122)\n",
      "Testing 2596/2880\n",
      "relu sgd 1500 0.01 76 (200,): Weighted 0.817052 (0.049759)\n",
      "relu sgd 1500 0.01 76 (200,): Macro 0.701303 (0.058531)\n",
      "Testing 2597/2880\n",
      "relu sgd 1500 0.01 112 (50,): Weighted 0.830203 (0.043747)\n",
      "relu sgd 1500 0.01 112 (50,): Macro 0.719601 (0.059620)\n",
      "Testing 2598/2880\n",
      "relu sgd 1500 0.01 112 (100,): Weighted 0.823204 (0.061270)\n",
      "relu sgd 1500 0.01 112 (100,): Macro 0.712760 (0.083195)\n",
      "Testing 2599/2880\n",
      "relu sgd 1500 0.01 112 (150,): Weighted 0.826007 (0.060511)\n",
      "relu sgd 1500 0.01 112 (150,): Macro 0.712848 (0.079158)\n",
      "Testing 2600/2880\n",
      "relu sgd 1500 0.01 112 (200,): Weighted 0.854934 (0.059000)\n",
      "relu sgd 1500 0.01 112 (200,): Macro 0.755213 (0.083393)\n",
      "Testing 2601/2880\n",
      "relu sgd 1500 0.001 17 (50,): Weighted 0.828334 (0.056433)\n",
      "relu sgd 1500 0.001 17 (50,): Macro 0.718572 (0.065142)\n",
      "Testing 2602/2880\n",
      "relu sgd 1500 0.001 17 (100,): Weighted 0.799628 (0.024277)\n",
      "relu sgd 1500 0.001 17 (100,): Macro 0.683392 (0.031996)\n",
      "Testing 2603/2880\n",
      "relu sgd 1500 0.001 17 (150,): Weighted 0.805661 (0.035160)\n",
      "relu sgd 1500 0.001 17 (150,): Macro 0.670459 (0.031243)\n",
      "Testing 2604/2880\n",
      "relu sgd 1500 0.001 17 (200,): Weighted 0.845416 (0.063696)\n",
      "relu sgd 1500 0.001 17 (200,): Macro 0.743249 (0.087582)\n",
      "Testing 2605/2880\n",
      "relu sgd 1500 0.001 29 (50,): Weighted 0.856659 (0.049825)\n",
      "relu sgd 1500 0.001 29 (50,): Macro 0.763794 (0.067055)\n",
      "Testing 2606/2880\n",
      "relu sgd 1500 0.001 29 (100,): Weighted 0.822619 (0.066776)\n",
      "relu sgd 1500 0.001 29 (100,): Macro 0.709974 (0.089979)\n",
      "Testing 2607/2880\n",
      "relu sgd 1500 0.001 29 (150,): Weighted 0.808319 (0.074429)\n",
      "relu sgd 1500 0.001 29 (150,): Macro 0.695980 (0.097687)\n",
      "Testing 2608/2880\n",
      "relu sgd 1500 0.001 29 (200,): Weighted 0.818502 (0.057897)\n",
      "relu sgd 1500 0.001 29 (200,): Macro 0.699024 (0.068522)\n",
      "Testing 2609/2880\n",
      "relu sgd 1500 0.001 42 (50,): Weighted 0.841156 (0.056676)\n",
      "relu sgd 1500 0.001 42 (50,): Macro 0.744149 (0.071172)\n",
      "Testing 2610/2880\n",
      "relu sgd 1500 0.001 42 (100,): Weighted 0.781204 (0.034078)\n",
      "relu sgd 1500 0.001 42 (100,): Macro 0.658422 (0.039361)\n",
      "Testing 2611/2880\n",
      "relu sgd 1500 0.001 42 (150,): Weighted 0.839492 (0.051433)\n",
      "relu sgd 1500 0.001 42 (150,): Macro 0.739008 (0.071628)\n",
      "Testing 2612/2880\n",
      "relu sgd 1500 0.001 42 (200,): Weighted 0.820914 (0.078107)\n",
      "relu sgd 1500 0.001 42 (200,): Macro 0.715963 (0.100967)\n",
      "Testing 2613/2880\n",
      "relu sgd 1500 0.001 76 (50,): Weighted 0.825949 (0.062830)\n",
      "relu sgd 1500 0.001 76 (50,): Macro 0.714329 (0.084276)\n",
      "Testing 2614/2880\n",
      "relu sgd 1500 0.001 76 (100,): Weighted 0.828901 (0.055184)\n",
      "relu sgd 1500 0.001 76 (100,): Macro 0.712442 (0.068149)\n",
      "Testing 2615/2880\n",
      "relu sgd 1500 0.001 76 (150,): Weighted 0.838833 (0.048288)\n",
      "relu sgd 1500 0.001 76 (150,): Macro 0.735157 (0.058122)\n",
      "Testing 2616/2880\n",
      "relu sgd 1500 0.001 76 (200,): Weighted 0.817052 (0.049759)\n",
      "relu sgd 1500 0.001 76 (200,): Macro 0.701303 (0.058531)\n",
      "Testing 2617/2880\n",
      "relu sgd 1500 0.001 112 (50,): Weighted 0.830203 (0.043747)\n",
      "relu sgd 1500 0.001 112 (50,): Macro 0.719601 (0.059620)\n",
      "Testing 2618/2880\n",
      "relu sgd 1500 0.001 112 (100,): Weighted 0.823409 (0.061528)\n",
      "relu sgd 1500 0.001 112 (100,): Macro 0.708906 (0.078678)\n",
      "Testing 2619/2880\n",
      "relu sgd 1500 0.001 112 (150,): Weighted 0.825321 (0.051541)\n",
      "relu sgd 1500 0.001 112 (150,): Macro 0.710730 (0.066818)\n",
      "Testing 2620/2880\n",
      "relu sgd 1500 0.001 112 (200,): Weighted 0.854934 (0.059000)\n",
      "relu sgd 1500 0.001 112 (200,): Macro 0.755213 (0.083393)\n",
      "Testing 2621/2880\n",
      "relu sgd 1500 0.0001 17 (50,): Weighted 0.828334 (0.056433)\n",
      "relu sgd 1500 0.0001 17 (50,): Macro 0.718572 (0.065142)\n",
      "Testing 2622/2880\n",
      "relu sgd 1500 0.0001 17 (100,): Weighted 0.799628 (0.024277)\n",
      "relu sgd 1500 0.0001 17 (100,): Macro 0.683392 (0.031996)\n",
      "Testing 2623/2880\n",
      "relu sgd 1500 0.0001 17 (150,): Weighted 0.805661 (0.035160)\n",
      "relu sgd 1500 0.0001 17 (150,): Macro 0.670459 (0.031243)\n",
      "Testing 2624/2880\n",
      "relu sgd 1500 0.0001 17 (200,): Weighted 0.845416 (0.063696)\n",
      "relu sgd 1500 0.0001 17 (200,): Macro 0.743249 (0.087582)\n",
      "Testing 2625/2880\n",
      "relu sgd 1500 0.0001 29 (50,): Weighted 0.856659 (0.049825)\n",
      "relu sgd 1500 0.0001 29 (50,): Macro 0.763794 (0.067055)\n",
      "Testing 2626/2880\n",
      "relu sgd 1500 0.0001 29 (100,): Weighted 0.822619 (0.066776)\n",
      "relu sgd 1500 0.0001 29 (100,): Macro 0.709974 (0.089979)\n",
      "Testing 2627/2880\n",
      "relu sgd 1500 0.0001 29 (150,): Weighted 0.808319 (0.074429)\n",
      "relu sgd 1500 0.0001 29 (150,): Macro 0.695980 (0.097687)\n",
      "Testing 2628/2880\n",
      "relu sgd 1500 0.0001 29 (200,): Weighted 0.818502 (0.057897)\n",
      "relu sgd 1500 0.0001 29 (200,): Macro 0.699024 (0.068522)\n",
      "Testing 2629/2880\n",
      "relu sgd 1500 0.0001 42 (50,): Weighted 0.841156 (0.056676)\n",
      "relu sgd 1500 0.0001 42 (50,): Macro 0.744149 (0.071172)\n",
      "Testing 2630/2880\n",
      "relu sgd 1500 0.0001 42 (100,): Weighted 0.781204 (0.034078)\n",
      "relu sgd 1500 0.0001 42 (100,): Macro 0.658422 (0.039361)\n",
      "Testing 2631/2880\n",
      "relu sgd 1500 0.0001 42 (150,): Weighted 0.839492 (0.051433)\n",
      "relu sgd 1500 0.0001 42 (150,): Macro 0.739008 (0.071628)\n",
      "Testing 2632/2880\n",
      "relu sgd 1500 0.0001 42 (200,): Weighted 0.820914 (0.078107)\n",
      "relu sgd 1500 0.0001 42 (200,): Macro 0.715963 (0.100967)\n",
      "Testing 2633/2880\n",
      "relu sgd 1500 0.0001 76 (50,): Weighted 0.825949 (0.062830)\n",
      "relu sgd 1500 0.0001 76 (50,): Macro 0.714329 (0.084276)\n",
      "Testing 2634/2880\n",
      "relu sgd 1500 0.0001 76 (100,): Weighted 0.828901 (0.055184)\n",
      "relu sgd 1500 0.0001 76 (100,): Macro 0.712442 (0.068149)\n",
      "Testing 2635/2880\n",
      "relu sgd 1500 0.0001 76 (150,): Weighted 0.838833 (0.048288)\n",
      "relu sgd 1500 0.0001 76 (150,): Macro 0.735157 (0.058122)\n",
      "Testing 2636/2880\n",
      "relu sgd 1500 0.0001 76 (200,): Weighted 0.817052 (0.049759)\n",
      "relu sgd 1500 0.0001 76 (200,): Macro 0.701303 (0.058531)\n",
      "Testing 2637/2880\n",
      "relu sgd 1500 0.0001 112 (50,): Weighted 0.830203 (0.043747)\n",
      "relu sgd 1500 0.0001 112 (50,): Macro 0.719601 (0.059620)\n",
      "Testing 2638/2880\n",
      "relu sgd 1500 0.0001 112 (100,): Weighted 0.823204 (0.061270)\n",
      "relu sgd 1500 0.0001 112 (100,): Macro 0.712760 (0.083195)\n",
      "Testing 2639/2880\n",
      "relu sgd 1500 0.0001 112 (150,): Weighted 0.826007 (0.060511)\n",
      "relu sgd 1500 0.0001 112 (150,): Macro 0.712848 (0.079158)\n",
      "Testing 2640/2880\n",
      "relu sgd 1500 0.0001 112 (200,): Weighted 0.854934 (0.059000)\n",
      "relu sgd 1500 0.0001 112 (200,): Macro 0.755213 (0.083393)\n",
      "Testing 2641/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relu adam 500 0.1 17 (50,): Weighted 0.827460 (0.066546)\n",
      "relu adam 500 0.1 17 (50,): Macro 0.720861 (0.084342)\n",
      "Testing 2642/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relu adam 500 0.1 17 (100,): Weighted 0.806482 (0.050030)\n",
      "relu adam 500 0.1 17 (100,): Macro 0.685058 (0.054964)\n",
      "Testing 2643/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relu adam 500 0.1 17 (150,): Weighted 0.822740 (0.053571)\n",
      "relu adam 500 0.1 17 (150,): Macro 0.706371 (0.068000)\n",
      "Testing 2644/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relu adam 500 0.1 17 (200,): Weighted 0.812034 (0.064938)\n",
      "relu adam 500 0.1 17 (200,): Macro 0.694510 (0.084361)\n",
      "Testing 2645/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relu adam 500 0.1 29 (50,): Weighted 0.823306 (0.065401)\n",
      "relu adam 500 0.1 29 (50,): Macro 0.712926 (0.082464)\n",
      "Testing 2646/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relu adam 500 0.1 29 (100,): Weighted 0.815291 (0.063363)\n",
      "relu adam 500 0.1 29 (100,): Macro 0.694888 (0.085175)\n",
      "Testing 2647/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relu adam 500 0.1 29 (150,): Weighted 0.811444 (0.062065)\n",
      "relu adam 500 0.1 29 (150,): Macro 0.689360 (0.080882)\n",
      "Testing 2648/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relu adam 500 0.1 29 (200,): Weighted 0.814742 (0.077622)\n",
      "relu adam 500 0.1 29 (200,): Macro 0.704554 (0.101650)\n",
      "Testing 2649/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relu adam 500 0.1 42 (50,): Weighted 0.821914 (0.063259)\n",
      "relu adam 500 0.1 42 (50,): Macro 0.700888 (0.089251)\n",
      "Testing 2650/2880\n",
      "relu adam 500 0.1 42 (100,): Weighted 0.830449 (0.061849)\n",
      "relu adam 500 0.1 42 (100,): Macro 0.726206 (0.077179)\n",
      "Testing 2651/2880\n",
      "relu adam 500 0.1 42 (150,): Weighted 0.823306 (0.064537)\n",
      "relu adam 500 0.1 42 (150,): Macro 0.711586 (0.083600)\n",
      "Testing 2652/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relu adam 500 0.1 42 (200,): Weighted 0.813814 (0.066567)\n",
      "relu adam 500 0.1 42 (200,): Macro 0.701720 (0.083103)\n",
      "Testing 2653/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relu adam 500 0.1 76 (50,): Weighted 0.815606 (0.061947)\n",
      "relu adam 500 0.1 76 (50,): Macro 0.700379 (0.081028)\n",
      "Testing 2654/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relu adam 500 0.1 76 (100,): Weighted 0.829891 (0.056325)\n",
      "relu adam 500 0.1 76 (100,): Macro 0.716281 (0.070939)\n",
      "Testing 2655/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relu adam 500 0.1 76 (150,): Weighted 0.822081 (0.057455)\n",
      "relu adam 500 0.1 76 (150,): Macro 0.707563 (0.073413)\n",
      "Testing 2656/2880\n",
      "relu adam 500 0.1 76 (200,): Weighted 0.816811 (0.058636)\n",
      "relu adam 500 0.1 76 (200,): Macro 0.698691 (0.067821)\n",
      "Testing 2657/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relu adam 500 0.1 112 (50,): Weighted 0.823988 (0.046591)\n",
      "relu adam 500 0.1 112 (50,): Macro 0.695066 (0.064764)\n",
      "Testing 2658/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relu adam 500 0.1 112 (100,): Weighted 0.805734 (0.040304)\n",
      "relu adam 500 0.1 112 (100,): Macro 0.682820 (0.046553)\n",
      "Testing 2659/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relu adam 500 0.1 112 (150,): Weighted 0.797953 (0.065805)\n",
      "relu adam 500 0.1 112 (150,): Macro 0.674989 (0.079820)\n",
      "Testing 2660/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relu adam 500 0.1 112 (200,): Weighted 0.801904 (0.063621)\n",
      "relu adam 500 0.1 112 (200,): Macro 0.683830 (0.076818)\n",
      "Testing 2661/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relu adam 500 0.01 17 (50,): Weighted 0.826785 (0.061625)\n",
      "relu adam 500 0.01 17 (50,): Macro 0.716499 (0.079003)\n",
      "Testing 2662/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relu adam 500 0.01 17 (100,): Weighted 0.812567 (0.050961)\n",
      "relu adam 500 0.01 17 (100,): Macro 0.692071 (0.057690)\n",
      "Testing 2663/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relu adam 500 0.01 17 (150,): Weighted 0.820541 (0.050508)\n",
      "relu adam 500 0.01 17 (150,): Macro 0.707691 (0.058688)\n",
      "Testing 2664/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relu adam 500 0.01 17 (200,): Weighted 0.799399 (0.062659)\n",
      "relu adam 500 0.01 17 (200,): Macro 0.678045 (0.075685)\n",
      "Testing 2665/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relu adam 500 0.01 29 (50,): Weighted 0.822424 (0.060687)\n",
      "relu adam 500 0.01 29 (50,): Macro 0.700785 (0.087424)\n",
      "Testing 2666/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relu adam 500 0.01 29 (100,): Weighted 0.813430 (0.064555)\n",
      "relu adam 500 0.01 29 (100,): Macro 0.694924 (0.085147)\n",
      "Testing 2667/2880\n",
      "relu adam 500 0.01 29 (150,): Weighted 0.829542 (0.052794)\n",
      "relu adam 500 0.01 29 (150,): Macro 0.716771 (0.071150)\n",
      "Testing 2668/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relu adam 500 0.01 29 (200,): Weighted 0.819194 (0.075017)\n",
      "relu adam 500 0.01 29 (200,): Macro 0.708699 (0.097987)\n",
      "Testing 2669/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relu adam 500 0.01 42 (50,): Weighted 0.808863 (0.050346)\n",
      "relu adam 500 0.01 42 (50,): Macro 0.680009 (0.068672)\n",
      "Testing 2670/2880\n",
      "relu adam 500 0.01 42 (100,): Weighted 0.830449 (0.061849)\n",
      "relu adam 500 0.01 42 (100,): Macro 0.726206 (0.077179)\n",
      "Testing 2671/2880\n",
      "relu adam 500 0.01 42 (150,): Weighted 0.818473 (0.063190)\n",
      "relu adam 500 0.01 42 (150,): Macro 0.702911 (0.080414)\n",
      "Testing 2672/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relu adam 500 0.01 42 (200,): Weighted 0.808708 (0.060115)\n",
      "relu adam 500 0.01 42 (200,): Macro 0.695084 (0.072343)\n",
      "Testing 2673/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relu adam 500 0.01 76 (50,): Weighted 0.811560 (0.054851)\n",
      "relu adam 500 0.01 76 (50,): Macro 0.683581 (0.079158)\n",
      "Testing 2674/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relu adam 500 0.01 76 (100,): Weighted 0.824028 (0.055711)\n",
      "relu adam 500 0.01 76 (100,): Macro 0.708181 (0.067576)\n",
      "Testing 2675/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relu adam 500 0.01 76 (150,): Weighted 0.840662 (0.056961)\n",
      "relu adam 500 0.01 76 (150,): Macro 0.733236 (0.075187)\n",
      "Testing 2676/2880\n",
      "relu adam 500 0.01 76 (200,): Weighted 0.814402 (0.064738)\n",
      "relu adam 500 0.01 76 (200,): Macro 0.701957 (0.079263)\n",
      "Testing 2677/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relu adam 500 0.01 112 (50,): Weighted 0.823988 (0.046591)\n",
      "relu adam 500 0.01 112 (50,): Macro 0.695066 (0.064764)\n",
      "Testing 2678/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relu adam 500 0.01 112 (100,): Weighted 0.813996 (0.053883)\n",
      "relu adam 500 0.01 112 (100,): Macro 0.694767 (0.068585)\n",
      "Testing 2679/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relu adam 500 0.01 112 (150,): Weighted 0.797036 (0.072605)\n",
      "relu adam 500 0.01 112 (150,): Macro 0.675581 (0.087885)\n",
      "Testing 2680/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relu adam 500 0.01 112 (200,): Weighted 0.796265 (0.057934)\n",
      "relu adam 500 0.01 112 (200,): Macro 0.668312 (0.064532)\n",
      "Testing 2681/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relu adam 500 0.001 17 (50,): Weighted 0.817432 (0.065290)\n",
      "relu adam 500 0.001 17 (50,): Macro 0.702001 (0.082110)\n",
      "Testing 2682/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relu adam 500 0.001 17 (100,): Weighted 0.819922 (0.052105)\n",
      "relu adam 500 0.001 17 (100,): Macro 0.700814 (0.066584)\n",
      "Testing 2683/2880\n",
      "relu adam 500 0.001 17 (150,): Weighted 0.807803 (0.063865)\n",
      "relu adam 500 0.001 17 (150,): Macro 0.689076 (0.078598)\n",
      "Testing 2684/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relu adam 500 0.001 17 (200,): Weighted 0.800268 (0.059212)\n",
      "relu adam 500 0.001 17 (200,): Macro 0.676866 (0.065859)\n",
      "Testing 2685/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relu adam 500 0.001 29 (50,): Weighted 0.827296 (0.060237)\n",
      "relu adam 500 0.001 29 (50,): Macro 0.707595 (0.087596)\n",
      "Testing 2686/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relu adam 500 0.001 29 (100,): Weighted 0.822136 (0.057524)\n",
      "relu adam 500 0.001 29 (100,): Macro 0.706108 (0.076010)\n",
      "Testing 2687/2880\n",
      "relu adam 500 0.001 29 (150,): Weighted 0.823970 (0.055524)\n",
      "relu adam 500 0.001 29 (150,): Macro 0.706607 (0.074797)\n",
      "Testing 2688/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relu adam 500 0.001 29 (200,): Weighted 0.805250 (0.059692)\n",
      "relu adam 500 0.001 29 (200,): Macro 0.681732 (0.069712)\n",
      "Testing 2689/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relu adam 500 0.001 42 (50,): Weighted 0.808863 (0.050346)\n",
      "relu adam 500 0.001 42 (50,): Macro 0.680009 (0.068672)\n",
      "Testing 2690/2880\n",
      "relu adam 500 0.001 42 (100,): Weighted 0.830449 (0.061849)\n",
      "relu adam 500 0.001 42 (100,): Macro 0.726206 (0.077179)\n",
      "Testing 2691/2880\n",
      "relu adam 500 0.001 42 (150,): Weighted 0.818340 (0.063168)\n",
      "relu adam 500 0.001 42 (150,): Macro 0.704504 (0.080799)\n",
      "Testing 2692/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relu adam 500 0.001 42 (200,): Weighted 0.795304 (0.072505)\n",
      "relu adam 500 0.001 42 (200,): Macro 0.676468 (0.090024)\n",
      "Testing 2693/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relu adam 500 0.001 76 (50,): Weighted 0.796413 (0.057351)\n",
      "relu adam 500 0.001 76 (50,): Macro 0.661573 (0.075047)\n",
      "Testing 2694/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relu adam 500 0.001 76 (100,): Weighted 0.817096 (0.056452)\n",
      "relu adam 500 0.001 76 (100,): Macro 0.697655 (0.068194)\n",
      "Testing 2695/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relu adam 500 0.001 76 (150,): Weighted 0.837300 (0.061906)\n",
      "relu adam 500 0.001 76 (150,): Macro 0.727445 (0.081607)\n",
      "Testing 2696/2880\n",
      "relu adam 500 0.001 76 (200,): Weighted 0.812889 (0.066566)\n",
      "relu adam 500 0.001 76 (200,): Macro 0.694152 (0.079714)\n",
      "Testing 2697/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relu adam 500 0.001 112 (50,): Weighted 0.819086 (0.048409)\n",
      "relu adam 500 0.001 112 (50,): Macro 0.689857 (0.064804)\n",
      "Testing 2698/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relu adam 500 0.001 112 (100,): Weighted 0.811238 (0.047338)\n",
      "relu adam 500 0.001 112 (100,): Macro 0.685278 (0.052265)\n",
      "Testing 2699/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relu adam 500 0.001 112 (150,): Weighted 0.809925 (0.059879)\n",
      "relu adam 500 0.001 112 (150,): Macro 0.692028 (0.071851)\n",
      "Testing 2700/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relu adam 500 0.001 112 (200,): Weighted 0.807004 (0.073394)\n",
      "relu adam 500 0.001 112 (200,): Macro 0.689167 (0.092884)\n",
      "Testing 2701/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relu adam 500 0.0001 17 (50,): Weighted 0.827420 (0.060965)\n",
      "relu adam 500 0.0001 17 (50,): Macro 0.709050 (0.088891)\n",
      "Testing 2702/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relu adam 500 0.0001 17 (100,): Weighted 0.824243 (0.051900)\n",
      "relu adam 500 0.0001 17 (100,): Macro 0.709875 (0.067101)\n",
      "Testing 2703/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relu adam 500 0.0001 17 (150,): Weighted 0.793663 (0.064817)\n",
      "relu adam 500 0.0001 17 (150,): Macro 0.667801 (0.079435)\n",
      "Testing 2704/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relu adam 500 0.0001 17 (200,): Weighted 0.800268 (0.059212)\n",
      "relu adam 500 0.0001 17 (200,): Macro 0.676866 (0.065859)\n",
      "Testing 2705/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relu adam 500 0.0001 29 (50,): Weighted 0.830404 (0.056297)\n",
      "relu adam 500 0.0001 29 (50,): Macro 0.721016 (0.069302)\n",
      "Testing 2706/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relu adam 500 0.0001 29 (100,): Weighted 0.817889 (0.060588)\n",
      "relu adam 500 0.0001 29 (100,): Macro 0.700574 (0.080077)\n",
      "Testing 2707/2880\n",
      "relu adam 500 0.0001 29 (150,): Weighted 0.819925 (0.056819)\n",
      "relu adam 500 0.0001 29 (150,): Macro 0.700821 (0.075587)\n",
      "Testing 2708/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relu adam 500 0.0001 29 (200,): Weighted 0.805675 (0.060299)\n",
      "relu adam 500 0.0001 29 (200,): Macro 0.680997 (0.068786)\n",
      "Testing 2709/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relu adam 500 0.0001 42 (50,): Weighted 0.804702 (0.051911)\n",
      "relu adam 500 0.0001 42 (50,): Macro 0.674286 (0.069230)\n",
      "Testing 2710/2880\n",
      "relu adam 500 0.0001 42 (100,): Weighted 0.830449 (0.061849)\n",
      "relu adam 500 0.0001 42 (100,): Macro 0.726206 (0.077179)\n",
      "Testing 2711/2880\n",
      "relu adam 500 0.0001 42 (150,): Weighted 0.814294 (0.056715)\n",
      "relu adam 500 0.0001 42 (150,): Macro 0.695543 (0.069239)\n",
      "Testing 2712/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relu adam 500 0.0001 42 (200,): Weighted 0.799465 (0.071938)\n",
      "relu adam 500 0.0001 42 (200,): Macro 0.682191 (0.089456)\n",
      "Testing 2713/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relu adam 500 0.0001 76 (50,): Weighted 0.806801 (0.052139)\n",
      "relu adam 500 0.0001 76 (50,): Macro 0.681014 (0.064239)\n",
      "Testing 2714/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relu adam 500 0.0001 76 (100,): Weighted 0.817096 (0.056452)\n",
      "relu adam 500 0.0001 76 (100,): Macro 0.697655 (0.068194)\n",
      "Testing 2715/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relu adam 500 0.0001 76 (150,): Weighted 0.836104 (0.055460)\n",
      "relu adam 500 0.0001 76 (150,): Macro 0.726314 (0.072244)\n",
      "Testing 2716/2880\n",
      "relu adam 500 0.0001 76 (200,): Weighted 0.813153 (0.053042)\n",
      "relu adam 500 0.0001 76 (200,): Macro 0.690481 (0.059317)\n",
      "Testing 2717/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relu adam 500 0.0001 112 (50,): Weighted 0.814733 (0.053886)\n",
      "relu adam 500 0.0001 112 (50,): Macro 0.686558 (0.069905)\n",
      "Testing 2718/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relu adam 500 0.0001 112 (100,): Weighted 0.806076 (0.044915)\n",
      "relu adam 500 0.0001 112 (100,): Macro 0.676043 (0.063916)\n",
      "Testing 2719/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relu adam 500 0.0001 112 (150,): Weighted 0.810636 (0.062148)\n",
      "relu adam 500 0.0001 112 (150,): Macro 0.693115 (0.074862)\n",
      "Testing 2720/2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relu adam 500 0.0001 112 (200,): Weighted 0.797798 (0.072357)\n",
      "relu adam 500 0.0001 112 (200,): Macro 0.678896 (0.091160)\n",
      "Testing 2721/2880\n",
      "relu adam 1000 0.1 17 (50,): Weighted 0.818615 (0.062545)\n",
      "relu adam 1000 0.1 17 (50,): Macro 0.707923 (0.076711)\n",
      "Testing 2722/2880\n",
      "relu adam 1000 0.1 17 (100,): Weighted 0.816041 (0.053249)\n",
      "relu adam 1000 0.1 17 (100,): Macro 0.698682 (0.061549)\n",
      "Testing 2723/2880\n",
      "relu adam 1000 0.1 17 (150,): Weighted 0.822740 (0.053571)\n",
      "relu adam 1000 0.1 17 (150,): Macro 0.706371 (0.068000)\n",
      "Testing 2724/2880\n",
      "relu adam 1000 0.1 17 (200,): Weighted 0.812034 (0.064938)\n",
      "relu adam 1000 0.1 17 (200,): Macro 0.694510 (0.084361)\n",
      "Testing 2725/2880\n",
      "relu adam 1000 0.1 29 (50,): Weighted 0.823306 (0.065401)\n",
      "relu adam 1000 0.1 29 (50,): Macro 0.712926 (0.082464)\n",
      "Testing 2726/2880\n",
      "relu adam 1000 0.1 29 (100,): Weighted 0.809890 (0.067193)\n",
      "relu adam 1000 0.1 29 (100,): Macro 0.690221 (0.089091)\n",
      "Testing 2727/2880\n",
      "relu adam 1000 0.1 29 (150,): Weighted 0.809584 (0.063169)\n",
      "relu adam 1000 0.1 29 (150,): Macro 0.689396 (0.080855)\n",
      "Testing 2728/2880\n",
      "relu adam 1000 0.1 29 (200,): Weighted 0.814742 (0.077622)\n",
      "relu adam 1000 0.1 29 (200,): Macro 0.704554 (0.101650)\n",
      "Testing 2729/2880\n",
      "relu adam 1000 0.1 42 (50,): Weighted 0.818833 (0.059652)\n",
      "relu adam 1000 0.1 42 (50,): Macro 0.704439 (0.075862)\n",
      "Testing 2730/2880\n",
      "relu adam 1000 0.1 42 (100,): Weighted 0.830449 (0.061849)\n",
      "relu adam 1000 0.1 42 (100,): Macro 0.726206 (0.077179)\n",
      "Testing 2731/2880\n",
      "relu adam 1000 0.1 42 (150,): Weighted 0.823306 (0.064537)\n",
      "relu adam 1000 0.1 42 (150,): Macro 0.711586 (0.083600)\n",
      "Testing 2732/2880\n",
      "relu adam 1000 0.1 42 (200,): Weighted 0.808800 (0.068726)\n",
      "relu adam 1000 0.1 42 (200,): Macro 0.694926 (0.085757)\n",
      "Testing 2733/2880\n",
      "relu adam 1000 0.1 76 (50,): Weighted 0.801049 (0.073301)\n",
      "relu adam 1000 0.1 76 (50,): Macro 0.682227 (0.091458)\n",
      "Testing 2734/2880\n",
      "relu adam 1000 0.1 76 (100,): Weighted 0.829891 (0.056325)\n",
      "relu adam 1000 0.1 76 (100,): Macro 0.716281 (0.070939)\n",
      "Testing 2735/2880\n",
      "relu adam 1000 0.1 76 (150,): Weighted 0.822081 (0.057455)\n",
      "relu adam 1000 0.1 76 (150,): Macro 0.707563 (0.073413)\n",
      "Testing 2736/2880\n",
      "relu adam 1000 0.1 76 (200,): Weighted 0.816811 (0.058636)\n",
      "relu adam 1000 0.1 76 (200,): Macro 0.698691 (0.067821)\n",
      "Testing 2737/2880\n",
      "relu adam 1000 0.1 112 (50,): Weighted 0.826061 (0.061862)\n",
      "relu adam 1000 0.1 112 (50,): Macro 0.706830 (0.088708)\n",
      "Testing 2738/2880\n",
      "relu adam 1000 0.1 112 (100,): Weighted 0.800321 (0.043504)\n",
      "relu adam 1000 0.1 112 (100,): Macro 0.675738 (0.050671)\n",
      "Testing 2739/2880\n",
      "relu adam 1000 0.1 112 (150,): Weighted 0.796926 (0.066767)\n",
      "relu adam 1000 0.1 112 (150,): Macro 0.674744 (0.080062)\n",
      "Testing 2740/2880\n",
      "relu adam 1000 0.1 112 (200,): Weighted 0.810847 (0.062211)\n",
      "relu adam 1000 0.1 112 (200,): Macro 0.696314 (0.076205)\n",
      "Testing 2741/2880\n",
      "relu adam 1000 0.01 17 (50,): Weighted 0.815562 (0.062058)\n",
      "relu adam 1000 0.01 17 (50,): Macro 0.699363 (0.079081)\n",
      "Testing 2742/2880\n",
      "relu adam 1000 0.01 17 (100,): Weighted 0.812912 (0.051072)\n",
      "relu adam 1000 0.01 17 (100,): Macro 0.693677 (0.058704)\n",
      "Testing 2743/2880\n",
      "relu adam 1000 0.01 17 (150,): Weighted 0.820541 (0.050508)\n",
      "relu adam 1000 0.01 17 (150,): Macro 0.707691 (0.058688)\n",
      "Testing 2744/2880\n",
      "relu adam 1000 0.01 17 (200,): Weighted 0.795238 (0.063304)\n",
      "relu adam 1000 0.01 17 (200,): Macro 0.672322 (0.076044)\n",
      "Testing 2745/2880\n",
      "relu adam 1000 0.01 29 (50,): Weighted 0.827641 (0.054738)\n",
      "relu adam 1000 0.01 29 (50,): Macro 0.712885 (0.071917)\n",
      "Testing 2746/2880\n",
      "relu adam 1000 0.01 29 (100,): Weighted 0.809890 (0.067193)\n",
      "relu adam 1000 0.01 29 (100,): Macro 0.690221 (0.089091)\n",
      "Testing 2747/2880\n",
      "relu adam 1000 0.01 29 (150,): Weighted 0.829542 (0.052794)\n",
      "relu adam 1000 0.01 29 (150,): Macro 0.716771 (0.071150)\n",
      "Testing 2748/2880\n",
      "relu adam 1000 0.01 29 (200,): Weighted 0.819194 (0.075017)\n",
      "relu adam 1000 0.01 29 (200,): Macro 0.708699 (0.097987)\n",
      "Testing 2749/2880\n",
      "relu adam 1000 0.01 42 (50,): Weighted 0.814850 (0.046991)\n",
      "relu adam 1000 0.01 42 (50,): Macro 0.693680 (0.054734)\n",
      "Testing 2750/2880\n",
      "relu adam 1000 0.01 42 (100,): Weighted 0.830449 (0.061849)\n",
      "relu adam 1000 0.01 42 (100,): Macro 0.726206 (0.077179)\n",
      "Testing 2751/2880\n",
      "relu adam 1000 0.01 42 (150,): Weighted 0.818473 (0.063190)\n",
      "relu adam 1000 0.01 42 (150,): Macro 0.702911 (0.080414)\n",
      "Testing 2752/2880\n",
      "relu adam 1000 0.01 42 (200,): Weighted 0.814429 (0.059308)\n",
      "relu adam 1000 0.01 42 (200,): Macro 0.701077 (0.071725)\n",
      "Testing 2753/2880\n",
      "relu adam 1000 0.01 76 (50,): Weighted 0.787973 (0.064078)\n",
      "relu adam 1000 0.01 76 (50,): Macro 0.659463 (0.073577)\n",
      "Testing 2754/2880\n",
      "relu adam 1000 0.01 76 (100,): Weighted 0.815682 (0.059788)\n",
      "relu adam 1000 0.01 76 (100,): Macro 0.696109 (0.070779)\n",
      "Testing 2755/2880\n",
      "relu adam 1000 0.01 76 (150,): Weighted 0.822979 (0.060017)\n",
      "relu adam 1000 0.01 76 (150,): Macro 0.707835 (0.078080)\n",
      "Testing 2756/2880\n",
      "relu adam 1000 0.01 76 (200,): Weighted 0.814402 (0.064738)\n",
      "relu adam 1000 0.01 76 (200,): Macro 0.701957 (0.079263)\n",
      "Testing 2757/2880\n",
      "relu adam 1000 0.01 112 (50,): Weighted 0.826061 (0.061862)\n",
      "relu adam 1000 0.01 112 (50,): Macro 0.706830 (0.088708)\n",
      "Testing 2758/2880\n",
      "relu adam 1000 0.01 112 (100,): Weighted 0.808583 (0.057105)\n",
      "relu adam 1000 0.01 112 (100,): Macro 0.687684 (0.072619)\n",
      "Testing 2759/2880\n",
      "relu adam 1000 0.01 112 (150,): Weighted 0.797036 (0.072605)\n",
      "relu adam 1000 0.01 112 (150,): Macro 0.675581 (0.087885)\n",
      "Testing 2760/2880\n",
      "relu adam 1000 0.01 112 (200,): Weighted 0.795897 (0.049784)\n",
      "relu adam 1000 0.01 112 (200,): Macro 0.669601 (0.052651)\n",
      "Testing 2761/2880\n",
      "relu adam 1000 0.001 17 (50,): Weighted 0.821069 (0.052434)\n",
      "relu adam 1000 0.001 17 (50,): Macro 0.702113 (0.068316)\n",
      "Testing 2762/2880\n",
      "relu adam 1000 0.001 17 (100,): Weighted 0.819922 (0.052105)\n",
      "relu adam 1000 0.001 17 (100,): Macro 0.700814 (0.066584)\n",
      "Testing 2763/2880\n",
      "relu adam 1000 0.001 17 (150,): Weighted 0.807803 (0.063865)\n",
      "relu adam 1000 0.001 17 (150,): Macro 0.689076 (0.078598)\n",
      "Testing 2764/2880\n",
      "relu adam 1000 0.001 17 (200,): Weighted 0.800268 (0.059212)\n",
      "relu adam 1000 0.001 17 (200,): Macro 0.676866 (0.065859)\n",
      "Testing 2765/2880\n",
      "relu adam 1000 0.001 29 (50,): Weighted 0.831417 (0.055067)\n",
      "relu adam 1000 0.001 29 (50,): Macro 0.719500 (0.071224)\n",
      "Testing 2766/2880\n",
      "relu adam 1000 0.001 29 (100,): Weighted 0.818595 (0.060977)\n",
      "relu adam 1000 0.001 29 (100,): Macro 0.701405 (0.081055)\n",
      "Testing 2767/2880\n",
      "relu adam 1000 0.001 29 (150,): Weighted 0.823970 (0.055524)\n",
      "relu adam 1000 0.001 29 (150,): Macro 0.706607 (0.074797)\n",
      "Testing 2768/2880\n",
      "relu adam 1000 0.001 29 (200,): Weighted 0.805250 (0.059692)\n",
      "relu adam 1000 0.001 29 (200,): Macro 0.681732 (0.069712)\n",
      "Testing 2769/2880\n",
      "relu adam 1000 0.001 42 (50,): Weighted 0.810057 (0.046142)\n",
      "relu adam 1000 0.001 42 (50,): Macro 0.686956 (0.053114)\n",
      "Testing 2770/2880\n",
      "relu adam 1000 0.001 42 (100,): Weighted 0.830449 (0.061849)\n",
      "relu adam 1000 0.001 42 (100,): Macro 0.726206 (0.077179)\n",
      "Testing 2771/2880\n",
      "relu adam 1000 0.001 42 (150,): Weighted 0.818340 (0.063168)\n",
      "relu adam 1000 0.001 42 (150,): Macro 0.704504 (0.080799)\n",
      "Testing 2772/2880\n",
      "relu adam 1000 0.001 42 (200,): Weighted 0.804829 (0.068445)\n",
      "relu adam 1000 0.001 42 (200,): Macro 0.686772 (0.085678)\n",
      "Testing 2773/2880\n",
      "relu adam 1000 0.001 76 (50,): Weighted 0.795728 (0.057918)\n",
      "relu adam 1000 0.001 76 (50,): Macro 0.662781 (0.069994)\n",
      "Testing 2774/2880\n",
      "relu adam 1000 0.001 76 (100,): Weighted 0.817096 (0.056452)\n",
      "relu adam 1000 0.001 76 (100,): Macro 0.697655 (0.068194)\n",
      "Testing 2775/2880\n",
      "relu adam 1000 0.001 76 (150,): Weighted 0.818359 (0.061566)\n",
      "relu adam 1000 0.001 76 (150,): Macro 0.700311 (0.080579)\n",
      "Testing 2776/2880\n",
      "relu adam 1000 0.001 76 (200,): Weighted 0.812889 (0.066566)\n",
      "relu adam 1000 0.001 76 (200,): Macro 0.694152 (0.079714)\n",
      "Testing 2777/2880\n",
      "relu adam 1000 0.001 112 (50,): Weighted 0.821159 (0.063403)\n",
      "relu adam 1000 0.001 112 (50,): Macro 0.701622 (0.089425)\n",
      "Testing 2778/2880\n",
      "relu adam 1000 0.001 112 (100,): Weighted 0.805825 (0.050682)\n",
      "relu adam 1000 0.001 112 (100,): Macro 0.678195 (0.056275)\n",
      "Testing 2779/2880\n",
      "relu adam 1000 0.001 112 (150,): Weighted 0.813448 (0.055527)\n",
      "relu adam 1000 0.001 112 (150,): Macro 0.696837 (0.065601)\n",
      "Testing 2780/2880\n",
      "relu adam 1000 0.001 112 (200,): Weighted 0.811429 (0.066688)\n",
      "relu adam 1000 0.001 112 (200,): Macro 0.697181 (0.084629)\n",
      "Testing 2781/2880\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relu adam 1000 0.0001 17 (50,): Weighted 0.811244 (0.066493)\n",
      "relu adam 1000 0.0001 17 (50,): Macro 0.693828 (0.083948)\n",
      "Testing 2782/2880\n",
      "relu adam 1000 0.0001 17 (100,): Weighted 0.798922 (0.065560)\n",
      "relu adam 1000 0.0001 17 (100,): Macro 0.672909 (0.081744)\n",
      "Testing 2783/2880\n",
      "relu adam 1000 0.0001 17 (150,): Weighted 0.791812 (0.066388)\n",
      "relu adam 1000 0.0001 17 (150,): Macro 0.667843 (0.079397)\n",
      "Testing 2784/2880\n",
      "relu adam 1000 0.0001 17 (200,): Weighted 0.791922 (0.059835)\n",
      "relu adam 1000 0.0001 17 (200,): Macro 0.664793 (0.063438)\n",
      "Testing 2785/2880\n",
      "relu adam 1000 0.0001 29 (50,): Weighted 0.826962 (0.060673)\n",
      "relu adam 1000 0.0001 29 (50,): Macro 0.716142 (0.075632)\n",
      "Testing 2786/2880\n",
      "relu adam 1000 0.0001 29 (100,): Weighted 0.808090 (0.068821)\n",
      "relu adam 1000 0.0001 29 (100,): Macro 0.690325 (0.089000)\n",
      "Testing 2787/2880\n",
      "relu adam 1000 0.0001 29 (150,): Weighted 0.819925 (0.056819)\n",
      "relu adam 1000 0.0001 29 (150,): Macro 0.700821 (0.075587)\n",
      "Testing 2788/2880\n",
      "relu adam 1000 0.0001 29 (200,): Weighted 0.805675 (0.060299)\n",
      "relu adam 1000 0.0001 29 (200,): Macro 0.680997 (0.068786)\n",
      "Testing 2789/2880\n",
      "relu adam 1000 0.0001 42 (50,): Weighted 0.818929 (0.053172)\n",
      "relu adam 1000 0.0001 42 (50,): Macro 0.700467 (0.064663)\n",
      "Testing 2790/2880\n",
      "relu adam 1000 0.0001 42 (100,): Weighted 0.830449 (0.061849)\n",
      "relu adam 1000 0.0001 42 (100,): Macro 0.726206 (0.077179)\n",
      "Testing 2791/2880\n",
      "relu adam 1000 0.0001 42 (150,): Weighted 0.814294 (0.056715)\n",
      "relu adam 1000 0.0001 42 (150,): Macro 0.695543 (0.069239)\n",
      "Testing 2792/2880\n",
      "relu adam 1000 0.0001 42 (200,): Weighted 0.808800 (0.068726)\n",
      "relu adam 1000 0.0001 42 (200,): Macro 0.694926 (0.085757)\n",
      "Testing 2793/2880\n",
      "relu adam 1000 0.0001 76 (50,): Weighted 0.804255 (0.054273)\n",
      "relu adam 1000 0.0001 76 (50,): Macro 0.680579 (0.064389)\n",
      "Testing 2794/2880\n",
      "relu adam 1000 0.0001 76 (100,): Weighted 0.817096 (0.056452)\n",
      "relu adam 1000 0.0001 76 (100,): Macro 0.697655 (0.068194)\n",
      "Testing 2795/2880\n",
      "relu adam 1000 0.0001 76 (150,): Weighted 0.826545 (0.055919)\n",
      "relu adam 1000 0.0001 76 (150,): Macro 0.712690 (0.072145)\n",
      "Testing 2796/2880\n",
      "relu adam 1000 0.0001 76 (200,): Weighted 0.813153 (0.053042)\n",
      "relu adam 1000 0.0001 76 (200,): Macro 0.690481 (0.059317)\n",
      "Testing 2797/2880\n",
      "relu adam 1000 0.0001 112 (50,): Weighted 0.816791 (0.068939)\n",
      "relu adam 1000 0.0001 112 (50,): Macro 0.698357 (0.094018)\n",
      "Testing 2798/2880\n",
      "relu adam 1000 0.0001 112 (100,): Weighted 0.806076 (0.044915)\n",
      "relu adam 1000 0.0001 112 (100,): Macro 0.676043 (0.063916)\n",
      "Testing 2799/2880\n",
      "relu adam 1000 0.0001 112 (150,): Weighted 0.815048 (0.056912)\n",
      "relu adam 1000 0.0001 112 (150,): Macro 0.696426 (0.070644)\n",
      "Testing 2800/2880\n",
      "relu adam 1000 0.0001 112 (200,): Weighted 0.806636 (0.067207)\n",
      "relu adam 1000 0.0001 112 (200,): Macro 0.690456 (0.084743)\n",
      "Testing 2801/2880\n",
      "relu adam 1500 0.1 17 (50,): Weighted 0.818615 (0.062545)\n",
      "relu adam 1500 0.1 17 (50,): Macro 0.707923 (0.076711)\n",
      "Testing 2802/2880\n",
      "relu adam 1500 0.1 17 (100,): Weighted 0.816041 (0.053249)\n",
      "relu adam 1500 0.1 17 (100,): Macro 0.698682 (0.061549)\n",
      "Testing 2803/2880\n",
      "relu adam 1500 0.1 17 (150,): Weighted 0.822740 (0.053571)\n",
      "relu adam 1500 0.1 17 (150,): Macro 0.706371 (0.068000)\n",
      "Testing 2804/2880\n",
      "relu adam 1500 0.1 17 (200,): Weighted 0.812034 (0.064938)\n",
      "relu adam 1500 0.1 17 (200,): Macro 0.694510 (0.084361)\n",
      "Testing 2805/2880\n",
      "relu adam 1500 0.1 29 (50,): Weighted 0.823306 (0.065401)\n",
      "relu adam 1500 0.1 29 (50,): Macro 0.712926 (0.082464)\n",
      "Testing 2806/2880\n",
      "relu adam 1500 0.1 29 (100,): Weighted 0.809890 (0.067193)\n",
      "relu adam 1500 0.1 29 (100,): Macro 0.690221 (0.089091)\n",
      "Testing 2807/2880\n",
      "relu adam 1500 0.1 29 (150,): Weighted 0.809584 (0.063169)\n",
      "relu adam 1500 0.1 29 (150,): Macro 0.689396 (0.080855)\n",
      "Testing 2808/2880\n",
      "relu adam 1500 0.1 29 (200,): Weighted 0.814742 (0.077622)\n",
      "relu adam 1500 0.1 29 (200,): Macro 0.704554 (0.101650)\n",
      "Testing 2809/2880\n",
      "relu adam 1500 0.1 42 (50,): Weighted 0.818833 (0.059652)\n",
      "relu adam 1500 0.1 42 (50,): Macro 0.704439 (0.075862)\n",
      "Testing 2810/2880\n",
      "relu adam 1500 0.1 42 (100,): Weighted 0.830449 (0.061849)\n",
      "relu adam 1500 0.1 42 (100,): Macro 0.726206 (0.077179)\n",
      "Testing 2811/2880\n",
      "relu adam 1500 0.1 42 (150,): Weighted 0.823306 (0.064537)\n",
      "relu adam 1500 0.1 42 (150,): Macro 0.711586 (0.083600)\n",
      "Testing 2812/2880\n",
      "relu adam 1500 0.1 42 (200,): Weighted 0.808800 (0.068726)\n",
      "relu adam 1500 0.1 42 (200,): Macro 0.694926 (0.085757)\n",
      "Testing 2813/2880\n",
      "relu adam 1500 0.1 76 (50,): Weighted 0.801049 (0.073301)\n",
      "relu adam 1500 0.1 76 (50,): Macro 0.682227 (0.091458)\n",
      "Testing 2814/2880\n",
      "relu adam 1500 0.1 76 (100,): Weighted 0.829891 (0.056325)\n",
      "relu adam 1500 0.1 76 (100,): Macro 0.716281 (0.070939)\n",
      "Testing 2815/2880\n",
      "relu adam 1500 0.1 76 (150,): Weighted 0.822081 (0.057455)\n",
      "relu adam 1500 0.1 76 (150,): Macro 0.707563 (0.073413)\n",
      "Testing 2816/2880\n",
      "relu adam 1500 0.1 76 (200,): Weighted 0.816811 (0.058636)\n",
      "relu adam 1500 0.1 76 (200,): Macro 0.698691 (0.067821)\n",
      "Testing 2817/2880\n",
      "relu adam 1500 0.1 112 (50,): Weighted 0.826061 (0.061862)\n",
      "relu adam 1500 0.1 112 (50,): Macro 0.706830 (0.088708)\n",
      "Testing 2818/2880\n",
      "relu adam 1500 0.1 112 (100,): Weighted 0.800321 (0.043504)\n",
      "relu adam 1500 0.1 112 (100,): Macro 0.675738 (0.050671)\n",
      "Testing 2819/2880\n",
      "relu adam 1500 0.1 112 (150,): Weighted 0.796926 (0.066767)\n",
      "relu adam 1500 0.1 112 (150,): Macro 0.674744 (0.080062)\n",
      "Testing 2820/2880\n",
      "relu adam 1500 0.1 112 (200,): Weighted 0.810847 (0.062211)\n",
      "relu adam 1500 0.1 112 (200,): Macro 0.696314 (0.076205)\n",
      "Testing 2821/2880\n",
      "relu adam 1500 0.01 17 (50,): Weighted 0.815562 (0.062058)\n",
      "relu adam 1500 0.01 17 (50,): Macro 0.699363 (0.079081)\n",
      "Testing 2822/2880\n",
      "relu adam 1500 0.01 17 (100,): Weighted 0.812912 (0.051072)\n",
      "relu adam 1500 0.01 17 (100,): Macro 0.693677 (0.058704)\n",
      "Testing 2823/2880\n",
      "relu adam 1500 0.01 17 (150,): Weighted 0.820541 (0.050508)\n",
      "relu adam 1500 0.01 17 (150,): Macro 0.707691 (0.058688)\n",
      "Testing 2824/2880\n",
      "relu adam 1500 0.01 17 (200,): Weighted 0.795238 (0.063304)\n",
      "relu adam 1500 0.01 17 (200,): Macro 0.672322 (0.076044)\n",
      "Testing 2825/2880\n",
      "relu adam 1500 0.01 29 (50,): Weighted 0.827641 (0.054738)\n",
      "relu adam 1500 0.01 29 (50,): Macro 0.712885 (0.071917)\n",
      "Testing 2826/2880\n",
      "relu adam 1500 0.01 29 (100,): Weighted 0.809890 (0.067193)\n",
      "relu adam 1500 0.01 29 (100,): Macro 0.690221 (0.089091)\n",
      "Testing 2827/2880\n",
      "relu adam 1500 0.01 29 (150,): Weighted 0.829542 (0.052794)\n",
      "relu adam 1500 0.01 29 (150,): Macro 0.716771 (0.071150)\n",
      "Testing 2828/2880\n",
      "relu adam 1500 0.01 29 (200,): Weighted 0.819194 (0.075017)\n",
      "relu adam 1500 0.01 29 (200,): Macro 0.708699 (0.097987)\n",
      "Testing 2829/2880\n",
      "relu adam 1500 0.01 42 (50,): Weighted 0.814850 (0.046991)\n",
      "relu adam 1500 0.01 42 (50,): Macro 0.693680 (0.054734)\n",
      "Testing 2830/2880\n",
      "relu adam 1500 0.01 42 (100,): Weighted 0.830449 (0.061849)\n",
      "relu adam 1500 0.01 42 (100,): Macro 0.726206 (0.077179)\n",
      "Testing 2831/2880\n",
      "relu adam 1500 0.01 42 (150,): Weighted 0.818473 (0.063190)\n",
      "relu adam 1500 0.01 42 (150,): Macro 0.702911 (0.080414)\n",
      "Testing 2832/2880\n",
      "relu adam 1500 0.01 42 (200,): Weighted 0.814429 (0.059308)\n",
      "relu adam 1500 0.01 42 (200,): Macro 0.701077 (0.071725)\n",
      "Testing 2833/2880\n",
      "relu adam 1500 0.01 76 (50,): Weighted 0.787973 (0.064078)\n",
      "relu adam 1500 0.01 76 (50,): Macro 0.659463 (0.073577)\n",
      "Testing 2834/2880\n",
      "relu adam 1500 0.01 76 (100,): Weighted 0.815682 (0.059788)\n",
      "relu adam 1500 0.01 76 (100,): Macro 0.696109 (0.070779)\n",
      "Testing 2835/2880\n",
      "relu adam 1500 0.01 76 (150,): Weighted 0.822979 (0.060017)\n",
      "relu adam 1500 0.01 76 (150,): Macro 0.707835 (0.078080)\n",
      "Testing 2836/2880\n",
      "relu adam 1500 0.01 76 (200,): Weighted 0.814402 (0.064738)\n",
      "relu adam 1500 0.01 76 (200,): Macro 0.701957 (0.079263)\n",
      "Testing 2837/2880\n",
      "relu adam 1500 0.01 112 (50,): Weighted 0.826061 (0.061862)\n",
      "relu adam 1500 0.01 112 (50,): Macro 0.706830 (0.088708)\n",
      "Testing 2838/2880\n",
      "relu adam 1500 0.01 112 (100,): Weighted 0.808583 (0.057105)\n",
      "relu adam 1500 0.01 112 (100,): Macro 0.687684 (0.072619)\n",
      "Testing 2839/2880\n",
      "relu adam 1500 0.01 112 (150,): Weighted 0.797036 (0.072605)\n",
      "relu adam 1500 0.01 112 (150,): Macro 0.675581 (0.087885)\n",
      "Testing 2840/2880\n",
      "relu adam 1500 0.01 112 (200,): Weighted 0.795897 (0.049784)\n",
      "relu adam 1500 0.01 112 (200,): Macro 0.669601 (0.052651)\n",
      "Testing 2841/2880\n",
      "relu adam 1500 0.001 17 (50,): Weighted 0.821069 (0.052434)\n",
      "relu adam 1500 0.001 17 (50,): Macro 0.702113 (0.068316)\n",
      "Testing 2842/2880\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relu adam 1500 0.001 17 (100,): Weighted 0.819922 (0.052105)\n",
      "relu adam 1500 0.001 17 (100,): Macro 0.700814 (0.066584)\n",
      "Testing 2843/2880\n",
      "relu adam 1500 0.001 17 (150,): Weighted 0.807803 (0.063865)\n",
      "relu adam 1500 0.001 17 (150,): Macro 0.689076 (0.078598)\n",
      "Testing 2844/2880\n",
      "relu adam 1500 0.001 17 (200,): Weighted 0.800268 (0.059212)\n",
      "relu adam 1500 0.001 17 (200,): Macro 0.676866 (0.065859)\n",
      "Testing 2845/2880\n",
      "relu adam 1500 0.001 29 (50,): Weighted 0.831417 (0.055067)\n",
      "relu adam 1500 0.001 29 (50,): Macro 0.719500 (0.071224)\n",
      "Testing 2846/2880\n",
      "relu adam 1500 0.001 29 (100,): Weighted 0.818595 (0.060977)\n",
      "relu adam 1500 0.001 29 (100,): Macro 0.701405 (0.081055)\n",
      "Testing 2847/2880\n",
      "relu adam 1500 0.001 29 (150,): Weighted 0.823970 (0.055524)\n",
      "relu adam 1500 0.001 29 (150,): Macro 0.706607 (0.074797)\n",
      "Testing 2848/2880\n",
      "relu adam 1500 0.001 29 (200,): Weighted 0.805250 (0.059692)\n",
      "relu adam 1500 0.001 29 (200,): Macro 0.681732 (0.069712)\n",
      "Testing 2849/2880\n",
      "relu adam 1500 0.001 42 (50,): Weighted 0.810057 (0.046142)\n",
      "relu adam 1500 0.001 42 (50,): Macro 0.686956 (0.053114)\n",
      "Testing 2850/2880\n",
      "relu adam 1500 0.001 42 (100,): Weighted 0.830449 (0.061849)\n",
      "relu adam 1500 0.001 42 (100,): Macro 0.726206 (0.077179)\n",
      "Testing 2851/2880\n",
      "relu adam 1500 0.001 42 (150,): Weighted 0.818340 (0.063168)\n",
      "relu adam 1500 0.001 42 (150,): Macro 0.704504 (0.080799)\n",
      "Testing 2852/2880\n",
      "relu adam 1500 0.001 42 (200,): Weighted 0.804829 (0.068445)\n",
      "relu adam 1500 0.001 42 (200,): Macro 0.686772 (0.085678)\n",
      "Testing 2853/2880\n",
      "relu adam 1500 0.001 76 (50,): Weighted 0.795728 (0.057918)\n",
      "relu adam 1500 0.001 76 (50,): Macro 0.662781 (0.069994)\n",
      "Testing 2854/2880\n",
      "relu adam 1500 0.001 76 (100,): Weighted 0.817096 (0.056452)\n",
      "relu adam 1500 0.001 76 (100,): Macro 0.697655 (0.068194)\n",
      "Testing 2855/2880\n",
      "relu adam 1500 0.001 76 (150,): Weighted 0.818359 (0.061566)\n",
      "relu adam 1500 0.001 76 (150,): Macro 0.700311 (0.080579)\n",
      "Testing 2856/2880\n",
      "relu adam 1500 0.001 76 (200,): Weighted 0.812889 (0.066566)\n",
      "relu adam 1500 0.001 76 (200,): Macro 0.694152 (0.079714)\n",
      "Testing 2857/2880\n",
      "relu adam 1500 0.001 112 (50,): Weighted 0.821159 (0.063403)\n",
      "relu adam 1500 0.001 112 (50,): Macro 0.701622 (0.089425)\n",
      "Testing 2858/2880\n",
      "relu adam 1500 0.001 112 (100,): Weighted 0.805825 (0.050682)\n",
      "relu adam 1500 0.001 112 (100,): Macro 0.678195 (0.056275)\n",
      "Testing 2859/2880\n",
      "relu adam 1500 0.001 112 (150,): Weighted 0.813448 (0.055527)\n",
      "relu adam 1500 0.001 112 (150,): Macro 0.696837 (0.065601)\n",
      "Testing 2860/2880\n",
      "relu adam 1500 0.001 112 (200,): Weighted 0.811429 (0.066688)\n",
      "relu adam 1500 0.001 112 (200,): Macro 0.697181 (0.084629)\n",
      "Testing 2861/2880\n",
      "relu adam 1500 0.0001 17 (50,): Weighted 0.811244 (0.066493)\n",
      "relu adam 1500 0.0001 17 (50,): Macro 0.693828 (0.083948)\n",
      "Testing 2862/2880\n",
      "relu adam 1500 0.0001 17 (100,): Weighted 0.798922 (0.065560)\n",
      "relu adam 1500 0.0001 17 (100,): Macro 0.672909 (0.081744)\n",
      "Testing 2863/2880\n",
      "relu adam 1500 0.0001 17 (150,): Weighted 0.791812 (0.066388)\n",
      "relu adam 1500 0.0001 17 (150,): Macro 0.667843 (0.079397)\n",
      "Testing 2864/2880\n",
      "relu adam 1500 0.0001 17 (200,): Weighted 0.791922 (0.059835)\n",
      "relu adam 1500 0.0001 17 (200,): Macro 0.664793 (0.063438)\n",
      "Testing 2865/2880\n",
      "relu adam 1500 0.0001 29 (50,): Weighted 0.826962 (0.060673)\n",
      "relu adam 1500 0.0001 29 (50,): Macro 0.716142 (0.075632)\n",
      "Testing 2866/2880\n",
      "relu adam 1500 0.0001 29 (100,): Weighted 0.808090 (0.068821)\n",
      "relu adam 1500 0.0001 29 (100,): Macro 0.690325 (0.089000)\n",
      "Testing 2867/2880\n",
      "relu adam 1500 0.0001 29 (150,): Weighted 0.819925 (0.056819)\n",
      "relu adam 1500 0.0001 29 (150,): Macro 0.700821 (0.075587)\n",
      "Testing 2868/2880\n",
      "relu adam 1500 0.0001 29 (200,): Weighted 0.805675 (0.060299)\n",
      "relu adam 1500 0.0001 29 (200,): Macro 0.680997 (0.068786)\n",
      "Testing 2869/2880\n",
      "relu adam 1500 0.0001 42 (50,): Weighted 0.818929 (0.053172)\n",
      "relu adam 1500 0.0001 42 (50,): Macro 0.700467 (0.064663)\n",
      "Testing 2870/2880\n",
      "relu adam 1500 0.0001 42 (100,): Weighted 0.830449 (0.061849)\n",
      "relu adam 1500 0.0001 42 (100,): Macro 0.726206 (0.077179)\n",
      "Testing 2871/2880\n",
      "relu adam 1500 0.0001 42 (150,): Weighted 0.814294 (0.056715)\n",
      "relu adam 1500 0.0001 42 (150,): Macro 0.695543 (0.069239)\n",
      "Testing 2872/2880\n",
      "relu adam 1500 0.0001 42 (200,): Weighted 0.808800 (0.068726)\n",
      "relu adam 1500 0.0001 42 (200,): Macro 0.694926 (0.085757)\n",
      "Testing 2873/2880\n",
      "relu adam 1500 0.0001 76 (50,): Weighted 0.804255 (0.054273)\n",
      "relu adam 1500 0.0001 76 (50,): Macro 0.680579 (0.064389)\n",
      "Testing 2874/2880\n",
      "relu adam 1500 0.0001 76 (100,): Weighted 0.817096 (0.056452)\n",
      "relu adam 1500 0.0001 76 (100,): Macro 0.697655 (0.068194)\n",
      "Testing 2875/2880\n",
      "relu adam 1500 0.0001 76 (150,): Weighted 0.826545 (0.055919)\n",
      "relu adam 1500 0.0001 76 (150,): Macro 0.712690 (0.072145)\n",
      "Testing 2876/2880\n",
      "relu adam 1500 0.0001 76 (200,): Weighted 0.813153 (0.053042)\n",
      "relu adam 1500 0.0001 76 (200,): Macro 0.690481 (0.059317)\n",
      "Testing 2877/2880\n",
      "relu adam 1500 0.0001 112 (50,): Weighted 0.816791 (0.068939)\n",
      "relu adam 1500 0.0001 112 (50,): Macro 0.698357 (0.094018)\n",
      "Testing 2878/2880\n",
      "relu adam 1500 0.0001 112 (100,): Weighted 0.806076 (0.044915)\n",
      "relu adam 1500 0.0001 112 (100,): Macro 0.676043 (0.063916)\n",
      "Testing 2879/2880\n",
      "relu adam 1500 0.0001 112 (150,): Weighted 0.815048 (0.056912)\n",
      "relu adam 1500 0.0001 112 (150,): Macro 0.696426 (0.070644)\n",
      "Testing 2880/2880\n",
      "relu adam 1500 0.0001 112 (200,): Weighted 0.806636 (0.067207)\n",
      "relu adam 1500 0.0001 112 (200,): Macro 0.690456 (0.084743)\n"
     ]
    }
   ],
   "source": [
    "results_weighted = []\n",
    "results_macro = []\n",
    "names = []\n",
    "num_tests = 4 * 3 * 3 * 4 * 5 * 4\n",
    "i = 1\n",
    "\n",
    "for activation in ['identity', 'logistic', 'tanh', 'relu']:\n",
    "    for solver in ['lbfgs', 'sgd', 'adam']:\n",
    "        for max_iter in [500, 1000, 1500]:\n",
    "            for alpha in 10.0 ** -np.arange(1, 5):\n",
    "                for random_state in [17, 29, 42, 76, 112]:\n",
    "                    for hidden_layer_sizes in [(50,), (100,), (150,), (200,)]:\n",
    "                        print(\"Testing {}/{}\".format(i,num_tests))\n",
    "                        i+=1\n",
    "                        kf = StratifiedKFold(n_splits=num_folds, random_state=seed)\n",
    "                        sm = SMOTE(random_state=seed, k_neighbors=7, sampling_strategy=\"not majority\")\n",
    "                        cv_results_weighted = np.array([])\n",
    "                        cv_results_macro = np.array([])\n",
    "                        for train_idx, test_idx, in kf.split(X_train, y_train):\n",
    "                            X_cross_train, y_cross_train = X_train.iloc[train_idx], y_train.iloc[train_idx]\n",
    "                            X_cross_test, y_cross_test = X_train.iloc[test_idx], y_train.iloc[test_idx]\n",
    "                            X_cross_train, y_cross_train = sm.fit_sample(X_cross_train, y_cross_train)\n",
    "                            model = MLPClassifier(activation=activation, solver=solver, max_iter=max_iter, alpha=alpha, \n",
    "                                      random_state=random_state, hidden_layer_sizes=hidden_layer_sizes )\n",
    "                            model.fit(X_cross_train, y_cross_train)  \n",
    "                            y_pred = model.predict(X_cross_test)\n",
    "                            f1s_weight = f1_score(y_cross_test, y_pred, average=\"weighted\")\n",
    "                            f1s_macro = f1_score(y_cross_test, y_pred, average=\"macro\")\n",
    "                            cv_results_weighted = np.append(cv_results_weighted, [f1s_weight])\n",
    "                            cv_results_macro = np.append(cv_results_macro, [f1s_macro])\n",
    "                        results_weighted.append(cv_results_weighted)\n",
    "                        results_macro.append(cv_results_macro)\n",
    "                        name = \"{} {} {} {} {} {}\".format(activation, solver, max_iter, alpha, random_state, hidden_layer_sizes)\n",
    "                        names.append(name)\n",
    "                        msg = \"%s: Weighted %f (%f)\" % (name, cv_results_weighted.mean(), cv_results_weighted.std())\n",
    "                        print(msg)\n",
    "                        msg = \"%s: Macro %f (%f)\" % (name, cv_results_macro.mean(), cv_results_macro.std())\n",
    "                        print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimport pickle\\nfile = open(\"names.pkl\", \"rb\")\\nnames = pickle.load(file)\\nfile = open(\"results_weighted.pkl\", \"rb\")\\nresults_weighted = pickle.load(file)\\nfile = open(\"results_macro.pkl\", \"rb\")\\nresults_macro = pickle.load(file)\\n'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''''''\n",
    "import pickle\n",
    "with open('names.pkl', 'wb') as f:\n",
    "    pickle.dump(names, f)\n",
    "\n",
    "with open('results_weighted.pkl', 'wb') as f:\n",
    "    pickle.dump(results_weighted, f)\n",
    "    \n",
    "with open('results_macro.pkl', 'wb') as f:\n",
    "    pickle.dump(results_macro, f)\n",
    "\n",
    "'''\n",
    "import pickle\n",
    "file = open(\"names.pkl\", \"rb\")\n",
    "names = pickle.load(file)\n",
    "file = open(\"results_weighted.pkl\", \"rb\")\n",
    "results_weighted = pickle.load(file)\n",
    "file = open(\"results_macro.pkl\", \"rb\")\n",
    "results_macro = pickle.load(file)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relu sgd 500 0.1 29 (50,) - Weighted: 0.7637944136919548 - Normal: 0.8566592580514953\n"
     ]
    }
   ],
   "source": [
    "avg_values_macro = [np.average(item) for item in results_macro]\n",
    "avg_values_weighted = [np.average(item) for item in results_weighted]\n",
    "max_index = avg_values_macro.index(max(avg_values_macro))\n",
    "print(\"{} - Weighted: {} - Normal: {}\".format(names[max_index], avg_values_macro[max_index], avg_values_weighted[max_index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 1.22382330\n",
      "Iteration 2, loss = 1.22056448\n",
      "Iteration 3, loss = 1.21573239\n",
      "Iteration 4, loss = 1.20957314\n",
      "Iteration 5, loss = 1.20228998\n",
      "Iteration 6, loss = 1.19404871\n",
      "Iteration 7, loss = 1.18566380\n",
      "Iteration 8, loss = 1.17680968\n",
      "Iteration 9, loss = 1.16723608\n",
      "Iteration 10, loss = 1.15775463\n",
      "Iteration 11, loss = 1.14844083\n",
      "Iteration 12, loss = 1.13865504\n",
      "Iteration 13, loss = 1.12903315\n",
      "Iteration 14, loss = 1.11966283\n",
      "Iteration 15, loss = 1.11006164\n",
      "Iteration 16, loss = 1.10102698\n",
      "Iteration 17, loss = 1.09201315\n",
      "Iteration 18, loss = 1.08321502\n",
      "Iteration 19, loss = 1.07430463\n",
      "Iteration 20, loss = 1.06618502\n",
      "Iteration 21, loss = 1.05763824\n",
      "Iteration 22, loss = 1.04955097\n",
      "Iteration 23, loss = 1.04162028\n",
      "Iteration 24, loss = 1.03415701\n",
      "Iteration 25, loss = 1.02632674\n",
      "Iteration 26, loss = 1.01943943\n",
      "Iteration 27, loss = 1.01216601\n",
      "Iteration 28, loss = 1.00536740\n",
      "Iteration 29, loss = 0.99842053\n",
      "Iteration 30, loss = 0.99201153\n",
      "Iteration 31, loss = 0.98554565\n",
      "Iteration 32, loss = 0.97950109\n",
      "Iteration 33, loss = 0.97335523\n",
      "Iteration 34, loss = 0.96758580\n",
      "Iteration 35, loss = 0.96180362\n",
      "Iteration 36, loss = 0.95631160\n",
      "Iteration 37, loss = 0.95082908\n",
      "Iteration 38, loss = 0.94559581\n",
      "Iteration 39, loss = 0.94042942\n",
      "Iteration 40, loss = 0.93540143\n",
      "Iteration 41, loss = 0.93045484\n",
      "Iteration 42, loss = 0.92571532\n",
      "Iteration 43, loss = 0.92112027\n",
      "Iteration 44, loss = 0.91654392\n",
      "Iteration 45, loss = 0.91213410\n",
      "Iteration 46, loss = 0.90772837\n",
      "Iteration 47, loss = 0.90350204\n",
      "Iteration 48, loss = 0.89930194\n",
      "Iteration 49, loss = 0.89522852\n",
      "Iteration 50, loss = 0.89128974\n",
      "Iteration 51, loss = 0.88735525\n",
      "Iteration 52, loss = 0.88351600\n",
      "Iteration 53, loss = 0.87984014\n",
      "Iteration 54, loss = 0.87610450\n",
      "Iteration 55, loss = 0.87250269\n",
      "Iteration 56, loss = 0.86889496\n",
      "Iteration 57, loss = 0.86544862\n",
      "Iteration 58, loss = 0.86213824\n",
      "Iteration 59, loss = 0.85871629\n",
      "Iteration 60, loss = 0.85547710\n",
      "Iteration 61, loss = 0.85228024\n",
      "Iteration 62, loss = 0.84902044\n",
      "Iteration 63, loss = 0.84591879\n",
      "Iteration 64, loss = 0.84289949\n",
      "Iteration 65, loss = 0.83990487\n",
      "Iteration 66, loss = 0.83689234\n",
      "Iteration 67, loss = 0.83392806\n",
      "Iteration 68, loss = 0.83109806\n",
      "Iteration 69, loss = 0.82832213\n",
      "Iteration 70, loss = 0.82542535\n",
      "Iteration 71, loss = 0.82266057\n",
      "Iteration 72, loss = 0.81997678\n",
      "Iteration 73, loss = 0.81733634\n",
      "Iteration 74, loss = 0.81465951\n",
      "Iteration 75, loss = 0.81209243\n",
      "Iteration 76, loss = 0.80951809\n",
      "Iteration 77, loss = 0.80702500\n",
      "Iteration 78, loss = 0.80448669\n",
      "Iteration 79, loss = 0.80205205\n",
      "Iteration 80, loss = 0.79958453\n",
      "Iteration 81, loss = 0.79718577\n",
      "Iteration 82, loss = 0.79485132\n",
      "Iteration 83, loss = 0.79249881\n",
      "Iteration 84, loss = 0.79016747\n",
      "Iteration 85, loss = 0.78789416\n",
      "Iteration 86, loss = 0.78562975\n",
      "Iteration 87, loss = 0.78340882\n",
      "Iteration 88, loss = 0.78119276\n",
      "Iteration 89, loss = 0.77902440\n",
      "Iteration 90, loss = 0.77683319\n",
      "Iteration 91, loss = 0.77475228\n",
      "Iteration 92, loss = 0.77263121\n",
      "Iteration 93, loss = 0.77058625\n",
      "Iteration 94, loss = 0.76854137\n",
      "Iteration 95, loss = 0.76648447\n",
      "Iteration 96, loss = 0.76448554\n",
      "Iteration 97, loss = 0.76251640\n",
      "Iteration 98, loss = 0.76052068\n",
      "Iteration 99, loss = 0.75861148\n",
      "Iteration 100, loss = 0.75681016\n",
      "Iteration 101, loss = 0.75482029\n",
      "Iteration 102, loss = 0.75293734\n",
      "Iteration 103, loss = 0.75112433\n",
      "Iteration 104, loss = 0.74922659\n",
      "Iteration 105, loss = 0.74746192\n",
      "Iteration 106, loss = 0.74564005\n",
      "Iteration 107, loss = 0.74384344\n",
      "Iteration 108, loss = 0.74204810\n",
      "Iteration 109, loss = 0.74033413\n",
      "Iteration 110, loss = 0.73856628\n",
      "Iteration 111, loss = 0.73685017\n",
      "Iteration 112, loss = 0.73514552\n",
      "Iteration 113, loss = 0.73345354\n",
      "Iteration 114, loss = 0.73175512\n",
      "Iteration 115, loss = 0.73010525\n",
      "Iteration 116, loss = 0.72846190\n",
      "Iteration 117, loss = 0.72683951\n",
      "Iteration 118, loss = 0.72520221\n",
      "Iteration 119, loss = 0.72357260\n",
      "Iteration 120, loss = 0.72199653\n",
      "Iteration 121, loss = 0.72042262\n",
      "Iteration 122, loss = 0.71882590\n",
      "Iteration 123, loss = 0.71727399\n",
      "Iteration 124, loss = 0.71570454\n",
      "Iteration 125, loss = 0.71416488\n",
      "Iteration 126, loss = 0.71267927\n",
      "Iteration 127, loss = 0.71113522\n",
      "Iteration 128, loss = 0.70968516\n",
      "Iteration 129, loss = 0.70816321\n",
      "Iteration 130, loss = 0.70666994\n",
      "Iteration 131, loss = 0.70527904\n",
      "Iteration 132, loss = 0.70375149\n",
      "Iteration 133, loss = 0.70232194\n",
      "Iteration 134, loss = 0.70090605\n",
      "Iteration 135, loss = 0.69946370\n",
      "Iteration 136, loss = 0.69804241\n",
      "Iteration 137, loss = 0.69669360\n",
      "Iteration 138, loss = 0.69528430\n",
      "Iteration 139, loss = 0.69391598\n",
      "Iteration 140, loss = 0.69254859\n",
      "Iteration 141, loss = 0.69118640\n",
      "Iteration 142, loss = 0.68982756\n",
      "Iteration 143, loss = 0.68851487\n",
      "Iteration 144, loss = 0.68715963\n",
      "Iteration 145, loss = 0.68585621\n",
      "Iteration 146, loss = 0.68455745\n",
      "Iteration 147, loss = 0.68328100\n",
      "Iteration 148, loss = 0.68199810\n",
      "Iteration 149, loss = 0.68070479\n",
      "Iteration 150, loss = 0.67941719\n",
      "Iteration 151, loss = 0.67817818\n",
      "Iteration 152, loss = 0.67692760\n",
      "Iteration 153, loss = 0.67568998\n",
      "Iteration 154, loss = 0.67447917\n",
      "Iteration 155, loss = 0.67324147\n",
      "Iteration 156, loss = 0.67204966\n",
      "Iteration 157, loss = 0.67083224\n",
      "Iteration 158, loss = 0.66962083\n",
      "Iteration 159, loss = 0.66845379\n",
      "Iteration 160, loss = 0.66729317\n",
      "Iteration 161, loss = 0.66608110\n",
      "Iteration 162, loss = 0.66492415\n",
      "Iteration 163, loss = 0.66378789\n",
      "Iteration 164, loss = 0.66263521\n",
      "Iteration 165, loss = 0.66147311\n",
      "Iteration 166, loss = 0.66034630\n",
      "Iteration 167, loss = 0.65922476\n",
      "Iteration 168, loss = 0.65811110\n",
      "Iteration 169, loss = 0.65699099\n",
      "Iteration 170, loss = 0.65587679\n",
      "Iteration 171, loss = 0.65479332\n",
      "Iteration 172, loss = 0.65370036\n",
      "Iteration 173, loss = 0.65261283\n",
      "Iteration 174, loss = 0.65153402\n",
      "Iteration 175, loss = 0.65047859\n",
      "Iteration 176, loss = 0.64939808\n",
      "Iteration 177, loss = 0.64836887\n",
      "Iteration 178, loss = 0.64730146\n",
      "Iteration 179, loss = 0.64623131\n",
      "Iteration 180, loss = 0.64522981\n",
      "Iteration 181, loss = 0.64420716\n",
      "Iteration 182, loss = 0.64316369\n",
      "Iteration 183, loss = 0.64214517\n",
      "Iteration 184, loss = 0.64116448\n",
      "Iteration 185, loss = 0.64014963\n",
      "Iteration 186, loss = 0.63913631\n",
      "Iteration 187, loss = 0.63812539\n",
      "Iteration 188, loss = 0.63715149\n",
      "Iteration 189, loss = 0.63618134\n",
      "Iteration 190, loss = 0.63519161\n",
      "Iteration 191, loss = 0.63420522\n",
      "Iteration 192, loss = 0.63325467\n",
      "Iteration 193, loss = 0.63230061\n",
      "Iteration 194, loss = 0.63134084\n",
      "Iteration 195, loss = 0.63036841\n",
      "Iteration 196, loss = 0.62946400\n",
      "Iteration 197, loss = 0.62848096\n",
      "Iteration 198, loss = 0.62755124\n",
      "Iteration 199, loss = 0.62661981\n",
      "Iteration 200, loss = 0.62569152\n",
      "Iteration 201, loss = 0.62477768\n",
      "Iteration 202, loss = 0.62386552\n",
      "Iteration 203, loss = 0.62294754\n",
      "Iteration 204, loss = 0.62204655\n",
      "Iteration 205, loss = 0.62115164\n",
      "Iteration 206, loss = 0.62026429\n",
      "Iteration 207, loss = 0.61935511\n",
      "Iteration 208, loss = 0.61846600\n",
      "Iteration 209, loss = 0.61758778\n",
      "Iteration 210, loss = 0.61671186\n",
      "Iteration 211, loss = 0.61585331\n",
      "Iteration 212, loss = 0.61496913\n",
      "Iteration 213, loss = 0.61411952\n",
      "Iteration 214, loss = 0.61325489\n",
      "Iteration 215, loss = 0.61239305\n",
      "Iteration 216, loss = 0.61152444\n",
      "Iteration 217, loss = 0.61071424\n",
      "Iteration 218, loss = 0.60986171\n",
      "Iteration 219, loss = 0.60901540\n",
      "Iteration 220, loss = 0.60818452\n",
      "Iteration 221, loss = 0.60734502\n",
      "Iteration 222, loss = 0.60654641\n",
      "Iteration 223, loss = 0.60572085\n",
      "Iteration 224, loss = 0.60488184\n",
      "Iteration 225, loss = 0.60407355\n",
      "Iteration 226, loss = 0.60328494\n",
      "Iteration 227, loss = 0.60247186\n",
      "Iteration 228, loss = 0.60169692\n",
      "Iteration 229, loss = 0.60087662\n",
      "Iteration 230, loss = 0.60011131\n",
      "Iteration 231, loss = 0.59930952\n",
      "Iteration 232, loss = 0.59853935\n",
      "Iteration 233, loss = 0.59776296\n",
      "Iteration 234, loss = 0.59695950\n",
      "Iteration 235, loss = 0.59621238\n",
      "Iteration 236, loss = 0.59547097\n",
      "Iteration 237, loss = 0.59470389\n",
      "Iteration 238, loss = 0.59391191\n",
      "Iteration 239, loss = 0.59316884\n",
      "Iteration 240, loss = 0.59241831\n",
      "Iteration 241, loss = 0.59167236\n",
      "Iteration 242, loss = 0.59092476\n",
      "Iteration 243, loss = 0.59017152\n",
      "Iteration 244, loss = 0.58943459\n",
      "Iteration 245, loss = 0.58873693\n",
      "Iteration 246, loss = 0.58797639\n",
      "Iteration 247, loss = 0.58728283\n",
      "Iteration 248, loss = 0.58654701\n",
      "Iteration 249, loss = 0.58585790\n",
      "Iteration 250, loss = 0.58511195\n",
      "Iteration 251, loss = 0.58441070\n",
      "Iteration 252, loss = 0.58371960\n",
      "Iteration 253, loss = 0.58299950\n",
      "Iteration 254, loss = 0.58229646\n",
      "Iteration 255, loss = 0.58161425\n",
      "Iteration 256, loss = 0.58092783\n",
      "Iteration 257, loss = 0.58024618\n",
      "Iteration 258, loss = 0.57956165\n",
      "Iteration 259, loss = 0.57889646\n",
      "Iteration 260, loss = 0.57821116\n",
      "Iteration 261, loss = 0.57755112\n",
      "Iteration 262, loss = 0.57688650\n",
      "Iteration 263, loss = 0.57622253\n",
      "Iteration 264, loss = 0.57557423\n",
      "Iteration 265, loss = 0.57490695\n",
      "Iteration 266, loss = 0.57428539\n",
      "Iteration 267, loss = 0.57360646\n",
      "Iteration 268, loss = 0.57300728\n",
      "Iteration 269, loss = 0.57235323\n",
      "Iteration 270, loss = 0.57170259\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 271, loss = 0.57106772\n",
      "Iteration 272, loss = 0.57045221\n",
      "Iteration 273, loss = 0.56983932\n",
      "Iteration 274, loss = 0.56918944\n",
      "Iteration 275, loss = 0.56859244\n",
      "Iteration 276, loss = 0.56796819\n",
      "Iteration 277, loss = 0.56735812\n",
      "Iteration 278, loss = 0.56672702\n",
      "Iteration 279, loss = 0.56616398\n",
      "Iteration 280, loss = 0.56554844\n",
      "Iteration 281, loss = 0.56494340\n",
      "Iteration 282, loss = 0.56434590\n",
      "Iteration 283, loss = 0.56377464\n",
      "Iteration 284, loss = 0.56315599\n",
      "Iteration 285, loss = 0.56256354\n",
      "Iteration 286, loss = 0.56197413\n",
      "Iteration 287, loss = 0.56139829\n",
      "Iteration 288, loss = 0.56081232\n",
      "Iteration 289, loss = 0.56023564\n",
      "Iteration 290, loss = 0.55967296\n",
      "Iteration 291, loss = 0.55910770\n",
      "Iteration 292, loss = 0.55852715\n",
      "Iteration 293, loss = 0.55794502\n",
      "Iteration 294, loss = 0.55740573\n",
      "Iteration 295, loss = 0.55682843\n",
      "Iteration 296, loss = 0.55628436\n",
      "Iteration 297, loss = 0.55571905\n",
      "Iteration 298, loss = 0.55517410\n",
      "Iteration 299, loss = 0.55462273\n",
      "Iteration 300, loss = 0.55407079\n",
      "Iteration 301, loss = 0.55352328\n",
      "Iteration 302, loss = 0.55300927\n",
      "Iteration 303, loss = 0.55244812\n",
      "Iteration 304, loss = 0.55192406\n",
      "Iteration 305, loss = 0.55140417\n",
      "Iteration 306, loss = 0.55085018\n",
      "Iteration 307, loss = 0.55033455\n",
      "Iteration 308, loss = 0.54982140\n",
      "Iteration 309, loss = 0.54929034\n",
      "Iteration 310, loss = 0.54876963\n",
      "Iteration 311, loss = 0.54825420\n",
      "Iteration 312, loss = 0.54774160\n",
      "Iteration 313, loss = 0.54722882\n",
      "Iteration 314, loss = 0.54672469\n",
      "Iteration 315, loss = 0.54622819\n",
      "Iteration 316, loss = 0.54570577\n",
      "Iteration 317, loss = 0.54522482\n",
      "Iteration 318, loss = 0.54471926\n",
      "Iteration 319, loss = 0.54420823\n",
      "Iteration 320, loss = 0.54372780\n",
      "Iteration 321, loss = 0.54323552\n",
      "Iteration 322, loss = 0.54273315\n",
      "Iteration 323, loss = 0.54224584\n",
      "Iteration 324, loss = 0.54177045\n",
      "Iteration 325, loss = 0.54127171\n",
      "Iteration 326, loss = 0.54079066\n",
      "Iteration 327, loss = 0.54030895\n",
      "Iteration 328, loss = 0.53982526\n",
      "Iteration 329, loss = 0.53935254\n",
      "Iteration 330, loss = 0.53887391\n",
      "Iteration 331, loss = 0.53841907\n",
      "Iteration 332, loss = 0.53794408\n",
      "Iteration 333, loss = 0.53747860\n",
      "Iteration 334, loss = 0.53700464\n",
      "Iteration 335, loss = 0.53656362\n",
      "Iteration 336, loss = 0.53608634\n",
      "Iteration 337, loss = 0.53561092\n",
      "Iteration 338, loss = 0.53518046\n",
      "Iteration 339, loss = 0.53473403\n",
      "Iteration 340, loss = 0.53426620\n",
      "Iteration 341, loss = 0.53380659\n",
      "Iteration 342, loss = 0.53336495\n",
      "Iteration 343, loss = 0.53292348\n",
      "Iteration 344, loss = 0.53247515\n",
      "Iteration 345, loss = 0.53203709\n",
      "Iteration 346, loss = 0.53157376\n",
      "Iteration 347, loss = 0.53115383\n",
      "Iteration 348, loss = 0.53075278\n",
      "Iteration 349, loss = 0.53027565\n",
      "Iteration 350, loss = 0.52985807\n",
      "Iteration 351, loss = 0.52942574\n",
      "Iteration 352, loss = 0.52898528\n",
      "Iteration 353, loss = 0.52857626\n",
      "Iteration 354, loss = 0.52813808\n",
      "Iteration 355, loss = 0.52771132\n",
      "Iteration 356, loss = 0.52729938\n",
      "Iteration 357, loss = 0.52688071\n",
      "Iteration 358, loss = 0.52646713\n",
      "Iteration 359, loss = 0.52604735\n",
      "Iteration 360, loss = 0.52563410\n",
      "Iteration 361, loss = 0.52521137\n",
      "Iteration 362, loss = 0.52483277\n",
      "Iteration 363, loss = 0.52440514\n",
      "Iteration 364, loss = 0.52399992\n",
      "Iteration 365, loss = 0.52358625\n",
      "Iteration 366, loss = 0.52318317\n",
      "Iteration 367, loss = 0.52278642\n",
      "Iteration 368, loss = 0.52239665\n",
      "Iteration 369, loss = 0.52200124\n",
      "Iteration 370, loss = 0.52158597\n",
      "Iteration 371, loss = 0.52120405\n",
      "Iteration 372, loss = 0.52082356\n",
      "Iteration 373, loss = 0.52043052\n",
      "Iteration 374, loss = 0.52004274\n",
      "Iteration 375, loss = 0.51966093\n",
      "Iteration 376, loss = 0.51927124\n",
      "Iteration 377, loss = 0.51888653\n",
      "Iteration 378, loss = 0.51852349\n",
      "Iteration 379, loss = 0.51813759\n",
      "Iteration 380, loss = 0.51774520\n",
      "Iteration 381, loss = 0.51737532\n",
      "Iteration 382, loss = 0.51703059\n",
      "Iteration 383, loss = 0.51662620\n",
      "Iteration 384, loss = 0.51626339\n",
      "Iteration 385, loss = 0.51588177\n",
      "Iteration 386, loss = 0.51551455\n",
      "Iteration 387, loss = 0.51515568\n",
      "Iteration 388, loss = 0.51478919\n",
      "Iteration 389, loss = 0.51442430\n",
      "Iteration 390, loss = 0.51405650\n",
      "Iteration 391, loss = 0.51370614\n",
      "Iteration 392, loss = 0.51335039\n",
      "Iteration 393, loss = 0.51298959\n",
      "Iteration 394, loss = 0.51262636\n",
      "Iteration 395, loss = 0.51225696\n",
      "Iteration 396, loss = 0.51190611\n",
      "Iteration 397, loss = 0.51156263\n",
      "Iteration 398, loss = 0.51120929\n",
      "Iteration 399, loss = 0.51087643\n",
      "Iteration 400, loss = 0.51050988\n",
      "Iteration 401, loss = 0.51015704\n",
      "Iteration 402, loss = 0.50981579\n",
      "Iteration 403, loss = 0.50947118\n",
      "Iteration 404, loss = 0.50911968\n",
      "Iteration 405, loss = 0.50877293\n",
      "Iteration 406, loss = 0.50844666\n",
      "Iteration 407, loss = 0.50810793\n",
      "Iteration 408, loss = 0.50779153\n",
      "Iteration 409, loss = 0.50743546\n",
      "Iteration 410, loss = 0.50709564\n",
      "Iteration 411, loss = 0.50677546\n",
      "Iteration 412, loss = 0.50643878\n",
      "Iteration 413, loss = 0.50610242\n",
      "Iteration 414, loss = 0.50578079\n",
      "Iteration 415, loss = 0.50543921\n",
      "Iteration 416, loss = 0.50512695\n",
      "Iteration 417, loss = 0.50479892\n",
      "Iteration 418, loss = 0.50448651\n",
      "Iteration 419, loss = 0.50417355\n",
      "Iteration 420, loss = 0.50384024\n",
      "Iteration 421, loss = 0.50354340\n",
      "Iteration 422, loss = 0.50319671\n",
      "Iteration 423, loss = 0.50288241\n",
      "Iteration 424, loss = 0.50257762\n",
      "Iteration 425, loss = 0.50227259\n",
      "Iteration 426, loss = 0.50194421\n",
      "Iteration 427, loss = 0.50164939\n",
      "Iteration 428, loss = 0.50132208\n",
      "Iteration 429, loss = 0.50102956\n",
      "Iteration 430, loss = 0.50072132\n",
      "Iteration 431, loss = 0.50041555\n",
      "Iteration 432, loss = 0.50010684\n",
      "Iteration 433, loss = 0.49981971\n",
      "Iteration 434, loss = 0.49952595\n",
      "Iteration 435, loss = 0.49921051\n",
      "Iteration 436, loss = 0.49890345\n",
      "Iteration 437, loss = 0.49861253\n",
      "Iteration 438, loss = 0.49831825\n",
      "Iteration 439, loss = 0.49801747\n",
      "Iteration 440, loss = 0.49773222\n",
      "Iteration 441, loss = 0.49743238\n",
      "Iteration 442, loss = 0.49714857\n",
      "Iteration 443, loss = 0.49686486\n",
      "Iteration 444, loss = 0.49655383\n",
      "Iteration 445, loss = 0.49627496\n",
      "Iteration 446, loss = 0.49599197\n",
      "Iteration 447, loss = 0.49570273\n",
      "Iteration 448, loss = 0.49540185\n",
      "Iteration 449, loss = 0.49511675\n",
      "Iteration 450, loss = 0.49485449\n",
      "Iteration 451, loss = 0.49456763\n",
      "Iteration 452, loss = 0.49429513\n",
      "Iteration 453, loss = 0.49401458\n",
      "Iteration 454, loss = 0.49373203\n",
      "Iteration 455, loss = 0.49345702\n",
      "Iteration 456, loss = 0.49317925\n",
      "Iteration 457, loss = 0.49290558\n",
      "Iteration 458, loss = 0.49263323\n",
      "Iteration 459, loss = 0.49235248\n",
      "Iteration 460, loss = 0.49208901\n",
      "Iteration 461, loss = 0.49180357\n",
      "Iteration 462, loss = 0.49156255\n",
      "Iteration 463, loss = 0.49126538\n",
      "Iteration 464, loss = 0.49101818\n",
      "Iteration 465, loss = 0.49074969\n",
      "Iteration 466, loss = 0.49049655\n",
      "Iteration 467, loss = 0.49022165\n",
      "Iteration 468, loss = 0.48995727\n",
      "Iteration 469, loss = 0.48969560\n",
      "Iteration 470, loss = 0.48945091\n",
      "Iteration 471, loss = 0.48916637\n",
      "Iteration 472, loss = 0.48892947\n",
      "Iteration 473, loss = 0.48866713\n",
      "Iteration 474, loss = 0.48841441\n",
      "Iteration 475, loss = 0.48816572\n",
      "Iteration 476, loss = 0.48790321\n",
      "Iteration 477, loss = 0.48765176\n",
      "Iteration 478, loss = 0.48739841\n",
      "Iteration 479, loss = 0.48715410\n",
      "Iteration 480, loss = 0.48689384\n",
      "Iteration 481, loss = 0.48664674\n",
      "Iteration 482, loss = 0.48638118\n",
      "Iteration 483, loss = 0.48615184\n",
      "Iteration 484, loss = 0.48589973\n",
      "Iteration 485, loss = 0.48566009\n",
      "Iteration 486, loss = 0.48540836\n",
      "Iteration 487, loss = 0.48517900\n",
      "Iteration 488, loss = 0.48492824\n",
      "Iteration 489, loss = 0.48468494\n",
      "Iteration 490, loss = 0.48443636\n",
      "Iteration 491, loss = 0.48424487\n",
      "Iteration 492, loss = 0.48398772\n",
      "Iteration 493, loss = 0.48372169\n",
      "Iteration 494, loss = 0.48349266\n",
      "Iteration 495, loss = 0.48327880\n",
      "Iteration 496, loss = 0.48301780\n",
      "Iteration 497, loss = 0.48279557\n",
      "Iteration 498, loss = 0.48255629\n",
      "Iteration 499, loss = 0.48232313\n",
      "Iteration 500, loss = 0.48210140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "#Evaluating with tuned parameters on all the training data\n",
    "model = MLPClassifier(hidden_layer_sizes=(50), max_iter=500, alpha=0.1, activation=\"relu\",\n",
    "                     solver='sgd', verbose=500 ,  random_state=29)\n",
    "\n",
    "pipeline = Pipeline([('Scaler', StandardScaler()),('Model', model)])\n",
    "\n",
    "pipeline.fit(X_train_res, y_train_res) \n",
    "\n",
    "y_pred = pipeline.predict(X_test) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1fd51640c18>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred_test = pipeline.predict(X_train_res) \n",
    "plot_confusion_matrix(y_train_res, y_pred_test, classes=class_names, title=\"cm train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1fd5166e8d0>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(y_test, y_pred, classes=class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.50      0.62        16\n",
      "           1       0.18      0.33      0.24         6\n",
      "           2       0.90      0.93      0.92        30\n",
      "\n",
      "    accuracy                           0.73        52\n",
      "   macro avg       0.63      0.59      0.59        52\n",
      "weighted avg       0.79      0.73      0.75        52\n",
      "\n"
     ]
    }
   ],
   "source": [
    " print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Tunining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing 1/4320\n",
      "1 2 3 log2 gini True 50 17: Weighted 0.817273 (0.061421)\n",
      "1 2 3 log2 gini True 50 17: Macro 0.718101 (0.081349)\n",
      "Testing 2/4320\n",
      "1 2 3 log2 gini True 100 17: Weighted 0.804345 (0.055018)\n",
      "1 2 3 log2 gini True 100 17: Macro 0.698862 (0.070981)\n",
      "Testing 3/4320\n",
      "1 2 3 log2 gini True 200 17: Weighted 0.809014 (0.051630)\n",
      "1 2 3 log2 gini True 200 17: Macro 0.702391 (0.068382)\n",
      "Testing 4/4320\n",
      "1 2 3 log2 gini True 500 17: Weighted 0.813941 (0.055478)\n",
      "1 2 3 log2 gini True 500 17: Macro 0.709900 (0.075733)\n",
      "Testing 5/4320\n",
      "1 2 3 log2 gini False 50 17: Weighted 0.804627 (0.072614)\n",
      "1 2 3 log2 gini False 50 17: Macro 0.701445 (0.092151)\n",
      "Testing 6/4320\n",
      "1 2 3 log2 gini False 100 17: Weighted 0.813081 (0.059751)\n",
      "1 2 3 log2 gini False 100 17: Macro 0.712700 (0.075647)\n",
      "Testing 7/4320\n",
      "1 2 3 log2 gini False 200 17: Weighted 0.809244 (0.065497)\n",
      "1 2 3 log2 gini False 200 17: Macro 0.704564 (0.087453)\n",
      "Testing 8/4320\n",
      "1 2 3 log2 gini False 500 17: Weighted 0.809244 (0.065497)\n",
      "1 2 3 log2 gini False 500 17: Macro 0.704564 (0.087453)\n",
      "Testing 9/4320\n",
      "1 2 3 log2 entropy True 50 17: Weighted 0.809935 (0.060810)\n",
      "1 2 3 log2 entropy True 50 17: Macro 0.704820 (0.082311)\n",
      "Testing 10/4320\n",
      "1 2 3 log2 entropy True 100 17: Weighted 0.809935 (0.060810)\n",
      "1 2 3 log2 entropy True 100 17: Macro 0.704820 (0.082311)\n",
      "Testing 11/4320\n",
      "1 2 3 log2 entropy True 200 17: Weighted 0.800801 (0.062924)\n",
      "1 2 3 log2 entropy True 200 17: Macro 0.692099 (0.082395)\n",
      "Testing 12/4320\n",
      "1 2 3 log2 entropy True 500 17: Weighted 0.805007 (0.056975)\n",
      "1 2 3 log2 entropy True 500 17: Macro 0.697312 (0.075095)\n",
      "Testing 13/4320\n",
      "1 2 3 log2 entropy False 50 17: Weighted 0.787834 (0.088117)\n",
      "1 2 3 log2 entropy False 50 17: Macro 0.680688 (0.106489)\n",
      "Testing 14/4320\n",
      "1 2 3 log2 entropy False 100 17: Weighted 0.787834 (0.088117)\n",
      "1 2 3 log2 entropy False 100 17: Macro 0.680688 (0.106489)\n",
      "Testing 15/4320\n",
      "1 2 3 log2 entropy False 200 17: Weighted 0.787834 (0.088117)\n",
      "1 2 3 log2 entropy False 200 17: Macro 0.680688 (0.106489)\n",
      "Testing 16/4320\n",
      "1 2 3 log2 entropy False 500 17: Weighted 0.787834 (0.088117)\n",
      "1 2 3 log2 entropy False 500 17: Macro 0.680688 (0.106489)\n",
      "Testing 17/4320\n",
      "1 2 3 sqrt gini True 50 17: Weighted 0.817273 (0.061421)\n",
      "1 2 3 sqrt gini True 50 17: Macro 0.718101 (0.081349)\n",
      "Testing 18/4320\n",
      "1 2 3 sqrt gini True 100 17: Weighted 0.804345 (0.055018)\n",
      "1 2 3 sqrt gini True 100 17: Macro 0.698862 (0.070981)\n",
      "Testing 19/4320\n",
      "1 2 3 sqrt gini True 200 17: Weighted 0.809014 (0.051630)\n",
      "1 2 3 sqrt gini True 200 17: Macro 0.702391 (0.068382)\n",
      "Testing 20/4320\n",
      "1 2 3 sqrt gini True 500 17: Weighted 0.813941 (0.055478)\n",
      "1 2 3 sqrt gini True 500 17: Macro 0.709900 (0.075733)\n",
      "Testing 21/4320\n",
      "1 2 3 sqrt gini False 50 17: Weighted 0.804627 (0.072614)\n",
      "1 2 3 sqrt gini False 50 17: Macro 0.701445 (0.092151)\n",
      "Testing 22/4320\n",
      "1 2 3 sqrt gini False 100 17: Weighted 0.813081 (0.059751)\n",
      "1 2 3 sqrt gini False 100 17: Macro 0.712700 (0.075647)\n",
      "Testing 23/4320\n",
      "1 2 3 sqrt gini False 200 17: Weighted 0.809244 (0.065497)\n",
      "1 2 3 sqrt gini False 200 17: Macro 0.704564 (0.087453)\n",
      "Testing 24/4320\n",
      "1 2 3 sqrt gini False 500 17: Weighted 0.809244 (0.065497)\n",
      "1 2 3 sqrt gini False 500 17: Macro 0.704564 (0.087453)\n",
      "Testing 25/4320\n",
      "1 2 3 sqrt entropy True 50 17: Weighted 0.809935 (0.060810)\n",
      "1 2 3 sqrt entropy True 50 17: Macro 0.704820 (0.082311)\n",
      "Testing 26/4320\n",
      "1 2 3 sqrt entropy True 100 17: Weighted 0.809935 (0.060810)\n",
      "1 2 3 sqrt entropy True 100 17: Macro 0.704820 (0.082311)\n",
      "Testing 27/4320\n",
      "1 2 3 sqrt entropy True 200 17: Weighted 0.800801 (0.062924)\n",
      "1 2 3 sqrt entropy True 200 17: Macro 0.692099 (0.082395)\n",
      "Testing 28/4320\n",
      "1 2 3 sqrt entropy True 500 17: Weighted 0.805007 (0.056975)\n",
      "1 2 3 sqrt entropy True 500 17: Macro 0.697312 (0.075095)\n",
      "Testing 29/4320\n",
      "1 2 3 sqrt entropy False 50 17: Weighted 0.787834 (0.088117)\n",
      "1 2 3 sqrt entropy False 50 17: Macro 0.680688 (0.106489)\n",
      "Testing 30/4320\n",
      "1 2 3 sqrt entropy False 100 17: Weighted 0.787834 (0.088117)\n",
      "1 2 3 sqrt entropy False 100 17: Macro 0.680688 (0.106489)\n",
      "Testing 31/4320\n",
      "1 2 3 sqrt entropy False 200 17: Weighted 0.787834 (0.088117)\n",
      "1 2 3 sqrt entropy False 200 17: Macro 0.680688 (0.106489)\n",
      "Testing 32/4320\n",
      "1 2 3 sqrt entropy False 500 17: Weighted 0.787834 (0.088117)\n",
      "1 2 3 sqrt entropy False 500 17: Macro 0.680688 (0.106489)\n",
      "Testing 33/4320\n",
      "1 2 5 log2 gini True 50 17: Weighted 0.814261 (0.070017)\n",
      "1 2 5 log2 gini True 50 17: Macro 0.717393 (0.088470)\n",
      "Testing 34/4320\n",
      "1 2 5 log2 gini True 100 17: Weighted 0.810586 (0.055150)\n",
      "1 2 5 log2 gini True 100 17: Macro 0.703801 (0.070936)\n",
      "Testing 35/4320\n",
      "1 2 5 log2 gini True 200 17: Weighted 0.803722 (0.061157)\n",
      "1 2 5 log2 gini True 200 17: Macro 0.695738 (0.076918)\n",
      "Testing 36/4320\n",
      "1 2 5 log2 gini True 500 17: Weighted 0.811746 (0.061575)\n",
      "1 2 5 log2 gini True 500 17: Macro 0.710507 (0.079796)\n",
      "Testing 37/4320\n",
      "1 2 5 log2 gini False 50 17: Weighted 0.795365 (0.074405)\n",
      "1 2 5 log2 gini False 50 17: Macro 0.687559 (0.114990)\n",
      "Testing 38/4320\n",
      "1 2 5 log2 gini False 100 17: Weighted 0.799501 (0.067904)\n",
      "1 2 5 log2 gini False 100 17: Macro 0.696888 (0.100110)\n",
      "Testing 39/4320\n",
      "1 2 5 log2 gini False 200 17: Weighted 0.799501 (0.067904)\n",
      "1 2 5 log2 gini False 200 17: Macro 0.696888 (0.100110)\n",
      "Testing 40/4320\n",
      "1 2 5 log2 gini False 500 17: Weighted 0.799501 (0.067904)\n",
      "1 2 5 log2 gini False 500 17: Macro 0.696888 (0.100110)\n",
      "Testing 41/4320\n",
      "1 2 5 log2 entropy True 50 17: Weighted 0.814765 (0.067317)\n",
      "1 2 5 log2 entropy True 50 17: Macro 0.717940 (0.085578)\n",
      "Testing 42/4320\n",
      "1 2 5 log2 entropy True 100 17: Weighted 0.816674 (0.064627)\n",
      "1 2 5 log2 entropy True 100 17: Macro 0.718015 (0.085470)\n",
      "Testing 43/4320\n",
      "1 2 5 log2 entropy True 200 17: Weighted 0.807129 (0.059688)\n",
      "1 2 5 log2 entropy True 200 17: Macro 0.700731 (0.075190)\n",
      "Testing 44/4320\n",
      "1 2 5 log2 entropy True 500 17: Weighted 0.807129 (0.059688)\n",
      "1 2 5 log2 entropy True 500 17: Macro 0.700731 (0.075190)\n",
      "Testing 45/4320\n",
      "1 2 5 log2 entropy False 50 17: Weighted 0.784830 (0.074175)\n",
      "1 2 5 log2 entropy False 50 17: Macro 0.674154 (0.110450)\n",
      "Testing 46/4320\n",
      "1 2 5 log2 entropy False 100 17: Weighted 0.779745 (0.070594)\n",
      "1 2 5 log2 entropy False 100 17: Macro 0.666731 (0.105191)\n",
      "Testing 47/4320\n",
      "1 2 5 log2 entropy False 200 17: Weighted 0.776265 (0.071203)\n",
      "1 2 5 log2 entropy False 200 17: Macro 0.661812 (0.105759)\n",
      "Testing 48/4320\n",
      "1 2 5 log2 entropy False 500 17: Weighted 0.776265 (0.071203)\n",
      "1 2 5 log2 entropy False 500 17: Macro 0.661812 (0.105759)\n",
      "Testing 49/4320\n",
      "1 2 5 sqrt gini True 50 17: Weighted 0.814261 (0.070017)\n",
      "1 2 5 sqrt gini True 50 17: Macro 0.717393 (0.088470)\n",
      "Testing 50/4320\n",
      "1 2 5 sqrt gini True 100 17: Weighted 0.810586 (0.055150)\n",
      "1 2 5 sqrt gini True 100 17: Macro 0.703801 (0.070936)\n",
      "Testing 51/4320\n",
      "1 2 5 sqrt gini True 200 17: Weighted 0.803722 (0.061157)\n",
      "1 2 5 sqrt gini True 200 17: Macro 0.695738 (0.076918)\n",
      "Testing 52/4320\n",
      "1 2 5 sqrt gini True 500 17: Weighted 0.811746 (0.061575)\n",
      "1 2 5 sqrt gini True 500 17: Macro 0.710507 (0.079796)\n",
      "Testing 53/4320\n",
      "1 2 5 sqrt gini False 50 17: Weighted 0.795365 (0.074405)\n",
      "1 2 5 sqrt gini False 50 17: Macro 0.687559 (0.114990)\n",
      "Testing 54/4320\n",
      "1 2 5 sqrt gini False 100 17: Weighted 0.799501 (0.067904)\n",
      "1 2 5 sqrt gini False 100 17: Macro 0.696888 (0.100110)\n",
      "Testing 55/4320\n",
      "1 2 5 sqrt gini False 200 17: Weighted 0.799501 (0.067904)\n",
      "1 2 5 sqrt gini False 200 17: Macro 0.696888 (0.100110)\n",
      "Testing 56/4320\n",
      "1 2 5 sqrt gini False 500 17: Weighted 0.799501 (0.067904)\n",
      "1 2 5 sqrt gini False 500 17: Macro 0.696888 (0.100110)\n",
      "Testing 57/4320\n",
      "1 2 5 sqrt entropy True 50 17: Weighted 0.814765 (0.067317)\n",
      "1 2 5 sqrt entropy True 50 17: Macro 0.717940 (0.085578)\n",
      "Testing 58/4320\n",
      "1 2 5 sqrt entropy True 100 17: Weighted 0.816674 (0.064627)\n",
      "1 2 5 sqrt entropy True 100 17: Macro 0.718015 (0.085470)\n",
      "Testing 59/4320\n",
      "1 2 5 sqrt entropy True 200 17: Weighted 0.807129 (0.059688)\n",
      "1 2 5 sqrt entropy True 200 17: Macro 0.700731 (0.075190)\n",
      "Testing 60/4320\n",
      "1 2 5 sqrt entropy True 500 17: Weighted 0.807129 (0.059688)\n",
      "1 2 5 sqrt entropy True 500 17: Macro 0.700731 (0.075190)\n",
      "Testing 61/4320\n",
      "1 2 5 sqrt entropy False 50 17: Weighted 0.784830 (0.074175)\n",
      "1 2 5 sqrt entropy False 50 17: Macro 0.674154 (0.110450)\n",
      "Testing 62/4320\n",
      "1 2 5 sqrt entropy False 100 17: Weighted 0.779745 (0.070594)\n",
      "1 2 5 sqrt entropy False 100 17: Macro 0.666731 (0.105191)\n",
      "Testing 63/4320\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 2 5 sqrt entropy False 200 17: Weighted 0.776265 (0.071203)\n",
      "1 2 5 sqrt entropy False 200 17: Macro 0.661812 (0.105759)\n",
      "Testing 64/4320\n",
      "1 2 5 sqrt entropy False 500 17: Weighted 0.776265 (0.071203)\n",
      "1 2 5 sqrt entropy False 500 17: Macro 0.661812 (0.105759)\n",
      "Testing 65/4320\n",
      "1 2 8 log2 gini True 50 17: Weighted 0.793808 (0.068602)\n",
      "1 2 8 log2 gini True 50 17: Macro 0.685841 (0.082968)\n",
      "Testing 66/4320\n",
      "1 2 8 log2 gini True 100 17: Weighted 0.803236 (0.048640)\n",
      "1 2 8 log2 gini True 100 17: Macro 0.692302 (0.060436)\n",
      "Testing 67/4320\n",
      "1 2 8 log2 gini True 200 17: Weighted 0.796146 (0.055342)\n",
      "1 2 8 log2 gini True 200 17: Macro 0.684184 (0.068030)\n",
      "Testing 68/4320\n",
      "1 2 8 log2 gini True 500 17: Weighted 0.804248 (0.058745)\n",
      "1 2 8 log2 gini True 500 17: Macro 0.695898 (0.073651)\n",
      "Testing 69/4320\n",
      "1 2 8 log2 gini False 50 17: Weighted 0.797553 (0.062917)\n",
      "1 2 8 log2 gini False 50 17: Macro 0.696321 (0.090203)\n",
      "Testing 70/4320\n",
      "1 2 8 log2 gini False 100 17: Weighted 0.793690 (0.067997)\n",
      "1 2 8 log2 gini False 100 17: Macro 0.691536 (0.096727)\n",
      "Testing 71/4320\n",
      "1 2 8 log2 gini False 200 17: Weighted 0.784342 (0.059048)\n",
      "1 2 8 log2 gini False 200 17: Macro 0.677324 (0.083314)\n",
      "Testing 72/4320\n",
      "1 2 8 log2 gini False 500 17: Weighted 0.790080 (0.070300)\n",
      "1 2 8 log2 gini False 500 17: Macro 0.686476 (0.099626)\n",
      "Testing 73/4320\n",
      "1 2 8 log2 entropy True 50 17: Weighted 0.798333 (0.065464)\n",
      "1 2 8 log2 entropy True 50 17: Macro 0.690743 (0.079600)\n",
      "Testing 74/4320\n",
      "1 2 8 log2 entropy True 100 17: Weighted 0.805006 (0.059010)\n",
      "1 2 8 log2 entropy True 100 17: Macro 0.701252 (0.070207)\n",
      "Testing 75/4320\n",
      "1 2 8 log2 entropy True 200 17: Weighted 0.803722 (0.061157)\n",
      "1 2 8 log2 entropy True 200 17: Macro 0.695738 (0.076918)\n",
      "Testing 76/4320\n",
      "1 2 8 log2 entropy True 500 17: Weighted 0.797418 (0.066036)\n",
      "1 2 8 log2 entropy True 500 17: Macro 0.690901 (0.079504)\n",
      "Testing 77/4320\n",
      "1 2 8 log2 entropy False 50 17: Weighted 0.786530 (0.058258)\n",
      "1 2 8 log2 entropy False 50 17: Macro 0.682485 (0.082100)\n",
      "Testing 78/4320\n",
      "1 2 8 log2 entropy False 100 17: Weighted 0.786530 (0.058258)\n",
      "1 2 8 log2 entropy False 100 17: Macro 0.682485 (0.082100)\n",
      "Testing 79/4320\n",
      "1 2 8 log2 entropy False 200 17: Weighted 0.786530 (0.058258)\n",
      "1 2 8 log2 entropy False 200 17: Macro 0.682485 (0.082100)\n",
      "Testing 80/4320\n",
      "1 2 8 log2 entropy False 500 17: Weighted 0.790393 (0.052767)\n",
      "1 2 8 log2 entropy False 500 17: Macro 0.687270 (0.074883)\n",
      "Testing 81/4320\n",
      "1 2 8 sqrt gini True 50 17: Weighted 0.793808 (0.068602)\n",
      "1 2 8 sqrt gini True 50 17: Macro 0.685841 (0.082968)\n",
      "Testing 82/4320\n",
      "1 2 8 sqrt gini True 100 17: Weighted 0.803236 (0.048640)\n",
      "1 2 8 sqrt gini True 100 17: Macro 0.692302 (0.060436)\n",
      "Testing 83/4320\n",
      "1 2 8 sqrt gini True 200 17: Weighted 0.796146 (0.055342)\n",
      "1 2 8 sqrt gini True 200 17: Macro 0.684184 (0.068030)\n",
      "Testing 84/4320\n",
      "1 2 8 sqrt gini True 500 17: Weighted 0.804248 (0.058745)\n",
      "1 2 8 sqrt gini True 500 17: Macro 0.695898 (0.073651)\n",
      "Testing 85/4320\n",
      "1 2 8 sqrt gini False 50 17: Weighted 0.797553 (0.062917)\n",
      "1 2 8 sqrt gini False 50 17: Macro 0.696321 (0.090203)\n",
      "Testing 86/4320\n",
      "1 2 8 sqrt gini False 100 17: Weighted 0.793690 (0.067997)\n",
      "1 2 8 sqrt gini False 100 17: Macro 0.691536 (0.096727)\n",
      "Testing 87/4320\n",
      "1 2 8 sqrt gini False 200 17: Weighted 0.784342 (0.059048)\n",
      "1 2 8 sqrt gini False 200 17: Macro 0.677324 (0.083314)\n",
      "Testing 88/4320\n",
      "1 2 8 sqrt gini False 500 17: Weighted 0.790080 (0.070300)\n",
      "1 2 8 sqrt gini False 500 17: Macro 0.686476 (0.099626)\n",
      "Testing 89/4320\n",
      "1 2 8 sqrt entropy True 50 17: Weighted 0.798333 (0.065464)\n",
      "1 2 8 sqrt entropy True 50 17: Macro 0.690743 (0.079600)\n",
      "Testing 90/4320\n",
      "1 2 8 sqrt entropy True 100 17: Weighted 0.805006 (0.059010)\n",
      "1 2 8 sqrt entropy True 100 17: Macro 0.701252 (0.070207)\n",
      "Testing 91/4320\n",
      "1 2 8 sqrt entropy True 200 17: Weighted 0.803722 (0.061157)\n",
      "1 2 8 sqrt entropy True 200 17: Macro 0.695738 (0.076918)\n",
      "Testing 92/4320\n",
      "1 2 8 sqrt entropy True 500 17: Weighted 0.797418 (0.066036)\n",
      "1 2 8 sqrt entropy True 500 17: Macro 0.690901 (0.079504)\n",
      "Testing 93/4320\n",
      "1 2 8 sqrt entropy False 50 17: Weighted 0.786530 (0.058258)\n",
      "1 2 8 sqrt entropy False 50 17: Macro 0.682485 (0.082100)\n",
      "Testing 94/4320\n",
      "1 2 8 sqrt entropy False 100 17: Weighted 0.786530 (0.058258)\n",
      "1 2 8 sqrt entropy False 100 17: Macro 0.682485 (0.082100)\n",
      "Testing 95/4320\n",
      "1 2 8 sqrt entropy False 200 17: Weighted 0.786530 (0.058258)\n",
      "1 2 8 sqrt entropy False 200 17: Macro 0.682485 (0.082100)\n",
      "Testing 96/4320\n",
      "1 2 8 sqrt entropy False 500 17: Weighted 0.790393 (0.052767)\n",
      "1 2 8 sqrt entropy False 500 17: Macro 0.687270 (0.074883)\n",
      "Testing 97/4320\n",
      "1 4 3 log2 gini True 50 17: Weighted 0.821696 (0.066944)\n",
      "1 4 3 log2 gini True 50 17: Macro 0.725063 (0.089180)\n",
      "Testing 98/4320\n",
      "1 4 3 log2 gini True 100 17: Weighted 0.800338 (0.059751)\n",
      "1 4 3 log2 gini True 100 17: Macro 0.693782 (0.077238)\n",
      "Testing 99/4320\n",
      "1 4 3 log2 gini True 200 17: Weighted 0.809014 (0.051630)\n",
      "1 4 3 log2 gini True 200 17: Macro 0.702391 (0.068382)\n",
      "Testing 100/4320\n",
      "1 4 3 log2 gini True 500 17: Weighted 0.813941 (0.055478)\n",
      "1 4 3 log2 gini True 500 17: Macro 0.709900 (0.075733)\n",
      "Testing 101/4320\n",
      "1 4 3 log2 gini False 50 17: Weighted 0.804627 (0.072614)\n",
      "1 4 3 log2 gini False 50 17: Macro 0.701445 (0.092151)\n",
      "Testing 102/4320\n",
      "1 4 3 log2 gini False 100 17: Weighted 0.808377 (0.061974)\n",
      "1 4 3 log2 gini False 100 17: Macro 0.709132 (0.077596)\n",
      "Testing 103/4320\n",
      "1 4 3 log2 gini False 200 17: Weighted 0.804540 (0.067263)\n",
      "1 4 3 log2 gini False 200 17: Macro 0.700997 (0.088818)\n",
      "Testing 104/4320\n",
      "1 4 3 log2 gini False 500 17: Weighted 0.804540 (0.067263)\n",
      "1 4 3 log2 gini False 500 17: Macro 0.700997 (0.088818)\n",
      "Testing 105/4320\n",
      "1 4 3 log2 entropy True 50 17: Weighted 0.809935 (0.060810)\n",
      "1 4 3 log2 entropy True 50 17: Macro 0.704820 (0.082311)\n",
      "Testing 106/4320\n",
      "1 4 3 log2 entropy True 100 17: Weighted 0.805728 (0.066727)\n",
      "1 4 3 log2 entropy True 100 17: Macro 0.699607 (0.089460)\n",
      "Testing 107/4320\n",
      "1 4 3 log2 entropy True 200 17: Weighted 0.800801 (0.062924)\n",
      "1 4 3 log2 entropy True 200 17: Macro 0.692099 (0.082395)\n",
      "Testing 108/4320\n",
      "1 4 3 log2 entropy True 500 17: Weighted 0.805007 (0.056975)\n",
      "1 4 3 log2 entropy True 500 17: Macro 0.697312 (0.075095)\n",
      "Testing 109/4320\n",
      "1 4 3 log2 entropy False 50 17: Weighted 0.787834 (0.088117)\n",
      "1 4 3 log2 entropy False 50 17: Macro 0.680688 (0.106489)\n",
      "Testing 110/4320\n",
      "1 4 3 log2 entropy False 100 17: Weighted 0.787834 (0.088117)\n",
      "1 4 3 log2 entropy False 100 17: Macro 0.680688 (0.106489)\n",
      "Testing 111/4320\n",
      "1 4 3 log2 entropy False 200 17: Weighted 0.787834 (0.088117)\n",
      "1 4 3 log2 entropy False 200 17: Macro 0.680688 (0.106489)\n",
      "Testing 112/4320\n",
      "1 4 3 log2 entropy False 500 17: Weighted 0.795172 (0.076239)\n",
      "1 4 3 log2 entropy False 500 17: Macro 0.686046 (0.097885)\n",
      "Testing 113/4320\n",
      "1 4 3 sqrt gini True 50 17: Weighted 0.821696 (0.066944)\n",
      "1 4 3 sqrt gini True 50 17: Macro 0.725063 (0.089180)\n",
      "Testing 114/4320\n",
      "1 4 3 sqrt gini True 100 17: Weighted 0.800338 (0.059751)\n",
      "1 4 3 sqrt gini True 100 17: Macro 0.693782 (0.077238)\n",
      "Testing 115/4320\n",
      "1 4 3 sqrt gini True 200 17: Weighted 0.809014 (0.051630)\n",
      "1 4 3 sqrt gini True 200 17: Macro 0.702391 (0.068382)\n",
      "Testing 116/4320\n",
      "1 4 3 sqrt gini True 500 17: Weighted 0.813941 (0.055478)\n",
      "1 4 3 sqrt gini True 500 17: Macro 0.709900 (0.075733)\n",
      "Testing 117/4320\n",
      "1 4 3 sqrt gini False 50 17: Weighted 0.804627 (0.072614)\n",
      "1 4 3 sqrt gini False 50 17: Macro 0.701445 (0.092151)\n",
      "Testing 118/4320\n",
      "1 4 3 sqrt gini False 100 17: Weighted 0.808377 (0.061974)\n",
      "1 4 3 sqrt gini False 100 17: Macro 0.709132 (0.077596)\n",
      "Testing 119/4320\n",
      "1 4 3 sqrt gini False 200 17: Weighted 0.804540 (0.067263)\n",
      "1 4 3 sqrt gini False 200 17: Macro 0.700997 (0.088818)\n",
      "Testing 120/4320\n",
      "1 4 3 sqrt gini False 500 17: Weighted 0.804540 (0.067263)\n",
      "1 4 3 sqrt gini False 500 17: Macro 0.700997 (0.088818)\n",
      "Testing 121/4320\n",
      "1 4 3 sqrt entropy True 50 17: Weighted 0.809935 (0.060810)\n",
      "1 4 3 sqrt entropy True 50 17: Macro 0.704820 (0.082311)\n",
      "Testing 122/4320\n",
      "1 4 3 sqrt entropy True 100 17: Weighted 0.805728 (0.066727)\n",
      "1 4 3 sqrt entropy True 100 17: Macro 0.699607 (0.089460)\n",
      "Testing 123/4320\n",
      "1 4 3 sqrt entropy True 200 17: Weighted 0.800801 (0.062924)\n",
      "1 4 3 sqrt entropy True 200 17: Macro 0.692099 (0.082395)\n",
      "Testing 124/4320\n",
      "1 4 3 sqrt entropy True 500 17: Weighted 0.805007 (0.056975)\n",
      "1 4 3 sqrt entropy True 500 17: Macro 0.697312 (0.075095)\n",
      "Testing 125/4320\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 4 3 sqrt entropy False 50 17: Weighted 0.787834 (0.088117)\n",
      "1 4 3 sqrt entropy False 50 17: Macro 0.680688 (0.106489)\n",
      "Testing 126/4320\n",
      "1 4 3 sqrt entropy False 100 17: Weighted 0.787834 (0.088117)\n",
      "1 4 3 sqrt entropy False 100 17: Macro 0.680688 (0.106489)\n",
      "Testing 127/4320\n",
      "1 4 3 sqrt entropy False 200 17: Weighted 0.787834 (0.088117)\n",
      "1 4 3 sqrt entropy False 200 17: Macro 0.680688 (0.106489)\n",
      "Testing 128/4320\n",
      "1 4 3 sqrt entropy False 500 17: Weighted 0.795172 (0.076239)\n",
      "1 4 3 sqrt entropy False 500 17: Macro 0.686046 (0.097885)\n",
      "Testing 129/4320\n",
      "1 4 5 log2 gini True 50 17: Weighted 0.821096 (0.069936)\n",
      "1 4 5 log2 gini True 50 17: Macro 0.724977 (0.092961)\n",
      "Testing 130/4320\n",
      "1 4 5 log2 gini True 100 17: Weighted 0.811552 (0.066041)\n",
      "1 4 5 log2 gini True 100 17: Macro 0.707693 (0.085034)\n",
      "Testing 131/4320\n",
      "1 4 5 log2 gini True 200 17: Weighted 0.807129 (0.059688)\n",
      "1 4 5 log2 gini True 200 17: Macro 0.700731 (0.075190)\n",
      "Testing 132/4320\n",
      "1 4 5 log2 gini True 500 17: Weighted 0.816674 (0.064627)\n",
      "1 4 5 log2 gini True 500 17: Macro 0.718015 (0.085470)\n",
      "Testing 133/4320\n",
      "1 4 5 log2 gini False 50 17: Weighted 0.793168 (0.077914)\n",
      "1 4 5 log2 gini False 50 17: Macro 0.683466 (0.114149)\n",
      "Testing 134/4320\n",
      "1 4 5 log2 gini False 100 17: Weighted 0.802167 (0.086156)\n",
      "1 4 5 log2 gini False 100 17: Macro 0.693894 (0.122438)\n",
      "Testing 135/4320\n",
      "1 4 5 log2 gini False 200 17: Weighted 0.808504 (0.076483)\n",
      "1 4 5 log2 gini False 200 17: Macro 0.704126 (0.106322)\n",
      "Testing 136/4320\n",
      "1 4 5 log2 gini False 500 17: Weighted 0.803975 (0.071873)\n",
      "1 4 5 log2 gini False 500 17: Macro 0.700456 (0.103028)\n",
      "Testing 137/4320\n",
      "1 4 5 log2 entropy True 50 17: Weighted 0.814765 (0.067317)\n",
      "1 4 5 log2 entropy True 50 17: Macro 0.717940 (0.085578)\n",
      "Testing 138/4320\n",
      "1 4 5 log2 entropy True 100 17: Weighted 0.814765 (0.067317)\n",
      "1 4 5 log2 entropy True 100 17: Macro 0.717940 (0.085578)\n",
      "Testing 139/4320\n",
      "1 4 5 log2 entropy True 200 17: Weighted 0.807129 (0.059688)\n",
      "1 4 5 log2 entropy True 200 17: Macro 0.700731 (0.075190)\n",
      "Testing 140/4320\n",
      "1 4 5 log2 entropy True 500 17: Weighted 0.807129 (0.059688)\n",
      "1 4 5 log2 entropy True 500 17: Macro 0.700731 (0.075190)\n",
      "Testing 141/4320\n",
      "1 4 5 log2 entropy False 50 17: Weighted 0.789304 (0.078664)\n",
      "1 4 5 log2 entropy False 50 17: Macro 0.677722 (0.113818)\n",
      "Testing 142/4320\n",
      "1 4 5 log2 entropy False 100 17: Weighted 0.788748 (0.081104)\n",
      "1 4 5 log2 entropy False 100 17: Macro 0.673970 (0.113068)\n",
      "Testing 143/4320\n",
      "1 4 5 log2 entropy False 200 17: Weighted 0.785268 (0.082017)\n",
      "1 4 5 log2 entropy False 200 17: Macro 0.669050 (0.113909)\n",
      "Testing 144/4320\n",
      "1 4 5 log2 entropy False 500 17: Weighted 0.785268 (0.082017)\n",
      "1 4 5 log2 entropy False 500 17: Macro 0.669050 (0.113909)\n",
      "Testing 145/4320\n",
      "1 4 5 sqrt gini True 50 17: Weighted 0.821096 (0.069936)\n",
      "1 4 5 sqrt gini True 50 17: Macro 0.724977 (0.092961)\n",
      "Testing 146/4320\n",
      "1 4 5 sqrt gini True 100 17: Weighted 0.811552 (0.066041)\n",
      "1 4 5 sqrt gini True 100 17: Macro 0.707693 (0.085034)\n",
      "Testing 147/4320\n",
      "1 4 5 sqrt gini True 200 17: Weighted 0.807129 (0.059688)\n",
      "1 4 5 sqrt gini True 200 17: Macro 0.700731 (0.075190)\n",
      "Testing 148/4320\n",
      "1 4 5 sqrt gini True 500 17: Weighted 0.816674 (0.064627)\n",
      "1 4 5 sqrt gini True 500 17: Macro 0.718015 (0.085470)\n",
      "Testing 149/4320\n",
      "1 4 5 sqrt gini False 50 17: Weighted 0.793168 (0.077914)\n",
      "1 4 5 sqrt gini False 50 17: Macro 0.683466 (0.114149)\n",
      "Testing 150/4320\n",
      "1 4 5 sqrt gini False 100 17: Weighted 0.802167 (0.086156)\n",
      "1 4 5 sqrt gini False 100 17: Macro 0.693894 (0.122438)\n",
      "Testing 151/4320\n",
      "1 4 5 sqrt gini False 200 17: Weighted 0.808504 (0.076483)\n",
      "1 4 5 sqrt gini False 200 17: Macro 0.704126 (0.106322)\n",
      "Testing 152/4320\n",
      "1 4 5 sqrt gini False 500 17: Weighted 0.803975 (0.071873)\n",
      "1 4 5 sqrt gini False 500 17: Macro 0.700456 (0.103028)\n",
      "Testing 153/4320\n",
      "1 4 5 sqrt entropy True 50 17: Weighted 0.814765 (0.067317)\n",
      "1 4 5 sqrt entropy True 50 17: Macro 0.717940 (0.085578)\n",
      "Testing 154/4320\n",
      "1 4 5 sqrt entropy True 100 17: Weighted 0.814765 (0.067317)\n",
      "1 4 5 sqrt entropy True 100 17: Macro 0.717940 (0.085578)\n",
      "Testing 155/4320\n",
      "1 4 5 sqrt entropy True 200 17: Weighted 0.807129 (0.059688)\n",
      "1 4 5 sqrt entropy True 200 17: Macro 0.700731 (0.075190)\n",
      "Testing 156/4320\n",
      "1 4 5 sqrt entropy True 500 17: Weighted 0.807129 (0.059688)\n",
      "1 4 5 sqrt entropy True 500 17: Macro 0.700731 (0.075190)\n",
      "Testing 157/4320\n",
      "1 4 5 sqrt entropy False 50 17: Weighted 0.789304 (0.078664)\n",
      "1 4 5 sqrt entropy False 50 17: Macro 0.677722 (0.113818)\n",
      "Testing 158/4320\n",
      "1 4 5 sqrt entropy False 100 17: Weighted 0.788748 (0.081104)\n",
      "1 4 5 sqrt entropy False 100 17: Macro 0.673970 (0.113068)\n",
      "Testing 159/4320\n",
      "1 4 5 sqrt entropy False 200 17: Weighted 0.785268 (0.082017)\n",
      "1 4 5 sqrt entropy False 200 17: Macro 0.669050 (0.113909)\n",
      "Testing 160/4320\n",
      "1 4 5 sqrt entropy False 500 17: Weighted 0.785268 (0.082017)\n",
      "1 4 5 sqrt entropy False 500 17: Macro 0.669050 (0.113909)\n",
      "Testing 161/4320\n",
      "1 4 8 log2 gini True 50 17: Weighted 0.790008 (0.071840)\n",
      "1 4 8 log2 gini True 50 17: Macro 0.671413 (0.096067)\n",
      "Testing 162/4320\n",
      "1 4 8 log2 gini True 100 17: Weighted 0.801339 (0.061929)\n",
      "1 4 8 log2 gini True 100 17: Macro 0.689091 (0.081622)\n",
      "Testing 163/4320\n",
      "1 4 8 log2 gini True 200 17: Weighted 0.812490 (0.058329)\n",
      "1 4 8 log2 gini True 200 17: Macro 0.707960 (0.073710)\n",
      "Testing 164/4320\n",
      "1 4 8 log2 gini True 500 17: Weighted 0.812490 (0.058329)\n",
      "1 4 8 log2 gini True 500 17: Macro 0.707960 (0.073710)\n",
      "Testing 165/4320\n",
      "1 4 8 log2 gini False 50 17: Weighted 0.801593 (0.068879)\n",
      "1 4 8 log2 gini False 50 17: Macro 0.694344 (0.089761)\n",
      "Testing 166/4320\n",
      "1 4 8 log2 gini False 100 17: Weighted 0.806556 (0.072334)\n",
      "1 4 8 log2 gini False 100 17: Macro 0.703560 (0.097094)\n",
      "Testing 167/4320\n",
      "1 4 8 log2 gini False 200 17: Weighted 0.793245 (0.068293)\n",
      "1 4 8 log2 gini False 200 17: Macro 0.684455 (0.089994)\n",
      "Testing 168/4320\n",
      "1 4 8 log2 gini False 500 17: Weighted 0.802036 (0.067320)\n",
      "1 4 8 log2 gini False 500 17: Macro 0.696749 (0.090576)\n",
      "Testing 169/4320\n",
      "1 4 8 log2 entropy True 50 17: Weighted 0.802633 (0.057260)\n",
      "1 4 8 log2 entropy True 50 17: Macro 0.696300 (0.068679)\n",
      "Testing 170/4320\n",
      "1 4 8 log2 entropy True 100 17: Weighted 0.800486 (0.052611)\n",
      "1 4 8 log2 entropy True 100 17: Macro 0.694440 (0.060617)\n",
      "Testing 171/4320\n",
      "1 4 8 log2 entropy True 200 17: Weighted 0.799908 (0.056513)\n",
      "1 4 8 log2 entropy True 200 17: Macro 0.694474 (0.066278)\n",
      "Testing 172/4320\n",
      "1 4 8 log2 entropy True 500 17: Weighted 0.804428 (0.062556)\n",
      "1 4 8 log2 entropy True 500 17: Macro 0.701285 (0.075147)\n",
      "Testing 173/4320\n",
      "1 4 8 log2 entropy False 50 17: Weighted 0.786505 (0.070199)\n",
      "1 4 8 log2 entropy False 50 17: Macro 0.675827 (0.101936)\n",
      "Testing 174/4320\n",
      "1 4 8 log2 entropy False 100 17: Weighted 0.799396 (0.064706)\n",
      "1 4 8 log2 entropy False 100 17: Macro 0.694509 (0.083840)\n",
      "Testing 175/4320\n",
      "1 4 8 log2 entropy False 200 17: Weighted 0.795533 (0.069758)\n",
      "1 4 8 log2 entropy False 200 17: Macro 0.689724 (0.090728)\n",
      "Testing 176/4320\n",
      "1 4 8 log2 entropy False 500 17: Weighted 0.799396 (0.064706)\n",
      "1 4 8 log2 entropy False 500 17: Macro 0.694509 (0.083840)\n",
      "Testing 177/4320\n",
      "1 4 8 sqrt gini True 50 17: Weighted 0.790008 (0.071840)\n",
      "1 4 8 sqrt gini True 50 17: Macro 0.671413 (0.096067)\n",
      "Testing 178/4320\n",
      "1 4 8 sqrt gini True 100 17: Weighted 0.801339 (0.061929)\n",
      "1 4 8 sqrt gini True 100 17: Macro 0.689091 (0.081622)\n",
      "Testing 179/4320\n",
      "1 4 8 sqrt gini True 200 17: Weighted 0.812490 (0.058329)\n",
      "1 4 8 sqrt gini True 200 17: Macro 0.707960 (0.073710)\n",
      "Testing 180/4320\n",
      "1 4 8 sqrt gini True 500 17: Weighted 0.812490 (0.058329)\n",
      "1 4 8 sqrt gini True 500 17: Macro 0.707960 (0.073710)\n",
      "Testing 181/4320\n",
      "1 4 8 sqrt gini False 50 17: Weighted 0.801593 (0.068879)\n",
      "1 4 8 sqrt gini False 50 17: Macro 0.694344 (0.089761)\n",
      "Testing 182/4320\n",
      "1 4 8 sqrt gini False 100 17: Weighted 0.806556 (0.072334)\n",
      "1 4 8 sqrt gini False 100 17: Macro 0.703560 (0.097094)\n",
      "Testing 183/4320\n",
      "1 4 8 sqrt gini False 200 17: Weighted 0.793245 (0.068293)\n",
      "1 4 8 sqrt gini False 200 17: Macro 0.684455 (0.089994)\n",
      "Testing 184/4320\n",
      "1 4 8 sqrt gini False 500 17: Weighted 0.802036 (0.067320)\n",
      "1 4 8 sqrt gini False 500 17: Macro 0.696749 (0.090576)\n",
      "Testing 185/4320\n",
      "1 4 8 sqrt entropy True 50 17: Weighted 0.802633 (0.057260)\n",
      "1 4 8 sqrt entropy True 50 17: Macro 0.696300 (0.068679)\n",
      "Testing 186/4320\n",
      "1 4 8 sqrt entropy True 100 17: Weighted 0.800486 (0.052611)\n",
      "1 4 8 sqrt entropy True 100 17: Macro 0.694440 (0.060617)\n",
      "Testing 187/4320\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 4 8 sqrt entropy True 200 17: Weighted 0.799908 (0.056513)\n",
      "1 4 8 sqrt entropy True 200 17: Macro 0.694474 (0.066278)\n",
      "Testing 188/4320\n",
      "1 4 8 sqrt entropy True 500 17: Weighted 0.804428 (0.062556)\n",
      "1 4 8 sqrt entropy True 500 17: Macro 0.701285 (0.075147)\n",
      "Testing 189/4320\n",
      "1 4 8 sqrt entropy False 50 17: Weighted 0.786505 (0.070199)\n",
      "1 4 8 sqrt entropy False 50 17: Macro 0.675827 (0.101936)\n",
      "Testing 190/4320\n",
      "1 4 8 sqrt entropy False 100 17: Weighted 0.799396 (0.064706)\n",
      "1 4 8 sqrt entropy False 100 17: Macro 0.694509 (0.083840)\n",
      "Testing 191/4320\n",
      "1 4 8 sqrt entropy False 200 17: Weighted 0.795533 (0.069758)\n",
      "1 4 8 sqrt entropy False 200 17: Macro 0.689724 (0.090728)\n",
      "Testing 192/4320\n",
      "1 4 8 sqrt entropy False 500 17: Weighted 0.799396 (0.064706)\n",
      "1 4 8 sqrt entropy False 500 17: Macro 0.694509 (0.083840)\n",
      "Testing 193/4320\n",
      "1 6 3 log2 gini True 50 17: Weighted 0.816826 (0.060889)\n",
      "1 6 3 log2 gini True 50 17: Macro 0.714827 (0.078040)\n",
      "Testing 194/4320\n",
      "1 6 3 log2 gini True 100 17: Weighted 0.805007 (0.056975)\n",
      "1 6 3 log2 gini True 100 17: Macro 0.697312 (0.075095)\n",
      "Testing 195/4320\n",
      "1 6 3 log2 gini True 200 17: Weighted 0.809014 (0.051630)\n",
      "1 6 3 log2 gini True 200 17: Macro 0.702391 (0.068382)\n",
      "Testing 196/4320\n",
      "1 6 3 log2 gini True 500 17: Weighted 0.813941 (0.055478)\n",
      "1 6 3 log2 gini True 500 17: Macro 0.709900 (0.075733)\n",
      "Testing 197/4320\n",
      "1 6 3 log2 gini False 50 17: Weighted 0.799923 (0.073917)\n",
      "1 6 3 log2 gini False 50 17: Macro 0.697877 (0.093328)\n",
      "Testing 198/4320\n",
      "1 6 3 log2 gini False 100 17: Weighted 0.799923 (0.073917)\n",
      "1 6 3 log2 gini False 100 17: Macro 0.697877 (0.093328)\n",
      "Testing 199/4320\n",
      "1 6 3 log2 gini False 200 17: Weighted 0.804540 (0.067263)\n",
      "1 6 3 log2 gini False 200 17: Macro 0.700997 (0.088818)\n",
      "Testing 200/4320\n",
      "1 6 3 log2 gini False 500 17: Weighted 0.804540 (0.067263)\n",
      "1 6 3 log2 gini False 500 17: Macro 0.700997 (0.088818)\n",
      "Testing 201/4320\n",
      "1 6 3 log2 entropy True 50 17: Weighted 0.809935 (0.060810)\n",
      "1 6 3 log2 entropy True 50 17: Macro 0.704820 (0.082311)\n",
      "Testing 202/4320\n",
      "1 6 3 log2 entropy True 100 17: Weighted 0.809935 (0.060810)\n",
      "1 6 3 log2 entropy True 100 17: Macro 0.704820 (0.082311)\n",
      "Testing 203/4320\n",
      "1 6 3 log2 entropy True 200 17: Weighted 0.805007 (0.056975)\n",
      "1 6 3 log2 entropy True 200 17: Macro 0.697312 (0.075095)\n",
      "Testing 204/4320\n",
      "1 6 3 log2 entropy True 500 17: Weighted 0.805007 (0.056975)\n",
      "1 6 3 log2 entropy True 500 17: Macro 0.697312 (0.075095)\n",
      "Testing 205/4320\n",
      "1 6 3 log2 entropy False 50 17: Weighted 0.787834 (0.088117)\n",
      "1 6 3 log2 entropy False 50 17: Macro 0.680688 (0.106489)\n",
      "Testing 206/4320\n",
      "1 6 3 log2 entropy False 100 17: Weighted 0.787834 (0.088117)\n",
      "1 6 3 log2 entropy False 100 17: Macro 0.680688 (0.106489)\n",
      "Testing 207/4320\n",
      "1 6 3 log2 entropy False 200 17: Weighted 0.787834 (0.088117)\n",
      "1 6 3 log2 entropy False 200 17: Macro 0.680688 (0.106489)\n",
      "Testing 208/4320\n",
      "1 6 3 log2 entropy False 500 17: Weighted 0.787834 (0.088117)\n",
      "1 6 3 log2 entropy False 500 17: Macro 0.680688 (0.106489)\n",
      "Testing 209/4320\n",
      "1 6 3 sqrt gini True 50 17: Weighted 0.816826 (0.060889)\n",
      "1 6 3 sqrt gini True 50 17: Macro 0.714827 (0.078040)\n",
      "Testing 210/4320\n",
      "1 6 3 sqrt gini True 100 17: Weighted 0.805007 (0.056975)\n",
      "1 6 3 sqrt gini True 100 17: Macro 0.697312 (0.075095)\n",
      "Testing 211/4320\n",
      "1 6 3 sqrt gini True 200 17: Weighted 0.809014 (0.051630)\n",
      "1 6 3 sqrt gini True 200 17: Macro 0.702391 (0.068382)\n",
      "Testing 212/4320\n",
      "1 6 3 sqrt gini True 500 17: Weighted 0.813941 (0.055478)\n",
      "1 6 3 sqrt gini True 500 17: Macro 0.709900 (0.075733)\n",
      "Testing 213/4320\n",
      "1 6 3 sqrt gini False 50 17: Weighted 0.799923 (0.073917)\n",
      "1 6 3 sqrt gini False 50 17: Macro 0.697877 (0.093328)\n",
      "Testing 214/4320\n",
      "1 6 3 sqrt gini False 100 17: Weighted 0.799923 (0.073917)\n",
      "1 6 3 sqrt gini False 100 17: Macro 0.697877 (0.093328)\n",
      "Testing 215/4320\n",
      "1 6 3 sqrt gini False 200 17: Weighted 0.804540 (0.067263)\n",
      "1 6 3 sqrt gini False 200 17: Macro 0.700997 (0.088818)\n",
      "Testing 216/4320\n",
      "1 6 3 sqrt gini False 500 17: Weighted 0.804540 (0.067263)\n",
      "1 6 3 sqrt gini False 500 17: Macro 0.700997 (0.088818)\n",
      "Testing 217/4320\n",
      "1 6 3 sqrt entropy True 50 17: Weighted 0.809935 (0.060810)\n",
      "1 6 3 sqrt entropy True 50 17: Macro 0.704820 (0.082311)\n",
      "Testing 218/4320\n",
      "1 6 3 sqrt entropy True 100 17: Weighted 0.809935 (0.060810)\n",
      "1 6 3 sqrt entropy True 100 17: Macro 0.704820 (0.082311)\n",
      "Testing 219/4320\n",
      "1 6 3 sqrt entropy True 200 17: Weighted 0.805007 (0.056975)\n",
      "1 6 3 sqrt entropy True 200 17: Macro 0.697312 (0.075095)\n",
      "Testing 220/4320\n",
      "1 6 3 sqrt entropy True 500 17: Weighted 0.805007 (0.056975)\n",
      "1 6 3 sqrt entropy True 500 17: Macro 0.697312 (0.075095)\n",
      "Testing 221/4320\n",
      "1 6 3 sqrt entropy False 50 17: Weighted 0.787834 (0.088117)\n",
      "1 6 3 sqrt entropy False 50 17: Macro 0.680688 (0.106489)\n",
      "Testing 222/4320\n",
      "1 6 3 sqrt entropy False 100 17: Weighted 0.787834 (0.088117)\n",
      "1 6 3 sqrt entropy False 100 17: Macro 0.680688 (0.106489)\n",
      "Testing 223/4320\n",
      "1 6 3 sqrt entropy False 200 17: Weighted 0.787834 (0.088117)\n",
      "1 6 3 sqrt entropy False 200 17: Macro 0.680688 (0.106489)\n",
      "Testing 224/4320\n",
      "1 6 3 sqrt entropy False 500 17: Weighted 0.787834 (0.088117)\n",
      "1 6 3 sqrt entropy False 500 17: Macro 0.680688 (0.106489)\n",
      "Testing 225/4320\n",
      "1 6 5 log2 gini True 50 17: Weighted 0.821047 (0.065875)\n",
      "1 6 5 log2 gini True 50 17: Macro 0.718434 (0.086014)\n",
      "Testing 226/4320\n",
      "1 6 5 log2 gini True 100 17: Weighted 0.811863 (0.058581)\n",
      "1 6 5 log2 gini True 100 17: Macro 0.704330 (0.074545)\n",
      "Testing 227/4320\n",
      "1 6 5 log2 gini True 200 17: Weighted 0.803722 (0.061157)\n",
      "1 6 5 log2 gini True 200 17: Macro 0.695738 (0.076918)\n",
      "Testing 228/4320\n",
      "1 6 5 log2 gini True 500 17: Weighted 0.816674 (0.064627)\n",
      "1 6 5 log2 gini True 500 17: Macro 0.718015 (0.085470)\n",
      "Testing 229/4320\n",
      "1 6 5 log2 gini False 50 17: Weighted 0.793168 (0.077914)\n",
      "1 6 5 log2 gini False 50 17: Macro 0.683466 (0.114149)\n",
      "Testing 230/4320\n",
      "1 6 5 log2 gini False 100 17: Weighted 0.804368 (0.082759)\n",
      "1 6 5 log2 gini False 100 17: Macro 0.694798 (0.120997)\n",
      "Testing 231/4320\n",
      "1 6 5 log2 gini False 200 17: Weighted 0.808504 (0.076483)\n",
      "1 6 5 log2 gini False 200 17: Macro 0.704126 (0.106322)\n",
      "Testing 232/4320\n",
      "1 6 5 log2 gini False 500 17: Weighted 0.803975 (0.071873)\n",
      "1 6 5 log2 gini False 500 17: Macro 0.700456 (0.103028)\n",
      "Testing 233/4320\n",
      "1 6 5 log2 entropy True 50 17: Weighted 0.811358 (0.069001)\n",
      "1 6 5 log2 entropy True 50 17: Macro 0.712947 (0.088081)\n",
      "Testing 234/4320\n",
      "1 6 5 log2 entropy True 100 17: Weighted 0.819498 (0.065790)\n",
      "1 6 5 log2 entropy True 100 17: Macro 0.721539 (0.084280)\n",
      "Testing 235/4320\n",
      "1 6 5 log2 entropy True 200 17: Weighted 0.811863 (0.058581)\n",
      "1 6 5 log2 entropy True 200 17: Macro 0.704330 (0.074545)\n",
      "Testing 236/4320\n",
      "1 6 5 log2 entropy True 500 17: Weighted 0.811863 (0.058581)\n",
      "1 6 5 log2 entropy True 500 17: Macro 0.704330 (0.074545)\n",
      "Testing 237/4320\n",
      "1 6 5 log2 entropy False 50 17: Weighted 0.793577 (0.072184)\n",
      "1 6 5 log2 entropy False 50 17: Macro 0.687441 (0.098753)\n",
      "Testing 238/4320\n",
      "1 6 5 log2 entropy False 100 17: Weighted 0.788748 (0.081104)\n",
      "1 6 5 log2 entropy False 100 17: Macro 0.673970 (0.113068)\n",
      "Testing 239/4320\n",
      "1 6 5 log2 entropy False 200 17: Weighted 0.780739 (0.076371)\n",
      "1 6 5 log2 entropy False 200 17: Macro 0.665380 (0.109674)\n",
      "Testing 240/4320\n",
      "1 6 5 log2 entropy False 500 17: Weighted 0.780739 (0.076371)\n",
      "1 6 5 log2 entropy False 500 17: Macro 0.665380 (0.109674)\n",
      "Testing 241/4320\n",
      "1 6 5 sqrt gini True 50 17: Weighted 0.821047 (0.065875)\n",
      "1 6 5 sqrt gini True 50 17: Macro 0.718434 (0.086014)\n",
      "Testing 242/4320\n",
      "1 6 5 sqrt gini True 100 17: Weighted 0.811863 (0.058581)\n",
      "1 6 5 sqrt gini True 100 17: Macro 0.704330 (0.074545)\n",
      "Testing 243/4320\n",
      "1 6 5 sqrt gini True 200 17: Weighted 0.803722 (0.061157)\n",
      "1 6 5 sqrt gini True 200 17: Macro 0.695738 (0.076918)\n",
      "Testing 244/4320\n",
      "1 6 5 sqrt gini True 500 17: Weighted 0.816674 (0.064627)\n",
      "1 6 5 sqrt gini True 500 17: Macro 0.718015 (0.085470)\n",
      "Testing 245/4320\n",
      "1 6 5 sqrt gini False 50 17: Weighted 0.793168 (0.077914)\n",
      "1 6 5 sqrt gini False 50 17: Macro 0.683466 (0.114149)\n",
      "Testing 246/4320\n",
      "1 6 5 sqrt gini False 100 17: Weighted 0.804368 (0.082759)\n",
      "1 6 5 sqrt gini False 100 17: Macro 0.694798 (0.120997)\n",
      "Testing 247/4320\n",
      "1 6 5 sqrt gini False 200 17: Weighted 0.808504 (0.076483)\n",
      "1 6 5 sqrt gini False 200 17: Macro 0.704126 (0.106322)\n",
      "Testing 248/4320\n",
      "1 6 5 sqrt gini False 500 17: Weighted 0.803975 (0.071873)\n",
      "1 6 5 sqrt gini False 500 17: Macro 0.700456 (0.103028)\n",
      "Testing 249/4320\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 6 5 sqrt entropy True 50 17: Weighted 0.811358 (0.069001)\n",
      "1 6 5 sqrt entropy True 50 17: Macro 0.712947 (0.088081)\n",
      "Testing 250/4320\n",
      "1 6 5 sqrt entropy True 100 17: Weighted 0.819498 (0.065790)\n",
      "1 6 5 sqrt entropy True 100 17: Macro 0.721539 (0.084280)\n",
      "Testing 251/4320\n",
      "1 6 5 sqrt entropy True 200 17: Weighted 0.811863 (0.058581)\n",
      "1 6 5 sqrt entropy True 200 17: Macro 0.704330 (0.074545)\n",
      "Testing 252/4320\n",
      "1 6 5 sqrt entropy True 500 17: Weighted 0.811863 (0.058581)\n",
      "1 6 5 sqrt entropy True 500 17: Macro 0.704330 (0.074545)\n",
      "Testing 253/4320\n",
      "1 6 5 sqrt entropy False 50 17: Weighted 0.793577 (0.072184)\n",
      "1 6 5 sqrt entropy False 50 17: Macro 0.687441 (0.098753)\n",
      "Testing 254/4320\n",
      "1 6 5 sqrt entropy False 100 17: Weighted 0.788748 (0.081104)\n",
      "1 6 5 sqrt entropy False 100 17: Macro 0.673970 (0.113068)\n",
      "Testing 255/4320\n",
      "1 6 5 sqrt entropy False 200 17: Weighted 0.780739 (0.076371)\n",
      "1 6 5 sqrt entropy False 200 17: Macro 0.665380 (0.109674)\n",
      "Testing 256/4320\n",
      "1 6 5 sqrt entropy False 500 17: Weighted 0.780739 (0.076371)\n",
      "1 6 5 sqrt entropy False 500 17: Macro 0.665380 (0.109674)\n",
      "Testing 257/4320\n",
      "1 6 8 log2 gini True 50 17: Weighted 0.802590 (0.077550)\n",
      "1 6 8 log2 gini True 50 17: Macro 0.689964 (0.105595)\n",
      "Testing 258/4320\n",
      "1 6 8 log2 gini True 100 17: Weighted 0.801407 (0.064137)\n",
      "1 6 8 log2 gini True 100 17: Macro 0.691038 (0.083251)\n",
      "Testing 259/4320\n",
      "1 6 8 log2 gini True 200 17: Weighted 0.809010 (0.060963)\n",
      "1 6 8 log2 gini True 200 17: Macro 0.703040 (0.077192)\n",
      "Testing 260/4320\n",
      "1 6 8 log2 gini True 500 17: Weighted 0.812490 (0.058329)\n",
      "1 6 8 log2 gini True 500 17: Macro 0.707960 (0.073710)\n",
      "Testing 261/4320\n",
      "1 6 8 log2 gini False 50 17: Weighted 0.802692 (0.077245)\n",
      "1 6 8 log2 gini False 50 17: Macro 0.698775 (0.103519)\n",
      "Testing 262/4320\n",
      "1 6 8 log2 gini False 100 17: Weighted 0.802692 (0.077245)\n",
      "1 6 8 log2 gini False 100 17: Macro 0.698775 (0.103519)\n",
      "Testing 263/4320\n",
      "1 6 8 log2 gini False 200 17: Weighted 0.797765 (0.073782)\n",
      "1 6 8 log2 gini False 200 17: Macro 0.691266 (0.097414)\n",
      "Testing 264/4320\n",
      "1 6 8 log2 gini False 500 17: Weighted 0.802946 (0.075124)\n",
      "1 6 8 log2 gini False 500 17: Macro 0.698501 (0.100589)\n",
      "Testing 265/4320\n",
      "1 6 8 log2 entropy True 50 17: Weighted 0.816062 (0.066802)\n",
      "1 6 8 log2 entropy True 50 17: Macro 0.716514 (0.086212)\n",
      "Testing 266/4320\n",
      "1 6 8 log2 entropy True 100 17: Weighted 0.818774 (0.057020)\n",
      "1 6 8 log2 entropy True 100 17: Macro 0.716623 (0.069636)\n",
      "Testing 267/4320\n",
      "1 6 8 log2 entropy True 200 17: Weighted 0.807343 (0.052721)\n",
      "1 6 8 log2 entropy True 200 17: Macro 0.697519 (0.065910)\n",
      "Testing 268/4320\n",
      "1 6 8 log2 entropy True 500 17: Weighted 0.806518 (0.061942)\n",
      "1 6 8 log2 entropy True 500 17: Macro 0.699230 (0.075691)\n",
      "Testing 269/4320\n",
      "1 6 8 log2 entropy False 50 17: Weighted 0.791034 (0.075960)\n",
      "1 6 8 log2 entropy False 50 17: Macro 0.679497 (0.106119)\n",
      "Testing 270/4320\n",
      "1 6 8 log2 entropy False 100 17: Weighted 0.794667 (0.070927)\n",
      "1 6 8 log2 entropy False 100 17: Macro 0.683740 (0.099640)\n",
      "Testing 271/4320\n",
      "1 6 8 log2 entropy False 200 17: Weighted 0.795533 (0.069758)\n",
      "1 6 8 log2 entropy False 200 17: Macro 0.689724 (0.090728)\n",
      "Testing 272/4320\n",
      "1 6 8 log2 entropy False 500 17: Weighted 0.795533 (0.069758)\n",
      "1 6 8 log2 entropy False 500 17: Macro 0.689724 (0.090728)\n",
      "Testing 273/4320\n",
      "1 6 8 sqrt gini True 50 17: Weighted 0.802590 (0.077550)\n",
      "1 6 8 sqrt gini True 50 17: Macro 0.689964 (0.105595)\n",
      "Testing 274/4320\n",
      "1 6 8 sqrt gini True 100 17: Weighted 0.801407 (0.064137)\n",
      "1 6 8 sqrt gini True 100 17: Macro 0.691038 (0.083251)\n",
      "Testing 275/4320\n",
      "1 6 8 sqrt gini True 200 17: Weighted 0.809010 (0.060963)\n",
      "1 6 8 sqrt gini True 200 17: Macro 0.703040 (0.077192)\n",
      "Testing 276/4320\n",
      "1 6 8 sqrt gini True 500 17: Weighted 0.812490 (0.058329)\n",
      "1 6 8 sqrt gini True 500 17: Macro 0.707960 (0.073710)\n",
      "Testing 277/4320\n",
      "1 6 8 sqrt gini False 50 17: Weighted 0.802692 (0.077245)\n",
      "1 6 8 sqrt gini False 50 17: Macro 0.698775 (0.103519)\n",
      "Testing 278/4320\n",
      "1 6 8 sqrt gini False 100 17: Weighted 0.802692 (0.077245)\n",
      "1 6 8 sqrt gini False 100 17: Macro 0.698775 (0.103519)\n",
      "Testing 279/4320\n",
      "1 6 8 sqrt gini False 200 17: Weighted 0.797765 (0.073782)\n",
      "1 6 8 sqrt gini False 200 17: Macro 0.691266 (0.097414)\n",
      "Testing 280/4320\n",
      "1 6 8 sqrt gini False 500 17: Weighted 0.802946 (0.075124)\n",
      "1 6 8 sqrt gini False 500 17: Macro 0.698501 (0.100589)\n",
      "Testing 281/4320\n",
      "1 6 8 sqrt entropy True 50 17: Weighted 0.816062 (0.066802)\n",
      "1 6 8 sqrt entropy True 50 17: Macro 0.716514 (0.086212)\n",
      "Testing 282/4320\n",
      "1 6 8 sqrt entropy True 100 17: Weighted 0.818774 (0.057020)\n",
      "1 6 8 sqrt entropy True 100 17: Macro 0.716623 (0.069636)\n",
      "Testing 283/4320\n",
      "1 6 8 sqrt entropy True 200 17: Weighted 0.807343 (0.052721)\n",
      "1 6 8 sqrt entropy True 200 17: Macro 0.697519 (0.065910)\n",
      "Testing 284/4320\n",
      "1 6 8 sqrt entropy True 500 17: Weighted 0.806518 (0.061942)\n",
      "1 6 8 sqrt entropy True 500 17: Macro 0.699230 (0.075691)\n",
      "Testing 285/4320\n",
      "1 6 8 sqrt entropy False 50 17: Weighted 0.791034 (0.075960)\n",
      "1 6 8 sqrt entropy False 50 17: Macro 0.679497 (0.106119)\n",
      "Testing 286/4320\n",
      "1 6 8 sqrt entropy False 100 17: Weighted 0.794667 (0.070927)\n",
      "1 6 8 sqrt entropy False 100 17: Macro 0.683740 (0.099640)\n",
      "Testing 287/4320\n",
      "1 6 8 sqrt entropy False 200 17: Weighted 0.795533 (0.069758)\n",
      "1 6 8 sqrt entropy False 200 17: Macro 0.689724 (0.090728)\n",
      "Testing 288/4320\n",
      "1 6 8 sqrt entropy False 500 17: Weighted 0.795533 (0.069758)\n",
      "1 6 8 sqrt entropy False 500 17: Macro 0.689724 (0.090728)\n",
      "Testing 289/4320\n",
      "3 2 3 log2 gini True 50 17: Weighted 0.818015 (0.060054)\n",
      "3 2 3 log2 gini True 50 17: Macro 0.713437 (0.079013)\n",
      "Testing 290/4320\n",
      "3 2 3 log2 gini True 100 17: Weighted 0.805007 (0.056975)\n",
      "3 2 3 log2 gini True 100 17: Macro 0.697312 (0.075095)\n",
      "Testing 291/4320\n",
      "3 2 3 log2 gini True 200 17: Weighted 0.809014 (0.051630)\n",
      "3 2 3 log2 gini True 200 17: Macro 0.702391 (0.068382)\n",
      "Testing 292/4320\n",
      "3 2 3 log2 gini True 500 17: Weighted 0.813941 (0.055478)\n",
      "3 2 3 log2 gini True 500 17: Macro 0.709900 (0.075733)\n",
      "Testing 293/4320\n",
      "3 2 3 log2 gini False 50 17: Weighted 0.804627 (0.072614)\n",
      "3 2 3 log2 gini False 50 17: Macro 0.701445 (0.092151)\n",
      "Testing 294/4320\n",
      "3 2 3 log2 gini False 100 17: Weighted 0.804627 (0.072614)\n",
      "3 2 3 log2 gini False 100 17: Macro 0.701445 (0.092151)\n",
      "Testing 295/4320\n",
      "3 2 3 log2 gini False 200 17: Weighted 0.809244 (0.065497)\n",
      "3 2 3 log2 gini False 200 17: Macro 0.704564 (0.087453)\n",
      "Testing 296/4320\n",
      "3 2 3 log2 gini False 500 17: Weighted 0.809244 (0.065497)\n",
      "3 2 3 log2 gini False 500 17: Macro 0.704564 (0.087453)\n",
      "Testing 297/4320\n",
      "3 2 3 log2 entropy True 50 17: Weighted 0.809935 (0.060810)\n",
      "3 2 3 log2 entropy True 50 17: Macro 0.704820 (0.082311)\n",
      "Testing 298/4320\n",
      "3 2 3 log2 entropy True 100 17: Weighted 0.809935 (0.060810)\n",
      "3 2 3 log2 entropy True 100 17: Macro 0.704820 (0.082311)\n",
      "Testing 299/4320\n",
      "3 2 3 log2 entropy True 200 17: Weighted 0.812527 (0.049802)\n",
      "3 2 3 log2 entropy True 200 17: Macro 0.710740 (0.060852)\n",
      "Testing 300/4320\n",
      "3 2 3 log2 entropy True 500 17: Weighted 0.808523 (0.055575)\n",
      "3 2 3 log2 entropy True 500 17: Macro 0.702270 (0.072850)\n",
      "Testing 301/4320\n",
      "3 2 3 log2 entropy False 50 17: Weighted 0.787834 (0.088117)\n",
      "3 2 3 log2 entropy False 50 17: Macro 0.680688 (0.106489)\n",
      "Testing 302/4320\n",
      "3 2 3 log2 entropy False 100 17: Weighted 0.787834 (0.088117)\n",
      "3 2 3 log2 entropy False 100 17: Macro 0.680688 (0.106489)\n",
      "Testing 303/4320\n",
      "3 2 3 log2 entropy False 200 17: Weighted 0.787834 (0.088117)\n",
      "3 2 3 log2 entropy False 200 17: Macro 0.680688 (0.106489)\n",
      "Testing 304/4320\n",
      "3 2 3 log2 entropy False 500 17: Weighted 0.787834 (0.088117)\n",
      "3 2 3 log2 entropy False 500 17: Macro 0.680688 (0.106489)\n",
      "Testing 305/4320\n",
      "3 2 3 sqrt gini True 50 17: Weighted 0.818015 (0.060054)\n",
      "3 2 3 sqrt gini True 50 17: Macro 0.713437 (0.079013)\n",
      "Testing 306/4320\n",
      "3 2 3 sqrt gini True 100 17: Weighted 0.805007 (0.056975)\n",
      "3 2 3 sqrt gini True 100 17: Macro 0.697312 (0.075095)\n",
      "Testing 307/4320\n",
      "3 2 3 sqrt gini True 200 17: Weighted 0.809014 (0.051630)\n",
      "3 2 3 sqrt gini True 200 17: Macro 0.702391 (0.068382)\n",
      "Testing 308/4320\n",
      "3 2 3 sqrt gini True 500 17: Weighted 0.813941 (0.055478)\n",
      "3 2 3 sqrt gini True 500 17: Macro 0.709900 (0.075733)\n",
      "Testing 309/4320\n",
      "3 2 3 sqrt gini False 50 17: Weighted 0.804627 (0.072614)\n",
      "3 2 3 sqrt gini False 50 17: Macro 0.701445 (0.092151)\n",
      "Testing 310/4320\n",
      "3 2 3 sqrt gini False 100 17: Weighted 0.804627 (0.072614)\n",
      "3 2 3 sqrt gini False 100 17: Macro 0.701445 (0.092151)\n",
      "Testing 311/4320\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 2 3 sqrt gini False 200 17: Weighted 0.809244 (0.065497)\n",
      "3 2 3 sqrt gini False 200 17: Macro 0.704564 (0.087453)\n",
      "Testing 312/4320\n",
      "3 2 3 sqrt gini False 500 17: Weighted 0.809244 (0.065497)\n",
      "3 2 3 sqrt gini False 500 17: Macro 0.704564 (0.087453)\n",
      "Testing 313/4320\n",
      "3 2 3 sqrt entropy True 50 17: Weighted 0.809935 (0.060810)\n",
      "3 2 3 sqrt entropy True 50 17: Macro 0.704820 (0.082311)\n",
      "Testing 314/4320\n",
      "3 2 3 sqrt entropy True 100 17: Weighted 0.809935 (0.060810)\n",
      "3 2 3 sqrt entropy True 100 17: Macro 0.704820 (0.082311)\n",
      "Testing 315/4320\n",
      "3 2 3 sqrt entropy True 200 17: Weighted 0.812527 (0.049802)\n",
      "3 2 3 sqrt entropy True 200 17: Macro 0.710740 (0.060852)\n",
      "Testing 316/4320\n",
      "3 2 3 sqrt entropy True 500 17: Weighted 0.808523 (0.055575)\n",
      "3 2 3 sqrt entropy True 500 17: Macro 0.702270 (0.072850)\n",
      "Testing 317/4320\n",
      "3 2 3 sqrt entropy False 50 17: Weighted 0.787834 (0.088117)\n",
      "3 2 3 sqrt entropy False 50 17: Macro 0.680688 (0.106489)\n",
      "Testing 318/4320\n",
      "3 2 3 sqrt entropy False 100 17: Weighted 0.787834 (0.088117)\n",
      "3 2 3 sqrt entropy False 100 17: Macro 0.680688 (0.106489)\n",
      "Testing 319/4320\n",
      "3 2 3 sqrt entropy False 200 17: Weighted 0.787834 (0.088117)\n",
      "3 2 3 sqrt entropy False 200 17: Macro 0.680688 (0.106489)\n",
      "Testing 320/4320\n",
      "3 2 3 sqrt entropy False 500 17: Weighted 0.787834 (0.088117)\n",
      "3 2 3 sqrt entropy False 500 17: Macro 0.680688 (0.106489)\n",
      "Testing 321/4320\n",
      "3 2 5 log2 gini True 50 17: Weighted 0.817971 (0.064052)\n",
      "3 2 5 log2 gini True 50 17: Macro 0.716589 (0.086105)\n",
      "Testing 322/4320\n",
      "3 2 5 log2 gini True 100 17: Weighted 0.811863 (0.058581)\n",
      "3 2 5 log2 gini True 100 17: Macro 0.704330 (0.074545)\n",
      "Testing 323/4320\n",
      "3 2 5 log2 gini True 200 17: Weighted 0.808426 (0.059274)\n",
      "3 2 5 log2 gini True 200 17: Macro 0.699306 (0.075587)\n",
      "Testing 324/4320\n",
      "3 2 5 log2 gini True 500 17: Weighted 0.813188 (0.061148)\n",
      "3 2 5 log2 gini True 500 17: Macro 0.706448 (0.078733)\n",
      "Testing 325/4320\n",
      "3 2 5 log2 gini False 50 17: Weighted 0.808216 (0.082181)\n",
      "3 2 5 log2 gini False 50 17: Macro 0.698926 (0.120768)\n",
      "Testing 326/4320\n",
      "3 2 5 log2 gini False 100 17: Weighted 0.808216 (0.082181)\n",
      "3 2 5 log2 gini False 100 17: Macro 0.698926 (0.120768)\n",
      "Testing 327/4320\n",
      "3 2 5 log2 gini False 200 17: Weighted 0.813237 (0.075536)\n",
      "3 2 5 log2 gini False 200 17: Macro 0.707725 (0.105751)\n",
      "Testing 328/4320\n",
      "3 2 5 log2 gini False 500 17: Weighted 0.813237 (0.075536)\n",
      "3 2 5 log2 gini False 500 17: Macro 0.707725 (0.105751)\n",
      "Testing 329/4320\n",
      "3 2 5 log2 entropy True 50 17: Weighted 0.814455 (0.065778)\n",
      "3 2 5 log2 entropy True 50 17: Macro 0.711632 (0.088816)\n",
      "Testing 330/4320\n",
      "3 2 5 log2 entropy True 100 17: Weighted 0.821407 (0.062892)\n",
      "3 2 5 log2 entropy True 100 17: Macro 0.721614 (0.084166)\n",
      "Testing 331/4320\n",
      "3 2 5 log2 entropy True 200 17: Weighted 0.808426 (0.059274)\n",
      "3 2 5 log2 entropy True 200 17: Macro 0.699306 (0.075587)\n",
      "Testing 332/4320\n",
      "3 2 5 log2 entropy True 500 17: Weighted 0.811863 (0.058581)\n",
      "3 2 5 log2 entropy True 500 17: Macro 0.704330 (0.074545)\n",
      "Testing 333/4320\n",
      "3 2 5 log2 entropy False 50 17: Weighted 0.797726 (0.074020)\n",
      "3 2 5 log2 entropy False 50 17: Macro 0.687256 (0.097662)\n",
      "Testing 334/4320\n",
      "3 2 5 log2 entropy False 100 17: Weighted 0.789937 (0.080892)\n",
      "3 2 5 log2 entropy False 100 17: Macro 0.672580 (0.113241)\n",
      "Testing 335/4320\n",
      "3 2 5 log2 entropy False 200 17: Weighted 0.792137 (0.077612)\n",
      "3 2 5 log2 entropy False 200 17: Macro 0.673483 (0.111854)\n",
      "Testing 336/4320\n",
      "3 2 5 log2 entropy False 500 17: Weighted 0.792137 (0.077612)\n",
      "3 2 5 log2 entropy False 500 17: Macro 0.673483 (0.111854)\n",
      "Testing 337/4320\n",
      "3 2 5 sqrt gini True 50 17: Weighted 0.817971 (0.064052)\n",
      "3 2 5 sqrt gini True 50 17: Macro 0.716589 (0.086105)\n",
      "Testing 338/4320\n",
      "3 2 5 sqrt gini True 100 17: Weighted 0.811863 (0.058581)\n",
      "3 2 5 sqrt gini True 100 17: Macro 0.704330 (0.074545)\n",
      "Testing 339/4320\n",
      "3 2 5 sqrt gini True 200 17: Weighted 0.808426 (0.059274)\n",
      "3 2 5 sqrt gini True 200 17: Macro 0.699306 (0.075587)\n",
      "Testing 340/4320\n",
      "3 2 5 sqrt gini True 500 17: Weighted 0.813188 (0.061148)\n",
      "3 2 5 sqrt gini True 500 17: Macro 0.706448 (0.078733)\n",
      "Testing 341/4320\n",
      "3 2 5 sqrt gini False 50 17: Weighted 0.808216 (0.082181)\n",
      "3 2 5 sqrt gini False 50 17: Macro 0.698926 (0.120768)\n",
      "Testing 342/4320\n",
      "3 2 5 sqrt gini False 100 17: Weighted 0.808216 (0.082181)\n",
      "3 2 5 sqrt gini False 100 17: Macro 0.698926 (0.120768)\n",
      "Testing 343/4320\n",
      "3 2 5 sqrt gini False 200 17: Weighted 0.813237 (0.075536)\n",
      "3 2 5 sqrt gini False 200 17: Macro 0.707725 (0.105751)\n",
      "Testing 344/4320\n",
      "3 2 5 sqrt gini False 500 17: Weighted 0.813237 (0.075536)\n",
      "3 2 5 sqrt gini False 500 17: Macro 0.707725 (0.105751)\n",
      "Testing 345/4320\n",
      "3 2 5 sqrt entropy True 50 17: Weighted 0.814455 (0.065778)\n",
      "3 2 5 sqrt entropy True 50 17: Macro 0.711632 (0.088816)\n",
      "Testing 346/4320\n",
      "3 2 5 sqrt entropy True 100 17: Weighted 0.821407 (0.062892)\n",
      "3 2 5 sqrt entropy True 100 17: Macro 0.721614 (0.084166)\n",
      "Testing 347/4320\n",
      "3 2 5 sqrt entropy True 200 17: Weighted 0.808426 (0.059274)\n",
      "3 2 5 sqrt entropy True 200 17: Macro 0.699306 (0.075587)\n",
      "Testing 348/4320\n",
      "3 2 5 sqrt entropy True 500 17: Weighted 0.811863 (0.058581)\n",
      "3 2 5 sqrt entropy True 500 17: Macro 0.704330 (0.074545)\n",
      "Testing 349/4320\n",
      "3 2 5 sqrt entropy False 50 17: Weighted 0.797726 (0.074020)\n",
      "3 2 5 sqrt entropy False 50 17: Macro 0.687256 (0.097662)\n",
      "Testing 350/4320\n",
      "3 2 5 sqrt entropy False 100 17: Weighted 0.789937 (0.080892)\n",
      "3 2 5 sqrt entropy False 100 17: Macro 0.672580 (0.113241)\n",
      "Testing 351/4320\n",
      "3 2 5 sqrt entropy False 200 17: Weighted 0.792137 (0.077612)\n",
      "3 2 5 sqrt entropy False 200 17: Macro 0.673483 (0.111854)\n",
      "Testing 352/4320\n",
      "3 2 5 sqrt entropy False 500 17: Weighted 0.792137 (0.077612)\n",
      "3 2 5 sqrt entropy False 500 17: Macro 0.673483 (0.111854)\n",
      "Testing 353/4320\n",
      "3 2 8 log2 gini True 50 17: Weighted 0.813440 (0.067066)\n",
      "3 2 8 log2 gini True 50 17: Macro 0.708481 (0.087845)\n",
      "Testing 354/4320\n",
      "3 2 8 log2 gini True 100 17: Weighted 0.811902 (0.061968)\n",
      "3 2 8 log2 gini True 100 17: Macro 0.702313 (0.085000)\n",
      "Testing 355/4320\n",
      "3 2 8 log2 gini True 200 17: Weighted 0.812229 (0.061512)\n",
      "3 2 8 log2 gini True 200 17: Macro 0.706711 (0.078634)\n",
      "Testing 356/4320\n",
      "3 2 8 log2 gini True 500 17: Weighted 0.816235 (0.056083)\n",
      "3 2 8 log2 gini True 500 17: Macro 0.711790 (0.071586)\n",
      "Testing 357/4320\n",
      "3 2 8 log2 gini False 50 17: Weighted 0.811131 (0.069449)\n",
      "3 2 8 log2 gini False 50 17: Macro 0.706988 (0.095113)\n",
      "Testing 358/4320\n",
      "3 2 8 log2 gini False 100 17: Weighted 0.811131 (0.069449)\n",
      "3 2 8 log2 gini False 100 17: Macro 0.706988 (0.095113)\n",
      "Testing 359/4320\n",
      "3 2 8 log2 gini False 200 17: Weighted 0.803616 (0.066511)\n",
      "3 2 8 log2 gini False 200 17: Macro 0.696353 (0.090556)\n",
      "Testing 360/4320\n",
      "3 2 8 log2 gini False 500 17: Weighted 0.808544 (0.069922)\n",
      "3 2 8 log2 gini False 500 17: Macro 0.703862 (0.096699)\n",
      "Testing 361/4320\n",
      "3 2 8 log2 entropy True 50 17: Weighted 0.813679 (0.057546)\n",
      "3 2 8 log2 entropy True 50 17: Macro 0.706570 (0.074612)\n",
      "Testing 362/4320\n",
      "3 2 8 log2 entropy True 100 17: Weighted 0.821977 (0.058466)\n",
      "3 2 8 log2 entropy True 100 17: Macro 0.721669 (0.079089)\n",
      "Testing 363/4320\n",
      "3 2 8 log2 entropy True 200 17: Weighted 0.812229 (0.061512)\n",
      "3 2 8 log2 entropy True 200 17: Macro 0.706711 (0.078634)\n",
      "Testing 364/4320\n",
      "3 2 8 log2 entropy True 500 17: Weighted 0.812229 (0.061512)\n",
      "3 2 8 log2 entropy True 500 17: Macro 0.706711 (0.078634)\n",
      "Testing 365/4320\n",
      "3 2 8 log2 entropy False 50 17: Weighted 0.804684 (0.062624)\n",
      "3 2 8 log2 entropy False 50 17: Macro 0.697221 (0.083059)\n",
      "Testing 366/4320\n",
      "3 2 8 log2 entropy False 100 17: Weighted 0.804684 (0.062624)\n",
      "3 2 8 log2 entropy False 100 17: Macro 0.697221 (0.083059)\n",
      "Testing 367/4320\n",
      "3 2 8 log2 entropy False 200 17: Weighted 0.804684 (0.062624)\n",
      "3 2 8 log2 entropy False 200 17: Macro 0.697221 (0.083059)\n",
      "Testing 368/4320\n",
      "3 2 8 log2 entropy False 500 17: Weighted 0.804684 (0.062624)\n",
      "3 2 8 log2 entropy False 500 17: Macro 0.697221 (0.083059)\n",
      "Testing 369/4320\n",
      "3 2 8 sqrt gini True 50 17: Weighted 0.813440 (0.067066)\n",
      "3 2 8 sqrt gini True 50 17: Macro 0.708481 (0.087845)\n",
      "Testing 370/4320\n",
      "3 2 8 sqrt gini True 100 17: Weighted 0.811902 (0.061968)\n",
      "3 2 8 sqrt gini True 100 17: Macro 0.702313 (0.085000)\n",
      "Testing 371/4320\n",
      "3 2 8 sqrt gini True 200 17: Weighted 0.812229 (0.061512)\n",
      "3 2 8 sqrt gini True 200 17: Macro 0.706711 (0.078634)\n",
      "Testing 372/4320\n",
      "3 2 8 sqrt gini True 500 17: Weighted 0.816235 (0.056083)\n",
      "3 2 8 sqrt gini True 500 17: Macro 0.711790 (0.071586)\n",
      "Testing 373/4320\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 2 8 sqrt gini False 50 17: Weighted 0.811131 (0.069449)\n",
      "3 2 8 sqrt gini False 50 17: Macro 0.706988 (0.095113)\n",
      "Testing 374/4320\n",
      "3 2 8 sqrt gini False 100 17: Weighted 0.811131 (0.069449)\n",
      "3 2 8 sqrt gini False 100 17: Macro 0.706988 (0.095113)\n",
      "Testing 375/4320\n",
      "3 2 8 sqrt gini False 200 17: Weighted 0.803616 (0.066511)\n",
      "3 2 8 sqrt gini False 200 17: Macro 0.696353 (0.090556)\n",
      "Testing 376/4320\n",
      "3 2 8 sqrt gini False 500 17: Weighted 0.808544 (0.069922)\n",
      "3 2 8 sqrt gini False 500 17: Macro 0.703862 (0.096699)\n",
      "Testing 377/4320\n",
      "3 2 8 sqrt entropy True 50 17: Weighted 0.813679 (0.057546)\n",
      "3 2 8 sqrt entropy True 50 17: Macro 0.706570 (0.074612)\n",
      "Testing 378/4320\n",
      "3 2 8 sqrt entropy True 100 17: Weighted 0.821977 (0.058466)\n",
      "3 2 8 sqrt entropy True 100 17: Macro 0.721669 (0.079089)\n",
      "Testing 379/4320\n",
      "3 2 8 sqrt entropy True 200 17: Weighted 0.812229 (0.061512)\n",
      "3 2 8 sqrt entropy True 200 17: Macro 0.706711 (0.078634)\n",
      "Testing 380/4320\n",
      "3 2 8 sqrt entropy True 500 17: Weighted 0.812229 (0.061512)\n",
      "3 2 8 sqrt entropy True 500 17: Macro 0.706711 (0.078634)\n",
      "Testing 381/4320\n",
      "3 2 8 sqrt entropy False 50 17: Weighted 0.804684 (0.062624)\n",
      "3 2 8 sqrt entropy False 50 17: Macro 0.697221 (0.083059)\n",
      "Testing 382/4320\n",
      "3 2 8 sqrt entropy False 100 17: Weighted 0.804684 (0.062624)\n",
      "3 2 8 sqrt entropy False 100 17: Macro 0.697221 (0.083059)\n",
      "Testing 383/4320\n",
      "3 2 8 sqrt entropy False 200 17: Weighted 0.804684 (0.062624)\n",
      "3 2 8 sqrt entropy False 200 17: Macro 0.697221 (0.083059)\n",
      "Testing 384/4320\n",
      "3 2 8 sqrt entropy False 500 17: Weighted 0.804684 (0.062624)\n",
      "3 2 8 sqrt entropy False 500 17: Macro 0.697221 (0.083059)\n",
      "Testing 385/4320\n",
      "3 4 3 log2 gini True 50 17: Weighted 0.818015 (0.060054)\n",
      "3 4 3 log2 gini True 50 17: Macro 0.713437 (0.079013)\n",
      "Testing 386/4320\n",
      "3 4 3 log2 gini True 100 17: Weighted 0.805007 (0.056975)\n",
      "3 4 3 log2 gini True 100 17: Macro 0.697312 (0.075095)\n",
      "Testing 387/4320\n",
      "3 4 3 log2 gini True 200 17: Weighted 0.809014 (0.051630)\n",
      "3 4 3 log2 gini True 200 17: Macro 0.702391 (0.068382)\n",
      "Testing 388/4320\n",
      "3 4 3 log2 gini True 500 17: Weighted 0.813941 (0.055478)\n",
      "3 4 3 log2 gini True 500 17: Macro 0.709900 (0.075733)\n",
      "Testing 389/4320\n",
      "3 4 3 log2 gini False 50 17: Weighted 0.804627 (0.072614)\n",
      "3 4 3 log2 gini False 50 17: Macro 0.701445 (0.092151)\n",
      "Testing 390/4320\n",
      "3 4 3 log2 gini False 100 17: Weighted 0.804627 (0.072614)\n",
      "3 4 3 log2 gini False 100 17: Macro 0.701445 (0.092151)\n",
      "Testing 391/4320\n",
      "3 4 3 log2 gini False 200 17: Weighted 0.809244 (0.065497)\n",
      "3 4 3 log2 gini False 200 17: Macro 0.704564 (0.087453)\n",
      "Testing 392/4320\n",
      "3 4 3 log2 gini False 500 17: Weighted 0.809244 (0.065497)\n",
      "3 4 3 log2 gini False 500 17: Macro 0.704564 (0.087453)\n",
      "Testing 393/4320\n",
      "3 4 3 log2 entropy True 50 17: Weighted 0.809935 (0.060810)\n",
      "3 4 3 log2 entropy True 50 17: Macro 0.704820 (0.082311)\n",
      "Testing 394/4320\n",
      "3 4 3 log2 entropy True 100 17: Weighted 0.809935 (0.060810)\n",
      "3 4 3 log2 entropy True 100 17: Macro 0.704820 (0.082311)\n",
      "Testing 395/4320\n",
      "3 4 3 log2 entropy True 200 17: Weighted 0.812527 (0.049802)\n",
      "3 4 3 log2 entropy True 200 17: Macro 0.710740 (0.060852)\n",
      "Testing 396/4320\n",
      "3 4 3 log2 entropy True 500 17: Weighted 0.808523 (0.055575)\n",
      "3 4 3 log2 entropy True 500 17: Macro 0.702270 (0.072850)\n",
      "Testing 397/4320\n",
      "3 4 3 log2 entropy False 50 17: Weighted 0.787834 (0.088117)\n",
      "3 4 3 log2 entropy False 50 17: Macro 0.680688 (0.106489)\n",
      "Testing 398/4320\n",
      "3 4 3 log2 entropy False 100 17: Weighted 0.787834 (0.088117)\n",
      "3 4 3 log2 entropy False 100 17: Macro 0.680688 (0.106489)\n",
      "Testing 399/4320\n",
      "3 4 3 log2 entropy False 200 17: Weighted 0.787834 (0.088117)\n",
      "3 4 3 log2 entropy False 200 17: Macro 0.680688 (0.106489)\n",
      "Testing 400/4320\n",
      "3 4 3 log2 entropy False 500 17: Weighted 0.787834 (0.088117)\n",
      "3 4 3 log2 entropy False 500 17: Macro 0.680688 (0.106489)\n",
      "Testing 401/4320\n",
      "3 4 3 sqrt gini True 50 17: Weighted 0.818015 (0.060054)\n",
      "3 4 3 sqrt gini True 50 17: Macro 0.713437 (0.079013)\n",
      "Testing 402/4320\n",
      "3 4 3 sqrt gini True 100 17: Weighted 0.805007 (0.056975)\n",
      "3 4 3 sqrt gini True 100 17: Macro 0.697312 (0.075095)\n",
      "Testing 403/4320\n",
      "3 4 3 sqrt gini True 200 17: Weighted 0.809014 (0.051630)\n",
      "3 4 3 sqrt gini True 200 17: Macro 0.702391 (0.068382)\n",
      "Testing 404/4320\n",
      "3 4 3 sqrt gini True 500 17: Weighted 0.813941 (0.055478)\n",
      "3 4 3 sqrt gini True 500 17: Macro 0.709900 (0.075733)\n",
      "Testing 405/4320\n",
      "3 4 3 sqrt gini False 50 17: Weighted 0.804627 (0.072614)\n",
      "3 4 3 sqrt gini False 50 17: Macro 0.701445 (0.092151)\n",
      "Testing 406/4320\n",
      "3 4 3 sqrt gini False 100 17: Weighted 0.804627 (0.072614)\n",
      "3 4 3 sqrt gini False 100 17: Macro 0.701445 (0.092151)\n",
      "Testing 407/4320\n",
      "3 4 3 sqrt gini False 200 17: Weighted 0.809244 (0.065497)\n",
      "3 4 3 sqrt gini False 200 17: Macro 0.704564 (0.087453)\n",
      "Testing 408/4320\n",
      "3 4 3 sqrt gini False 500 17: Weighted 0.809244 (0.065497)\n",
      "3 4 3 sqrt gini False 500 17: Macro 0.704564 (0.087453)\n",
      "Testing 409/4320\n",
      "3 4 3 sqrt entropy True 50 17: Weighted 0.809935 (0.060810)\n",
      "3 4 3 sqrt entropy True 50 17: Macro 0.704820 (0.082311)\n",
      "Testing 410/4320\n",
      "3 4 3 sqrt entropy True 100 17: Weighted 0.809935 (0.060810)\n",
      "3 4 3 sqrt entropy True 100 17: Macro 0.704820 (0.082311)\n",
      "Testing 411/4320\n",
      "3 4 3 sqrt entropy True 200 17: Weighted 0.812527 (0.049802)\n",
      "3 4 3 sqrt entropy True 200 17: Macro 0.710740 (0.060852)\n",
      "Testing 412/4320\n",
      "3 4 3 sqrt entropy True 500 17: Weighted 0.808523 (0.055575)\n",
      "3 4 3 sqrt entropy True 500 17: Macro 0.702270 (0.072850)\n",
      "Testing 413/4320\n",
      "3 4 3 sqrt entropy False 50 17: Weighted 0.787834 (0.088117)\n",
      "3 4 3 sqrt entropy False 50 17: Macro 0.680688 (0.106489)\n",
      "Testing 414/4320\n",
      "3 4 3 sqrt entropy False 100 17: Weighted 0.787834 (0.088117)\n",
      "3 4 3 sqrt entropy False 100 17: Macro 0.680688 (0.106489)\n",
      "Testing 415/4320\n",
      "3 4 3 sqrt entropy False 200 17: Weighted 0.787834 (0.088117)\n",
      "3 4 3 sqrt entropy False 200 17: Macro 0.680688 (0.106489)\n",
      "Testing 416/4320\n",
      "3 4 3 sqrt entropy False 500 17: Weighted 0.787834 (0.088117)\n",
      "3 4 3 sqrt entropy False 500 17: Macro 0.680688 (0.106489)\n",
      "Testing 417/4320\n",
      "3 4 5 log2 gini True 50 17: Weighted 0.817971 (0.064052)\n",
      "3 4 5 log2 gini True 50 17: Macro 0.716589 (0.086105)\n",
      "Testing 418/4320\n",
      "3 4 5 log2 gini True 100 17: Weighted 0.811863 (0.058581)\n",
      "3 4 5 log2 gini True 100 17: Macro 0.704330 (0.074545)\n",
      "Testing 419/4320\n",
      "3 4 5 log2 gini True 200 17: Weighted 0.808426 (0.059274)\n",
      "3 4 5 log2 gini True 200 17: Macro 0.699306 (0.075587)\n",
      "Testing 420/4320\n",
      "3 4 5 log2 gini True 500 17: Weighted 0.813188 (0.061148)\n",
      "3 4 5 log2 gini True 500 17: Macro 0.706448 (0.078733)\n",
      "Testing 421/4320\n",
      "3 4 5 log2 gini False 50 17: Weighted 0.808216 (0.082181)\n",
      "3 4 5 log2 gini False 50 17: Macro 0.698926 (0.120768)\n",
      "Testing 422/4320\n",
      "3 4 5 log2 gini False 100 17: Weighted 0.808216 (0.082181)\n",
      "3 4 5 log2 gini False 100 17: Macro 0.698926 (0.120768)\n",
      "Testing 423/4320\n",
      "3 4 5 log2 gini False 200 17: Weighted 0.813237 (0.075536)\n",
      "3 4 5 log2 gini False 200 17: Macro 0.707725 (0.105751)\n",
      "Testing 424/4320\n",
      "3 4 5 log2 gini False 500 17: Weighted 0.813237 (0.075536)\n",
      "3 4 5 log2 gini False 500 17: Macro 0.707725 (0.105751)\n",
      "Testing 425/4320\n",
      "3 4 5 log2 entropy True 50 17: Weighted 0.814455 (0.065778)\n",
      "3 4 5 log2 entropy True 50 17: Macro 0.711632 (0.088816)\n",
      "Testing 426/4320\n",
      "3 4 5 log2 entropy True 100 17: Weighted 0.821407 (0.062892)\n",
      "3 4 5 log2 entropy True 100 17: Macro 0.721614 (0.084166)\n",
      "Testing 427/4320\n",
      "3 4 5 log2 entropy True 200 17: Weighted 0.808426 (0.059274)\n",
      "3 4 5 log2 entropy True 200 17: Macro 0.699306 (0.075587)\n",
      "Testing 428/4320\n",
      "3 4 5 log2 entropy True 500 17: Weighted 0.811863 (0.058581)\n",
      "3 4 5 log2 entropy True 500 17: Macro 0.704330 (0.074545)\n",
      "Testing 429/4320\n",
      "3 4 5 log2 entropy False 50 17: Weighted 0.797726 (0.074020)\n",
      "3 4 5 log2 entropy False 50 17: Macro 0.687256 (0.097662)\n",
      "Testing 430/4320\n",
      "3 4 5 log2 entropy False 100 17: Weighted 0.789937 (0.080892)\n",
      "3 4 5 log2 entropy False 100 17: Macro 0.672580 (0.113241)\n",
      "Testing 431/4320\n",
      "3 4 5 log2 entropy False 200 17: Weighted 0.792137 (0.077612)\n",
      "3 4 5 log2 entropy False 200 17: Macro 0.673483 (0.111854)\n",
      "Testing 432/4320\n",
      "3 4 5 log2 entropy False 500 17: Weighted 0.792137 (0.077612)\n",
      "3 4 5 log2 entropy False 500 17: Macro 0.673483 (0.111854)\n",
      "Testing 433/4320\n",
      "3 4 5 sqrt gini True 50 17: Weighted 0.817971 (0.064052)\n",
      "3 4 5 sqrt gini True 50 17: Macro 0.716589 (0.086105)\n",
      "Testing 434/4320\n",
      "3 4 5 sqrt gini True 100 17: Weighted 0.811863 (0.058581)\n",
      "3 4 5 sqrt gini True 100 17: Macro 0.704330 (0.074545)\n",
      "Testing 435/4320\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 4 5 sqrt gini True 200 17: Weighted 0.808426 (0.059274)\n",
      "3 4 5 sqrt gini True 200 17: Macro 0.699306 (0.075587)\n",
      "Testing 436/4320\n",
      "3 4 5 sqrt gini True 500 17: Weighted 0.813188 (0.061148)\n",
      "3 4 5 sqrt gini True 500 17: Macro 0.706448 (0.078733)\n",
      "Testing 437/4320\n",
      "3 4 5 sqrt gini False 50 17: Weighted 0.808216 (0.082181)\n",
      "3 4 5 sqrt gini False 50 17: Macro 0.698926 (0.120768)\n",
      "Testing 438/4320\n",
      "3 4 5 sqrt gini False 100 17: Weighted 0.808216 (0.082181)\n",
      "3 4 5 sqrt gini False 100 17: Macro 0.698926 (0.120768)\n",
      "Testing 439/4320\n",
      "3 4 5 sqrt gini False 200 17: Weighted 0.813237 (0.075536)\n",
      "3 4 5 sqrt gini False 200 17: Macro 0.707725 (0.105751)\n",
      "Testing 440/4320\n",
      "3 4 5 sqrt gini False 500 17: Weighted 0.813237 (0.075536)\n",
      "3 4 5 sqrt gini False 500 17: Macro 0.707725 (0.105751)\n",
      "Testing 441/4320\n",
      "3 4 5 sqrt entropy True 50 17: Weighted 0.814455 (0.065778)\n",
      "3 4 5 sqrt entropy True 50 17: Macro 0.711632 (0.088816)\n",
      "Testing 442/4320\n",
      "3 4 5 sqrt entropy True 100 17: Weighted 0.821407 (0.062892)\n",
      "3 4 5 sqrt entropy True 100 17: Macro 0.721614 (0.084166)\n",
      "Testing 443/4320\n",
      "3 4 5 sqrt entropy True 200 17: Weighted 0.808426 (0.059274)\n",
      "3 4 5 sqrt entropy True 200 17: Macro 0.699306 (0.075587)\n",
      "Testing 444/4320\n",
      "3 4 5 sqrt entropy True 500 17: Weighted 0.811863 (0.058581)\n",
      "3 4 5 sqrt entropy True 500 17: Macro 0.704330 (0.074545)\n",
      "Testing 445/4320\n",
      "3 4 5 sqrt entropy False 50 17: Weighted 0.797726 (0.074020)\n",
      "3 4 5 sqrt entropy False 50 17: Macro 0.687256 (0.097662)\n",
      "Testing 446/4320\n",
      "3 4 5 sqrt entropy False 100 17: Weighted 0.789937 (0.080892)\n",
      "3 4 5 sqrt entropy False 100 17: Macro 0.672580 (0.113241)\n",
      "Testing 447/4320\n",
      "3 4 5 sqrt entropy False 200 17: Weighted 0.792137 (0.077612)\n",
      "3 4 5 sqrt entropy False 200 17: Macro 0.673483 (0.111854)\n",
      "Testing 448/4320\n",
      "3 4 5 sqrt entropy False 500 17: Weighted 0.792137 (0.077612)\n",
      "3 4 5 sqrt entropy False 500 17: Macro 0.673483 (0.111854)\n",
      "Testing 449/4320\n",
      "3 4 8 log2 gini True 50 17: Weighted 0.813440 (0.067066)\n",
      "3 4 8 log2 gini True 50 17: Macro 0.708481 (0.087845)\n",
      "Testing 450/4320\n",
      "3 4 8 log2 gini True 100 17: Weighted 0.811902 (0.061968)\n",
      "3 4 8 log2 gini True 100 17: Macro 0.702313 (0.085000)\n",
      "Testing 451/4320\n",
      "3 4 8 log2 gini True 200 17: Weighted 0.812229 (0.061512)\n",
      "3 4 8 log2 gini True 200 17: Macro 0.706711 (0.078634)\n",
      "Testing 452/4320\n",
      "3 4 8 log2 gini True 500 17: Weighted 0.816235 (0.056083)\n",
      "3 4 8 log2 gini True 500 17: Macro 0.711790 (0.071586)\n",
      "Testing 453/4320\n",
      "3 4 8 log2 gini False 50 17: Weighted 0.811131 (0.069449)\n",
      "3 4 8 log2 gini False 50 17: Macro 0.706988 (0.095113)\n",
      "Testing 454/4320\n",
      "3 4 8 log2 gini False 100 17: Weighted 0.811131 (0.069449)\n",
      "3 4 8 log2 gini False 100 17: Macro 0.706988 (0.095113)\n",
      "Testing 455/4320\n",
      "3 4 8 log2 gini False 200 17: Weighted 0.803616 (0.066511)\n",
      "3 4 8 log2 gini False 200 17: Macro 0.696353 (0.090556)\n",
      "Testing 456/4320\n",
      "3 4 8 log2 gini False 500 17: Weighted 0.808544 (0.069922)\n",
      "3 4 8 log2 gini False 500 17: Macro 0.703862 (0.096699)\n",
      "Testing 457/4320\n",
      "3 4 8 log2 entropy True 50 17: Weighted 0.813679 (0.057546)\n",
      "3 4 8 log2 entropy True 50 17: Macro 0.706570 (0.074612)\n",
      "Testing 458/4320\n",
      "3 4 8 log2 entropy True 100 17: Weighted 0.821977 (0.058466)\n",
      "3 4 8 log2 entropy True 100 17: Macro 0.721669 (0.079089)\n",
      "Testing 459/4320\n",
      "3 4 8 log2 entropy True 200 17: Weighted 0.812229 (0.061512)\n",
      "3 4 8 log2 entropy True 200 17: Macro 0.706711 (0.078634)\n",
      "Testing 460/4320\n",
      "3 4 8 log2 entropy True 500 17: Weighted 0.812229 (0.061512)\n",
      "3 4 8 log2 entropy True 500 17: Macro 0.706711 (0.078634)\n",
      "Testing 461/4320\n",
      "3 4 8 log2 entropy False 50 17: Weighted 0.804684 (0.062624)\n",
      "3 4 8 log2 entropy False 50 17: Macro 0.697221 (0.083059)\n",
      "Testing 462/4320\n",
      "3 4 8 log2 entropy False 100 17: Weighted 0.804684 (0.062624)\n",
      "3 4 8 log2 entropy False 100 17: Macro 0.697221 (0.083059)\n",
      "Testing 463/4320\n",
      "3 4 8 log2 entropy False 200 17: Weighted 0.804684 (0.062624)\n",
      "3 4 8 log2 entropy False 200 17: Macro 0.697221 (0.083059)\n",
      "Testing 464/4320\n",
      "3 4 8 log2 entropy False 500 17: Weighted 0.804684 (0.062624)\n",
      "3 4 8 log2 entropy False 500 17: Macro 0.697221 (0.083059)\n",
      "Testing 465/4320\n",
      "3 4 8 sqrt gini True 50 17: Weighted 0.813440 (0.067066)\n",
      "3 4 8 sqrt gini True 50 17: Macro 0.708481 (0.087845)\n",
      "Testing 466/4320\n",
      "3 4 8 sqrt gini True 100 17: Weighted 0.811902 (0.061968)\n",
      "3 4 8 sqrt gini True 100 17: Macro 0.702313 (0.085000)\n",
      "Testing 467/4320\n",
      "3 4 8 sqrt gini True 200 17: Weighted 0.812229 (0.061512)\n",
      "3 4 8 sqrt gini True 200 17: Macro 0.706711 (0.078634)\n",
      "Testing 468/4320\n",
      "3 4 8 sqrt gini True 500 17: Weighted 0.816235 (0.056083)\n",
      "3 4 8 sqrt gini True 500 17: Macro 0.711790 (0.071586)\n",
      "Testing 469/4320\n",
      "3 4 8 sqrt gini False 50 17: Weighted 0.811131 (0.069449)\n",
      "3 4 8 sqrt gini False 50 17: Macro 0.706988 (0.095113)\n",
      "Testing 470/4320\n",
      "3 4 8 sqrt gini False 100 17: Weighted 0.811131 (0.069449)\n",
      "3 4 8 sqrt gini False 100 17: Macro 0.706988 (0.095113)\n",
      "Testing 471/4320\n",
      "3 4 8 sqrt gini False 200 17: Weighted 0.803616 (0.066511)\n",
      "3 4 8 sqrt gini False 200 17: Macro 0.696353 (0.090556)\n",
      "Testing 472/4320\n",
      "3 4 8 sqrt gini False 500 17: Weighted 0.808544 (0.069922)\n",
      "3 4 8 sqrt gini False 500 17: Macro 0.703862 (0.096699)\n",
      "Testing 473/4320\n",
      "3 4 8 sqrt entropy True 50 17: Weighted 0.813679 (0.057546)\n",
      "3 4 8 sqrt entropy True 50 17: Macro 0.706570 (0.074612)\n",
      "Testing 474/4320\n",
      "3 4 8 sqrt entropy True 100 17: Weighted 0.821977 (0.058466)\n",
      "3 4 8 sqrt entropy True 100 17: Macro 0.721669 (0.079089)\n",
      "Testing 475/4320\n",
      "3 4 8 sqrt entropy True 200 17: Weighted 0.812229 (0.061512)\n",
      "3 4 8 sqrt entropy True 200 17: Macro 0.706711 (0.078634)\n",
      "Testing 476/4320\n",
      "3 4 8 sqrt entropy True 500 17: Weighted 0.812229 (0.061512)\n",
      "3 4 8 sqrt entropy True 500 17: Macro 0.706711 (0.078634)\n",
      "Testing 477/4320\n",
      "3 4 8 sqrt entropy False 50 17: Weighted 0.804684 (0.062624)\n",
      "3 4 8 sqrt entropy False 50 17: Macro 0.697221 (0.083059)\n",
      "Testing 478/4320\n",
      "3 4 8 sqrt entropy False 100 17: Weighted 0.804684 (0.062624)\n",
      "3 4 8 sqrt entropy False 100 17: Macro 0.697221 (0.083059)\n",
      "Testing 479/4320\n",
      "3 4 8 sqrt entropy False 200 17: Weighted 0.804684 (0.062624)\n",
      "3 4 8 sqrt entropy False 200 17: Macro 0.697221 (0.083059)\n",
      "Testing 480/4320\n",
      "3 4 8 sqrt entropy False 500 17: Weighted 0.804684 (0.062624)\n",
      "3 4 8 sqrt entropy False 500 17: Macro 0.697221 (0.083059)\n",
      "Testing 481/4320\n",
      "3 6 3 log2 gini True 50 17: Weighted 0.818015 (0.060054)\n",
      "3 6 3 log2 gini True 50 17: Macro 0.713437 (0.079013)\n",
      "Testing 482/4320\n",
      "3 6 3 log2 gini True 100 17: Weighted 0.805007 (0.056975)\n",
      "3 6 3 log2 gini True 100 17: Macro 0.697312 (0.075095)\n",
      "Testing 483/4320\n",
      "3 6 3 log2 gini True 200 17: Weighted 0.809014 (0.051630)\n",
      "3 6 3 log2 gini True 200 17: Macro 0.702391 (0.068382)\n",
      "Testing 484/4320\n",
      "3 6 3 log2 gini True 500 17: Weighted 0.813941 (0.055478)\n",
      "3 6 3 log2 gini True 500 17: Macro 0.709900 (0.075733)\n",
      "Testing 485/4320\n",
      "3 6 3 log2 gini False 50 17: Weighted 0.804627 (0.072614)\n",
      "3 6 3 log2 gini False 50 17: Macro 0.701445 (0.092151)\n",
      "Testing 486/4320\n",
      "3 6 3 log2 gini False 100 17: Weighted 0.804627 (0.072614)\n",
      "3 6 3 log2 gini False 100 17: Macro 0.701445 (0.092151)\n",
      "Testing 487/4320\n",
      "3 6 3 log2 gini False 200 17: Weighted 0.809244 (0.065497)\n",
      "3 6 3 log2 gini False 200 17: Macro 0.704564 (0.087453)\n",
      "Testing 488/4320\n",
      "3 6 3 log2 gini False 500 17: Weighted 0.809244 (0.065497)\n",
      "3 6 3 log2 gini False 500 17: Macro 0.704564 (0.087453)\n",
      "Testing 489/4320\n",
      "3 6 3 log2 entropy True 50 17: Weighted 0.809935 (0.060810)\n",
      "3 6 3 log2 entropy True 50 17: Macro 0.704820 (0.082311)\n",
      "Testing 490/4320\n",
      "3 6 3 log2 entropy True 100 17: Weighted 0.809935 (0.060810)\n",
      "3 6 3 log2 entropy True 100 17: Macro 0.704820 (0.082311)\n",
      "Testing 491/4320\n",
      "3 6 3 log2 entropy True 200 17: Weighted 0.812527 (0.049802)\n",
      "3 6 3 log2 entropy True 200 17: Macro 0.710740 (0.060852)\n",
      "Testing 492/4320\n",
      "3 6 3 log2 entropy True 500 17: Weighted 0.808523 (0.055575)\n",
      "3 6 3 log2 entropy True 500 17: Macro 0.702270 (0.072850)\n",
      "Testing 493/4320\n",
      "3 6 3 log2 entropy False 50 17: Weighted 0.787834 (0.088117)\n",
      "3 6 3 log2 entropy False 50 17: Macro 0.680688 (0.106489)\n",
      "Testing 494/4320\n",
      "3 6 3 log2 entropy False 100 17: Weighted 0.787834 (0.088117)\n",
      "3 6 3 log2 entropy False 100 17: Macro 0.680688 (0.106489)\n",
      "Testing 495/4320\n",
      "3 6 3 log2 entropy False 200 17: Weighted 0.787834 (0.088117)\n",
      "3 6 3 log2 entropy False 200 17: Macro 0.680688 (0.106489)\n",
      "Testing 496/4320\n",
      "3 6 3 log2 entropy False 500 17: Weighted 0.787834 (0.088117)\n",
      "3 6 3 log2 entropy False 500 17: Macro 0.680688 (0.106489)\n",
      "Testing 497/4320\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 6 3 sqrt gini True 50 17: Weighted 0.818015 (0.060054)\n",
      "3 6 3 sqrt gini True 50 17: Macro 0.713437 (0.079013)\n",
      "Testing 498/4320\n",
      "3 6 3 sqrt gini True 100 17: Weighted 0.805007 (0.056975)\n",
      "3 6 3 sqrt gini True 100 17: Macro 0.697312 (0.075095)\n",
      "Testing 499/4320\n",
      "3 6 3 sqrt gini True 200 17: Weighted 0.809014 (0.051630)\n",
      "3 6 3 sqrt gini True 200 17: Macro 0.702391 (0.068382)\n",
      "Testing 500/4320\n",
      "3 6 3 sqrt gini True 500 17: Weighted 0.813941 (0.055478)\n",
      "3 6 3 sqrt gini True 500 17: Macro 0.709900 (0.075733)\n",
      "Testing 501/4320\n",
      "3 6 3 sqrt gini False 50 17: Weighted 0.804627 (0.072614)\n",
      "3 6 3 sqrt gini False 50 17: Macro 0.701445 (0.092151)\n",
      "Testing 502/4320\n",
      "3 6 3 sqrt gini False 100 17: Weighted 0.804627 (0.072614)\n",
      "3 6 3 sqrt gini False 100 17: Macro 0.701445 (0.092151)\n",
      "Testing 503/4320\n",
      "3 6 3 sqrt gini False 200 17: Weighted 0.809244 (0.065497)\n",
      "3 6 3 sqrt gini False 200 17: Macro 0.704564 (0.087453)\n",
      "Testing 504/4320\n",
      "3 6 3 sqrt gini False 500 17: Weighted 0.809244 (0.065497)\n",
      "3 6 3 sqrt gini False 500 17: Macro 0.704564 (0.087453)\n",
      "Testing 505/4320\n",
      "3 6 3 sqrt entropy True 50 17: Weighted 0.809935 (0.060810)\n",
      "3 6 3 sqrt entropy True 50 17: Macro 0.704820 (0.082311)\n",
      "Testing 506/4320\n",
      "3 6 3 sqrt entropy True 100 17: Weighted 0.809935 (0.060810)\n",
      "3 6 3 sqrt entropy True 100 17: Macro 0.704820 (0.082311)\n",
      "Testing 507/4320\n",
      "3 6 3 sqrt entropy True 200 17: Weighted 0.812527 (0.049802)\n",
      "3 6 3 sqrt entropy True 200 17: Macro 0.710740 (0.060852)\n",
      "Testing 508/4320\n",
      "3 6 3 sqrt entropy True 500 17: Weighted 0.808523 (0.055575)\n",
      "3 6 3 sqrt entropy True 500 17: Macro 0.702270 (0.072850)\n",
      "Testing 509/4320\n",
      "3 6 3 sqrt entropy False 50 17: Weighted 0.787834 (0.088117)\n",
      "3 6 3 sqrt entropy False 50 17: Macro 0.680688 (0.106489)\n",
      "Testing 510/4320\n",
      "3 6 3 sqrt entropy False 100 17: Weighted 0.787834 (0.088117)\n",
      "3 6 3 sqrt entropy False 100 17: Macro 0.680688 (0.106489)\n",
      "Testing 511/4320\n",
      "3 6 3 sqrt entropy False 200 17: Weighted 0.787834 (0.088117)\n",
      "3 6 3 sqrt entropy False 200 17: Macro 0.680688 (0.106489)\n",
      "Testing 512/4320\n",
      "3 6 3 sqrt entropy False 500 17: Weighted 0.787834 (0.088117)\n",
      "3 6 3 sqrt entropy False 500 17: Macro 0.680688 (0.106489)\n",
      "Testing 513/4320\n",
      "3 6 5 log2 gini True 50 17: Weighted 0.817971 (0.064052)\n",
      "3 6 5 log2 gini True 50 17: Macro 0.716589 (0.086105)\n",
      "Testing 514/4320\n",
      "3 6 5 log2 gini True 100 17: Weighted 0.811863 (0.058581)\n",
      "3 6 5 log2 gini True 100 17: Macro 0.704330 (0.074545)\n",
      "Testing 515/4320\n",
      "3 6 5 log2 gini True 200 17: Weighted 0.808426 (0.059274)\n",
      "3 6 5 log2 gini True 200 17: Macro 0.699306 (0.075587)\n",
      "Testing 516/4320\n",
      "3 6 5 log2 gini True 500 17: Weighted 0.813188 (0.061148)\n",
      "3 6 5 log2 gini True 500 17: Macro 0.706448 (0.078733)\n",
      "Testing 517/4320\n",
      "3 6 5 log2 gini False 50 17: Weighted 0.808216 (0.082181)\n",
      "3 6 5 log2 gini False 50 17: Macro 0.698926 (0.120768)\n",
      "Testing 518/4320\n",
      "3 6 5 log2 gini False 100 17: Weighted 0.808216 (0.082181)\n",
      "3 6 5 log2 gini False 100 17: Macro 0.698926 (0.120768)\n",
      "Testing 519/4320\n",
      "3 6 5 log2 gini False 200 17: Weighted 0.813237 (0.075536)\n",
      "3 6 5 log2 gini False 200 17: Macro 0.707725 (0.105751)\n",
      "Testing 520/4320\n",
      "3 6 5 log2 gini False 500 17: Weighted 0.813237 (0.075536)\n",
      "3 6 5 log2 gini False 500 17: Macro 0.707725 (0.105751)\n",
      "Testing 521/4320\n",
      "3 6 5 log2 entropy True 50 17: Weighted 0.814455 (0.065778)\n",
      "3 6 5 log2 entropy True 50 17: Macro 0.711632 (0.088816)\n",
      "Testing 522/4320\n",
      "3 6 5 log2 entropy True 100 17: Weighted 0.821407 (0.062892)\n",
      "3 6 5 log2 entropy True 100 17: Macro 0.721614 (0.084166)\n",
      "Testing 523/4320\n",
      "3 6 5 log2 entropy True 200 17: Weighted 0.808426 (0.059274)\n",
      "3 6 5 log2 entropy True 200 17: Macro 0.699306 (0.075587)\n",
      "Testing 524/4320\n",
      "3 6 5 log2 entropy True 500 17: Weighted 0.811863 (0.058581)\n",
      "3 6 5 log2 entropy True 500 17: Macro 0.704330 (0.074545)\n",
      "Testing 525/4320\n",
      "3 6 5 log2 entropy False 50 17: Weighted 0.797726 (0.074020)\n",
      "3 6 5 log2 entropy False 50 17: Macro 0.687256 (0.097662)\n",
      "Testing 526/4320\n",
      "3 6 5 log2 entropy False 100 17: Weighted 0.789937 (0.080892)\n",
      "3 6 5 log2 entropy False 100 17: Macro 0.672580 (0.113241)\n",
      "Testing 527/4320\n",
      "3 6 5 log2 entropy False 200 17: Weighted 0.792137 (0.077612)\n",
      "3 6 5 log2 entropy False 200 17: Macro 0.673483 (0.111854)\n",
      "Testing 528/4320\n",
      "3 6 5 log2 entropy False 500 17: Weighted 0.792137 (0.077612)\n",
      "3 6 5 log2 entropy False 500 17: Macro 0.673483 (0.111854)\n",
      "Testing 529/4320\n",
      "3 6 5 sqrt gini True 50 17: Weighted 0.817971 (0.064052)\n",
      "3 6 5 sqrt gini True 50 17: Macro 0.716589 (0.086105)\n",
      "Testing 530/4320\n",
      "3 6 5 sqrt gini True 100 17: Weighted 0.811863 (0.058581)\n",
      "3 6 5 sqrt gini True 100 17: Macro 0.704330 (0.074545)\n",
      "Testing 531/4320\n",
      "3 6 5 sqrt gini True 200 17: Weighted 0.808426 (0.059274)\n",
      "3 6 5 sqrt gini True 200 17: Macro 0.699306 (0.075587)\n",
      "Testing 532/4320\n",
      "3 6 5 sqrt gini True 500 17: Weighted 0.813188 (0.061148)\n",
      "3 6 5 sqrt gini True 500 17: Macro 0.706448 (0.078733)\n",
      "Testing 533/4320\n",
      "3 6 5 sqrt gini False 50 17: Weighted 0.808216 (0.082181)\n",
      "3 6 5 sqrt gini False 50 17: Macro 0.698926 (0.120768)\n",
      "Testing 534/4320\n",
      "3 6 5 sqrt gini False 100 17: Weighted 0.808216 (0.082181)\n",
      "3 6 5 sqrt gini False 100 17: Macro 0.698926 (0.120768)\n",
      "Testing 535/4320\n",
      "3 6 5 sqrt gini False 200 17: Weighted 0.813237 (0.075536)\n",
      "3 6 5 sqrt gini False 200 17: Macro 0.707725 (0.105751)\n",
      "Testing 536/4320\n",
      "3 6 5 sqrt gini False 500 17: Weighted 0.813237 (0.075536)\n",
      "3 6 5 sqrt gini False 500 17: Macro 0.707725 (0.105751)\n",
      "Testing 537/4320\n",
      "3 6 5 sqrt entropy True 50 17: Weighted 0.814455 (0.065778)\n",
      "3 6 5 sqrt entropy True 50 17: Macro 0.711632 (0.088816)\n",
      "Testing 538/4320\n",
      "3 6 5 sqrt entropy True 100 17: Weighted 0.821407 (0.062892)\n",
      "3 6 5 sqrt entropy True 100 17: Macro 0.721614 (0.084166)\n",
      "Testing 539/4320\n",
      "3 6 5 sqrt entropy True 200 17: Weighted 0.808426 (0.059274)\n",
      "3 6 5 sqrt entropy True 200 17: Macro 0.699306 (0.075587)\n",
      "Testing 540/4320\n",
      "3 6 5 sqrt entropy True 500 17: Weighted 0.811863 (0.058581)\n",
      "3 6 5 sqrt entropy True 500 17: Macro 0.704330 (0.074545)\n",
      "Testing 541/4320\n",
      "3 6 5 sqrt entropy False 50 17: Weighted 0.797726 (0.074020)\n",
      "3 6 5 sqrt entropy False 50 17: Macro 0.687256 (0.097662)\n",
      "Testing 542/4320\n",
      "3 6 5 sqrt entropy False 100 17: Weighted 0.789937 (0.080892)\n",
      "3 6 5 sqrt entropy False 100 17: Macro 0.672580 (0.113241)\n",
      "Testing 543/4320\n",
      "3 6 5 sqrt entropy False 200 17: Weighted 0.792137 (0.077612)\n",
      "3 6 5 sqrt entropy False 200 17: Macro 0.673483 (0.111854)\n",
      "Testing 544/4320\n",
      "3 6 5 sqrt entropy False 500 17: Weighted 0.792137 (0.077612)\n",
      "3 6 5 sqrt entropy False 500 17: Macro 0.673483 (0.111854)\n",
      "Testing 545/4320\n",
      "3 6 8 log2 gini True 50 17: Weighted 0.813440 (0.067066)\n",
      "3 6 8 log2 gini True 50 17: Macro 0.708481 (0.087845)\n",
      "Testing 546/4320\n",
      "3 6 8 log2 gini True 100 17: Weighted 0.811902 (0.061968)\n",
      "3 6 8 log2 gini True 100 17: Macro 0.702313 (0.085000)\n",
      "Testing 547/4320\n",
      "3 6 8 log2 gini True 200 17: Weighted 0.812229 (0.061512)\n",
      "3 6 8 log2 gini True 200 17: Macro 0.706711 (0.078634)\n",
      "Testing 548/4320\n",
      "3 6 8 log2 gini True 500 17: Weighted 0.816235 (0.056083)\n",
      "3 6 8 log2 gini True 500 17: Macro 0.711790 (0.071586)\n",
      "Testing 549/4320\n",
      "3 6 8 log2 gini False 50 17: Weighted 0.811131 (0.069449)\n",
      "3 6 8 log2 gini False 50 17: Macro 0.706988 (0.095113)\n",
      "Testing 550/4320\n",
      "3 6 8 log2 gini False 100 17: Weighted 0.811131 (0.069449)\n",
      "3 6 8 log2 gini False 100 17: Macro 0.706988 (0.095113)\n",
      "Testing 551/4320\n",
      "3 6 8 log2 gini False 200 17: Weighted 0.803616 (0.066511)\n",
      "3 6 8 log2 gini False 200 17: Macro 0.696353 (0.090556)\n",
      "Testing 552/4320\n",
      "3 6 8 log2 gini False 500 17: Weighted 0.808544 (0.069922)\n",
      "3 6 8 log2 gini False 500 17: Macro 0.703862 (0.096699)\n",
      "Testing 553/4320\n",
      "3 6 8 log2 entropy True 50 17: Weighted 0.813679 (0.057546)\n",
      "3 6 8 log2 entropy True 50 17: Macro 0.706570 (0.074612)\n",
      "Testing 554/4320\n",
      "3 6 8 log2 entropy True 100 17: Weighted 0.821977 (0.058466)\n",
      "3 6 8 log2 entropy True 100 17: Macro 0.721669 (0.079089)\n",
      "Testing 555/4320\n",
      "3 6 8 log2 entropy True 200 17: Weighted 0.812229 (0.061512)\n",
      "3 6 8 log2 entropy True 200 17: Macro 0.706711 (0.078634)\n",
      "Testing 556/4320\n",
      "3 6 8 log2 entropy True 500 17: Weighted 0.812229 (0.061512)\n",
      "3 6 8 log2 entropy True 500 17: Macro 0.706711 (0.078634)\n",
      "Testing 557/4320\n",
      "3 6 8 log2 entropy False 50 17: Weighted 0.804684 (0.062624)\n",
      "3 6 8 log2 entropy False 50 17: Macro 0.697221 (0.083059)\n",
      "Testing 558/4320\n",
      "3 6 8 log2 entropy False 100 17: Weighted 0.804684 (0.062624)\n",
      "3 6 8 log2 entropy False 100 17: Macro 0.697221 (0.083059)\n",
      "Testing 559/4320\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 6 8 log2 entropy False 200 17: Weighted 0.804684 (0.062624)\n",
      "3 6 8 log2 entropy False 200 17: Macro 0.697221 (0.083059)\n",
      "Testing 560/4320\n",
      "3 6 8 log2 entropy False 500 17: Weighted 0.804684 (0.062624)\n",
      "3 6 8 log2 entropy False 500 17: Macro 0.697221 (0.083059)\n",
      "Testing 561/4320\n",
      "3 6 8 sqrt gini True 50 17: Weighted 0.813440 (0.067066)\n",
      "3 6 8 sqrt gini True 50 17: Macro 0.708481 (0.087845)\n",
      "Testing 562/4320\n",
      "3 6 8 sqrt gini True 100 17: Weighted 0.811902 (0.061968)\n",
      "3 6 8 sqrt gini True 100 17: Macro 0.702313 (0.085000)\n",
      "Testing 563/4320\n",
      "3 6 8 sqrt gini True 200 17: Weighted 0.812229 (0.061512)\n",
      "3 6 8 sqrt gini True 200 17: Macro 0.706711 (0.078634)\n",
      "Testing 564/4320\n",
      "3 6 8 sqrt gini True 500 17: Weighted 0.816235 (0.056083)\n",
      "3 6 8 sqrt gini True 500 17: Macro 0.711790 (0.071586)\n",
      "Testing 565/4320\n",
      "3 6 8 sqrt gini False 50 17: Weighted 0.811131 (0.069449)\n",
      "3 6 8 sqrt gini False 50 17: Macro 0.706988 (0.095113)\n",
      "Testing 566/4320\n",
      "3 6 8 sqrt gini False 100 17: Weighted 0.811131 (0.069449)\n",
      "3 6 8 sqrt gini False 100 17: Macro 0.706988 (0.095113)\n",
      "Testing 567/4320\n",
      "3 6 8 sqrt gini False 200 17: Weighted 0.803616 (0.066511)\n",
      "3 6 8 sqrt gini False 200 17: Macro 0.696353 (0.090556)\n",
      "Testing 568/4320\n",
      "3 6 8 sqrt gini False 500 17: Weighted 0.808544 (0.069922)\n",
      "3 6 8 sqrt gini False 500 17: Macro 0.703862 (0.096699)\n",
      "Testing 569/4320\n",
      "3 6 8 sqrt entropy True 50 17: Weighted 0.813679 (0.057546)\n",
      "3 6 8 sqrt entropy True 50 17: Macro 0.706570 (0.074612)\n",
      "Testing 570/4320\n",
      "3 6 8 sqrt entropy True 100 17: Weighted 0.821977 (0.058466)\n",
      "3 6 8 sqrt entropy True 100 17: Macro 0.721669 (0.079089)\n",
      "Testing 571/4320\n",
      "3 6 8 sqrt entropy True 200 17: Weighted 0.812229 (0.061512)\n",
      "3 6 8 sqrt entropy True 200 17: Macro 0.706711 (0.078634)\n",
      "Testing 572/4320\n",
      "3 6 8 sqrt entropy True 500 17: Weighted 0.812229 (0.061512)\n",
      "3 6 8 sqrt entropy True 500 17: Macro 0.706711 (0.078634)\n",
      "Testing 573/4320\n",
      "3 6 8 sqrt entropy False 50 17: Weighted 0.804684 (0.062624)\n",
      "3 6 8 sqrt entropy False 50 17: Macro 0.697221 (0.083059)\n",
      "Testing 574/4320\n",
      "3 6 8 sqrt entropy False 100 17: Weighted 0.804684 (0.062624)\n",
      "3 6 8 sqrt entropy False 100 17: Macro 0.697221 (0.083059)\n",
      "Testing 575/4320\n",
      "3 6 8 sqrt entropy False 200 17: Weighted 0.804684 (0.062624)\n",
      "3 6 8 sqrt entropy False 200 17: Macro 0.697221 (0.083059)\n",
      "Testing 576/4320\n",
      "3 6 8 sqrt entropy False 500 17: Weighted 0.804684 (0.062624)\n",
      "3 6 8 sqrt entropy False 500 17: Macro 0.697221 (0.083059)\n",
      "Testing 577/4320\n",
      "5 2 3 log2 gini True 50 17: Weighted 0.818015 (0.060054)\n",
      "5 2 3 log2 gini True 50 17: Macro 0.713437 (0.079013)\n",
      "Testing 578/4320\n",
      "5 2 3 log2 gini True 100 17: Weighted 0.809014 (0.051630)\n",
      "5 2 3 log2 gini True 100 17: Macro 0.702391 (0.068382)\n",
      "Testing 579/4320\n",
      "5 2 3 log2 gini True 200 17: Weighted 0.804397 (0.049109)\n",
      "5 2 3 log2 gini True 200 17: Macro 0.692616 (0.061673)\n",
      "Testing 580/4320\n",
      "5 2 3 log2 gini True 500 17: Weighted 0.813941 (0.055478)\n",
      "5 2 3 log2 gini True 500 17: Macro 0.709900 (0.075733)\n",
      "Testing 581/4320\n",
      "5 2 3 log2 gini False 50 17: Weighted 0.804627 (0.072614)\n",
      "5 2 3 log2 gini False 50 17: Macro 0.701445 (0.092151)\n",
      "Testing 582/4320\n",
      "5 2 3 log2 gini False 100 17: Weighted 0.813081 (0.059751)\n",
      "5 2 3 log2 gini False 100 17: Macro 0.712700 (0.075647)\n",
      "Testing 583/4320\n",
      "5 2 3 log2 gini False 200 17: Weighted 0.809244 (0.065497)\n",
      "5 2 3 log2 gini False 200 17: Macro 0.704564 (0.087453)\n",
      "Testing 584/4320\n",
      "5 2 3 log2 gini False 500 17: Weighted 0.809244 (0.065497)\n",
      "5 2 3 log2 gini False 500 17: Macro 0.704564 (0.087453)\n",
      "Testing 585/4320\n",
      "5 2 3 log2 entropy True 50 17: Weighted 0.804911 (0.060583)\n",
      "5 2 3 log2 entropy True 50 17: Macro 0.694348 (0.077564)\n",
      "Testing 586/4320\n",
      "5 2 3 log2 entropy True 100 17: Weighted 0.813451 (0.059208)\n",
      "5 2 3 log2 entropy True 100 17: Macro 0.709778 (0.079802)\n",
      "Testing 587/4320\n",
      "5 2 3 log2 entropy True 200 17: Weighted 0.804317 (0.061898)\n",
      "5 2 3 log2 entropy True 200 17: Macro 0.697056 (0.080675)\n",
      "Testing 588/4320\n",
      "5 2 3 log2 entropy True 500 17: Weighted 0.808523 (0.055575)\n",
      "5 2 3 log2 entropy True 500 17: Macro 0.702270 (0.072850)\n",
      "Testing 589/4320\n",
      "5 2 3 log2 entropy False 50 17: Weighted 0.788636 (0.086808)\n",
      "5 2 3 log2 entropy False 50 17: Macro 0.680947 (0.106072)\n",
      "Testing 590/4320\n",
      "5 2 3 log2 entropy False 100 17: Weighted 0.788636 (0.086808)\n",
      "5 2 3 log2 entropy False 100 17: Macro 0.680947 (0.106072)\n",
      "Testing 591/4320\n",
      "5 2 3 log2 entropy False 200 17: Weighted 0.798644 (0.070719)\n",
      "5 2 3 log2 entropy False 200 17: Macro 0.693509 (0.086134)\n",
      "Testing 592/4320\n",
      "5 2 3 log2 entropy False 500 17: Weighted 0.787834 (0.088117)\n",
      "5 2 3 log2 entropy False 500 17: Macro 0.680688 (0.106489)\n",
      "Testing 593/4320\n",
      "5 2 3 sqrt gini True 50 17: Weighted 0.818015 (0.060054)\n",
      "5 2 3 sqrt gini True 50 17: Macro 0.713437 (0.079013)\n",
      "Testing 594/4320\n",
      "5 2 3 sqrt gini True 100 17: Weighted 0.809014 (0.051630)\n",
      "5 2 3 sqrt gini True 100 17: Macro 0.702391 (0.068382)\n",
      "Testing 595/4320\n",
      "5 2 3 sqrt gini True 200 17: Weighted 0.804397 (0.049109)\n",
      "5 2 3 sqrt gini True 200 17: Macro 0.692616 (0.061673)\n",
      "Testing 596/4320\n",
      "5 2 3 sqrt gini True 500 17: Weighted 0.813941 (0.055478)\n",
      "5 2 3 sqrt gini True 500 17: Macro 0.709900 (0.075733)\n",
      "Testing 597/4320\n",
      "5 2 3 sqrt gini False 50 17: Weighted 0.804627 (0.072614)\n",
      "5 2 3 sqrt gini False 50 17: Macro 0.701445 (0.092151)\n",
      "Testing 598/4320\n",
      "5 2 3 sqrt gini False 100 17: Weighted 0.813081 (0.059751)\n",
      "5 2 3 sqrt gini False 100 17: Macro 0.712700 (0.075647)\n",
      "Testing 599/4320\n",
      "5 2 3 sqrt gini False 200 17: Weighted 0.809244 (0.065497)\n",
      "5 2 3 sqrt gini False 200 17: Macro 0.704564 (0.087453)\n",
      "Testing 600/4320\n",
      "5 2 3 sqrt gini False 500 17: Weighted 0.809244 (0.065497)\n",
      "5 2 3 sqrt gini False 500 17: Macro 0.704564 (0.087453)\n",
      "Testing 601/4320\n",
      "5 2 3 sqrt entropy True 50 17: Weighted 0.804911 (0.060583)\n",
      "5 2 3 sqrt entropy True 50 17: Macro 0.694348 (0.077564)\n",
      "Testing 602/4320\n",
      "5 2 3 sqrt entropy True 100 17: Weighted 0.813451 (0.059208)\n",
      "5 2 3 sqrt entropy True 100 17: Macro 0.709778 (0.079802)\n",
      "Testing 603/4320\n",
      "5 2 3 sqrt entropy True 200 17: Weighted 0.804317 (0.061898)\n",
      "5 2 3 sqrt entropy True 200 17: Macro 0.697056 (0.080675)\n",
      "Testing 604/4320\n",
      "5 2 3 sqrt entropy True 500 17: Weighted 0.808523 (0.055575)\n",
      "5 2 3 sqrt entropy True 500 17: Macro 0.702270 (0.072850)\n",
      "Testing 605/4320\n",
      "5 2 3 sqrt entropy False 50 17: Weighted 0.788636 (0.086808)\n",
      "5 2 3 sqrt entropy False 50 17: Macro 0.680947 (0.106072)\n",
      "Testing 606/4320\n",
      "5 2 3 sqrt entropy False 100 17: Weighted 0.788636 (0.086808)\n",
      "5 2 3 sqrt entropy False 100 17: Macro 0.680947 (0.106072)\n",
      "Testing 607/4320\n",
      "5 2 3 sqrt entropy False 200 17: Weighted 0.798644 (0.070719)\n",
      "5 2 3 sqrt entropy False 200 17: Macro 0.693509 (0.086134)\n",
      "Testing 608/4320\n",
      "5 2 3 sqrt entropy False 500 17: Weighted 0.787834 (0.088117)\n",
      "5 2 3 sqrt entropy False 500 17: Macro 0.680688 (0.106489)\n",
      "Testing 609/4320\n",
      "5 2 5 log2 gini True 50 17: Weighted 0.821407 (0.062892)\n",
      "5 2 5 log2 gini True 50 17: Macro 0.721614 (0.084166)\n",
      "Testing 610/4320\n",
      "5 2 5 log2 gini True 100 17: Weighted 0.816624 (0.060205)\n",
      "5 2 5 log2 gini True 100 17: Macro 0.711473 (0.077270)\n",
      "Testing 611/4320\n",
      "5 2 5 log2 gini True 200 17: Weighted 0.809673 (0.062686)\n",
      "5 2 5 log2 gini True 200 17: Macro 0.701491 (0.081072)\n",
      "Testing 612/4320\n",
      "5 2 5 log2 gini True 500 17: Weighted 0.813188 (0.061148)\n",
      "5 2 5 log2 gini True 500 17: Macro 0.706448 (0.078733)\n",
      "Testing 613/4320\n",
      "5 2 5 log2 gini False 50 17: Weighted 0.808216 (0.082181)\n",
      "5 2 5 log2 gini False 50 17: Macro 0.698926 (0.120768)\n",
      "Testing 614/4320\n",
      "5 2 5 log2 gini False 100 17: Weighted 0.803696 (0.077900)\n",
      "5 2 5 log2 gini False 100 17: Macro 0.692114 (0.115319)\n",
      "Testing 615/4320\n",
      "5 2 5 log2 gini False 200 17: Weighted 0.812352 (0.075646)\n",
      "5 2 5 log2 gini False 200 17: Macro 0.708254 (0.105698)\n",
      "Testing 616/4320\n",
      "5 2 5 log2 gini False 500 17: Weighted 0.812352 (0.075646)\n",
      "5 2 5 log2 gini False 500 17: Macro 0.708254 (0.105698)\n",
      "Testing 617/4320\n",
      "5 2 5 log2 entropy True 50 17: Weighted 0.813188 (0.061148)\n",
      "5 2 5 log2 entropy True 50 17: Macro 0.706448 (0.078733)\n",
      "Testing 618/4320\n",
      "5 2 5 log2 entropy True 100 17: Weighted 0.821407 (0.062892)\n",
      "5 2 5 log2 entropy True 100 17: Macro 0.721614 (0.084166)\n",
      "Testing 619/4320\n",
      "5 2 5 log2 entropy True 200 17: Weighted 0.808426 (0.059274)\n",
      "5 2 5 log2 entropy True 200 17: Macro 0.699306 (0.075587)\n",
      "Testing 620/4320\n",
      "5 2 5 log2 entropy True 500 17: Weighted 0.811863 (0.058581)\n",
      "5 2 5 log2 entropy True 500 17: Macro 0.704330 (0.074545)\n",
      "Testing 621/4320\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 2 5 log2 entropy False 50 17: Weighted 0.808309 (0.072708)\n",
      "5 2 5 log2 entropy False 50 17: Macro 0.700217 (0.100455)\n",
      "Testing 622/4320\n",
      "5 2 5 log2 entropy False 100 17: Weighted 0.800353 (0.068032)\n",
      "5 2 5 log2 entropy False 100 17: Macro 0.688381 (0.094176)\n",
      "Testing 623/4320\n",
      "5 2 5 log2 entropy False 200 17: Weighted 0.798829 (0.071049)\n",
      "5 2 5 log2 entropy False 200 17: Macro 0.688032 (0.096843)\n",
      "Testing 624/4320\n",
      "5 2 5 log2 entropy False 500 17: Weighted 0.799789 (0.070916)\n",
      "5 2 5 log2 entropy False 500 17: Macro 0.687770 (0.096874)\n",
      "Testing 625/4320\n",
      "5 2 5 sqrt gini True 50 17: Weighted 0.821407 (0.062892)\n",
      "5 2 5 sqrt gini True 50 17: Macro 0.721614 (0.084166)\n",
      "Testing 626/4320\n",
      "5 2 5 sqrt gini True 100 17: Weighted 0.816624 (0.060205)\n",
      "5 2 5 sqrt gini True 100 17: Macro 0.711473 (0.077270)\n",
      "Testing 627/4320\n",
      "5 2 5 sqrt gini True 200 17: Weighted 0.809673 (0.062686)\n",
      "5 2 5 sqrt gini True 200 17: Macro 0.701491 (0.081072)\n",
      "Testing 628/4320\n",
      "5 2 5 sqrt gini True 500 17: Weighted 0.813188 (0.061148)\n",
      "5 2 5 sqrt gini True 500 17: Macro 0.706448 (0.078733)\n",
      "Testing 629/4320\n",
      "5 2 5 sqrt gini False 50 17: Weighted 0.808216 (0.082181)\n",
      "5 2 5 sqrt gini False 50 17: Macro 0.698926 (0.120768)\n",
      "Testing 630/4320\n",
      "5 2 5 sqrt gini False 100 17: Weighted 0.803696 (0.077900)\n",
      "5 2 5 sqrt gini False 100 17: Macro 0.692114 (0.115319)\n",
      "Testing 631/4320\n",
      "5 2 5 sqrt gini False 200 17: Weighted 0.812352 (0.075646)\n",
      "5 2 5 sqrt gini False 200 17: Macro 0.708254 (0.105698)\n",
      "Testing 632/4320\n",
      "5 2 5 sqrt gini False 500 17: Weighted 0.812352 (0.075646)\n",
      "5 2 5 sqrt gini False 500 17: Macro 0.708254 (0.105698)\n",
      "Testing 633/4320\n",
      "5 2 5 sqrt entropy True 50 17: Weighted 0.813188 (0.061148)\n",
      "5 2 5 sqrt entropy True 50 17: Macro 0.706448 (0.078733)\n",
      "Testing 634/4320\n",
      "5 2 5 sqrt entropy True 100 17: Weighted 0.821407 (0.062892)\n",
      "5 2 5 sqrt entropy True 100 17: Macro 0.721614 (0.084166)\n",
      "Testing 635/4320\n",
      "5 2 5 sqrt entropy True 200 17: Weighted 0.808426 (0.059274)\n",
      "5 2 5 sqrt entropy True 200 17: Macro 0.699306 (0.075587)\n",
      "Testing 636/4320\n",
      "5 2 5 sqrt entropy True 500 17: Weighted 0.811863 (0.058581)\n",
      "5 2 5 sqrt entropy True 500 17: Macro 0.704330 (0.074545)\n",
      "Testing 637/4320\n",
      "5 2 5 sqrt entropy False 50 17: Weighted 0.808309 (0.072708)\n",
      "5 2 5 sqrt entropy False 50 17: Macro 0.700217 (0.100455)\n",
      "Testing 638/4320\n",
      "5 2 5 sqrt entropy False 100 17: Weighted 0.800353 (0.068032)\n",
      "5 2 5 sqrt entropy False 100 17: Macro 0.688381 (0.094176)\n",
      "Testing 639/4320\n",
      "5 2 5 sqrt entropy False 200 17: Weighted 0.798829 (0.071049)\n",
      "5 2 5 sqrt entropy False 200 17: Macro 0.688032 (0.096843)\n",
      "Testing 640/4320\n",
      "5 2 5 sqrt entropy False 500 17: Weighted 0.799789 (0.070916)\n",
      "5 2 5 sqrt entropy False 500 17: Macro 0.687770 (0.096874)\n",
      "Testing 641/4320\n",
      "5 2 8 log2 gini True 50 17: Weighted 0.809334 (0.066998)\n",
      "5 2 8 log2 gini True 50 17: Macro 0.701309 (0.087649)\n",
      "Testing 642/4320\n",
      "5 2 8 log2 gini True 100 17: Weighted 0.820721 (0.066344)\n",
      "5 2 8 log2 gini True 100 17: Macro 0.714036 (0.092430)\n",
      "Testing 643/4320\n",
      "5 2 8 log2 gini True 200 17: Weighted 0.816652 (0.067360)\n",
      "5 2 8 log2 gini True 200 17: Macro 0.713673 (0.087620)\n",
      "Testing 644/4320\n",
      "5 2 8 log2 gini True 500 17: Weighted 0.812229 (0.061512)\n",
      "5 2 8 log2 gini True 500 17: Macro 0.706711 (0.078634)\n",
      "Testing 645/4320\n",
      "5 2 8 log2 gini False 50 17: Weighted 0.804333 (0.068679)\n",
      "5 2 8 log2 gini False 50 17: Macro 0.693402 (0.094129)\n",
      "Testing 646/4320\n",
      "5 2 8 log2 gini False 100 17: Weighted 0.809296 (0.071955)\n",
      "5 2 8 log2 gini False 100 17: Macro 0.702618 (0.101231)\n",
      "Testing 647/4320\n",
      "5 2 8 log2 gini False 200 17: Weighted 0.809296 (0.071955)\n",
      "5 2 8 log2 gini False 200 17: Macro 0.702618 (0.101231)\n",
      "Testing 648/4320\n",
      "5 2 8 log2 gini False 500 17: Weighted 0.804333 (0.068679)\n",
      "5 2 8 log2 gini False 500 17: Macro 0.693402 (0.094129)\n",
      "Testing 649/4320\n",
      "5 2 8 log2 entropy True 50 17: Weighted 0.809673 (0.062686)\n",
      "5 2 8 log2 entropy True 50 17: Macro 0.701491 (0.081072)\n",
      "Testing 650/4320\n",
      "5 2 8 log2 entropy True 100 17: Weighted 0.816001 (0.058417)\n",
      "5 2 8 log2 entropy True 100 17: Macro 0.715332 (0.078025)\n",
      "Testing 651/4320\n",
      "5 2 8 log2 entropy True 200 17: Weighted 0.812229 (0.061512)\n",
      "5 2 8 log2 entropy True 200 17: Macro 0.706711 (0.078634)\n",
      "Testing 652/4320\n",
      "5 2 8 log2 entropy True 500 17: Weighted 0.812229 (0.061512)\n",
      "5 2 8 log2 entropy True 500 17: Macro 0.706711 (0.078634)\n",
      "Testing 653/4320\n",
      "5 2 8 log2 entropy False 50 17: Weighted 0.799284 (0.066331)\n",
      "5 2 8 log2 entropy False 50 17: Macro 0.687687 (0.090862)\n",
      "Testing 654/4320\n",
      "5 2 8 log2 entropy False 100 17: Weighted 0.802850 (0.065211)\n",
      "5 2 8 log2 entropy False 100 17: Macro 0.692852 (0.089525)\n",
      "Testing 655/4320\n",
      "5 2 8 log2 entropy False 200 17: Weighted 0.799284 (0.066331)\n",
      "5 2 8 log2 entropy False 200 17: Macro 0.687687 (0.090862)\n",
      "Testing 656/4320\n",
      "5 2 8 log2 entropy False 500 17: Weighted 0.799284 (0.066331)\n",
      "5 2 8 log2 entropy False 500 17: Macro 0.687687 (0.090862)\n",
      "Testing 657/4320\n",
      "5 2 8 sqrt gini True 50 17: Weighted 0.809334 (0.066998)\n",
      "5 2 8 sqrt gini True 50 17: Macro 0.701309 (0.087649)\n",
      "Testing 658/4320\n",
      "5 2 8 sqrt gini True 100 17: Weighted 0.820721 (0.066344)\n",
      "5 2 8 sqrt gini True 100 17: Macro 0.714036 (0.092430)\n",
      "Testing 659/4320\n",
      "5 2 8 sqrt gini True 200 17: Weighted 0.816652 (0.067360)\n",
      "5 2 8 sqrt gini True 200 17: Macro 0.713673 (0.087620)\n",
      "Testing 660/4320\n",
      "5 2 8 sqrt gini True 500 17: Weighted 0.812229 (0.061512)\n",
      "5 2 8 sqrt gini True 500 17: Macro 0.706711 (0.078634)\n",
      "Testing 661/4320\n",
      "5 2 8 sqrt gini False 50 17: Weighted 0.804333 (0.068679)\n",
      "5 2 8 sqrt gini False 50 17: Macro 0.693402 (0.094129)\n",
      "Testing 662/4320\n",
      "5 2 8 sqrt gini False 100 17: Weighted 0.809296 (0.071955)\n",
      "5 2 8 sqrt gini False 100 17: Macro 0.702618 (0.101231)\n",
      "Testing 663/4320\n",
      "5 2 8 sqrt gini False 200 17: Weighted 0.809296 (0.071955)\n",
      "5 2 8 sqrt gini False 200 17: Macro 0.702618 (0.101231)\n",
      "Testing 664/4320\n",
      "5 2 8 sqrt gini False 500 17: Weighted 0.804333 (0.068679)\n",
      "5 2 8 sqrt gini False 500 17: Macro 0.693402 (0.094129)\n",
      "Testing 665/4320\n",
      "5 2 8 sqrt entropy True 50 17: Weighted 0.809673 (0.062686)\n",
      "5 2 8 sqrt entropy True 50 17: Macro 0.701491 (0.081072)\n",
      "Testing 666/4320\n",
      "5 2 8 sqrt entropy True 100 17: Weighted 0.816001 (0.058417)\n",
      "5 2 8 sqrt entropy True 100 17: Macro 0.715332 (0.078025)\n",
      "Testing 667/4320\n",
      "5 2 8 sqrt entropy True 200 17: Weighted 0.812229 (0.061512)\n",
      "5 2 8 sqrt entropy True 200 17: Macro 0.706711 (0.078634)\n",
      "Testing 668/4320\n",
      "5 2 8 sqrt entropy True 500 17: Weighted 0.812229 (0.061512)\n",
      "5 2 8 sqrt entropy True 500 17: Macro 0.706711 (0.078634)\n",
      "Testing 669/4320\n",
      "5 2 8 sqrt entropy False 50 17: Weighted 0.799284 (0.066331)\n",
      "5 2 8 sqrt entropy False 50 17: Macro 0.687687 (0.090862)\n",
      "Testing 670/4320\n",
      "5 2 8 sqrt entropy False 100 17: Weighted 0.802850 (0.065211)\n",
      "5 2 8 sqrt entropy False 100 17: Macro 0.692852 (0.089525)\n",
      "Testing 671/4320\n",
      "5 2 8 sqrt entropy False 200 17: Weighted 0.799284 (0.066331)\n",
      "5 2 8 sqrt entropy False 200 17: Macro 0.687687 (0.090862)\n",
      "Testing 672/4320\n",
      "5 2 8 sqrt entropy False 500 17: Weighted 0.799284 (0.066331)\n",
      "5 2 8 sqrt entropy False 500 17: Macro 0.687687 (0.090862)\n",
      "Testing 673/4320\n",
      "5 4 3 log2 gini True 50 17: Weighted 0.818015 (0.060054)\n",
      "5 4 3 log2 gini True 50 17: Macro 0.713437 (0.079013)\n",
      "Testing 674/4320\n",
      "5 4 3 log2 gini True 100 17: Weighted 0.809014 (0.051630)\n",
      "5 4 3 log2 gini True 100 17: Macro 0.702391 (0.068382)\n",
      "Testing 675/4320\n",
      "5 4 3 log2 gini True 200 17: Weighted 0.804397 (0.049109)\n",
      "5 4 3 log2 gini True 200 17: Macro 0.692616 (0.061673)\n",
      "Testing 676/4320\n",
      "5 4 3 log2 gini True 500 17: Weighted 0.813941 (0.055478)\n",
      "5 4 3 log2 gini True 500 17: Macro 0.709900 (0.075733)\n",
      "Testing 677/4320\n",
      "5 4 3 log2 gini False 50 17: Weighted 0.804627 (0.072614)\n",
      "5 4 3 log2 gini False 50 17: Macro 0.701445 (0.092151)\n",
      "Testing 678/4320\n",
      "5 4 3 log2 gini False 100 17: Weighted 0.813081 (0.059751)\n",
      "5 4 3 log2 gini False 100 17: Macro 0.712700 (0.075647)\n",
      "Testing 679/4320\n",
      "5 4 3 log2 gini False 200 17: Weighted 0.809244 (0.065497)\n",
      "5 4 3 log2 gini False 200 17: Macro 0.704564 (0.087453)\n",
      "Testing 680/4320\n",
      "5 4 3 log2 gini False 500 17: Weighted 0.809244 (0.065497)\n",
      "5 4 3 log2 gini False 500 17: Macro 0.704564 (0.087453)\n",
      "Testing 681/4320\n",
      "5 4 3 log2 entropy True 50 17: Weighted 0.804911 (0.060583)\n",
      "5 4 3 log2 entropy True 50 17: Macro 0.694348 (0.077564)\n",
      "Testing 682/4320\n",
      "5 4 3 log2 entropy True 100 17: Weighted 0.813451 (0.059208)\n",
      "5 4 3 log2 entropy True 100 17: Macro 0.709778 (0.079802)\n",
      "Testing 683/4320\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 4 3 log2 entropy True 200 17: Weighted 0.804317 (0.061898)\n",
      "5 4 3 log2 entropy True 200 17: Macro 0.697056 (0.080675)\n",
      "Testing 684/4320\n",
      "5 4 3 log2 entropy True 500 17: Weighted 0.808523 (0.055575)\n",
      "5 4 3 log2 entropy True 500 17: Macro 0.702270 (0.072850)\n",
      "Testing 685/4320\n",
      "5 4 3 log2 entropy False 50 17: Weighted 0.788636 (0.086808)\n",
      "5 4 3 log2 entropy False 50 17: Macro 0.680947 (0.106072)\n",
      "Testing 686/4320\n",
      "5 4 3 log2 entropy False 100 17: Weighted 0.788636 (0.086808)\n",
      "5 4 3 log2 entropy False 100 17: Macro 0.680947 (0.106072)\n",
      "Testing 687/4320\n",
      "5 4 3 log2 entropy False 200 17: Weighted 0.798644 (0.070719)\n",
      "5 4 3 log2 entropy False 200 17: Macro 0.693509 (0.086134)\n",
      "Testing 688/4320\n",
      "5 4 3 log2 entropy False 500 17: Weighted 0.787834 (0.088117)\n",
      "5 4 3 log2 entropy False 500 17: Macro 0.680688 (0.106489)\n",
      "Testing 689/4320\n",
      "5 4 3 sqrt gini True 50 17: Weighted 0.818015 (0.060054)\n",
      "5 4 3 sqrt gini True 50 17: Macro 0.713437 (0.079013)\n",
      "Testing 690/4320\n",
      "5 4 3 sqrt gini True 100 17: Weighted 0.809014 (0.051630)\n",
      "5 4 3 sqrt gini True 100 17: Macro 0.702391 (0.068382)\n",
      "Testing 691/4320\n",
      "5 4 3 sqrt gini True 200 17: Weighted 0.804397 (0.049109)\n",
      "5 4 3 sqrt gini True 200 17: Macro 0.692616 (0.061673)\n",
      "Testing 692/4320\n",
      "5 4 3 sqrt gini True 500 17: Weighted 0.813941 (0.055478)\n",
      "5 4 3 sqrt gini True 500 17: Macro 0.709900 (0.075733)\n",
      "Testing 693/4320\n",
      "5 4 3 sqrt gini False 50 17: Weighted 0.804627 (0.072614)\n",
      "5 4 3 sqrt gini False 50 17: Macro 0.701445 (0.092151)\n",
      "Testing 694/4320\n",
      "5 4 3 sqrt gini False 100 17: Weighted 0.813081 (0.059751)\n",
      "5 4 3 sqrt gini False 100 17: Macro 0.712700 (0.075647)\n",
      "Testing 695/4320\n",
      "5 4 3 sqrt gini False 200 17: Weighted 0.809244 (0.065497)\n",
      "5 4 3 sqrt gini False 200 17: Macro 0.704564 (0.087453)\n",
      "Testing 696/4320\n",
      "5 4 3 sqrt gini False 500 17: Weighted 0.809244 (0.065497)\n",
      "5 4 3 sqrt gini False 500 17: Macro 0.704564 (0.087453)\n",
      "Testing 697/4320\n",
      "5 4 3 sqrt entropy True 50 17: Weighted 0.804911 (0.060583)\n",
      "5 4 3 sqrt entropy True 50 17: Macro 0.694348 (0.077564)\n",
      "Testing 698/4320\n",
      "5 4 3 sqrt entropy True 100 17: Weighted 0.813451 (0.059208)\n",
      "5 4 3 sqrt entropy True 100 17: Macro 0.709778 (0.079802)\n",
      "Testing 699/4320\n",
      "5 4 3 sqrt entropy True 200 17: Weighted 0.804317 (0.061898)\n",
      "5 4 3 sqrt entropy True 200 17: Macro 0.697056 (0.080675)\n",
      "Testing 700/4320\n",
      "5 4 3 sqrt entropy True 500 17: Weighted 0.808523 (0.055575)\n",
      "5 4 3 sqrt entropy True 500 17: Macro 0.702270 (0.072850)\n",
      "Testing 701/4320\n",
      "5 4 3 sqrt entropy False 50 17: Weighted 0.788636 (0.086808)\n",
      "5 4 3 sqrt entropy False 50 17: Macro 0.680947 (0.106072)\n",
      "Testing 702/4320\n",
      "5 4 3 sqrt entropy False 100 17: Weighted 0.788636 (0.086808)\n",
      "5 4 3 sqrt entropy False 100 17: Macro 0.680947 (0.106072)\n",
      "Testing 703/4320\n",
      "5 4 3 sqrt entropy False 200 17: Weighted 0.798644 (0.070719)\n",
      "5 4 3 sqrt entropy False 200 17: Macro 0.693509 (0.086134)\n",
      "Testing 704/4320\n",
      "5 4 3 sqrt entropy False 500 17: Weighted 0.787834 (0.088117)\n",
      "5 4 3 sqrt entropy False 500 17: Macro 0.680688 (0.106489)\n",
      "Testing 705/4320\n",
      "5 4 5 log2 gini True 50 17: Weighted 0.821407 (0.062892)\n",
      "5 4 5 log2 gini True 50 17: Macro 0.721614 (0.084166)\n",
      "Testing 706/4320\n",
      "5 4 5 log2 gini True 100 17: Weighted 0.816624 (0.060205)\n",
      "5 4 5 log2 gini True 100 17: Macro 0.711473 (0.077270)\n",
      "Testing 707/4320\n",
      "5 4 5 log2 gini True 200 17: Weighted 0.809673 (0.062686)\n",
      "5 4 5 log2 gini True 200 17: Macro 0.701491 (0.081072)\n",
      "Testing 708/4320\n",
      "5 4 5 log2 gini True 500 17: Weighted 0.813188 (0.061148)\n",
      "5 4 5 log2 gini True 500 17: Macro 0.706448 (0.078733)\n",
      "Testing 709/4320\n",
      "5 4 5 log2 gini False 50 17: Weighted 0.808216 (0.082181)\n",
      "5 4 5 log2 gini False 50 17: Macro 0.698926 (0.120768)\n",
      "Testing 710/4320\n",
      "5 4 5 log2 gini False 100 17: Weighted 0.803696 (0.077900)\n",
      "5 4 5 log2 gini False 100 17: Macro 0.692114 (0.115319)\n",
      "Testing 711/4320\n",
      "5 4 5 log2 gini False 200 17: Weighted 0.812352 (0.075646)\n",
      "5 4 5 log2 gini False 200 17: Macro 0.708254 (0.105698)\n",
      "Testing 712/4320\n",
      "5 4 5 log2 gini False 500 17: Weighted 0.812352 (0.075646)\n",
      "5 4 5 log2 gini False 500 17: Macro 0.708254 (0.105698)\n",
      "Testing 713/4320\n",
      "5 4 5 log2 entropy True 50 17: Weighted 0.813188 (0.061148)\n",
      "5 4 5 log2 entropy True 50 17: Macro 0.706448 (0.078733)\n",
      "Testing 714/4320\n",
      "5 4 5 log2 entropy True 100 17: Weighted 0.821407 (0.062892)\n",
      "5 4 5 log2 entropy True 100 17: Macro 0.721614 (0.084166)\n",
      "Testing 715/4320\n",
      "5 4 5 log2 entropy True 200 17: Weighted 0.808426 (0.059274)\n",
      "5 4 5 log2 entropy True 200 17: Macro 0.699306 (0.075587)\n",
      "Testing 716/4320\n",
      "5 4 5 log2 entropy True 500 17: Weighted 0.811863 (0.058581)\n",
      "5 4 5 log2 entropy True 500 17: Macro 0.704330 (0.074545)\n",
      "Testing 717/4320\n",
      "5 4 5 log2 entropy False 50 17: Weighted 0.808309 (0.072708)\n",
      "5 4 5 log2 entropy False 50 17: Macro 0.700217 (0.100455)\n",
      "Testing 718/4320\n",
      "5 4 5 log2 entropy False 100 17: Weighted 0.800353 (0.068032)\n",
      "5 4 5 log2 entropy False 100 17: Macro 0.688381 (0.094176)\n",
      "Testing 719/4320\n",
      "5 4 5 log2 entropy False 200 17: Weighted 0.798829 (0.071049)\n",
      "5 4 5 log2 entropy False 200 17: Macro 0.688032 (0.096843)\n",
      "Testing 720/4320\n",
      "5 4 5 log2 entropy False 500 17: Weighted 0.799789 (0.070916)\n",
      "5 4 5 log2 entropy False 500 17: Macro 0.687770 (0.096874)\n",
      "Testing 721/4320\n",
      "5 4 5 sqrt gini True 50 17: Weighted 0.821407 (0.062892)\n",
      "5 4 5 sqrt gini True 50 17: Macro 0.721614 (0.084166)\n",
      "Testing 722/4320\n",
      "5 4 5 sqrt gini True 100 17: Weighted 0.816624 (0.060205)\n",
      "5 4 5 sqrt gini True 100 17: Macro 0.711473 (0.077270)\n",
      "Testing 723/4320\n",
      "5 4 5 sqrt gini True 200 17: Weighted 0.809673 (0.062686)\n",
      "5 4 5 sqrt gini True 200 17: Macro 0.701491 (0.081072)\n",
      "Testing 724/4320\n",
      "5 4 5 sqrt gini True 500 17: Weighted 0.813188 (0.061148)\n",
      "5 4 5 sqrt gini True 500 17: Macro 0.706448 (0.078733)\n",
      "Testing 725/4320\n",
      "5 4 5 sqrt gini False 50 17: Weighted 0.808216 (0.082181)\n",
      "5 4 5 sqrt gini False 50 17: Macro 0.698926 (0.120768)\n",
      "Testing 726/4320\n",
      "5 4 5 sqrt gini False 100 17: Weighted 0.803696 (0.077900)\n",
      "5 4 5 sqrt gini False 100 17: Macro 0.692114 (0.115319)\n",
      "Testing 727/4320\n",
      "5 4 5 sqrt gini False 200 17: Weighted 0.812352 (0.075646)\n",
      "5 4 5 sqrt gini False 200 17: Macro 0.708254 (0.105698)\n",
      "Testing 728/4320\n",
      "5 4 5 sqrt gini False 500 17: Weighted 0.812352 (0.075646)\n",
      "5 4 5 sqrt gini False 500 17: Macro 0.708254 (0.105698)\n",
      "Testing 729/4320\n",
      "5 4 5 sqrt entropy True 50 17: Weighted 0.813188 (0.061148)\n",
      "5 4 5 sqrt entropy True 50 17: Macro 0.706448 (0.078733)\n",
      "Testing 730/4320\n",
      "5 4 5 sqrt entropy True 100 17: Weighted 0.821407 (0.062892)\n",
      "5 4 5 sqrt entropy True 100 17: Macro 0.721614 (0.084166)\n",
      "Testing 731/4320\n",
      "5 4 5 sqrt entropy True 200 17: Weighted 0.808426 (0.059274)\n",
      "5 4 5 sqrt entropy True 200 17: Macro 0.699306 (0.075587)\n",
      "Testing 732/4320\n",
      "5 4 5 sqrt entropy True 500 17: Weighted 0.811863 (0.058581)\n",
      "5 4 5 sqrt entropy True 500 17: Macro 0.704330 (0.074545)\n",
      "Testing 733/4320\n",
      "5 4 5 sqrt entropy False 50 17: Weighted 0.808309 (0.072708)\n",
      "5 4 5 sqrt entropy False 50 17: Macro 0.700217 (0.100455)\n",
      "Testing 734/4320\n",
      "5 4 5 sqrt entropy False 100 17: Weighted 0.800353 (0.068032)\n",
      "5 4 5 sqrt entropy False 100 17: Macro 0.688381 (0.094176)\n",
      "Testing 735/4320\n",
      "5 4 5 sqrt entropy False 200 17: Weighted 0.798829 (0.071049)\n",
      "5 4 5 sqrt entropy False 200 17: Macro 0.688032 (0.096843)\n",
      "Testing 736/4320\n",
      "5 4 5 sqrt entropy False 500 17: Weighted 0.799789 (0.070916)\n",
      "5 4 5 sqrt entropy False 500 17: Macro 0.687770 (0.096874)\n",
      "Testing 737/4320\n",
      "5 4 8 log2 gini True 50 17: Weighted 0.809334 (0.066998)\n",
      "5 4 8 log2 gini True 50 17: Macro 0.701309 (0.087649)\n",
      "Testing 738/4320\n",
      "5 4 8 log2 gini True 100 17: Weighted 0.820721 (0.066344)\n",
      "5 4 8 log2 gini True 100 17: Macro 0.714036 (0.092430)\n",
      "Testing 739/4320\n",
      "5 4 8 log2 gini True 200 17: Weighted 0.816652 (0.067360)\n",
      "5 4 8 log2 gini True 200 17: Macro 0.713673 (0.087620)\n",
      "Testing 740/4320\n",
      "5 4 8 log2 gini True 500 17: Weighted 0.812229 (0.061512)\n",
      "5 4 8 log2 gini True 500 17: Macro 0.706711 (0.078634)\n",
      "Testing 741/4320\n",
      "5 4 8 log2 gini False 50 17: Weighted 0.804333 (0.068679)\n",
      "5 4 8 log2 gini False 50 17: Macro 0.693402 (0.094129)\n",
      "Testing 742/4320\n",
      "5 4 8 log2 gini False 100 17: Weighted 0.809296 (0.071955)\n",
      "5 4 8 log2 gini False 100 17: Macro 0.702618 (0.101231)\n",
      "Testing 743/4320\n",
      "5 4 8 log2 gini False 200 17: Weighted 0.809296 (0.071955)\n",
      "5 4 8 log2 gini False 200 17: Macro 0.702618 (0.101231)\n",
      "Testing 744/4320\n",
      "5 4 8 log2 gini False 500 17: Weighted 0.804333 (0.068679)\n",
      "5 4 8 log2 gini False 500 17: Macro 0.693402 (0.094129)\n",
      "Testing 745/4320\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 4 8 log2 entropy True 50 17: Weighted 0.809673 (0.062686)\n",
      "5 4 8 log2 entropy True 50 17: Macro 0.701491 (0.081072)\n",
      "Testing 746/4320\n",
      "5 4 8 log2 entropy True 100 17: Weighted 0.816001 (0.058417)\n",
      "5 4 8 log2 entropy True 100 17: Macro 0.715332 (0.078025)\n",
      "Testing 747/4320\n",
      "5 4 8 log2 entropy True 200 17: Weighted 0.812229 (0.061512)\n",
      "5 4 8 log2 entropy True 200 17: Macro 0.706711 (0.078634)\n",
      "Testing 748/4320\n",
      "5 4 8 log2 entropy True 500 17: Weighted 0.812229 (0.061512)\n",
      "5 4 8 log2 entropy True 500 17: Macro 0.706711 (0.078634)\n",
      "Testing 749/4320\n",
      "5 4 8 log2 entropy False 50 17: Weighted 0.799284 (0.066331)\n",
      "5 4 8 log2 entropy False 50 17: Macro 0.687687 (0.090862)\n",
      "Testing 750/4320\n",
      "5 4 8 log2 entropy False 100 17: Weighted 0.802850 (0.065211)\n",
      "5 4 8 log2 entropy False 100 17: Macro 0.692852 (0.089525)\n",
      "Testing 751/4320\n",
      "5 4 8 log2 entropy False 200 17: Weighted 0.799284 (0.066331)\n",
      "5 4 8 log2 entropy False 200 17: Macro 0.687687 (0.090862)\n",
      "Testing 752/4320\n",
      "5 4 8 log2 entropy False 500 17: Weighted 0.799284 (0.066331)\n",
      "5 4 8 log2 entropy False 500 17: Macro 0.687687 (0.090862)\n",
      "Testing 753/4320\n",
      "5 4 8 sqrt gini True 50 17: Weighted 0.809334 (0.066998)\n",
      "5 4 8 sqrt gini True 50 17: Macro 0.701309 (0.087649)\n",
      "Testing 754/4320\n",
      "5 4 8 sqrt gini True 100 17: Weighted 0.820721 (0.066344)\n",
      "5 4 8 sqrt gini True 100 17: Macro 0.714036 (0.092430)\n",
      "Testing 755/4320\n",
      "5 4 8 sqrt gini True 200 17: Weighted 0.816652 (0.067360)\n",
      "5 4 8 sqrt gini True 200 17: Macro 0.713673 (0.087620)\n",
      "Testing 756/4320\n",
      "5 4 8 sqrt gini True 500 17: Weighted 0.812229 (0.061512)\n",
      "5 4 8 sqrt gini True 500 17: Macro 0.706711 (0.078634)\n",
      "Testing 757/4320\n",
      "5 4 8 sqrt gini False 50 17: Weighted 0.804333 (0.068679)\n",
      "5 4 8 sqrt gini False 50 17: Macro 0.693402 (0.094129)\n",
      "Testing 758/4320\n",
      "5 4 8 sqrt gini False 100 17: Weighted 0.809296 (0.071955)\n",
      "5 4 8 sqrt gini False 100 17: Macro 0.702618 (0.101231)\n",
      "Testing 759/4320\n",
      "5 4 8 sqrt gini False 200 17: Weighted 0.809296 (0.071955)\n",
      "5 4 8 sqrt gini False 200 17: Macro 0.702618 (0.101231)\n",
      "Testing 760/4320\n",
      "5 4 8 sqrt gini False 500 17: Weighted 0.804333 (0.068679)\n",
      "5 4 8 sqrt gini False 500 17: Macro 0.693402 (0.094129)\n",
      "Testing 761/4320\n",
      "5 4 8 sqrt entropy True 50 17: Weighted 0.809673 (0.062686)\n",
      "5 4 8 sqrt entropy True 50 17: Macro 0.701491 (0.081072)\n",
      "Testing 762/4320\n",
      "5 4 8 sqrt entropy True 100 17: Weighted 0.816001 (0.058417)\n",
      "5 4 8 sqrt entropy True 100 17: Macro 0.715332 (0.078025)\n",
      "Testing 763/4320\n",
      "5 4 8 sqrt entropy True 200 17: Weighted 0.812229 (0.061512)\n",
      "5 4 8 sqrt entropy True 200 17: Macro 0.706711 (0.078634)\n",
      "Testing 764/4320\n",
      "5 4 8 sqrt entropy True 500 17: Weighted 0.812229 (0.061512)\n",
      "5 4 8 sqrt entropy True 500 17: Macro 0.706711 (0.078634)\n",
      "Testing 765/4320\n",
      "5 4 8 sqrt entropy False 50 17: Weighted 0.799284 (0.066331)\n",
      "5 4 8 sqrt entropy False 50 17: Macro 0.687687 (0.090862)\n",
      "Testing 766/4320\n",
      "5 4 8 sqrt entropy False 100 17: Weighted 0.802850 (0.065211)\n",
      "5 4 8 sqrt entropy False 100 17: Macro 0.692852 (0.089525)\n",
      "Testing 767/4320\n",
      "5 4 8 sqrt entropy False 200 17: Weighted 0.799284 (0.066331)\n",
      "5 4 8 sqrt entropy False 200 17: Macro 0.687687 (0.090862)\n",
      "Testing 768/4320\n",
      "5 4 8 sqrt entropy False 500 17: Weighted 0.799284 (0.066331)\n",
      "5 4 8 sqrt entropy False 500 17: Macro 0.687687 (0.090862)\n",
      "Testing 769/4320\n",
      "5 6 3 log2 gini True 50 17: Weighted 0.818015 (0.060054)\n",
      "5 6 3 log2 gini True 50 17: Macro 0.713437 (0.079013)\n",
      "Testing 770/4320\n",
      "5 6 3 log2 gini True 100 17: Weighted 0.809014 (0.051630)\n",
      "5 6 3 log2 gini True 100 17: Macro 0.702391 (0.068382)\n",
      "Testing 771/4320\n",
      "5 6 3 log2 gini True 200 17: Weighted 0.804397 (0.049109)\n",
      "5 6 3 log2 gini True 200 17: Macro 0.692616 (0.061673)\n",
      "Testing 772/4320\n",
      "5 6 3 log2 gini True 500 17: Weighted 0.813941 (0.055478)\n",
      "5 6 3 log2 gini True 500 17: Macro 0.709900 (0.075733)\n",
      "Testing 773/4320\n",
      "5 6 3 log2 gini False 50 17: Weighted 0.804627 (0.072614)\n",
      "5 6 3 log2 gini False 50 17: Macro 0.701445 (0.092151)\n",
      "Testing 774/4320\n",
      "5 6 3 log2 gini False 100 17: Weighted 0.813081 (0.059751)\n",
      "5 6 3 log2 gini False 100 17: Macro 0.712700 (0.075647)\n",
      "Testing 775/4320\n",
      "5 6 3 log2 gini False 200 17: Weighted 0.809244 (0.065497)\n",
      "5 6 3 log2 gini False 200 17: Macro 0.704564 (0.087453)\n",
      "Testing 776/4320\n",
      "5 6 3 log2 gini False 500 17: Weighted 0.809244 (0.065497)\n",
      "5 6 3 log2 gini False 500 17: Macro 0.704564 (0.087453)\n",
      "Testing 777/4320\n",
      "5 6 3 log2 entropy True 50 17: Weighted 0.804911 (0.060583)\n",
      "5 6 3 log2 entropy True 50 17: Macro 0.694348 (0.077564)\n",
      "Testing 778/4320\n",
      "5 6 3 log2 entropy True 100 17: Weighted 0.813451 (0.059208)\n",
      "5 6 3 log2 entropy True 100 17: Macro 0.709778 (0.079802)\n",
      "Testing 779/4320\n",
      "5 6 3 log2 entropy True 200 17: Weighted 0.804317 (0.061898)\n",
      "5 6 3 log2 entropy True 200 17: Macro 0.697056 (0.080675)\n",
      "Testing 780/4320\n",
      "5 6 3 log2 entropy True 500 17: Weighted 0.808523 (0.055575)\n",
      "5 6 3 log2 entropy True 500 17: Macro 0.702270 (0.072850)\n",
      "Testing 781/4320\n",
      "5 6 3 log2 entropy False 50 17: Weighted 0.788636 (0.086808)\n",
      "5 6 3 log2 entropy False 50 17: Macro 0.680947 (0.106072)\n",
      "Testing 782/4320\n",
      "5 6 3 log2 entropy False 100 17: Weighted 0.788636 (0.086808)\n",
      "5 6 3 log2 entropy False 100 17: Macro 0.680947 (0.106072)\n",
      "Testing 783/4320\n",
      "5 6 3 log2 entropy False 200 17: Weighted 0.798644 (0.070719)\n",
      "5 6 3 log2 entropy False 200 17: Macro 0.693509 (0.086134)\n",
      "Testing 784/4320\n",
      "5 6 3 log2 entropy False 500 17: Weighted 0.787834 (0.088117)\n",
      "5 6 3 log2 entropy False 500 17: Macro 0.680688 (0.106489)\n",
      "Testing 785/4320\n",
      "5 6 3 sqrt gini True 50 17: Weighted 0.818015 (0.060054)\n",
      "5 6 3 sqrt gini True 50 17: Macro 0.713437 (0.079013)\n",
      "Testing 786/4320\n",
      "5 6 3 sqrt gini True 100 17: Weighted 0.809014 (0.051630)\n",
      "5 6 3 sqrt gini True 100 17: Macro 0.702391 (0.068382)\n",
      "Testing 787/4320\n",
      "5 6 3 sqrt gini True 200 17: Weighted 0.804397 (0.049109)\n",
      "5 6 3 sqrt gini True 200 17: Macro 0.692616 (0.061673)\n",
      "Testing 788/4320\n",
      "5 6 3 sqrt gini True 500 17: Weighted 0.813941 (0.055478)\n",
      "5 6 3 sqrt gini True 500 17: Macro 0.709900 (0.075733)\n",
      "Testing 789/4320\n",
      "5 6 3 sqrt gini False 50 17: Weighted 0.804627 (0.072614)\n",
      "5 6 3 sqrt gini False 50 17: Macro 0.701445 (0.092151)\n",
      "Testing 790/4320\n",
      "5 6 3 sqrt gini False 100 17: Weighted 0.813081 (0.059751)\n",
      "5 6 3 sqrt gini False 100 17: Macro 0.712700 (0.075647)\n",
      "Testing 791/4320\n",
      "5 6 3 sqrt gini False 200 17: Weighted 0.809244 (0.065497)\n",
      "5 6 3 sqrt gini False 200 17: Macro 0.704564 (0.087453)\n",
      "Testing 792/4320\n",
      "5 6 3 sqrt gini False 500 17: Weighted 0.809244 (0.065497)\n",
      "5 6 3 sqrt gini False 500 17: Macro 0.704564 (0.087453)\n",
      "Testing 793/4320\n",
      "5 6 3 sqrt entropy True 50 17: Weighted 0.804911 (0.060583)\n",
      "5 6 3 sqrt entropy True 50 17: Macro 0.694348 (0.077564)\n",
      "Testing 794/4320\n",
      "5 6 3 sqrt entropy True 100 17: Weighted 0.813451 (0.059208)\n",
      "5 6 3 sqrt entropy True 100 17: Macro 0.709778 (0.079802)\n",
      "Testing 795/4320\n",
      "5 6 3 sqrt entropy True 200 17: Weighted 0.804317 (0.061898)\n",
      "5 6 3 sqrt entropy True 200 17: Macro 0.697056 (0.080675)\n",
      "Testing 796/4320\n",
      "5 6 3 sqrt entropy True 500 17: Weighted 0.808523 (0.055575)\n",
      "5 6 3 sqrt entropy True 500 17: Macro 0.702270 (0.072850)\n",
      "Testing 797/4320\n",
      "5 6 3 sqrt entropy False 50 17: Weighted 0.788636 (0.086808)\n",
      "5 6 3 sqrt entropy False 50 17: Macro 0.680947 (0.106072)\n",
      "Testing 798/4320\n",
      "5 6 3 sqrt entropy False 100 17: Weighted 0.788636 (0.086808)\n",
      "5 6 3 sqrt entropy False 100 17: Macro 0.680947 (0.106072)\n",
      "Testing 799/4320\n",
      "5 6 3 sqrt entropy False 200 17: Weighted 0.798644 (0.070719)\n",
      "5 6 3 sqrt entropy False 200 17: Macro 0.693509 (0.086134)\n",
      "Testing 800/4320\n",
      "5 6 3 sqrt entropy False 500 17: Weighted 0.787834 (0.088117)\n",
      "5 6 3 sqrt entropy False 500 17: Macro 0.680688 (0.106489)\n",
      "Testing 801/4320\n",
      "5 6 5 log2 gini True 50 17: Weighted 0.821407 (0.062892)\n",
      "5 6 5 log2 gini True 50 17: Macro 0.721614 (0.084166)\n",
      "Testing 802/4320\n",
      "5 6 5 log2 gini True 100 17: Weighted 0.816624 (0.060205)\n",
      "5 6 5 log2 gini True 100 17: Macro 0.711473 (0.077270)\n",
      "Testing 803/4320\n",
      "5 6 5 log2 gini True 200 17: Weighted 0.809673 (0.062686)\n",
      "5 6 5 log2 gini True 200 17: Macro 0.701491 (0.081072)\n",
      "Testing 804/4320\n",
      "5 6 5 log2 gini True 500 17: Weighted 0.813188 (0.061148)\n",
      "5 6 5 log2 gini True 500 17: Macro 0.706448 (0.078733)\n",
      "Testing 805/4320\n",
      "5 6 5 log2 gini False 50 17: Weighted 0.808216 (0.082181)\n",
      "5 6 5 log2 gini False 50 17: Macro 0.698926 (0.120768)\n",
      "Testing 806/4320\n",
      "5 6 5 log2 gini False 100 17: Weighted 0.803696 (0.077900)\n",
      "5 6 5 log2 gini False 100 17: Macro 0.692114 (0.115319)\n",
      "Testing 807/4320\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 6 5 log2 gini False 200 17: Weighted 0.812352 (0.075646)\n",
      "5 6 5 log2 gini False 200 17: Macro 0.708254 (0.105698)\n",
      "Testing 808/4320\n",
      "5 6 5 log2 gini False 500 17: Weighted 0.812352 (0.075646)\n",
      "5 6 5 log2 gini False 500 17: Macro 0.708254 (0.105698)\n",
      "Testing 809/4320\n",
      "5 6 5 log2 entropy True 50 17: Weighted 0.813188 (0.061148)\n",
      "5 6 5 log2 entropy True 50 17: Macro 0.706448 (0.078733)\n",
      "Testing 810/4320\n",
      "5 6 5 log2 entropy True 100 17: Weighted 0.821407 (0.062892)\n",
      "5 6 5 log2 entropy True 100 17: Macro 0.721614 (0.084166)\n",
      "Testing 811/4320\n",
      "5 6 5 log2 entropy True 200 17: Weighted 0.808426 (0.059274)\n",
      "5 6 5 log2 entropy True 200 17: Macro 0.699306 (0.075587)\n",
      "Testing 812/4320\n",
      "5 6 5 log2 entropy True 500 17: Weighted 0.811863 (0.058581)\n",
      "5 6 5 log2 entropy True 500 17: Macro 0.704330 (0.074545)\n",
      "Testing 813/4320\n",
      "5 6 5 log2 entropy False 50 17: Weighted 0.808309 (0.072708)\n",
      "5 6 5 log2 entropy False 50 17: Macro 0.700217 (0.100455)\n",
      "Testing 814/4320\n",
      "5 6 5 log2 entropy False 100 17: Weighted 0.800353 (0.068032)\n",
      "5 6 5 log2 entropy False 100 17: Macro 0.688381 (0.094176)\n",
      "Testing 815/4320\n",
      "5 6 5 log2 entropy False 200 17: Weighted 0.798829 (0.071049)\n",
      "5 6 5 log2 entropy False 200 17: Macro 0.688032 (0.096843)\n",
      "Testing 816/4320\n",
      "5 6 5 log2 entropy False 500 17: Weighted 0.799789 (0.070916)\n",
      "5 6 5 log2 entropy False 500 17: Macro 0.687770 (0.096874)\n",
      "Testing 817/4320\n",
      "5 6 5 sqrt gini True 50 17: Weighted 0.821407 (0.062892)\n",
      "5 6 5 sqrt gini True 50 17: Macro 0.721614 (0.084166)\n",
      "Testing 818/4320\n",
      "5 6 5 sqrt gini True 100 17: Weighted 0.816624 (0.060205)\n",
      "5 6 5 sqrt gini True 100 17: Macro 0.711473 (0.077270)\n",
      "Testing 819/4320\n",
      "5 6 5 sqrt gini True 200 17: Weighted 0.809673 (0.062686)\n",
      "5 6 5 sqrt gini True 200 17: Macro 0.701491 (0.081072)\n",
      "Testing 820/4320\n",
      "5 6 5 sqrt gini True 500 17: Weighted 0.813188 (0.061148)\n",
      "5 6 5 sqrt gini True 500 17: Macro 0.706448 (0.078733)\n",
      "Testing 821/4320\n",
      "5 6 5 sqrt gini False 50 17: Weighted 0.808216 (0.082181)\n",
      "5 6 5 sqrt gini False 50 17: Macro 0.698926 (0.120768)\n",
      "Testing 822/4320\n",
      "5 6 5 sqrt gini False 100 17: Weighted 0.803696 (0.077900)\n",
      "5 6 5 sqrt gini False 100 17: Macro 0.692114 (0.115319)\n",
      "Testing 823/4320\n",
      "5 6 5 sqrt gini False 200 17: Weighted 0.812352 (0.075646)\n",
      "5 6 5 sqrt gini False 200 17: Macro 0.708254 (0.105698)\n",
      "Testing 824/4320\n",
      "5 6 5 sqrt gini False 500 17: Weighted 0.812352 (0.075646)\n",
      "5 6 5 sqrt gini False 500 17: Macro 0.708254 (0.105698)\n",
      "Testing 825/4320\n",
      "5 6 5 sqrt entropy True 50 17: Weighted 0.813188 (0.061148)\n",
      "5 6 5 sqrt entropy True 50 17: Macro 0.706448 (0.078733)\n",
      "Testing 826/4320\n",
      "5 6 5 sqrt entropy True 100 17: Weighted 0.821407 (0.062892)\n",
      "5 6 5 sqrt entropy True 100 17: Macro 0.721614 (0.084166)\n",
      "Testing 827/4320\n",
      "5 6 5 sqrt entropy True 200 17: Weighted 0.808426 (0.059274)\n",
      "5 6 5 sqrt entropy True 200 17: Macro 0.699306 (0.075587)\n",
      "Testing 828/4320\n",
      "5 6 5 sqrt entropy True 500 17: Weighted 0.811863 (0.058581)\n",
      "5 6 5 sqrt entropy True 500 17: Macro 0.704330 (0.074545)\n",
      "Testing 829/4320\n",
      "5 6 5 sqrt entropy False 50 17: Weighted 0.808309 (0.072708)\n",
      "5 6 5 sqrt entropy False 50 17: Macro 0.700217 (0.100455)\n",
      "Testing 830/4320\n",
      "5 6 5 sqrt entropy False 100 17: Weighted 0.800353 (0.068032)\n",
      "5 6 5 sqrt entropy False 100 17: Macro 0.688381 (0.094176)\n",
      "Testing 831/4320\n",
      "5 6 5 sqrt entropy False 200 17: Weighted 0.798829 (0.071049)\n",
      "5 6 5 sqrt entropy False 200 17: Macro 0.688032 (0.096843)\n",
      "Testing 832/4320\n",
      "5 6 5 sqrt entropy False 500 17: Weighted 0.799789 (0.070916)\n",
      "5 6 5 sqrt entropy False 500 17: Macro 0.687770 (0.096874)\n",
      "Testing 833/4320\n",
      "5 6 8 log2 gini True 50 17: Weighted 0.809334 (0.066998)\n",
      "5 6 8 log2 gini True 50 17: Macro 0.701309 (0.087649)\n",
      "Testing 834/4320\n",
      "5 6 8 log2 gini True 100 17: Weighted 0.820721 (0.066344)\n",
      "5 6 8 log2 gini True 100 17: Macro 0.714036 (0.092430)\n",
      "Testing 835/4320\n",
      "5 6 8 log2 gini True 200 17: Weighted 0.816652 (0.067360)\n",
      "5 6 8 log2 gini True 200 17: Macro 0.713673 (0.087620)\n",
      "Testing 836/4320\n",
      "5 6 8 log2 gini True 500 17: Weighted 0.812229 (0.061512)\n",
      "5 6 8 log2 gini True 500 17: Macro 0.706711 (0.078634)\n",
      "Testing 837/4320\n",
      "5 6 8 log2 gini False 50 17: Weighted 0.804333 (0.068679)\n",
      "5 6 8 log2 gini False 50 17: Macro 0.693402 (0.094129)\n",
      "Testing 838/4320\n",
      "5 6 8 log2 gini False 100 17: Weighted 0.809296 (0.071955)\n",
      "5 6 8 log2 gini False 100 17: Macro 0.702618 (0.101231)\n",
      "Testing 839/4320\n",
      "5 6 8 log2 gini False 200 17: Weighted 0.809296 (0.071955)\n",
      "5 6 8 log2 gini False 200 17: Macro 0.702618 (0.101231)\n",
      "Testing 840/4320\n",
      "5 6 8 log2 gini False 500 17: Weighted 0.804333 (0.068679)\n",
      "5 6 8 log2 gini False 500 17: Macro 0.693402 (0.094129)\n",
      "Testing 841/4320\n",
      "5 6 8 log2 entropy True 50 17: Weighted 0.809673 (0.062686)\n",
      "5 6 8 log2 entropy True 50 17: Macro 0.701491 (0.081072)\n",
      "Testing 842/4320\n",
      "5 6 8 log2 entropy True 100 17: Weighted 0.816001 (0.058417)\n",
      "5 6 8 log2 entropy True 100 17: Macro 0.715332 (0.078025)\n",
      "Testing 843/4320\n",
      "5 6 8 log2 entropy True 200 17: Weighted 0.812229 (0.061512)\n",
      "5 6 8 log2 entropy True 200 17: Macro 0.706711 (0.078634)\n",
      "Testing 844/4320\n",
      "5 6 8 log2 entropy True 500 17: Weighted 0.812229 (0.061512)\n",
      "5 6 8 log2 entropy True 500 17: Macro 0.706711 (0.078634)\n",
      "Testing 845/4320\n",
      "5 6 8 log2 entropy False 50 17: Weighted 0.799284 (0.066331)\n",
      "5 6 8 log2 entropy False 50 17: Macro 0.687687 (0.090862)\n",
      "Testing 846/4320\n",
      "5 6 8 log2 entropy False 100 17: Weighted 0.802850 (0.065211)\n",
      "5 6 8 log2 entropy False 100 17: Macro 0.692852 (0.089525)\n",
      "Testing 847/4320\n",
      "5 6 8 log2 entropy False 200 17: Weighted 0.799284 (0.066331)\n",
      "5 6 8 log2 entropy False 200 17: Macro 0.687687 (0.090862)\n",
      "Testing 848/4320\n",
      "5 6 8 log2 entropy False 500 17: Weighted 0.799284 (0.066331)\n",
      "5 6 8 log2 entropy False 500 17: Macro 0.687687 (0.090862)\n",
      "Testing 849/4320\n",
      "5 6 8 sqrt gini True 50 17: Weighted 0.809334 (0.066998)\n",
      "5 6 8 sqrt gini True 50 17: Macro 0.701309 (0.087649)\n",
      "Testing 850/4320\n",
      "5 6 8 sqrt gini True 100 17: Weighted 0.820721 (0.066344)\n",
      "5 6 8 sqrt gini True 100 17: Macro 0.714036 (0.092430)\n",
      "Testing 851/4320\n",
      "5 6 8 sqrt gini True 200 17: Weighted 0.816652 (0.067360)\n",
      "5 6 8 sqrt gini True 200 17: Macro 0.713673 (0.087620)\n",
      "Testing 852/4320\n",
      "5 6 8 sqrt gini True 500 17: Weighted 0.812229 (0.061512)\n",
      "5 6 8 sqrt gini True 500 17: Macro 0.706711 (0.078634)\n",
      "Testing 853/4320\n",
      "5 6 8 sqrt gini False 50 17: Weighted 0.804333 (0.068679)\n",
      "5 6 8 sqrt gini False 50 17: Macro 0.693402 (0.094129)\n",
      "Testing 854/4320\n",
      "5 6 8 sqrt gini False 100 17: Weighted 0.809296 (0.071955)\n",
      "5 6 8 sqrt gini False 100 17: Macro 0.702618 (0.101231)\n",
      "Testing 855/4320\n",
      "5 6 8 sqrt gini False 200 17: Weighted 0.809296 (0.071955)\n",
      "5 6 8 sqrt gini False 200 17: Macro 0.702618 (0.101231)\n",
      "Testing 856/4320\n",
      "5 6 8 sqrt gini False 500 17: Weighted 0.804333 (0.068679)\n",
      "5 6 8 sqrt gini False 500 17: Macro 0.693402 (0.094129)\n",
      "Testing 857/4320\n",
      "5 6 8 sqrt entropy True 50 17: Weighted 0.809673 (0.062686)\n",
      "5 6 8 sqrt entropy True 50 17: Macro 0.701491 (0.081072)\n",
      "Testing 858/4320\n",
      "5 6 8 sqrt entropy True 100 17: Weighted 0.816001 (0.058417)\n",
      "5 6 8 sqrt entropy True 100 17: Macro 0.715332 (0.078025)\n",
      "Testing 859/4320\n",
      "5 6 8 sqrt entropy True 200 17: Weighted 0.812229 (0.061512)\n",
      "5 6 8 sqrt entropy True 200 17: Macro 0.706711 (0.078634)\n",
      "Testing 860/4320\n",
      "5 6 8 sqrt entropy True 500 17: Weighted 0.812229 (0.061512)\n",
      "5 6 8 sqrt entropy True 500 17: Macro 0.706711 (0.078634)\n",
      "Testing 861/4320\n",
      "5 6 8 sqrt entropy False 50 17: Weighted 0.799284 (0.066331)\n",
      "5 6 8 sqrt entropy False 50 17: Macro 0.687687 (0.090862)\n",
      "Testing 862/4320\n",
      "5 6 8 sqrt entropy False 100 17: Weighted 0.802850 (0.065211)\n",
      "5 6 8 sqrt entropy False 100 17: Macro 0.692852 (0.089525)\n",
      "Testing 863/4320\n",
      "5 6 8 sqrt entropy False 200 17: Weighted 0.799284 (0.066331)\n",
      "5 6 8 sqrt entropy False 200 17: Macro 0.687687 (0.090862)\n",
      "Testing 864/4320\n",
      "5 6 8 sqrt entropy False 500 17: Weighted 0.799284 (0.066331)\n",
      "5 6 8 sqrt entropy False 500 17: Macro 0.687687 (0.090862)\n",
      "Testing 865/4320\n",
      "1 2 3 log2 gini True 50 29: Weighted 0.799924 (0.064510)\n",
      "1 2 3 log2 gini True 50 29: Macro 0.689124 (0.080763)\n",
      "Testing 866/4320\n",
      "1 2 3 log2 gini True 100 29: Weighted 0.800391 (0.054362)\n",
      "1 2 3 log2 gini True 100 29: Macro 0.687536 (0.068319)\n",
      "Testing 867/4320\n",
      "1 2 3 log2 gini True 200 29: Weighted 0.809935 (0.060810)\n",
      "1 2 3 log2 gini True 200 29: Macro 0.704820 (0.082311)\n",
      "Testing 868/4320\n",
      "1 2 3 log2 gini True 500 29: Weighted 0.813941 (0.055478)\n",
      "1 2 3 log2 gini True 500 29: Macro 0.709900 (0.075733)\n",
      "Testing 869/4320\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 2 3 log2 gini False 50 29: Weighted 0.800801 (0.062924)\n",
      "1 2 3 log2 gini False 50 29: Macro 0.692099 (0.082395)\n",
      "Testing 870/4320\n",
      "1 2 3 log2 gini False 100 29: Weighted 0.798644 (0.070719)\n",
      "1 2 3 log2 gini False 100 29: Macro 0.693509 (0.086134)\n",
      "Testing 871/4320\n",
      "1 2 3 log2 gini False 200 29: Weighted 0.804765 (0.061493)\n",
      "1 2 3 log2 gini False 200 29: Macro 0.700947 (0.084665)\n",
      "Testing 872/4320\n",
      "1 2 3 log2 gini False 500 29: Weighted 0.804627 (0.072614)\n",
      "1 2 3 log2 gini False 500 29: Macro 0.701445 (0.092151)\n",
      "Testing 873/4320\n",
      "1 2 3 log2 entropy True 50 29: Weighted 0.805007 (0.056975)\n",
      "1 2 3 log2 entropy True 50 29: Macro 0.697312 (0.075095)\n",
      "Testing 874/4320\n",
      "1 2 3 log2 entropy True 100 29: Weighted 0.809935 (0.060810)\n",
      "1 2 3 log2 entropy True 100 29: Macro 0.704820 (0.082311)\n",
      "Testing 875/4320\n",
      "1 2 3 log2 entropy True 200 29: Weighted 0.805007 (0.056975)\n",
      "1 2 3 log2 entropy True 200 29: Macro 0.697312 (0.075095)\n",
      "Testing 876/4320\n",
      "1 2 3 log2 entropy True 500 29: Weighted 0.805007 (0.056975)\n",
      "1 2 3 log2 entropy True 500 29: Macro 0.697312 (0.075095)\n",
      "Testing 877/4320\n",
      "1 2 3 log2 entropy False 50 29: Weighted 0.782580 (0.097085)\n",
      "1 2 3 log2 entropy False 50 29: Macro 0.671174 (0.115799)\n",
      "Testing 878/4320\n",
      "1 2 3 log2 entropy False 100 29: Weighted 0.788781 (0.086901)\n",
      "1 2 3 log2 entropy False 100 29: Macro 0.678314 (0.104148)\n",
      "Testing 879/4320\n",
      "1 2 3 log2 entropy False 200 29: Weighted 0.783355 (0.084050)\n",
      "1 2 3 log2 entropy False 200 29: Macro 0.677071 (0.103379)\n",
      "Testing 880/4320\n",
      "1 2 3 log2 entropy False 500 29: Weighted 0.787834 (0.088117)\n",
      "1 2 3 log2 entropy False 500 29: Macro 0.680688 (0.106489)\n",
      "Testing 881/4320\n",
      "1 2 3 sqrt gini True 50 29: Weighted 0.799924 (0.064510)\n",
      "1 2 3 sqrt gini True 50 29: Macro 0.689124 (0.080763)\n",
      "Testing 882/4320\n",
      "1 2 3 sqrt gini True 100 29: Weighted 0.800391 (0.054362)\n",
      "1 2 3 sqrt gini True 100 29: Macro 0.687536 (0.068319)\n",
      "Testing 883/4320\n",
      "1 2 3 sqrt gini True 200 29: Weighted 0.809935 (0.060810)\n",
      "1 2 3 sqrt gini True 200 29: Macro 0.704820 (0.082311)\n",
      "Testing 884/4320\n",
      "1 2 3 sqrt gini True 500 29: Weighted 0.813941 (0.055478)\n",
      "1 2 3 sqrt gini True 500 29: Macro 0.709900 (0.075733)\n",
      "Testing 885/4320\n",
      "1 2 3 sqrt gini False 50 29: Weighted 0.800801 (0.062924)\n",
      "1 2 3 sqrt gini False 50 29: Macro 0.692099 (0.082395)\n",
      "Testing 886/4320\n",
      "1 2 3 sqrt gini False 100 29: Weighted 0.798644 (0.070719)\n",
      "1 2 3 sqrt gini False 100 29: Macro 0.693509 (0.086134)\n",
      "Testing 887/4320\n",
      "1 2 3 sqrt gini False 200 29: Weighted 0.804765 (0.061493)\n",
      "1 2 3 sqrt gini False 200 29: Macro 0.700947 (0.084665)\n",
      "Testing 888/4320\n",
      "1 2 3 sqrt gini False 500 29: Weighted 0.804627 (0.072614)\n",
      "1 2 3 sqrt gini False 500 29: Macro 0.701445 (0.092151)\n",
      "Testing 889/4320\n",
      "1 2 3 sqrt entropy True 50 29: Weighted 0.805007 (0.056975)\n",
      "1 2 3 sqrt entropy True 50 29: Macro 0.697312 (0.075095)\n",
      "Testing 890/4320\n",
      "1 2 3 sqrt entropy True 100 29: Weighted 0.809935 (0.060810)\n",
      "1 2 3 sqrt entropy True 100 29: Macro 0.704820 (0.082311)\n",
      "Testing 891/4320\n",
      "1 2 3 sqrt entropy True 200 29: Weighted 0.805007 (0.056975)\n",
      "1 2 3 sqrt entropy True 200 29: Macro 0.697312 (0.075095)\n",
      "Testing 892/4320\n",
      "1 2 3 sqrt entropy True 500 29: Weighted 0.805007 (0.056975)\n",
      "1 2 3 sqrt entropy True 500 29: Macro 0.697312 (0.075095)\n",
      "Testing 893/4320\n",
      "1 2 3 sqrt entropy False 50 29: Weighted 0.782580 (0.097085)\n",
      "1 2 3 sqrt entropy False 50 29: Macro 0.671174 (0.115799)\n",
      "Testing 894/4320\n",
      "1 2 3 sqrt entropy False 100 29: Weighted 0.788781 (0.086901)\n",
      "1 2 3 sqrt entropy False 100 29: Macro 0.678314 (0.104148)\n",
      "Testing 895/4320\n",
      "1 2 3 sqrt entropy False 200 29: Weighted 0.783355 (0.084050)\n",
      "1 2 3 sqrt entropy False 200 29: Macro 0.677071 (0.103379)\n",
      "Testing 896/4320\n",
      "1 2 3 sqrt entropy False 500 29: Weighted 0.787834 (0.088117)\n",
      "1 2 3 sqrt entropy False 500 29: Macro 0.680688 (0.106489)\n",
      "Testing 897/4320\n",
      "1 2 5 log2 gini True 50 29: Weighted 0.791663 (0.049368)\n",
      "1 2 5 log2 gini True 50 29: Macro 0.683958 (0.059932)\n",
      "Testing 898/4320\n",
      "1 2 5 log2 gini True 100 29: Weighted 0.803722 (0.061157)\n",
      "1 2 5 log2 gini True 100 29: Macro 0.695738 (0.076918)\n",
      "Testing 899/4320\n",
      "1 2 5 log2 gini True 200 29: Weighted 0.803722 (0.061157)\n",
      "1 2 5 log2 gini True 200 29: Macro 0.695738 (0.076918)\n",
      "Testing 900/4320\n",
      "1 2 5 log2 gini True 500 29: Weighted 0.803722 (0.061157)\n",
      "1 2 5 log2 gini True 500 29: Macro 0.695738 (0.076918)\n",
      "Testing 901/4320\n",
      "1 2 5 log2 gini False 50 29: Weighted 0.794573 (0.063691)\n",
      "1 2 5 log2 gini False 50 29: Macro 0.689379 (0.093632)\n",
      "Testing 902/4320\n",
      "1 2 5 log2 gini False 100 29: Weighted 0.792510 (0.066969)\n",
      "1 2 5 log2 gini False 100 29: Macro 0.688866 (0.094456)\n",
      "Testing 903/4320\n",
      "1 2 5 log2 gini False 200 29: Weighted 0.792510 (0.066969)\n",
      "1 2 5 log2 gini False 200 29: Macro 0.688866 (0.094456)\n",
      "Testing 904/4320\n",
      "1 2 5 log2 gini False 500 29: Weighted 0.799501 (0.067904)\n",
      "1 2 5 log2 gini False 500 29: Macro 0.696888 (0.100110)\n",
      "Testing 905/4320\n",
      "1 2 5 log2 entropy True 50 29: Weighted 0.796132 (0.065146)\n",
      "1 2 5 log2 entropy True 50 29: Macro 0.688569 (0.084134)\n",
      "Testing 906/4320\n",
      "1 2 5 log2 entropy True 100 29: Weighted 0.802923 (0.065526)\n",
      "1 2 5 log2 entropy True 100 29: Macro 0.695518 (0.082698)\n",
      "Testing 907/4320\n",
      "1 2 5 log2 entropy True 200 29: Weighted 0.807540 (0.067537)\n",
      "1 2 5 log2 entropy True 200 29: Macro 0.705293 (0.087491)\n",
      "Testing 908/4320\n",
      "1 2 5 log2 entropy True 500 29: Weighted 0.802923 (0.065526)\n",
      "1 2 5 log2 entropy True 500 29: Macro 0.695518 (0.082698)\n",
      "Testing 909/4320\n",
      "1 2 5 log2 entropy False 50 29: Weighted 0.784486 (0.064225)\n",
      "1 2 5 log2 entropy False 50 29: Macro 0.674097 (0.088497)\n",
      "Testing 910/4320\n",
      "1 2 5 log2 entropy False 100 29: Weighted 0.784019 (0.063935)\n",
      "1 2 5 log2 entropy False 100 29: Macro 0.676449 (0.089869)\n",
      "Testing 911/4320\n",
      "1 2 5 log2 entropy False 200 29: Weighted 0.784019 (0.063935)\n",
      "1 2 5 log2 entropy False 200 29: Macro 0.676449 (0.089869)\n",
      "Testing 912/4320\n",
      "1 2 5 log2 entropy False 500 29: Weighted 0.780538 (0.064836)\n",
      "1 2 5 log2 entropy False 500 29: Macro 0.671530 (0.091060)\n",
      "Testing 913/4320\n",
      "1 2 5 sqrt gini True 50 29: Weighted 0.791663 (0.049368)\n",
      "1 2 5 sqrt gini True 50 29: Macro 0.683958 (0.059932)\n",
      "Testing 914/4320\n",
      "1 2 5 sqrt gini True 100 29: Weighted 0.803722 (0.061157)\n",
      "1 2 5 sqrt gini True 100 29: Macro 0.695738 (0.076918)\n",
      "Testing 915/4320\n",
      "1 2 5 sqrt gini True 200 29: Weighted 0.803722 (0.061157)\n",
      "1 2 5 sqrt gini True 200 29: Macro 0.695738 (0.076918)\n",
      "Testing 916/4320\n",
      "1 2 5 sqrt gini True 500 29: Weighted 0.803722 (0.061157)\n",
      "1 2 5 sqrt gini True 500 29: Macro 0.695738 (0.076918)\n",
      "Testing 917/4320\n",
      "1 2 5 sqrt gini False 50 29: Weighted 0.794573 (0.063691)\n",
      "1 2 5 sqrt gini False 50 29: Macro 0.689379 (0.093632)\n",
      "Testing 918/4320\n",
      "1 2 5 sqrt gini False 100 29: Weighted 0.792510 (0.066969)\n",
      "1 2 5 sqrt gini False 100 29: Macro 0.688866 (0.094456)\n",
      "Testing 919/4320\n",
      "1 2 5 sqrt gini False 200 29: Weighted 0.792510 (0.066969)\n",
      "1 2 5 sqrt gini False 200 29: Macro 0.688866 (0.094456)\n",
      "Testing 920/4320\n",
      "1 2 5 sqrt gini False 500 29: Weighted 0.799501 (0.067904)\n",
      "1 2 5 sqrt gini False 500 29: Macro 0.696888 (0.100110)\n",
      "Testing 921/4320\n",
      "1 2 5 sqrt entropy True 50 29: Weighted 0.796132 (0.065146)\n",
      "1 2 5 sqrt entropy True 50 29: Macro 0.688569 (0.084134)\n",
      "Testing 922/4320\n",
      "1 2 5 sqrt entropy True 100 29: Weighted 0.802923 (0.065526)\n",
      "1 2 5 sqrt entropy True 100 29: Macro 0.695518 (0.082698)\n",
      "Testing 923/4320\n",
      "1 2 5 sqrt entropy True 200 29: Weighted 0.807540 (0.067537)\n",
      "1 2 5 sqrt entropy True 200 29: Macro 0.705293 (0.087491)\n",
      "Testing 924/4320\n",
      "1 2 5 sqrt entropy True 500 29: Weighted 0.802923 (0.065526)\n",
      "1 2 5 sqrt entropy True 500 29: Macro 0.695518 (0.082698)\n",
      "Testing 925/4320\n",
      "1 2 5 sqrt entropy False 50 29: Weighted 0.784486 (0.064225)\n",
      "1 2 5 sqrt entropy False 50 29: Macro 0.674097 (0.088497)\n",
      "Testing 926/4320\n",
      "1 2 5 sqrt entropy False 100 29: Weighted 0.784019 (0.063935)\n",
      "1 2 5 sqrt entropy False 100 29: Macro 0.676449 (0.089869)\n",
      "Testing 927/4320\n",
      "1 2 5 sqrt entropy False 200 29: Weighted 0.784019 (0.063935)\n",
      "1 2 5 sqrt entropy False 200 29: Macro 0.676449 (0.089869)\n",
      "Testing 928/4320\n",
      "1 2 5 sqrt entropy False 500 29: Weighted 0.780538 (0.064836)\n",
      "1 2 5 sqrt entropy False 500 29: Macro 0.671530 (0.091060)\n",
      "Testing 929/4320\n",
      "1 2 8 log2 gini True 50 29: Weighted 0.790297 (0.054251)\n",
      "1 2 8 log2 gini True 50 29: Macro 0.677133 (0.065082)\n",
      "Testing 930/4320\n",
      "1 2 8 log2 gini True 100 29: Weighted 0.794223 (0.057212)\n",
      "1 2 8 log2 gini True 100 29: Macro 0.678628 (0.073515)\n",
      "Testing 931/4320\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 2 8 log2 gini True 200 29: Weighted 0.803333 (0.059473)\n",
      "1 2 8 log2 gini True 200 29: Macro 0.696055 (0.073536)\n",
      "Testing 932/4320\n",
      "1 2 8 log2 gini True 500 29: Weighted 0.803395 (0.061571)\n",
      "1 2 8 log2 gini True 500 29: Macro 0.691340 (0.082835)\n",
      "Testing 933/4320\n",
      "1 2 8 log2 gini False 50 29: Weighted 0.783121 (0.049090)\n",
      "1 2 8 log2 gini False 50 29: Macro 0.674687 (0.069581)\n",
      "Testing 934/4320\n",
      "1 2 8 log2 gini False 100 29: Weighted 0.779511 (0.051498)\n",
      "1 2 8 log2 gini False 100 29: Macro 0.669627 (0.072389)\n",
      "Testing 935/4320\n",
      "1 2 8 log2 gini False 200 29: Weighted 0.783931 (0.056743)\n",
      "1 2 8 log2 gini False 200 29: Macro 0.676331 (0.080144)\n",
      "Testing 936/4320\n",
      "1 2 8 log2 gini False 500 29: Weighted 0.789015 (0.060793)\n",
      "1 2 8 log2 gini False 500 29: Macro 0.683754 (0.086109)\n",
      "Testing 937/4320\n",
      "1 2 8 log2 entropy True 50 29: Weighted 0.794943 (0.055250)\n",
      "1 2 8 log2 entropy True 50 29: Macro 0.690323 (0.073436)\n",
      "Testing 938/4320\n",
      "1 2 8 log2 entropy True 100 29: Weighted 0.801817 (0.053810)\n",
      "1 2 8 log2 entropy True 100 29: Macro 0.694549 (0.066165)\n",
      "Testing 939/4320\n",
      "1 2 8 log2 entropy True 200 29: Weighted 0.797418 (0.066036)\n",
      "1 2 8 log2 entropy True 200 29: Macro 0.690901 (0.079504)\n",
      "Testing 940/4320\n",
      "1 2 8 log2 entropy True 500 29: Weighted 0.798813 (0.052987)\n",
      "1 2 8 log2 entropy True 500 29: Macro 0.689244 (0.063891)\n",
      "Testing 941/4320\n",
      "1 2 8 log2 entropy False 50 29: Weighted 0.790775 (0.044267)\n",
      "1 2 8 log2 entropy False 50 29: Macro 0.687733 (0.058004)\n",
      "Testing 942/4320\n",
      "1 2 8 log2 entropy False 100 29: Weighted 0.790097 (0.044613)\n",
      "1 2 8 log2 entropy False 100 29: Macro 0.688487 (0.057701)\n",
      "Testing 943/4320\n",
      "1 2 8 log2 entropy False 200 29: Weighted 0.786797 (0.054734)\n",
      "1 2 8 log2 entropy False 200 29: Macro 0.681886 (0.076936)\n",
      "Testing 944/4320\n",
      "1 2 8 log2 entropy False 500 29: Weighted 0.786797 (0.054734)\n",
      "1 2 8 log2 entropy False 500 29: Macro 0.681886 (0.076936)\n",
      "Testing 945/4320\n",
      "1 2 8 sqrt gini True 50 29: Weighted 0.790297 (0.054251)\n",
      "1 2 8 sqrt gini True 50 29: Macro 0.677133 (0.065082)\n",
      "Testing 946/4320\n",
      "1 2 8 sqrt gini True 100 29: Weighted 0.794223 (0.057212)\n",
      "1 2 8 sqrt gini True 100 29: Macro 0.678628 (0.073515)\n",
      "Testing 947/4320\n",
      "1 2 8 sqrt gini True 200 29: Weighted 0.803333 (0.059473)\n",
      "1 2 8 sqrt gini True 200 29: Macro 0.696055 (0.073536)\n",
      "Testing 948/4320\n",
      "1 2 8 sqrt gini True 500 29: Weighted 0.803395 (0.061571)\n",
      "1 2 8 sqrt gini True 500 29: Macro 0.691340 (0.082835)\n",
      "Testing 949/4320\n",
      "1 2 8 sqrt gini False 50 29: Weighted 0.783121 (0.049090)\n",
      "1 2 8 sqrt gini False 50 29: Macro 0.674687 (0.069581)\n",
      "Testing 950/4320\n",
      "1 2 8 sqrt gini False 100 29: Weighted 0.779511 (0.051498)\n",
      "1 2 8 sqrt gini False 100 29: Macro 0.669627 (0.072389)\n",
      "Testing 951/4320\n",
      "1 2 8 sqrt gini False 200 29: Weighted 0.783931 (0.056743)\n",
      "1 2 8 sqrt gini False 200 29: Macro 0.676331 (0.080144)\n",
      "Testing 952/4320\n",
      "1 2 8 sqrt gini False 500 29: Weighted 0.789015 (0.060793)\n",
      "1 2 8 sqrt gini False 500 29: Macro 0.683754 (0.086109)\n",
      "Testing 953/4320\n",
      "1 2 8 sqrt entropy True 50 29: Weighted 0.794943 (0.055250)\n",
      "1 2 8 sqrt entropy True 50 29: Macro 0.690323 (0.073436)\n",
      "Testing 954/4320\n",
      "1 2 8 sqrt entropy True 100 29: Weighted 0.801817 (0.053810)\n",
      "1 2 8 sqrt entropy True 100 29: Macro 0.694549 (0.066165)\n",
      "Testing 955/4320\n",
      "1 2 8 sqrt entropy True 200 29: Weighted 0.797418 (0.066036)\n",
      "1 2 8 sqrt entropy True 200 29: Macro 0.690901 (0.079504)\n",
      "Testing 956/4320\n",
      "1 2 8 sqrt entropy True 500 29: Weighted 0.798813 (0.052987)\n",
      "1 2 8 sqrt entropy True 500 29: Macro 0.689244 (0.063891)\n",
      "Testing 957/4320\n",
      "1 2 8 sqrt entropy False 50 29: Weighted 0.790775 (0.044267)\n",
      "1 2 8 sqrt entropy False 50 29: Macro 0.687733 (0.058004)\n",
      "Testing 958/4320\n",
      "1 2 8 sqrt entropy False 100 29: Weighted 0.790097 (0.044613)\n",
      "1 2 8 sqrt entropy False 100 29: Macro 0.688487 (0.057701)\n",
      "Testing 959/4320\n",
      "1 2 8 sqrt entropy False 200 29: Weighted 0.786797 (0.054734)\n",
      "1 2 8 sqrt entropy False 200 29: Macro 0.681886 (0.076936)\n",
      "Testing 960/4320\n",
      "1 2 8 sqrt entropy False 500 29: Weighted 0.786797 (0.054734)\n",
      "1 2 8 sqrt entropy False 500 29: Macro 0.681886 (0.076936)\n",
      "Testing 961/4320\n",
      "1 4 3 log2 gini True 50 29: Weighted 0.799924 (0.064510)\n",
      "1 4 3 log2 gini True 50 29: Macro 0.689124 (0.080763)\n",
      "Testing 962/4320\n",
      "1 4 3 log2 gini True 100 29: Weighted 0.800391 (0.054362)\n",
      "1 4 3 log2 gini True 100 29: Macro 0.687536 (0.068319)\n",
      "Testing 963/4320\n",
      "1 4 3 log2 gini True 200 29: Weighted 0.809935 (0.060810)\n",
      "1 4 3 log2 gini True 200 29: Macro 0.704820 (0.082311)\n",
      "Testing 964/4320\n",
      "1 4 3 log2 gini True 500 29: Weighted 0.813941 (0.055478)\n",
      "1 4 3 log2 gini True 500 29: Macro 0.709900 (0.075733)\n",
      "Testing 965/4320\n",
      "1 4 3 log2 gini False 50 29: Weighted 0.796132 (0.065146)\n",
      "1 4 3 log2 gini False 50 29: Macro 0.688569 (0.084134)\n",
      "Testing 966/4320\n",
      "1 4 3 log2 gini False 100 29: Weighted 0.799612 (0.063399)\n",
      "1 4 3 log2 gini False 100 29: Macro 0.693488 (0.081826)\n",
      "Testing 967/4320\n",
      "1 4 3 log2 gini False 200 29: Weighted 0.804540 (0.067263)\n",
      "1 4 3 log2 gini False 200 29: Macro 0.700997 (0.088818)\n",
      "Testing 968/4320\n",
      "1 4 3 log2 gini False 500 29: Weighted 0.808377 (0.061974)\n",
      "1 4 3 log2 gini False 500 29: Macro 0.709132 (0.077596)\n",
      "Testing 969/4320\n",
      "1 4 3 log2 entropy True 50 29: Weighted 0.805007 (0.056975)\n",
      "1 4 3 log2 entropy True 50 29: Macro 0.697312 (0.075095)\n",
      "Testing 970/4320\n",
      "1 4 3 log2 entropy True 100 29: Weighted 0.809935 (0.060810)\n",
      "1 4 3 log2 entropy True 100 29: Macro 0.704820 (0.082311)\n",
      "Testing 971/4320\n",
      "1 4 3 log2 entropy True 200 29: Weighted 0.805007 (0.056975)\n",
      "1 4 3 log2 entropy True 200 29: Macro 0.697312 (0.075095)\n",
      "Testing 972/4320\n",
      "1 4 3 log2 entropy True 500 29: Weighted 0.805007 (0.056975)\n",
      "1 4 3 log2 entropy True 500 29: Macro 0.697312 (0.075095)\n",
      "Testing 973/4320\n",
      "1 4 3 log2 entropy False 50 29: Weighted 0.782580 (0.097085)\n",
      "1 4 3 log2 entropy False 50 29: Macro 0.671174 (0.115799)\n",
      "Testing 974/4320\n",
      "1 4 3 log2 entropy False 100 29: Weighted 0.788781 (0.086901)\n",
      "1 4 3 log2 entropy False 100 29: Macro 0.678314 (0.104148)\n",
      "Testing 975/4320\n",
      "1 4 3 log2 entropy False 200 29: Weighted 0.787834 (0.088117)\n",
      "1 4 3 log2 entropy False 200 29: Macro 0.680688 (0.106489)\n",
      "Testing 976/4320\n",
      "1 4 3 log2 entropy False 500 29: Weighted 0.787834 (0.088117)\n",
      "1 4 3 log2 entropy False 500 29: Macro 0.680688 (0.106489)\n",
      "Testing 977/4320\n",
      "1 4 3 sqrt gini True 50 29: Weighted 0.799924 (0.064510)\n",
      "1 4 3 sqrt gini True 50 29: Macro 0.689124 (0.080763)\n",
      "Testing 978/4320\n",
      "1 4 3 sqrt gini True 100 29: Weighted 0.800391 (0.054362)\n",
      "1 4 3 sqrt gini True 100 29: Macro 0.687536 (0.068319)\n",
      "Testing 979/4320\n",
      "1 4 3 sqrt gini True 200 29: Weighted 0.809935 (0.060810)\n",
      "1 4 3 sqrt gini True 200 29: Macro 0.704820 (0.082311)\n",
      "Testing 980/4320\n",
      "1 4 3 sqrt gini True 500 29: Weighted 0.813941 (0.055478)\n",
      "1 4 3 sqrt gini True 500 29: Macro 0.709900 (0.075733)\n",
      "Testing 981/4320\n",
      "1 4 3 sqrt gini False 50 29: Weighted 0.796132 (0.065146)\n",
      "1 4 3 sqrt gini False 50 29: Macro 0.688569 (0.084134)\n",
      "Testing 982/4320\n",
      "1 4 3 sqrt gini False 100 29: Weighted 0.799612 (0.063399)\n",
      "1 4 3 sqrt gini False 100 29: Macro 0.693488 (0.081826)\n",
      "Testing 983/4320\n",
      "1 4 3 sqrt gini False 200 29: Weighted 0.804540 (0.067263)\n",
      "1 4 3 sqrt gini False 200 29: Macro 0.700997 (0.088818)\n",
      "Testing 984/4320\n",
      "1 4 3 sqrt gini False 500 29: Weighted 0.808377 (0.061974)\n",
      "1 4 3 sqrt gini False 500 29: Macro 0.709132 (0.077596)\n",
      "Testing 985/4320\n",
      "1 4 3 sqrt entropy True 50 29: Weighted 0.805007 (0.056975)\n",
      "1 4 3 sqrt entropy True 50 29: Macro 0.697312 (0.075095)\n",
      "Testing 986/4320\n",
      "1 4 3 sqrt entropy True 100 29: Weighted 0.809935 (0.060810)\n",
      "1 4 3 sqrt entropy True 100 29: Macro 0.704820 (0.082311)\n",
      "Testing 987/4320\n",
      "1 4 3 sqrt entropy True 200 29: Weighted 0.805007 (0.056975)\n",
      "1 4 3 sqrt entropy True 200 29: Macro 0.697312 (0.075095)\n",
      "Testing 988/4320\n",
      "1 4 3 sqrt entropy True 500 29: Weighted 0.805007 (0.056975)\n",
      "1 4 3 sqrt entropy True 500 29: Macro 0.697312 (0.075095)\n",
      "Testing 989/4320\n",
      "1 4 3 sqrt entropy False 50 29: Weighted 0.782580 (0.097085)\n",
      "1 4 3 sqrt entropy False 50 29: Macro 0.671174 (0.115799)\n",
      "Testing 990/4320\n",
      "1 4 3 sqrt entropy False 100 29: Weighted 0.788781 (0.086901)\n",
      "1 4 3 sqrt entropy False 100 29: Macro 0.678314 (0.104148)\n",
      "Testing 991/4320\n",
      "1 4 3 sqrt entropy False 200 29: Weighted 0.787834 (0.088117)\n",
      "1 4 3 sqrt entropy False 200 29: Macro 0.680688 (0.106489)\n",
      "Testing 992/4320\n",
      "1 4 3 sqrt entropy False 500 29: Weighted 0.787834 (0.088117)\n",
      "1 4 3 sqrt entropy False 500 29: Macro 0.680688 (0.106489)\n",
      "Testing 993/4320\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 4 5 log2 gini True 50 29: Weighted 0.796952 (0.065392)\n",
      "1 4 5 log2 gini True 50 29: Macro 0.689452 (0.079523)\n",
      "Testing 994/4320\n",
      "1 4 5 log2 gini True 100 29: Weighted 0.803722 (0.061157)\n",
      "1 4 5 log2 gini True 100 29: Macro 0.695738 (0.076918)\n",
      "Testing 995/4320\n",
      "1 4 5 log2 gini True 200 29: Weighted 0.803722 (0.061157)\n",
      "1 4 5 log2 gini True 200 29: Macro 0.695738 (0.076918)\n",
      "Testing 996/4320\n",
      "1 4 5 log2 gini True 500 29: Weighted 0.803722 (0.061157)\n",
      "1 4 5 log2 gini True 500 29: Macro 0.695738 (0.076918)\n",
      "Testing 997/4320\n",
      "1 4 5 log2 gini False 50 29: Weighted 0.803576 (0.073375)\n",
      "1 4 5 log2 gini False 50 29: Macro 0.696618 (0.100788)\n",
      "Testing 998/4320\n",
      "1 4 5 log2 gini False 100 29: Weighted 0.799047 (0.068230)\n",
      "1 4 5 log2 gini False 100 29: Macro 0.692948 (0.097024)\n",
      "Testing 999/4320\n",
      "1 4 5 log2 gini False 200 29: Weighted 0.803576 (0.073375)\n",
      "1 4 5 log2 gini False 200 29: Macro 0.696618 (0.100788)\n",
      "Testing 1000/4320\n",
      "1 4 5 log2 gini False 500 29: Weighted 0.808504 (0.076483)\n",
      "1 4 5 log2 gini False 500 29: Macro 0.704126 (0.106322)\n",
      "Testing 1001/4320\n",
      "1 4 5 log2 entropy True 50 29: Weighted 0.797069 (0.073056)\n",
      "1 4 5 log2 entropy True 50 29: Macro 0.690479 (0.094901)\n",
      "Testing 1002/4320\n",
      "1 4 5 log2 entropy True 100 29: Weighted 0.802923 (0.065526)\n",
      "1 4 5 log2 entropy True 100 29: Macro 0.695518 (0.082698)\n",
      "Testing 1003/4320\n",
      "1 4 5 log2 entropy True 200 29: Weighted 0.804132 (0.068859)\n",
      "1 4 5 log2 entropy True 200 29: Macro 0.700300 (0.089236)\n",
      "Testing 1004/4320\n",
      "1 4 5 log2 entropy True 500 29: Weighted 0.802923 (0.065526)\n",
      "1 4 5 log2 entropy True 500 29: Macro 0.695518 (0.082698)\n",
      "Testing 1005/4320\n",
      "1 4 5 log2 entropy False 50 29: Weighted 0.795552 (0.072121)\n",
      "1 4 5 log2 entropy False 50 29: Macro 0.681849 (0.096421)\n",
      "Testing 1006/4320\n",
      "1 4 5 log2 entropy False 100 29: Weighted 0.792567 (0.063186)\n",
      "1 4 5 log2 entropy False 100 29: Macro 0.689007 (0.080569)\n",
      "Testing 1007/4320\n",
      "1 4 5 log2 entropy False 200 29: Weighted 0.793615 (0.070617)\n",
      "1 4 5 log2 entropy False 200 29: Macro 0.687757 (0.087408)\n",
      "Testing 1008/4320\n",
      "1 4 5 log2 entropy False 500 29: Weighted 0.789541 (0.076051)\n",
      "1 4 5 log2 entropy False 500 29: Macro 0.678769 (0.099708)\n",
      "Testing 1009/4320\n",
      "1 4 5 sqrt gini True 50 29: Weighted 0.796952 (0.065392)\n",
      "1 4 5 sqrt gini True 50 29: Macro 0.689452 (0.079523)\n",
      "Testing 1010/4320\n",
      "1 4 5 sqrt gini True 100 29: Weighted 0.803722 (0.061157)\n",
      "1 4 5 sqrt gini True 100 29: Macro 0.695738 (0.076918)\n",
      "Testing 1011/4320\n",
      "1 4 5 sqrt gini True 200 29: Weighted 0.803722 (0.061157)\n",
      "1 4 5 sqrt gini True 200 29: Macro 0.695738 (0.076918)\n",
      "Testing 1012/4320\n",
      "1 4 5 sqrt gini True 500 29: Weighted 0.803722 (0.061157)\n",
      "1 4 5 sqrt gini True 500 29: Macro 0.695738 (0.076918)\n",
      "Testing 1013/4320\n",
      "1 4 5 sqrt gini False 50 29: Weighted 0.803576 (0.073375)\n",
      "1 4 5 sqrt gini False 50 29: Macro 0.696618 (0.100788)\n",
      "Testing 1014/4320\n",
      "1 4 5 sqrt gini False 100 29: Weighted 0.799047 (0.068230)\n",
      "1 4 5 sqrt gini False 100 29: Macro 0.692948 (0.097024)\n",
      "Testing 1015/4320\n",
      "1 4 5 sqrt gini False 200 29: Weighted 0.803576 (0.073375)\n",
      "1 4 5 sqrt gini False 200 29: Macro 0.696618 (0.100788)\n",
      "Testing 1016/4320\n",
      "1 4 5 sqrt gini False 500 29: Weighted 0.808504 (0.076483)\n",
      "1 4 5 sqrt gini False 500 29: Macro 0.704126 (0.106322)\n",
      "Testing 1017/4320\n",
      "1 4 5 sqrt entropy True 50 29: Weighted 0.797069 (0.073056)\n",
      "1 4 5 sqrt entropy True 50 29: Macro 0.690479 (0.094901)\n",
      "Testing 1018/4320\n",
      "1 4 5 sqrt entropy True 100 29: Weighted 0.802923 (0.065526)\n",
      "1 4 5 sqrt entropy True 100 29: Macro 0.695518 (0.082698)\n",
      "Testing 1019/4320\n",
      "1 4 5 sqrt entropy True 200 29: Weighted 0.804132 (0.068859)\n",
      "1 4 5 sqrt entropy True 200 29: Macro 0.700300 (0.089236)\n",
      "Testing 1020/4320\n",
      "1 4 5 sqrt entropy True 500 29: Weighted 0.802923 (0.065526)\n",
      "1 4 5 sqrt entropy True 500 29: Macro 0.695518 (0.082698)\n",
      "Testing 1021/4320\n",
      "1 4 5 sqrt entropy False 50 29: Weighted 0.795552 (0.072121)\n",
      "1 4 5 sqrt entropy False 50 29: Macro 0.681849 (0.096421)\n",
      "Testing 1022/4320\n",
      "1 4 5 sqrt entropy False 100 29: Weighted 0.792567 (0.063186)\n",
      "1 4 5 sqrt entropy False 100 29: Macro 0.689007 (0.080569)\n",
      "Testing 1023/4320\n",
      "1 4 5 sqrt entropy False 200 29: Weighted 0.793615 (0.070617)\n",
      "1 4 5 sqrt entropy False 200 29: Macro 0.687757 (0.087408)\n",
      "Testing 1024/4320\n",
      "1 4 5 sqrt entropy False 500 29: Weighted 0.789541 (0.076051)\n",
      "1 4 5 sqrt entropy False 500 29: Macro 0.678769 (0.099708)\n",
      "Testing 1025/4320\n",
      "1 4 8 log2 gini True 50 29: Weighted 0.790216 (0.061116)\n",
      "1 4 8 log2 gini True 50 29: Macro 0.673549 (0.078271)\n",
      "Testing 1026/4320\n",
      "1 4 8 log2 gini True 100 29: Weighted 0.794223 (0.057212)\n",
      "1 4 8 log2 gini True 100 29: Macro 0.678628 (0.073515)\n",
      "Testing 1027/4320\n",
      "1 4 8 log2 gini True 200 29: Weighted 0.802342 (0.050355)\n",
      "1 4 8 log2 gini True 200 29: Macro 0.694369 (0.060709)\n",
      "Testing 1028/4320\n",
      "1 4 8 log2 gini True 500 29: Weighted 0.803209 (0.049802)\n",
      "1 4 8 log2 gini True 500 29: Macro 0.694005 (0.060898)\n",
      "Testing 1029/4320\n",
      "1 4 8 log2 gini False 50 29: Weighted 0.797082 (0.065998)\n",
      "1 4 8 log2 gini False 50 29: Macro 0.692829 (0.084452)\n",
      "Testing 1030/4320\n",
      "1 4 8 log2 gini False 100 29: Weighted 0.789626 (0.070554)\n",
      "1 4 8 log2 gini False 100 29: Macro 0.682536 (0.096098)\n",
      "Testing 1031/4320\n",
      "1 4 8 log2 gini False 200 29: Weighted 0.798303 (0.073475)\n",
      "1 4 8 log2 gini False 200 29: Macro 0.695466 (0.095583)\n",
      "Testing 1032/4320\n",
      "1 4 8 log2 gini False 500 29: Weighted 0.798018 (0.071576)\n",
      "1 4 8 log2 gini False 500 29: Macro 0.690992 (0.094273)\n",
      "Testing 1033/4320\n",
      "1 4 8 log2 entropy True 50 29: Weighted 0.799423 (0.060407)\n",
      "1 4 8 log2 entropy True 50 29: Macro 0.693940 (0.077133)\n",
      "Testing 1034/4320\n",
      "1 4 8 log2 entropy True 100 29: Weighted 0.810953 (0.061918)\n",
      "1 4 8 log2 entropy True 100 29: Macro 0.711136 (0.079578)\n",
      "Testing 1035/4320\n",
      "1 4 8 log2 entropy True 200 29: Weighted 0.807950 (0.061651)\n",
      "1 4 8 log2 entropy True 200 29: Macro 0.705831 (0.078822)\n",
      "Testing 1036/4320\n",
      "1 4 8 log2 entropy True 500 29: Weighted 0.802342 (0.050355)\n",
      "1 4 8 log2 entropy True 500 29: Macro 0.694369 (0.060709)\n",
      "Testing 1037/4320\n",
      "1 4 8 log2 entropy False 50 29: Weighted 0.798593 (0.057874)\n",
      "1 4 8 log2 entropy False 50 29: Macro 0.696509 (0.069241)\n",
      "Testing 1038/4320\n",
      "1 4 8 log2 entropy False 100 29: Weighted 0.808961 (0.065466)\n",
      "1 4 8 log2 entropy False 100 29: Macro 0.710566 (0.081138)\n",
      "Testing 1039/4320\n",
      "1 4 8 log2 entropy False 200 29: Weighted 0.800073 (0.064371)\n",
      "1 4 8 log2 entropy False 200 29: Macro 0.693755 (0.084103)\n",
      "Testing 1040/4320\n",
      "1 4 8 log2 entropy False 500 29: Weighted 0.799396 (0.064706)\n",
      "1 4 8 log2 entropy False 500 29: Macro 0.694509 (0.083840)\n",
      "Testing 1041/4320\n",
      "1 4 8 sqrt gini True 50 29: Weighted 0.790216 (0.061116)\n",
      "1 4 8 sqrt gini True 50 29: Macro 0.673549 (0.078271)\n",
      "Testing 1042/4320\n",
      "1 4 8 sqrt gini True 100 29: Weighted 0.794223 (0.057212)\n",
      "1 4 8 sqrt gini True 100 29: Macro 0.678628 (0.073515)\n",
      "Testing 1043/4320\n",
      "1 4 8 sqrt gini True 200 29: Weighted 0.802342 (0.050355)\n",
      "1 4 8 sqrt gini True 200 29: Macro 0.694369 (0.060709)\n",
      "Testing 1044/4320\n",
      "1 4 8 sqrt gini True 500 29: Weighted 0.803209 (0.049802)\n",
      "1 4 8 sqrt gini True 500 29: Macro 0.694005 (0.060898)\n",
      "Testing 1045/4320\n",
      "1 4 8 sqrt gini False 50 29: Weighted 0.797082 (0.065998)\n",
      "1 4 8 sqrt gini False 50 29: Macro 0.692829 (0.084452)\n",
      "Testing 1046/4320\n",
      "1 4 8 sqrt gini False 100 29: Weighted 0.789626 (0.070554)\n",
      "1 4 8 sqrt gini False 100 29: Macro 0.682536 (0.096098)\n",
      "Testing 1047/4320\n",
      "1 4 8 sqrt gini False 200 29: Weighted 0.798303 (0.073475)\n",
      "1 4 8 sqrt gini False 200 29: Macro 0.695466 (0.095583)\n",
      "Testing 1048/4320\n",
      "1 4 8 sqrt gini False 500 29: Weighted 0.798018 (0.071576)\n",
      "1 4 8 sqrt gini False 500 29: Macro 0.690992 (0.094273)\n",
      "Testing 1049/4320\n",
      "1 4 8 sqrt entropy True 50 29: Weighted 0.799423 (0.060407)\n",
      "1 4 8 sqrt entropy True 50 29: Macro 0.693940 (0.077133)\n",
      "Testing 1050/4320\n",
      "1 4 8 sqrt entropy True 100 29: Weighted 0.810953 (0.061918)\n",
      "1 4 8 sqrt entropy True 100 29: Macro 0.711136 (0.079578)\n",
      "Testing 1051/4320\n",
      "1 4 8 sqrt entropy True 200 29: Weighted 0.807950 (0.061651)\n",
      "1 4 8 sqrt entropy True 200 29: Macro 0.705831 (0.078822)\n",
      "Testing 1052/4320\n",
      "1 4 8 sqrt entropy True 500 29: Weighted 0.802342 (0.050355)\n",
      "1 4 8 sqrt entropy True 500 29: Macro 0.694369 (0.060709)\n",
      "Testing 1053/4320\n",
      "1 4 8 sqrt entropy False 50 29: Weighted 0.798593 (0.057874)\n",
      "1 4 8 sqrt entropy False 50 29: Macro 0.696509 (0.069241)\n",
      "Testing 1054/4320\n",
      "1 4 8 sqrt entropy False 100 29: Weighted 0.808961 (0.065466)\n",
      "1 4 8 sqrt entropy False 100 29: Macro 0.710566 (0.081138)\n",
      "Testing 1055/4320\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 4 8 sqrt entropy False 200 29: Weighted 0.800073 (0.064371)\n",
      "1 4 8 sqrt entropy False 200 29: Macro 0.693755 (0.084103)\n",
      "Testing 1056/4320\n",
      "1 4 8 sqrt entropy False 500 29: Weighted 0.799396 (0.064706)\n",
      "1 4 8 sqrt entropy False 500 29: Macro 0.694509 (0.083840)\n",
      "Testing 1057/4320\n",
      "1 6 3 log2 gini True 50 29: Weighted 0.799924 (0.064510)\n",
      "1 6 3 log2 gini True 50 29: Macro 0.689124 (0.080763)\n",
      "Testing 1058/4320\n",
      "1 6 3 log2 gini True 100 29: Weighted 0.800391 (0.054362)\n",
      "1 6 3 log2 gini True 100 29: Macro 0.687536 (0.068319)\n",
      "Testing 1059/4320\n",
      "1 6 3 log2 gini True 200 29: Weighted 0.809935 (0.060810)\n",
      "1 6 3 log2 gini True 200 29: Macro 0.704820 (0.082311)\n",
      "Testing 1060/4320\n",
      "1 6 3 log2 gini True 500 29: Weighted 0.813941 (0.055478)\n",
      "1 6 3 log2 gini True 500 29: Macro 0.709900 (0.075733)\n",
      "Testing 1061/4320\n",
      "1 6 3 log2 gini False 50 29: Weighted 0.796132 (0.065146)\n",
      "1 6 3 log2 gini False 50 29: Macro 0.688569 (0.084134)\n",
      "Testing 1062/4320\n",
      "1 6 3 log2 gini False 100 29: Weighted 0.799612 (0.063399)\n",
      "1 6 3 log2 gini False 100 29: Macro 0.693488 (0.081826)\n",
      "Testing 1063/4320\n",
      "1 6 3 log2 gini False 200 29: Weighted 0.804540 (0.067263)\n",
      "1 6 3 log2 gini False 200 29: Macro 0.700997 (0.088818)\n",
      "Testing 1064/4320\n",
      "1 6 3 log2 gini False 500 29: Weighted 0.798867 (0.075476)\n",
      "1 6 3 log2 gini False 500 29: Macro 0.697450 (0.093953)\n",
      "Testing 1065/4320\n",
      "1 6 3 log2 entropy True 50 29: Weighted 0.805007 (0.056975)\n",
      "1 6 3 log2 entropy True 50 29: Macro 0.697312 (0.075095)\n",
      "Testing 1066/4320\n",
      "1 6 3 log2 entropy True 100 29: Weighted 0.809935 (0.060810)\n",
      "1 6 3 log2 entropy True 100 29: Macro 0.704820 (0.082311)\n",
      "Testing 1067/4320\n",
      "1 6 3 log2 entropy True 200 29: Weighted 0.805007 (0.056975)\n",
      "1 6 3 log2 entropy True 200 29: Macro 0.697312 (0.075095)\n",
      "Testing 1068/4320\n",
      "1 6 3 log2 entropy True 500 29: Weighted 0.805007 (0.056975)\n",
      "1 6 3 log2 entropy True 500 29: Macro 0.697312 (0.075095)\n",
      "Testing 1069/4320\n",
      "1 6 3 log2 entropy False 50 29: Weighted 0.782580 (0.097085)\n",
      "1 6 3 log2 entropy False 50 29: Macro 0.671174 (0.115799)\n",
      "Testing 1070/4320\n",
      "1 6 3 log2 entropy False 100 29: Weighted 0.788781 (0.086901)\n",
      "1 6 3 log2 entropy False 100 29: Macro 0.678314 (0.104148)\n",
      "Testing 1071/4320\n",
      "1 6 3 log2 entropy False 200 29: Weighted 0.787834 (0.088117)\n",
      "1 6 3 log2 entropy False 200 29: Macro 0.680688 (0.106489)\n",
      "Testing 1072/4320\n",
      "1 6 3 log2 entropy False 500 29: Weighted 0.787834 (0.088117)\n",
      "1 6 3 log2 entropy False 500 29: Macro 0.680688 (0.106489)\n",
      "Testing 1073/4320\n",
      "1 6 3 sqrt gini True 50 29: Weighted 0.799924 (0.064510)\n",
      "1 6 3 sqrt gini True 50 29: Macro 0.689124 (0.080763)\n",
      "Testing 1074/4320\n",
      "1 6 3 sqrt gini True 100 29: Weighted 0.800391 (0.054362)\n",
      "1 6 3 sqrt gini True 100 29: Macro 0.687536 (0.068319)\n",
      "Testing 1075/4320\n",
      "1 6 3 sqrt gini True 200 29: Weighted 0.809935 (0.060810)\n",
      "1 6 3 sqrt gini True 200 29: Macro 0.704820 (0.082311)\n",
      "Testing 1076/4320\n",
      "1 6 3 sqrt gini True 500 29: Weighted 0.813941 (0.055478)\n",
      "1 6 3 sqrt gini True 500 29: Macro 0.709900 (0.075733)\n",
      "Testing 1077/4320\n",
      "1 6 3 sqrt gini False 50 29: Weighted 0.796132 (0.065146)\n",
      "1 6 3 sqrt gini False 50 29: Macro 0.688569 (0.084134)\n",
      "Testing 1078/4320\n",
      "1 6 3 sqrt gini False 100 29: Weighted 0.799612 (0.063399)\n",
      "1 6 3 sqrt gini False 100 29: Macro 0.693488 (0.081826)\n",
      "Testing 1079/4320\n",
      "1 6 3 sqrt gini False 200 29: Weighted 0.804540 (0.067263)\n",
      "1 6 3 sqrt gini False 200 29: Macro 0.700997 (0.088818)\n",
      "Testing 1080/4320\n",
      "1 6 3 sqrt gini False 500 29: Weighted 0.798867 (0.075476)\n",
      "1 6 3 sqrt gini False 500 29: Macro 0.697450 (0.093953)\n",
      "Testing 1081/4320\n",
      "1 6 3 sqrt entropy True 50 29: Weighted 0.805007 (0.056975)\n",
      "1 6 3 sqrt entropy True 50 29: Macro 0.697312 (0.075095)\n",
      "Testing 1082/4320\n",
      "1 6 3 sqrt entropy True 100 29: Weighted 0.809935 (0.060810)\n",
      "1 6 3 sqrt entropy True 100 29: Macro 0.704820 (0.082311)\n",
      "Testing 1083/4320\n",
      "1 6 3 sqrt entropy True 200 29: Weighted 0.805007 (0.056975)\n",
      "1 6 3 sqrt entropy True 200 29: Macro 0.697312 (0.075095)\n",
      "Testing 1084/4320\n",
      "1 6 3 sqrt entropy True 500 29: Weighted 0.805007 (0.056975)\n",
      "1 6 3 sqrt entropy True 500 29: Macro 0.697312 (0.075095)\n",
      "Testing 1085/4320\n",
      "1 6 3 sqrt entropy False 50 29: Weighted 0.782580 (0.097085)\n",
      "1 6 3 sqrt entropy False 50 29: Macro 0.671174 (0.115799)\n",
      "Testing 1086/4320\n",
      "1 6 3 sqrt entropy False 100 29: Weighted 0.788781 (0.086901)\n",
      "1 6 3 sqrt entropy False 100 29: Macro 0.678314 (0.104148)\n",
      "Testing 1087/4320\n",
      "1 6 3 sqrt entropy False 200 29: Weighted 0.787834 (0.088117)\n",
      "1 6 3 sqrt entropy False 200 29: Macro 0.680688 (0.106489)\n",
      "Testing 1088/4320\n",
      "1 6 3 sqrt entropy False 500 29: Weighted 0.787834 (0.088117)\n",
      "1 6 3 sqrt entropy False 500 29: Macro 0.680688 (0.106489)\n",
      "Testing 1089/4320\n",
      "1 6 5 log2 gini True 50 29: Weighted 0.792948 (0.068991)\n",
      "1 6 5 log2 gini True 50 29: Macro 0.680982 (0.086991)\n",
      "Testing 1090/4320\n",
      "1 6 5 log2 gini True 100 29: Weighted 0.803722 (0.061157)\n",
      "1 6 5 log2 gini True 100 29: Macro 0.695738 (0.076918)\n",
      "Testing 1091/4320\n",
      "1 6 5 log2 gini True 200 29: Weighted 0.803722 (0.061157)\n",
      "1 6 5 log2 gini True 200 29: Macro 0.695738 (0.076918)\n",
      "Testing 1092/4320\n",
      "1 6 5 log2 gini True 500 29: Weighted 0.803722 (0.061157)\n",
      "1 6 5 log2 gini True 500 29: Macro 0.695738 (0.076918)\n",
      "Testing 1093/4320\n",
      "1 6 5 log2 gini False 50 29: Weighted 0.803068 (0.062114)\n",
      "1 6 5 log2 gini False 50 29: Macro 0.697768 (0.089456)\n",
      "Testing 1094/4320\n",
      "1 6 5 log2 gini False 100 29: Weighted 0.799047 (0.068230)\n",
      "1 6 5 log2 gini False 100 29: Macro 0.692948 (0.097024)\n",
      "Testing 1095/4320\n",
      "1 6 5 log2 gini False 200 29: Weighted 0.803576 (0.073375)\n",
      "1 6 5 log2 gini False 200 29: Macro 0.696618 (0.100788)\n",
      "Testing 1096/4320\n",
      "1 6 5 log2 gini False 500 29: Weighted 0.808504 (0.076483)\n",
      "1 6 5 log2 gini False 500 29: Macro 0.704126 (0.106322)\n",
      "Testing 1097/4320\n",
      "1 6 5 log2 entropy True 50 29: Weighted 0.792549 (0.067462)\n",
      "1 6 5 log2 entropy True 50 29: Macro 0.683667 (0.087205)\n",
      "Testing 1098/4320\n",
      "1 6 5 log2 entropy True 100 29: Weighted 0.799516 (0.066652)\n",
      "1 6 5 log2 entropy True 100 29: Macro 0.690524 (0.083962)\n",
      "Testing 1099/4320\n",
      "1 6 5 log2 entropy True 200 29: Weighted 0.799516 (0.066652)\n",
      "1 6 5 log2 entropy True 200 29: Macro 0.690524 (0.083962)\n",
      "Testing 1100/4320\n",
      "1 6 5 log2 entropy True 500 29: Weighted 0.802923 (0.065526)\n",
      "1 6 5 log2 entropy True 500 29: Macro 0.695518 (0.082698)\n",
      "Testing 1101/4320\n",
      "1 6 5 log2 entropy False 50 29: Weighted 0.790697 (0.066814)\n",
      "1 6 5 log2 entropy False 50 29: Macro 0.673202 (0.099501)\n",
      "Testing 1102/4320\n",
      "1 6 5 log2 entropy False 100 29: Weighted 0.784219 (0.075598)\n",
      "1 6 5 log2 entropy False 100 29: Macro 0.670300 (0.108965)\n",
      "Testing 1103/4320\n",
      "1 6 5 log2 entropy False 200 29: Weighted 0.788748 (0.081104)\n",
      "1 6 5 log2 entropy False 200 29: Macro 0.673970 (0.113068)\n",
      "Testing 1104/4320\n",
      "1 6 5 log2 entropy False 500 29: Weighted 0.785268 (0.082017)\n",
      "1 6 5 log2 entropy False 500 29: Macro 0.669050 (0.113909)\n",
      "Testing 1105/4320\n",
      "1 6 5 sqrt gini True 50 29: Weighted 0.792948 (0.068991)\n",
      "1 6 5 sqrt gini True 50 29: Macro 0.680982 (0.086991)\n",
      "Testing 1106/4320\n",
      "1 6 5 sqrt gini True 100 29: Weighted 0.803722 (0.061157)\n",
      "1 6 5 sqrt gini True 100 29: Macro 0.695738 (0.076918)\n",
      "Testing 1107/4320\n",
      "1 6 5 sqrt gini True 200 29: Weighted 0.803722 (0.061157)\n",
      "1 6 5 sqrt gini True 200 29: Macro 0.695738 (0.076918)\n",
      "Testing 1108/4320\n",
      "1 6 5 sqrt gini True 500 29: Weighted 0.803722 (0.061157)\n",
      "1 6 5 sqrt gini True 500 29: Macro 0.695738 (0.076918)\n",
      "Testing 1109/4320\n",
      "1 6 5 sqrt gini False 50 29: Weighted 0.803068 (0.062114)\n",
      "1 6 5 sqrt gini False 50 29: Macro 0.697768 (0.089456)\n",
      "Testing 1110/4320\n",
      "1 6 5 sqrt gini False 100 29: Weighted 0.799047 (0.068230)\n",
      "1 6 5 sqrt gini False 100 29: Macro 0.692948 (0.097024)\n",
      "Testing 1111/4320\n",
      "1 6 5 sqrt gini False 200 29: Weighted 0.803576 (0.073375)\n",
      "1 6 5 sqrt gini False 200 29: Macro 0.696618 (0.100788)\n",
      "Testing 1112/4320\n",
      "1 6 5 sqrt gini False 500 29: Weighted 0.808504 (0.076483)\n",
      "1 6 5 sqrt gini False 500 29: Macro 0.704126 (0.106322)\n",
      "Testing 1113/4320\n",
      "1 6 5 sqrt entropy True 50 29: Weighted 0.792549 (0.067462)\n",
      "1 6 5 sqrt entropy True 50 29: Macro 0.683667 (0.087205)\n",
      "Testing 1114/4320\n",
      "1 6 5 sqrt entropy True 100 29: Weighted 0.799516 (0.066652)\n",
      "1 6 5 sqrt entropy True 100 29: Macro 0.690524 (0.083962)\n",
      "Testing 1115/4320\n",
      "1 6 5 sqrt entropy True 200 29: Weighted 0.799516 (0.066652)\n",
      "1 6 5 sqrt entropy True 200 29: Macro 0.690524 (0.083962)\n",
      "Testing 1116/4320\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 6 5 sqrt entropy True 500 29: Weighted 0.802923 (0.065526)\n",
      "1 6 5 sqrt entropy True 500 29: Macro 0.695518 (0.082698)\n",
      "Testing 1117/4320\n",
      "1 6 5 sqrt entropy False 50 29: Weighted 0.790697 (0.066814)\n",
      "1 6 5 sqrt entropy False 50 29: Macro 0.673202 (0.099501)\n",
      "Testing 1118/4320\n",
      "1 6 5 sqrt entropy False 100 29: Weighted 0.784219 (0.075598)\n",
      "1 6 5 sqrt entropy False 100 29: Macro 0.670300 (0.108965)\n",
      "Testing 1119/4320\n",
      "1 6 5 sqrt entropy False 200 29: Weighted 0.788748 (0.081104)\n",
      "1 6 5 sqrt entropy False 200 29: Macro 0.673970 (0.113068)\n",
      "Testing 1120/4320\n",
      "1 6 5 sqrt entropy False 500 29: Weighted 0.785268 (0.082017)\n",
      "1 6 5 sqrt entropy False 500 29: Macro 0.669050 (0.113909)\n",
      "Testing 1121/4320\n",
      "1 6 8 log2 gini True 50 29: Weighted 0.785310 (0.058876)\n",
      "1 6 8 log2 gini True 50 29: Macro 0.666498 (0.074726)\n",
      "Testing 1122/4320\n",
      "1 6 8 log2 gini True 100 29: Weighted 0.790216 (0.061116)\n",
      "1 6 8 log2 gini True 100 29: Macro 0.673549 (0.078271)\n",
      "Testing 1123/4320\n",
      "1 6 8 log2 gini True 200 29: Weighted 0.803016 (0.059732)\n",
      "1 6 8 log2 gini True 200 29: Macro 0.690070 (0.078432)\n",
      "Testing 1124/4320\n",
      "1 6 8 log2 gini True 500 29: Weighted 0.806862 (0.056860)\n",
      "1 6 8 log2 gini True 500 29: Macro 0.701181 (0.070294)\n",
      "Testing 1125/4320\n",
      "1 6 8 log2 gini False 50 29: Weighted 0.797082 (0.065998)\n",
      "1 6 8 log2 gini False 50 29: Macro 0.692829 (0.084452)\n",
      "Testing 1126/4320\n",
      "1 6 8 log2 gini False 100 29: Weighted 0.798018 (0.071576)\n",
      "1 6 8 log2 gini False 100 29: Macro 0.690992 (0.094273)\n",
      "Testing 1127/4320\n",
      "1 6 8 log2 gini False 200 29: Weighted 0.798303 (0.073475)\n",
      "1 6 8 log2 gini False 200 29: Macro 0.695466 (0.095583)\n",
      "Testing 1128/4320\n",
      "1 6 8 log2 gini False 500 29: Weighted 0.794155 (0.076103)\n",
      "1 6 8 log2 gini False 500 29: Macro 0.686207 (0.100280)\n",
      "Testing 1129/4320\n",
      "1 6 8 log2 entropy True 50 29: Weighted 0.799423 (0.060407)\n",
      "1 6 8 log2 entropy True 50 29: Macro 0.693940 (0.077133)\n",
      "Testing 1130/4320\n",
      "1 6 8 log2 entropy True 100 29: Weighted 0.802953 (0.058074)\n",
      "1 6 8 log2 entropy True 100 29: Macro 0.699066 (0.074195)\n",
      "Testing 1131/4320\n",
      "1 6 8 log2 entropy True 200 29: Weighted 0.802953 (0.058074)\n",
      "1 6 8 log2 entropy True 200 29: Macro 0.699066 (0.074195)\n",
      "Testing 1132/4320\n",
      "1 6 8 log2 entropy True 500 29: Weighted 0.802342 (0.050355)\n",
      "1 6 8 log2 entropy True 500 29: Macro 0.694369 (0.060709)\n",
      "Testing 1133/4320\n",
      "1 6 8 log2 entropy False 50 29: Weighted 0.793414 (0.059022)\n",
      "1 6 8 log2 entropy False 50 29: Macro 0.683439 (0.081575)\n",
      "Testing 1134/4320\n",
      "1 6 8 log2 entropy False 100 29: Weighted 0.790875 (0.063591)\n",
      "1 6 8 log2 entropy False 100 29: Macro 0.689362 (0.090275)\n",
      "Testing 1135/4320\n",
      "1 6 8 log2 entropy False 200 29: Weighted 0.796544 (0.066329)\n",
      "1 6 8 log2 entropy False 200 29: Macro 0.688629 (0.086392)\n",
      "Testing 1136/4320\n",
      "1 6 8 log2 entropy False 500 29: Weighted 0.795800 (0.066806)\n",
      "1 6 8 log2 entropy False 500 29: Macro 0.689125 (0.086133)\n",
      "Testing 1137/4320\n",
      "1 6 8 sqrt gini True 50 29: Weighted 0.785310 (0.058876)\n",
      "1 6 8 sqrt gini True 50 29: Macro 0.666498 (0.074726)\n",
      "Testing 1138/4320\n",
      "1 6 8 sqrt gini True 100 29: Weighted 0.790216 (0.061116)\n",
      "1 6 8 sqrt gini True 100 29: Macro 0.673549 (0.078271)\n",
      "Testing 1139/4320\n",
      "1 6 8 sqrt gini True 200 29: Weighted 0.803016 (0.059732)\n",
      "1 6 8 sqrt gini True 200 29: Macro 0.690070 (0.078432)\n",
      "Testing 1140/4320\n",
      "1 6 8 sqrt gini True 500 29: Weighted 0.806862 (0.056860)\n",
      "1 6 8 sqrt gini True 500 29: Macro 0.701181 (0.070294)\n",
      "Testing 1141/4320\n",
      "1 6 8 sqrt gini False 50 29: Weighted 0.797082 (0.065998)\n",
      "1 6 8 sqrt gini False 50 29: Macro 0.692829 (0.084452)\n",
      "Testing 1142/4320\n",
      "1 6 8 sqrt gini False 100 29: Weighted 0.798018 (0.071576)\n",
      "1 6 8 sqrt gini False 100 29: Macro 0.690992 (0.094273)\n",
      "Testing 1143/4320\n",
      "1 6 8 sqrt gini False 200 29: Weighted 0.798303 (0.073475)\n",
      "1 6 8 sqrt gini False 200 29: Macro 0.695466 (0.095583)\n",
      "Testing 1144/4320\n",
      "1 6 8 sqrt gini False 500 29: Weighted 0.794155 (0.076103)\n",
      "1 6 8 sqrt gini False 500 29: Macro 0.686207 (0.100280)\n",
      "Testing 1145/4320\n",
      "1 6 8 sqrt entropy True 50 29: Weighted 0.799423 (0.060407)\n",
      "1 6 8 sqrt entropy True 50 29: Macro 0.693940 (0.077133)\n",
      "Testing 1146/4320\n",
      "1 6 8 sqrt entropy True 100 29: Weighted 0.802953 (0.058074)\n",
      "1 6 8 sqrt entropy True 100 29: Macro 0.699066 (0.074195)\n",
      "Testing 1147/4320\n",
      "1 6 8 sqrt entropy True 200 29: Weighted 0.802953 (0.058074)\n",
      "1 6 8 sqrt entropy True 200 29: Macro 0.699066 (0.074195)\n",
      "Testing 1148/4320\n",
      "1 6 8 sqrt entropy True 500 29: Weighted 0.802342 (0.050355)\n",
      "1 6 8 sqrt entropy True 500 29: Macro 0.694369 (0.060709)\n",
      "Testing 1149/4320\n",
      "1 6 8 sqrt entropy False 50 29: Weighted 0.793414 (0.059022)\n",
      "1 6 8 sqrt entropy False 50 29: Macro 0.683439 (0.081575)\n",
      "Testing 1150/4320\n",
      "1 6 8 sqrt entropy False 100 29: Weighted 0.790875 (0.063591)\n",
      "1 6 8 sqrt entropy False 100 29: Macro 0.689362 (0.090275)\n",
      "Testing 1151/4320\n",
      "1 6 8 sqrt entropy False 200 29: Weighted 0.796544 (0.066329)\n",
      "1 6 8 sqrt entropy False 200 29: Macro 0.688629 (0.086392)\n",
      "Testing 1152/4320\n",
      "1 6 8 sqrt entropy False 500 29: Weighted 0.795800 (0.066806)\n",
      "1 6 8 sqrt entropy False 500 29: Macro 0.689125 (0.086133)\n",
      "Testing 1153/4320\n",
      "3 2 3 log2 gini True 50 29: Weighted 0.799924 (0.064510)\n",
      "3 2 3 log2 gini True 50 29: Macro 0.689124 (0.080763)\n",
      "Testing 1154/4320\n",
      "3 2 3 log2 gini True 100 29: Weighted 0.805153 (0.057074)\n",
      "3 2 3 log2 gini True 100 29: Macro 0.694679 (0.072946)\n",
      "Testing 1155/4320\n",
      "3 2 3 log2 gini True 200 29: Weighted 0.809935 (0.060810)\n",
      "3 2 3 log2 gini True 200 29: Macro 0.704820 (0.082311)\n",
      "Testing 1156/4320\n",
      "3 2 3 log2 gini True 500 29: Weighted 0.813941 (0.055478)\n",
      "3 2 3 log2 gini True 500 29: Macro 0.709900 (0.075733)\n",
      "Testing 1157/4320\n",
      "3 2 3 log2 gini False 50 29: Weighted 0.800801 (0.062924)\n",
      "3 2 3 log2 gini False 50 29: Macro 0.692099 (0.082395)\n",
      "Testing 1158/4320\n",
      "3 2 3 log2 gini False 100 29: Weighted 0.804317 (0.061898)\n",
      "3 2 3 log2 gini False 100 29: Macro 0.697056 (0.080675)\n",
      "Testing 1159/4320\n",
      "3 2 3 log2 gini False 200 29: Weighted 0.809244 (0.065497)\n",
      "3 2 3 log2 gini False 200 29: Macro 0.704564 (0.087453)\n",
      "Testing 1160/4320\n",
      "3 2 3 log2 gini False 500 29: Weighted 0.803571 (0.074267)\n",
      "3 2 3 log2 gini False 500 29: Macro 0.701017 (0.092801)\n",
      "Testing 1161/4320\n",
      "3 2 3 log2 entropy True 50 29: Weighted 0.805007 (0.056975)\n",
      "3 2 3 log2 entropy True 50 29: Macro 0.697312 (0.075095)\n",
      "Testing 1162/4320\n",
      "3 2 3 log2 entropy True 100 29: Weighted 0.805007 (0.056975)\n",
      "3 2 3 log2 entropy True 100 29: Macro 0.697312 (0.075095)\n",
      "Testing 1163/4320\n",
      "3 2 3 log2 entropy True 200 29: Weighted 0.805007 (0.056975)\n",
      "3 2 3 log2 entropy True 200 29: Macro 0.697312 (0.075095)\n",
      "Testing 1164/4320\n",
      "3 2 3 log2 entropy True 500 29: Weighted 0.808523 (0.055575)\n",
      "3 2 3 log2 entropy True 500 29: Macro 0.702270 (0.072850)\n",
      "Testing 1165/4320\n",
      "3 2 3 log2 entropy False 50 29: Weighted 0.782580 (0.097085)\n",
      "3 2 3 log2 entropy False 50 29: Macro 0.671174 (0.115799)\n",
      "Testing 1166/4320\n",
      "3 2 3 log2 entropy False 100 29: Weighted 0.788781 (0.086901)\n",
      "3 2 3 log2 entropy False 100 29: Macro 0.678314 (0.104148)\n",
      "Testing 1167/4320\n",
      "3 2 3 log2 entropy False 200 29: Weighted 0.787834 (0.088117)\n",
      "3 2 3 log2 entropy False 200 29: Macro 0.680688 (0.106489)\n",
      "Testing 1168/4320\n",
      "3 2 3 log2 entropy False 500 29: Weighted 0.787834 (0.088117)\n",
      "3 2 3 log2 entropy False 500 29: Macro 0.680688 (0.106489)\n",
      "Testing 1169/4320\n",
      "3 2 3 sqrt gini True 50 29: Weighted 0.799924 (0.064510)\n",
      "3 2 3 sqrt gini True 50 29: Macro 0.689124 (0.080763)\n",
      "Testing 1170/4320\n",
      "3 2 3 sqrt gini True 100 29: Weighted 0.805153 (0.057074)\n",
      "3 2 3 sqrt gini True 100 29: Macro 0.694679 (0.072946)\n",
      "Testing 1171/4320\n",
      "3 2 3 sqrt gini True 200 29: Weighted 0.809935 (0.060810)\n",
      "3 2 3 sqrt gini True 200 29: Macro 0.704820 (0.082311)\n",
      "Testing 1172/4320\n",
      "3 2 3 sqrt gini True 500 29: Weighted 0.813941 (0.055478)\n",
      "3 2 3 sqrt gini True 500 29: Macro 0.709900 (0.075733)\n",
      "Testing 1173/4320\n",
      "3 2 3 sqrt gini False 50 29: Weighted 0.800801 (0.062924)\n",
      "3 2 3 sqrt gini False 50 29: Macro 0.692099 (0.082395)\n",
      "Testing 1174/4320\n",
      "3 2 3 sqrt gini False 100 29: Weighted 0.804317 (0.061898)\n",
      "3 2 3 sqrt gini False 100 29: Macro 0.697056 (0.080675)\n",
      "Testing 1175/4320\n",
      "3 2 3 sqrt gini False 200 29: Weighted 0.809244 (0.065497)\n",
      "3 2 3 sqrt gini False 200 29: Macro 0.704564 (0.087453)\n",
      "Testing 1176/4320\n",
      "3 2 3 sqrt gini False 500 29: Weighted 0.803571 (0.074267)\n",
      "3 2 3 sqrt gini False 500 29: Macro 0.701017 (0.092801)\n",
      "Testing 1177/4320\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 2 3 sqrt entropy True 50 29: Weighted 0.805007 (0.056975)\n",
      "3 2 3 sqrt entropy True 50 29: Macro 0.697312 (0.075095)\n",
      "Testing 1178/4320\n",
      "3 2 3 sqrt entropy True 100 29: Weighted 0.805007 (0.056975)\n",
      "3 2 3 sqrt entropy True 100 29: Macro 0.697312 (0.075095)\n",
      "Testing 1179/4320\n",
      "3 2 3 sqrt entropy True 200 29: Weighted 0.805007 (0.056975)\n",
      "3 2 3 sqrt entropy True 200 29: Macro 0.697312 (0.075095)\n",
      "Testing 1180/4320\n",
      "3 2 3 sqrt entropy True 500 29: Weighted 0.808523 (0.055575)\n",
      "3 2 3 sqrt entropy True 500 29: Macro 0.702270 (0.072850)\n",
      "Testing 1181/4320\n",
      "3 2 3 sqrt entropy False 50 29: Weighted 0.782580 (0.097085)\n",
      "3 2 3 sqrt entropy False 50 29: Macro 0.671174 (0.115799)\n",
      "Testing 1182/4320\n",
      "3 2 3 sqrt entropy False 100 29: Weighted 0.788781 (0.086901)\n",
      "3 2 3 sqrt entropy False 100 29: Macro 0.678314 (0.104148)\n",
      "Testing 1183/4320\n",
      "3 2 3 sqrt entropy False 200 29: Weighted 0.787834 (0.088117)\n",
      "3 2 3 sqrt entropy False 200 29: Macro 0.680688 (0.106489)\n",
      "Testing 1184/4320\n",
      "3 2 3 sqrt entropy False 500 29: Weighted 0.787834 (0.088117)\n",
      "3 2 3 sqrt entropy False 500 29: Macro 0.680688 (0.106489)\n",
      "Testing 1185/4320\n",
      "3 2 5 log2 gini True 50 29: Weighted 0.793593 (0.068404)\n",
      "3 2 5 log2 gini True 50 29: Macro 0.679330 (0.088508)\n",
      "Testing 1186/4320\n",
      "3 2 5 log2 gini True 100 29: Weighted 0.808426 (0.059274)\n",
      "3 2 5 log2 gini True 100 29: Macro 0.699306 (0.075587)\n",
      "Testing 1187/4320\n",
      "3 2 5 log2 gini True 200 29: Weighted 0.808426 (0.059274)\n",
      "3 2 5 log2 gini True 200 29: Macro 0.699306 (0.075587)\n",
      "Testing 1188/4320\n",
      "3 2 5 log2 gini True 500 29: Weighted 0.808426 (0.059274)\n",
      "3 2 5 log2 gini True 500 29: Macro 0.699306 (0.075587)\n",
      "Testing 1189/4320\n",
      "3 2 5 log2 gini False 50 29: Weighted 0.802783 (0.073575)\n",
      "3 2 5 log2 gini False 50 29: Macro 0.697247 (0.100702)\n",
      "Testing 1190/4320\n",
      "3 2 5 log2 gini False 100 29: Weighted 0.807424 (0.072763)\n",
      "3 2 5 log2 gini False 100 29: Macro 0.700746 (0.100438)\n",
      "Testing 1191/4320\n",
      "3 2 5 log2 gini False 200 29: Weighted 0.808309 (0.072708)\n",
      "3 2 5 log2 gini False 200 29: Macro 0.700217 (0.100455)\n",
      "Testing 1192/4320\n",
      "3 2 5 log2 gini False 500 29: Weighted 0.808504 (0.076483)\n",
      "3 2 5 log2 gini False 500 29: Macro 0.704126 (0.106322)\n",
      "Testing 1193/4320\n",
      "3 2 5 log2 entropy True 50 29: Weighted 0.804317 (0.061898)\n",
      "3 2 5 log2 entropy True 50 29: Macro 0.697056 (0.080675)\n",
      "Testing 1194/4320\n",
      "3 2 5 log2 entropy True 100 29: Weighted 0.804220 (0.065233)\n",
      "3 2 5 log2 entropy True 100 29: Macro 0.694092 (0.082969)\n",
      "Testing 1195/4320\n",
      "3 2 5 log2 entropy True 200 29: Weighted 0.808837 (0.067164)\n",
      "3 2 5 log2 entropy True 200 29: Macro 0.703868 (0.087906)\n",
      "Testing 1196/4320\n",
      "3 2 5 log2 entropy True 500 29: Weighted 0.811863 (0.058581)\n",
      "3 2 5 log2 entropy True 500 29: Macro 0.704330 (0.074545)\n",
      "Testing 1197/4320\n",
      "3 2 5 log2 entropy False 50 29: Weighted 0.799557 (0.077368)\n",
      "3 2 5 log2 entropy False 50 29: Macro 0.681113 (0.110710)\n",
      "Testing 1198/4320\n",
      "3 2 5 log2 entropy False 100 29: Weighted 0.795653 (0.077179)\n",
      "3 2 5 log2 entropy False 100 29: Macro 0.678441 (0.111424)\n",
      "Testing 1199/4320\n",
      "3 2 5 log2 entropy False 200 29: Weighted 0.795653 (0.077179)\n",
      "3 2 5 log2 entropy False 200 29: Macro 0.678441 (0.111424)\n",
      "Testing 1200/4320\n",
      "3 2 5 log2 entropy False 500 29: Weighted 0.792137 (0.077612)\n",
      "3 2 5 log2 entropy False 500 29: Macro 0.673483 (0.111854)\n",
      "Testing 1201/4320\n",
      "3 2 5 sqrt gini True 50 29: Weighted 0.793593 (0.068404)\n",
      "3 2 5 sqrt gini True 50 29: Macro 0.679330 (0.088508)\n",
      "Testing 1202/4320\n",
      "3 2 5 sqrt gini True 100 29: Weighted 0.808426 (0.059274)\n",
      "3 2 5 sqrt gini True 100 29: Macro 0.699306 (0.075587)\n",
      "Testing 1203/4320\n",
      "3 2 5 sqrt gini True 200 29: Weighted 0.808426 (0.059274)\n",
      "3 2 5 sqrt gini True 200 29: Macro 0.699306 (0.075587)\n",
      "Testing 1204/4320\n",
      "3 2 5 sqrt gini True 500 29: Weighted 0.808426 (0.059274)\n",
      "3 2 5 sqrt gini True 500 29: Macro 0.699306 (0.075587)\n",
      "Testing 1205/4320\n",
      "3 2 5 sqrt gini False 50 29: Weighted 0.802783 (0.073575)\n",
      "3 2 5 sqrt gini False 50 29: Macro 0.697247 (0.100702)\n",
      "Testing 1206/4320\n",
      "3 2 5 sqrt gini False 100 29: Weighted 0.807424 (0.072763)\n",
      "3 2 5 sqrt gini False 100 29: Macro 0.700746 (0.100438)\n",
      "Testing 1207/4320\n",
      "3 2 5 sqrt gini False 200 29: Weighted 0.808309 (0.072708)\n",
      "3 2 5 sqrt gini False 200 29: Macro 0.700217 (0.100455)\n",
      "Testing 1208/4320\n",
      "3 2 5 sqrt gini False 500 29: Weighted 0.808504 (0.076483)\n",
      "3 2 5 sqrt gini False 500 29: Macro 0.704126 (0.106322)\n",
      "Testing 1209/4320\n",
      "3 2 5 sqrt entropy True 50 29: Weighted 0.804317 (0.061898)\n",
      "3 2 5 sqrt entropy True 50 29: Macro 0.697056 (0.080675)\n",
      "Testing 1210/4320\n",
      "3 2 5 sqrt entropy True 100 29: Weighted 0.804220 (0.065233)\n",
      "3 2 5 sqrt entropy True 100 29: Macro 0.694092 (0.082969)\n",
      "Testing 1211/4320\n",
      "3 2 5 sqrt entropy True 200 29: Weighted 0.808837 (0.067164)\n",
      "3 2 5 sqrt entropy True 200 29: Macro 0.703868 (0.087906)\n",
      "Testing 1212/4320\n",
      "3 2 5 sqrt entropy True 500 29: Weighted 0.811863 (0.058581)\n",
      "3 2 5 sqrt entropy True 500 29: Macro 0.704330 (0.074545)\n",
      "Testing 1213/4320\n",
      "3 2 5 sqrt entropy False 50 29: Weighted 0.799557 (0.077368)\n",
      "3 2 5 sqrt entropy False 50 29: Macro 0.681113 (0.110710)\n",
      "Testing 1214/4320\n",
      "3 2 5 sqrt entropy False 100 29: Weighted 0.795653 (0.077179)\n",
      "3 2 5 sqrt entropy False 100 29: Macro 0.678441 (0.111424)\n",
      "Testing 1215/4320\n",
      "3 2 5 sqrt entropy False 200 29: Weighted 0.795653 (0.077179)\n",
      "3 2 5 sqrt entropy False 200 29: Macro 0.678441 (0.111424)\n",
      "Testing 1216/4320\n",
      "3 2 5 sqrt entropy False 500 29: Weighted 0.792137 (0.077612)\n",
      "3 2 5 sqrt entropy False 500 29: Macro 0.673483 (0.111854)\n",
      "Testing 1217/4320\n",
      "3 2 8 log2 gini True 50 29: Weighted 0.791958 (0.059646)\n",
      "3 2 8 log2 gini True 50 29: Macro 0.677380 (0.074900)\n",
      "Testing 1218/4320\n",
      "3 2 8 log2 gini True 100 29: Weighted 0.807908 (0.056191)\n",
      "3 2 8 log2 gini True 100 29: Macro 0.699483 (0.071262)\n",
      "Testing 1219/4320\n",
      "3 2 8 log2 gini True 200 29: Weighted 0.807908 (0.056191)\n",
      "3 2 8 log2 gini True 200 29: Macro 0.699483 (0.071262)\n",
      "Testing 1220/4320\n",
      "3 2 8 log2 gini True 500 29: Weighted 0.811473 (0.054301)\n",
      "3 2 8 log2 gini True 500 29: Macro 0.704647 (0.068668)\n",
      "Testing 1221/4320\n",
      "3 2 8 log2 gini False 50 29: Weighted 0.796349 (0.062774)\n",
      "3 2 8 log2 gini False 50 29: Macro 0.679694 (0.081586)\n",
      "Testing 1222/4320\n",
      "3 2 8 log2 gini False 100 29: Weighted 0.806203 (0.066206)\n",
      "3 2 8 log2 gini False 100 29: Macro 0.699479 (0.089125)\n",
      "Testing 1223/4320\n",
      "3 2 8 log2 gini False 200 29: Weighted 0.802550 (0.068292)\n",
      "3 2 8 log2 gini False 200 29: Macro 0.694373 (0.091976)\n",
      "Testing 1224/4320\n",
      "3 2 8 log2 gini False 500 29: Weighted 0.806203 (0.066206)\n",
      "3 2 8 log2 gini False 500 29: Macro 0.699479 (0.089125)\n",
      "Testing 1225/4320\n",
      "3 2 8 log2 entropy True 50 29: Weighted 0.803998 (0.057490)\n",
      "3 2 8 log2 entropy True 50 29: Macro 0.697368 (0.075065)\n",
      "Testing 1226/4320\n",
      "3 2 8 log2 entropy True 100 29: Weighted 0.807467 (0.059573)\n",
      "3 2 8 log2 entropy True 100 29: Macro 0.699568 (0.075508)\n",
      "Testing 1227/4320\n",
      "3 2 8 log2 entropy True 200 29: Weighted 0.807467 (0.059573)\n",
      "3 2 8 log2 entropy True 200 29: Macro 0.699568 (0.075508)\n",
      "Testing 1228/4320\n",
      "3 2 8 log2 entropy True 500 29: Weighted 0.802947 (0.053450)\n",
      "3 2 8 log2 entropy True 500 29: Macro 0.692757 (0.066512)\n",
      "Testing 1229/4320\n",
      "3 2 8 log2 entropy False 50 29: Weighted 0.803425 (0.061355)\n",
      "3 2 8 log2 entropy False 50 29: Macro 0.690149 (0.080629)\n",
      "Testing 1230/4320\n",
      "3 2 8 log2 entropy False 100 29: Weighted 0.800821 (0.068131)\n",
      "3 2 8 log2 entropy False 100 29: Macro 0.692436 (0.090150)\n",
      "Testing 1231/4320\n",
      "3 2 8 log2 entropy False 200 29: Weighted 0.804684 (0.062624)\n",
      "3 2 8 log2 entropy False 200 29: Macro 0.697221 (0.083059)\n",
      "Testing 1232/4320\n",
      "3 2 8 log2 entropy False 500 29: Weighted 0.804684 (0.062624)\n",
      "3 2 8 log2 entropy False 500 29: Macro 0.697221 (0.083059)\n",
      "Testing 1233/4320\n",
      "3 2 8 sqrt gini True 50 29: Weighted 0.791958 (0.059646)\n",
      "3 2 8 sqrt gini True 50 29: Macro 0.677380 (0.074900)\n",
      "Testing 1234/4320\n",
      "3 2 8 sqrt gini True 100 29: Weighted 0.807908 (0.056191)\n",
      "3 2 8 sqrt gini True 100 29: Macro 0.699483 (0.071262)\n",
      "Testing 1235/4320\n",
      "3 2 8 sqrt gini True 200 29: Weighted 0.807908 (0.056191)\n",
      "3 2 8 sqrt gini True 200 29: Macro 0.699483 (0.071262)\n",
      "Testing 1236/4320\n",
      "3 2 8 sqrt gini True 500 29: Weighted 0.811473 (0.054301)\n",
      "3 2 8 sqrt gini True 500 29: Macro 0.704647 (0.068668)\n",
      "Testing 1237/4320\n",
      "3 2 8 sqrt gini False 50 29: Weighted 0.796349 (0.062774)\n",
      "3 2 8 sqrt gini False 50 29: Macro 0.679694 (0.081586)\n",
      "Testing 1238/4320\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 2 8 sqrt gini False 100 29: Weighted 0.806203 (0.066206)\n",
      "3 2 8 sqrt gini False 100 29: Macro 0.699479 (0.089125)\n",
      "Testing 1239/4320\n",
      "3 2 8 sqrt gini False 200 29: Weighted 0.802550 (0.068292)\n",
      "3 2 8 sqrt gini False 200 29: Macro 0.694373 (0.091976)\n",
      "Testing 1240/4320\n",
      "3 2 8 sqrt gini False 500 29: Weighted 0.806203 (0.066206)\n",
      "3 2 8 sqrt gini False 500 29: Macro 0.699479 (0.089125)\n",
      "Testing 1241/4320\n",
      "3 2 8 sqrt entropy True 50 29: Weighted 0.803998 (0.057490)\n",
      "3 2 8 sqrt entropy True 50 29: Macro 0.697368 (0.075065)\n",
      "Testing 1242/4320\n",
      "3 2 8 sqrt entropy True 100 29: Weighted 0.807467 (0.059573)\n",
      "3 2 8 sqrt entropy True 100 29: Macro 0.699568 (0.075508)\n",
      "Testing 1243/4320\n",
      "3 2 8 sqrt entropy True 200 29: Weighted 0.807467 (0.059573)\n",
      "3 2 8 sqrt entropy True 200 29: Macro 0.699568 (0.075508)\n",
      "Testing 1244/4320\n",
      "3 2 8 sqrt entropy True 500 29: Weighted 0.802947 (0.053450)\n",
      "3 2 8 sqrt entropy True 500 29: Macro 0.692757 (0.066512)\n",
      "Testing 1245/4320\n",
      "3 2 8 sqrt entropy False 50 29: Weighted 0.803425 (0.061355)\n",
      "3 2 8 sqrt entropy False 50 29: Macro 0.690149 (0.080629)\n",
      "Testing 1246/4320\n",
      "3 2 8 sqrt entropy False 100 29: Weighted 0.800821 (0.068131)\n",
      "3 2 8 sqrt entropy False 100 29: Macro 0.692436 (0.090150)\n",
      "Testing 1247/4320\n",
      "3 2 8 sqrt entropy False 200 29: Weighted 0.804684 (0.062624)\n",
      "3 2 8 sqrt entropy False 200 29: Macro 0.697221 (0.083059)\n",
      "Testing 1248/4320\n",
      "3 2 8 sqrt entropy False 500 29: Weighted 0.804684 (0.062624)\n",
      "3 2 8 sqrt entropy False 500 29: Macro 0.697221 (0.083059)\n",
      "Testing 1249/4320\n",
      "3 4 3 log2 gini True 50 29: Weighted 0.799924 (0.064510)\n",
      "3 4 3 log2 gini True 50 29: Macro 0.689124 (0.080763)\n",
      "Testing 1250/4320\n",
      "3 4 3 log2 gini True 100 29: Weighted 0.805153 (0.057074)\n",
      "3 4 3 log2 gini True 100 29: Macro 0.694679 (0.072946)\n",
      "Testing 1251/4320\n",
      "3 4 3 log2 gini True 200 29: Weighted 0.809935 (0.060810)\n",
      "3 4 3 log2 gini True 200 29: Macro 0.704820 (0.082311)\n",
      "Testing 1252/4320\n",
      "3 4 3 log2 gini True 500 29: Weighted 0.813941 (0.055478)\n",
      "3 4 3 log2 gini True 500 29: Macro 0.709900 (0.075733)\n",
      "Testing 1253/4320\n",
      "3 4 3 log2 gini False 50 29: Weighted 0.800801 (0.062924)\n",
      "3 4 3 log2 gini False 50 29: Macro 0.692099 (0.082395)\n",
      "Testing 1254/4320\n",
      "3 4 3 log2 gini False 100 29: Weighted 0.804317 (0.061898)\n",
      "3 4 3 log2 gini False 100 29: Macro 0.697056 (0.080675)\n",
      "Testing 1255/4320\n",
      "3 4 3 log2 gini False 200 29: Weighted 0.809244 (0.065497)\n",
      "3 4 3 log2 gini False 200 29: Macro 0.704564 (0.087453)\n",
      "Testing 1256/4320\n",
      "3 4 3 log2 gini False 500 29: Weighted 0.803571 (0.074267)\n",
      "3 4 3 log2 gini False 500 29: Macro 0.701017 (0.092801)\n",
      "Testing 1257/4320\n",
      "3 4 3 log2 entropy True 50 29: Weighted 0.805007 (0.056975)\n",
      "3 4 3 log2 entropy True 50 29: Macro 0.697312 (0.075095)\n",
      "Testing 1258/4320\n",
      "3 4 3 log2 entropy True 100 29: Weighted 0.805007 (0.056975)\n",
      "3 4 3 log2 entropy True 100 29: Macro 0.697312 (0.075095)\n",
      "Testing 1259/4320\n",
      "3 4 3 log2 entropy True 200 29: Weighted 0.805007 (0.056975)\n",
      "3 4 3 log2 entropy True 200 29: Macro 0.697312 (0.075095)\n",
      "Testing 1260/4320\n",
      "3 4 3 log2 entropy True 500 29: Weighted 0.808523 (0.055575)\n",
      "3 4 3 log2 entropy True 500 29: Macro 0.702270 (0.072850)\n",
      "Testing 1261/4320\n",
      "3 4 3 log2 entropy False 50 29: Weighted 0.782580 (0.097085)\n",
      "3 4 3 log2 entropy False 50 29: Macro 0.671174 (0.115799)\n",
      "Testing 1262/4320\n",
      "3 4 3 log2 entropy False 100 29: Weighted 0.788781 (0.086901)\n",
      "3 4 3 log2 entropy False 100 29: Macro 0.678314 (0.104148)\n",
      "Testing 1263/4320\n",
      "3 4 3 log2 entropy False 200 29: Weighted 0.787834 (0.088117)\n",
      "3 4 3 log2 entropy False 200 29: Macro 0.680688 (0.106489)\n",
      "Testing 1264/4320\n",
      "3 4 3 log2 entropy False 500 29: Weighted 0.787834 (0.088117)\n",
      "3 4 3 log2 entropy False 500 29: Macro 0.680688 (0.106489)\n",
      "Testing 1265/4320\n",
      "3 4 3 sqrt gini True 50 29: Weighted 0.799924 (0.064510)\n",
      "3 4 3 sqrt gini True 50 29: Macro 0.689124 (0.080763)\n",
      "Testing 1266/4320\n",
      "3 4 3 sqrt gini True 100 29: Weighted 0.805153 (0.057074)\n",
      "3 4 3 sqrt gini True 100 29: Macro 0.694679 (0.072946)\n",
      "Testing 1267/4320\n",
      "3 4 3 sqrt gini True 200 29: Weighted 0.809935 (0.060810)\n",
      "3 4 3 sqrt gini True 200 29: Macro 0.704820 (0.082311)\n",
      "Testing 1268/4320\n",
      "3 4 3 sqrt gini True 500 29: Weighted 0.813941 (0.055478)\n",
      "3 4 3 sqrt gini True 500 29: Macro 0.709900 (0.075733)\n",
      "Testing 1269/4320\n",
      "3 4 3 sqrt gini False 50 29: Weighted 0.800801 (0.062924)\n",
      "3 4 3 sqrt gini False 50 29: Macro 0.692099 (0.082395)\n",
      "Testing 1270/4320\n",
      "3 4 3 sqrt gini False 100 29: Weighted 0.804317 (0.061898)\n",
      "3 4 3 sqrt gini False 100 29: Macro 0.697056 (0.080675)\n",
      "Testing 1271/4320\n",
      "3 4 3 sqrt gini False 200 29: Weighted 0.809244 (0.065497)\n",
      "3 4 3 sqrt gini False 200 29: Macro 0.704564 (0.087453)\n",
      "Testing 1272/4320\n",
      "3 4 3 sqrt gini False 500 29: Weighted 0.803571 (0.074267)\n",
      "3 4 3 sqrt gini False 500 29: Macro 0.701017 (0.092801)\n",
      "Testing 1273/4320\n",
      "3 4 3 sqrt entropy True 50 29: Weighted 0.805007 (0.056975)\n",
      "3 4 3 sqrt entropy True 50 29: Macro 0.697312 (0.075095)\n",
      "Testing 1274/4320\n",
      "3 4 3 sqrt entropy True 100 29: Weighted 0.805007 (0.056975)\n",
      "3 4 3 sqrt entropy True 100 29: Macro 0.697312 (0.075095)\n",
      "Testing 1275/4320\n",
      "3 4 3 sqrt entropy True 200 29: Weighted 0.805007 (0.056975)\n",
      "3 4 3 sqrt entropy True 200 29: Macro 0.697312 (0.075095)\n",
      "Testing 1276/4320\n",
      "3 4 3 sqrt entropy True 500 29: Weighted 0.808523 (0.055575)\n",
      "3 4 3 sqrt entropy True 500 29: Macro 0.702270 (0.072850)\n",
      "Testing 1277/4320\n",
      "3 4 3 sqrt entropy False 50 29: Weighted 0.782580 (0.097085)\n",
      "3 4 3 sqrt entropy False 50 29: Macro 0.671174 (0.115799)\n",
      "Testing 1278/4320\n",
      "3 4 3 sqrt entropy False 100 29: Weighted 0.788781 (0.086901)\n",
      "3 4 3 sqrt entropy False 100 29: Macro 0.678314 (0.104148)\n",
      "Testing 1279/4320\n",
      "3 4 3 sqrt entropy False 200 29: Weighted 0.787834 (0.088117)\n",
      "3 4 3 sqrt entropy False 200 29: Macro 0.680688 (0.106489)\n",
      "Testing 1280/4320\n",
      "3 4 3 sqrt entropy False 500 29: Weighted 0.787834 (0.088117)\n",
      "3 4 3 sqrt entropy False 500 29: Macro 0.680688 (0.106489)\n",
      "Testing 1281/4320\n",
      "3 4 5 log2 gini True 50 29: Weighted 0.793593 (0.068404)\n",
      "3 4 5 log2 gini True 50 29: Macro 0.679330 (0.088508)\n",
      "Testing 1282/4320\n",
      "3 4 5 log2 gini True 100 29: Weighted 0.808426 (0.059274)\n",
      "3 4 5 log2 gini True 100 29: Macro 0.699306 (0.075587)\n",
      "Testing 1283/4320\n",
      "3 4 5 log2 gini True 200 29: Weighted 0.808426 (0.059274)\n",
      "3 4 5 log2 gini True 200 29: Macro 0.699306 (0.075587)\n",
      "Testing 1284/4320\n",
      "3 4 5 log2 gini True 500 29: Weighted 0.808426 (0.059274)\n",
      "3 4 5 log2 gini True 500 29: Macro 0.699306 (0.075587)\n",
      "Testing 1285/4320\n",
      "3 4 5 log2 gini False 50 29: Weighted 0.802783 (0.073575)\n",
      "3 4 5 log2 gini False 50 29: Macro 0.697247 (0.100702)\n",
      "Testing 1286/4320\n",
      "3 4 5 log2 gini False 100 29: Weighted 0.807424 (0.072763)\n",
      "3 4 5 log2 gini False 100 29: Macro 0.700746 (0.100438)\n",
      "Testing 1287/4320\n",
      "3 4 5 log2 gini False 200 29: Weighted 0.808309 (0.072708)\n",
      "3 4 5 log2 gini False 200 29: Macro 0.700217 (0.100455)\n",
      "Testing 1288/4320\n",
      "3 4 5 log2 gini False 500 29: Weighted 0.808504 (0.076483)\n",
      "3 4 5 log2 gini False 500 29: Macro 0.704126 (0.106322)\n",
      "Testing 1289/4320\n",
      "3 4 5 log2 entropy True 50 29: Weighted 0.804317 (0.061898)\n",
      "3 4 5 log2 entropy True 50 29: Macro 0.697056 (0.080675)\n",
      "Testing 1290/4320\n",
      "3 4 5 log2 entropy True 100 29: Weighted 0.804220 (0.065233)\n",
      "3 4 5 log2 entropy True 100 29: Macro 0.694092 (0.082969)\n",
      "Testing 1291/4320\n",
      "3 4 5 log2 entropy True 200 29: Weighted 0.808837 (0.067164)\n",
      "3 4 5 log2 entropy True 200 29: Macro 0.703868 (0.087906)\n",
      "Testing 1292/4320\n",
      "3 4 5 log2 entropy True 500 29: Weighted 0.811863 (0.058581)\n",
      "3 4 5 log2 entropy True 500 29: Macro 0.704330 (0.074545)\n",
      "Testing 1293/4320\n",
      "3 4 5 log2 entropy False 50 29: Weighted 0.799557 (0.077368)\n",
      "3 4 5 log2 entropy False 50 29: Macro 0.681113 (0.110710)\n",
      "Testing 1294/4320\n",
      "3 4 5 log2 entropy False 100 29: Weighted 0.795653 (0.077179)\n",
      "3 4 5 log2 entropy False 100 29: Macro 0.678441 (0.111424)\n",
      "Testing 1295/4320\n",
      "3 4 5 log2 entropy False 200 29: Weighted 0.795653 (0.077179)\n",
      "3 4 5 log2 entropy False 200 29: Macro 0.678441 (0.111424)\n",
      "Testing 1296/4320\n",
      "3 4 5 log2 entropy False 500 29: Weighted 0.792137 (0.077612)\n",
      "3 4 5 log2 entropy False 500 29: Macro 0.673483 (0.111854)\n",
      "Testing 1297/4320\n",
      "3 4 5 sqrt gini True 50 29: Weighted 0.793593 (0.068404)\n",
      "3 4 5 sqrt gini True 50 29: Macro 0.679330 (0.088508)\n",
      "Testing 1298/4320\n",
      "3 4 5 sqrt gini True 100 29: Weighted 0.808426 (0.059274)\n",
      "3 4 5 sqrt gini True 100 29: Macro 0.699306 (0.075587)\n",
      "Testing 1299/4320\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 4 5 sqrt gini True 200 29: Weighted 0.808426 (0.059274)\n",
      "3 4 5 sqrt gini True 200 29: Macro 0.699306 (0.075587)\n",
      "Testing 1300/4320\n",
      "3 4 5 sqrt gini True 500 29: Weighted 0.808426 (0.059274)\n",
      "3 4 5 sqrt gini True 500 29: Macro 0.699306 (0.075587)\n",
      "Testing 1301/4320\n",
      "3 4 5 sqrt gini False 50 29: Weighted 0.802783 (0.073575)\n",
      "3 4 5 sqrt gini False 50 29: Macro 0.697247 (0.100702)\n",
      "Testing 1302/4320\n",
      "3 4 5 sqrt gini False 100 29: Weighted 0.807424 (0.072763)\n",
      "3 4 5 sqrt gini False 100 29: Macro 0.700746 (0.100438)\n",
      "Testing 1303/4320\n",
      "3 4 5 sqrt gini False 200 29: Weighted 0.808309 (0.072708)\n",
      "3 4 5 sqrt gini False 200 29: Macro 0.700217 (0.100455)\n",
      "Testing 1304/4320\n",
      "3 4 5 sqrt gini False 500 29: Weighted 0.808504 (0.076483)\n",
      "3 4 5 sqrt gini False 500 29: Macro 0.704126 (0.106322)\n",
      "Testing 1305/4320\n",
      "3 4 5 sqrt entropy True 50 29: Weighted 0.804317 (0.061898)\n",
      "3 4 5 sqrt entropy True 50 29: Macro 0.697056 (0.080675)\n",
      "Testing 1306/4320\n",
      "3 4 5 sqrt entropy True 100 29: Weighted 0.804220 (0.065233)\n",
      "3 4 5 sqrt entropy True 100 29: Macro 0.694092 (0.082969)\n",
      "Testing 1307/4320\n",
      "3 4 5 sqrt entropy True 200 29: Weighted 0.808837 (0.067164)\n",
      "3 4 5 sqrt entropy True 200 29: Macro 0.703868 (0.087906)\n",
      "Testing 1308/4320\n",
      "3 4 5 sqrt entropy True 500 29: Weighted 0.811863 (0.058581)\n",
      "3 4 5 sqrt entropy True 500 29: Macro 0.704330 (0.074545)\n",
      "Testing 1309/4320\n",
      "3 4 5 sqrt entropy False 50 29: Weighted 0.799557 (0.077368)\n",
      "3 4 5 sqrt entropy False 50 29: Macro 0.681113 (0.110710)\n",
      "Testing 1310/4320\n",
      "3 4 5 sqrt entropy False 100 29: Weighted 0.795653 (0.077179)\n",
      "3 4 5 sqrt entropy False 100 29: Macro 0.678441 (0.111424)\n",
      "Testing 1311/4320\n",
      "3 4 5 sqrt entropy False 200 29: Weighted 0.795653 (0.077179)\n",
      "3 4 5 sqrt entropy False 200 29: Macro 0.678441 (0.111424)\n",
      "Testing 1312/4320\n",
      "3 4 5 sqrt entropy False 500 29: Weighted 0.792137 (0.077612)\n",
      "3 4 5 sqrt entropy False 500 29: Macro 0.673483 (0.111854)\n",
      "Testing 1313/4320\n",
      "3 4 8 log2 gini True 50 29: Weighted 0.791958 (0.059646)\n",
      "3 4 8 log2 gini True 50 29: Macro 0.677380 (0.074900)\n",
      "Testing 1314/4320\n",
      "3 4 8 log2 gini True 100 29: Weighted 0.807908 (0.056191)\n",
      "3 4 8 log2 gini True 100 29: Macro 0.699483 (0.071262)\n",
      "Testing 1315/4320\n",
      "3 4 8 log2 gini True 200 29: Weighted 0.807908 (0.056191)\n",
      "3 4 8 log2 gini True 200 29: Macro 0.699483 (0.071262)\n",
      "Testing 1316/4320\n",
      "3 4 8 log2 gini True 500 29: Weighted 0.811473 (0.054301)\n",
      "3 4 8 log2 gini True 500 29: Macro 0.704647 (0.068668)\n",
      "Testing 1317/4320\n",
      "3 4 8 log2 gini False 50 29: Weighted 0.796349 (0.062774)\n",
      "3 4 8 log2 gini False 50 29: Macro 0.679694 (0.081586)\n",
      "Testing 1318/4320\n",
      "3 4 8 log2 gini False 100 29: Weighted 0.806203 (0.066206)\n",
      "3 4 8 log2 gini False 100 29: Macro 0.699479 (0.089125)\n",
      "Testing 1319/4320\n",
      "3 4 8 log2 gini False 200 29: Weighted 0.802550 (0.068292)\n",
      "3 4 8 log2 gini False 200 29: Macro 0.694373 (0.091976)\n",
      "Testing 1320/4320\n",
      "3 4 8 log2 gini False 500 29: Weighted 0.806203 (0.066206)\n",
      "3 4 8 log2 gini False 500 29: Macro 0.699479 (0.089125)\n",
      "Testing 1321/4320\n",
      "3 4 8 log2 entropy True 50 29: Weighted 0.803998 (0.057490)\n",
      "3 4 8 log2 entropy True 50 29: Macro 0.697368 (0.075065)\n",
      "Testing 1322/4320\n",
      "3 4 8 log2 entropy True 100 29: Weighted 0.807467 (0.059573)\n",
      "3 4 8 log2 entropy True 100 29: Macro 0.699568 (0.075508)\n",
      "Testing 1323/4320\n",
      "3 4 8 log2 entropy True 200 29: Weighted 0.807467 (0.059573)\n",
      "3 4 8 log2 entropy True 200 29: Macro 0.699568 (0.075508)\n",
      "Testing 1324/4320\n",
      "3 4 8 log2 entropy True 500 29: Weighted 0.802947 (0.053450)\n",
      "3 4 8 log2 entropy True 500 29: Macro 0.692757 (0.066512)\n",
      "Testing 1325/4320\n",
      "3 4 8 log2 entropy False 50 29: Weighted 0.803425 (0.061355)\n",
      "3 4 8 log2 entropy False 50 29: Macro 0.690149 (0.080629)\n",
      "Testing 1326/4320\n",
      "3 4 8 log2 entropy False 100 29: Weighted 0.800821 (0.068131)\n",
      "3 4 8 log2 entropy False 100 29: Macro 0.692436 (0.090150)\n",
      "Testing 1327/4320\n",
      "3 4 8 log2 entropy False 200 29: Weighted 0.804684 (0.062624)\n",
      "3 4 8 log2 entropy False 200 29: Macro 0.697221 (0.083059)\n",
      "Testing 1328/4320\n",
      "3 4 8 log2 entropy False 500 29: Weighted 0.804684 (0.062624)\n",
      "3 4 8 log2 entropy False 500 29: Macro 0.697221 (0.083059)\n",
      "Testing 1329/4320\n",
      "3 4 8 sqrt gini True 50 29: Weighted 0.791958 (0.059646)\n",
      "3 4 8 sqrt gini True 50 29: Macro 0.677380 (0.074900)\n",
      "Testing 1330/4320\n",
      "3 4 8 sqrt gini True 100 29: Weighted 0.807908 (0.056191)\n",
      "3 4 8 sqrt gini True 100 29: Macro 0.699483 (0.071262)\n",
      "Testing 1331/4320\n",
      "3 4 8 sqrt gini True 200 29: Weighted 0.807908 (0.056191)\n",
      "3 4 8 sqrt gini True 200 29: Macro 0.699483 (0.071262)\n",
      "Testing 1332/4320\n",
      "3 4 8 sqrt gini True 500 29: Weighted 0.811473 (0.054301)\n",
      "3 4 8 sqrt gini True 500 29: Macro 0.704647 (0.068668)\n",
      "Testing 1333/4320\n",
      "3 4 8 sqrt gini False 50 29: Weighted 0.796349 (0.062774)\n",
      "3 4 8 sqrt gini False 50 29: Macro 0.679694 (0.081586)\n",
      "Testing 1334/4320\n",
      "3 4 8 sqrt gini False 100 29: Weighted 0.806203 (0.066206)\n",
      "3 4 8 sqrt gini False 100 29: Macro 0.699479 (0.089125)\n",
      "Testing 1335/4320\n",
      "3 4 8 sqrt gini False 200 29: Weighted 0.802550 (0.068292)\n",
      "3 4 8 sqrt gini False 200 29: Macro 0.694373 (0.091976)\n",
      "Testing 1336/4320\n",
      "3 4 8 sqrt gini False 500 29: Weighted 0.806203 (0.066206)\n",
      "3 4 8 sqrt gini False 500 29: Macro 0.699479 (0.089125)\n",
      "Testing 1337/4320\n",
      "3 4 8 sqrt entropy True 50 29: Weighted 0.803998 (0.057490)\n",
      "3 4 8 sqrt entropy True 50 29: Macro 0.697368 (0.075065)\n",
      "Testing 1338/4320\n",
      "3 4 8 sqrt entropy True 100 29: Weighted 0.807467 (0.059573)\n",
      "3 4 8 sqrt entropy True 100 29: Macro 0.699568 (0.075508)\n",
      "Testing 1339/4320\n",
      "3 4 8 sqrt entropy True 200 29: Weighted 0.807467 (0.059573)\n",
      "3 4 8 sqrt entropy True 200 29: Macro 0.699568 (0.075508)\n",
      "Testing 1340/4320\n",
      "3 4 8 sqrt entropy True 500 29: Weighted 0.802947 (0.053450)\n",
      "3 4 8 sqrt entropy True 500 29: Macro 0.692757 (0.066512)\n",
      "Testing 1341/4320\n",
      "3 4 8 sqrt entropy False 50 29: Weighted 0.803425 (0.061355)\n",
      "3 4 8 sqrt entropy False 50 29: Macro 0.690149 (0.080629)\n",
      "Testing 1342/4320\n",
      "3 4 8 sqrt entropy False 100 29: Weighted 0.800821 (0.068131)\n",
      "3 4 8 sqrt entropy False 100 29: Macro 0.692436 (0.090150)\n",
      "Testing 1343/4320\n",
      "3 4 8 sqrt entropy False 200 29: Weighted 0.804684 (0.062624)\n",
      "3 4 8 sqrt entropy False 200 29: Macro 0.697221 (0.083059)\n",
      "Testing 1344/4320\n",
      "3 4 8 sqrt entropy False 500 29: Weighted 0.804684 (0.062624)\n",
      "3 4 8 sqrt entropy False 500 29: Macro 0.697221 (0.083059)\n",
      "Testing 1345/4320\n",
      "3 6 3 log2 gini True 50 29: Weighted 0.799924 (0.064510)\n",
      "3 6 3 log2 gini True 50 29: Macro 0.689124 (0.080763)\n",
      "Testing 1346/4320\n",
      "3 6 3 log2 gini True 100 29: Weighted 0.805153 (0.057074)\n",
      "3 6 3 log2 gini True 100 29: Macro 0.694679 (0.072946)\n",
      "Testing 1347/4320\n",
      "3 6 3 log2 gini True 200 29: Weighted 0.809935 (0.060810)\n",
      "3 6 3 log2 gini True 200 29: Macro 0.704820 (0.082311)\n",
      "Testing 1348/4320\n",
      "3 6 3 log2 gini True 500 29: Weighted 0.813941 (0.055478)\n",
      "3 6 3 log2 gini True 500 29: Macro 0.709900 (0.075733)\n",
      "Testing 1349/4320\n",
      "3 6 3 log2 gini False 50 29: Weighted 0.800801 (0.062924)\n",
      "3 6 3 log2 gini False 50 29: Macro 0.692099 (0.082395)\n",
      "Testing 1350/4320\n",
      "3 6 3 log2 gini False 100 29: Weighted 0.804317 (0.061898)\n",
      "3 6 3 log2 gini False 100 29: Macro 0.697056 (0.080675)\n",
      "Testing 1351/4320\n",
      "3 6 3 log2 gini False 200 29: Weighted 0.809244 (0.065497)\n",
      "3 6 3 log2 gini False 200 29: Macro 0.704564 (0.087453)\n",
      "Testing 1352/4320\n",
      "3 6 3 log2 gini False 500 29: Weighted 0.803571 (0.074267)\n",
      "3 6 3 log2 gini False 500 29: Macro 0.701017 (0.092801)\n",
      "Testing 1353/4320\n",
      "3 6 3 log2 entropy True 50 29: Weighted 0.805007 (0.056975)\n",
      "3 6 3 log2 entropy True 50 29: Macro 0.697312 (0.075095)\n",
      "Testing 1354/4320\n",
      "3 6 3 log2 entropy True 100 29: Weighted 0.805007 (0.056975)\n",
      "3 6 3 log2 entropy True 100 29: Macro 0.697312 (0.075095)\n",
      "Testing 1355/4320\n",
      "3 6 3 log2 entropy True 200 29: Weighted 0.805007 (0.056975)\n",
      "3 6 3 log2 entropy True 200 29: Macro 0.697312 (0.075095)\n",
      "Testing 1356/4320\n",
      "3 6 3 log2 entropy True 500 29: Weighted 0.808523 (0.055575)\n",
      "3 6 3 log2 entropy True 500 29: Macro 0.702270 (0.072850)\n",
      "Testing 1357/4320\n",
      "3 6 3 log2 entropy False 50 29: Weighted 0.782580 (0.097085)\n",
      "3 6 3 log2 entropy False 50 29: Macro 0.671174 (0.115799)\n",
      "Testing 1358/4320\n",
      "3 6 3 log2 entropy False 100 29: Weighted 0.788781 (0.086901)\n",
      "3 6 3 log2 entropy False 100 29: Macro 0.678314 (0.104148)\n",
      "Testing 1359/4320\n",
      "3 6 3 log2 entropy False 200 29: Weighted 0.787834 (0.088117)\n",
      "3 6 3 log2 entropy False 200 29: Macro 0.680688 (0.106489)\n",
      "Testing 1360/4320\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 6 3 log2 entropy False 500 29: Weighted 0.787834 (0.088117)\n",
      "3 6 3 log2 entropy False 500 29: Macro 0.680688 (0.106489)\n",
      "Testing 1361/4320\n",
      "3 6 3 sqrt gini True 50 29: Weighted 0.799924 (0.064510)\n",
      "3 6 3 sqrt gini True 50 29: Macro 0.689124 (0.080763)\n",
      "Testing 1362/4320\n",
      "3 6 3 sqrt gini True 100 29: Weighted 0.805153 (0.057074)\n",
      "3 6 3 sqrt gini True 100 29: Macro 0.694679 (0.072946)\n",
      "Testing 1363/4320\n",
      "3 6 3 sqrt gini True 200 29: Weighted 0.809935 (0.060810)\n",
      "3 6 3 sqrt gini True 200 29: Macro 0.704820 (0.082311)\n",
      "Testing 1364/4320\n",
      "3 6 3 sqrt gini True 500 29: Weighted 0.813941 (0.055478)\n",
      "3 6 3 sqrt gini True 500 29: Macro 0.709900 (0.075733)\n",
      "Testing 1365/4320\n",
      "3 6 3 sqrt gini False 50 29: Weighted 0.800801 (0.062924)\n",
      "3 6 3 sqrt gini False 50 29: Macro 0.692099 (0.082395)\n",
      "Testing 1366/4320\n",
      "3 6 3 sqrt gini False 100 29: Weighted 0.804317 (0.061898)\n",
      "3 6 3 sqrt gini False 100 29: Macro 0.697056 (0.080675)\n",
      "Testing 1367/4320\n",
      "3 6 3 sqrt gini False 200 29: Weighted 0.809244 (0.065497)\n",
      "3 6 3 sqrt gini False 200 29: Macro 0.704564 (0.087453)\n",
      "Testing 1368/4320\n",
      "3 6 3 sqrt gini False 500 29: Weighted 0.803571 (0.074267)\n",
      "3 6 3 sqrt gini False 500 29: Macro 0.701017 (0.092801)\n",
      "Testing 1369/4320\n",
      "3 6 3 sqrt entropy True 50 29: Weighted 0.805007 (0.056975)\n",
      "3 6 3 sqrt entropy True 50 29: Macro 0.697312 (0.075095)\n",
      "Testing 1370/4320\n",
      "3 6 3 sqrt entropy True 100 29: Weighted 0.805007 (0.056975)\n",
      "3 6 3 sqrt entropy True 100 29: Macro 0.697312 (0.075095)\n",
      "Testing 1371/4320\n",
      "3 6 3 sqrt entropy True 200 29: Weighted 0.805007 (0.056975)\n",
      "3 6 3 sqrt entropy True 200 29: Macro 0.697312 (0.075095)\n",
      "Testing 1372/4320\n",
      "3 6 3 sqrt entropy True 500 29: Weighted 0.808523 (0.055575)\n",
      "3 6 3 sqrt entropy True 500 29: Macro 0.702270 (0.072850)\n",
      "Testing 1373/4320\n",
      "3 6 3 sqrt entropy False 50 29: Weighted 0.782580 (0.097085)\n",
      "3 6 3 sqrt entropy False 50 29: Macro 0.671174 (0.115799)\n",
      "Testing 1374/4320\n",
      "3 6 3 sqrt entropy False 100 29: Weighted 0.788781 (0.086901)\n",
      "3 6 3 sqrt entropy False 100 29: Macro 0.678314 (0.104148)\n",
      "Testing 1375/4320\n",
      "3 6 3 sqrt entropy False 200 29: Weighted 0.787834 (0.088117)\n",
      "3 6 3 sqrt entropy False 200 29: Macro 0.680688 (0.106489)\n",
      "Testing 1376/4320\n",
      "3 6 3 sqrt entropy False 500 29: Weighted 0.787834 (0.088117)\n",
      "3 6 3 sqrt entropy False 500 29: Macro 0.680688 (0.106489)\n",
      "Testing 1377/4320\n",
      "3 6 5 log2 gini True 50 29: Weighted 0.793593 (0.068404)\n",
      "3 6 5 log2 gini True 50 29: Macro 0.679330 (0.088508)\n",
      "Testing 1378/4320\n",
      "3 6 5 log2 gini True 100 29: Weighted 0.808426 (0.059274)\n",
      "3 6 5 log2 gini True 100 29: Macro 0.699306 (0.075587)\n",
      "Testing 1379/4320\n",
      "3 6 5 log2 gini True 200 29: Weighted 0.808426 (0.059274)\n",
      "3 6 5 log2 gini True 200 29: Macro 0.699306 (0.075587)\n",
      "Testing 1380/4320\n",
      "3 6 5 log2 gini True 500 29: Weighted 0.808426 (0.059274)\n",
      "3 6 5 log2 gini True 500 29: Macro 0.699306 (0.075587)\n",
      "Testing 1381/4320\n",
      "3 6 5 log2 gini False 50 29: Weighted 0.802783 (0.073575)\n",
      "3 6 5 log2 gini False 50 29: Macro 0.697247 (0.100702)\n",
      "Testing 1382/4320\n",
      "3 6 5 log2 gini False 100 29: Weighted 0.807424 (0.072763)\n",
      "3 6 5 log2 gini False 100 29: Macro 0.700746 (0.100438)\n",
      "Testing 1383/4320\n",
      "3 6 5 log2 gini False 200 29: Weighted 0.808309 (0.072708)\n",
      "3 6 5 log2 gini False 200 29: Macro 0.700217 (0.100455)\n",
      "Testing 1384/4320\n",
      "3 6 5 log2 gini False 500 29: Weighted 0.808504 (0.076483)\n",
      "3 6 5 log2 gini False 500 29: Macro 0.704126 (0.106322)\n",
      "Testing 1385/4320\n",
      "3 6 5 log2 entropy True 50 29: Weighted 0.804317 (0.061898)\n",
      "3 6 5 log2 entropy True 50 29: Macro 0.697056 (0.080675)\n",
      "Testing 1386/4320\n",
      "3 6 5 log2 entropy True 100 29: Weighted 0.804220 (0.065233)\n",
      "3 6 5 log2 entropy True 100 29: Macro 0.694092 (0.082969)\n",
      "Testing 1387/4320\n",
      "3 6 5 log2 entropy True 200 29: Weighted 0.808837 (0.067164)\n",
      "3 6 5 log2 entropy True 200 29: Macro 0.703868 (0.087906)\n",
      "Testing 1388/4320\n",
      "3 6 5 log2 entropy True 500 29: Weighted 0.811863 (0.058581)\n",
      "3 6 5 log2 entropy True 500 29: Macro 0.704330 (0.074545)\n",
      "Testing 1389/4320\n",
      "3 6 5 log2 entropy False 50 29: Weighted 0.799557 (0.077368)\n",
      "3 6 5 log2 entropy False 50 29: Macro 0.681113 (0.110710)\n",
      "Testing 1390/4320\n",
      "3 6 5 log2 entropy False 100 29: Weighted 0.795653 (0.077179)\n",
      "3 6 5 log2 entropy False 100 29: Macro 0.678441 (0.111424)\n",
      "Testing 1391/4320\n",
      "3 6 5 log2 entropy False 200 29: Weighted 0.795653 (0.077179)\n",
      "3 6 5 log2 entropy False 200 29: Macro 0.678441 (0.111424)\n",
      "Testing 1392/4320\n",
      "3 6 5 log2 entropy False 500 29: Weighted 0.792137 (0.077612)\n",
      "3 6 5 log2 entropy False 500 29: Macro 0.673483 (0.111854)\n",
      "Testing 1393/4320\n",
      "3 6 5 sqrt gini True 50 29: Weighted 0.793593 (0.068404)\n",
      "3 6 5 sqrt gini True 50 29: Macro 0.679330 (0.088508)\n",
      "Testing 1394/4320\n",
      "3 6 5 sqrt gini True 100 29: Weighted 0.808426 (0.059274)\n",
      "3 6 5 sqrt gini True 100 29: Macro 0.699306 (0.075587)\n",
      "Testing 1395/4320\n",
      "3 6 5 sqrt gini True 200 29: Weighted 0.808426 (0.059274)\n",
      "3 6 5 sqrt gini True 200 29: Macro 0.699306 (0.075587)\n",
      "Testing 1396/4320\n",
      "3 6 5 sqrt gini True 500 29: Weighted 0.808426 (0.059274)\n",
      "3 6 5 sqrt gini True 500 29: Macro 0.699306 (0.075587)\n",
      "Testing 1397/4320\n",
      "3 6 5 sqrt gini False 50 29: Weighted 0.802783 (0.073575)\n",
      "3 6 5 sqrt gini False 50 29: Macro 0.697247 (0.100702)\n",
      "Testing 1398/4320\n",
      "3 6 5 sqrt gini False 100 29: Weighted 0.807424 (0.072763)\n",
      "3 6 5 sqrt gini False 100 29: Macro 0.700746 (0.100438)\n",
      "Testing 1399/4320\n",
      "3 6 5 sqrt gini False 200 29: Weighted 0.808309 (0.072708)\n",
      "3 6 5 sqrt gini False 200 29: Macro 0.700217 (0.100455)\n",
      "Testing 1400/4320\n",
      "3 6 5 sqrt gini False 500 29: Weighted 0.808504 (0.076483)\n",
      "3 6 5 sqrt gini False 500 29: Macro 0.704126 (0.106322)\n",
      "Testing 1401/4320\n",
      "3 6 5 sqrt entropy True 50 29: Weighted 0.804317 (0.061898)\n",
      "3 6 5 sqrt entropy True 50 29: Macro 0.697056 (0.080675)\n",
      "Testing 1402/4320\n",
      "3 6 5 sqrt entropy True 100 29: Weighted 0.804220 (0.065233)\n",
      "3 6 5 sqrt entropy True 100 29: Macro 0.694092 (0.082969)\n",
      "Testing 1403/4320\n",
      "3 6 5 sqrt entropy True 200 29: Weighted 0.808837 (0.067164)\n",
      "3 6 5 sqrt entropy True 200 29: Macro 0.703868 (0.087906)\n",
      "Testing 1404/4320\n",
      "3 6 5 sqrt entropy True 500 29: Weighted 0.811863 (0.058581)\n",
      "3 6 5 sqrt entropy True 500 29: Macro 0.704330 (0.074545)\n",
      "Testing 1405/4320\n",
      "3 6 5 sqrt entropy False 50 29: Weighted 0.799557 (0.077368)\n",
      "3 6 5 sqrt entropy False 50 29: Macro 0.681113 (0.110710)\n",
      "Testing 1406/4320\n",
      "3 6 5 sqrt entropy False 100 29: Weighted 0.795653 (0.077179)\n",
      "3 6 5 sqrt entropy False 100 29: Macro 0.678441 (0.111424)\n",
      "Testing 1407/4320\n",
      "3 6 5 sqrt entropy False 200 29: Weighted 0.795653 (0.077179)\n",
      "3 6 5 sqrt entropy False 200 29: Macro 0.678441 (0.111424)\n",
      "Testing 1408/4320\n",
      "3 6 5 sqrt entropy False 500 29: Weighted 0.792137 (0.077612)\n",
      "3 6 5 sqrt entropy False 500 29: Macro 0.673483 (0.111854)\n",
      "Testing 1409/4320\n",
      "3 6 8 log2 gini True 50 29: Weighted 0.791958 (0.059646)\n",
      "3 6 8 log2 gini True 50 29: Macro 0.677380 (0.074900)\n",
      "Testing 1410/4320\n",
      "3 6 8 log2 gini True 100 29: Weighted 0.807908 (0.056191)\n",
      "3 6 8 log2 gini True 100 29: Macro 0.699483 (0.071262)\n",
      "Testing 1411/4320\n",
      "3 6 8 log2 gini True 200 29: Weighted 0.807908 (0.056191)\n",
      "3 6 8 log2 gini True 200 29: Macro 0.699483 (0.071262)\n",
      "Testing 1412/4320\n",
      "3 6 8 log2 gini True 500 29: Weighted 0.811473 (0.054301)\n",
      "3 6 8 log2 gini True 500 29: Macro 0.704647 (0.068668)\n",
      "Testing 1413/4320\n",
      "3 6 8 log2 gini False 50 29: Weighted 0.796349 (0.062774)\n",
      "3 6 8 log2 gini False 50 29: Macro 0.679694 (0.081586)\n",
      "Testing 1414/4320\n",
      "3 6 8 log2 gini False 100 29: Weighted 0.806203 (0.066206)\n",
      "3 6 8 log2 gini False 100 29: Macro 0.699479 (0.089125)\n",
      "Testing 1415/4320\n",
      "3 6 8 log2 gini False 200 29: Weighted 0.802550 (0.068292)\n",
      "3 6 8 log2 gini False 200 29: Macro 0.694373 (0.091976)\n",
      "Testing 1416/4320\n",
      "3 6 8 log2 gini False 500 29: Weighted 0.806203 (0.066206)\n",
      "3 6 8 log2 gini False 500 29: Macro 0.699479 (0.089125)\n",
      "Testing 1417/4320\n",
      "3 6 8 log2 entropy True 50 29: Weighted 0.803998 (0.057490)\n",
      "3 6 8 log2 entropy True 50 29: Macro 0.697368 (0.075065)\n",
      "Testing 1418/4320\n",
      "3 6 8 log2 entropy True 100 29: Weighted 0.807467 (0.059573)\n",
      "3 6 8 log2 entropy True 100 29: Macro 0.699568 (0.075508)\n",
      "Testing 1419/4320\n",
      "3 6 8 log2 entropy True 200 29: Weighted 0.807467 (0.059573)\n",
      "3 6 8 log2 entropy True 200 29: Macro 0.699568 (0.075508)\n",
      "Testing 1420/4320\n",
      "3 6 8 log2 entropy True 500 29: Weighted 0.802947 (0.053450)\n",
      "3 6 8 log2 entropy True 500 29: Macro 0.692757 (0.066512)\n",
      "Testing 1421/4320\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 6 8 log2 entropy False 50 29: Weighted 0.803425 (0.061355)\n",
      "3 6 8 log2 entropy False 50 29: Macro 0.690149 (0.080629)\n",
      "Testing 1422/4320\n",
      "3 6 8 log2 entropy False 100 29: Weighted 0.800821 (0.068131)\n",
      "3 6 8 log2 entropy False 100 29: Macro 0.692436 (0.090150)\n",
      "Testing 1423/4320\n",
      "3 6 8 log2 entropy False 200 29: Weighted 0.804684 (0.062624)\n",
      "3 6 8 log2 entropy False 200 29: Macro 0.697221 (0.083059)\n",
      "Testing 1424/4320\n",
      "3 6 8 log2 entropy False 500 29: Weighted 0.804684 (0.062624)\n",
      "3 6 8 log2 entropy False 500 29: Macro 0.697221 (0.083059)\n",
      "Testing 1425/4320\n",
      "3 6 8 sqrt gini True 50 29: Weighted 0.791958 (0.059646)\n",
      "3 6 8 sqrt gini True 50 29: Macro 0.677380 (0.074900)\n",
      "Testing 1426/4320\n",
      "3 6 8 sqrt gini True 100 29: Weighted 0.807908 (0.056191)\n",
      "3 6 8 sqrt gini True 100 29: Macro 0.699483 (0.071262)\n",
      "Testing 1427/4320\n",
      "3 6 8 sqrt gini True 200 29: Weighted 0.807908 (0.056191)\n",
      "3 6 8 sqrt gini True 200 29: Macro 0.699483 (0.071262)\n",
      "Testing 1428/4320\n",
      "3 6 8 sqrt gini True 500 29: Weighted 0.811473 (0.054301)\n",
      "3 6 8 sqrt gini True 500 29: Macro 0.704647 (0.068668)\n",
      "Testing 1429/4320\n",
      "3 6 8 sqrt gini False 50 29: Weighted 0.796349 (0.062774)\n",
      "3 6 8 sqrt gini False 50 29: Macro 0.679694 (0.081586)\n",
      "Testing 1430/4320\n",
      "3 6 8 sqrt gini False 100 29: Weighted 0.806203 (0.066206)\n",
      "3 6 8 sqrt gini False 100 29: Macro 0.699479 (0.089125)\n",
      "Testing 1431/4320\n",
      "3 6 8 sqrt gini False 200 29: Weighted 0.802550 (0.068292)\n",
      "3 6 8 sqrt gini False 200 29: Macro 0.694373 (0.091976)\n",
      "Testing 1432/4320\n",
      "3 6 8 sqrt gini False 500 29: Weighted 0.806203 (0.066206)\n",
      "3 6 8 sqrt gini False 500 29: Macro 0.699479 (0.089125)\n",
      "Testing 1433/4320\n",
      "3 6 8 sqrt entropy True 50 29: Weighted 0.803998 (0.057490)\n",
      "3 6 8 sqrt entropy True 50 29: Macro 0.697368 (0.075065)\n",
      "Testing 1434/4320\n",
      "3 6 8 sqrt entropy True 100 29: Weighted 0.807467 (0.059573)\n",
      "3 6 8 sqrt entropy True 100 29: Macro 0.699568 (0.075508)\n",
      "Testing 1435/4320\n",
      "3 6 8 sqrt entropy True 200 29: Weighted 0.807467 (0.059573)\n",
      "3 6 8 sqrt entropy True 200 29: Macro 0.699568 (0.075508)\n",
      "Testing 1436/4320\n",
      "3 6 8 sqrt entropy True 500 29: Weighted 0.802947 (0.053450)\n",
      "3 6 8 sqrt entropy True 500 29: Macro 0.692757 (0.066512)\n",
      "Testing 1437/4320\n",
      "3 6 8 sqrt entropy False 50 29: Weighted 0.803425 (0.061355)\n",
      "3 6 8 sqrt entropy False 50 29: Macro 0.690149 (0.080629)\n",
      "Testing 1438/4320\n",
      "3 6 8 sqrt entropy False 100 29: Weighted 0.800821 (0.068131)\n",
      "3 6 8 sqrt entropy False 100 29: Macro 0.692436 (0.090150)\n",
      "Testing 1439/4320\n",
      "3 6 8 sqrt entropy False 200 29: Weighted 0.804684 (0.062624)\n",
      "3 6 8 sqrt entropy False 200 29: Macro 0.697221 (0.083059)\n",
      "Testing 1440/4320\n",
      "3 6 8 sqrt entropy False 500 29: Weighted 0.804684 (0.062624)\n",
      "3 6 8 sqrt entropy False 500 29: Macro 0.697221 (0.083059)\n",
      "Testing 1441/4320\n",
      "5 2 3 log2 gini True 50 29: Weighted 0.804099 (0.058536)\n",
      "5 2 3 log2 gini True 50 29: Macro 0.694382 (0.073353)\n",
      "Testing 1442/4320\n",
      "5 2 3 log2 gini True 100 29: Weighted 0.809673 (0.062686)\n",
      "5 2 3 log2 gini True 100 29: Macro 0.701491 (0.081072)\n",
      "Testing 1443/4320\n",
      "5 2 3 log2 gini True 200 29: Weighted 0.809935 (0.060810)\n",
      "5 2 3 log2 gini True 200 29: Macro 0.704820 (0.082311)\n",
      "Testing 1444/4320\n",
      "5 2 3 log2 gini True 500 29: Weighted 0.813941 (0.055478)\n",
      "5 2 3 log2 gini True 500 29: Macro 0.709900 (0.075733)\n",
      "Testing 1445/4320\n",
      "5 2 3 log2 gini False 50 29: Weighted 0.800801 (0.062924)\n",
      "5 2 3 log2 gini False 50 29: Macro 0.692099 (0.082395)\n",
      "Testing 1446/4320\n",
      "5 2 3 log2 gini False 100 29: Weighted 0.804317 (0.061898)\n",
      "5 2 3 log2 gini False 100 29: Macro 0.697056 (0.080675)\n",
      "Testing 1447/4320\n",
      "5 2 3 log2 gini False 200 29: Weighted 0.809244 (0.065497)\n",
      "5 2 3 log2 gini False 200 29: Macro 0.704564 (0.087453)\n",
      "Testing 1448/4320\n",
      "5 2 3 log2 gini False 500 29: Weighted 0.804627 (0.072614)\n",
      "5 2 3 log2 gini False 500 29: Macro 0.701445 (0.092151)\n",
      "Testing 1449/4320\n",
      "5 2 3 log2 entropy True 50 29: Weighted 0.800801 (0.062924)\n",
      "5 2 3 log2 entropy True 50 29: Macro 0.692099 (0.082395)\n",
      "Testing 1450/4320\n",
      "5 2 3 log2 entropy True 100 29: Weighted 0.796362 (0.069477)\n",
      "5 2 3 log2 entropy True 100 29: Macro 0.686706 (0.090276)\n",
      "Testing 1451/4320\n",
      "5 2 3 log2 entropy True 200 29: Weighted 0.800801 (0.062924)\n",
      "5 2 3 log2 entropy True 200 29: Macro 0.692099 (0.082395)\n",
      "Testing 1452/4320\n",
      "5 2 3 log2 entropy True 500 29: Weighted 0.808523 (0.055575)\n",
      "5 2 3 log2 entropy True 500 29: Macro 0.702270 (0.072850)\n",
      "Testing 1453/4320\n",
      "5 2 3 log2 entropy False 50 29: Weighted 0.794516 (0.077616)\n",
      "5 2 3 log2 entropy False 50 29: Macro 0.685000 (0.093405)\n",
      "Testing 1454/4320\n",
      "5 2 3 log2 entropy False 100 29: Weighted 0.799845 (0.069149)\n",
      "5 2 3 log2 entropy False 100 29: Macro 0.691304 (0.083483)\n",
      "Testing 1455/4320\n",
      "5 2 3 log2 entropy False 200 29: Weighted 0.799700 (0.069057)\n",
      "5 2 3 log2 entropy False 200 29: Macro 0.693936 (0.085471)\n",
      "Testing 1456/4320\n",
      "5 2 3 log2 entropy False 500 29: Weighted 0.787834 (0.088117)\n",
      "5 2 3 log2 entropy False 500 29: Macro 0.680688 (0.106489)\n",
      "Testing 1457/4320\n",
      "5 2 3 sqrt gini True 50 29: Weighted 0.804099 (0.058536)\n",
      "5 2 3 sqrt gini True 50 29: Macro 0.694382 (0.073353)\n",
      "Testing 1458/4320\n",
      "5 2 3 sqrt gini True 100 29: Weighted 0.809673 (0.062686)\n",
      "5 2 3 sqrt gini True 100 29: Macro 0.701491 (0.081072)\n",
      "Testing 1459/4320\n",
      "5 2 3 sqrt gini True 200 29: Weighted 0.809935 (0.060810)\n",
      "5 2 3 sqrt gini True 200 29: Macro 0.704820 (0.082311)\n",
      "Testing 1460/4320\n",
      "5 2 3 sqrt gini True 500 29: Weighted 0.813941 (0.055478)\n",
      "5 2 3 sqrt gini True 500 29: Macro 0.709900 (0.075733)\n",
      "Testing 1461/4320\n",
      "5 2 3 sqrt gini False 50 29: Weighted 0.800801 (0.062924)\n",
      "5 2 3 sqrt gini False 50 29: Macro 0.692099 (0.082395)\n",
      "Testing 1462/4320\n",
      "5 2 3 sqrt gini False 100 29: Weighted 0.804317 (0.061898)\n",
      "5 2 3 sqrt gini False 100 29: Macro 0.697056 (0.080675)\n",
      "Testing 1463/4320\n",
      "5 2 3 sqrt gini False 200 29: Weighted 0.809244 (0.065497)\n",
      "5 2 3 sqrt gini False 200 29: Macro 0.704564 (0.087453)\n",
      "Testing 1464/4320\n",
      "5 2 3 sqrt gini False 500 29: Weighted 0.804627 (0.072614)\n",
      "5 2 3 sqrt gini False 500 29: Macro 0.701445 (0.092151)\n",
      "Testing 1465/4320\n",
      "5 2 3 sqrt entropy True 50 29: Weighted 0.800801 (0.062924)\n",
      "5 2 3 sqrt entropy True 50 29: Macro 0.692099 (0.082395)\n",
      "Testing 1466/4320\n",
      "5 2 3 sqrt entropy True 100 29: Weighted 0.796362 (0.069477)\n",
      "5 2 3 sqrt entropy True 100 29: Macro 0.686706 (0.090276)\n",
      "Testing 1467/4320\n",
      "5 2 3 sqrt entropy True 200 29: Weighted 0.800801 (0.062924)\n",
      "5 2 3 sqrt entropy True 200 29: Macro 0.692099 (0.082395)\n",
      "Testing 1468/4320\n",
      "5 2 3 sqrt entropy True 500 29: Weighted 0.808523 (0.055575)\n",
      "5 2 3 sqrt entropy True 500 29: Macro 0.702270 (0.072850)\n",
      "Testing 1469/4320\n",
      "5 2 3 sqrt entropy False 50 29: Weighted 0.794516 (0.077616)\n",
      "5 2 3 sqrt entropy False 50 29: Macro 0.685000 (0.093405)\n",
      "Testing 1470/4320\n",
      "5 2 3 sqrt entropy False 100 29: Weighted 0.799845 (0.069149)\n",
      "5 2 3 sqrt entropy False 100 29: Macro 0.691304 (0.083483)\n",
      "Testing 1471/4320\n",
      "5 2 3 sqrt entropy False 200 29: Weighted 0.799700 (0.069057)\n",
      "5 2 3 sqrt entropy False 200 29: Macro 0.693936 (0.085471)\n",
      "Testing 1472/4320\n",
      "5 2 3 sqrt entropy False 500 29: Weighted 0.787834 (0.088117)\n",
      "5 2 3 sqrt entropy False 500 29: Macro 0.680688 (0.106489)\n",
      "Testing 1473/4320\n",
      "5 2 5 log2 gini True 50 29: Weighted 0.810054 (0.060122)\n",
      "5 2 5 log2 gini True 50 29: Macro 0.701622 (0.078340)\n",
      "Testing 1474/4320\n",
      "5 2 5 log2 gini True 100 29: Weighted 0.812433 (0.053903)\n",
      "5 2 5 log2 gini True 100 29: Macro 0.704385 (0.068774)\n",
      "Testing 1475/4320\n",
      "5 2 5 log2 gini True 200 29: Weighted 0.804911 (0.060583)\n",
      "5 2 5 log2 gini True 200 29: Macro 0.694348 (0.077564)\n",
      "Testing 1476/4320\n",
      "5 2 5 log2 gini True 500 29: Weighted 0.804911 (0.060583)\n",
      "5 2 5 log2 gini True 500 29: Macro 0.694348 (0.077564)\n",
      "Testing 1477/4320\n",
      "5 2 5 log2 gini False 50 29: Weighted 0.799297 (0.071214)\n",
      "5 2 5 log2 gini False 50 29: Macro 0.685679 (0.095856)\n",
      "Testing 1478/4320\n",
      "5 2 5 log2 gini False 100 29: Weighted 0.807424 (0.072763)\n",
      "5 2 5 log2 gini False 100 29: Macro 0.700746 (0.100438)\n",
      "Testing 1479/4320\n",
      "5 2 5 log2 gini False 200 29: Weighted 0.807424 (0.072763)\n",
      "5 2 5 log2 gini False 200 29: Macro 0.700746 (0.100438)\n",
      "Testing 1480/4320\n",
      "5 2 5 log2 gini False 500 29: Weighted 0.808841 (0.076386)\n",
      "5 2 5 log2 gini False 500 29: Macro 0.702963 (0.106584)\n",
      "Testing 1481/4320\n",
      "5 2 5 log2 entropy True 50 29: Weighted 0.809889 (0.074131)\n",
      "5 2 5 log2 entropy True 50 29: Macro 0.703239 (0.096980)\n",
      "Testing 1482/4320\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 2 5 log2 entropy True 100 29: Weighted 0.807656 (0.064827)\n",
      "5 2 5 log2 entropy True 100 29: Macro 0.699117 (0.082339)\n",
      "Testing 1483/4320\n",
      "5 2 5 log2 entropy True 200 29: Weighted 0.800704 (0.066202)\n",
      "5 2 5 log2 entropy True 200 29: Macro 0.689134 (0.084469)\n",
      "Testing 1484/4320\n",
      "5 2 5 log2 entropy True 500 29: Weighted 0.808426 (0.059274)\n",
      "5 2 5 log2 entropy True 500 29: Macro 0.699306 (0.075587)\n",
      "Testing 1485/4320\n",
      "5 2 5 log2 entropy False 50 29: Weighted 0.795161 (0.077426)\n",
      "5 2 5 log2 entropy False 50 29: Macro 0.676351 (0.110364)\n",
      "Testing 1486/4320\n",
      "5 2 5 log2 entropy False 100 29: Weighted 0.794391 (0.069940)\n",
      "5 2 5 log2 entropy False 100 29: Macro 0.678628 (0.093900)\n",
      "Testing 1487/4320\n",
      "5 2 5 log2 entropy False 200 29: Weighted 0.794694 (0.077250)\n",
      "5 2 5 log2 entropy False 200 29: Macro 0.678704 (0.111419)\n",
      "Testing 1488/4320\n",
      "5 2 5 log2 entropy False 500 29: Weighted 0.798829 (0.071049)\n",
      "5 2 5 log2 entropy False 500 29: Macro 0.688032 (0.096843)\n",
      "Testing 1489/4320\n",
      "5 2 5 sqrt gini True 50 29: Weighted 0.810054 (0.060122)\n",
      "5 2 5 sqrt gini True 50 29: Macro 0.701622 (0.078340)\n",
      "Testing 1490/4320\n",
      "5 2 5 sqrt gini True 100 29: Weighted 0.812433 (0.053903)\n",
      "5 2 5 sqrt gini True 100 29: Macro 0.704385 (0.068774)\n",
      "Testing 1491/4320\n",
      "5 2 5 sqrt gini True 200 29: Weighted 0.804911 (0.060583)\n",
      "5 2 5 sqrt gini True 200 29: Macro 0.694348 (0.077564)\n",
      "Testing 1492/4320\n",
      "5 2 5 sqrt gini True 500 29: Weighted 0.804911 (0.060583)\n",
      "5 2 5 sqrt gini True 500 29: Macro 0.694348 (0.077564)\n",
      "Testing 1493/4320\n",
      "5 2 5 sqrt gini False 50 29: Weighted 0.799297 (0.071214)\n",
      "5 2 5 sqrt gini False 50 29: Macro 0.685679 (0.095856)\n",
      "Testing 1494/4320\n",
      "5 2 5 sqrt gini False 100 29: Weighted 0.807424 (0.072763)\n",
      "5 2 5 sqrt gini False 100 29: Macro 0.700746 (0.100438)\n",
      "Testing 1495/4320\n",
      "5 2 5 sqrt gini False 200 29: Weighted 0.807424 (0.072763)\n",
      "5 2 5 sqrt gini False 200 29: Macro 0.700746 (0.100438)\n",
      "Testing 1496/4320\n",
      "5 2 5 sqrt gini False 500 29: Weighted 0.808841 (0.076386)\n",
      "5 2 5 sqrt gini False 500 29: Macro 0.702963 (0.106584)\n",
      "Testing 1497/4320\n",
      "5 2 5 sqrt entropy True 50 29: Weighted 0.809889 (0.074131)\n",
      "5 2 5 sqrt entropy True 50 29: Macro 0.703239 (0.096980)\n",
      "Testing 1498/4320\n",
      "5 2 5 sqrt entropy True 100 29: Weighted 0.807656 (0.064827)\n",
      "5 2 5 sqrt entropy True 100 29: Macro 0.699117 (0.082339)\n",
      "Testing 1499/4320\n",
      "5 2 5 sqrt entropy True 200 29: Weighted 0.800704 (0.066202)\n",
      "5 2 5 sqrt entropy True 200 29: Macro 0.689134 (0.084469)\n",
      "Testing 1500/4320\n",
      "5 2 5 sqrt entropy True 500 29: Weighted 0.808426 (0.059274)\n",
      "5 2 5 sqrt entropy True 500 29: Macro 0.699306 (0.075587)\n",
      "Testing 1501/4320\n",
      "5 2 5 sqrt entropy False 50 29: Weighted 0.795161 (0.077426)\n",
      "5 2 5 sqrt entropy False 50 29: Macro 0.676351 (0.110364)\n",
      "Testing 1502/4320\n",
      "5 2 5 sqrt entropy False 100 29: Weighted 0.794391 (0.069940)\n",
      "5 2 5 sqrt entropy False 100 29: Macro 0.678628 (0.093900)\n",
      "Testing 1503/4320\n",
      "5 2 5 sqrt entropy False 200 29: Weighted 0.794694 (0.077250)\n",
      "5 2 5 sqrt entropy False 200 29: Macro 0.678704 (0.111419)\n",
      "Testing 1504/4320\n",
      "5 2 5 sqrt entropy False 500 29: Weighted 0.798829 (0.071049)\n",
      "5 2 5 sqrt entropy False 500 29: Macro 0.688032 (0.096843)\n",
      "Testing 1505/4320\n",
      "5 2 8 log2 gini True 50 29: Weighted 0.806291 (0.063345)\n",
      "5 2 8 log2 gini True 50 29: Macro 0.696631 (0.082832)\n",
      "Testing 1506/4320\n",
      "5 2 8 log2 gini True 100 29: Weighted 0.813679 (0.057546)\n",
      "5 2 8 log2 gini True 100 29: Macro 0.706570 (0.074612)\n",
      "Testing 1507/4320\n",
      "5 2 8 log2 gini True 200 29: Weighted 0.813679 (0.057546)\n",
      "5 2 8 log2 gini True 200 29: Macro 0.706570 (0.074612)\n",
      "Testing 1508/4320\n",
      "5 2 8 log2 gini True 500 29: Weighted 0.804911 (0.060583)\n",
      "5 2 8 log2 gini True 500 29: Macro 0.694348 (0.077564)\n",
      "Testing 1509/4320\n",
      "5 2 8 log2 gini False 50 29: Weighted 0.791353 (0.077918)\n",
      "5 2 8 log2 gini False 50 29: Macro 0.672043 (0.111091)\n",
      "Testing 1510/4320\n",
      "5 2 8 log2 gini False 100 29: Weighted 0.804369 (0.068699)\n",
      "5 2 8 log2 gini False 100 29: Macro 0.695110 (0.095284)\n",
      "Testing 1511/4320\n",
      "5 2 8 log2 gini False 200 29: Weighted 0.804369 (0.068699)\n",
      "5 2 8 log2 gini False 200 29: Macro 0.695110 (0.095284)\n",
      "Testing 1512/4320\n",
      "5 2 8 log2 gini False 500 29: Weighted 0.804369 (0.068699)\n",
      "5 2 8 log2 gini False 500 29: Macro 0.695110 (0.095284)\n",
      "Testing 1513/4320\n",
      "5 2 8 log2 entropy True 50 29: Weighted 0.807467 (0.059573)\n",
      "5 2 8 log2 entropy True 50 29: Macro 0.699568 (0.075508)\n",
      "Testing 1514/4320\n",
      "5 2 8 log2 entropy True 100 29: Weighted 0.807467 (0.059573)\n",
      "5 2 8 log2 entropy True 100 29: Macro 0.699568 (0.075508)\n",
      "Testing 1515/4320\n",
      "5 2 8 log2 entropy True 200 29: Weighted 0.803902 (0.061066)\n",
      "5 2 8 log2 entropy True 200 29: Macro 0.694404 (0.077537)\n",
      "Testing 1516/4320\n",
      "5 2 8 log2 entropy True 500 29: Weighted 0.807467 (0.059573)\n",
      "5 2 8 log2 entropy True 500 29: Macro 0.699568 (0.075508)\n",
      "Testing 1517/4320\n",
      "5 2 8 log2 entropy False 50 29: Weighted 0.798411 (0.064279)\n",
      "5 2 8 log2 entropy False 50 29: Macro 0.683448 (0.086856)\n",
      "Testing 1518/4320\n",
      "5 2 8 log2 entropy False 100 29: Weighted 0.798829 (0.071049)\n",
      "5 2 8 log2 entropy False 100 29: Macro 0.688032 (0.096843)\n",
      "Testing 1519/4320\n",
      "5 2 8 log2 entropy False 200 29: Weighted 0.799284 (0.066331)\n",
      "5 2 8 log2 entropy False 200 29: Macro 0.687687 (0.090862)\n",
      "Testing 1520/4320\n",
      "5 2 8 log2 entropy False 500 29: Weighted 0.799284 (0.066331)\n",
      "5 2 8 log2 entropy False 500 29: Macro 0.687687 (0.090862)\n",
      "Testing 1521/4320\n",
      "5 2 8 sqrt gini True 50 29: Weighted 0.806291 (0.063345)\n",
      "5 2 8 sqrt gini True 50 29: Macro 0.696631 (0.082832)\n",
      "Testing 1522/4320\n",
      "5 2 8 sqrt gini True 100 29: Weighted 0.813679 (0.057546)\n",
      "5 2 8 sqrt gini True 100 29: Macro 0.706570 (0.074612)\n",
      "Testing 1523/4320\n",
      "5 2 8 sqrt gini True 200 29: Weighted 0.813679 (0.057546)\n",
      "5 2 8 sqrt gini True 200 29: Macro 0.706570 (0.074612)\n",
      "Testing 1524/4320\n",
      "5 2 8 sqrt gini True 500 29: Weighted 0.804911 (0.060583)\n",
      "5 2 8 sqrt gini True 500 29: Macro 0.694348 (0.077564)\n",
      "Testing 1525/4320\n",
      "5 2 8 sqrt gini False 50 29: Weighted 0.791353 (0.077918)\n",
      "5 2 8 sqrt gini False 50 29: Macro 0.672043 (0.111091)\n",
      "Testing 1526/4320\n",
      "5 2 8 sqrt gini False 100 29: Weighted 0.804369 (0.068699)\n",
      "5 2 8 sqrt gini False 100 29: Macro 0.695110 (0.095284)\n",
      "Testing 1527/4320\n",
      "5 2 8 sqrt gini False 200 29: Weighted 0.804369 (0.068699)\n",
      "5 2 8 sqrt gini False 200 29: Macro 0.695110 (0.095284)\n",
      "Testing 1528/4320\n",
      "5 2 8 sqrt gini False 500 29: Weighted 0.804369 (0.068699)\n",
      "5 2 8 sqrt gini False 500 29: Macro 0.695110 (0.095284)\n",
      "Testing 1529/4320\n",
      "5 2 8 sqrt entropy True 50 29: Weighted 0.807467 (0.059573)\n",
      "5 2 8 sqrt entropy True 50 29: Macro 0.699568 (0.075508)\n",
      "Testing 1530/4320\n",
      "5 2 8 sqrt entropy True 100 29: Weighted 0.807467 (0.059573)\n",
      "5 2 8 sqrt entropy True 100 29: Macro 0.699568 (0.075508)\n",
      "Testing 1531/4320\n",
      "5 2 8 sqrt entropy True 200 29: Weighted 0.803902 (0.061066)\n",
      "5 2 8 sqrt entropy True 200 29: Macro 0.694404 (0.077537)\n",
      "Testing 1532/4320\n",
      "5 2 8 sqrt entropy True 500 29: Weighted 0.807467 (0.059573)\n",
      "5 2 8 sqrt entropy True 500 29: Macro 0.699568 (0.075508)\n",
      "Testing 1533/4320\n",
      "5 2 8 sqrt entropy False 50 29: Weighted 0.798411 (0.064279)\n",
      "5 2 8 sqrt entropy False 50 29: Macro 0.683448 (0.086856)\n",
      "Testing 1534/4320\n",
      "5 2 8 sqrt entropy False 100 29: Weighted 0.798829 (0.071049)\n",
      "5 2 8 sqrt entropy False 100 29: Macro 0.688032 (0.096843)\n",
      "Testing 1535/4320\n",
      "5 2 8 sqrt entropy False 200 29: Weighted 0.799284 (0.066331)\n",
      "5 2 8 sqrt entropy False 200 29: Macro 0.687687 (0.090862)\n",
      "Testing 1536/4320\n",
      "5 2 8 sqrt entropy False 500 29: Weighted 0.799284 (0.066331)\n",
      "5 2 8 sqrt entropy False 500 29: Macro 0.687687 (0.090862)\n",
      "Testing 1537/4320\n",
      "5 4 3 log2 gini True 50 29: Weighted 0.804099 (0.058536)\n",
      "5 4 3 log2 gini True 50 29: Macro 0.694382 (0.073353)\n",
      "Testing 1538/4320\n",
      "5 4 3 log2 gini True 100 29: Weighted 0.809673 (0.062686)\n",
      "5 4 3 log2 gini True 100 29: Macro 0.701491 (0.081072)\n",
      "Testing 1539/4320\n",
      "5 4 3 log2 gini True 200 29: Weighted 0.809935 (0.060810)\n",
      "5 4 3 log2 gini True 200 29: Macro 0.704820 (0.082311)\n",
      "Testing 1540/4320\n",
      "5 4 3 log2 gini True 500 29: Weighted 0.813941 (0.055478)\n",
      "5 4 3 log2 gini True 500 29: Macro 0.709900 (0.075733)\n",
      "Testing 1541/4320\n",
      "5 4 3 log2 gini False 50 29: Weighted 0.800801 (0.062924)\n",
      "5 4 3 log2 gini False 50 29: Macro 0.692099 (0.082395)\n",
      "Testing 1542/4320\n",
      "5 4 3 log2 gini False 100 29: Weighted 0.804317 (0.061898)\n",
      "5 4 3 log2 gini False 100 29: Macro 0.697056 (0.080675)\n",
      "Testing 1543/4320\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 4 3 log2 gini False 200 29: Weighted 0.809244 (0.065497)\n",
      "5 4 3 log2 gini False 200 29: Macro 0.704564 (0.087453)\n",
      "Testing 1544/4320\n",
      "5 4 3 log2 gini False 500 29: Weighted 0.804627 (0.072614)\n",
      "5 4 3 log2 gini False 500 29: Macro 0.701445 (0.092151)\n",
      "Testing 1545/4320\n",
      "5 4 3 log2 entropy True 50 29: Weighted 0.800801 (0.062924)\n",
      "5 4 3 log2 entropy True 50 29: Macro 0.692099 (0.082395)\n",
      "Testing 1546/4320\n",
      "5 4 3 log2 entropy True 100 29: Weighted 0.796362 (0.069477)\n",
      "5 4 3 log2 entropy True 100 29: Macro 0.686706 (0.090276)\n",
      "Testing 1547/4320\n",
      "5 4 3 log2 entropy True 200 29: Weighted 0.800801 (0.062924)\n",
      "5 4 3 log2 entropy True 200 29: Macro 0.692099 (0.082395)\n",
      "Testing 1548/4320\n",
      "5 4 3 log2 entropy True 500 29: Weighted 0.808523 (0.055575)\n",
      "5 4 3 log2 entropy True 500 29: Macro 0.702270 (0.072850)\n",
      "Testing 1549/4320\n",
      "5 4 3 log2 entropy False 50 29: Weighted 0.794516 (0.077616)\n",
      "5 4 3 log2 entropy False 50 29: Macro 0.685000 (0.093405)\n",
      "Testing 1550/4320\n",
      "5 4 3 log2 entropy False 100 29: Weighted 0.799845 (0.069149)\n",
      "5 4 3 log2 entropy False 100 29: Macro 0.691304 (0.083483)\n",
      "Testing 1551/4320\n",
      "5 4 3 log2 entropy False 200 29: Weighted 0.799700 (0.069057)\n",
      "5 4 3 log2 entropy False 200 29: Macro 0.693936 (0.085471)\n",
      "Testing 1552/4320\n",
      "5 4 3 log2 entropy False 500 29: Weighted 0.787834 (0.088117)\n",
      "5 4 3 log2 entropy False 500 29: Macro 0.680688 (0.106489)\n",
      "Testing 1553/4320\n",
      "5 4 3 sqrt gini True 50 29: Weighted 0.804099 (0.058536)\n",
      "5 4 3 sqrt gini True 50 29: Macro 0.694382 (0.073353)\n",
      "Testing 1554/4320\n",
      "5 4 3 sqrt gini True 100 29: Weighted 0.809673 (0.062686)\n",
      "5 4 3 sqrt gini True 100 29: Macro 0.701491 (0.081072)\n",
      "Testing 1555/4320\n",
      "5 4 3 sqrt gini True 200 29: Weighted 0.809935 (0.060810)\n",
      "5 4 3 sqrt gini True 200 29: Macro 0.704820 (0.082311)\n",
      "Testing 1556/4320\n",
      "5 4 3 sqrt gini True 500 29: Weighted 0.813941 (0.055478)\n",
      "5 4 3 sqrt gini True 500 29: Macro 0.709900 (0.075733)\n",
      "Testing 1557/4320\n",
      "5 4 3 sqrt gini False 50 29: Weighted 0.800801 (0.062924)\n",
      "5 4 3 sqrt gini False 50 29: Macro 0.692099 (0.082395)\n",
      "Testing 1558/4320\n",
      "5 4 3 sqrt gini False 100 29: Weighted 0.804317 (0.061898)\n",
      "5 4 3 sqrt gini False 100 29: Macro 0.697056 (0.080675)\n",
      "Testing 1559/4320\n",
      "5 4 3 sqrt gini False 200 29: Weighted 0.809244 (0.065497)\n",
      "5 4 3 sqrt gini False 200 29: Macro 0.704564 (0.087453)\n",
      "Testing 1560/4320\n",
      "5 4 3 sqrt gini False 500 29: Weighted 0.804627 (0.072614)\n",
      "5 4 3 sqrt gini False 500 29: Macro 0.701445 (0.092151)\n",
      "Testing 1561/4320\n",
      "5 4 3 sqrt entropy True 50 29: Weighted 0.800801 (0.062924)\n",
      "5 4 3 sqrt entropy True 50 29: Macro 0.692099 (0.082395)\n",
      "Testing 1562/4320\n",
      "5 4 3 sqrt entropy True 100 29: Weighted 0.796362 (0.069477)\n",
      "5 4 3 sqrt entropy True 100 29: Macro 0.686706 (0.090276)\n",
      "Testing 1563/4320\n",
      "5 4 3 sqrt entropy True 200 29: Weighted 0.800801 (0.062924)\n",
      "5 4 3 sqrt entropy True 200 29: Macro 0.692099 (0.082395)\n",
      "Testing 1564/4320\n",
      "5 4 3 sqrt entropy True 500 29: Weighted 0.808523 (0.055575)\n",
      "5 4 3 sqrt entropy True 500 29: Macro 0.702270 (0.072850)\n",
      "Testing 1565/4320\n",
      "5 4 3 sqrt entropy False 50 29: Weighted 0.794516 (0.077616)\n",
      "5 4 3 sqrt entropy False 50 29: Macro 0.685000 (0.093405)\n",
      "Testing 1566/4320\n",
      "5 4 3 sqrt entropy False 100 29: Weighted 0.799845 (0.069149)\n",
      "5 4 3 sqrt entropy False 100 29: Macro 0.691304 (0.083483)\n",
      "Testing 1567/4320\n",
      "5 4 3 sqrt entropy False 200 29: Weighted 0.799700 (0.069057)\n",
      "5 4 3 sqrt entropy False 200 29: Macro 0.693936 (0.085471)\n",
      "Testing 1568/4320\n",
      "5 4 3 sqrt entropy False 500 29: Weighted 0.787834 (0.088117)\n",
      "5 4 3 sqrt entropy False 500 29: Macro 0.680688 (0.106489)\n",
      "Testing 1569/4320\n",
      "5 4 5 log2 gini True 50 29: Weighted 0.810054 (0.060122)\n",
      "5 4 5 log2 gini True 50 29: Macro 0.701622 (0.078340)\n",
      "Testing 1570/4320\n",
      "5 4 5 log2 gini True 100 29: Weighted 0.812433 (0.053903)\n",
      "5 4 5 log2 gini True 100 29: Macro 0.704385 (0.068774)\n",
      "Testing 1571/4320\n",
      "5 4 5 log2 gini True 200 29: Weighted 0.804911 (0.060583)\n",
      "5 4 5 log2 gini True 200 29: Macro 0.694348 (0.077564)\n",
      "Testing 1572/4320\n",
      "5 4 5 log2 gini True 500 29: Weighted 0.804911 (0.060583)\n",
      "5 4 5 log2 gini True 500 29: Macro 0.694348 (0.077564)\n",
      "Testing 1573/4320\n",
      "5 4 5 log2 gini False 50 29: Weighted 0.799297 (0.071214)\n",
      "5 4 5 log2 gini False 50 29: Macro 0.685679 (0.095856)\n",
      "Testing 1574/4320\n",
      "5 4 5 log2 gini False 100 29: Weighted 0.807424 (0.072763)\n",
      "5 4 5 log2 gini False 100 29: Macro 0.700746 (0.100438)\n",
      "Testing 1575/4320\n",
      "5 4 5 log2 gini False 200 29: Weighted 0.807424 (0.072763)\n",
      "5 4 5 log2 gini False 200 29: Macro 0.700746 (0.100438)\n",
      "Testing 1576/4320\n",
      "5 4 5 log2 gini False 500 29: Weighted 0.808841 (0.076386)\n",
      "5 4 5 log2 gini False 500 29: Macro 0.702963 (0.106584)\n",
      "Testing 1577/4320\n",
      "5 4 5 log2 entropy True 50 29: Weighted 0.809889 (0.074131)\n",
      "5 4 5 log2 entropy True 50 29: Macro 0.703239 (0.096980)\n",
      "Testing 1578/4320\n",
      "5 4 5 log2 entropy True 100 29: Weighted 0.807656 (0.064827)\n",
      "5 4 5 log2 entropy True 100 29: Macro 0.699117 (0.082339)\n",
      "Testing 1579/4320\n",
      "5 4 5 log2 entropy True 200 29: Weighted 0.800704 (0.066202)\n",
      "5 4 5 log2 entropy True 200 29: Macro 0.689134 (0.084469)\n",
      "Testing 1580/4320\n",
      "5 4 5 log2 entropy True 500 29: Weighted 0.808426 (0.059274)\n",
      "5 4 5 log2 entropy True 500 29: Macro 0.699306 (0.075587)\n",
      "Testing 1581/4320\n",
      "5 4 5 log2 entropy False 50 29: Weighted 0.795161 (0.077426)\n",
      "5 4 5 log2 entropy False 50 29: Macro 0.676351 (0.110364)\n",
      "Testing 1582/4320\n",
      "5 4 5 log2 entropy False 100 29: Weighted 0.794391 (0.069940)\n",
      "5 4 5 log2 entropy False 100 29: Macro 0.678628 (0.093900)\n",
      "Testing 1583/4320\n",
      "5 4 5 log2 entropy False 200 29: Weighted 0.794694 (0.077250)\n",
      "5 4 5 log2 entropy False 200 29: Macro 0.678704 (0.111419)\n",
      "Testing 1584/4320\n",
      "5 4 5 log2 entropy False 500 29: Weighted 0.798829 (0.071049)\n",
      "5 4 5 log2 entropy False 500 29: Macro 0.688032 (0.096843)\n",
      "Testing 1585/4320\n",
      "5 4 5 sqrt gini True 50 29: Weighted 0.810054 (0.060122)\n",
      "5 4 5 sqrt gini True 50 29: Macro 0.701622 (0.078340)\n",
      "Testing 1586/4320\n",
      "5 4 5 sqrt gini True 100 29: Weighted 0.812433 (0.053903)\n",
      "5 4 5 sqrt gini True 100 29: Macro 0.704385 (0.068774)\n",
      "Testing 1587/4320\n",
      "5 4 5 sqrt gini True 200 29: Weighted 0.804911 (0.060583)\n",
      "5 4 5 sqrt gini True 200 29: Macro 0.694348 (0.077564)\n",
      "Testing 1588/4320\n",
      "5 4 5 sqrt gini True 500 29: Weighted 0.804911 (0.060583)\n",
      "5 4 5 sqrt gini True 500 29: Macro 0.694348 (0.077564)\n",
      "Testing 1589/4320\n",
      "5 4 5 sqrt gini False 50 29: Weighted 0.799297 (0.071214)\n",
      "5 4 5 sqrt gini False 50 29: Macro 0.685679 (0.095856)\n",
      "Testing 1590/4320\n",
      "5 4 5 sqrt gini False 100 29: Weighted 0.807424 (0.072763)\n",
      "5 4 5 sqrt gini False 100 29: Macro 0.700746 (0.100438)\n",
      "Testing 1591/4320\n",
      "5 4 5 sqrt gini False 200 29: Weighted 0.807424 (0.072763)\n",
      "5 4 5 sqrt gini False 200 29: Macro 0.700746 (0.100438)\n",
      "Testing 1592/4320\n",
      "5 4 5 sqrt gini False 500 29: Weighted 0.808841 (0.076386)\n",
      "5 4 5 sqrt gini False 500 29: Macro 0.702963 (0.106584)\n",
      "Testing 1593/4320\n",
      "5 4 5 sqrt entropy True 50 29: Weighted 0.809889 (0.074131)\n",
      "5 4 5 sqrt entropy True 50 29: Macro 0.703239 (0.096980)\n",
      "Testing 1594/4320\n",
      "5 4 5 sqrt entropy True 100 29: Weighted 0.807656 (0.064827)\n",
      "5 4 5 sqrt entropy True 100 29: Macro 0.699117 (0.082339)\n",
      "Testing 1595/4320\n",
      "5 4 5 sqrt entropy True 200 29: Weighted 0.800704 (0.066202)\n",
      "5 4 5 sqrt entropy True 200 29: Macro 0.689134 (0.084469)\n",
      "Testing 1596/4320\n",
      "5 4 5 sqrt entropy True 500 29: Weighted 0.808426 (0.059274)\n",
      "5 4 5 sqrt entropy True 500 29: Macro 0.699306 (0.075587)\n",
      "Testing 1597/4320\n",
      "5 4 5 sqrt entropy False 50 29: Weighted 0.795161 (0.077426)\n",
      "5 4 5 sqrt entropy False 50 29: Macro 0.676351 (0.110364)\n",
      "Testing 1598/4320\n",
      "5 4 5 sqrt entropy False 100 29: Weighted 0.794391 (0.069940)\n",
      "5 4 5 sqrt entropy False 100 29: Macro 0.678628 (0.093900)\n",
      "Testing 1599/4320\n",
      "5 4 5 sqrt entropy False 200 29: Weighted 0.794694 (0.077250)\n",
      "5 4 5 sqrt entropy False 200 29: Macro 0.678704 (0.111419)\n",
      "Testing 1600/4320\n",
      "5 4 5 sqrt entropy False 500 29: Weighted 0.798829 (0.071049)\n",
      "5 4 5 sqrt entropy False 500 29: Macro 0.688032 (0.096843)\n",
      "Testing 1601/4320\n",
      "5 4 8 log2 gini True 50 29: Weighted 0.806291 (0.063345)\n",
      "5 4 8 log2 gini True 50 29: Macro 0.696631 (0.082832)\n",
      "Testing 1602/4320\n",
      "5 4 8 log2 gini True 100 29: Weighted 0.813679 (0.057546)\n",
      "5 4 8 log2 gini True 100 29: Macro 0.706570 (0.074612)\n",
      "Testing 1603/4320\n",
      "5 4 8 log2 gini True 200 29: Weighted 0.813679 (0.057546)\n",
      "5 4 8 log2 gini True 200 29: Macro 0.706570 (0.074612)\n",
      "Testing 1604/4320\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 4 8 log2 gini True 500 29: Weighted 0.804911 (0.060583)\n",
      "5 4 8 log2 gini True 500 29: Macro 0.694348 (0.077564)\n",
      "Testing 1605/4320\n",
      "5 4 8 log2 gini False 50 29: Weighted 0.791353 (0.077918)\n",
      "5 4 8 log2 gini False 50 29: Macro 0.672043 (0.111091)\n",
      "Testing 1606/4320\n",
      "5 4 8 log2 gini False 100 29: Weighted 0.804369 (0.068699)\n",
      "5 4 8 log2 gini False 100 29: Macro 0.695110 (0.095284)\n",
      "Testing 1607/4320\n",
      "5 4 8 log2 gini False 200 29: Weighted 0.804369 (0.068699)\n",
      "5 4 8 log2 gini False 200 29: Macro 0.695110 (0.095284)\n",
      "Testing 1608/4320\n",
      "5 4 8 log2 gini False 500 29: Weighted 0.804369 (0.068699)\n",
      "5 4 8 log2 gini False 500 29: Macro 0.695110 (0.095284)\n",
      "Testing 1609/4320\n",
      "5 4 8 log2 entropy True 50 29: Weighted 0.807467 (0.059573)\n",
      "5 4 8 log2 entropy True 50 29: Macro 0.699568 (0.075508)\n",
      "Testing 1610/4320\n",
      "5 4 8 log2 entropy True 100 29: Weighted 0.807467 (0.059573)\n",
      "5 4 8 log2 entropy True 100 29: Macro 0.699568 (0.075508)\n",
      "Testing 1611/4320\n",
      "5 4 8 log2 entropy True 200 29: Weighted 0.803902 (0.061066)\n",
      "5 4 8 log2 entropy True 200 29: Macro 0.694404 (0.077537)\n",
      "Testing 1612/4320\n",
      "5 4 8 log2 entropy True 500 29: Weighted 0.807467 (0.059573)\n",
      "5 4 8 log2 entropy True 500 29: Macro 0.699568 (0.075508)\n",
      "Testing 1613/4320\n",
      "5 4 8 log2 entropy False 50 29: Weighted 0.798411 (0.064279)\n",
      "5 4 8 log2 entropy False 50 29: Macro 0.683448 (0.086856)\n",
      "Testing 1614/4320\n",
      "5 4 8 log2 entropy False 100 29: Weighted 0.798829 (0.071049)\n",
      "5 4 8 log2 entropy False 100 29: Macro 0.688032 (0.096843)\n",
      "Testing 1615/4320\n",
      "5 4 8 log2 entropy False 200 29: Weighted 0.799284 (0.066331)\n",
      "5 4 8 log2 entropy False 200 29: Macro 0.687687 (0.090862)\n",
      "Testing 1616/4320\n",
      "5 4 8 log2 entropy False 500 29: Weighted 0.799284 (0.066331)\n",
      "5 4 8 log2 entropy False 500 29: Macro 0.687687 (0.090862)\n",
      "Testing 1617/4320\n",
      "5 4 8 sqrt gini True 50 29: Weighted 0.806291 (0.063345)\n",
      "5 4 8 sqrt gini True 50 29: Macro 0.696631 (0.082832)\n",
      "Testing 1618/4320\n",
      "5 4 8 sqrt gini True 100 29: Weighted 0.813679 (0.057546)\n",
      "5 4 8 sqrt gini True 100 29: Macro 0.706570 (0.074612)\n",
      "Testing 1619/4320\n",
      "5 4 8 sqrt gini True 200 29: Weighted 0.813679 (0.057546)\n",
      "5 4 8 sqrt gini True 200 29: Macro 0.706570 (0.074612)\n",
      "Testing 1620/4320\n",
      "5 4 8 sqrt gini True 500 29: Weighted 0.804911 (0.060583)\n",
      "5 4 8 sqrt gini True 500 29: Macro 0.694348 (0.077564)\n",
      "Testing 1621/4320\n",
      "5 4 8 sqrt gini False 50 29: Weighted 0.791353 (0.077918)\n",
      "5 4 8 sqrt gini False 50 29: Macro 0.672043 (0.111091)\n",
      "Testing 1622/4320\n",
      "5 4 8 sqrt gini False 100 29: Weighted 0.804369 (0.068699)\n",
      "5 4 8 sqrt gini False 100 29: Macro 0.695110 (0.095284)\n",
      "Testing 1623/4320\n",
      "5 4 8 sqrt gini False 200 29: Weighted 0.804369 (0.068699)\n",
      "5 4 8 sqrt gini False 200 29: Macro 0.695110 (0.095284)\n",
      "Testing 1624/4320\n",
      "5 4 8 sqrt gini False 500 29: Weighted 0.804369 (0.068699)\n",
      "5 4 8 sqrt gini False 500 29: Macro 0.695110 (0.095284)\n",
      "Testing 1625/4320\n",
      "5 4 8 sqrt entropy True 50 29: Weighted 0.807467 (0.059573)\n",
      "5 4 8 sqrt entropy True 50 29: Macro 0.699568 (0.075508)\n",
      "Testing 1626/4320\n",
      "5 4 8 sqrt entropy True 100 29: Weighted 0.807467 (0.059573)\n",
      "5 4 8 sqrt entropy True 100 29: Macro 0.699568 (0.075508)\n",
      "Testing 1627/4320\n",
      "5 4 8 sqrt entropy True 200 29: Weighted 0.803902 (0.061066)\n",
      "5 4 8 sqrt entropy True 200 29: Macro 0.694404 (0.077537)\n",
      "Testing 1628/4320\n",
      "5 4 8 sqrt entropy True 500 29: Weighted 0.807467 (0.059573)\n",
      "5 4 8 sqrt entropy True 500 29: Macro 0.699568 (0.075508)\n",
      "Testing 1629/4320\n",
      "5 4 8 sqrt entropy False 50 29: Weighted 0.798411 (0.064279)\n",
      "5 4 8 sqrt entropy False 50 29: Macro 0.683448 (0.086856)\n",
      "Testing 1630/4320\n",
      "5 4 8 sqrt entropy False 100 29: Weighted 0.798829 (0.071049)\n",
      "5 4 8 sqrt entropy False 100 29: Macro 0.688032 (0.096843)\n",
      "Testing 1631/4320\n",
      "5 4 8 sqrt entropy False 200 29: Weighted 0.799284 (0.066331)\n",
      "5 4 8 sqrt entropy False 200 29: Macro 0.687687 (0.090862)\n",
      "Testing 1632/4320\n",
      "5 4 8 sqrt entropy False 500 29: Weighted 0.799284 (0.066331)\n",
      "5 4 8 sqrt entropy False 500 29: Macro 0.687687 (0.090862)\n",
      "Testing 1633/4320\n",
      "5 6 3 log2 gini True 50 29: Weighted 0.804099 (0.058536)\n",
      "5 6 3 log2 gini True 50 29: Macro 0.694382 (0.073353)\n",
      "Testing 1634/4320\n",
      "5 6 3 log2 gini True 100 29: Weighted 0.809673 (0.062686)\n",
      "5 6 3 log2 gini True 100 29: Macro 0.701491 (0.081072)\n",
      "Testing 1635/4320\n",
      "5 6 3 log2 gini True 200 29: Weighted 0.809935 (0.060810)\n",
      "5 6 3 log2 gini True 200 29: Macro 0.704820 (0.082311)\n",
      "Testing 1636/4320\n",
      "5 6 3 log2 gini True 500 29: Weighted 0.813941 (0.055478)\n",
      "5 6 3 log2 gini True 500 29: Macro 0.709900 (0.075733)\n",
      "Testing 1637/4320\n",
      "5 6 3 log2 gini False 50 29: Weighted 0.800801 (0.062924)\n",
      "5 6 3 log2 gini False 50 29: Macro 0.692099 (0.082395)\n",
      "Testing 1638/4320\n",
      "5 6 3 log2 gini False 100 29: Weighted 0.804317 (0.061898)\n",
      "5 6 3 log2 gini False 100 29: Macro 0.697056 (0.080675)\n",
      "Testing 1639/4320\n",
      "5 6 3 log2 gini False 200 29: Weighted 0.809244 (0.065497)\n",
      "5 6 3 log2 gini False 200 29: Macro 0.704564 (0.087453)\n",
      "Testing 1640/4320\n",
      "5 6 3 log2 gini False 500 29: Weighted 0.804627 (0.072614)\n",
      "5 6 3 log2 gini False 500 29: Macro 0.701445 (0.092151)\n",
      "Testing 1641/4320\n",
      "5 6 3 log2 entropy True 50 29: Weighted 0.800801 (0.062924)\n",
      "5 6 3 log2 entropy True 50 29: Macro 0.692099 (0.082395)\n",
      "Testing 1642/4320\n",
      "5 6 3 log2 entropy True 100 29: Weighted 0.796362 (0.069477)\n",
      "5 6 3 log2 entropy True 100 29: Macro 0.686706 (0.090276)\n",
      "Testing 1643/4320\n",
      "5 6 3 log2 entropy True 200 29: Weighted 0.800801 (0.062924)\n",
      "5 6 3 log2 entropy True 200 29: Macro 0.692099 (0.082395)\n",
      "Testing 1644/4320\n",
      "5 6 3 log2 entropy True 500 29: Weighted 0.808523 (0.055575)\n",
      "5 6 3 log2 entropy True 500 29: Macro 0.702270 (0.072850)\n",
      "Testing 1645/4320\n",
      "5 6 3 log2 entropy False 50 29: Weighted 0.794516 (0.077616)\n",
      "5 6 3 log2 entropy False 50 29: Macro 0.685000 (0.093405)\n",
      "Testing 1646/4320\n",
      "5 6 3 log2 entropy False 100 29: Weighted 0.799845 (0.069149)\n",
      "5 6 3 log2 entropy False 100 29: Macro 0.691304 (0.083483)\n",
      "Testing 1647/4320\n",
      "5 6 3 log2 entropy False 200 29: Weighted 0.799700 (0.069057)\n",
      "5 6 3 log2 entropy False 200 29: Macro 0.693936 (0.085471)\n",
      "Testing 1648/4320\n",
      "5 6 3 log2 entropy False 500 29: Weighted 0.787834 (0.088117)\n",
      "5 6 3 log2 entropy False 500 29: Macro 0.680688 (0.106489)\n",
      "Testing 1649/4320\n",
      "5 6 3 sqrt gini True 50 29: Weighted 0.804099 (0.058536)\n",
      "5 6 3 sqrt gini True 50 29: Macro 0.694382 (0.073353)\n",
      "Testing 1650/4320\n",
      "5 6 3 sqrt gini True 100 29: Weighted 0.809673 (0.062686)\n",
      "5 6 3 sqrt gini True 100 29: Macro 0.701491 (0.081072)\n",
      "Testing 1651/4320\n",
      "5 6 3 sqrt gini True 200 29: Weighted 0.809935 (0.060810)\n",
      "5 6 3 sqrt gini True 200 29: Macro 0.704820 (0.082311)\n",
      "Testing 1652/4320\n",
      "5 6 3 sqrt gini True 500 29: Weighted 0.813941 (0.055478)\n",
      "5 6 3 sqrt gini True 500 29: Macro 0.709900 (0.075733)\n",
      "Testing 1653/4320\n",
      "5 6 3 sqrt gini False 50 29: Weighted 0.800801 (0.062924)\n",
      "5 6 3 sqrt gini False 50 29: Macro 0.692099 (0.082395)\n",
      "Testing 1654/4320\n",
      "5 6 3 sqrt gini False 100 29: Weighted 0.804317 (0.061898)\n",
      "5 6 3 sqrt gini False 100 29: Macro 0.697056 (0.080675)\n",
      "Testing 1655/4320\n",
      "5 6 3 sqrt gini False 200 29: Weighted 0.809244 (0.065497)\n",
      "5 6 3 sqrt gini False 200 29: Macro 0.704564 (0.087453)\n",
      "Testing 1656/4320\n",
      "5 6 3 sqrt gini False 500 29: Weighted 0.804627 (0.072614)\n",
      "5 6 3 sqrt gini False 500 29: Macro 0.701445 (0.092151)\n",
      "Testing 1657/4320\n",
      "5 6 3 sqrt entropy True 50 29: Weighted 0.800801 (0.062924)\n",
      "5 6 3 sqrt entropy True 50 29: Macro 0.692099 (0.082395)\n",
      "Testing 1658/4320\n",
      "5 6 3 sqrt entropy True 100 29: Weighted 0.796362 (0.069477)\n",
      "5 6 3 sqrt entropy True 100 29: Macro 0.686706 (0.090276)\n",
      "Testing 1659/4320\n",
      "5 6 3 sqrt entropy True 200 29: Weighted 0.800801 (0.062924)\n",
      "5 6 3 sqrt entropy True 200 29: Macro 0.692099 (0.082395)\n",
      "Testing 1660/4320\n",
      "5 6 3 sqrt entropy True 500 29: Weighted 0.808523 (0.055575)\n",
      "5 6 3 sqrt entropy True 500 29: Macro 0.702270 (0.072850)\n",
      "Testing 1661/4320\n",
      "5 6 3 sqrt entropy False 50 29: Weighted 0.794516 (0.077616)\n",
      "5 6 3 sqrt entropy False 50 29: Macro 0.685000 (0.093405)\n",
      "Testing 1662/4320\n",
      "5 6 3 sqrt entropy False 100 29: Weighted 0.799845 (0.069149)\n",
      "5 6 3 sqrt entropy False 100 29: Macro 0.691304 (0.083483)\n",
      "Testing 1663/4320\n",
      "5 6 3 sqrt entropy False 200 29: Weighted 0.799700 (0.069057)\n",
      "5 6 3 sqrt entropy False 200 29: Macro 0.693936 (0.085471)\n",
      "Testing 1664/4320\n",
      "5 6 3 sqrt entropy False 500 29: Weighted 0.787834 (0.088117)\n",
      "5 6 3 sqrt entropy False 500 29: Macro 0.680688 (0.106489)\n",
      "Testing 1665/4320\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 6 5 log2 gini True 50 29: Weighted 0.810054 (0.060122)\n",
      "5 6 5 log2 gini True 50 29: Macro 0.701622 (0.078340)\n",
      "Testing 1666/4320\n",
      "5 6 5 log2 gini True 100 29: Weighted 0.812433 (0.053903)\n",
      "5 6 5 log2 gini True 100 29: Macro 0.704385 (0.068774)\n",
      "Testing 1667/4320\n",
      "5 6 5 log2 gini True 200 29: Weighted 0.804911 (0.060583)\n",
      "5 6 5 log2 gini True 200 29: Macro 0.694348 (0.077564)\n",
      "Testing 1668/4320\n",
      "5 6 5 log2 gini True 500 29: Weighted 0.804911 (0.060583)\n",
      "5 6 5 log2 gini True 500 29: Macro 0.694348 (0.077564)\n",
      "Testing 1669/4320\n",
      "5 6 5 log2 gini False 50 29: Weighted 0.799297 (0.071214)\n",
      "5 6 5 log2 gini False 50 29: Macro 0.685679 (0.095856)\n",
      "Testing 1670/4320\n",
      "5 6 5 log2 gini False 100 29: Weighted 0.807424 (0.072763)\n",
      "5 6 5 log2 gini False 100 29: Macro 0.700746 (0.100438)\n",
      "Testing 1671/4320\n",
      "5 6 5 log2 gini False 200 29: Weighted 0.807424 (0.072763)\n",
      "5 6 5 log2 gini False 200 29: Macro 0.700746 (0.100438)\n",
      "Testing 1672/4320\n",
      "5 6 5 log2 gini False 500 29: Weighted 0.808841 (0.076386)\n",
      "5 6 5 log2 gini False 500 29: Macro 0.702963 (0.106584)\n",
      "Testing 1673/4320\n",
      "5 6 5 log2 entropy True 50 29: Weighted 0.809889 (0.074131)\n",
      "5 6 5 log2 entropy True 50 29: Macro 0.703239 (0.096980)\n",
      "Testing 1674/4320\n",
      "5 6 5 log2 entropy True 100 29: Weighted 0.807656 (0.064827)\n",
      "5 6 5 log2 entropy True 100 29: Macro 0.699117 (0.082339)\n",
      "Testing 1675/4320\n",
      "5 6 5 log2 entropy True 200 29: Weighted 0.800704 (0.066202)\n",
      "5 6 5 log2 entropy True 200 29: Macro 0.689134 (0.084469)\n",
      "Testing 1676/4320\n",
      "5 6 5 log2 entropy True 500 29: Weighted 0.808426 (0.059274)\n",
      "5 6 5 log2 entropy True 500 29: Macro 0.699306 (0.075587)\n",
      "Testing 1677/4320\n",
      "5 6 5 log2 entropy False 50 29: Weighted 0.795161 (0.077426)\n",
      "5 6 5 log2 entropy False 50 29: Macro 0.676351 (0.110364)\n",
      "Testing 1678/4320\n",
      "5 6 5 log2 entropy False 100 29: Weighted 0.794391 (0.069940)\n",
      "5 6 5 log2 entropy False 100 29: Macro 0.678628 (0.093900)\n",
      "Testing 1679/4320\n",
      "5 6 5 log2 entropy False 200 29: Weighted 0.794694 (0.077250)\n",
      "5 6 5 log2 entropy False 200 29: Macro 0.678704 (0.111419)\n",
      "Testing 1680/4320\n",
      "5 6 5 log2 entropy False 500 29: Weighted 0.798829 (0.071049)\n",
      "5 6 5 log2 entropy False 500 29: Macro 0.688032 (0.096843)\n",
      "Testing 1681/4320\n",
      "5 6 5 sqrt gini True 50 29: Weighted 0.810054 (0.060122)\n",
      "5 6 5 sqrt gini True 50 29: Macro 0.701622 (0.078340)\n",
      "Testing 1682/4320\n",
      "5 6 5 sqrt gini True 100 29: Weighted 0.812433 (0.053903)\n",
      "5 6 5 sqrt gini True 100 29: Macro 0.704385 (0.068774)\n",
      "Testing 1683/4320\n",
      "5 6 5 sqrt gini True 200 29: Weighted 0.804911 (0.060583)\n",
      "5 6 5 sqrt gini True 200 29: Macro 0.694348 (0.077564)\n",
      "Testing 1684/4320\n",
      "5 6 5 sqrt gini True 500 29: Weighted 0.804911 (0.060583)\n",
      "5 6 5 sqrt gini True 500 29: Macro 0.694348 (0.077564)\n",
      "Testing 1685/4320\n",
      "5 6 5 sqrt gini False 50 29: Weighted 0.799297 (0.071214)\n",
      "5 6 5 sqrt gini False 50 29: Macro 0.685679 (0.095856)\n",
      "Testing 1686/4320\n",
      "5 6 5 sqrt gini False 100 29: Weighted 0.807424 (0.072763)\n",
      "5 6 5 sqrt gini False 100 29: Macro 0.700746 (0.100438)\n",
      "Testing 1687/4320\n",
      "5 6 5 sqrt gini False 200 29: Weighted 0.807424 (0.072763)\n",
      "5 6 5 sqrt gini False 200 29: Macro 0.700746 (0.100438)\n",
      "Testing 1688/4320\n",
      "5 6 5 sqrt gini False 500 29: Weighted 0.808841 (0.076386)\n",
      "5 6 5 sqrt gini False 500 29: Macro 0.702963 (0.106584)\n",
      "Testing 1689/4320\n",
      "5 6 5 sqrt entropy True 50 29: Weighted 0.809889 (0.074131)\n",
      "5 6 5 sqrt entropy True 50 29: Macro 0.703239 (0.096980)\n",
      "Testing 1690/4320\n",
      "5 6 5 sqrt entropy True 100 29: Weighted 0.807656 (0.064827)\n",
      "5 6 5 sqrt entropy True 100 29: Macro 0.699117 (0.082339)\n",
      "Testing 1691/4320\n",
      "5 6 5 sqrt entropy True 200 29: Weighted 0.800704 (0.066202)\n",
      "5 6 5 sqrt entropy True 200 29: Macro 0.689134 (0.084469)\n",
      "Testing 1692/4320\n",
      "5 6 5 sqrt entropy True 500 29: Weighted 0.808426 (0.059274)\n",
      "5 6 5 sqrt entropy True 500 29: Macro 0.699306 (0.075587)\n",
      "Testing 1693/4320\n",
      "5 6 5 sqrt entropy False 50 29: Weighted 0.795161 (0.077426)\n",
      "5 6 5 sqrt entropy False 50 29: Macro 0.676351 (0.110364)\n",
      "Testing 1694/4320\n",
      "5 6 5 sqrt entropy False 100 29: Weighted 0.794391 (0.069940)\n",
      "5 6 5 sqrt entropy False 100 29: Macro 0.678628 (0.093900)\n",
      "Testing 1695/4320\n",
      "5 6 5 sqrt entropy False 200 29: Weighted 0.794694 (0.077250)\n",
      "5 6 5 sqrt entropy False 200 29: Macro 0.678704 (0.111419)\n",
      "Testing 1696/4320\n",
      "5 6 5 sqrt entropy False 500 29: Weighted 0.798829 (0.071049)\n",
      "5 6 5 sqrt entropy False 500 29: Macro 0.688032 (0.096843)\n",
      "Testing 1697/4320\n",
      "5 6 8 log2 gini True 50 29: Weighted 0.806291 (0.063345)\n",
      "5 6 8 log2 gini True 50 29: Macro 0.696631 (0.082832)\n",
      "Testing 1698/4320\n",
      "5 6 8 log2 gini True 100 29: Weighted 0.813679 (0.057546)\n",
      "5 6 8 log2 gini True 100 29: Macro 0.706570 (0.074612)\n",
      "Testing 1699/4320\n",
      "5 6 8 log2 gini True 200 29: Weighted 0.813679 (0.057546)\n",
      "5 6 8 log2 gini True 200 29: Macro 0.706570 (0.074612)\n",
      "Testing 1700/4320\n",
      "5 6 8 log2 gini True 500 29: Weighted 0.804911 (0.060583)\n",
      "5 6 8 log2 gini True 500 29: Macro 0.694348 (0.077564)\n",
      "Testing 1701/4320\n",
      "5 6 8 log2 gini False 50 29: Weighted 0.791353 (0.077918)\n",
      "5 6 8 log2 gini False 50 29: Macro 0.672043 (0.111091)\n",
      "Testing 1702/4320\n",
      "5 6 8 log2 gini False 100 29: Weighted 0.804369 (0.068699)\n",
      "5 6 8 log2 gini False 100 29: Macro 0.695110 (0.095284)\n",
      "Testing 1703/4320\n",
      "5 6 8 log2 gini False 200 29: Weighted 0.804369 (0.068699)\n",
      "5 6 8 log2 gini False 200 29: Macro 0.695110 (0.095284)\n",
      "Testing 1704/4320\n",
      "5 6 8 log2 gini False 500 29: Weighted 0.804369 (0.068699)\n",
      "5 6 8 log2 gini False 500 29: Macro 0.695110 (0.095284)\n",
      "Testing 1705/4320\n",
      "5 6 8 log2 entropy True 50 29: Weighted 0.807467 (0.059573)\n",
      "5 6 8 log2 entropy True 50 29: Macro 0.699568 (0.075508)\n",
      "Testing 1706/4320\n",
      "5 6 8 log2 entropy True 100 29: Weighted 0.807467 (0.059573)\n",
      "5 6 8 log2 entropy True 100 29: Macro 0.699568 (0.075508)\n",
      "Testing 1707/4320\n",
      "5 6 8 log2 entropy True 200 29: Weighted 0.803902 (0.061066)\n",
      "5 6 8 log2 entropy True 200 29: Macro 0.694404 (0.077537)\n",
      "Testing 1708/4320\n",
      "5 6 8 log2 entropy True 500 29: Weighted 0.807467 (0.059573)\n",
      "5 6 8 log2 entropy True 500 29: Macro 0.699568 (0.075508)\n",
      "Testing 1709/4320\n",
      "5 6 8 log2 entropy False 50 29: Weighted 0.798411 (0.064279)\n",
      "5 6 8 log2 entropy False 50 29: Macro 0.683448 (0.086856)\n",
      "Testing 1710/4320\n",
      "5 6 8 log2 entropy False 100 29: Weighted 0.798829 (0.071049)\n",
      "5 6 8 log2 entropy False 100 29: Macro 0.688032 (0.096843)\n",
      "Testing 1711/4320\n",
      "5 6 8 log2 entropy False 200 29: Weighted 0.799284 (0.066331)\n",
      "5 6 8 log2 entropy False 200 29: Macro 0.687687 (0.090862)\n",
      "Testing 1712/4320\n",
      "5 6 8 log2 entropy False 500 29: Weighted 0.799284 (0.066331)\n",
      "5 6 8 log2 entropy False 500 29: Macro 0.687687 (0.090862)\n",
      "Testing 1713/4320\n",
      "5 6 8 sqrt gini True 50 29: Weighted 0.806291 (0.063345)\n",
      "5 6 8 sqrt gini True 50 29: Macro 0.696631 (0.082832)\n",
      "Testing 1714/4320\n",
      "5 6 8 sqrt gini True 100 29: Weighted 0.813679 (0.057546)\n",
      "5 6 8 sqrt gini True 100 29: Macro 0.706570 (0.074612)\n",
      "Testing 1715/4320\n",
      "5 6 8 sqrt gini True 200 29: Weighted 0.813679 (0.057546)\n",
      "5 6 8 sqrt gini True 200 29: Macro 0.706570 (0.074612)\n",
      "Testing 1716/4320\n",
      "5 6 8 sqrt gini True 500 29: Weighted 0.804911 (0.060583)\n",
      "5 6 8 sqrt gini True 500 29: Macro 0.694348 (0.077564)\n",
      "Testing 1717/4320\n",
      "5 6 8 sqrt gini False 50 29: Weighted 0.791353 (0.077918)\n",
      "5 6 8 sqrt gini False 50 29: Macro 0.672043 (0.111091)\n",
      "Testing 1718/4320\n",
      "5 6 8 sqrt gini False 100 29: Weighted 0.804369 (0.068699)\n",
      "5 6 8 sqrt gini False 100 29: Macro 0.695110 (0.095284)\n",
      "Testing 1719/4320\n",
      "5 6 8 sqrt gini False 200 29: Weighted 0.804369 (0.068699)\n",
      "5 6 8 sqrt gini False 200 29: Macro 0.695110 (0.095284)\n",
      "Testing 1720/4320\n",
      "5 6 8 sqrt gini False 500 29: Weighted 0.804369 (0.068699)\n",
      "5 6 8 sqrt gini False 500 29: Macro 0.695110 (0.095284)\n",
      "Testing 1721/4320\n",
      "5 6 8 sqrt entropy True 50 29: Weighted 0.807467 (0.059573)\n",
      "5 6 8 sqrt entropy True 50 29: Macro 0.699568 (0.075508)\n",
      "Testing 1722/4320\n",
      "5 6 8 sqrt entropy True 100 29: Weighted 0.807467 (0.059573)\n",
      "5 6 8 sqrt entropy True 100 29: Macro 0.699568 (0.075508)\n",
      "Testing 1723/4320\n",
      "5 6 8 sqrt entropy True 200 29: Weighted 0.803902 (0.061066)\n",
      "5 6 8 sqrt entropy True 200 29: Macro 0.694404 (0.077537)\n",
      "Testing 1724/4320\n",
      "5 6 8 sqrt entropy True 500 29: Weighted 0.807467 (0.059573)\n",
      "5 6 8 sqrt entropy True 500 29: Macro 0.699568 (0.075508)\n",
      "Testing 1725/4320\n",
      "5 6 8 sqrt entropy False 50 29: Weighted 0.798411 (0.064279)\n",
      "5 6 8 sqrt entropy False 50 29: Macro 0.683448 (0.086856)\n",
      "Testing 1726/4320\n",
      "5 6 8 sqrt entropy False 100 29: Weighted 0.798829 (0.071049)\n",
      "5 6 8 sqrt entropy False 100 29: Macro 0.688032 (0.096843)\n",
      "Testing 1727/4320\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 6 8 sqrt entropy False 200 29: Weighted 0.799284 (0.066331)\n",
      "5 6 8 sqrt entropy False 200 29: Macro 0.687687 (0.090862)\n",
      "Testing 1728/4320\n",
      "5 6 8 sqrt entropy False 500 29: Weighted 0.799284 (0.066331)\n",
      "5 6 8 sqrt entropy False 500 29: Macro 0.687687 (0.090862)\n",
      "Testing 1729/4320\n",
      "1 2 3 log2 gini True 50 42: Weighted 0.800597 (0.059190)\n",
      "1 2 3 log2 gini True 50 42: Macro 0.694531 (0.079229)\n",
      "Testing 1730/4320\n",
      "1 2 3 log2 gini True 100 42: Weighted 0.809935 (0.060810)\n",
      "1 2 3 log2 gini True 100 42: Macro 0.704820 (0.082311)\n",
      "Testing 1731/4320\n",
      "1 2 3 log2 gini True 200 42: Weighted 0.809935 (0.060810)\n",
      "1 2 3 log2 gini True 200 42: Macro 0.704820 (0.082311)\n",
      "Testing 1732/4320\n",
      "1 2 3 log2 gini True 500 42: Weighted 0.809014 (0.051630)\n",
      "1 2 3 log2 gini True 500 42: Macro 0.702391 (0.068382)\n",
      "Testing 1733/4320\n",
      "1 2 3 log2 gini False 50 42: Weighted 0.796632 (0.069438)\n",
      "1 2 3 log2 gini False 50 42: Macro 0.692870 (0.090981)\n",
      "Testing 1734/4320\n",
      "1 2 3 log2 gini False 100 42: Weighted 0.795735 (0.048271)\n",
      "1 2 3 log2 gini False 100 42: Macro 0.693103 (0.064293)\n",
      "Testing 1735/4320\n",
      "1 2 3 log2 gini False 200 42: Weighted 0.793563 (0.090270)\n",
      "1 2 3 log2 gini False 200 42: Macro 0.688455 (0.112395)\n",
      "Testing 1736/4320\n",
      "1 2 3 log2 gini False 500 42: Weighted 0.800147 (0.068724)\n",
      "1 2 3 log2 gini False 500 42: Macro 0.697828 (0.089383)\n",
      "Testing 1737/4320\n",
      "1 2 3 log2 entropy True 50 42: Weighted 0.801060 (0.062389)\n",
      "1 2 3 log2 entropy True 50 42: Macro 0.692847 (0.084279)\n",
      "Testing 1738/4320\n",
      "1 2 3 log2 entropy True 100 42: Weighted 0.809935 (0.060810)\n",
      "1 2 3 log2 entropy True 100 42: Macro 0.704820 (0.082311)\n",
      "Testing 1739/4320\n",
      "1 2 3 log2 entropy True 200 42: Weighted 0.809244 (0.065497)\n",
      "1 2 3 log2 entropy True 200 42: Macro 0.704564 (0.087453)\n",
      "Testing 1740/4320\n",
      "1 2 3 log2 entropy True 500 42: Weighted 0.805007 (0.056975)\n",
      "1 2 3 log2 entropy True 500 42: Macro 0.697312 (0.075095)\n",
      "Testing 1741/4320\n",
      "1 2 3 log2 entropy False 50 42: Weighted 0.783778 (0.060808)\n",
      "1 2 3 log2 entropy False 50 42: Macro 0.675024 (0.073400)\n",
      "Testing 1742/4320\n",
      "1 2 3 log2 entropy False 100 42: Weighted 0.789741 (0.062610)\n",
      "1 2 3 log2 entropy False 100 42: Macro 0.686378 (0.079941)\n",
      "Testing 1743/4320\n",
      "1 2 3 log2 entropy False 200 42: Weighted 0.787834 (0.088117)\n",
      "1 2 3 log2 entropy False 200 42: Macro 0.680688 (0.106489)\n",
      "Testing 1744/4320\n",
      "1 2 3 log2 entropy False 500 42: Weighted 0.783355 (0.084050)\n",
      "1 2 3 log2 entropy False 500 42: Macro 0.677071 (0.103379)\n",
      "Testing 1745/4320\n",
      "1 2 3 sqrt gini True 50 42: Weighted 0.800597 (0.059190)\n",
      "1 2 3 sqrt gini True 50 42: Macro 0.694531 (0.079229)\n",
      "Testing 1746/4320\n",
      "1 2 3 sqrt gini True 100 42: Weighted 0.809935 (0.060810)\n",
      "1 2 3 sqrt gini True 100 42: Macro 0.704820 (0.082311)\n",
      "Testing 1747/4320\n",
      "1 2 3 sqrt gini True 200 42: Weighted 0.809935 (0.060810)\n",
      "1 2 3 sqrt gini True 200 42: Macro 0.704820 (0.082311)\n",
      "Testing 1748/4320\n",
      "1 2 3 sqrt gini True 500 42: Weighted 0.809014 (0.051630)\n",
      "1 2 3 sqrt gini True 500 42: Macro 0.702391 (0.068382)\n",
      "Testing 1749/4320\n",
      "1 2 3 sqrt gini False 50 42: Weighted 0.796632 (0.069438)\n",
      "1 2 3 sqrt gini False 50 42: Macro 0.692870 (0.090981)\n",
      "Testing 1750/4320\n",
      "1 2 3 sqrt gini False 100 42: Weighted 0.795735 (0.048271)\n",
      "1 2 3 sqrt gini False 100 42: Macro 0.693103 (0.064293)\n",
      "Testing 1751/4320\n",
      "1 2 3 sqrt gini False 200 42: Weighted 0.793563 (0.090270)\n",
      "1 2 3 sqrt gini False 200 42: Macro 0.688455 (0.112395)\n",
      "Testing 1752/4320\n",
      "1 2 3 sqrt gini False 500 42: Weighted 0.800147 (0.068724)\n",
      "1 2 3 sqrt gini False 500 42: Macro 0.697828 (0.089383)\n",
      "Testing 1753/4320\n",
      "1 2 3 sqrt entropy True 50 42: Weighted 0.801060 (0.062389)\n",
      "1 2 3 sqrt entropy True 50 42: Macro 0.692847 (0.084279)\n",
      "Testing 1754/4320\n",
      "1 2 3 sqrt entropy True 100 42: Weighted 0.809935 (0.060810)\n",
      "1 2 3 sqrt entropy True 100 42: Macro 0.704820 (0.082311)\n",
      "Testing 1755/4320\n",
      "1 2 3 sqrt entropy True 200 42: Weighted 0.809244 (0.065497)\n",
      "1 2 3 sqrt entropy True 200 42: Macro 0.704564 (0.087453)\n",
      "Testing 1756/4320\n",
      "1 2 3 sqrt entropy True 500 42: Weighted 0.805007 (0.056975)\n",
      "1 2 3 sqrt entropy True 500 42: Macro 0.697312 (0.075095)\n",
      "Testing 1757/4320\n",
      "1 2 3 sqrt entropy False 50 42: Weighted 0.783778 (0.060808)\n",
      "1 2 3 sqrt entropy False 50 42: Macro 0.675024 (0.073400)\n",
      "Testing 1758/4320\n",
      "1 2 3 sqrt entropy False 100 42: Weighted 0.789741 (0.062610)\n",
      "1 2 3 sqrt entropy False 100 42: Macro 0.686378 (0.079941)\n",
      "Testing 1759/4320\n",
      "1 2 3 sqrt entropy False 200 42: Weighted 0.787834 (0.088117)\n",
      "1 2 3 sqrt entropy False 200 42: Macro 0.680688 (0.106489)\n",
      "Testing 1760/4320\n",
      "1 2 3 sqrt entropy False 500 42: Weighted 0.783355 (0.084050)\n",
      "1 2 3 sqrt entropy False 500 42: Macro 0.677071 (0.103379)\n",
      "Testing 1761/4320\n",
      "1 2 5 log2 gini True 50 42: Weighted 0.819700 (0.049443)\n",
      "1 2 5 log2 gini True 50 42: Macro 0.726156 (0.065679)\n",
      "Testing 1762/4320\n",
      "1 2 5 log2 gini True 100 42: Weighted 0.812145 (0.059723)\n",
      "1 2 5 log2 gini True 100 42: Macro 0.714345 (0.081960)\n",
      "Testing 1763/4320\n",
      "1 2 5 log2 gini True 200 42: Weighted 0.816674 (0.064627)\n",
      "1 2 5 log2 gini True 200 42: Macro 0.718015 (0.085470)\n",
      "Testing 1764/4320\n",
      "1 2 5 log2 gini True 500 42: Weighted 0.807129 (0.059688)\n",
      "1 2 5 log2 gini True 500 42: Macro 0.700731 (0.075190)\n",
      "Testing 1765/4320\n",
      "1 2 5 log2 gini False 50 42: Weighted 0.794030 (0.071910)\n",
      "1 2 5 log2 gini False 50 42: Macro 0.691380 (0.102000)\n",
      "Testing 1766/4320\n",
      "1 2 5 log2 gini False 100 42: Weighted 0.792510 (0.066969)\n",
      "1 2 5 log2 gini False 100 42: Macro 0.688866 (0.094456)\n",
      "Testing 1767/4320\n",
      "1 2 5 log2 gini False 200 42: Weighted 0.797438 (0.071131)\n",
      "1 2 5 log2 gini False 200 42: Macro 0.696374 (0.100919)\n",
      "Testing 1768/4320\n",
      "1 2 5 log2 gini False 500 42: Weighted 0.792510 (0.066969)\n",
      "1 2 5 log2 gini False 500 42: Macro 0.688866 (0.094456)\n",
      "Testing 1769/4320\n",
      "1 2 5 log2 entropy True 50 42: Weighted 0.809060 (0.072124)\n",
      "1 2 5 log2 entropy True 50 42: Macro 0.707808 (0.095153)\n",
      "Testing 1770/4320\n",
      "1 2 5 log2 entropy True 100 42: Weighted 0.811891 (0.061650)\n",
      "1 2 5 log2 entropy True 100 42: Macro 0.707874 (0.078223)\n",
      "Testing 1771/4320\n",
      "1 2 5 log2 entropy True 200 42: Weighted 0.812079 (0.070687)\n",
      "1 2 5 log2 entropy True 200 42: Macro 0.706078 (0.091539)\n",
      "Testing 1772/4320\n",
      "1 2 5 log2 entropy True 500 42: Weighted 0.807129 (0.059688)\n",
      "1 2 5 log2 entropy True 500 42: Macro 0.700731 (0.075190)\n",
      "Testing 1773/4320\n",
      "1 2 5 log2 entropy False 50 42: Weighted 0.776265 (0.071203)\n",
      "1 2 5 log2 entropy False 50 42: Macro 0.661812 (0.105759)\n",
      "Testing 1774/4320\n",
      "1 2 5 log2 entropy False 100 42: Weighted 0.779745 (0.070594)\n",
      "1 2 5 log2 entropy False 100 42: Macro 0.666731 (0.105191)\n",
      "Testing 1775/4320\n",
      "1 2 5 log2 entropy False 200 42: Weighted 0.784019 (0.063935)\n",
      "1 2 5 log2 entropy False 200 42: Macro 0.676449 (0.089869)\n",
      "Testing 1776/4320\n",
      "1 2 5 log2 entropy False 500 42: Weighted 0.780538 (0.064836)\n",
      "1 2 5 log2 entropy False 500 42: Macro 0.671530 (0.091060)\n",
      "Testing 1777/4320\n",
      "1 2 5 sqrt gini True 50 42: Weighted 0.819700 (0.049443)\n",
      "1 2 5 sqrt gini True 50 42: Macro 0.726156 (0.065679)\n",
      "Testing 1778/4320\n",
      "1 2 5 sqrt gini True 100 42: Weighted 0.812145 (0.059723)\n",
      "1 2 5 sqrt gini True 100 42: Macro 0.714345 (0.081960)\n",
      "Testing 1779/4320\n",
      "1 2 5 sqrt gini True 200 42: Weighted 0.816674 (0.064627)\n",
      "1 2 5 sqrt gini True 200 42: Macro 0.718015 (0.085470)\n",
      "Testing 1780/4320\n",
      "1 2 5 sqrt gini True 500 42: Weighted 0.807129 (0.059688)\n",
      "1 2 5 sqrt gini True 500 42: Macro 0.700731 (0.075190)\n",
      "Testing 1781/4320\n",
      "1 2 5 sqrt gini False 50 42: Weighted 0.794030 (0.071910)\n",
      "1 2 5 sqrt gini False 50 42: Macro 0.691380 (0.102000)\n",
      "Testing 1782/4320\n",
      "1 2 5 sqrt gini False 100 42: Weighted 0.792510 (0.066969)\n",
      "1 2 5 sqrt gini False 100 42: Macro 0.688866 (0.094456)\n",
      "Testing 1783/4320\n",
      "1 2 5 sqrt gini False 200 42: Weighted 0.797438 (0.071131)\n",
      "1 2 5 sqrt gini False 200 42: Macro 0.696374 (0.100919)\n",
      "Testing 1784/4320\n",
      "1 2 5 sqrt gini False 500 42: Weighted 0.792510 (0.066969)\n",
      "1 2 5 sqrt gini False 500 42: Macro 0.688866 (0.094456)\n",
      "Testing 1785/4320\n",
      "1 2 5 sqrt entropy True 50 42: Weighted 0.809060 (0.072124)\n",
      "1 2 5 sqrt entropy True 50 42: Macro 0.707808 (0.095153)\n",
      "Testing 1786/4320\n",
      "1 2 5 sqrt entropy True 100 42: Weighted 0.811891 (0.061650)\n",
      "1 2 5 sqrt entropy True 100 42: Macro 0.707874 (0.078223)\n",
      "Testing 1787/4320\n",
      "1 2 5 sqrt entropy True 200 42: Weighted 0.812079 (0.070687)\n",
      "1 2 5 sqrt entropy True 200 42: Macro 0.706078 (0.091539)\n",
      "Testing 1788/4320\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 2 5 sqrt entropy True 500 42: Weighted 0.807129 (0.059688)\n",
      "1 2 5 sqrt entropy True 500 42: Macro 0.700731 (0.075190)\n",
      "Testing 1789/4320\n",
      "1 2 5 sqrt entropy False 50 42: Weighted 0.776265 (0.071203)\n",
      "1 2 5 sqrt entropy False 50 42: Macro 0.661812 (0.105759)\n",
      "Testing 1790/4320\n",
      "1 2 5 sqrt entropy False 100 42: Weighted 0.779745 (0.070594)\n",
      "1 2 5 sqrt entropy False 100 42: Macro 0.666731 (0.105191)\n",
      "Testing 1791/4320\n",
      "1 2 5 sqrt entropy False 200 42: Weighted 0.784019 (0.063935)\n",
      "1 2 5 sqrt entropy False 200 42: Macro 0.676449 (0.089869)\n",
      "Testing 1792/4320\n",
      "1 2 5 sqrt entropy False 500 42: Weighted 0.780538 (0.064836)\n",
      "1 2 5 sqrt entropy False 500 42: Macro 0.671530 (0.091060)\n",
      "Testing 1793/4320\n",
      "1 2 8 log2 gini True 50 42: Weighted 0.804679 (0.065256)\n",
      "1 2 8 log2 gini True 50 42: Macro 0.702136 (0.087987)\n",
      "Testing 1794/4320\n",
      "1 2 8 log2 gini True 100 42: Weighted 0.809803 (0.064228)\n",
      "1 2 8 log2 gini True 100 42: Macro 0.708723 (0.078857)\n",
      "Testing 1795/4320\n",
      "1 2 8 log2 gini True 200 42: Weighted 0.809983 (0.064322)\n",
      "1 2 8 log2 gini True 200 42: Macro 0.707799 (0.078331)\n",
      "Testing 1796/4320\n",
      "1 2 8 log2 gini True 500 42: Weighted 0.793813 (0.059254)\n",
      "1 2 8 log2 gini True 500 42: Macro 0.683932 (0.070273)\n",
      "Testing 1797/4320\n",
      "1 2 8 log2 gini False 50 42: Weighted 0.783800 (0.062548)\n",
      "1 2 8 log2 gini False 50 42: Macro 0.679049 (0.087714)\n",
      "Testing 1798/4320\n",
      "1 2 8 log2 gini False 100 42: Weighted 0.789300 (0.063058)\n",
      "1 2 8 log2 gini False 100 42: Macro 0.688227 (0.087910)\n",
      "Testing 1799/4320\n",
      "1 2 8 log2 gini False 200 42: Weighted 0.784880 (0.058788)\n",
      "1 2 8 log2 gini False 200 42: Macro 0.681524 (0.081883)\n",
      "Testing 1800/4320\n",
      "1 2 8 log2 gini False 500 42: Weighted 0.789300 (0.063058)\n",
      "1 2 8 log2 gini False 500 42: Macro 0.688227 (0.087910)\n",
      "Testing 1801/4320\n",
      "1 2 8 log2 entropy True 50 42: Weighted 0.807513 (0.066039)\n",
      "1 2 8 log2 entropy True 50 42: Macro 0.703873 (0.084176)\n",
      "Testing 1802/4320\n",
      "1 2 8 log2 entropy True 100 42: Weighted 0.810100 (0.054769)\n",
      "1 2 8 log2 entropy True 100 42: Macro 0.707296 (0.068239)\n",
      "Testing 1803/4320\n",
      "1 2 8 log2 entropy True 200 42: Weighted 0.805006 (0.059010)\n",
      "1 2 8 log2 entropy True 200 42: Macro 0.701252 (0.070207)\n",
      "Testing 1804/4320\n",
      "1 2 8 log2 entropy True 500 42: Weighted 0.805006 (0.059010)\n",
      "1 2 8 log2 entropy True 500 42: Macro 0.701252 (0.070207)\n",
      "Testing 1805/4320\n",
      "1 2 8 log2 entropy False 50 42: Weighted 0.786797 (0.054734)\n",
      "1 2 8 log2 entropy False 50 42: Macro 0.681886 (0.076936)\n",
      "Testing 1806/4320\n",
      "1 2 8 log2 entropy False 100 42: Weighted 0.786797 (0.054734)\n",
      "1 2 8 log2 entropy False 100 42: Macro 0.681886 (0.076936)\n",
      "Testing 1807/4320\n",
      "1 2 8 log2 entropy False 200 42: Weighted 0.786797 (0.054734)\n",
      "1 2 8 log2 entropy False 200 42: Macro 0.681886 (0.076936)\n",
      "Testing 1808/4320\n",
      "1 2 8 log2 entropy False 500 42: Weighted 0.786797 (0.054734)\n",
      "1 2 8 log2 entropy False 500 42: Macro 0.681886 (0.076936)\n",
      "Testing 1809/4320\n",
      "1 2 8 sqrt gini True 50 42: Weighted 0.804679 (0.065256)\n",
      "1 2 8 sqrt gini True 50 42: Macro 0.702136 (0.087987)\n",
      "Testing 1810/4320\n",
      "1 2 8 sqrt gini True 100 42: Weighted 0.809803 (0.064228)\n",
      "1 2 8 sqrt gini True 100 42: Macro 0.708723 (0.078857)\n",
      "Testing 1811/4320\n",
      "1 2 8 sqrt gini True 200 42: Weighted 0.809983 (0.064322)\n",
      "1 2 8 sqrt gini True 200 42: Macro 0.707799 (0.078331)\n",
      "Testing 1812/4320\n",
      "1 2 8 sqrt gini True 500 42: Weighted 0.793813 (0.059254)\n",
      "1 2 8 sqrt gini True 500 42: Macro 0.683932 (0.070273)\n",
      "Testing 1813/4320\n",
      "1 2 8 sqrt gini False 50 42: Weighted 0.783800 (0.062548)\n",
      "1 2 8 sqrt gini False 50 42: Macro 0.679049 (0.087714)\n",
      "Testing 1814/4320\n",
      "1 2 8 sqrt gini False 100 42: Weighted 0.789300 (0.063058)\n",
      "1 2 8 sqrt gini False 100 42: Macro 0.688227 (0.087910)\n",
      "Testing 1815/4320\n",
      "1 2 8 sqrt gini False 200 42: Weighted 0.784880 (0.058788)\n",
      "1 2 8 sqrt gini False 200 42: Macro 0.681524 (0.081883)\n",
      "Testing 1816/4320\n",
      "1 2 8 sqrt gini False 500 42: Weighted 0.789300 (0.063058)\n",
      "1 2 8 sqrt gini False 500 42: Macro 0.688227 (0.087910)\n",
      "Testing 1817/4320\n",
      "1 2 8 sqrt entropy True 50 42: Weighted 0.807513 (0.066039)\n",
      "1 2 8 sqrt entropy True 50 42: Macro 0.703873 (0.084176)\n",
      "Testing 1818/4320\n",
      "1 2 8 sqrt entropy True 100 42: Weighted 0.810100 (0.054769)\n",
      "1 2 8 sqrt entropy True 100 42: Macro 0.707296 (0.068239)\n",
      "Testing 1819/4320\n",
      "1 2 8 sqrt entropy True 200 42: Weighted 0.805006 (0.059010)\n",
      "1 2 8 sqrt entropy True 200 42: Macro 0.701252 (0.070207)\n",
      "Testing 1820/4320\n",
      "1 2 8 sqrt entropy True 500 42: Weighted 0.805006 (0.059010)\n",
      "1 2 8 sqrt entropy True 500 42: Macro 0.701252 (0.070207)\n",
      "Testing 1821/4320\n",
      "1 2 8 sqrt entropy False 50 42: Weighted 0.786797 (0.054734)\n",
      "1 2 8 sqrt entropy False 50 42: Macro 0.681886 (0.076936)\n",
      "Testing 1822/4320\n",
      "1 2 8 sqrt entropy False 100 42: Weighted 0.786797 (0.054734)\n",
      "1 2 8 sqrt entropy False 100 42: Macro 0.681886 (0.076936)\n",
      "Testing 1823/4320\n",
      "1 2 8 sqrt entropy False 200 42: Weighted 0.786797 (0.054734)\n",
      "1 2 8 sqrt entropy False 200 42: Macro 0.681886 (0.076936)\n",
      "Testing 1824/4320\n",
      "1 2 8 sqrt entropy False 500 42: Weighted 0.786797 (0.054734)\n",
      "1 2 8 sqrt entropy False 500 42: Macro 0.681886 (0.076936)\n",
      "Testing 1825/4320\n",
      "1 4 3 log2 gini True 50 42: Weighted 0.805266 (0.063779)\n",
      "1 4 3 log2 gini True 50 42: Macro 0.701291 (0.084584)\n",
      "Testing 1826/4320\n",
      "1 4 3 log2 gini True 100 42: Weighted 0.805266 (0.063779)\n",
      "1 4 3 log2 gini True 100 42: Macro 0.701291 (0.084584)\n",
      "Testing 1827/4320\n",
      "1 4 3 log2 gini True 200 42: Weighted 0.809935 (0.060810)\n",
      "1 4 3 log2 gini True 200 42: Macro 0.704820 (0.082311)\n",
      "Testing 1828/4320\n",
      "1 4 3 log2 gini True 500 42: Weighted 0.809014 (0.051630)\n",
      "1 4 3 log2 gini True 500 42: Macro 0.702391 (0.068382)\n",
      "Testing 1829/4320\n",
      "1 4 3 log2 gini False 50 42: Weighted 0.796442 (0.075436)\n",
      "1 4 3 log2 gini False 50 42: Macro 0.692957 (0.095585)\n",
      "Testing 1830/4320\n",
      "1 4 3 log2 gini False 100 42: Weighted 0.796132 (0.065146)\n",
      "1 4 3 log2 gini False 100 42: Macro 0.688569 (0.084134)\n",
      "Testing 1831/4320\n",
      "1 4 3 log2 gini False 200 42: Weighted 0.788859 (0.090750)\n",
      "1 4 3 log2 gini False 200 42: Macro 0.684887 (0.112953)\n",
      "Testing 1832/4320\n",
      "1 4 3 log2 gini False 500 42: Weighted 0.798867 (0.075476)\n",
      "1 4 3 log2 gini False 500 42: Macro 0.697450 (0.093953)\n",
      "Testing 1833/4320\n",
      "1 4 3 log2 entropy True 50 42: Weighted 0.801060 (0.062389)\n",
      "1 4 3 log2 entropy True 50 42: Macro 0.692847 (0.084279)\n",
      "Testing 1834/4320\n",
      "1 4 3 log2 entropy True 100 42: Weighted 0.809935 (0.060810)\n",
      "1 4 3 log2 entropy True 100 42: Macro 0.704820 (0.082311)\n",
      "Testing 1835/4320\n",
      "1 4 3 log2 entropy True 200 42: Weighted 0.809244 (0.065497)\n",
      "1 4 3 log2 entropy True 200 42: Macro 0.704564 (0.087453)\n",
      "Testing 1836/4320\n",
      "1 4 3 log2 entropy True 500 42: Weighted 0.805007 (0.056975)\n",
      "1 4 3 log2 entropy True 500 42: Macro 0.697312 (0.075095)\n",
      "Testing 1837/4320\n",
      "1 4 3 log2 entropy False 50 42: Weighted 0.777448 (0.083265)\n",
      "1 4 3 log2 entropy False 50 42: Macro 0.665820 (0.097952)\n",
      "Testing 1838/4320\n",
      "1 4 3 log2 entropy False 100 42: Weighted 0.787834 (0.088117)\n",
      "1 4 3 log2 entropy False 100 42: Macro 0.680688 (0.106489)\n",
      "Testing 1839/4320\n",
      "1 4 3 log2 entropy False 200 42: Weighted 0.787834 (0.088117)\n",
      "1 4 3 log2 entropy False 200 42: Macro 0.680688 (0.106489)\n",
      "Testing 1840/4320\n",
      "1 4 3 log2 entropy False 500 42: Weighted 0.787834 (0.088117)\n",
      "1 4 3 log2 entropy False 500 42: Macro 0.680688 (0.106489)\n",
      "Testing 1841/4320\n",
      "1 4 3 sqrt gini True 50 42: Weighted 0.805266 (0.063779)\n",
      "1 4 3 sqrt gini True 50 42: Macro 0.701291 (0.084584)\n",
      "Testing 1842/4320\n",
      "1 4 3 sqrt gini True 100 42: Weighted 0.805266 (0.063779)\n",
      "1 4 3 sqrt gini True 100 42: Macro 0.701291 (0.084584)\n",
      "Testing 1843/4320\n",
      "1 4 3 sqrt gini True 200 42: Weighted 0.809935 (0.060810)\n",
      "1 4 3 sqrt gini True 200 42: Macro 0.704820 (0.082311)\n",
      "Testing 1844/4320\n",
      "1 4 3 sqrt gini True 500 42: Weighted 0.809014 (0.051630)\n",
      "1 4 3 sqrt gini True 500 42: Macro 0.702391 (0.068382)\n",
      "Testing 1845/4320\n",
      "1 4 3 sqrt gini False 50 42: Weighted 0.796442 (0.075436)\n",
      "1 4 3 sqrt gini False 50 42: Macro 0.692957 (0.095585)\n",
      "Testing 1846/4320\n",
      "1 4 3 sqrt gini False 100 42: Weighted 0.796132 (0.065146)\n",
      "1 4 3 sqrt gini False 100 42: Macro 0.688569 (0.084134)\n",
      "Testing 1847/4320\n",
      "1 4 3 sqrt gini False 200 42: Weighted 0.788859 (0.090750)\n",
      "1 4 3 sqrt gini False 200 42: Macro 0.684887 (0.112953)\n",
      "Testing 1848/4320\n",
      "1 4 3 sqrt gini False 500 42: Weighted 0.798867 (0.075476)\n",
      "1 4 3 sqrt gini False 500 42: Macro 0.697450 (0.093953)\n",
      "Testing 1849/4320\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 4 3 sqrt entropy True 50 42: Weighted 0.801060 (0.062389)\n",
      "1 4 3 sqrt entropy True 50 42: Macro 0.692847 (0.084279)\n",
      "Testing 1850/4320\n",
      "1 4 3 sqrt entropy True 100 42: Weighted 0.809935 (0.060810)\n",
      "1 4 3 sqrt entropy True 100 42: Macro 0.704820 (0.082311)\n",
      "Testing 1851/4320\n",
      "1 4 3 sqrt entropy True 200 42: Weighted 0.809244 (0.065497)\n",
      "1 4 3 sqrt entropy True 200 42: Macro 0.704564 (0.087453)\n",
      "Testing 1852/4320\n",
      "1 4 3 sqrt entropy True 500 42: Weighted 0.805007 (0.056975)\n",
      "1 4 3 sqrt entropy True 500 42: Macro 0.697312 (0.075095)\n",
      "Testing 1853/4320\n",
      "1 4 3 sqrt entropy False 50 42: Weighted 0.777448 (0.083265)\n",
      "1 4 3 sqrt entropy False 50 42: Macro 0.665820 (0.097952)\n",
      "Testing 1854/4320\n",
      "1 4 3 sqrt entropy False 100 42: Weighted 0.787834 (0.088117)\n",
      "1 4 3 sqrt entropy False 100 42: Macro 0.680688 (0.106489)\n",
      "Testing 1855/4320\n",
      "1 4 3 sqrt entropy False 200 42: Weighted 0.787834 (0.088117)\n",
      "1 4 3 sqrt entropy False 200 42: Macro 0.680688 (0.106489)\n",
      "Testing 1856/4320\n",
      "1 4 3 sqrt entropy False 500 42: Weighted 0.787834 (0.088117)\n",
      "1 4 3 sqrt entropy False 500 42: Macro 0.680688 (0.106489)\n",
      "Testing 1857/4320\n",
      "1 4 5 log2 gini True 50 42: Weighted 0.816674 (0.064627)\n",
      "1 4 5 log2 gini True 50 42: Macro 0.718015 (0.085470)\n",
      "Testing 1858/4320\n",
      "1 4 5 log2 gini True 100 42: Weighted 0.816674 (0.064627)\n",
      "1 4 5 log2 gini True 100 42: Macro 0.718015 (0.085470)\n",
      "Testing 1859/4320\n",
      "1 4 5 log2 gini True 200 42: Weighted 0.816674 (0.064627)\n",
      "1 4 5 log2 gini True 200 42: Macro 0.718015 (0.085470)\n",
      "Testing 1860/4320\n",
      "1 4 5 log2 gini True 500 42: Weighted 0.807129 (0.059688)\n",
      "1 4 5 log2 gini True 500 42: Macro 0.700731 (0.075190)\n",
      "Testing 1861/4320\n",
      "1 4 5 log2 gini False 50 42: Weighted 0.800576 (0.072959)\n",
      "1 4 5 log2 gini False 50 42: Macro 0.692321 (0.101576)\n",
      "Testing 1862/4320\n",
      "1 4 5 log2 gini False 100 42: Weighted 0.803576 (0.073375)\n",
      "1 4 5 log2 gini False 100 42: Macro 0.696618 (0.100788)\n",
      "Testing 1863/4320\n",
      "1 4 5 log2 gini False 200 42: Weighted 0.808504 (0.076483)\n",
      "1 4 5 log2 gini False 200 42: Macro 0.704126 (0.106322)\n",
      "Testing 1864/4320\n",
      "1 4 5 log2 gini False 500 42: Weighted 0.803576 (0.073375)\n",
      "1 4 5 log2 gini False 500 42: Macro 0.696618 (0.100788)\n",
      "Testing 1865/4320\n",
      "1 4 5 log2 entropy True 50 42: Weighted 0.804097 (0.068839)\n",
      "1 4 5 log2 entropy True 50 42: Macro 0.698592 (0.088103)\n",
      "Testing 1866/4320\n",
      "1 4 5 log2 entropy True 100 42: Weighted 0.807129 (0.059688)\n",
      "1 4 5 log2 entropy True 100 42: Macro 0.700731 (0.075190)\n",
      "Testing 1867/4320\n",
      "1 4 5 log2 entropy True 200 42: Weighted 0.811891 (0.061650)\n",
      "1 4 5 log2 entropy True 200 42: Macro 0.707874 (0.078223)\n",
      "Testing 1868/4320\n",
      "1 4 5 log2 entropy True 500 42: Weighted 0.807129 (0.059688)\n",
      "1 4 5 log2 entropy True 500 42: Macro 0.700731 (0.075190)\n",
      "Testing 1869/4320\n",
      "1 4 5 log2 entropy False 50 42: Weighted 0.788748 (0.081104)\n",
      "1 4 5 log2 entropy False 50 42: Macro 0.673970 (0.113068)\n",
      "Testing 1870/4320\n",
      "1 4 5 log2 entropy False 100 42: Weighted 0.788748 (0.081104)\n",
      "1 4 5 log2 entropy False 100 42: Macro 0.673970 (0.113068)\n",
      "Testing 1871/4320\n",
      "1 4 5 log2 entropy False 200 42: Weighted 0.788748 (0.081104)\n",
      "1 4 5 log2 entropy False 200 42: Macro 0.673970 (0.113068)\n",
      "Testing 1872/4320\n",
      "1 4 5 log2 entropy False 500 42: Weighted 0.789541 (0.076051)\n",
      "1 4 5 log2 entropy False 500 42: Macro 0.678769 (0.099708)\n",
      "Testing 1873/4320\n",
      "1 4 5 sqrt gini True 50 42: Weighted 0.816674 (0.064627)\n",
      "1 4 5 sqrt gini True 50 42: Macro 0.718015 (0.085470)\n",
      "Testing 1874/4320\n",
      "1 4 5 sqrt gini True 100 42: Weighted 0.816674 (0.064627)\n",
      "1 4 5 sqrt gini True 100 42: Macro 0.718015 (0.085470)\n",
      "Testing 1875/4320\n",
      "1 4 5 sqrt gini True 200 42: Weighted 0.816674 (0.064627)\n",
      "1 4 5 sqrt gini True 200 42: Macro 0.718015 (0.085470)\n",
      "Testing 1876/4320\n",
      "1 4 5 sqrt gini True 500 42: Weighted 0.807129 (0.059688)\n",
      "1 4 5 sqrt gini True 500 42: Macro 0.700731 (0.075190)\n",
      "Testing 1877/4320\n",
      "1 4 5 sqrt gini False 50 42: Weighted 0.800576 (0.072959)\n",
      "1 4 5 sqrt gini False 50 42: Macro 0.692321 (0.101576)\n",
      "Testing 1878/4320\n",
      "1 4 5 sqrt gini False 100 42: Weighted 0.803576 (0.073375)\n",
      "1 4 5 sqrt gini False 100 42: Macro 0.696618 (0.100788)\n",
      "Testing 1879/4320\n",
      "1 4 5 sqrt gini False 200 42: Weighted 0.808504 (0.076483)\n",
      "1 4 5 sqrt gini False 200 42: Macro 0.704126 (0.106322)\n",
      "Testing 1880/4320\n",
      "1 4 5 sqrt gini False 500 42: Weighted 0.803576 (0.073375)\n",
      "1 4 5 sqrt gini False 500 42: Macro 0.696618 (0.100788)\n",
      "Testing 1881/4320\n",
      "1 4 5 sqrt entropy True 50 42: Weighted 0.804097 (0.068839)\n",
      "1 4 5 sqrt entropy True 50 42: Macro 0.698592 (0.088103)\n",
      "Testing 1882/4320\n",
      "1 4 5 sqrt entropy True 100 42: Weighted 0.807129 (0.059688)\n",
      "1 4 5 sqrt entropy True 100 42: Macro 0.700731 (0.075190)\n",
      "Testing 1883/4320\n",
      "1 4 5 sqrt entropy True 200 42: Weighted 0.811891 (0.061650)\n",
      "1 4 5 sqrt entropy True 200 42: Macro 0.707874 (0.078223)\n",
      "Testing 1884/4320\n",
      "1 4 5 sqrt entropy True 500 42: Weighted 0.807129 (0.059688)\n",
      "1 4 5 sqrt entropy True 500 42: Macro 0.700731 (0.075190)\n",
      "Testing 1885/4320\n",
      "1 4 5 sqrt entropy False 50 42: Weighted 0.788748 (0.081104)\n",
      "1 4 5 sqrt entropy False 50 42: Macro 0.673970 (0.113068)\n",
      "Testing 1886/4320\n",
      "1 4 5 sqrt entropy False 100 42: Weighted 0.788748 (0.081104)\n",
      "1 4 5 sqrt entropy False 100 42: Macro 0.673970 (0.113068)\n",
      "Testing 1887/4320\n",
      "1 4 5 sqrt entropy False 200 42: Weighted 0.788748 (0.081104)\n",
      "1 4 5 sqrt entropy False 200 42: Macro 0.673970 (0.113068)\n",
      "Testing 1888/4320\n",
      "1 4 5 sqrt entropy False 500 42: Weighted 0.789541 (0.076051)\n",
      "1 4 5 sqrt entropy False 500 42: Macro 0.678769 (0.099708)\n",
      "Testing 1889/4320\n",
      "1 4 8 log2 gini True 50 42: Weighted 0.812400 (0.069591)\n",
      "1 4 8 log2 gini True 50 42: Macro 0.706369 (0.095691)\n",
      "Testing 1890/4320\n",
      "1 4 8 log2 gini True 100 42: Weighted 0.821696 (0.066944)\n",
      "1 4 8 log2 gini True 100 42: Macro 0.725063 (0.089180)\n",
      "Testing 1891/4320\n",
      "1 4 8 log2 gini True 200 42: Weighted 0.816913 (0.064448)\n",
      "1 4 8 log2 gini True 200 42: Macro 0.714921 (0.083125)\n",
      "Testing 1892/4320\n",
      "1 4 8 log2 gini True 500 42: Weighted 0.803722 (0.061157)\n",
      "1 4 8 log2 gini True 500 42: Macro 0.695738 (0.076918)\n",
      "Testing 1893/4320\n",
      "1 4 8 log2 gini False 50 42: Weighted 0.805117 (0.055800)\n",
      "1 4 8 log2 gini False 50 42: Macro 0.703584 (0.072416)\n",
      "Testing 1894/4320\n",
      "1 4 8 log2 gini False 100 42: Weighted 0.792562 (0.059748)\n",
      "1 4 8 log2 gini False 100 42: Macro 0.686017 (0.075912)\n",
      "Testing 1895/4320\n",
      "1 4 8 log2 gini False 200 42: Weighted 0.793498 (0.065922)\n",
      "1 4 8 log2 gini False 200 42: Macro 0.684181 (0.086562)\n",
      "Testing 1896/4320\n",
      "1 4 8 log2 gini False 500 42: Weighted 0.793498 (0.065922)\n",
      "1 4 8 log2 gini False 500 42: Macro 0.684181 (0.086562)\n",
      "Testing 1897/4320\n",
      "1 4 8 log2 entropy True 50 42: Weighted 0.808428 (0.065326)\n",
      "1 4 8 log2 entropy True 50 42: Macro 0.703716 (0.084291)\n",
      "Testing 1898/4320\n",
      "1 4 8 log2 entropy True 100 42: Weighted 0.810343 (0.054832)\n",
      "1 4 8 log2 entropy True 100 42: Macro 0.706440 (0.068020)\n",
      "Testing 1899/4320\n",
      "1 4 8 log2 entropy True 200 42: Weighted 0.810343 (0.054832)\n",
      "1 4 8 log2 entropy True 200 42: Macro 0.706440 (0.068020)\n",
      "Testing 1900/4320\n",
      "1 4 8 log2 entropy True 500 42: Weighted 0.802856 (0.061615)\n",
      "1 4 8 log2 entropy True 500 42: Macro 0.696102 (0.076761)\n",
      "Testing 1901/4320\n",
      "1 4 8 log2 entropy False 50 42: Weighted 0.795656 (0.066602)\n",
      "1 4 8 log2 entropy False 50 42: Macro 0.692375 (0.090524)\n",
      "Testing 1902/4320\n",
      "1 4 8 log2 entropy False 100 42: Weighted 0.790927 (0.072417)\n",
      "1 4 8 log2 entropy False 100 42: Macro 0.681606 (0.105107)\n",
      "Testing 1903/4320\n",
      "1 4 8 log2 entropy False 200 42: Weighted 0.795493 (0.078827)\n",
      "1 4 8 log2 entropy False 200 42: Macro 0.685317 (0.109957)\n",
      "Testing 1904/4320\n",
      "1 4 8 log2 entropy False 500 42: Weighted 0.791070 (0.072614)\n",
      "1 4 8 log2 entropy False 500 42: Macro 0.678356 (0.101004)\n",
      "Testing 1905/4320\n",
      "1 4 8 sqrt gini True 50 42: Weighted 0.812400 (0.069591)\n",
      "1 4 8 sqrt gini True 50 42: Macro 0.706369 (0.095691)\n",
      "Testing 1906/4320\n",
      "1 4 8 sqrt gini True 100 42: Weighted 0.821696 (0.066944)\n",
      "1 4 8 sqrt gini True 100 42: Macro 0.725063 (0.089180)\n",
      "Testing 1907/4320\n",
      "1 4 8 sqrt gini True 200 42: Weighted 0.816913 (0.064448)\n",
      "1 4 8 sqrt gini True 200 42: Macro 0.714921 (0.083125)\n",
      "Testing 1908/4320\n",
      "1 4 8 sqrt gini True 500 42: Weighted 0.803722 (0.061157)\n",
      "1 4 8 sqrt gini True 500 42: Macro 0.695738 (0.076918)\n",
      "Testing 1909/4320\n",
      "1 4 8 sqrt gini False 50 42: Weighted 0.805117 (0.055800)\n",
      "1 4 8 sqrt gini False 50 42: Macro 0.703584 (0.072416)\n",
      "Testing 1910/4320\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 4 8 sqrt gini False 100 42: Weighted 0.792562 (0.059748)\n",
      "1 4 8 sqrt gini False 100 42: Macro 0.686017 (0.075912)\n",
      "Testing 1911/4320\n",
      "1 4 8 sqrt gini False 200 42: Weighted 0.793498 (0.065922)\n",
      "1 4 8 sqrt gini False 200 42: Macro 0.684181 (0.086562)\n",
      "Testing 1912/4320\n",
      "1 4 8 sqrt gini False 500 42: Weighted 0.793498 (0.065922)\n",
      "1 4 8 sqrt gini False 500 42: Macro 0.684181 (0.086562)\n",
      "Testing 1913/4320\n",
      "1 4 8 sqrt entropy True 50 42: Weighted 0.808428 (0.065326)\n",
      "1 4 8 sqrt entropy True 50 42: Macro 0.703716 (0.084291)\n",
      "Testing 1914/4320\n",
      "1 4 8 sqrt entropy True 100 42: Weighted 0.810343 (0.054832)\n",
      "1 4 8 sqrt entropy True 100 42: Macro 0.706440 (0.068020)\n",
      "Testing 1915/4320\n",
      "1 4 8 sqrt entropy True 200 42: Weighted 0.810343 (0.054832)\n",
      "1 4 8 sqrt entropy True 200 42: Macro 0.706440 (0.068020)\n",
      "Testing 1916/4320\n",
      "1 4 8 sqrt entropy True 500 42: Weighted 0.802856 (0.061615)\n",
      "1 4 8 sqrt entropy True 500 42: Macro 0.696102 (0.076761)\n",
      "Testing 1917/4320\n",
      "1 4 8 sqrt entropy False 50 42: Weighted 0.795656 (0.066602)\n",
      "1 4 8 sqrt entropy False 50 42: Macro 0.692375 (0.090524)\n",
      "Testing 1918/4320\n",
      "1 4 8 sqrt entropy False 100 42: Weighted 0.790927 (0.072417)\n",
      "1 4 8 sqrt entropy False 100 42: Macro 0.681606 (0.105107)\n",
      "Testing 1919/4320\n",
      "1 4 8 sqrt entropy False 200 42: Weighted 0.795493 (0.078827)\n",
      "1 4 8 sqrt entropy False 200 42: Macro 0.685317 (0.109957)\n",
      "Testing 1920/4320\n",
      "1 4 8 sqrt entropy False 500 42: Weighted 0.791070 (0.072614)\n",
      "1 4 8 sqrt entropy False 500 42: Macro 0.678356 (0.101004)\n",
      "Testing 1921/4320\n",
      "1 6 3 log2 gini True 50 42: Weighted 0.800597 (0.059190)\n",
      "1 6 3 log2 gini True 50 42: Macro 0.694531 (0.079229)\n",
      "Testing 1922/4320\n",
      "1 6 3 log2 gini True 100 42: Weighted 0.805266 (0.063779)\n",
      "1 6 3 log2 gini True 100 42: Macro 0.701291 (0.084584)\n",
      "Testing 1923/4320\n",
      "1 6 3 log2 gini True 200 42: Weighted 0.809935 (0.060810)\n",
      "1 6 3 log2 gini True 200 42: Macro 0.704820 (0.082311)\n",
      "Testing 1924/4320\n",
      "1 6 3 log2 gini True 500 42: Weighted 0.809014 (0.051630)\n",
      "1 6 3 log2 gini True 500 42: Macro 0.702391 (0.068382)\n",
      "Testing 1925/4320\n",
      "1 6 3 log2 gini False 50 42: Weighted 0.796442 (0.075436)\n",
      "1 6 3 log2 gini False 50 42: Macro 0.692957 (0.095585)\n",
      "Testing 1926/4320\n",
      "1 6 3 log2 gini False 100 42: Weighted 0.796132 (0.065146)\n",
      "1 6 3 log2 gini False 100 42: Macro 0.688569 (0.084134)\n",
      "Testing 1927/4320\n",
      "1 6 3 log2 gini False 200 42: Weighted 0.788859 (0.090750)\n",
      "1 6 3 log2 gini False 200 42: Macro 0.684887 (0.112953)\n",
      "Testing 1928/4320\n",
      "1 6 3 log2 gini False 500 42: Weighted 0.798867 (0.075476)\n",
      "1 6 3 log2 gini False 500 42: Macro 0.697450 (0.093953)\n",
      "Testing 1929/4320\n",
      "1 6 3 log2 entropy True 50 42: Weighted 0.801060 (0.062389)\n",
      "1 6 3 log2 entropy True 50 42: Macro 0.692847 (0.084279)\n",
      "Testing 1930/4320\n",
      "1 6 3 log2 entropy True 100 42: Weighted 0.809935 (0.060810)\n",
      "1 6 3 log2 entropy True 100 42: Macro 0.704820 (0.082311)\n",
      "Testing 1931/4320\n",
      "1 6 3 log2 entropy True 200 42: Weighted 0.809244 (0.065497)\n",
      "1 6 3 log2 entropy True 200 42: Macro 0.704564 (0.087453)\n",
      "Testing 1932/4320\n",
      "1 6 3 log2 entropy True 500 42: Weighted 0.805007 (0.056975)\n",
      "1 6 3 log2 entropy True 500 42: Macro 0.697312 (0.075095)\n",
      "Testing 1933/4320\n",
      "1 6 3 log2 entropy False 50 42: Weighted 0.777448 (0.083265)\n",
      "1 6 3 log2 entropy False 50 42: Macro 0.665820 (0.097952)\n",
      "Testing 1934/4320\n",
      "1 6 3 log2 entropy False 100 42: Weighted 0.798644 (0.070719)\n",
      "1 6 3 log2 entropy False 100 42: Macro 0.693509 (0.086134)\n",
      "Testing 1935/4320\n",
      "1 6 3 log2 entropy False 200 42: Weighted 0.787834 (0.088117)\n",
      "1 6 3 log2 entropy False 200 42: Macro 0.680688 (0.106489)\n",
      "Testing 1936/4320\n",
      "1 6 3 log2 entropy False 500 42: Weighted 0.787834 (0.088117)\n",
      "1 6 3 log2 entropy False 500 42: Macro 0.680688 (0.106489)\n",
      "Testing 1937/4320\n",
      "1 6 3 sqrt gini True 50 42: Weighted 0.800597 (0.059190)\n",
      "1 6 3 sqrt gini True 50 42: Macro 0.694531 (0.079229)\n",
      "Testing 1938/4320\n",
      "1 6 3 sqrt gini True 100 42: Weighted 0.805266 (0.063779)\n",
      "1 6 3 sqrt gini True 100 42: Macro 0.701291 (0.084584)\n",
      "Testing 1939/4320\n",
      "1 6 3 sqrt gini True 200 42: Weighted 0.809935 (0.060810)\n",
      "1 6 3 sqrt gini True 200 42: Macro 0.704820 (0.082311)\n",
      "Testing 1940/4320\n",
      "1 6 3 sqrt gini True 500 42: Weighted 0.809014 (0.051630)\n",
      "1 6 3 sqrt gini True 500 42: Macro 0.702391 (0.068382)\n",
      "Testing 1941/4320\n",
      "1 6 3 sqrt gini False 50 42: Weighted 0.796442 (0.075436)\n",
      "1 6 3 sqrt gini False 50 42: Macro 0.692957 (0.095585)\n",
      "Testing 1942/4320\n",
      "1 6 3 sqrt gini False 100 42: Weighted 0.796132 (0.065146)\n",
      "1 6 3 sqrt gini False 100 42: Macro 0.688569 (0.084134)\n",
      "Testing 1943/4320\n",
      "1 6 3 sqrt gini False 200 42: Weighted 0.788859 (0.090750)\n",
      "1 6 3 sqrt gini False 200 42: Macro 0.684887 (0.112953)\n",
      "Testing 1944/4320\n",
      "1 6 3 sqrt gini False 500 42: Weighted 0.798867 (0.075476)\n",
      "1 6 3 sqrt gini False 500 42: Macro 0.697450 (0.093953)\n",
      "Testing 1945/4320\n",
      "1 6 3 sqrt entropy True 50 42: Weighted 0.801060 (0.062389)\n",
      "1 6 3 sqrt entropy True 50 42: Macro 0.692847 (0.084279)\n",
      "Testing 1946/4320\n",
      "1 6 3 sqrt entropy True 100 42: Weighted 0.809935 (0.060810)\n",
      "1 6 3 sqrt entropy True 100 42: Macro 0.704820 (0.082311)\n",
      "Testing 1947/4320\n",
      "1 6 3 sqrt entropy True 200 42: Weighted 0.809244 (0.065497)\n",
      "1 6 3 sqrt entropy True 200 42: Macro 0.704564 (0.087453)\n",
      "Testing 1948/4320\n",
      "1 6 3 sqrt entropy True 500 42: Weighted 0.805007 (0.056975)\n",
      "1 6 3 sqrt entropy True 500 42: Macro 0.697312 (0.075095)\n",
      "Testing 1949/4320\n",
      "1 6 3 sqrt entropy False 50 42: Weighted 0.777448 (0.083265)\n",
      "1 6 3 sqrt entropy False 50 42: Macro 0.665820 (0.097952)\n",
      "Testing 1950/4320\n",
      "1 6 3 sqrt entropy False 100 42: Weighted 0.798644 (0.070719)\n",
      "1 6 3 sqrt entropy False 100 42: Macro 0.693509 (0.086134)\n",
      "Testing 1951/4320\n",
      "1 6 3 sqrt entropy False 200 42: Weighted 0.787834 (0.088117)\n",
      "1 6 3 sqrt entropy False 200 42: Macro 0.680688 (0.106489)\n",
      "Testing 1952/4320\n",
      "1 6 3 sqrt entropy False 500 42: Weighted 0.787834 (0.088117)\n",
      "1 6 3 sqrt entropy False 500 42: Macro 0.680688 (0.106489)\n",
      "Testing 1953/4320\n",
      "1 6 5 log2 gini True 50 42: Weighted 0.820677 (0.059187)\n",
      "1 6 5 log2 gini True 50 42: Macro 0.726485 (0.073717)\n",
      "Testing 1954/4320\n",
      "1 6 5 log2 gini True 100 42: Weighted 0.816674 (0.064627)\n",
      "1 6 5 log2 gini True 100 42: Macro 0.718015 (0.085470)\n",
      "Testing 1955/4320\n",
      "1 6 5 log2 gini True 200 42: Weighted 0.816674 (0.064627)\n",
      "1 6 5 log2 gini True 200 42: Macro 0.718015 (0.085470)\n",
      "Testing 1956/4320\n",
      "1 6 5 log2 gini True 500 42: Weighted 0.807129 (0.059688)\n",
      "1 6 5 log2 gini True 500 42: Macro 0.700731 (0.075190)\n",
      "Testing 1957/4320\n",
      "1 6 5 log2 gini False 50 42: Weighted 0.800568 (0.072950)\n",
      "1 6 5 log2 gini False 50 42: Macro 0.695463 (0.104283)\n",
      "Testing 1958/4320\n",
      "1 6 5 log2 gini False 100 42: Weighted 0.801513 (0.076481)\n",
      "1 6 5 log2 gini False 100 42: Macro 0.696104 (0.101591)\n",
      "Testing 1959/4320\n",
      "1 6 5 log2 gini False 200 42: Weighted 0.806441 (0.079595)\n",
      "1 6 5 log2 gini False 200 42: Macro 0.703613 (0.107119)\n",
      "Testing 1960/4320\n",
      "1 6 5 log2 gini False 500 42: Weighted 0.803576 (0.073375)\n",
      "1 6 5 log2 gini False 500 42: Macro 0.696618 (0.100788)\n",
      "Testing 1961/4320\n",
      "1 6 5 log2 entropy True 50 42: Weighted 0.809060 (0.072124)\n",
      "1 6 5 log2 entropy True 50 42: Macro 0.707808 (0.095153)\n",
      "Testing 1962/4320\n",
      "1 6 5 log2 entropy True 100 42: Weighted 0.811891 (0.061650)\n",
      "1 6 5 log2 entropy True 100 42: Macro 0.707874 (0.078223)\n",
      "Testing 1963/4320\n",
      "1 6 5 log2 entropy True 200 42: Weighted 0.821047 (0.065875)\n",
      "1 6 5 log2 entropy True 200 42: Macro 0.718434 (0.086014)\n",
      "Testing 1964/4320\n",
      "1 6 5 log2 entropy True 500 42: Weighted 0.811863 (0.058581)\n",
      "1 6 5 log2 entropy True 500 42: Macro 0.704330 (0.074545)\n",
      "Testing 1965/4320\n",
      "1 6 5 log2 entropy False 50 42: Weighted 0.788493 (0.069144)\n",
      "1 6 5 log2 entropy False 50 42: Macro 0.680018 (0.093890)\n",
      "Testing 1966/4320\n",
      "1 6 5 log2 entropy False 100 42: Weighted 0.784219 (0.075598)\n",
      "1 6 5 log2 entropy False 100 42: Macro 0.670300 (0.108965)\n",
      "Testing 1967/4320\n",
      "1 6 5 log2 entropy False 200 42: Weighted 0.788748 (0.081104)\n",
      "1 6 5 log2 entropy False 200 42: Macro 0.673970 (0.113068)\n",
      "Testing 1968/4320\n",
      "1 6 5 log2 entropy False 500 42: Weighted 0.793021 (0.074867)\n",
      "1 6 5 log2 entropy False 500 42: Macro 0.683688 (0.098259)\n",
      "Testing 1969/4320\n",
      "1 6 5 sqrt gini True 50 42: Weighted 0.820677 (0.059187)\n",
      "1 6 5 sqrt gini True 50 42: Macro 0.726485 (0.073717)\n",
      "Testing 1970/4320\n",
      "1 6 5 sqrt gini True 100 42: Weighted 0.816674 (0.064627)\n",
      "1 6 5 sqrt gini True 100 42: Macro 0.718015 (0.085470)\n",
      "Testing 1971/4320\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 6 5 sqrt gini True 200 42: Weighted 0.816674 (0.064627)\n",
      "1 6 5 sqrt gini True 200 42: Macro 0.718015 (0.085470)\n",
      "Testing 1972/4320\n",
      "1 6 5 sqrt gini True 500 42: Weighted 0.807129 (0.059688)\n",
      "1 6 5 sqrt gini True 500 42: Macro 0.700731 (0.075190)\n",
      "Testing 1973/4320\n",
      "1 6 5 sqrt gini False 50 42: Weighted 0.800568 (0.072950)\n",
      "1 6 5 sqrt gini False 50 42: Macro 0.695463 (0.104283)\n",
      "Testing 1974/4320\n",
      "1 6 5 sqrt gini False 100 42: Weighted 0.801513 (0.076481)\n",
      "1 6 5 sqrt gini False 100 42: Macro 0.696104 (0.101591)\n",
      "Testing 1975/4320\n",
      "1 6 5 sqrt gini False 200 42: Weighted 0.806441 (0.079595)\n",
      "1 6 5 sqrt gini False 200 42: Macro 0.703613 (0.107119)\n",
      "Testing 1976/4320\n",
      "1 6 5 sqrt gini False 500 42: Weighted 0.803576 (0.073375)\n",
      "1 6 5 sqrt gini False 500 42: Macro 0.696618 (0.100788)\n",
      "Testing 1977/4320\n",
      "1 6 5 sqrt entropy True 50 42: Weighted 0.809060 (0.072124)\n",
      "1 6 5 sqrt entropy True 50 42: Macro 0.707808 (0.095153)\n",
      "Testing 1978/4320\n",
      "1 6 5 sqrt entropy True 100 42: Weighted 0.811891 (0.061650)\n",
      "1 6 5 sqrt entropy True 100 42: Macro 0.707874 (0.078223)\n",
      "Testing 1979/4320\n",
      "1 6 5 sqrt entropy True 200 42: Weighted 0.821047 (0.065875)\n",
      "1 6 5 sqrt entropy True 200 42: Macro 0.718434 (0.086014)\n",
      "Testing 1980/4320\n",
      "1 6 5 sqrt entropy True 500 42: Weighted 0.811863 (0.058581)\n",
      "1 6 5 sqrt entropy True 500 42: Macro 0.704330 (0.074545)\n",
      "Testing 1981/4320\n",
      "1 6 5 sqrt entropy False 50 42: Weighted 0.788493 (0.069144)\n",
      "1 6 5 sqrt entropy False 50 42: Macro 0.680018 (0.093890)\n",
      "Testing 1982/4320\n",
      "1 6 5 sqrt entropy False 100 42: Weighted 0.784219 (0.075598)\n",
      "1 6 5 sqrt entropy False 100 42: Macro 0.670300 (0.108965)\n",
      "Testing 1983/4320\n",
      "1 6 5 sqrt entropy False 200 42: Weighted 0.788748 (0.081104)\n",
      "1 6 5 sqrt entropy False 200 42: Macro 0.673970 (0.113068)\n",
      "Testing 1984/4320\n",
      "1 6 5 sqrt entropy False 500 42: Weighted 0.793021 (0.074867)\n",
      "1 6 5 sqrt entropy False 500 42: Macro 0.683688 (0.098259)\n",
      "Testing 1985/4320\n",
      "1 6 8 log2 gini True 50 42: Weighted 0.818215 (0.069713)\n",
      "1 6 8 log2 gini True 50 42: Macro 0.720143 (0.092989)\n",
      "Testing 1986/4320\n",
      "1 6 8 log2 gini True 100 42: Weighted 0.820321 (0.062340)\n",
      "1 6 8 log2 gini True 100 42: Macro 0.719915 (0.080345)\n",
      "Testing 1987/4320\n",
      "1 6 8 log2 gini True 200 42: Weighted 0.816314 (0.067508)\n",
      "1 6 8 log2 gini True 200 42: Macro 0.714836 (0.087158)\n",
      "Testing 1988/4320\n",
      "1 6 8 log2 gini True 500 42: Weighted 0.803722 (0.061157)\n",
      "1 6 8 log2 gini True 500 42: Macro 0.695738 (0.076918)\n",
      "Testing 1989/4320\n",
      "1 6 8 log2 gini False 50 42: Weighted 0.805937 (0.066340)\n",
      "1 6 8 log2 gini False 50 42: Macro 0.705698 (0.086752)\n",
      "Testing 1990/4320\n",
      "1 6 8 log2 gini False 100 42: Weighted 0.797082 (0.065998)\n",
      "1 6 8 log2 gini False 100 42: Macro 0.692829 (0.084452)\n",
      "Testing 1991/4320\n",
      "1 6 8 log2 gini False 200 42: Weighted 0.802166 (0.068542)\n",
      "1 6 8 log2 gini False 200 42: Macro 0.700252 (0.088763)\n",
      "Testing 1992/4320\n",
      "1 6 8 log2 gini False 500 42: Weighted 0.798303 (0.073475)\n",
      "1 6 8 log2 gini False 500 42: Macro 0.695466 (0.095583)\n",
      "Testing 1993/4320\n",
      "1 6 8 log2 entropy True 50 42: Weighted 0.803943 (0.066127)\n",
      "1 6 8 log2 entropy True 50 42: Macro 0.700752 (0.084918)\n",
      "Testing 1994/4320\n",
      "1 6 8 log2 entropy True 100 42: Weighted 0.815594 (0.060326)\n",
      "1 6 8 log2 entropy True 100 42: Macro 0.714635 (0.078628)\n",
      "Testing 1995/4320\n",
      "1 6 8 log2 entropy True 200 42: Weighted 0.820162 (0.066106)\n",
      "1 6 8 log2 entropy True 200 42: Macro 0.718964 (0.085882)\n",
      "Testing 1996/4320\n",
      "1 6 8 log2 entropy True 500 42: Weighted 0.810977 (0.058703)\n",
      "1 6 8 log2 entropy True 500 42: Macro 0.704859 (0.074493)\n",
      "Testing 1997/4320\n",
      "1 6 8 log2 entropy False 50 42: Weighted 0.800223 (0.073226)\n",
      "1 6 8 log2 entropy False 50 42: Macro 0.696087 (0.095696)\n",
      "Testing 1998/4320\n",
      "1 6 8 log2 entropy False 100 42: Weighted 0.800223 (0.073226)\n",
      "1 6 8 log2 entropy False 100 42: Macro 0.696087 (0.095696)\n",
      "Testing 1999/4320\n",
      "1 6 8 log2 entropy False 200 42: Weighted 0.799252 (0.064504)\n",
      "1 6 8 log2 entropy False 200 42: Macro 0.697759 (0.088147)\n",
      "Testing 2000/4320\n",
      "1 6 8 log2 entropy False 500 42: Weighted 0.795800 (0.066806)\n",
      "1 6 8 log2 entropy False 500 42: Macro 0.689125 (0.086133)\n",
      "Testing 2001/4320\n",
      "1 6 8 sqrt gini True 50 42: Weighted 0.818215 (0.069713)\n",
      "1 6 8 sqrt gini True 50 42: Macro 0.720143 (0.092989)\n",
      "Testing 2002/4320\n",
      "1 6 8 sqrt gini True 100 42: Weighted 0.820321 (0.062340)\n",
      "1 6 8 sqrt gini True 100 42: Macro 0.719915 (0.080345)\n",
      "Testing 2003/4320\n",
      "1 6 8 sqrt gini True 200 42: Weighted 0.816314 (0.067508)\n",
      "1 6 8 sqrt gini True 200 42: Macro 0.714836 (0.087158)\n",
      "Testing 2004/4320\n",
      "1 6 8 sqrt gini True 500 42: Weighted 0.803722 (0.061157)\n",
      "1 6 8 sqrt gini True 500 42: Macro 0.695738 (0.076918)\n",
      "Testing 2005/4320\n",
      "1 6 8 sqrt gini False 50 42: Weighted 0.805937 (0.066340)\n",
      "1 6 8 sqrt gini False 50 42: Macro 0.705698 (0.086752)\n",
      "Testing 2006/4320\n",
      "1 6 8 sqrt gini False 100 42: Weighted 0.797082 (0.065998)\n",
      "1 6 8 sqrt gini False 100 42: Macro 0.692829 (0.084452)\n",
      "Testing 2007/4320\n",
      "1 6 8 sqrt gini False 200 42: Weighted 0.802166 (0.068542)\n",
      "1 6 8 sqrt gini False 200 42: Macro 0.700252 (0.088763)\n",
      "Testing 2008/4320\n",
      "1 6 8 sqrt gini False 500 42: Weighted 0.798303 (0.073475)\n",
      "1 6 8 sqrt gini False 500 42: Macro 0.695466 (0.095583)\n",
      "Testing 2009/4320\n",
      "1 6 8 sqrt entropy True 50 42: Weighted 0.803943 (0.066127)\n",
      "1 6 8 sqrt entropy True 50 42: Macro 0.700752 (0.084918)\n",
      "Testing 2010/4320\n",
      "1 6 8 sqrt entropy True 100 42: Weighted 0.815594 (0.060326)\n",
      "1 6 8 sqrt entropy True 100 42: Macro 0.714635 (0.078628)\n",
      "Testing 2011/4320\n",
      "1 6 8 sqrt entropy True 200 42: Weighted 0.820162 (0.066106)\n",
      "1 6 8 sqrt entropy True 200 42: Macro 0.718964 (0.085882)\n",
      "Testing 2012/4320\n",
      "1 6 8 sqrt entropy True 500 42: Weighted 0.810977 (0.058703)\n",
      "1 6 8 sqrt entropy True 500 42: Macro 0.704859 (0.074493)\n",
      "Testing 2013/4320\n",
      "1 6 8 sqrt entropy False 50 42: Weighted 0.800223 (0.073226)\n",
      "1 6 8 sqrt entropy False 50 42: Macro 0.696087 (0.095696)\n",
      "Testing 2014/4320\n",
      "1 6 8 sqrt entropy False 100 42: Weighted 0.800223 (0.073226)\n",
      "1 6 8 sqrt entropy False 100 42: Macro 0.696087 (0.095696)\n",
      "Testing 2015/4320\n",
      "1 6 8 sqrt entropy False 200 42: Weighted 0.799252 (0.064504)\n",
      "1 6 8 sqrt entropy False 200 42: Macro 0.697759 (0.088147)\n",
      "Testing 2016/4320\n",
      "1 6 8 sqrt entropy False 500 42: Weighted 0.795800 (0.066806)\n",
      "1 6 8 sqrt entropy False 500 42: Macro 0.689125 (0.086133)\n",
      "Testing 2017/4320\n",
      "3 2 3 log2 gini True 50 42: Weighted 0.805267 (0.056365)\n",
      "3 2 3 log2 gini True 50 42: Macro 0.698061 (0.077107)\n",
      "Testing 2018/4320\n",
      "3 2 3 log2 gini True 100 42: Weighted 0.809935 (0.060810)\n",
      "3 2 3 log2 gini True 100 42: Macro 0.704820 (0.082311)\n",
      "Testing 2019/4320\n",
      "3 2 3 log2 gini True 200 42: Weighted 0.809935 (0.060810)\n",
      "3 2 3 log2 gini True 200 42: Macro 0.704820 (0.082311)\n",
      "Testing 2020/4320\n",
      "3 2 3 log2 gini True 500 42: Weighted 0.809014 (0.051630)\n",
      "3 2 3 log2 gini True 500 42: Macro 0.702391 (0.068382)\n",
      "Testing 2021/4320\n",
      "3 2 3 log2 gini False 50 42: Weighted 0.801111 (0.073505)\n",
      "3 2 3 log2 gini False 50 42: Macro 0.696487 (0.093893)\n",
      "Testing 2022/4320\n",
      "3 2 3 log2 gini False 100 42: Weighted 0.800801 (0.062924)\n",
      "3 2 3 log2 gini False 100 42: Macro 0.692099 (0.082395)\n",
      "Testing 2023/4320\n",
      "3 2 3 log2 gini False 200 42: Weighted 0.793563 (0.090270)\n",
      "3 2 3 log2 gini False 200 42: Macro 0.688455 (0.112395)\n",
      "Testing 2024/4320\n",
      "3 2 3 log2 gini False 500 42: Weighted 0.803571 (0.074267)\n",
      "3 2 3 log2 gini False 500 42: Macro 0.701017 (0.092801)\n",
      "Testing 2025/4320\n",
      "3 2 3 log2 entropy True 50 42: Weighted 0.804576 (0.061340)\n",
      "3 2 3 log2 entropy True 50 42: Macro 0.697805 (0.082553)\n",
      "Testing 2026/4320\n",
      "3 2 3 log2 entropy True 100 42: Weighted 0.809935 (0.060810)\n",
      "3 2 3 log2 entropy True 100 42: Macro 0.704820 (0.082311)\n",
      "Testing 2027/4320\n",
      "3 2 3 log2 entropy True 200 42: Weighted 0.805728 (0.066727)\n",
      "3 2 3 log2 entropy True 200 42: Macro 0.699607 (0.089460)\n",
      "Testing 2028/4320\n",
      "3 2 3 log2 entropy True 500 42: Weighted 0.805007 (0.056975)\n",
      "3 2 3 log2 entropy True 500 42: Macro 0.697312 (0.075095)\n",
      "Testing 2029/4320\n",
      "3 2 3 log2 entropy False 50 42: Weighted 0.777448 (0.083265)\n",
      "3 2 3 log2 entropy False 50 42: Macro 0.665820 (0.097952)\n",
      "Testing 2030/4320\n",
      "3 2 3 log2 entropy False 100 42: Weighted 0.798644 (0.070719)\n",
      "3 2 3 log2 entropy False 100 42: Macro 0.693509 (0.086134)\n",
      "Testing 2031/4320\n",
      "3 2 3 log2 entropy False 200 42: Weighted 0.787834 (0.088117)\n",
      "3 2 3 log2 entropy False 200 42: Macro 0.680688 (0.106489)\n",
      "Testing 2032/4320\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 2 3 log2 entropy False 500 42: Weighted 0.787834 (0.088117)\n",
      "3 2 3 log2 entropy False 500 42: Macro 0.680688 (0.106489)\n",
      "Testing 2033/4320\n",
      "3 2 3 sqrt gini True 50 42: Weighted 0.805267 (0.056365)\n",
      "3 2 3 sqrt gini True 50 42: Macro 0.698061 (0.077107)\n",
      "Testing 2034/4320\n",
      "3 2 3 sqrt gini True 100 42: Weighted 0.809935 (0.060810)\n",
      "3 2 3 sqrt gini True 100 42: Macro 0.704820 (0.082311)\n",
      "Testing 2035/4320\n",
      "3 2 3 sqrt gini True 200 42: Weighted 0.809935 (0.060810)\n",
      "3 2 3 sqrt gini True 200 42: Macro 0.704820 (0.082311)\n",
      "Testing 2036/4320\n",
      "3 2 3 sqrt gini True 500 42: Weighted 0.809014 (0.051630)\n",
      "3 2 3 sqrt gini True 500 42: Macro 0.702391 (0.068382)\n",
      "Testing 2037/4320\n",
      "3 2 3 sqrt gini False 50 42: Weighted 0.801111 (0.073505)\n",
      "3 2 3 sqrt gini False 50 42: Macro 0.696487 (0.093893)\n",
      "Testing 2038/4320\n",
      "3 2 3 sqrt gini False 100 42: Weighted 0.800801 (0.062924)\n",
      "3 2 3 sqrt gini False 100 42: Macro 0.692099 (0.082395)\n",
      "Testing 2039/4320\n",
      "3 2 3 sqrt gini False 200 42: Weighted 0.793563 (0.090270)\n",
      "3 2 3 sqrt gini False 200 42: Macro 0.688455 (0.112395)\n",
      "Testing 2040/4320\n",
      "3 2 3 sqrt gini False 500 42: Weighted 0.803571 (0.074267)\n",
      "3 2 3 sqrt gini False 500 42: Macro 0.701017 (0.092801)\n",
      "Testing 2041/4320\n",
      "3 2 3 sqrt entropy True 50 42: Weighted 0.804576 (0.061340)\n",
      "3 2 3 sqrt entropy True 50 42: Macro 0.697805 (0.082553)\n",
      "Testing 2042/4320\n",
      "3 2 3 sqrt entropy True 100 42: Weighted 0.809935 (0.060810)\n",
      "3 2 3 sqrt entropy True 100 42: Macro 0.704820 (0.082311)\n",
      "Testing 2043/4320\n",
      "3 2 3 sqrt entropy True 200 42: Weighted 0.805728 (0.066727)\n",
      "3 2 3 sqrt entropy True 200 42: Macro 0.699607 (0.089460)\n",
      "Testing 2044/4320\n",
      "3 2 3 sqrt entropy True 500 42: Weighted 0.805007 (0.056975)\n",
      "3 2 3 sqrt entropy True 500 42: Macro 0.697312 (0.075095)\n",
      "Testing 2045/4320\n",
      "3 2 3 sqrt entropy False 50 42: Weighted 0.777448 (0.083265)\n",
      "3 2 3 sqrt entropy False 50 42: Macro 0.665820 (0.097952)\n",
      "Testing 2046/4320\n",
      "3 2 3 sqrt entropy False 100 42: Weighted 0.798644 (0.070719)\n",
      "3 2 3 sqrt entropy False 100 42: Macro 0.693509 (0.086134)\n",
      "Testing 2047/4320\n",
      "3 2 3 sqrt entropy False 200 42: Weighted 0.787834 (0.088117)\n",
      "3 2 3 sqrt entropy False 200 42: Macro 0.680688 (0.106489)\n",
      "Testing 2048/4320\n",
      "3 2 3 sqrt entropy False 500 42: Weighted 0.787834 (0.088117)\n",
      "3 2 3 sqrt entropy False 500 42: Macro 0.680688 (0.106489)\n",
      "Testing 2049/4320\n",
      "3 2 5 log2 gini True 50 42: Weighted 0.821974 (0.058470)\n",
      "3 2 5 log2 gini True 50 42: Macro 0.725060 (0.074615)\n",
      "Testing 2050/4320\n",
      "3 2 5 log2 gini True 100 42: Weighted 0.813188 (0.061148)\n",
      "3 2 5 log2 gini True 100 42: Macro 0.706448 (0.078733)\n",
      "Testing 2051/4320\n",
      "3 2 5 log2 gini True 200 42: Weighted 0.813188 (0.061148)\n",
      "3 2 5 log2 gini True 200 42: Macro 0.706448 (0.078733)\n",
      "Testing 2052/4320\n",
      "3 2 5 log2 gini True 500 42: Weighted 0.808426 (0.059274)\n",
      "3 2 5 log2 gini True 500 42: Macro 0.699306 (0.075587)\n",
      "Testing 2053/4320\n",
      "3 2 5 log2 gini False 50 42: Weighted 0.813237 (0.075536)\n",
      "3 2 5 log2 gini False 50 42: Macro 0.707725 (0.105751)\n",
      "Testing 2054/4320\n",
      "3 2 5 log2 gini False 100 42: Weighted 0.808309 (0.072708)\n",
      "3 2 5 log2 gini False 100 42: Macro 0.700217 (0.100455)\n",
      "Testing 2055/4320\n",
      "3 2 5 log2 gini False 200 42: Weighted 0.813237 (0.075536)\n",
      "3 2 5 log2 gini False 200 42: Macro 0.707725 (0.105751)\n",
      "Testing 2056/4320\n",
      "3 2 5 log2 gini False 500 42: Weighted 0.803576 (0.073375)\n",
      "3 2 5 log2 gini False 500 42: Macro 0.696618 (0.100788)\n",
      "Testing 2057/4320\n",
      "3 2 5 log2 entropy True 50 42: Weighted 0.814455 (0.065778)\n",
      "3 2 5 log2 entropy True 50 42: Macro 0.711632 (0.088816)\n",
      "Testing 2058/4320\n",
      "3 2 5 log2 entropy True 100 42: Weighted 0.816624 (0.060205)\n",
      "3 2 5 log2 entropy True 100 42: Macro 0.711473 (0.077270)\n",
      "Testing 2059/4320\n",
      "3 2 5 log2 entropy True 200 42: Weighted 0.816624 (0.060205)\n",
      "3 2 5 log2 entropy True 200 42: Macro 0.711473 (0.077270)\n",
      "Testing 2060/4320\n",
      "3 2 5 log2 entropy True 500 42: Weighted 0.811863 (0.058581)\n",
      "3 2 5 log2 entropy True 500 42: Macro 0.704330 (0.074545)\n",
      "Testing 2061/4320\n",
      "3 2 5 log2 entropy False 50 42: Weighted 0.799089 (0.077218)\n",
      "3 2 5 log2 entropy False 50 42: Macro 0.683466 (0.111662)\n",
      "Testing 2062/4320\n",
      "3 2 5 log2 entropy False 100 42: Weighted 0.793453 (0.080572)\n",
      "3 2 5 log2 entropy False 100 42: Macro 0.677538 (0.112856)\n",
      "Testing 2063/4320\n",
      "3 2 5 log2 entropy False 200 42: Weighted 0.795653 (0.077179)\n",
      "3 2 5 log2 entropy False 200 42: Macro 0.678441 (0.111424)\n",
      "Testing 2064/4320\n",
      "3 2 5 log2 entropy False 500 42: Weighted 0.795653 (0.077179)\n",
      "3 2 5 log2 entropy False 500 42: Macro 0.678441 (0.111424)\n",
      "Testing 2065/4320\n",
      "3 2 5 sqrt gini True 50 42: Weighted 0.821974 (0.058470)\n",
      "3 2 5 sqrt gini True 50 42: Macro 0.725060 (0.074615)\n",
      "Testing 2066/4320\n",
      "3 2 5 sqrt gini True 100 42: Weighted 0.813188 (0.061148)\n",
      "3 2 5 sqrt gini True 100 42: Macro 0.706448 (0.078733)\n",
      "Testing 2067/4320\n",
      "3 2 5 sqrt gini True 200 42: Weighted 0.813188 (0.061148)\n",
      "3 2 5 sqrt gini True 200 42: Macro 0.706448 (0.078733)\n",
      "Testing 2068/4320\n",
      "3 2 5 sqrt gini True 500 42: Weighted 0.808426 (0.059274)\n",
      "3 2 5 sqrt gini True 500 42: Macro 0.699306 (0.075587)\n",
      "Testing 2069/4320\n",
      "3 2 5 sqrt gini False 50 42: Weighted 0.813237 (0.075536)\n",
      "3 2 5 sqrt gini False 50 42: Macro 0.707725 (0.105751)\n",
      "Testing 2070/4320\n",
      "3 2 5 sqrt gini False 100 42: Weighted 0.808309 (0.072708)\n",
      "3 2 5 sqrt gini False 100 42: Macro 0.700217 (0.100455)\n",
      "Testing 2071/4320\n",
      "3 2 5 sqrt gini False 200 42: Weighted 0.813237 (0.075536)\n",
      "3 2 5 sqrt gini False 200 42: Macro 0.707725 (0.105751)\n",
      "Testing 2072/4320\n",
      "3 2 5 sqrt gini False 500 42: Weighted 0.803576 (0.073375)\n",
      "3 2 5 sqrt gini False 500 42: Macro 0.696618 (0.100788)\n",
      "Testing 2073/4320\n",
      "3 2 5 sqrt entropy True 50 42: Weighted 0.814455 (0.065778)\n",
      "3 2 5 sqrt entropy True 50 42: Macro 0.711632 (0.088816)\n",
      "Testing 2074/4320\n",
      "3 2 5 sqrt entropy True 100 42: Weighted 0.816624 (0.060205)\n",
      "3 2 5 sqrt entropy True 100 42: Macro 0.711473 (0.077270)\n",
      "Testing 2075/4320\n",
      "3 2 5 sqrt entropy True 200 42: Weighted 0.816624 (0.060205)\n",
      "3 2 5 sqrt entropy True 200 42: Macro 0.711473 (0.077270)\n",
      "Testing 2076/4320\n",
      "3 2 5 sqrt entropy True 500 42: Weighted 0.811863 (0.058581)\n",
      "3 2 5 sqrt entropy True 500 42: Macro 0.704330 (0.074545)\n",
      "Testing 2077/4320\n",
      "3 2 5 sqrt entropy False 50 42: Weighted 0.799089 (0.077218)\n",
      "3 2 5 sqrt entropy False 50 42: Macro 0.683466 (0.111662)\n",
      "Testing 2078/4320\n",
      "3 2 5 sqrt entropy False 100 42: Weighted 0.793453 (0.080572)\n",
      "3 2 5 sqrt entropy False 100 42: Macro 0.677538 (0.112856)\n",
      "Testing 2079/4320\n",
      "3 2 5 sqrt entropy False 200 42: Weighted 0.795653 (0.077179)\n",
      "3 2 5 sqrt entropy False 200 42: Macro 0.678441 (0.111424)\n",
      "Testing 2080/4320\n",
      "3 2 5 sqrt entropy False 500 42: Weighted 0.795653 (0.077179)\n",
      "3 2 5 sqrt entropy False 500 42: Macro 0.678441 (0.111424)\n",
      "Testing 2081/4320\n",
      "3 2 8 log2 gini True 50 42: Weighted 0.818551 (0.071564)\n",
      "3 2 8 log2 gini True 50 42: Macro 0.714195 (0.102275)\n",
      "Testing 2082/4320\n",
      "3 2 8 log2 gini True 100 42: Weighted 0.816235 (0.056083)\n",
      "3 2 8 log2 gini True 100 42: Macro 0.711790 (0.071586)\n",
      "Testing 2083/4320\n",
      "3 2 8 log2 gini True 200 42: Weighted 0.816652 (0.067360)\n",
      "3 2 8 log2 gini True 200 42: Macro 0.713673 (0.087620)\n",
      "Testing 2084/4320\n",
      "3 2 8 log2 gini True 500 42: Weighted 0.811473 (0.054301)\n",
      "3 2 8 log2 gini True 500 42: Macro 0.704647 (0.068668)\n",
      "Testing 2085/4320\n",
      "3 2 8 log2 gini False 50 42: Weighted 0.792312 (0.064620)\n",
      "3 2 8 log2 gini False 50 42: Macro 0.680466 (0.081378)\n",
      "Testing 2086/4320\n",
      "3 2 8 log2 gini False 100 42: Weighted 0.792696 (0.064414)\n",
      "3 2 8 log2 gini False 100 42: Macro 0.674587 (0.083489)\n",
      "Testing 2087/4320\n",
      "3 2 8 log2 gini False 200 42: Weighted 0.804539 (0.065853)\n",
      "3 2 8 log2 gini False 200 42: Macro 0.694675 (0.091588)\n",
      "Testing 2088/4320\n",
      "3 2 8 log2 gini False 500 42: Weighted 0.808191 (0.063573)\n",
      "3 2 8 log2 gini False 500 42: Macro 0.699781 (0.088708)\n",
      "Testing 2089/4320\n",
      "3 2 8 log2 entropy True 50 42: Weighted 0.814455 (0.065778)\n",
      "3 2 8 log2 entropy True 50 42: Macro 0.711632 (0.088816)\n",
      "Testing 2090/4320\n",
      "3 2 8 log2 entropy True 100 42: Weighted 0.810977 (0.058703)\n",
      "3 2 8 log2 entropy True 100 42: Macro 0.704859 (0.074493)\n",
      "Testing 2091/4320\n",
      "3 2 8 log2 entropy True 200 42: Weighted 0.816652 (0.067360)\n",
      "3 2 8 log2 entropy True 200 42: Macro 0.713673 (0.087620)\n",
      "Testing 2092/4320\n",
      "3 2 8 log2 entropy True 500 42: Weighted 0.807467 (0.059573)\n",
      "3 2 8 log2 entropy True 500 42: Macro 0.699568 (0.075508)\n",
      "Testing 2093/4320\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 2 8 log2 entropy False 50 42: Weighted 0.799951 (0.069875)\n",
      "3 2 8 log2 entropy False 50 42: Macro 0.690788 (0.092253)\n",
      "Testing 2094/4320\n",
      "3 2 8 log2 entropy False 100 42: Weighted 0.797466 (0.065768)\n",
      "3 2 8 log2 entropy False 100 42: Macro 0.686951 (0.087324)\n",
      "Testing 2095/4320\n",
      "3 2 8 log2 entropy False 200 42: Weighted 0.801119 (0.063891)\n",
      "3 2 8 log2 entropy False 200 42: Macro 0.692057 (0.084765)\n",
      "Testing 2096/4320\n",
      "3 2 8 log2 entropy False 500 42: Weighted 0.804684 (0.062624)\n",
      "3 2 8 log2 entropy False 500 42: Macro 0.697221 (0.083059)\n",
      "Testing 2097/4320\n",
      "3 2 8 sqrt gini True 50 42: Weighted 0.818551 (0.071564)\n",
      "3 2 8 sqrt gini True 50 42: Macro 0.714195 (0.102275)\n",
      "Testing 2098/4320\n",
      "3 2 8 sqrt gini True 100 42: Weighted 0.816235 (0.056083)\n",
      "3 2 8 sqrt gini True 100 42: Macro 0.711790 (0.071586)\n",
      "Testing 2099/4320\n",
      "3 2 8 sqrt gini True 200 42: Weighted 0.816652 (0.067360)\n",
      "3 2 8 sqrt gini True 200 42: Macro 0.713673 (0.087620)\n",
      "Testing 2100/4320\n",
      "3 2 8 sqrt gini True 500 42: Weighted 0.811473 (0.054301)\n",
      "3 2 8 sqrt gini True 500 42: Macro 0.704647 (0.068668)\n",
      "Testing 2101/4320\n",
      "3 2 8 sqrt gini False 50 42: Weighted 0.792312 (0.064620)\n",
      "3 2 8 sqrt gini False 50 42: Macro 0.680466 (0.081378)\n",
      "Testing 2102/4320\n",
      "3 2 8 sqrt gini False 100 42: Weighted 0.792696 (0.064414)\n",
      "3 2 8 sqrt gini False 100 42: Macro 0.674587 (0.083489)\n",
      "Testing 2103/4320\n",
      "3 2 8 sqrt gini False 200 42: Weighted 0.804539 (0.065853)\n",
      "3 2 8 sqrt gini False 200 42: Macro 0.694675 (0.091588)\n",
      "Testing 2104/4320\n",
      "3 2 8 sqrt gini False 500 42: Weighted 0.808191 (0.063573)\n",
      "3 2 8 sqrt gini False 500 42: Macro 0.699781 (0.088708)\n",
      "Testing 2105/4320\n",
      "3 2 8 sqrt entropy True 50 42: Weighted 0.814455 (0.065778)\n",
      "3 2 8 sqrt entropy True 50 42: Macro 0.711632 (0.088816)\n",
      "Testing 2106/4320\n",
      "3 2 8 sqrt entropy True 100 42: Weighted 0.810977 (0.058703)\n",
      "3 2 8 sqrt entropy True 100 42: Macro 0.704859 (0.074493)\n",
      "Testing 2107/4320\n",
      "3 2 8 sqrt entropy True 200 42: Weighted 0.816652 (0.067360)\n",
      "3 2 8 sqrt entropy True 200 42: Macro 0.713673 (0.087620)\n",
      "Testing 2108/4320\n",
      "3 2 8 sqrt entropy True 500 42: Weighted 0.807467 (0.059573)\n",
      "3 2 8 sqrt entropy True 500 42: Macro 0.699568 (0.075508)\n",
      "Testing 2109/4320\n",
      "3 2 8 sqrt entropy False 50 42: Weighted 0.799951 (0.069875)\n",
      "3 2 8 sqrt entropy False 50 42: Macro 0.690788 (0.092253)\n",
      "Testing 2110/4320\n",
      "3 2 8 sqrt entropy False 100 42: Weighted 0.797466 (0.065768)\n",
      "3 2 8 sqrt entropy False 100 42: Macro 0.686951 (0.087324)\n",
      "Testing 2111/4320\n",
      "3 2 8 sqrt entropy False 200 42: Weighted 0.801119 (0.063891)\n",
      "3 2 8 sqrt entropy False 200 42: Macro 0.692057 (0.084765)\n",
      "Testing 2112/4320\n",
      "3 2 8 sqrt entropy False 500 42: Weighted 0.804684 (0.062624)\n",
      "3 2 8 sqrt entropy False 500 42: Macro 0.697221 (0.083059)\n",
      "Testing 2113/4320\n",
      "3 4 3 log2 gini True 50 42: Weighted 0.805267 (0.056365)\n",
      "3 4 3 log2 gini True 50 42: Macro 0.698061 (0.077107)\n",
      "Testing 2114/4320\n",
      "3 4 3 log2 gini True 100 42: Weighted 0.809935 (0.060810)\n",
      "3 4 3 log2 gini True 100 42: Macro 0.704820 (0.082311)\n",
      "Testing 2115/4320\n",
      "3 4 3 log2 gini True 200 42: Weighted 0.809935 (0.060810)\n",
      "3 4 3 log2 gini True 200 42: Macro 0.704820 (0.082311)\n",
      "Testing 2116/4320\n",
      "3 4 3 log2 gini True 500 42: Weighted 0.809014 (0.051630)\n",
      "3 4 3 log2 gini True 500 42: Macro 0.702391 (0.068382)\n",
      "Testing 2117/4320\n",
      "3 4 3 log2 gini False 50 42: Weighted 0.801111 (0.073505)\n",
      "3 4 3 log2 gini False 50 42: Macro 0.696487 (0.093893)\n",
      "Testing 2118/4320\n",
      "3 4 3 log2 gini False 100 42: Weighted 0.800801 (0.062924)\n",
      "3 4 3 log2 gini False 100 42: Macro 0.692099 (0.082395)\n",
      "Testing 2119/4320\n",
      "3 4 3 log2 gini False 200 42: Weighted 0.793563 (0.090270)\n",
      "3 4 3 log2 gini False 200 42: Macro 0.688455 (0.112395)\n",
      "Testing 2120/4320\n",
      "3 4 3 log2 gini False 500 42: Weighted 0.803571 (0.074267)\n",
      "3 4 3 log2 gini False 500 42: Macro 0.701017 (0.092801)\n",
      "Testing 2121/4320\n",
      "3 4 3 log2 entropy True 50 42: Weighted 0.804576 (0.061340)\n",
      "3 4 3 log2 entropy True 50 42: Macro 0.697805 (0.082553)\n",
      "Testing 2122/4320\n",
      "3 4 3 log2 entropy True 100 42: Weighted 0.809935 (0.060810)\n",
      "3 4 3 log2 entropy True 100 42: Macro 0.704820 (0.082311)\n",
      "Testing 2123/4320\n",
      "3 4 3 log2 entropy True 200 42: Weighted 0.805728 (0.066727)\n",
      "3 4 3 log2 entropy True 200 42: Macro 0.699607 (0.089460)\n",
      "Testing 2124/4320\n",
      "3 4 3 log2 entropy True 500 42: Weighted 0.805007 (0.056975)\n",
      "3 4 3 log2 entropy True 500 42: Macro 0.697312 (0.075095)\n",
      "Testing 2125/4320\n",
      "3 4 3 log2 entropy False 50 42: Weighted 0.777448 (0.083265)\n",
      "3 4 3 log2 entropy False 50 42: Macro 0.665820 (0.097952)\n",
      "Testing 2126/4320\n",
      "3 4 3 log2 entropy False 100 42: Weighted 0.798644 (0.070719)\n",
      "3 4 3 log2 entropy False 100 42: Macro 0.693509 (0.086134)\n",
      "Testing 2127/4320\n",
      "3 4 3 log2 entropy False 200 42: Weighted 0.787834 (0.088117)\n",
      "3 4 3 log2 entropy False 200 42: Macro 0.680688 (0.106489)\n",
      "Testing 2128/4320\n",
      "3 4 3 log2 entropy False 500 42: Weighted 0.787834 (0.088117)\n",
      "3 4 3 log2 entropy False 500 42: Macro 0.680688 (0.106489)\n",
      "Testing 2129/4320\n",
      "3 4 3 sqrt gini True 50 42: Weighted 0.805267 (0.056365)\n",
      "3 4 3 sqrt gini True 50 42: Macro 0.698061 (0.077107)\n",
      "Testing 2130/4320\n",
      "3 4 3 sqrt gini True 100 42: Weighted 0.809935 (0.060810)\n",
      "3 4 3 sqrt gini True 100 42: Macro 0.704820 (0.082311)\n",
      "Testing 2131/4320\n",
      "3 4 3 sqrt gini True 200 42: Weighted 0.809935 (0.060810)\n",
      "3 4 3 sqrt gini True 200 42: Macro 0.704820 (0.082311)\n",
      "Testing 2132/4320\n",
      "3 4 3 sqrt gini True 500 42: Weighted 0.809014 (0.051630)\n",
      "3 4 3 sqrt gini True 500 42: Macro 0.702391 (0.068382)\n",
      "Testing 2133/4320\n",
      "3 4 3 sqrt gini False 50 42: Weighted 0.801111 (0.073505)\n",
      "3 4 3 sqrt gini False 50 42: Macro 0.696487 (0.093893)\n",
      "Testing 2134/4320\n",
      "3 4 3 sqrt gini False 100 42: Weighted 0.800801 (0.062924)\n",
      "3 4 3 sqrt gini False 100 42: Macro 0.692099 (0.082395)\n",
      "Testing 2135/4320\n",
      "3 4 3 sqrt gini False 200 42: Weighted 0.793563 (0.090270)\n",
      "3 4 3 sqrt gini False 200 42: Macro 0.688455 (0.112395)\n",
      "Testing 2136/4320\n",
      "3 4 3 sqrt gini False 500 42: Weighted 0.803571 (0.074267)\n",
      "3 4 3 sqrt gini False 500 42: Macro 0.701017 (0.092801)\n",
      "Testing 2137/4320\n",
      "3 4 3 sqrt entropy True 50 42: Weighted 0.804576 (0.061340)\n",
      "3 4 3 sqrt entropy True 50 42: Macro 0.697805 (0.082553)\n",
      "Testing 2138/4320\n",
      "3 4 3 sqrt entropy True 100 42: Weighted 0.809935 (0.060810)\n",
      "3 4 3 sqrt entropy True 100 42: Macro 0.704820 (0.082311)\n",
      "Testing 2139/4320\n",
      "3 4 3 sqrt entropy True 200 42: Weighted 0.805728 (0.066727)\n",
      "3 4 3 sqrt entropy True 200 42: Macro 0.699607 (0.089460)\n",
      "Testing 2140/4320\n",
      "3 4 3 sqrt entropy True 500 42: Weighted 0.805007 (0.056975)\n",
      "3 4 3 sqrt entropy True 500 42: Macro 0.697312 (0.075095)\n",
      "Testing 2141/4320\n",
      "3 4 3 sqrt entropy False 50 42: Weighted 0.777448 (0.083265)\n",
      "3 4 3 sqrt entropy False 50 42: Macro 0.665820 (0.097952)\n",
      "Testing 2142/4320\n",
      "3 4 3 sqrt entropy False 100 42: Weighted 0.798644 (0.070719)\n",
      "3 4 3 sqrt entropy False 100 42: Macro 0.693509 (0.086134)\n",
      "Testing 2143/4320\n",
      "3 4 3 sqrt entropy False 200 42: Weighted 0.787834 (0.088117)\n",
      "3 4 3 sqrt entropy False 200 42: Macro 0.680688 (0.106489)\n",
      "Testing 2144/4320\n",
      "3 4 3 sqrt entropy False 500 42: Weighted 0.787834 (0.088117)\n",
      "3 4 3 sqrt entropy False 500 42: Macro 0.680688 (0.106489)\n",
      "Testing 2145/4320\n",
      "3 4 5 log2 gini True 50 42: Weighted 0.821974 (0.058470)\n",
      "3 4 5 log2 gini True 50 42: Macro 0.725060 (0.074615)\n",
      "Testing 2146/4320\n",
      "3 4 5 log2 gini True 100 42: Weighted 0.813188 (0.061148)\n",
      "3 4 5 log2 gini True 100 42: Macro 0.706448 (0.078733)\n",
      "Testing 2147/4320\n",
      "3 4 5 log2 gini True 200 42: Weighted 0.813188 (0.061148)\n",
      "3 4 5 log2 gini True 200 42: Macro 0.706448 (0.078733)\n",
      "Testing 2148/4320\n",
      "3 4 5 log2 gini True 500 42: Weighted 0.808426 (0.059274)\n",
      "3 4 5 log2 gini True 500 42: Macro 0.699306 (0.075587)\n",
      "Testing 2149/4320\n",
      "3 4 5 log2 gini False 50 42: Weighted 0.813237 (0.075536)\n",
      "3 4 5 log2 gini False 50 42: Macro 0.707725 (0.105751)\n",
      "Testing 2150/4320\n",
      "3 4 5 log2 gini False 100 42: Weighted 0.808309 (0.072708)\n",
      "3 4 5 log2 gini False 100 42: Macro 0.700217 (0.100455)\n",
      "Testing 2151/4320\n",
      "3 4 5 log2 gini False 200 42: Weighted 0.813237 (0.075536)\n",
      "3 4 5 log2 gini False 200 42: Macro 0.707725 (0.105751)\n",
      "Testing 2152/4320\n",
      "3 4 5 log2 gini False 500 42: Weighted 0.803576 (0.073375)\n",
      "3 4 5 log2 gini False 500 42: Macro 0.696618 (0.100788)\n",
      "Testing 2153/4320\n",
      "3 4 5 log2 entropy True 50 42: Weighted 0.814455 (0.065778)\n",
      "3 4 5 log2 entropy True 50 42: Macro 0.711632 (0.088816)\n",
      "Testing 2154/4320\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 4 5 log2 entropy True 100 42: Weighted 0.816624 (0.060205)\n",
      "3 4 5 log2 entropy True 100 42: Macro 0.711473 (0.077270)\n",
      "Testing 2155/4320\n",
      "3 4 5 log2 entropy True 200 42: Weighted 0.816624 (0.060205)\n",
      "3 4 5 log2 entropy True 200 42: Macro 0.711473 (0.077270)\n",
      "Testing 2156/4320\n",
      "3 4 5 log2 entropy True 500 42: Weighted 0.811863 (0.058581)\n",
      "3 4 5 log2 entropy True 500 42: Macro 0.704330 (0.074545)\n",
      "Testing 2157/4320\n",
      "3 4 5 log2 entropy False 50 42: Weighted 0.799089 (0.077218)\n",
      "3 4 5 log2 entropy False 50 42: Macro 0.683466 (0.111662)\n",
      "Testing 2158/4320\n",
      "3 4 5 log2 entropy False 100 42: Weighted 0.793453 (0.080572)\n",
      "3 4 5 log2 entropy False 100 42: Macro 0.677538 (0.112856)\n",
      "Testing 2159/4320\n",
      "3 4 5 log2 entropy False 200 42: Weighted 0.795653 (0.077179)\n",
      "3 4 5 log2 entropy False 200 42: Macro 0.678441 (0.111424)\n",
      "Testing 2160/4320\n",
      "3 4 5 log2 entropy False 500 42: Weighted 0.795653 (0.077179)\n",
      "3 4 5 log2 entropy False 500 42: Macro 0.678441 (0.111424)\n",
      "Testing 2161/4320\n",
      "3 4 5 sqrt gini True 50 42: Weighted 0.821974 (0.058470)\n",
      "3 4 5 sqrt gini True 50 42: Macro 0.725060 (0.074615)\n",
      "Testing 2162/4320\n",
      "3 4 5 sqrt gini True 100 42: Weighted 0.813188 (0.061148)\n",
      "3 4 5 sqrt gini True 100 42: Macro 0.706448 (0.078733)\n",
      "Testing 2163/4320\n",
      "3 4 5 sqrt gini True 200 42: Weighted 0.813188 (0.061148)\n",
      "3 4 5 sqrt gini True 200 42: Macro 0.706448 (0.078733)\n",
      "Testing 2164/4320\n",
      "3 4 5 sqrt gini True 500 42: Weighted 0.808426 (0.059274)\n",
      "3 4 5 sqrt gini True 500 42: Macro 0.699306 (0.075587)\n",
      "Testing 2165/4320\n",
      "3 4 5 sqrt gini False 50 42: Weighted 0.813237 (0.075536)\n",
      "3 4 5 sqrt gini False 50 42: Macro 0.707725 (0.105751)\n",
      "Testing 2166/4320\n",
      "3 4 5 sqrt gini False 100 42: Weighted 0.808309 (0.072708)\n",
      "3 4 5 sqrt gini False 100 42: Macro 0.700217 (0.100455)\n",
      "Testing 2167/4320\n",
      "3 4 5 sqrt gini False 200 42: Weighted 0.813237 (0.075536)\n",
      "3 4 5 sqrt gini False 200 42: Macro 0.707725 (0.105751)\n",
      "Testing 2168/4320\n",
      "3 4 5 sqrt gini False 500 42: Weighted 0.803576 (0.073375)\n",
      "3 4 5 sqrt gini False 500 42: Macro 0.696618 (0.100788)\n",
      "Testing 2169/4320\n",
      "3 4 5 sqrt entropy True 50 42: Weighted 0.814455 (0.065778)\n",
      "3 4 5 sqrt entropy True 50 42: Macro 0.711632 (0.088816)\n",
      "Testing 2170/4320\n",
      "3 4 5 sqrt entropy True 100 42: Weighted 0.816624 (0.060205)\n",
      "3 4 5 sqrt entropy True 100 42: Macro 0.711473 (0.077270)\n",
      "Testing 2171/4320\n",
      "3 4 5 sqrt entropy True 200 42: Weighted 0.816624 (0.060205)\n",
      "3 4 5 sqrt entropy True 200 42: Macro 0.711473 (0.077270)\n",
      "Testing 2172/4320\n",
      "3 4 5 sqrt entropy True 500 42: Weighted 0.811863 (0.058581)\n",
      "3 4 5 sqrt entropy True 500 42: Macro 0.704330 (0.074545)\n",
      "Testing 2173/4320\n",
      "3 4 5 sqrt entropy False 50 42: Weighted 0.799089 (0.077218)\n",
      "3 4 5 sqrt entropy False 50 42: Macro 0.683466 (0.111662)\n",
      "Testing 2174/4320\n",
      "3 4 5 sqrt entropy False 100 42: Weighted 0.793453 (0.080572)\n",
      "3 4 5 sqrt entropy False 100 42: Macro 0.677538 (0.112856)\n",
      "Testing 2175/4320\n",
      "3 4 5 sqrt entropy False 200 42: Weighted 0.795653 (0.077179)\n",
      "3 4 5 sqrt entropy False 200 42: Macro 0.678441 (0.111424)\n",
      "Testing 2176/4320\n",
      "3 4 5 sqrt entropy False 500 42: Weighted 0.795653 (0.077179)\n",
      "3 4 5 sqrt entropy False 500 42: Macro 0.678441 (0.111424)\n",
      "Testing 2177/4320\n",
      "3 4 8 log2 gini True 50 42: Weighted 0.818551 (0.071564)\n",
      "3 4 8 log2 gini True 50 42: Macro 0.714195 (0.102275)\n",
      "Testing 2178/4320\n",
      "3 4 8 log2 gini True 100 42: Weighted 0.816235 (0.056083)\n",
      "3 4 8 log2 gini True 100 42: Macro 0.711790 (0.071586)\n",
      "Testing 2179/4320\n",
      "3 4 8 log2 gini True 200 42: Weighted 0.816652 (0.067360)\n",
      "3 4 8 log2 gini True 200 42: Macro 0.713673 (0.087620)\n",
      "Testing 2180/4320\n",
      "3 4 8 log2 gini True 500 42: Weighted 0.811473 (0.054301)\n",
      "3 4 8 log2 gini True 500 42: Macro 0.704647 (0.068668)\n",
      "Testing 2181/4320\n",
      "3 4 8 log2 gini False 50 42: Weighted 0.792312 (0.064620)\n",
      "3 4 8 log2 gini False 50 42: Macro 0.680466 (0.081378)\n",
      "Testing 2182/4320\n",
      "3 4 8 log2 gini False 100 42: Weighted 0.792696 (0.064414)\n",
      "3 4 8 log2 gini False 100 42: Macro 0.674587 (0.083489)\n",
      "Testing 2183/4320\n",
      "3 4 8 log2 gini False 200 42: Weighted 0.804539 (0.065853)\n",
      "3 4 8 log2 gini False 200 42: Macro 0.694675 (0.091588)\n",
      "Testing 2184/4320\n",
      "3 4 8 log2 gini False 500 42: Weighted 0.808191 (0.063573)\n",
      "3 4 8 log2 gini False 500 42: Macro 0.699781 (0.088708)\n",
      "Testing 2185/4320\n",
      "3 4 8 log2 entropy True 50 42: Weighted 0.814455 (0.065778)\n",
      "3 4 8 log2 entropy True 50 42: Macro 0.711632 (0.088816)\n",
      "Testing 2186/4320\n",
      "3 4 8 log2 entropy True 100 42: Weighted 0.810977 (0.058703)\n",
      "3 4 8 log2 entropy True 100 42: Macro 0.704859 (0.074493)\n",
      "Testing 2187/4320\n",
      "3 4 8 log2 entropy True 200 42: Weighted 0.816652 (0.067360)\n",
      "3 4 8 log2 entropy True 200 42: Macro 0.713673 (0.087620)\n",
      "Testing 2188/4320\n",
      "3 4 8 log2 entropy True 500 42: Weighted 0.807467 (0.059573)\n",
      "3 4 8 log2 entropy True 500 42: Macro 0.699568 (0.075508)\n",
      "Testing 2189/4320\n",
      "3 4 8 log2 entropy False 50 42: Weighted 0.799951 (0.069875)\n",
      "3 4 8 log2 entropy False 50 42: Macro 0.690788 (0.092253)\n",
      "Testing 2190/4320\n",
      "3 4 8 log2 entropy False 100 42: Weighted 0.797466 (0.065768)\n",
      "3 4 8 log2 entropy False 100 42: Macro 0.686951 (0.087324)\n",
      "Testing 2191/4320\n",
      "3 4 8 log2 entropy False 200 42: Weighted 0.801119 (0.063891)\n",
      "3 4 8 log2 entropy False 200 42: Macro 0.692057 (0.084765)\n",
      "Testing 2192/4320\n",
      "3 4 8 log2 entropy False 500 42: Weighted 0.804684 (0.062624)\n",
      "3 4 8 log2 entropy False 500 42: Macro 0.697221 (0.083059)\n",
      "Testing 2193/4320\n",
      "3 4 8 sqrt gini True 50 42: Weighted 0.818551 (0.071564)\n",
      "3 4 8 sqrt gini True 50 42: Macro 0.714195 (0.102275)\n",
      "Testing 2194/4320\n",
      "3 4 8 sqrt gini True 100 42: Weighted 0.816235 (0.056083)\n",
      "3 4 8 sqrt gini True 100 42: Macro 0.711790 (0.071586)\n",
      "Testing 2195/4320\n",
      "3 4 8 sqrt gini True 200 42: Weighted 0.816652 (0.067360)\n",
      "3 4 8 sqrt gini True 200 42: Macro 0.713673 (0.087620)\n",
      "Testing 2196/4320\n",
      "3 4 8 sqrt gini True 500 42: Weighted 0.811473 (0.054301)\n",
      "3 4 8 sqrt gini True 500 42: Macro 0.704647 (0.068668)\n",
      "Testing 2197/4320\n",
      "3 4 8 sqrt gini False 50 42: Weighted 0.792312 (0.064620)\n",
      "3 4 8 sqrt gini False 50 42: Macro 0.680466 (0.081378)\n",
      "Testing 2198/4320\n",
      "3 4 8 sqrt gini False 100 42: Weighted 0.792696 (0.064414)\n",
      "3 4 8 sqrt gini False 100 42: Macro 0.674587 (0.083489)\n",
      "Testing 2199/4320\n",
      "3 4 8 sqrt gini False 200 42: Weighted 0.804539 (0.065853)\n",
      "3 4 8 sqrt gini False 200 42: Macro 0.694675 (0.091588)\n",
      "Testing 2200/4320\n",
      "3 4 8 sqrt gini False 500 42: Weighted 0.808191 (0.063573)\n",
      "3 4 8 sqrt gini False 500 42: Macro 0.699781 (0.088708)\n",
      "Testing 2201/4320\n",
      "3 4 8 sqrt entropy True 50 42: Weighted 0.814455 (0.065778)\n",
      "3 4 8 sqrt entropy True 50 42: Macro 0.711632 (0.088816)\n",
      "Testing 2202/4320\n",
      "3 4 8 sqrt entropy True 100 42: Weighted 0.810977 (0.058703)\n",
      "3 4 8 sqrt entropy True 100 42: Macro 0.704859 (0.074493)\n",
      "Testing 2203/4320\n",
      "3 4 8 sqrt entropy True 200 42: Weighted 0.816652 (0.067360)\n",
      "3 4 8 sqrt entropy True 200 42: Macro 0.713673 (0.087620)\n",
      "Testing 2204/4320\n",
      "3 4 8 sqrt entropy True 500 42: Weighted 0.807467 (0.059573)\n",
      "3 4 8 sqrt entropy True 500 42: Macro 0.699568 (0.075508)\n",
      "Testing 2205/4320\n",
      "3 4 8 sqrt entropy False 50 42: Weighted 0.799951 (0.069875)\n",
      "3 4 8 sqrt entropy False 50 42: Macro 0.690788 (0.092253)\n",
      "Testing 2206/4320\n",
      "3 4 8 sqrt entropy False 100 42: Weighted 0.797466 (0.065768)\n",
      "3 4 8 sqrt entropy False 100 42: Macro 0.686951 (0.087324)\n",
      "Testing 2207/4320\n",
      "3 4 8 sqrt entropy False 200 42: Weighted 0.801119 (0.063891)\n",
      "3 4 8 sqrt entropy False 200 42: Macro 0.692057 (0.084765)\n",
      "Testing 2208/4320\n",
      "3 4 8 sqrt entropy False 500 42: Weighted 0.804684 (0.062624)\n",
      "3 4 8 sqrt entropy False 500 42: Macro 0.697221 (0.083059)\n",
      "Testing 2209/4320\n",
      "3 6 3 log2 gini True 50 42: Weighted 0.805267 (0.056365)\n",
      "3 6 3 log2 gini True 50 42: Macro 0.698061 (0.077107)\n",
      "Testing 2210/4320\n",
      "3 6 3 log2 gini True 100 42: Weighted 0.809935 (0.060810)\n",
      "3 6 3 log2 gini True 100 42: Macro 0.704820 (0.082311)\n",
      "Testing 2211/4320\n",
      "3 6 3 log2 gini True 200 42: Weighted 0.809935 (0.060810)\n",
      "3 6 3 log2 gini True 200 42: Macro 0.704820 (0.082311)\n",
      "Testing 2212/4320\n",
      "3 6 3 log2 gini True 500 42: Weighted 0.809014 (0.051630)\n",
      "3 6 3 log2 gini True 500 42: Macro 0.702391 (0.068382)\n",
      "Testing 2213/4320\n",
      "3 6 3 log2 gini False 50 42: Weighted 0.801111 (0.073505)\n",
      "3 6 3 log2 gini False 50 42: Macro 0.696487 (0.093893)\n",
      "Testing 2214/4320\n",
      "3 6 3 log2 gini False 100 42: Weighted 0.800801 (0.062924)\n",
      "3 6 3 log2 gini False 100 42: Macro 0.692099 (0.082395)\n",
      "Testing 2215/4320\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 6 3 log2 gini False 200 42: Weighted 0.793563 (0.090270)\n",
      "3 6 3 log2 gini False 200 42: Macro 0.688455 (0.112395)\n",
      "Testing 2216/4320\n",
      "3 6 3 log2 gini False 500 42: Weighted 0.803571 (0.074267)\n",
      "3 6 3 log2 gini False 500 42: Macro 0.701017 (0.092801)\n",
      "Testing 2217/4320\n",
      "3 6 3 log2 entropy True 50 42: Weighted 0.804576 (0.061340)\n",
      "3 6 3 log2 entropy True 50 42: Macro 0.697805 (0.082553)\n",
      "Testing 2218/4320\n",
      "3 6 3 log2 entropy True 100 42: Weighted 0.809935 (0.060810)\n",
      "3 6 3 log2 entropy True 100 42: Macro 0.704820 (0.082311)\n",
      "Testing 2219/4320\n",
      "3 6 3 log2 entropy True 200 42: Weighted 0.805728 (0.066727)\n",
      "3 6 3 log2 entropy True 200 42: Macro 0.699607 (0.089460)\n",
      "Testing 2220/4320\n",
      "3 6 3 log2 entropy True 500 42: Weighted 0.805007 (0.056975)\n",
      "3 6 3 log2 entropy True 500 42: Macro 0.697312 (0.075095)\n",
      "Testing 2221/4320\n",
      "3 6 3 log2 entropy False 50 42: Weighted 0.777448 (0.083265)\n",
      "3 6 3 log2 entropy False 50 42: Macro 0.665820 (0.097952)\n",
      "Testing 2222/4320\n",
      "3 6 3 log2 entropy False 100 42: Weighted 0.798644 (0.070719)\n",
      "3 6 3 log2 entropy False 100 42: Macro 0.693509 (0.086134)\n",
      "Testing 2223/4320\n",
      "3 6 3 log2 entropy False 200 42: Weighted 0.787834 (0.088117)\n",
      "3 6 3 log2 entropy False 200 42: Macro 0.680688 (0.106489)\n",
      "Testing 2224/4320\n",
      "3 6 3 log2 entropy False 500 42: Weighted 0.787834 (0.088117)\n",
      "3 6 3 log2 entropy False 500 42: Macro 0.680688 (0.106489)\n",
      "Testing 2225/4320\n",
      "3 6 3 sqrt gini True 50 42: Weighted 0.805267 (0.056365)\n",
      "3 6 3 sqrt gini True 50 42: Macro 0.698061 (0.077107)\n",
      "Testing 2226/4320\n",
      "3 6 3 sqrt gini True 100 42: Weighted 0.809935 (0.060810)\n",
      "3 6 3 sqrt gini True 100 42: Macro 0.704820 (0.082311)\n",
      "Testing 2227/4320\n",
      "3 6 3 sqrt gini True 200 42: Weighted 0.809935 (0.060810)\n",
      "3 6 3 sqrt gini True 200 42: Macro 0.704820 (0.082311)\n",
      "Testing 2228/4320\n",
      "3 6 3 sqrt gini True 500 42: Weighted 0.809014 (0.051630)\n",
      "3 6 3 sqrt gini True 500 42: Macro 0.702391 (0.068382)\n",
      "Testing 2229/4320\n",
      "3 6 3 sqrt gini False 50 42: Weighted 0.801111 (0.073505)\n",
      "3 6 3 sqrt gini False 50 42: Macro 0.696487 (0.093893)\n",
      "Testing 2230/4320\n",
      "3 6 3 sqrt gini False 100 42: Weighted 0.800801 (0.062924)\n",
      "3 6 3 sqrt gini False 100 42: Macro 0.692099 (0.082395)\n",
      "Testing 2231/4320\n",
      "3 6 3 sqrt gini False 200 42: Weighted 0.793563 (0.090270)\n",
      "3 6 3 sqrt gini False 200 42: Macro 0.688455 (0.112395)\n",
      "Testing 2232/4320\n",
      "3 6 3 sqrt gini False 500 42: Weighted 0.803571 (0.074267)\n",
      "3 6 3 sqrt gini False 500 42: Macro 0.701017 (0.092801)\n",
      "Testing 2233/4320\n",
      "3 6 3 sqrt entropy True 50 42: Weighted 0.804576 (0.061340)\n",
      "3 6 3 sqrt entropy True 50 42: Macro 0.697805 (0.082553)\n",
      "Testing 2234/4320\n",
      "3 6 3 sqrt entropy True 100 42: Weighted 0.809935 (0.060810)\n",
      "3 6 3 sqrt entropy True 100 42: Macro 0.704820 (0.082311)\n",
      "Testing 2235/4320\n",
      "3 6 3 sqrt entropy True 200 42: Weighted 0.805728 (0.066727)\n",
      "3 6 3 sqrt entropy True 200 42: Macro 0.699607 (0.089460)\n",
      "Testing 2236/4320\n",
      "3 6 3 sqrt entropy True 500 42: Weighted 0.805007 (0.056975)\n",
      "3 6 3 sqrt entropy True 500 42: Macro 0.697312 (0.075095)\n",
      "Testing 2237/4320\n",
      "3 6 3 sqrt entropy False 50 42: Weighted 0.777448 (0.083265)\n",
      "3 6 3 sqrt entropy False 50 42: Macro 0.665820 (0.097952)\n",
      "Testing 2238/4320\n",
      "3 6 3 sqrt entropy False 100 42: Weighted 0.798644 (0.070719)\n",
      "3 6 3 sqrt entropy False 100 42: Macro 0.693509 (0.086134)\n",
      "Testing 2239/4320\n",
      "3 6 3 sqrt entropy False 200 42: Weighted 0.787834 (0.088117)\n",
      "3 6 3 sqrt entropy False 200 42: Macro 0.680688 (0.106489)\n",
      "Testing 2240/4320\n",
      "3 6 3 sqrt entropy False 500 42: Weighted 0.787834 (0.088117)\n",
      "3 6 3 sqrt entropy False 500 42: Macro 0.680688 (0.106489)\n",
      "Testing 2241/4320\n",
      "3 6 5 log2 gini True 50 42: Weighted 0.821974 (0.058470)\n",
      "3 6 5 log2 gini True 50 42: Macro 0.725060 (0.074615)\n",
      "Testing 2242/4320\n",
      "3 6 5 log2 gini True 100 42: Weighted 0.813188 (0.061148)\n",
      "3 6 5 log2 gini True 100 42: Macro 0.706448 (0.078733)\n",
      "Testing 2243/4320\n",
      "3 6 5 log2 gini True 200 42: Weighted 0.813188 (0.061148)\n",
      "3 6 5 log2 gini True 200 42: Macro 0.706448 (0.078733)\n",
      "Testing 2244/4320\n",
      "3 6 5 log2 gini True 500 42: Weighted 0.808426 (0.059274)\n",
      "3 6 5 log2 gini True 500 42: Macro 0.699306 (0.075587)\n",
      "Testing 2245/4320\n",
      "3 6 5 log2 gini False 50 42: Weighted 0.813237 (0.075536)\n",
      "3 6 5 log2 gini False 50 42: Macro 0.707725 (0.105751)\n",
      "Testing 2246/4320\n",
      "3 6 5 log2 gini False 100 42: Weighted 0.808309 (0.072708)\n",
      "3 6 5 log2 gini False 100 42: Macro 0.700217 (0.100455)\n",
      "Testing 2247/4320\n",
      "3 6 5 log2 gini False 200 42: Weighted 0.813237 (0.075536)\n",
      "3 6 5 log2 gini False 200 42: Macro 0.707725 (0.105751)\n",
      "Testing 2248/4320\n",
      "3 6 5 log2 gini False 500 42: Weighted 0.803576 (0.073375)\n",
      "3 6 5 log2 gini False 500 42: Macro 0.696618 (0.100788)\n",
      "Testing 2249/4320\n",
      "3 6 5 log2 entropy True 50 42: Weighted 0.814455 (0.065778)\n",
      "3 6 5 log2 entropy True 50 42: Macro 0.711632 (0.088816)\n",
      "Testing 2250/4320\n",
      "3 6 5 log2 entropy True 100 42: Weighted 0.816624 (0.060205)\n",
      "3 6 5 log2 entropy True 100 42: Macro 0.711473 (0.077270)\n",
      "Testing 2251/4320\n",
      "3 6 5 log2 entropy True 200 42: Weighted 0.816624 (0.060205)\n",
      "3 6 5 log2 entropy True 200 42: Macro 0.711473 (0.077270)\n",
      "Testing 2252/4320\n",
      "3 6 5 log2 entropy True 500 42: Weighted 0.811863 (0.058581)\n",
      "3 6 5 log2 entropy True 500 42: Macro 0.704330 (0.074545)\n",
      "Testing 2253/4320\n",
      "3 6 5 log2 entropy False 50 42: Weighted 0.799089 (0.077218)\n",
      "3 6 5 log2 entropy False 50 42: Macro 0.683466 (0.111662)\n",
      "Testing 2254/4320\n",
      "3 6 5 log2 entropy False 100 42: Weighted 0.793453 (0.080572)\n",
      "3 6 5 log2 entropy False 100 42: Macro 0.677538 (0.112856)\n",
      "Testing 2255/4320\n",
      "3 6 5 log2 entropy False 200 42: Weighted 0.795653 (0.077179)\n",
      "3 6 5 log2 entropy False 200 42: Macro 0.678441 (0.111424)\n",
      "Testing 2256/4320\n",
      "3 6 5 log2 entropy False 500 42: Weighted 0.795653 (0.077179)\n",
      "3 6 5 log2 entropy False 500 42: Macro 0.678441 (0.111424)\n",
      "Testing 2257/4320\n",
      "3 6 5 sqrt gini True 50 42: Weighted 0.821974 (0.058470)\n",
      "3 6 5 sqrt gini True 50 42: Macro 0.725060 (0.074615)\n",
      "Testing 2258/4320\n",
      "3 6 5 sqrt gini True 100 42: Weighted 0.813188 (0.061148)\n",
      "3 6 5 sqrt gini True 100 42: Macro 0.706448 (0.078733)\n",
      "Testing 2259/4320\n",
      "3 6 5 sqrt gini True 200 42: Weighted 0.813188 (0.061148)\n",
      "3 6 5 sqrt gini True 200 42: Macro 0.706448 (0.078733)\n",
      "Testing 2260/4320\n",
      "3 6 5 sqrt gini True 500 42: Weighted 0.808426 (0.059274)\n",
      "3 6 5 sqrt gini True 500 42: Macro 0.699306 (0.075587)\n",
      "Testing 2261/4320\n",
      "3 6 5 sqrt gini False 50 42: Weighted 0.813237 (0.075536)\n",
      "3 6 5 sqrt gini False 50 42: Macro 0.707725 (0.105751)\n",
      "Testing 2262/4320\n",
      "3 6 5 sqrt gini False 100 42: Weighted 0.808309 (0.072708)\n",
      "3 6 5 sqrt gini False 100 42: Macro 0.700217 (0.100455)\n",
      "Testing 2263/4320\n",
      "3 6 5 sqrt gini False 200 42: Weighted 0.813237 (0.075536)\n",
      "3 6 5 sqrt gini False 200 42: Macro 0.707725 (0.105751)\n",
      "Testing 2264/4320\n",
      "3 6 5 sqrt gini False 500 42: Weighted 0.803576 (0.073375)\n",
      "3 6 5 sqrt gini False 500 42: Macro 0.696618 (0.100788)\n",
      "Testing 2265/4320\n",
      "3 6 5 sqrt entropy True 50 42: Weighted 0.814455 (0.065778)\n",
      "3 6 5 sqrt entropy True 50 42: Macro 0.711632 (0.088816)\n",
      "Testing 2266/4320\n",
      "3 6 5 sqrt entropy True 100 42: Weighted 0.816624 (0.060205)\n",
      "3 6 5 sqrt entropy True 100 42: Macro 0.711473 (0.077270)\n",
      "Testing 2267/4320\n",
      "3 6 5 sqrt entropy True 200 42: Weighted 0.816624 (0.060205)\n",
      "3 6 5 sqrt entropy True 200 42: Macro 0.711473 (0.077270)\n",
      "Testing 2268/4320\n",
      "3 6 5 sqrt entropy True 500 42: Weighted 0.811863 (0.058581)\n",
      "3 6 5 sqrt entropy True 500 42: Macro 0.704330 (0.074545)\n",
      "Testing 2269/4320\n",
      "3 6 5 sqrt entropy False 50 42: Weighted 0.799089 (0.077218)\n",
      "3 6 5 sqrt entropy False 50 42: Macro 0.683466 (0.111662)\n",
      "Testing 2270/4320\n",
      "3 6 5 sqrt entropy False 100 42: Weighted 0.793453 (0.080572)\n",
      "3 6 5 sqrt entropy False 100 42: Macro 0.677538 (0.112856)\n",
      "Testing 2271/4320\n",
      "3 6 5 sqrt entropy False 200 42: Weighted 0.795653 (0.077179)\n",
      "3 6 5 sqrt entropy False 200 42: Macro 0.678441 (0.111424)\n",
      "Testing 2272/4320\n",
      "3 6 5 sqrt entropy False 500 42: Weighted 0.795653 (0.077179)\n",
      "3 6 5 sqrt entropy False 500 42: Macro 0.678441 (0.111424)\n",
      "Testing 2273/4320\n",
      "3 6 8 log2 gini True 50 42: Weighted 0.818551 (0.071564)\n",
      "3 6 8 log2 gini True 50 42: Macro 0.714195 (0.102275)\n",
      "Testing 2274/4320\n",
      "3 6 8 log2 gini True 100 42: Weighted 0.816235 (0.056083)\n",
      "3 6 8 log2 gini True 100 42: Macro 0.711790 (0.071586)\n",
      "Testing 2275/4320\n",
      "3 6 8 log2 gini True 200 42: Weighted 0.816652 (0.067360)\n",
      "3 6 8 log2 gini True 200 42: Macro 0.713673 (0.087620)\n",
      "Testing 2276/4320\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 6 8 log2 gini True 500 42: Weighted 0.811473 (0.054301)\n",
      "3 6 8 log2 gini True 500 42: Macro 0.704647 (0.068668)\n",
      "Testing 2277/4320\n",
      "3 6 8 log2 gini False 50 42: Weighted 0.792312 (0.064620)\n",
      "3 6 8 log2 gini False 50 42: Macro 0.680466 (0.081378)\n",
      "Testing 2278/4320\n",
      "3 6 8 log2 gini False 100 42: Weighted 0.792696 (0.064414)\n",
      "3 6 8 log2 gini False 100 42: Macro 0.674587 (0.083489)\n",
      "Testing 2279/4320\n",
      "3 6 8 log2 gini False 200 42: Weighted 0.804539 (0.065853)\n",
      "3 6 8 log2 gini False 200 42: Macro 0.694675 (0.091588)\n",
      "Testing 2280/4320\n",
      "3 6 8 log2 gini False 500 42: Weighted 0.808191 (0.063573)\n",
      "3 6 8 log2 gini False 500 42: Macro 0.699781 (0.088708)\n",
      "Testing 2281/4320\n",
      "3 6 8 log2 entropy True 50 42: Weighted 0.814455 (0.065778)\n",
      "3 6 8 log2 entropy True 50 42: Macro 0.711632 (0.088816)\n",
      "Testing 2282/4320\n",
      "3 6 8 log2 entropy True 100 42: Weighted 0.810977 (0.058703)\n",
      "3 6 8 log2 entropy True 100 42: Macro 0.704859 (0.074493)\n",
      "Testing 2283/4320\n",
      "3 6 8 log2 entropy True 200 42: Weighted 0.816652 (0.067360)\n",
      "3 6 8 log2 entropy True 200 42: Macro 0.713673 (0.087620)\n",
      "Testing 2284/4320\n",
      "3 6 8 log2 entropy True 500 42: Weighted 0.807467 (0.059573)\n",
      "3 6 8 log2 entropy True 500 42: Macro 0.699568 (0.075508)\n",
      "Testing 2285/4320\n",
      "3 6 8 log2 entropy False 50 42: Weighted 0.799951 (0.069875)\n",
      "3 6 8 log2 entropy False 50 42: Macro 0.690788 (0.092253)\n",
      "Testing 2286/4320\n",
      "3 6 8 log2 entropy False 100 42: Weighted 0.797466 (0.065768)\n",
      "3 6 8 log2 entropy False 100 42: Macro 0.686951 (0.087324)\n",
      "Testing 2287/4320\n",
      "3 6 8 log2 entropy False 200 42: Weighted 0.801119 (0.063891)\n",
      "3 6 8 log2 entropy False 200 42: Macro 0.692057 (0.084765)\n",
      "Testing 2288/4320\n",
      "3 6 8 log2 entropy False 500 42: Weighted 0.804684 (0.062624)\n",
      "3 6 8 log2 entropy False 500 42: Macro 0.697221 (0.083059)\n",
      "Testing 2289/4320\n",
      "3 6 8 sqrt gini True 50 42: Weighted 0.818551 (0.071564)\n",
      "3 6 8 sqrt gini True 50 42: Macro 0.714195 (0.102275)\n",
      "Testing 2290/4320\n",
      "3 6 8 sqrt gini True 100 42: Weighted 0.816235 (0.056083)\n",
      "3 6 8 sqrt gini True 100 42: Macro 0.711790 (0.071586)\n",
      "Testing 2291/4320\n",
      "3 6 8 sqrt gini True 200 42: Weighted 0.816652 (0.067360)\n",
      "3 6 8 sqrt gini True 200 42: Macro 0.713673 (0.087620)\n",
      "Testing 2292/4320\n",
      "3 6 8 sqrt gini True 500 42: Weighted 0.811473 (0.054301)\n",
      "3 6 8 sqrt gini True 500 42: Macro 0.704647 (0.068668)\n",
      "Testing 2293/4320\n",
      "3 6 8 sqrt gini False 50 42: Weighted 0.792312 (0.064620)\n",
      "3 6 8 sqrt gini False 50 42: Macro 0.680466 (0.081378)\n",
      "Testing 2294/4320\n",
      "3 6 8 sqrt gini False 100 42: Weighted 0.792696 (0.064414)\n",
      "3 6 8 sqrt gini False 100 42: Macro 0.674587 (0.083489)\n",
      "Testing 2295/4320\n",
      "3 6 8 sqrt gini False 200 42: Weighted 0.804539 (0.065853)\n",
      "3 6 8 sqrt gini False 200 42: Macro 0.694675 (0.091588)\n",
      "Testing 2296/4320\n",
      "3 6 8 sqrt gini False 500 42: Weighted 0.808191 (0.063573)\n",
      "3 6 8 sqrt gini False 500 42: Macro 0.699781 (0.088708)\n",
      "Testing 2297/4320\n",
      "3 6 8 sqrt entropy True 50 42: Weighted 0.814455 (0.065778)\n",
      "3 6 8 sqrt entropy True 50 42: Macro 0.711632 (0.088816)\n",
      "Testing 2298/4320\n",
      "3 6 8 sqrt entropy True 100 42: Weighted 0.810977 (0.058703)\n",
      "3 6 8 sqrt entropy True 100 42: Macro 0.704859 (0.074493)\n",
      "Testing 2299/4320\n",
      "3 6 8 sqrt entropy True 200 42: Weighted 0.816652 (0.067360)\n",
      "3 6 8 sqrt entropy True 200 42: Macro 0.713673 (0.087620)\n",
      "Testing 2300/4320\n",
      "3 6 8 sqrt entropy True 500 42: Weighted 0.807467 (0.059573)\n",
      "3 6 8 sqrt entropy True 500 42: Macro 0.699568 (0.075508)\n",
      "Testing 2301/4320\n",
      "3 6 8 sqrt entropy False 50 42: Weighted 0.799951 (0.069875)\n",
      "3 6 8 sqrt entropy False 50 42: Macro 0.690788 (0.092253)\n",
      "Testing 2302/4320\n",
      "3 6 8 sqrt entropy False 100 42: Weighted 0.797466 (0.065768)\n",
      "3 6 8 sqrt entropy False 100 42: Macro 0.686951 (0.087324)\n",
      "Testing 2303/4320\n",
      "3 6 8 sqrt entropy False 200 42: Weighted 0.801119 (0.063891)\n",
      "3 6 8 sqrt entropy False 200 42: Macro 0.692057 (0.084765)\n",
      "Testing 2304/4320\n",
      "3 6 8 sqrt entropy False 500 42: Weighted 0.804684 (0.062624)\n",
      "3 6 8 sqrt entropy False 500 42: Macro 0.697221 (0.083059)\n",
      "Testing 2305/4320\n",
      "5 2 3 log2 gini True 50 42: Weighted 0.805267 (0.056365)\n",
      "5 2 3 log2 gini True 50 42: Macro 0.698061 (0.077107)\n",
      "Testing 2306/4320\n",
      "5 2 3 log2 gini True 100 42: Weighted 0.809935 (0.060810)\n",
      "5 2 3 log2 gini True 100 42: Macro 0.704820 (0.082311)\n",
      "Testing 2307/4320\n",
      "5 2 3 log2 gini True 200 42: Weighted 0.809935 (0.060810)\n",
      "5 2 3 log2 gini True 200 42: Macro 0.704820 (0.082311)\n",
      "Testing 2308/4320\n",
      "5 2 3 log2 gini True 500 42: Weighted 0.809014 (0.051630)\n",
      "5 2 3 log2 gini True 500 42: Macro 0.702391 (0.068382)\n",
      "Testing 2309/4320\n",
      "5 2 3 log2 gini False 50 42: Weighted 0.801111 (0.073505)\n",
      "5 2 3 log2 gini False 50 42: Macro 0.696487 (0.093893)\n",
      "Testing 2310/4320\n",
      "5 2 3 log2 gini False 100 42: Weighted 0.804638 (0.057485)\n",
      "5 2 3 log2 gini False 100 42: Macro 0.700234 (0.071178)\n",
      "Testing 2311/4320\n",
      "5 2 3 log2 gini False 200 42: Weighted 0.793563 (0.090270)\n",
      "5 2 3 log2 gini False 200 42: Macro 0.688455 (0.112395)\n",
      "Testing 2312/4320\n",
      "5 2 3 log2 gini False 500 42: Weighted 0.798644 (0.070719)\n",
      "5 2 3 log2 gini False 500 42: Macro 0.693509 (0.086134)\n",
      "Testing 2313/4320\n",
      "5 2 3 log2 entropy True 50 42: Weighted 0.801060 (0.062389)\n",
      "5 2 3 log2 entropy True 50 42: Macro 0.692847 (0.084279)\n",
      "Testing 2314/4320\n",
      "5 2 3 log2 entropy True 100 42: Weighted 0.809935 (0.060810)\n",
      "5 2 3 log2 entropy True 100 42: Macro 0.704820 (0.082311)\n",
      "Testing 2315/4320\n",
      "5 2 3 log2 entropy True 200 42: Weighted 0.805728 (0.066727)\n",
      "5 2 3 log2 entropy True 200 42: Macro 0.699607 (0.089460)\n",
      "Testing 2316/4320\n",
      "5 2 3 log2 entropy True 500 42: Weighted 0.805007 (0.056975)\n",
      "5 2 3 log2 entropy True 500 42: Macro 0.697312 (0.075095)\n",
      "Testing 2317/4320\n",
      "5 2 3 log2 entropy False 50 42: Weighted 0.777448 (0.083265)\n",
      "5 2 3 log2 entropy False 50 42: Macro 0.665820 (0.097952)\n",
      "Testing 2318/4320\n",
      "5 2 3 log2 entropy False 100 42: Weighted 0.798644 (0.070719)\n",
      "5 2 3 log2 entropy False 100 42: Macro 0.693509 (0.086134)\n",
      "Testing 2319/4320\n",
      "5 2 3 log2 entropy False 200 42: Weighted 0.787834 (0.088117)\n",
      "5 2 3 log2 entropy False 200 42: Macro 0.680688 (0.106489)\n",
      "Testing 2320/4320\n",
      "5 2 3 log2 entropy False 500 42: Weighted 0.787834 (0.088117)\n",
      "5 2 3 log2 entropy False 500 42: Macro 0.680688 (0.106489)\n",
      "Testing 2321/4320\n",
      "5 2 3 sqrt gini True 50 42: Weighted 0.805267 (0.056365)\n",
      "5 2 3 sqrt gini True 50 42: Macro 0.698061 (0.077107)\n",
      "Testing 2322/4320\n",
      "5 2 3 sqrt gini True 100 42: Weighted 0.809935 (0.060810)\n",
      "5 2 3 sqrt gini True 100 42: Macro 0.704820 (0.082311)\n",
      "Testing 2323/4320\n",
      "5 2 3 sqrt gini True 200 42: Weighted 0.809935 (0.060810)\n",
      "5 2 3 sqrt gini True 200 42: Macro 0.704820 (0.082311)\n",
      "Testing 2324/4320\n",
      "5 2 3 sqrt gini True 500 42: Weighted 0.809014 (0.051630)\n",
      "5 2 3 sqrt gini True 500 42: Macro 0.702391 (0.068382)\n",
      "Testing 2325/4320\n",
      "5 2 3 sqrt gini False 50 42: Weighted 0.801111 (0.073505)\n",
      "5 2 3 sqrt gini False 50 42: Macro 0.696487 (0.093893)\n",
      "Testing 2326/4320\n",
      "5 2 3 sqrt gini False 100 42: Weighted 0.804638 (0.057485)\n",
      "5 2 3 sqrt gini False 100 42: Macro 0.700234 (0.071178)\n",
      "Testing 2327/4320\n",
      "5 2 3 sqrt gini False 200 42: Weighted 0.793563 (0.090270)\n",
      "5 2 3 sqrt gini False 200 42: Macro 0.688455 (0.112395)\n",
      "Testing 2328/4320\n",
      "5 2 3 sqrt gini False 500 42: Weighted 0.798644 (0.070719)\n",
      "5 2 3 sqrt gini False 500 42: Macro 0.693509 (0.086134)\n",
      "Testing 2329/4320\n",
      "5 2 3 sqrt entropy True 50 42: Weighted 0.801060 (0.062389)\n",
      "5 2 3 sqrt entropy True 50 42: Macro 0.692847 (0.084279)\n",
      "Testing 2330/4320\n",
      "5 2 3 sqrt entropy True 100 42: Weighted 0.809935 (0.060810)\n",
      "5 2 3 sqrt entropy True 100 42: Macro 0.704820 (0.082311)\n",
      "Testing 2331/4320\n",
      "5 2 3 sqrt entropy True 200 42: Weighted 0.805728 (0.066727)\n",
      "5 2 3 sqrt entropy True 200 42: Macro 0.699607 (0.089460)\n",
      "Testing 2332/4320\n",
      "5 2 3 sqrt entropy True 500 42: Weighted 0.805007 (0.056975)\n",
      "5 2 3 sqrt entropy True 500 42: Macro 0.697312 (0.075095)\n",
      "Testing 2333/4320\n",
      "5 2 3 sqrt entropy False 50 42: Weighted 0.777448 (0.083265)\n",
      "5 2 3 sqrt entropy False 50 42: Macro 0.665820 (0.097952)\n",
      "Testing 2334/4320\n",
      "5 2 3 sqrt entropy False 100 42: Weighted 0.798644 (0.070719)\n",
      "5 2 3 sqrt entropy False 100 42: Macro 0.693509 (0.086134)\n",
      "Testing 2335/4320\n",
      "5 2 3 sqrt entropy False 200 42: Weighted 0.787834 (0.088117)\n",
      "5 2 3 sqrt entropy False 200 42: Macro 0.680688 (0.106489)\n",
      "Testing 2336/4320\n",
      "5 2 3 sqrt entropy False 500 42: Weighted 0.787834 (0.088117)\n",
      "5 2 3 sqrt entropy False 500 42: Macro 0.680688 (0.106489)\n",
      "Testing 2337/4320\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 2 5 log2 gini True 50 42: Weighted 0.821407 (0.062892)\n",
      "5 2 5 log2 gini True 50 42: Macro 0.721614 (0.084166)\n",
      "Testing 2338/4320\n",
      "5 2 5 log2 gini True 100 42: Weighted 0.821407 (0.062892)\n",
      "5 2 5 log2 gini True 100 42: Macro 0.721614 (0.084166)\n",
      "Testing 2339/4320\n",
      "5 2 5 log2 gini True 200 42: Weighted 0.821047 (0.065875)\n",
      "5 2 5 log2 gini True 200 42: Macro 0.718434 (0.086014)\n",
      "Testing 2340/4320\n",
      "5 2 5 log2 gini True 500 42: Weighted 0.816624 (0.060205)\n",
      "5 2 5 log2 gini True 500 42: Macro 0.711473 (0.077270)\n",
      "Testing 2341/4320\n",
      "5 2 5 log2 gini False 50 42: Weighted 0.812352 (0.075646)\n",
      "5 2 5 log2 gini False 50 42: Macro 0.708254 (0.105698)\n",
      "Testing 2342/4320\n",
      "5 2 5 log2 gini False 100 42: Weighted 0.807424 (0.072763)\n",
      "5 2 5 log2 gini False 100 42: Macro 0.700746 (0.100438)\n",
      "Testing 2343/4320\n",
      "5 2 5 log2 gini False 200 42: Weighted 0.812352 (0.075646)\n",
      "5 2 5 log2 gini False 200 42: Macro 0.708254 (0.105698)\n",
      "Testing 2344/4320\n",
      "5 2 5 log2 gini False 500 42: Weighted 0.807424 (0.072763)\n",
      "5 2 5 log2 gini False 500 42: Macro 0.700746 (0.100438)\n",
      "Testing 2345/4320\n",
      "5 2 5 log2 entropy True 50 42: Weighted 0.812273 (0.066532)\n",
      "5 2 5 log2 entropy True 50 42: Macro 0.708892 (0.086748)\n",
      "Testing 2346/4320\n",
      "5 2 5 log2 entropy True 100 42: Weighted 0.816479 (0.060140)\n",
      "5 2 5 log2 entropy True 100 42: Macro 0.714106 (0.078743)\n",
      "Testing 2347/4320\n",
      "5 2 5 log2 entropy True 200 42: Weighted 0.824944 (0.068314)\n",
      "5 2 5 log2 entropy True 200 42: Macro 0.729105 (0.091308)\n",
      "Testing 2348/4320\n",
      "5 2 5 log2 entropy True 500 42: Weighted 0.811863 (0.058581)\n",
      "5 2 5 log2 entropy True 500 42: Macro 0.704330 (0.074545)\n",
      "Testing 2349/4320\n",
      "5 2 5 log2 entropy False 50 42: Weighted 0.794694 (0.077250)\n",
      "5 2 5 log2 entropy False 50 42: Macro 0.678704 (0.111419)\n",
      "Testing 2350/4320\n",
      "5 2 5 log2 entropy False 100 42: Weighted 0.794694 (0.077250)\n",
      "5 2 5 log2 entropy False 100 42: Macro 0.678704 (0.111419)\n",
      "Testing 2351/4320\n",
      "5 2 5 log2 entropy False 200 42: Weighted 0.794694 (0.077250)\n",
      "5 2 5 log2 entropy False 200 42: Macro 0.678704 (0.111419)\n",
      "Testing 2352/4320\n",
      "5 2 5 log2 entropy False 500 42: Weighted 0.794694 (0.077250)\n",
      "5 2 5 log2 entropy False 500 42: Macro 0.678704 (0.111419)\n",
      "Testing 2353/4320\n",
      "5 2 5 sqrt gini True 50 42: Weighted 0.821407 (0.062892)\n",
      "5 2 5 sqrt gini True 50 42: Macro 0.721614 (0.084166)\n",
      "Testing 2354/4320\n",
      "5 2 5 sqrt gini True 100 42: Weighted 0.821407 (0.062892)\n",
      "5 2 5 sqrt gini True 100 42: Macro 0.721614 (0.084166)\n",
      "Testing 2355/4320\n",
      "5 2 5 sqrt gini True 200 42: Weighted 0.821047 (0.065875)\n",
      "5 2 5 sqrt gini True 200 42: Macro 0.718434 (0.086014)\n",
      "Testing 2356/4320\n",
      "5 2 5 sqrt gini True 500 42: Weighted 0.816624 (0.060205)\n",
      "5 2 5 sqrt gini True 500 42: Macro 0.711473 (0.077270)\n",
      "Testing 2357/4320\n",
      "5 2 5 sqrt gini False 50 42: Weighted 0.812352 (0.075646)\n",
      "5 2 5 sqrt gini False 50 42: Macro 0.708254 (0.105698)\n",
      "Testing 2358/4320\n",
      "5 2 5 sqrt gini False 100 42: Weighted 0.807424 (0.072763)\n",
      "5 2 5 sqrt gini False 100 42: Macro 0.700746 (0.100438)\n",
      "Testing 2359/4320\n",
      "5 2 5 sqrt gini False 200 42: Weighted 0.812352 (0.075646)\n",
      "5 2 5 sqrt gini False 200 42: Macro 0.708254 (0.105698)\n",
      "Testing 2360/4320\n",
      "5 2 5 sqrt gini False 500 42: Weighted 0.807424 (0.072763)\n",
      "5 2 5 sqrt gini False 500 42: Macro 0.700746 (0.100438)\n",
      "Testing 2361/4320\n",
      "5 2 5 sqrt entropy True 50 42: Weighted 0.812273 (0.066532)\n",
      "5 2 5 sqrt entropy True 50 42: Macro 0.708892 (0.086748)\n",
      "Testing 2362/4320\n",
      "5 2 5 sqrt entropy True 100 42: Weighted 0.816479 (0.060140)\n",
      "5 2 5 sqrt entropy True 100 42: Macro 0.714106 (0.078743)\n",
      "Testing 2363/4320\n",
      "5 2 5 sqrt entropy True 200 42: Weighted 0.824944 (0.068314)\n",
      "5 2 5 sqrt entropy True 200 42: Macro 0.729105 (0.091308)\n",
      "Testing 2364/4320\n",
      "5 2 5 sqrt entropy True 500 42: Weighted 0.811863 (0.058581)\n",
      "5 2 5 sqrt entropy True 500 42: Macro 0.704330 (0.074545)\n",
      "Testing 2365/4320\n",
      "5 2 5 sqrt entropy False 50 42: Weighted 0.794694 (0.077250)\n",
      "5 2 5 sqrt entropy False 50 42: Macro 0.678704 (0.111419)\n",
      "Testing 2366/4320\n",
      "5 2 5 sqrt entropy False 100 42: Weighted 0.794694 (0.077250)\n",
      "5 2 5 sqrt entropy False 100 42: Macro 0.678704 (0.111419)\n",
      "Testing 2367/4320\n",
      "5 2 5 sqrt entropy False 200 42: Weighted 0.794694 (0.077250)\n",
      "5 2 5 sqrt entropy False 200 42: Macro 0.678704 (0.111419)\n",
      "Testing 2368/4320\n",
      "5 2 5 sqrt entropy False 500 42: Weighted 0.794694 (0.077250)\n",
      "5 2 5 sqrt entropy False 500 42: Macro 0.678704 (0.111419)\n",
      "Testing 2369/4320\n",
      "5 2 8 log2 gini True 50 42: Weighted 0.822393 (0.069322)\n",
      "5 2 8 log2 gini True 50 42: Macro 0.723551 (0.093651)\n",
      "Testing 2370/4320\n",
      "5 2 8 log2 gini True 100 42: Weighted 0.812229 (0.061512)\n",
      "5 2 8 log2 gini True 100 42: Macro 0.706711 (0.078634)\n",
      "Testing 2371/4320\n",
      "5 2 8 log2 gini True 200 42: Weighted 0.815739 (0.060394)\n",
      "5 2 8 log2 gini True 200 42: Macro 0.712002 (0.077172)\n",
      "Testing 2372/4320\n",
      "5 2 8 log2 gini True 500 42: Weighted 0.807467 (0.059573)\n",
      "5 2 8 log2 gini True 500 42: Macro 0.699568 (0.075508)\n",
      "Testing 2373/4320\n",
      "5 2 8 log2 gini False 50 42: Weighted 0.800716 (0.070617)\n",
      "5 2 8 log2 gini False 50 42: Macro 0.690004 (0.097727)\n",
      "Testing 2374/4320\n",
      "5 2 8 log2 gini False 100 42: Weighted 0.799509 (0.066413)\n",
      "5 2 8 log2 gini False 100 42: Macro 0.686191 (0.090167)\n",
      "Testing 2375/4320\n",
      "5 2 8 log2 gini False 200 42: Weighted 0.809296 (0.071955)\n",
      "5 2 8 log2 gini False 200 42: Macro 0.702618 (0.101231)\n",
      "Testing 2376/4320\n",
      "5 2 8 log2 gini False 500 42: Weighted 0.804333 (0.068679)\n",
      "5 2 8 log2 gini False 500 42: Macro 0.693402 (0.094129)\n",
      "Testing 2377/4320\n",
      "5 2 8 log2 entropy True 50 42: Weighted 0.813446 (0.066368)\n",
      "5 2 8 log2 entropy True 50 42: Macro 0.711688 (0.088782)\n",
      "Testing 2378/4320\n",
      "5 2 8 log2 entropy True 100 42: Weighted 0.812084 (0.061437)\n",
      "5 2 8 log2 entropy True 100 42: Macro 0.709344 (0.080237)\n",
      "Testing 2379/4320\n",
      "5 2 8 log2 entropy True 200 42: Weighted 0.820162 (0.066106)\n",
      "5 2 8 log2 entropy True 200 42: Macro 0.718964 (0.085882)\n",
      "Testing 2380/4320\n",
      "5 2 8 log2 entropy True 500 42: Weighted 0.810977 (0.058703)\n",
      "5 2 8 log2 entropy True 500 42: Macro 0.704859 (0.074493)\n",
      "Testing 2381/4320\n",
      "5 2 8 log2 entropy False 50 42: Weighted 0.803707 (0.072581)\n",
      "5 2 8 log2 entropy False 50 42: Macro 0.694649 (0.100074)\n",
      "Testing 2382/4320\n",
      "5 2 8 log2 entropy False 100 42: Weighted 0.799284 (0.066331)\n",
      "5 2 8 log2 entropy False 100 42: Macro 0.687687 (0.090862)\n",
      "Testing 2383/4320\n",
      "5 2 8 log2 entropy False 200 42: Weighted 0.795632 (0.068042)\n",
      "5 2 8 log2 entropy False 200 42: Macro 0.682581 (0.093015)\n",
      "Testing 2384/4320\n",
      "5 2 8 log2 entropy False 500 42: Weighted 0.799284 (0.066331)\n",
      "5 2 8 log2 entropy False 500 42: Macro 0.687687 (0.090862)\n",
      "Testing 2385/4320\n",
      "5 2 8 sqrt gini True 50 42: Weighted 0.822393 (0.069322)\n",
      "5 2 8 sqrt gini True 50 42: Macro 0.723551 (0.093651)\n",
      "Testing 2386/4320\n",
      "5 2 8 sqrt gini True 100 42: Weighted 0.812229 (0.061512)\n",
      "5 2 8 sqrt gini True 100 42: Macro 0.706711 (0.078634)\n",
      "Testing 2387/4320\n",
      "5 2 8 sqrt gini True 200 42: Weighted 0.815739 (0.060394)\n",
      "5 2 8 sqrt gini True 200 42: Macro 0.712002 (0.077172)\n",
      "Testing 2388/4320\n",
      "5 2 8 sqrt gini True 500 42: Weighted 0.807467 (0.059573)\n",
      "5 2 8 sqrt gini True 500 42: Macro 0.699568 (0.075508)\n",
      "Testing 2389/4320\n",
      "5 2 8 sqrt gini False 50 42: Weighted 0.800716 (0.070617)\n",
      "5 2 8 sqrt gini False 50 42: Macro 0.690004 (0.097727)\n",
      "Testing 2390/4320\n",
      "5 2 8 sqrt gini False 100 42: Weighted 0.799509 (0.066413)\n",
      "5 2 8 sqrt gini False 100 42: Macro 0.686191 (0.090167)\n",
      "Testing 2391/4320\n",
      "5 2 8 sqrt gini False 200 42: Weighted 0.809296 (0.071955)\n",
      "5 2 8 sqrt gini False 200 42: Macro 0.702618 (0.101231)\n",
      "Testing 2392/4320\n",
      "5 2 8 sqrt gini False 500 42: Weighted 0.804333 (0.068679)\n",
      "5 2 8 sqrt gini False 500 42: Macro 0.693402 (0.094129)\n",
      "Testing 2393/4320\n",
      "5 2 8 sqrt entropy True 50 42: Weighted 0.813446 (0.066368)\n",
      "5 2 8 sqrt entropy True 50 42: Macro 0.711688 (0.088782)\n",
      "Testing 2394/4320\n",
      "5 2 8 sqrt entropy True 100 42: Weighted 0.812084 (0.061437)\n",
      "5 2 8 sqrt entropy True 100 42: Macro 0.709344 (0.080237)\n",
      "Testing 2395/4320\n",
      "5 2 8 sqrt entropy True 200 42: Weighted 0.820162 (0.066106)\n",
      "5 2 8 sqrt entropy True 200 42: Macro 0.718964 (0.085882)\n",
      "Testing 2396/4320\n",
      "5 2 8 sqrt entropy True 500 42: Weighted 0.810977 (0.058703)\n",
      "5 2 8 sqrt entropy True 500 42: Macro 0.704859 (0.074493)\n",
      "Testing 2397/4320\n",
      "5 2 8 sqrt entropy False 50 42: Weighted 0.803707 (0.072581)\n",
      "5 2 8 sqrt entropy False 50 42: Macro 0.694649 (0.100074)\n",
      "Testing 2398/4320\n",
      "5 2 8 sqrt entropy False 100 42: Weighted 0.799284 (0.066331)\n",
      "5 2 8 sqrt entropy False 100 42: Macro 0.687687 (0.090862)\n",
      "Testing 2399/4320\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 2 8 sqrt entropy False 200 42: Weighted 0.795632 (0.068042)\n",
      "5 2 8 sqrt entropy False 200 42: Macro 0.682581 (0.093015)\n",
      "Testing 2400/4320\n",
      "5 2 8 sqrt entropy False 500 42: Weighted 0.799284 (0.066331)\n",
      "5 2 8 sqrt entropy False 500 42: Macro 0.687687 (0.090862)\n",
      "Testing 2401/4320\n",
      "5 4 3 log2 gini True 50 42: Weighted 0.805267 (0.056365)\n",
      "5 4 3 log2 gini True 50 42: Macro 0.698061 (0.077107)\n",
      "Testing 2402/4320\n",
      "5 4 3 log2 gini True 100 42: Weighted 0.809935 (0.060810)\n",
      "5 4 3 log2 gini True 100 42: Macro 0.704820 (0.082311)\n",
      "Testing 2403/4320\n",
      "5 4 3 log2 gini True 200 42: Weighted 0.809935 (0.060810)\n",
      "5 4 3 log2 gini True 200 42: Macro 0.704820 (0.082311)\n",
      "Testing 2404/4320\n",
      "5 4 3 log2 gini True 500 42: Weighted 0.809014 (0.051630)\n",
      "5 4 3 log2 gini True 500 42: Macro 0.702391 (0.068382)\n",
      "Testing 2405/4320\n",
      "5 4 3 log2 gini False 50 42: Weighted 0.801111 (0.073505)\n",
      "5 4 3 log2 gini False 50 42: Macro 0.696487 (0.093893)\n",
      "Testing 2406/4320\n",
      "5 4 3 log2 gini False 100 42: Weighted 0.804638 (0.057485)\n",
      "5 4 3 log2 gini False 100 42: Macro 0.700234 (0.071178)\n",
      "Testing 2407/4320\n",
      "5 4 3 log2 gini False 200 42: Weighted 0.793563 (0.090270)\n",
      "5 4 3 log2 gini False 200 42: Macro 0.688455 (0.112395)\n",
      "Testing 2408/4320\n",
      "5 4 3 log2 gini False 500 42: Weighted 0.798644 (0.070719)\n",
      "5 4 3 log2 gini False 500 42: Macro 0.693509 (0.086134)\n",
      "Testing 2409/4320\n",
      "5 4 3 log2 entropy True 50 42: Weighted 0.801060 (0.062389)\n",
      "5 4 3 log2 entropy True 50 42: Macro 0.692847 (0.084279)\n",
      "Testing 2410/4320\n",
      "5 4 3 log2 entropy True 100 42: Weighted 0.809935 (0.060810)\n",
      "5 4 3 log2 entropy True 100 42: Macro 0.704820 (0.082311)\n",
      "Testing 2411/4320\n",
      "5 4 3 log2 entropy True 200 42: Weighted 0.805728 (0.066727)\n",
      "5 4 3 log2 entropy True 200 42: Macro 0.699607 (0.089460)\n",
      "Testing 2412/4320\n",
      "5 4 3 log2 entropy True 500 42: Weighted 0.805007 (0.056975)\n",
      "5 4 3 log2 entropy True 500 42: Macro 0.697312 (0.075095)\n",
      "Testing 2413/4320\n",
      "5 4 3 log2 entropy False 50 42: Weighted 0.777448 (0.083265)\n",
      "5 4 3 log2 entropy False 50 42: Macro 0.665820 (0.097952)\n",
      "Testing 2414/4320\n",
      "5 4 3 log2 entropy False 100 42: Weighted 0.798644 (0.070719)\n",
      "5 4 3 log2 entropy False 100 42: Macro 0.693509 (0.086134)\n",
      "Testing 2415/4320\n",
      "5 4 3 log2 entropy False 200 42: Weighted 0.787834 (0.088117)\n",
      "5 4 3 log2 entropy False 200 42: Macro 0.680688 (0.106489)\n",
      "Testing 2416/4320\n",
      "5 4 3 log2 entropy False 500 42: Weighted 0.787834 (0.088117)\n",
      "5 4 3 log2 entropy False 500 42: Macro 0.680688 (0.106489)\n",
      "Testing 2417/4320\n",
      "5 4 3 sqrt gini True 50 42: Weighted 0.805267 (0.056365)\n",
      "5 4 3 sqrt gini True 50 42: Macro 0.698061 (0.077107)\n",
      "Testing 2418/4320\n",
      "5 4 3 sqrt gini True 100 42: Weighted 0.809935 (0.060810)\n",
      "5 4 3 sqrt gini True 100 42: Macro 0.704820 (0.082311)\n",
      "Testing 2419/4320\n",
      "5 4 3 sqrt gini True 200 42: Weighted 0.809935 (0.060810)\n",
      "5 4 3 sqrt gini True 200 42: Macro 0.704820 (0.082311)\n",
      "Testing 2420/4320\n",
      "5 4 3 sqrt gini True 500 42: Weighted 0.809014 (0.051630)\n",
      "5 4 3 sqrt gini True 500 42: Macro 0.702391 (0.068382)\n",
      "Testing 2421/4320\n",
      "5 4 3 sqrt gini False 50 42: Weighted 0.801111 (0.073505)\n",
      "5 4 3 sqrt gini False 50 42: Macro 0.696487 (0.093893)\n",
      "Testing 2422/4320\n",
      "5 4 3 sqrt gini False 100 42: Weighted 0.804638 (0.057485)\n",
      "5 4 3 sqrt gini False 100 42: Macro 0.700234 (0.071178)\n",
      "Testing 2423/4320\n",
      "5 4 3 sqrt gini False 200 42: Weighted 0.793563 (0.090270)\n",
      "5 4 3 sqrt gini False 200 42: Macro 0.688455 (0.112395)\n",
      "Testing 2424/4320\n",
      "5 4 3 sqrt gini False 500 42: Weighted 0.798644 (0.070719)\n",
      "5 4 3 sqrt gini False 500 42: Macro 0.693509 (0.086134)\n",
      "Testing 2425/4320\n",
      "5 4 3 sqrt entropy True 50 42: Weighted 0.801060 (0.062389)\n",
      "5 4 3 sqrt entropy True 50 42: Macro 0.692847 (0.084279)\n",
      "Testing 2426/4320\n",
      "5 4 3 sqrt entropy True 100 42: Weighted 0.809935 (0.060810)\n",
      "5 4 3 sqrt entropy True 100 42: Macro 0.704820 (0.082311)\n",
      "Testing 2427/4320\n",
      "5 4 3 sqrt entropy True 200 42: Weighted 0.805728 (0.066727)\n",
      "5 4 3 sqrt entropy True 200 42: Macro 0.699607 (0.089460)\n",
      "Testing 2428/4320\n",
      "5 4 3 sqrt entropy True 500 42: Weighted 0.805007 (0.056975)\n",
      "5 4 3 sqrt entropy True 500 42: Macro 0.697312 (0.075095)\n",
      "Testing 2429/4320\n",
      "5 4 3 sqrt entropy False 50 42: Weighted 0.777448 (0.083265)\n",
      "5 4 3 sqrt entropy False 50 42: Macro 0.665820 (0.097952)\n",
      "Testing 2430/4320\n",
      "5 4 3 sqrt entropy False 100 42: Weighted 0.798644 (0.070719)\n",
      "5 4 3 sqrt entropy False 100 42: Macro 0.693509 (0.086134)\n",
      "Testing 2431/4320\n",
      "5 4 3 sqrt entropy False 200 42: Weighted 0.787834 (0.088117)\n",
      "5 4 3 sqrt entropy False 200 42: Macro 0.680688 (0.106489)\n",
      "Testing 2432/4320\n",
      "5 4 3 sqrt entropy False 500 42: Weighted 0.787834 (0.088117)\n",
      "5 4 3 sqrt entropy False 500 42: Macro 0.680688 (0.106489)\n",
      "Testing 2433/4320\n",
      "5 4 5 log2 gini True 50 42: Weighted 0.821407 (0.062892)\n",
      "5 4 5 log2 gini True 50 42: Macro 0.721614 (0.084166)\n",
      "Testing 2434/4320\n",
      "5 4 5 log2 gini True 100 42: Weighted 0.821407 (0.062892)\n",
      "5 4 5 log2 gini True 100 42: Macro 0.721614 (0.084166)\n",
      "Testing 2435/4320\n",
      "5 4 5 log2 gini True 200 42: Weighted 0.821047 (0.065875)\n",
      "5 4 5 log2 gini True 200 42: Macro 0.718434 (0.086014)\n",
      "Testing 2436/4320\n",
      "5 4 5 log2 gini True 500 42: Weighted 0.816624 (0.060205)\n",
      "5 4 5 log2 gini True 500 42: Macro 0.711473 (0.077270)\n",
      "Testing 2437/4320\n",
      "5 4 5 log2 gini False 50 42: Weighted 0.812352 (0.075646)\n",
      "5 4 5 log2 gini False 50 42: Macro 0.708254 (0.105698)\n",
      "Testing 2438/4320\n",
      "5 4 5 log2 gini False 100 42: Weighted 0.807424 (0.072763)\n",
      "5 4 5 log2 gini False 100 42: Macro 0.700746 (0.100438)\n",
      "Testing 2439/4320\n",
      "5 4 5 log2 gini False 200 42: Weighted 0.812352 (0.075646)\n",
      "5 4 5 log2 gini False 200 42: Macro 0.708254 (0.105698)\n",
      "Testing 2440/4320\n",
      "5 4 5 log2 gini False 500 42: Weighted 0.807424 (0.072763)\n",
      "5 4 5 log2 gini False 500 42: Macro 0.700746 (0.100438)\n",
      "Testing 2441/4320\n",
      "5 4 5 log2 entropy True 50 42: Weighted 0.812273 (0.066532)\n",
      "5 4 5 log2 entropy True 50 42: Macro 0.708892 (0.086748)\n",
      "Testing 2442/4320\n",
      "5 4 5 log2 entropy True 100 42: Weighted 0.816479 (0.060140)\n",
      "5 4 5 log2 entropy True 100 42: Macro 0.714106 (0.078743)\n",
      "Testing 2443/4320\n",
      "5 4 5 log2 entropy True 200 42: Weighted 0.824944 (0.068314)\n",
      "5 4 5 log2 entropy True 200 42: Macro 0.729105 (0.091308)\n",
      "Testing 2444/4320\n",
      "5 4 5 log2 entropy True 500 42: Weighted 0.811863 (0.058581)\n",
      "5 4 5 log2 entropy True 500 42: Macro 0.704330 (0.074545)\n",
      "Testing 2445/4320\n",
      "5 4 5 log2 entropy False 50 42: Weighted 0.794694 (0.077250)\n",
      "5 4 5 log2 entropy False 50 42: Macro 0.678704 (0.111419)\n",
      "Testing 2446/4320\n",
      "5 4 5 log2 entropy False 100 42: Weighted 0.794694 (0.077250)\n",
      "5 4 5 log2 entropy False 100 42: Macro 0.678704 (0.111419)\n",
      "Testing 2447/4320\n",
      "5 4 5 log2 entropy False 200 42: Weighted 0.794694 (0.077250)\n",
      "5 4 5 log2 entropy False 200 42: Macro 0.678704 (0.111419)\n",
      "Testing 2448/4320\n",
      "5 4 5 log2 entropy False 500 42: Weighted 0.794694 (0.077250)\n",
      "5 4 5 log2 entropy False 500 42: Macro 0.678704 (0.111419)\n",
      "Testing 2449/4320\n",
      "5 4 5 sqrt gini True 50 42: Weighted 0.821407 (0.062892)\n",
      "5 4 5 sqrt gini True 50 42: Macro 0.721614 (0.084166)\n",
      "Testing 2450/4320\n",
      "5 4 5 sqrt gini True 100 42: Weighted 0.821407 (0.062892)\n",
      "5 4 5 sqrt gini True 100 42: Macro 0.721614 (0.084166)\n",
      "Testing 2451/4320\n",
      "5 4 5 sqrt gini True 200 42: Weighted 0.821047 (0.065875)\n",
      "5 4 5 sqrt gini True 200 42: Macro 0.718434 (0.086014)\n",
      "Testing 2452/4320\n",
      "5 4 5 sqrt gini True 500 42: Weighted 0.816624 (0.060205)\n",
      "5 4 5 sqrt gini True 500 42: Macro 0.711473 (0.077270)\n",
      "Testing 2453/4320\n",
      "5 4 5 sqrt gini False 50 42: Weighted 0.812352 (0.075646)\n",
      "5 4 5 sqrt gini False 50 42: Macro 0.708254 (0.105698)\n",
      "Testing 2454/4320\n",
      "5 4 5 sqrt gini False 100 42: Weighted 0.807424 (0.072763)\n",
      "5 4 5 sqrt gini False 100 42: Macro 0.700746 (0.100438)\n",
      "Testing 2455/4320\n",
      "5 4 5 sqrt gini False 200 42: Weighted 0.812352 (0.075646)\n",
      "5 4 5 sqrt gini False 200 42: Macro 0.708254 (0.105698)\n",
      "Testing 2456/4320\n",
      "5 4 5 sqrt gini False 500 42: Weighted 0.807424 (0.072763)\n",
      "5 4 5 sqrt gini False 500 42: Macro 0.700746 (0.100438)\n",
      "Testing 2457/4320\n",
      "5 4 5 sqrt entropy True 50 42: Weighted 0.812273 (0.066532)\n",
      "5 4 5 sqrt entropy True 50 42: Macro 0.708892 (0.086748)\n",
      "Testing 2458/4320\n",
      "5 4 5 sqrt entropy True 100 42: Weighted 0.816479 (0.060140)\n",
      "5 4 5 sqrt entropy True 100 42: Macro 0.714106 (0.078743)\n",
      "Testing 2459/4320\n",
      "5 4 5 sqrt entropy True 200 42: Weighted 0.824944 (0.068314)\n",
      "5 4 5 sqrt entropy True 200 42: Macro 0.729105 (0.091308)\n",
      "Testing 2460/4320\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 4 5 sqrt entropy True 500 42: Weighted 0.811863 (0.058581)\n",
      "5 4 5 sqrt entropy True 500 42: Macro 0.704330 (0.074545)\n",
      "Testing 2461/4320\n",
      "5 4 5 sqrt entropy False 50 42: Weighted 0.794694 (0.077250)\n",
      "5 4 5 sqrt entropy False 50 42: Macro 0.678704 (0.111419)\n",
      "Testing 2462/4320\n",
      "5 4 5 sqrt entropy False 100 42: Weighted 0.794694 (0.077250)\n",
      "5 4 5 sqrt entropy False 100 42: Macro 0.678704 (0.111419)\n",
      "Testing 2463/4320\n",
      "5 4 5 sqrt entropy False 200 42: Weighted 0.794694 (0.077250)\n",
      "5 4 5 sqrt entropy False 200 42: Macro 0.678704 (0.111419)\n",
      "Testing 2464/4320\n",
      "5 4 5 sqrt entropy False 500 42: Weighted 0.794694 (0.077250)\n",
      "5 4 5 sqrt entropy False 500 42: Macro 0.678704 (0.111419)\n",
      "Testing 2465/4320\n",
      "5 4 8 log2 gini True 50 42: Weighted 0.822393 (0.069322)\n",
      "5 4 8 log2 gini True 50 42: Macro 0.723551 (0.093651)\n",
      "Testing 2466/4320\n",
      "5 4 8 log2 gini True 100 42: Weighted 0.812229 (0.061512)\n",
      "5 4 8 log2 gini True 100 42: Macro 0.706711 (0.078634)\n",
      "Testing 2467/4320\n",
      "5 4 8 log2 gini True 200 42: Weighted 0.815739 (0.060394)\n",
      "5 4 8 log2 gini True 200 42: Macro 0.712002 (0.077172)\n",
      "Testing 2468/4320\n",
      "5 4 8 log2 gini True 500 42: Weighted 0.807467 (0.059573)\n",
      "5 4 8 log2 gini True 500 42: Macro 0.699568 (0.075508)\n",
      "Testing 2469/4320\n",
      "5 4 8 log2 gini False 50 42: Weighted 0.800716 (0.070617)\n",
      "5 4 8 log2 gini False 50 42: Macro 0.690004 (0.097727)\n",
      "Testing 2470/4320\n",
      "5 4 8 log2 gini False 100 42: Weighted 0.799509 (0.066413)\n",
      "5 4 8 log2 gini False 100 42: Macro 0.686191 (0.090167)\n",
      "Testing 2471/4320\n",
      "5 4 8 log2 gini False 200 42: Weighted 0.809296 (0.071955)\n",
      "5 4 8 log2 gini False 200 42: Macro 0.702618 (0.101231)\n",
      "Testing 2472/4320\n",
      "5 4 8 log2 gini False 500 42: Weighted 0.804333 (0.068679)\n",
      "5 4 8 log2 gini False 500 42: Macro 0.693402 (0.094129)\n",
      "Testing 2473/4320\n",
      "5 4 8 log2 entropy True 50 42: Weighted 0.813446 (0.066368)\n",
      "5 4 8 log2 entropy True 50 42: Macro 0.711688 (0.088782)\n",
      "Testing 2474/4320\n",
      "5 4 8 log2 entropy True 100 42: Weighted 0.812084 (0.061437)\n",
      "5 4 8 log2 entropy True 100 42: Macro 0.709344 (0.080237)\n",
      "Testing 2475/4320\n",
      "5 4 8 log2 entropy True 200 42: Weighted 0.820162 (0.066106)\n",
      "5 4 8 log2 entropy True 200 42: Macro 0.718964 (0.085882)\n",
      "Testing 2476/4320\n",
      "5 4 8 log2 entropy True 500 42: Weighted 0.810977 (0.058703)\n",
      "5 4 8 log2 entropy True 500 42: Macro 0.704859 (0.074493)\n",
      "Testing 2477/4320\n",
      "5 4 8 log2 entropy False 50 42: Weighted 0.803707 (0.072581)\n",
      "5 4 8 log2 entropy False 50 42: Macro 0.694649 (0.100074)\n",
      "Testing 2478/4320\n",
      "5 4 8 log2 entropy False 100 42: Weighted 0.799284 (0.066331)\n",
      "5 4 8 log2 entropy False 100 42: Macro 0.687687 (0.090862)\n",
      "Testing 2479/4320\n",
      "5 4 8 log2 entropy False 200 42: Weighted 0.795632 (0.068042)\n",
      "5 4 8 log2 entropy False 200 42: Macro 0.682581 (0.093015)\n",
      "Testing 2480/4320\n",
      "5 4 8 log2 entropy False 500 42: Weighted 0.799284 (0.066331)\n",
      "5 4 8 log2 entropy False 500 42: Macro 0.687687 (0.090862)\n",
      "Testing 2481/4320\n",
      "5 4 8 sqrt gini True 50 42: Weighted 0.822393 (0.069322)\n",
      "5 4 8 sqrt gini True 50 42: Macro 0.723551 (0.093651)\n",
      "Testing 2482/4320\n",
      "5 4 8 sqrt gini True 100 42: Weighted 0.812229 (0.061512)\n",
      "5 4 8 sqrt gini True 100 42: Macro 0.706711 (0.078634)\n",
      "Testing 2483/4320\n",
      "5 4 8 sqrt gini True 200 42: Weighted 0.815739 (0.060394)\n",
      "5 4 8 sqrt gini True 200 42: Macro 0.712002 (0.077172)\n",
      "Testing 2484/4320\n",
      "5 4 8 sqrt gini True 500 42: Weighted 0.807467 (0.059573)\n",
      "5 4 8 sqrt gini True 500 42: Macro 0.699568 (0.075508)\n",
      "Testing 2485/4320\n",
      "5 4 8 sqrt gini False 50 42: Weighted 0.800716 (0.070617)\n",
      "5 4 8 sqrt gini False 50 42: Macro 0.690004 (0.097727)\n",
      "Testing 2486/4320\n",
      "5 4 8 sqrt gini False 100 42: Weighted 0.799509 (0.066413)\n",
      "5 4 8 sqrt gini False 100 42: Macro 0.686191 (0.090167)\n",
      "Testing 2487/4320\n",
      "5 4 8 sqrt gini False 200 42: Weighted 0.809296 (0.071955)\n",
      "5 4 8 sqrt gini False 200 42: Macro 0.702618 (0.101231)\n",
      "Testing 2488/4320\n",
      "5 4 8 sqrt gini False 500 42: Weighted 0.804333 (0.068679)\n",
      "5 4 8 sqrt gini False 500 42: Macro 0.693402 (0.094129)\n",
      "Testing 2489/4320\n",
      "5 4 8 sqrt entropy True 50 42: Weighted 0.813446 (0.066368)\n",
      "5 4 8 sqrt entropy True 50 42: Macro 0.711688 (0.088782)\n",
      "Testing 2490/4320\n",
      "5 4 8 sqrt entropy True 100 42: Weighted 0.812084 (0.061437)\n",
      "5 4 8 sqrt entropy True 100 42: Macro 0.709344 (0.080237)\n",
      "Testing 2491/4320\n",
      "5 4 8 sqrt entropy True 200 42: Weighted 0.820162 (0.066106)\n",
      "5 4 8 sqrt entropy True 200 42: Macro 0.718964 (0.085882)\n",
      "Testing 2492/4320\n",
      "5 4 8 sqrt entropy True 500 42: Weighted 0.810977 (0.058703)\n",
      "5 4 8 sqrt entropy True 500 42: Macro 0.704859 (0.074493)\n",
      "Testing 2493/4320\n",
      "5 4 8 sqrt entropy False 50 42: Weighted 0.803707 (0.072581)\n",
      "5 4 8 sqrt entropy False 50 42: Macro 0.694649 (0.100074)\n",
      "Testing 2494/4320\n",
      "5 4 8 sqrt entropy False 100 42: Weighted 0.799284 (0.066331)\n",
      "5 4 8 sqrt entropy False 100 42: Macro 0.687687 (0.090862)\n",
      "Testing 2495/4320\n",
      "5 4 8 sqrt entropy False 200 42: Weighted 0.795632 (0.068042)\n",
      "5 4 8 sqrt entropy False 200 42: Macro 0.682581 (0.093015)\n",
      "Testing 2496/4320\n",
      "5 4 8 sqrt entropy False 500 42: Weighted 0.799284 (0.066331)\n",
      "5 4 8 sqrt entropy False 500 42: Macro 0.687687 (0.090862)\n",
      "Testing 2497/4320\n",
      "5 6 3 log2 gini True 50 42: Weighted 0.805267 (0.056365)\n",
      "5 6 3 log2 gini True 50 42: Macro 0.698061 (0.077107)\n",
      "Testing 2498/4320\n",
      "5 6 3 log2 gini True 100 42: Weighted 0.809935 (0.060810)\n",
      "5 6 3 log2 gini True 100 42: Macro 0.704820 (0.082311)\n",
      "Testing 2499/4320\n",
      "5 6 3 log2 gini True 200 42: Weighted 0.809935 (0.060810)\n",
      "5 6 3 log2 gini True 200 42: Macro 0.704820 (0.082311)\n",
      "Testing 2500/4320\n",
      "5 6 3 log2 gini True 500 42: Weighted 0.809014 (0.051630)\n",
      "5 6 3 log2 gini True 500 42: Macro 0.702391 (0.068382)\n",
      "Testing 2501/4320\n",
      "5 6 3 log2 gini False 50 42: Weighted 0.801111 (0.073505)\n",
      "5 6 3 log2 gini False 50 42: Macro 0.696487 (0.093893)\n",
      "Testing 2502/4320\n",
      "5 6 3 log2 gini False 100 42: Weighted 0.804638 (0.057485)\n",
      "5 6 3 log2 gini False 100 42: Macro 0.700234 (0.071178)\n",
      "Testing 2503/4320\n",
      "5 6 3 log2 gini False 200 42: Weighted 0.793563 (0.090270)\n",
      "5 6 3 log2 gini False 200 42: Macro 0.688455 (0.112395)\n",
      "Testing 2504/4320\n",
      "5 6 3 log2 gini False 500 42: Weighted 0.798644 (0.070719)\n",
      "5 6 3 log2 gini False 500 42: Macro 0.693509 (0.086134)\n",
      "Testing 2505/4320\n",
      "5 6 3 log2 entropy True 50 42: Weighted 0.801060 (0.062389)\n",
      "5 6 3 log2 entropy True 50 42: Macro 0.692847 (0.084279)\n",
      "Testing 2506/4320\n",
      "5 6 3 log2 entropy True 100 42: Weighted 0.809935 (0.060810)\n",
      "5 6 3 log2 entropy True 100 42: Macro 0.704820 (0.082311)\n",
      "Testing 2507/4320\n",
      "5 6 3 log2 entropy True 200 42: Weighted 0.805728 (0.066727)\n",
      "5 6 3 log2 entropy True 200 42: Macro 0.699607 (0.089460)\n",
      "Testing 2508/4320\n",
      "5 6 3 log2 entropy True 500 42: Weighted 0.805007 (0.056975)\n",
      "5 6 3 log2 entropy True 500 42: Macro 0.697312 (0.075095)\n",
      "Testing 2509/4320\n",
      "5 6 3 log2 entropy False 50 42: Weighted 0.777448 (0.083265)\n",
      "5 6 3 log2 entropy False 50 42: Macro 0.665820 (0.097952)\n",
      "Testing 2510/4320\n",
      "5 6 3 log2 entropy False 100 42: Weighted 0.798644 (0.070719)\n",
      "5 6 3 log2 entropy False 100 42: Macro 0.693509 (0.086134)\n",
      "Testing 2511/4320\n",
      "5 6 3 log2 entropy False 200 42: Weighted 0.787834 (0.088117)\n",
      "5 6 3 log2 entropy False 200 42: Macro 0.680688 (0.106489)\n",
      "Testing 2512/4320\n",
      "5 6 3 log2 entropy False 500 42: Weighted 0.787834 (0.088117)\n",
      "5 6 3 log2 entropy False 500 42: Macro 0.680688 (0.106489)\n",
      "Testing 2513/4320\n",
      "5 6 3 sqrt gini True 50 42: Weighted 0.805267 (0.056365)\n",
      "5 6 3 sqrt gini True 50 42: Macro 0.698061 (0.077107)\n",
      "Testing 2514/4320\n",
      "5 6 3 sqrt gini True 100 42: Weighted 0.809935 (0.060810)\n",
      "5 6 3 sqrt gini True 100 42: Macro 0.704820 (0.082311)\n",
      "Testing 2515/4320\n",
      "5 6 3 sqrt gini True 200 42: Weighted 0.809935 (0.060810)\n",
      "5 6 3 sqrt gini True 200 42: Macro 0.704820 (0.082311)\n",
      "Testing 2516/4320\n",
      "5 6 3 sqrt gini True 500 42: Weighted 0.809014 (0.051630)\n",
      "5 6 3 sqrt gini True 500 42: Macro 0.702391 (0.068382)\n",
      "Testing 2517/4320\n",
      "5 6 3 sqrt gini False 50 42: Weighted 0.801111 (0.073505)\n",
      "5 6 3 sqrt gini False 50 42: Macro 0.696487 (0.093893)\n",
      "Testing 2518/4320\n",
      "5 6 3 sqrt gini False 100 42: Weighted 0.804638 (0.057485)\n",
      "5 6 3 sqrt gini False 100 42: Macro 0.700234 (0.071178)\n",
      "Testing 2519/4320\n",
      "5 6 3 sqrt gini False 200 42: Weighted 0.793563 (0.090270)\n",
      "5 6 3 sqrt gini False 200 42: Macro 0.688455 (0.112395)\n",
      "Testing 2520/4320\n",
      "5 6 3 sqrt gini False 500 42: Weighted 0.798644 (0.070719)\n",
      "5 6 3 sqrt gini False 500 42: Macro 0.693509 (0.086134)\n",
      "Testing 2521/4320\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 6 3 sqrt entropy True 50 42: Weighted 0.801060 (0.062389)\n",
      "5 6 3 sqrt entropy True 50 42: Macro 0.692847 (0.084279)\n",
      "Testing 2522/4320\n",
      "5 6 3 sqrt entropy True 100 42: Weighted 0.809935 (0.060810)\n",
      "5 6 3 sqrt entropy True 100 42: Macro 0.704820 (0.082311)\n",
      "Testing 2523/4320\n",
      "5 6 3 sqrt entropy True 200 42: Weighted 0.805728 (0.066727)\n",
      "5 6 3 sqrt entropy True 200 42: Macro 0.699607 (0.089460)\n",
      "Testing 2524/4320\n",
      "5 6 3 sqrt entropy True 500 42: Weighted 0.805007 (0.056975)\n",
      "5 6 3 sqrt entropy True 500 42: Macro 0.697312 (0.075095)\n",
      "Testing 2525/4320\n",
      "5 6 3 sqrt entropy False 50 42: Weighted 0.777448 (0.083265)\n",
      "5 6 3 sqrt entropy False 50 42: Macro 0.665820 (0.097952)\n",
      "Testing 2526/4320\n",
      "5 6 3 sqrt entropy False 100 42: Weighted 0.798644 (0.070719)\n",
      "5 6 3 sqrt entropy False 100 42: Macro 0.693509 (0.086134)\n",
      "Testing 2527/4320\n",
      "5 6 3 sqrt entropy False 200 42: Weighted 0.787834 (0.088117)\n",
      "5 6 3 sqrt entropy False 200 42: Macro 0.680688 (0.106489)\n",
      "Testing 2528/4320\n",
      "5 6 3 sqrt entropy False 500 42: Weighted 0.787834 (0.088117)\n",
      "5 6 3 sqrt entropy False 500 42: Macro 0.680688 (0.106489)\n",
      "Testing 2529/4320\n",
      "5 6 5 log2 gini True 50 42: Weighted 0.821407 (0.062892)\n",
      "5 6 5 log2 gini True 50 42: Macro 0.721614 (0.084166)\n",
      "Testing 2530/4320\n",
      "5 6 5 log2 gini True 100 42: Weighted 0.821407 (0.062892)\n",
      "5 6 5 log2 gini True 100 42: Macro 0.721614 (0.084166)\n",
      "Testing 2531/4320\n",
      "5 6 5 log2 gini True 200 42: Weighted 0.821047 (0.065875)\n",
      "5 6 5 log2 gini True 200 42: Macro 0.718434 (0.086014)\n",
      "Testing 2532/4320\n",
      "5 6 5 log2 gini True 500 42: Weighted 0.816624 (0.060205)\n",
      "5 6 5 log2 gini True 500 42: Macro 0.711473 (0.077270)\n",
      "Testing 2533/4320\n",
      "5 6 5 log2 gini False 50 42: Weighted 0.812352 (0.075646)\n",
      "5 6 5 log2 gini False 50 42: Macro 0.708254 (0.105698)\n",
      "Testing 2534/4320\n",
      "5 6 5 log2 gini False 100 42: Weighted 0.807424 (0.072763)\n",
      "5 6 5 log2 gini False 100 42: Macro 0.700746 (0.100438)\n",
      "Testing 2535/4320\n",
      "5 6 5 log2 gini False 200 42: Weighted 0.812352 (0.075646)\n",
      "5 6 5 log2 gini False 200 42: Macro 0.708254 (0.105698)\n",
      "Testing 2536/4320\n",
      "5 6 5 log2 gini False 500 42: Weighted 0.807424 (0.072763)\n",
      "5 6 5 log2 gini False 500 42: Macro 0.700746 (0.100438)\n",
      "Testing 2537/4320\n",
      "5 6 5 log2 entropy True 50 42: Weighted 0.812273 (0.066532)\n",
      "5 6 5 log2 entropy True 50 42: Macro 0.708892 (0.086748)\n",
      "Testing 2538/4320\n",
      "5 6 5 log2 entropy True 100 42: Weighted 0.816479 (0.060140)\n",
      "5 6 5 log2 entropy True 100 42: Macro 0.714106 (0.078743)\n",
      "Testing 2539/4320\n",
      "5 6 5 log2 entropy True 200 42: Weighted 0.824944 (0.068314)\n",
      "5 6 5 log2 entropy True 200 42: Macro 0.729105 (0.091308)\n",
      "Testing 2540/4320\n",
      "5 6 5 log2 entropy True 500 42: Weighted 0.811863 (0.058581)\n",
      "5 6 5 log2 entropy True 500 42: Macro 0.704330 (0.074545)\n",
      "Testing 2541/4320\n",
      "5 6 5 log2 entropy False 50 42: Weighted 0.794694 (0.077250)\n",
      "5 6 5 log2 entropy False 50 42: Macro 0.678704 (0.111419)\n",
      "Testing 2542/4320\n",
      "5 6 5 log2 entropy False 100 42: Weighted 0.794694 (0.077250)\n",
      "5 6 5 log2 entropy False 100 42: Macro 0.678704 (0.111419)\n",
      "Testing 2543/4320\n",
      "5 6 5 log2 entropy False 200 42: Weighted 0.794694 (0.077250)\n",
      "5 6 5 log2 entropy False 200 42: Macro 0.678704 (0.111419)\n",
      "Testing 2544/4320\n",
      "5 6 5 log2 entropy False 500 42: Weighted 0.794694 (0.077250)\n",
      "5 6 5 log2 entropy False 500 42: Macro 0.678704 (0.111419)\n",
      "Testing 2545/4320\n",
      "5 6 5 sqrt gini True 50 42: Weighted 0.821407 (0.062892)\n",
      "5 6 5 sqrt gini True 50 42: Macro 0.721614 (0.084166)\n",
      "Testing 2546/4320\n",
      "5 6 5 sqrt gini True 100 42: Weighted 0.821407 (0.062892)\n",
      "5 6 5 sqrt gini True 100 42: Macro 0.721614 (0.084166)\n",
      "Testing 2547/4320\n",
      "5 6 5 sqrt gini True 200 42: Weighted 0.821047 (0.065875)\n",
      "5 6 5 sqrt gini True 200 42: Macro 0.718434 (0.086014)\n",
      "Testing 2548/4320\n",
      "5 6 5 sqrt gini True 500 42: Weighted 0.816624 (0.060205)\n",
      "5 6 5 sqrt gini True 500 42: Macro 0.711473 (0.077270)\n",
      "Testing 2549/4320\n",
      "5 6 5 sqrt gini False 50 42: Weighted 0.812352 (0.075646)\n",
      "5 6 5 sqrt gini False 50 42: Macro 0.708254 (0.105698)\n",
      "Testing 2550/4320\n",
      "5 6 5 sqrt gini False 100 42: Weighted 0.807424 (0.072763)\n",
      "5 6 5 sqrt gini False 100 42: Macro 0.700746 (0.100438)\n",
      "Testing 2551/4320\n",
      "5 6 5 sqrt gini False 200 42: Weighted 0.812352 (0.075646)\n",
      "5 6 5 sqrt gini False 200 42: Macro 0.708254 (0.105698)\n",
      "Testing 2552/4320\n",
      "5 6 5 sqrt gini False 500 42: Weighted 0.807424 (0.072763)\n",
      "5 6 5 sqrt gini False 500 42: Macro 0.700746 (0.100438)\n",
      "Testing 2553/4320\n",
      "5 6 5 sqrt entropy True 50 42: Weighted 0.812273 (0.066532)\n",
      "5 6 5 sqrt entropy True 50 42: Macro 0.708892 (0.086748)\n",
      "Testing 2554/4320\n",
      "5 6 5 sqrt entropy True 100 42: Weighted 0.816479 (0.060140)\n",
      "5 6 5 sqrt entropy True 100 42: Macro 0.714106 (0.078743)\n",
      "Testing 2555/4320\n",
      "5 6 5 sqrt entropy True 200 42: Weighted 0.824944 (0.068314)\n",
      "5 6 5 sqrt entropy True 200 42: Macro 0.729105 (0.091308)\n",
      "Testing 2556/4320\n",
      "5 6 5 sqrt entropy True 500 42: Weighted 0.811863 (0.058581)\n",
      "5 6 5 sqrt entropy True 500 42: Macro 0.704330 (0.074545)\n",
      "Testing 2557/4320\n",
      "5 6 5 sqrt entropy False 50 42: Weighted 0.794694 (0.077250)\n",
      "5 6 5 sqrt entropy False 50 42: Macro 0.678704 (0.111419)\n",
      "Testing 2558/4320\n",
      "5 6 5 sqrt entropy False 100 42: Weighted 0.794694 (0.077250)\n",
      "5 6 5 sqrt entropy False 100 42: Macro 0.678704 (0.111419)\n",
      "Testing 2559/4320\n",
      "5 6 5 sqrt entropy False 200 42: Weighted 0.794694 (0.077250)\n",
      "5 6 5 sqrt entropy False 200 42: Macro 0.678704 (0.111419)\n",
      "Testing 2560/4320\n",
      "5 6 5 sqrt entropy False 500 42: Weighted 0.794694 (0.077250)\n",
      "5 6 5 sqrt entropy False 500 42: Macro 0.678704 (0.111419)\n",
      "Testing 2561/4320\n",
      "5 6 8 log2 gini True 50 42: Weighted 0.822393 (0.069322)\n",
      "5 6 8 log2 gini True 50 42: Macro 0.723551 (0.093651)\n",
      "Testing 2562/4320\n",
      "5 6 8 log2 gini True 100 42: Weighted 0.812229 (0.061512)\n",
      "5 6 8 log2 gini True 100 42: Macro 0.706711 (0.078634)\n",
      "Testing 2563/4320\n",
      "5 6 8 log2 gini True 200 42: Weighted 0.815739 (0.060394)\n",
      "5 6 8 log2 gini True 200 42: Macro 0.712002 (0.077172)\n",
      "Testing 2564/4320\n",
      "5 6 8 log2 gini True 500 42: Weighted 0.807467 (0.059573)\n",
      "5 6 8 log2 gini True 500 42: Macro 0.699568 (0.075508)\n",
      "Testing 2565/4320\n",
      "5 6 8 log2 gini False 50 42: Weighted 0.800716 (0.070617)\n",
      "5 6 8 log2 gini False 50 42: Macro 0.690004 (0.097727)\n",
      "Testing 2566/4320\n",
      "5 6 8 log2 gini False 100 42: Weighted 0.799509 (0.066413)\n",
      "5 6 8 log2 gini False 100 42: Macro 0.686191 (0.090167)\n",
      "Testing 2567/4320\n",
      "5 6 8 log2 gini False 200 42: Weighted 0.809296 (0.071955)\n",
      "5 6 8 log2 gini False 200 42: Macro 0.702618 (0.101231)\n",
      "Testing 2568/4320\n",
      "5 6 8 log2 gini False 500 42: Weighted 0.804333 (0.068679)\n",
      "5 6 8 log2 gini False 500 42: Macro 0.693402 (0.094129)\n",
      "Testing 2569/4320\n",
      "5 6 8 log2 entropy True 50 42: Weighted 0.813446 (0.066368)\n",
      "5 6 8 log2 entropy True 50 42: Macro 0.711688 (0.088782)\n",
      "Testing 2570/4320\n",
      "5 6 8 log2 entropy True 100 42: Weighted 0.812084 (0.061437)\n",
      "5 6 8 log2 entropy True 100 42: Macro 0.709344 (0.080237)\n",
      "Testing 2571/4320\n",
      "5 6 8 log2 entropy True 200 42: Weighted 0.820162 (0.066106)\n",
      "5 6 8 log2 entropy True 200 42: Macro 0.718964 (0.085882)\n",
      "Testing 2572/4320\n",
      "5 6 8 log2 entropy True 500 42: Weighted 0.810977 (0.058703)\n",
      "5 6 8 log2 entropy True 500 42: Macro 0.704859 (0.074493)\n",
      "Testing 2573/4320\n",
      "5 6 8 log2 entropy False 50 42: Weighted 0.803707 (0.072581)\n",
      "5 6 8 log2 entropy False 50 42: Macro 0.694649 (0.100074)\n",
      "Testing 2574/4320\n",
      "5 6 8 log2 entropy False 100 42: Weighted 0.799284 (0.066331)\n",
      "5 6 8 log2 entropy False 100 42: Macro 0.687687 (0.090862)\n",
      "Testing 2575/4320\n",
      "5 6 8 log2 entropy False 200 42: Weighted 0.795632 (0.068042)\n",
      "5 6 8 log2 entropy False 200 42: Macro 0.682581 (0.093015)\n",
      "Testing 2576/4320\n",
      "5 6 8 log2 entropy False 500 42: Weighted 0.799284 (0.066331)\n",
      "5 6 8 log2 entropy False 500 42: Macro 0.687687 (0.090862)\n",
      "Testing 2577/4320\n",
      "5 6 8 sqrt gini True 50 42: Weighted 0.822393 (0.069322)\n",
      "5 6 8 sqrt gini True 50 42: Macro 0.723551 (0.093651)\n",
      "Testing 2578/4320\n",
      "5 6 8 sqrt gini True 100 42: Weighted 0.812229 (0.061512)\n",
      "5 6 8 sqrt gini True 100 42: Macro 0.706711 (0.078634)\n",
      "Testing 2579/4320\n",
      "5 6 8 sqrt gini True 200 42: Weighted 0.815739 (0.060394)\n",
      "5 6 8 sqrt gini True 200 42: Macro 0.712002 (0.077172)\n",
      "Testing 2580/4320\n",
      "5 6 8 sqrt gini True 500 42: Weighted 0.807467 (0.059573)\n",
      "5 6 8 sqrt gini True 500 42: Macro 0.699568 (0.075508)\n",
      "Testing 2581/4320\n",
      "5 6 8 sqrt gini False 50 42: Weighted 0.800716 (0.070617)\n",
      "5 6 8 sqrt gini False 50 42: Macro 0.690004 (0.097727)\n",
      "Testing 2582/4320\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 6 8 sqrt gini False 100 42: Weighted 0.799509 (0.066413)\n",
      "5 6 8 sqrt gini False 100 42: Macro 0.686191 (0.090167)\n",
      "Testing 2583/4320\n",
      "5 6 8 sqrt gini False 200 42: Weighted 0.809296 (0.071955)\n",
      "5 6 8 sqrt gini False 200 42: Macro 0.702618 (0.101231)\n",
      "Testing 2584/4320\n",
      "5 6 8 sqrt gini False 500 42: Weighted 0.804333 (0.068679)\n",
      "5 6 8 sqrt gini False 500 42: Macro 0.693402 (0.094129)\n",
      "Testing 2585/4320\n",
      "5 6 8 sqrt entropy True 50 42: Weighted 0.813446 (0.066368)\n",
      "5 6 8 sqrt entropy True 50 42: Macro 0.711688 (0.088782)\n",
      "Testing 2586/4320\n",
      "5 6 8 sqrt entropy True 100 42: Weighted 0.812084 (0.061437)\n",
      "5 6 8 sqrt entropy True 100 42: Macro 0.709344 (0.080237)\n",
      "Testing 2587/4320\n",
      "5 6 8 sqrt entropy True 200 42: Weighted 0.820162 (0.066106)\n",
      "5 6 8 sqrt entropy True 200 42: Macro 0.718964 (0.085882)\n",
      "Testing 2588/4320\n",
      "5 6 8 sqrt entropy True 500 42: Weighted 0.810977 (0.058703)\n",
      "5 6 8 sqrt entropy True 500 42: Macro 0.704859 (0.074493)\n",
      "Testing 2589/4320\n",
      "5 6 8 sqrt entropy False 50 42: Weighted 0.803707 (0.072581)\n",
      "5 6 8 sqrt entropy False 50 42: Macro 0.694649 (0.100074)\n",
      "Testing 2590/4320\n",
      "5 6 8 sqrt entropy False 100 42: Weighted 0.799284 (0.066331)\n",
      "5 6 8 sqrt entropy False 100 42: Macro 0.687687 (0.090862)\n",
      "Testing 2591/4320\n",
      "5 6 8 sqrt entropy False 200 42: Weighted 0.795632 (0.068042)\n",
      "5 6 8 sqrt entropy False 200 42: Macro 0.682581 (0.093015)\n",
      "Testing 2592/4320\n",
      "5 6 8 sqrt entropy False 500 42: Weighted 0.799284 (0.066331)\n",
      "5 6 8 sqrt entropy False 500 42: Macro 0.687687 (0.090862)\n",
      "Testing 2593/4320\n",
      "1 2 3 log2 gini True 50 76: Weighted 0.792088 (0.057127)\n",
      "1 2 3 log2 gini True 50 76: Macro 0.682121 (0.074148)\n",
      "Testing 2594/4320\n",
      "1 2 3 log2 gini True 100 76: Weighted 0.803906 (0.053199)\n",
      "1 2 3 log2 gini True 100 76: Macro 0.692494 (0.066574)\n",
      "Testing 2595/4320\n",
      "1 2 3 log2 gini True 200 76: Weighted 0.811959 (0.054829)\n",
      "1 2 3 log2 gini True 200 76: Macro 0.707294 (0.071560)\n",
      "Testing 2596/4320\n",
      "1 2 3 log2 gini True 500 76: Weighted 0.817457 (0.053455)\n",
      "1 2 3 log2 gini True 500 76: Macro 0.714857 (0.072653)\n",
      "Testing 2597/4320\n",
      "1 2 3 log2 gini False 50 76: Weighted 0.782336 (0.071642)\n",
      "1 2 3 log2 gini False 50 76: Macro 0.676430 (0.093991)\n",
      "Testing 2598/4320\n",
      "1 2 3 log2 gini False 100 76: Weighted 0.791196 (0.072840)\n",
      "1 2 3 log2 gini False 100 76: Macro 0.686423 (0.099290)\n",
      "Testing 2599/4320\n",
      "1 2 3 log2 gini False 200 76: Weighted 0.800341 (0.058287)\n",
      "1 2 3 log2 gini False 200 76: Macro 0.697434 (0.082324)\n",
      "Testing 2600/4320\n",
      "1 2 3 log2 gini False 500 76: Weighted 0.800147 (0.068724)\n",
      "1 2 3 log2 gini False 500 76: Macro 0.697828 (0.089383)\n",
      "Testing 2601/4320\n",
      "1 2 3 log2 entropy True 50 76: Weighted 0.795670 (0.054404)\n",
      "1 2 3 log2 entropy True 50 76: Macro 0.687023 (0.070618)\n",
      "Testing 2602/4320\n",
      "1 2 3 log2 entropy True 100 76: Weighted 0.809527 (0.062607)\n",
      "1 2 3 log2 entropy True 100 76: Macro 0.704124 (0.082794)\n",
      "Testing 2603/4320\n",
      "1 2 3 log2 entropy True 200 76: Weighted 0.808837 (0.067164)\n",
      "1 2 3 log2 entropy True 200 76: Macro 0.703868 (0.087906)\n",
      "Testing 2604/4320\n",
      "1 2 3 log2 entropy True 500 76: Weighted 0.808523 (0.055575)\n",
      "1 2 3 log2 entropy True 500 76: Macro 0.702270 (0.072850)\n",
      "Testing 2605/4320\n",
      "1 2 3 log2 entropy False 50 76: Weighted 0.773349 (0.089526)\n",
      "1 2 3 log2 entropy False 50 76: Macro 0.663498 (0.109802)\n",
      "Testing 2606/4320\n",
      "1 2 3 log2 entropy False 100 76: Weighted 0.778931 (0.080567)\n",
      "1 2 3 log2 entropy False 100 76: Macro 0.673558 (0.100640)\n",
      "Testing 2607/4320\n",
      "1 2 3 log2 entropy False 200 76: Weighted 0.778931 (0.080567)\n",
      "1 2 3 log2 entropy False 200 76: Macro 0.673558 (0.100640)\n",
      "Testing 2608/4320\n",
      "1 2 3 log2 entropy False 500 76: Weighted 0.778931 (0.080567)\n",
      "1 2 3 log2 entropy False 500 76: Macro 0.673558 (0.100640)\n",
      "Testing 2609/4320\n",
      "1 2 3 sqrt gini True 50 76: Weighted 0.792088 (0.057127)\n",
      "1 2 3 sqrt gini True 50 76: Macro 0.682121 (0.074148)\n",
      "Testing 2610/4320\n",
      "1 2 3 sqrt gini True 100 76: Weighted 0.803906 (0.053199)\n",
      "1 2 3 sqrt gini True 100 76: Macro 0.692494 (0.066574)\n",
      "Testing 2611/4320\n",
      "1 2 3 sqrt gini True 200 76: Weighted 0.811959 (0.054829)\n",
      "1 2 3 sqrt gini True 200 76: Macro 0.707294 (0.071560)\n",
      "Testing 2612/4320\n",
      "1 2 3 sqrt gini True 500 76: Weighted 0.817457 (0.053455)\n",
      "1 2 3 sqrt gini True 500 76: Macro 0.714857 (0.072653)\n",
      "Testing 2613/4320\n",
      "1 2 3 sqrt gini False 50 76: Weighted 0.782336 (0.071642)\n",
      "1 2 3 sqrt gini False 50 76: Macro 0.676430 (0.093991)\n",
      "Testing 2614/4320\n",
      "1 2 3 sqrt gini False 100 76: Weighted 0.791196 (0.072840)\n",
      "1 2 3 sqrt gini False 100 76: Macro 0.686423 (0.099290)\n",
      "Testing 2615/4320\n",
      "1 2 3 sqrt gini False 200 76: Weighted 0.800341 (0.058287)\n",
      "1 2 3 sqrt gini False 200 76: Macro 0.697434 (0.082324)\n",
      "Testing 2616/4320\n",
      "1 2 3 sqrt gini False 500 76: Weighted 0.800147 (0.068724)\n",
      "1 2 3 sqrt gini False 500 76: Macro 0.697828 (0.089383)\n",
      "Testing 2617/4320\n",
      "1 2 3 sqrt entropy True 50 76: Weighted 0.795670 (0.054404)\n",
      "1 2 3 sqrt entropy True 50 76: Macro 0.687023 (0.070618)\n",
      "Testing 2618/4320\n",
      "1 2 3 sqrt entropy True 100 76: Weighted 0.809527 (0.062607)\n",
      "1 2 3 sqrt entropy True 100 76: Macro 0.704124 (0.082794)\n",
      "Testing 2619/4320\n",
      "1 2 3 sqrt entropy True 200 76: Weighted 0.808837 (0.067164)\n",
      "1 2 3 sqrt entropy True 200 76: Macro 0.703868 (0.087906)\n",
      "Testing 2620/4320\n",
      "1 2 3 sqrt entropy True 500 76: Weighted 0.808523 (0.055575)\n",
      "1 2 3 sqrt entropy True 500 76: Macro 0.702270 (0.072850)\n",
      "Testing 2621/4320\n",
      "1 2 3 sqrt entropy False 50 76: Weighted 0.773349 (0.089526)\n",
      "1 2 3 sqrt entropy False 50 76: Macro 0.663498 (0.109802)\n",
      "Testing 2622/4320\n",
      "1 2 3 sqrt entropy False 100 76: Weighted 0.778931 (0.080567)\n",
      "1 2 3 sqrt entropy False 100 76: Macro 0.673558 (0.100640)\n",
      "Testing 2623/4320\n",
      "1 2 3 sqrt entropy False 200 76: Weighted 0.778931 (0.080567)\n",
      "1 2 3 sqrt entropy False 200 76: Macro 0.673558 (0.100640)\n",
      "Testing 2624/4320\n",
      "1 2 3 sqrt entropy False 500 76: Weighted 0.778931 (0.080567)\n",
      "1 2 3 sqrt entropy False 500 76: Macro 0.673558 (0.100640)\n",
      "Testing 2625/4320\n",
      "1 2 5 log2 gini True 50 76: Weighted 0.802223 (0.058820)\n",
      "1 2 5 log2 gini True 50 76: Macro 0.693680 (0.074126)\n",
      "Testing 2626/4320\n",
      "1 2 5 log2 gini True 100 76: Weighted 0.811891 (0.061650)\n",
      "1 2 5 log2 gini True 100 76: Macro 0.707874 (0.078223)\n",
      "Testing 2627/4320\n",
      "1 2 5 log2 gini True 200 76: Weighted 0.807129 (0.059688)\n",
      "1 2 5 log2 gini True 200 76: Macro 0.700731 (0.075190)\n",
      "Testing 2628/4320\n",
      "1 2 5 log2 gini True 500 76: Weighted 0.807129 (0.059688)\n",
      "1 2 5 log2 gini True 500 76: Macro 0.700731 (0.075190)\n",
      "Testing 2629/4320\n",
      "1 2 5 log2 gini False 50 76: Weighted 0.797438 (0.071131)\n",
      "1 2 5 log2 gini False 50 76: Macro 0.696374 (0.100919)\n",
      "Testing 2630/4320\n",
      "1 2 5 log2 gini False 100 76: Weighted 0.791166 (0.064408)\n",
      "1 2 5 log2 gini False 100 76: Macro 0.684386 (0.094427)\n",
      "Testing 2631/4320\n",
      "1 2 5 log2 gini False 200 76: Weighted 0.791166 (0.064408)\n",
      "1 2 5 log2 gini False 200 76: Macro 0.684386 (0.094427)\n",
      "Testing 2632/4320\n",
      "1 2 5 log2 gini False 500 76: Weighted 0.799501 (0.067904)\n",
      "1 2 5 log2 gini False 500 76: Macro 0.696888 (0.100110)\n",
      "Testing 2633/4320\n",
      "1 2 5 log2 entropy True 50 76: Weighted 0.807453 (0.067278)\n",
      "1 2 5 log2 entropy True 50 76: Macro 0.704688 (0.096991)\n",
      "Testing 2634/4320\n",
      "1 2 5 log2 entropy True 100 76: Weighted 0.807403 (0.071544)\n",
      "1 2 5 log2 entropy True 100 76: Macro 0.698624 (0.097591)\n",
      "Testing 2635/4320\n",
      "1 2 5 log2 entropy True 200 76: Weighted 0.807129 (0.059688)\n",
      "1 2 5 log2 entropy True 200 76: Macro 0.700731 (0.075190)\n",
      "Testing 2636/4320\n",
      "1 2 5 log2 entropy True 500 76: Weighted 0.802923 (0.065526)\n",
      "1 2 5 log2 entropy True 500 76: Macro 0.695518 (0.082698)\n",
      "Testing 2637/4320\n",
      "1 2 5 log2 entropy False 50 76: Weighted 0.779109 (0.069281)\n",
      "1 2 5 log2 entropy False 50 76: Macro 0.669150 (0.106156)\n",
      "Testing 2638/4320\n",
      "1 2 5 log2 entropy False 100 76: Weighted 0.775629 (0.069869)\n",
      "1 2 5 log2 entropy False 100 76: Macro 0.664231 (0.106830)\n",
      "Testing 2639/4320\n",
      "1 2 5 log2 entropy False 200 76: Weighted 0.779109 (0.069281)\n",
      "1 2 5 log2 entropy False 200 76: Macro 0.669150 (0.106156)\n",
      "Testing 2640/4320\n",
      "1 2 5 log2 entropy False 500 76: Weighted 0.781349 (0.074991)\n",
      "1 2 5 log2 entropy False 500 76: Macro 0.669234 (0.111320)\n",
      "Testing 2641/4320\n",
      "1 2 5 sqrt gini True 50 76: Weighted 0.802223 (0.058820)\n",
      "1 2 5 sqrt gini True 50 76: Macro 0.693680 (0.074126)\n",
      "Testing 2642/4320\n",
      "1 2 5 sqrt gini True 100 76: Weighted 0.811891 (0.061650)\n",
      "1 2 5 sqrt gini True 100 76: Macro 0.707874 (0.078223)\n",
      "Testing 2643/4320\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 2 5 sqrt gini True 200 76: Weighted 0.807129 (0.059688)\n",
      "1 2 5 sqrt gini True 200 76: Macro 0.700731 (0.075190)\n",
      "Testing 2644/4320\n",
      "1 2 5 sqrt gini True 500 76: Weighted 0.807129 (0.059688)\n",
      "1 2 5 sqrt gini True 500 76: Macro 0.700731 (0.075190)\n",
      "Testing 2645/4320\n",
      "1 2 5 sqrt gini False 50 76: Weighted 0.797438 (0.071131)\n",
      "1 2 5 sqrt gini False 50 76: Macro 0.696374 (0.100919)\n",
      "Testing 2646/4320\n",
      "1 2 5 sqrt gini False 100 76: Weighted 0.791166 (0.064408)\n",
      "1 2 5 sqrt gini False 100 76: Macro 0.684386 (0.094427)\n",
      "Testing 2647/4320\n",
      "1 2 5 sqrt gini False 200 76: Weighted 0.791166 (0.064408)\n",
      "1 2 5 sqrt gini False 200 76: Macro 0.684386 (0.094427)\n",
      "Testing 2648/4320\n",
      "1 2 5 sqrt gini False 500 76: Weighted 0.799501 (0.067904)\n",
      "1 2 5 sqrt gini False 500 76: Macro 0.696888 (0.100110)\n",
      "Testing 2649/4320\n",
      "1 2 5 sqrt entropy True 50 76: Weighted 0.807453 (0.067278)\n",
      "1 2 5 sqrt entropy True 50 76: Macro 0.704688 (0.096991)\n",
      "Testing 2650/4320\n",
      "1 2 5 sqrt entropy True 100 76: Weighted 0.807403 (0.071544)\n",
      "1 2 5 sqrt entropy True 100 76: Macro 0.698624 (0.097591)\n",
      "Testing 2651/4320\n",
      "1 2 5 sqrt entropy True 200 76: Weighted 0.807129 (0.059688)\n",
      "1 2 5 sqrt entropy True 200 76: Macro 0.700731 (0.075190)\n",
      "Testing 2652/4320\n",
      "1 2 5 sqrt entropy True 500 76: Weighted 0.802923 (0.065526)\n",
      "1 2 5 sqrt entropy True 500 76: Macro 0.695518 (0.082698)\n",
      "Testing 2653/4320\n",
      "1 2 5 sqrt entropy False 50 76: Weighted 0.779109 (0.069281)\n",
      "1 2 5 sqrt entropy False 50 76: Macro 0.669150 (0.106156)\n",
      "Testing 2654/4320\n",
      "1 2 5 sqrt entropy False 100 76: Weighted 0.775629 (0.069869)\n",
      "1 2 5 sqrt entropy False 100 76: Macro 0.664231 (0.106830)\n",
      "Testing 2655/4320\n",
      "1 2 5 sqrt entropy False 200 76: Weighted 0.779109 (0.069281)\n",
      "1 2 5 sqrt entropy False 200 76: Macro 0.669150 (0.106156)\n",
      "Testing 2656/4320\n",
      "1 2 5 sqrt entropy False 500 76: Weighted 0.781349 (0.074991)\n",
      "1 2 5 sqrt entropy False 500 76: Macro 0.669234 (0.111320)\n",
      "Testing 2657/4320\n",
      "1 2 8 log2 gini True 50 76: Weighted 0.811136 (0.054453)\n",
      "1 2 8 log2 gini True 50 76: Macro 0.705810 (0.068232)\n",
      "Testing 2658/4320\n",
      "1 2 8 log2 gini True 100 76: Weighted 0.806337 (0.059981)\n",
      "1 2 8 log2 gini True 100 76: Macro 0.701360 (0.075040)\n",
      "Testing 2659/4320\n",
      "1 2 8 log2 gini True 200 76: Weighted 0.799326 (0.063812)\n",
      "1 2 8 log2 gini True 200 76: Macro 0.690976 (0.079413)\n",
      "Testing 2660/4320\n",
      "1 2 8 log2 gini True 500 76: Weighted 0.798813 (0.052987)\n",
      "1 2 8 log2 gini True 500 76: Macro 0.689244 (0.063891)\n",
      "Testing 2661/4320\n",
      "1 2 8 log2 gini False 50 76: Weighted 0.774865 (0.060120)\n",
      "1 2 8 log2 gini False 50 76: Macro 0.671343 (0.085652)\n",
      "Testing 2662/4320\n",
      "1 2 8 log2 gini False 100 76: Weighted 0.788743 (0.053470)\n",
      "1 2 8 log2 gini False 100 76: Macro 0.686309 (0.074706)\n",
      "Testing 2663/4320\n",
      "1 2 8 log2 gini False 200 76: Weighted 0.792716 (0.056621)\n",
      "1 2 8 log2 gini False 200 76: Macro 0.688451 (0.080432)\n",
      "Testing 2664/4320\n",
      "1 2 8 log2 gini False 500 76: Weighted 0.784595 (0.056328)\n",
      "1 2 8 log2 gini False 500 76: Macro 0.677050 (0.079570)\n",
      "Testing 2665/4320\n",
      "1 2 8 log2 entropy True 50 76: Weighted 0.810179 (0.055670)\n",
      "1 2 8 log2 entropy True 50 76: Macro 0.699176 (0.077396)\n",
      "Testing 2666/4320\n",
      "1 2 8 log2 entropy True 100 76: Weighted 0.806010 (0.060417)\n",
      "1 2 8 log2 entropy True 100 76: Macro 0.696962 (0.081399)\n",
      "Testing 2667/4320\n",
      "1 2 8 log2 entropy True 200 76: Weighted 0.803966 (0.050850)\n",
      "1 2 8 log2 entropy True 200 76: Macro 0.699699 (0.058572)\n",
      "Testing 2668/4320\n",
      "1 2 8 log2 entropy True 500 76: Weighted 0.795579 (0.050988)\n",
      "1 2 8 log2 entropy True 500 76: Macro 0.687389 (0.058538)\n",
      "Testing 2669/4320\n",
      "1 2 8 log2 entropy False 50 76: Weighted 0.778582 (0.035994)\n",
      "1 2 8 log2 entropy False 50 76: Macro 0.668758 (0.056849)\n",
      "Testing 2670/4320\n",
      "1 2 8 log2 entropy False 100 76: Weighted 0.783613 (0.037755)\n",
      "1 2 8 log2 entropy False 100 76: Macro 0.678332 (0.057646)\n",
      "Testing 2671/4320\n",
      "1 2 8 log2 entropy False 200 76: Weighted 0.779912 (0.042987)\n",
      "1 2 8 log2 entropy False 200 76: Macro 0.673634 (0.064603)\n",
      "Testing 2672/4320\n",
      "1 2 8 log2 entropy False 500 76: Weighted 0.790393 (0.052767)\n",
      "1 2 8 log2 entropy False 500 76: Macro 0.687270 (0.074883)\n",
      "Testing 2673/4320\n",
      "1 2 8 sqrt gini True 50 76: Weighted 0.811136 (0.054453)\n",
      "1 2 8 sqrt gini True 50 76: Macro 0.705810 (0.068232)\n",
      "Testing 2674/4320\n",
      "1 2 8 sqrt gini True 100 76: Weighted 0.806337 (0.059981)\n",
      "1 2 8 sqrt gini True 100 76: Macro 0.701360 (0.075040)\n",
      "Testing 2675/4320\n",
      "1 2 8 sqrt gini True 200 76: Weighted 0.799326 (0.063812)\n",
      "1 2 8 sqrt gini True 200 76: Macro 0.690976 (0.079413)\n",
      "Testing 2676/4320\n",
      "1 2 8 sqrt gini True 500 76: Weighted 0.798813 (0.052987)\n",
      "1 2 8 sqrt gini True 500 76: Macro 0.689244 (0.063891)\n",
      "Testing 2677/4320\n",
      "1 2 8 sqrt gini False 50 76: Weighted 0.774865 (0.060120)\n",
      "1 2 8 sqrt gini False 50 76: Macro 0.671343 (0.085652)\n",
      "Testing 2678/4320\n",
      "1 2 8 sqrt gini False 100 76: Weighted 0.788743 (0.053470)\n",
      "1 2 8 sqrt gini False 100 76: Macro 0.686309 (0.074706)\n",
      "Testing 2679/4320\n",
      "1 2 8 sqrt gini False 200 76: Weighted 0.792716 (0.056621)\n",
      "1 2 8 sqrt gini False 200 76: Macro 0.688451 (0.080432)\n",
      "Testing 2680/4320\n",
      "1 2 8 sqrt gini False 500 76: Weighted 0.784595 (0.056328)\n",
      "1 2 8 sqrt gini False 500 76: Macro 0.677050 (0.079570)\n",
      "Testing 2681/4320\n",
      "1 2 8 sqrt entropy True 50 76: Weighted 0.810179 (0.055670)\n",
      "1 2 8 sqrt entropy True 50 76: Macro 0.699176 (0.077396)\n",
      "Testing 2682/4320\n",
      "1 2 8 sqrt entropy True 100 76: Weighted 0.806010 (0.060417)\n",
      "1 2 8 sqrt entropy True 100 76: Macro 0.696962 (0.081399)\n",
      "Testing 2683/4320\n",
      "1 2 8 sqrt entropy True 200 76: Weighted 0.803966 (0.050850)\n",
      "1 2 8 sqrt entropy True 200 76: Macro 0.699699 (0.058572)\n",
      "Testing 2684/4320\n",
      "1 2 8 sqrt entropy True 500 76: Weighted 0.795579 (0.050988)\n",
      "1 2 8 sqrt entropy True 500 76: Macro 0.687389 (0.058538)\n",
      "Testing 2685/4320\n",
      "1 2 8 sqrt entropy False 50 76: Weighted 0.778582 (0.035994)\n",
      "1 2 8 sqrt entropy False 50 76: Macro 0.668758 (0.056849)\n",
      "Testing 2686/4320\n",
      "1 2 8 sqrt entropy False 100 76: Weighted 0.783613 (0.037755)\n",
      "1 2 8 sqrt entropy False 100 76: Macro 0.678332 (0.057646)\n",
      "Testing 2687/4320\n",
      "1 2 8 sqrt entropy False 200 76: Weighted 0.779912 (0.042987)\n",
      "1 2 8 sqrt entropy False 200 76: Macro 0.673634 (0.064603)\n",
      "Testing 2688/4320\n",
      "1 2 8 sqrt entropy False 500 76: Weighted 0.790393 (0.052767)\n",
      "1 2 8 sqrt entropy False 500 76: Macro 0.687270 (0.074883)\n",
      "Testing 2689/4320\n",
      "1 4 3 log2 gini True 50 76: Weighted 0.792088 (0.057127)\n",
      "1 4 3 log2 gini True 50 76: Macro 0.682121 (0.074148)\n",
      "Testing 2690/4320\n",
      "1 4 3 log2 gini True 100 76: Weighted 0.803906 (0.053199)\n",
      "1 4 3 log2 gini True 100 76: Macro 0.692494 (0.066574)\n",
      "Testing 2691/4320\n",
      "1 4 3 log2 gini True 200 76: Weighted 0.811959 (0.054829)\n",
      "1 4 3 log2 gini True 200 76: Macro 0.707294 (0.071560)\n",
      "Testing 2692/4320\n",
      "1 4 3 log2 gini True 500 76: Weighted 0.817457 (0.053455)\n",
      "1 4 3 log2 gini True 500 76: Macro 0.714857 (0.072653)\n",
      "Testing 2693/4320\n",
      "1 4 3 log2 gini False 50 76: Weighted 0.780710 (0.087380)\n",
      "1 4 3 log2 gini False 50 76: Macro 0.673208 (0.109047)\n",
      "Testing 2694/4320\n",
      "1 4 3 log2 gini False 100 76: Weighted 0.800099 (0.079756)\n",
      "1 4 3 log2 gini False 100 76: Macro 0.693554 (0.104338)\n",
      "Testing 2695/4320\n",
      "1 4 3 log2 gini False 200 76: Weighted 0.795395 (0.080681)\n",
      "1 4 3 log2 gini False 200 76: Macro 0.689986 (0.105112)\n",
      "Testing 2696/4320\n",
      "1 4 3 log2 gini False 500 76: Weighted 0.799923 (0.073917)\n",
      "1 4 3 log2 gini False 500 76: Macro 0.697877 (0.093328)\n",
      "Testing 2697/4320\n",
      "1 4 3 log2 entropy True 50 76: Weighted 0.795670 (0.054404)\n",
      "1 4 3 log2 entropy True 50 76: Macro 0.687023 (0.070618)\n",
      "Testing 2698/4320\n",
      "1 4 3 log2 entropy True 100 76: Weighted 0.809527 (0.062607)\n",
      "1 4 3 log2 entropy True 100 76: Macro 0.704124 (0.082794)\n",
      "Testing 2699/4320\n",
      "1 4 3 log2 entropy True 200 76: Weighted 0.808837 (0.067164)\n",
      "1 4 3 log2 entropy True 200 76: Macro 0.703868 (0.087906)\n",
      "Testing 2700/4320\n",
      "1 4 3 log2 entropy True 500 76: Weighted 0.808523 (0.055575)\n",
      "1 4 3 log2 entropy True 500 76: Macro 0.702270 (0.072850)\n",
      "Testing 2701/4320\n",
      "1 4 3 log2 entropy False 50 76: Weighted 0.777766 (0.092899)\n",
      "1 4 3 log2 entropy False 50 76: Macro 0.667047 (0.112261)\n",
      "Testing 2702/4320\n",
      "1 4 3 log2 entropy False 100 76: Weighted 0.787834 (0.088117)\n",
      "1 4 3 log2 entropy False 100 76: Macro 0.680688 (0.106489)\n",
      "Testing 2703/4320\n",
      "1 4 3 log2 entropy False 200 76: Weighted 0.787834 (0.088117)\n",
      "1 4 3 log2 entropy False 200 76: Macro 0.680688 (0.106489)\n",
      "Testing 2704/4320\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 4 3 log2 entropy False 500 76: Weighted 0.787834 (0.088117)\n",
      "1 4 3 log2 entropy False 500 76: Macro 0.680688 (0.106489)\n",
      "Testing 2705/4320\n",
      "1 4 3 sqrt gini True 50 76: Weighted 0.792088 (0.057127)\n",
      "1 4 3 sqrt gini True 50 76: Macro 0.682121 (0.074148)\n",
      "Testing 2706/4320\n",
      "1 4 3 sqrt gini True 100 76: Weighted 0.803906 (0.053199)\n",
      "1 4 3 sqrt gini True 100 76: Macro 0.692494 (0.066574)\n",
      "Testing 2707/4320\n",
      "1 4 3 sqrt gini True 200 76: Weighted 0.811959 (0.054829)\n",
      "1 4 3 sqrt gini True 200 76: Macro 0.707294 (0.071560)\n",
      "Testing 2708/4320\n",
      "1 4 3 sqrt gini True 500 76: Weighted 0.817457 (0.053455)\n",
      "1 4 3 sqrt gini True 500 76: Macro 0.714857 (0.072653)\n",
      "Testing 2709/4320\n",
      "1 4 3 sqrt gini False 50 76: Weighted 0.780710 (0.087380)\n",
      "1 4 3 sqrt gini False 50 76: Macro 0.673208 (0.109047)\n",
      "Testing 2710/4320\n",
      "1 4 3 sqrt gini False 100 76: Weighted 0.800099 (0.079756)\n",
      "1 4 3 sqrt gini False 100 76: Macro 0.693554 (0.104338)\n",
      "Testing 2711/4320\n",
      "1 4 3 sqrt gini False 200 76: Weighted 0.795395 (0.080681)\n",
      "1 4 3 sqrt gini False 200 76: Macro 0.689986 (0.105112)\n",
      "Testing 2712/4320\n",
      "1 4 3 sqrt gini False 500 76: Weighted 0.799923 (0.073917)\n",
      "1 4 3 sqrt gini False 500 76: Macro 0.697877 (0.093328)\n",
      "Testing 2713/4320\n",
      "1 4 3 sqrt entropy True 50 76: Weighted 0.795670 (0.054404)\n",
      "1 4 3 sqrt entropy True 50 76: Macro 0.687023 (0.070618)\n",
      "Testing 2714/4320\n",
      "1 4 3 sqrt entropy True 100 76: Weighted 0.809527 (0.062607)\n",
      "1 4 3 sqrt entropy True 100 76: Macro 0.704124 (0.082794)\n",
      "Testing 2715/4320\n",
      "1 4 3 sqrt entropy True 200 76: Weighted 0.808837 (0.067164)\n",
      "1 4 3 sqrt entropy True 200 76: Macro 0.703868 (0.087906)\n",
      "Testing 2716/4320\n",
      "1 4 3 sqrt entropy True 500 76: Weighted 0.808523 (0.055575)\n",
      "1 4 3 sqrt entropy True 500 76: Macro 0.702270 (0.072850)\n",
      "Testing 2717/4320\n",
      "1 4 3 sqrt entropy False 50 76: Weighted 0.777766 (0.092899)\n",
      "1 4 3 sqrt entropy False 50 76: Macro 0.667047 (0.112261)\n",
      "Testing 2718/4320\n",
      "1 4 3 sqrt entropy False 100 76: Weighted 0.787834 (0.088117)\n",
      "1 4 3 sqrt entropy False 100 76: Macro 0.680688 (0.106489)\n",
      "Testing 2719/4320\n",
      "1 4 3 sqrt entropy False 200 76: Weighted 0.787834 (0.088117)\n",
      "1 4 3 sqrt entropy False 200 76: Macro 0.680688 (0.106489)\n",
      "Testing 2720/4320\n",
      "1 4 3 sqrt entropy False 500 76: Weighted 0.787834 (0.088117)\n",
      "1 4 3 sqrt entropy False 500 76: Macro 0.680688 (0.106489)\n",
      "Testing 2721/4320\n",
      "1 4 5 log2 gini True 50 76: Weighted 0.802223 (0.058820)\n",
      "1 4 5 log2 gini True 50 76: Macro 0.693680 (0.074126)\n",
      "Testing 2722/4320\n",
      "1 4 5 log2 gini True 100 76: Weighted 0.811891 (0.061650)\n",
      "1 4 5 log2 gini True 100 76: Macro 0.707874 (0.078223)\n",
      "Testing 2723/4320\n",
      "1 4 5 log2 gini True 200 76: Weighted 0.807129 (0.059688)\n",
      "1 4 5 log2 gini True 200 76: Macro 0.700731 (0.075190)\n",
      "Testing 2724/4320\n",
      "1 4 5 log2 gini True 500 76: Weighted 0.807129 (0.059688)\n",
      "1 4 5 log2 gini True 500 76: Macro 0.700731 (0.075190)\n",
      "Testing 2725/4320\n",
      "1 4 5 log2 gini False 50 76: Weighted 0.808504 (0.076483)\n",
      "1 4 5 log2 gini False 50 76: Macro 0.704126 (0.106322)\n",
      "Testing 2726/4320\n",
      "1 4 5 log2 gini False 100 76: Weighted 0.800169 (0.074412)\n",
      "1 4 5 log2 gini False 100 76: Macro 0.691625 (0.101882)\n",
      "Testing 2727/4320\n",
      "1 4 5 log2 gini False 200 76: Weighted 0.800169 (0.074412)\n",
      "1 4 5 log2 gini False 200 76: Macro 0.691625 (0.101882)\n",
      "Testing 2728/4320\n",
      "1 4 5 log2 gini False 500 76: Weighted 0.808504 (0.076483)\n",
      "1 4 5 log2 gini False 500 76: Macro 0.704126 (0.106322)\n",
      "Testing 2729/4320\n",
      "1 4 5 log2 entropy True 50 76: Weighted 0.812019 (0.073108)\n",
      "1 4 5 log2 entropy True 50 76: Macro 0.708399 (0.101385)\n",
      "Testing 2730/4320\n",
      "1 4 5 log2 entropy True 100 76: Weighted 0.807403 (0.071544)\n",
      "1 4 5 log2 entropy True 100 76: Macro 0.698624 (0.097591)\n",
      "Testing 2731/4320\n",
      "1 4 5 log2 entropy True 200 76: Weighted 0.807129 (0.059688)\n",
      "1 4 5 log2 entropy True 200 76: Macro 0.700731 (0.075190)\n",
      "Testing 2732/4320\n",
      "1 4 5 log2 entropy True 500 76: Weighted 0.807129 (0.059688)\n",
      "1 4 5 log2 entropy True 500 76: Macro 0.700731 (0.075190)\n",
      "Testing 2733/4320\n",
      "1 4 5 log2 entropy False 50 76: Weighted 0.793832 (0.083694)\n",
      "1 4 5 log2 entropy False 50 76: Macro 0.681393 (0.117520)\n",
      "Testing 2734/4320\n",
      "1 4 5 log2 entropy False 100 76: Weighted 0.790352 (0.084789)\n",
      "1 4 5 log2 entropy False 100 76: Macro 0.676473 (0.118638)\n",
      "Testing 2735/4320\n",
      "1 4 5 log2 entropy False 200 76: Weighted 0.790352 (0.084789)\n",
      "1 4 5 log2 entropy False 200 76: Macro 0.676473 (0.118638)\n",
      "Testing 2736/4320\n",
      "1 4 5 log2 entropy False 500 76: Weighted 0.794625 (0.078757)\n",
      "1 4 5 log2 entropy False 500 76: Macro 0.686191 (0.104389)\n",
      "Testing 2737/4320\n",
      "1 4 5 sqrt gini True 50 76: Weighted 0.802223 (0.058820)\n",
      "1 4 5 sqrt gini True 50 76: Macro 0.693680 (0.074126)\n",
      "Testing 2738/4320\n",
      "1 4 5 sqrt gini True 100 76: Weighted 0.811891 (0.061650)\n",
      "1 4 5 sqrt gini True 100 76: Macro 0.707874 (0.078223)\n",
      "Testing 2739/4320\n",
      "1 4 5 sqrt gini True 200 76: Weighted 0.807129 (0.059688)\n",
      "1 4 5 sqrt gini True 200 76: Macro 0.700731 (0.075190)\n",
      "Testing 2740/4320\n",
      "1 4 5 sqrt gini True 500 76: Weighted 0.807129 (0.059688)\n",
      "1 4 5 sqrt gini True 500 76: Macro 0.700731 (0.075190)\n",
      "Testing 2741/4320\n",
      "1 4 5 sqrt gini False 50 76: Weighted 0.808504 (0.076483)\n",
      "1 4 5 sqrt gini False 50 76: Macro 0.704126 (0.106322)\n",
      "Testing 2742/4320\n",
      "1 4 5 sqrt gini False 100 76: Weighted 0.800169 (0.074412)\n",
      "1 4 5 sqrt gini False 100 76: Macro 0.691625 (0.101882)\n",
      "Testing 2743/4320\n",
      "1 4 5 sqrt gini False 200 76: Weighted 0.800169 (0.074412)\n",
      "1 4 5 sqrt gini False 200 76: Macro 0.691625 (0.101882)\n",
      "Testing 2744/4320\n",
      "1 4 5 sqrt gini False 500 76: Weighted 0.808504 (0.076483)\n",
      "1 4 5 sqrt gini False 500 76: Macro 0.704126 (0.106322)\n",
      "Testing 2745/4320\n",
      "1 4 5 sqrt entropy True 50 76: Weighted 0.812019 (0.073108)\n",
      "1 4 5 sqrt entropy True 50 76: Macro 0.708399 (0.101385)\n",
      "Testing 2746/4320\n",
      "1 4 5 sqrt entropy True 100 76: Weighted 0.807403 (0.071544)\n",
      "1 4 5 sqrt entropy True 100 76: Macro 0.698624 (0.097591)\n",
      "Testing 2747/4320\n",
      "1 4 5 sqrt entropy True 200 76: Weighted 0.807129 (0.059688)\n",
      "1 4 5 sqrt entropy True 200 76: Macro 0.700731 (0.075190)\n",
      "Testing 2748/4320\n",
      "1 4 5 sqrt entropy True 500 76: Weighted 0.807129 (0.059688)\n",
      "1 4 5 sqrt entropy True 500 76: Macro 0.700731 (0.075190)\n",
      "Testing 2749/4320\n",
      "1 4 5 sqrt entropy False 50 76: Weighted 0.793832 (0.083694)\n",
      "1 4 5 sqrt entropy False 50 76: Macro 0.681393 (0.117520)\n",
      "Testing 2750/4320\n",
      "1 4 5 sqrt entropy False 100 76: Weighted 0.790352 (0.084789)\n",
      "1 4 5 sqrt entropy False 100 76: Macro 0.676473 (0.118638)\n",
      "Testing 2751/4320\n",
      "1 4 5 sqrt entropy False 200 76: Weighted 0.790352 (0.084789)\n",
      "1 4 5 sqrt entropy False 200 76: Macro 0.676473 (0.118638)\n",
      "Testing 2752/4320\n",
      "1 4 5 sqrt entropy False 500 76: Weighted 0.794625 (0.078757)\n",
      "1 4 5 sqrt entropy False 500 76: Macro 0.686191 (0.104389)\n",
      "Testing 2753/4320\n",
      "1 4 8 log2 gini True 50 76: Weighted 0.806616 (0.048024)\n",
      "1 4 8 log2 gini True 50 76: Macro 0.698999 (0.058847)\n",
      "Testing 2754/4320\n",
      "1 4 8 log2 gini True 100 76: Weighted 0.807129 (0.059688)\n",
      "1 4 8 log2 gini True 100 76: Macro 0.700731 (0.075190)\n",
      "Testing 2755/4320\n",
      "1 4 8 log2 gini True 200 76: Weighted 0.798336 (0.055342)\n",
      "1 4 8 log2 gini True 200 76: Macro 0.689290 (0.067582)\n",
      "Testing 2756/4320\n",
      "1 4 8 log2 gini True 500 76: Weighted 0.803722 (0.061157)\n",
      "1 4 8 log2 gini True 500 76: Macro 0.695738 (0.076918)\n",
      "Testing 2757/4320\n",
      "1 4 8 log2 gini False 50 76: Weighted 0.783989 (0.067812)\n",
      "1 4 8 log2 gini False 50 76: Macro 0.670774 (0.085667)\n",
      "Testing 2758/4320\n",
      "1 4 8 log2 gini False 100 76: Weighted 0.793498 (0.065922)\n",
      "1 4 8 log2 gini False 100 76: Macro 0.684181 (0.086562)\n",
      "Testing 2759/4320\n",
      "1 4 8 log2 gini False 200 76: Weighted 0.789635 (0.070564)\n",
      "1 4 8 log2 gini False 200 76: Macro 0.679395 (0.092716)\n",
      "Testing 2760/4320\n",
      "1 4 8 log2 gini False 500 76: Weighted 0.789635 (0.070564)\n",
      "1 4 8 log2 gini False 500 76: Macro 0.679395 (0.092716)\n",
      "Testing 2761/4320\n",
      "1 4 8 log2 entropy True 50 76: Weighted 0.811225 (0.066463)\n",
      "1 4 8 log2 entropy True 50 76: Macro 0.703295 (0.091001)\n",
      "Testing 2762/4320\n",
      "1 4 8 log2 entropy True 100 76: Weighted 0.801817 (0.053810)\n",
      "1 4 8 log2 entropy True 100 76: Macro 0.694549 (0.066165)\n",
      "Testing 2763/4320\n",
      "1 4 8 log2 entropy True 200 76: Weighted 0.801817 (0.053810)\n",
      "1 4 8 log2 entropy True 200 76: Macro 0.694549 (0.066165)\n",
      "Testing 2764/4320\n",
      "1 4 8 log2 entropy True 500 76: Weighted 0.799908 (0.056513)\n",
      "1 4 8 log2 entropy True 500 76: Macro 0.694474 (0.066278)\n",
      "Testing 2765/4320\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 4 8 log2 entropy False 50 76: Weighted 0.793366 (0.065040)\n",
      "1 4 8 log2 entropy False 50 76: Macro 0.679218 (0.090559)\n",
      "Testing 2766/4320\n",
      "1 4 8 log2 entropy False 100 76: Weighted 0.793366 (0.065040)\n",
      "1 4 8 log2 entropy False 100 76: Macro 0.679218 (0.090559)\n",
      "Testing 2767/4320\n",
      "1 4 8 log2 entropy False 200 76: Weighted 0.799396 (0.064706)\n",
      "1 4 8 log2 entropy False 200 76: Macro 0.694509 (0.083840)\n",
      "Testing 2768/4320\n",
      "1 4 8 log2 entropy False 500 76: Weighted 0.799396 (0.064706)\n",
      "1 4 8 log2 entropy False 500 76: Macro 0.694509 (0.083840)\n",
      "Testing 2769/4320\n",
      "1 4 8 sqrt gini True 50 76: Weighted 0.806616 (0.048024)\n",
      "1 4 8 sqrt gini True 50 76: Macro 0.698999 (0.058847)\n",
      "Testing 2770/4320\n",
      "1 4 8 sqrt gini True 100 76: Weighted 0.807129 (0.059688)\n",
      "1 4 8 sqrt gini True 100 76: Macro 0.700731 (0.075190)\n",
      "Testing 2771/4320\n",
      "1 4 8 sqrt gini True 200 76: Weighted 0.798336 (0.055342)\n",
      "1 4 8 sqrt gini True 200 76: Macro 0.689290 (0.067582)\n",
      "Testing 2772/4320\n",
      "1 4 8 sqrt gini True 500 76: Weighted 0.803722 (0.061157)\n",
      "1 4 8 sqrt gini True 500 76: Macro 0.695738 (0.076918)\n",
      "Testing 2773/4320\n",
      "1 4 8 sqrt gini False 50 76: Weighted 0.783989 (0.067812)\n",
      "1 4 8 sqrt gini False 50 76: Macro 0.670774 (0.085667)\n",
      "Testing 2774/4320\n",
      "1 4 8 sqrt gini False 100 76: Weighted 0.793498 (0.065922)\n",
      "1 4 8 sqrt gini False 100 76: Macro 0.684181 (0.086562)\n",
      "Testing 2775/4320\n",
      "1 4 8 sqrt gini False 200 76: Weighted 0.789635 (0.070564)\n",
      "1 4 8 sqrt gini False 200 76: Macro 0.679395 (0.092716)\n",
      "Testing 2776/4320\n",
      "1 4 8 sqrt gini False 500 76: Weighted 0.789635 (0.070564)\n",
      "1 4 8 sqrt gini False 500 76: Macro 0.679395 (0.092716)\n",
      "Testing 2777/4320\n",
      "1 4 8 sqrt entropy True 50 76: Weighted 0.811225 (0.066463)\n",
      "1 4 8 sqrt entropy True 50 76: Macro 0.703295 (0.091001)\n",
      "Testing 2778/4320\n",
      "1 4 8 sqrt entropy True 100 76: Weighted 0.801817 (0.053810)\n",
      "1 4 8 sqrt entropy True 100 76: Macro 0.694549 (0.066165)\n",
      "Testing 2779/4320\n",
      "1 4 8 sqrt entropy True 200 76: Weighted 0.801817 (0.053810)\n",
      "1 4 8 sqrt entropy True 200 76: Macro 0.694549 (0.066165)\n",
      "Testing 2780/4320\n",
      "1 4 8 sqrt entropy True 500 76: Weighted 0.799908 (0.056513)\n",
      "1 4 8 sqrt entropy True 500 76: Macro 0.694474 (0.066278)\n",
      "Testing 2781/4320\n",
      "1 4 8 sqrt entropy False 50 76: Weighted 0.793366 (0.065040)\n",
      "1 4 8 sqrt entropy False 50 76: Macro 0.679218 (0.090559)\n",
      "Testing 2782/4320\n",
      "1 4 8 sqrt entropy False 100 76: Weighted 0.793366 (0.065040)\n",
      "1 4 8 sqrt entropy False 100 76: Macro 0.679218 (0.090559)\n",
      "Testing 2783/4320\n",
      "1 4 8 sqrt entropy False 200 76: Weighted 0.799396 (0.064706)\n",
      "1 4 8 sqrt entropy False 200 76: Macro 0.694509 (0.083840)\n",
      "Testing 2784/4320\n",
      "1 4 8 sqrt entropy False 500 76: Weighted 0.799396 (0.064706)\n",
      "1 4 8 sqrt entropy False 500 76: Macro 0.694509 (0.083840)\n",
      "Testing 2785/4320\n",
      "1 6 3 log2 gini True 50 76: Weighted 0.787471 (0.053416)\n",
      "1 6 3 log2 gini True 50 76: Macro 0.672345 (0.065031)\n",
      "Testing 2786/4320\n",
      "1 6 3 log2 gini True 100 76: Weighted 0.803906 (0.053199)\n",
      "1 6 3 log2 gini True 100 76: Macro 0.692494 (0.066574)\n",
      "Testing 2787/4320\n",
      "1 6 3 log2 gini True 200 76: Weighted 0.811959 (0.054829)\n",
      "1 6 3 log2 gini True 200 76: Macro 0.707294 (0.071560)\n",
      "Testing 2788/4320\n",
      "1 6 3 log2 gini True 500 76: Weighted 0.817457 (0.053455)\n",
      "1 6 3 log2 gini True 500 76: Macro 0.714857 (0.072653)\n",
      "Testing 2789/4320\n",
      "1 6 3 log2 gini False 50 76: Weighted 0.795387 (0.070889)\n",
      "1 6 3 log2 gini False 50 76: Macro 0.689300 (0.089352)\n",
      "Testing 2790/4320\n",
      "1 6 3 log2 gini False 100 76: Weighted 0.800099 (0.079756)\n",
      "1 6 3 log2 gini False 100 76: Macro 0.693554 (0.104338)\n",
      "Testing 2791/4320\n",
      "1 6 3 log2 gini False 200 76: Weighted 0.804540 (0.067263)\n",
      "1 6 3 log2 gini False 200 76: Macro 0.700997 (0.088818)\n",
      "Testing 2792/4320\n",
      "1 6 3 log2 gini False 500 76: Weighted 0.799923 (0.073917)\n",
      "1 6 3 log2 gini False 500 76: Macro 0.697877 (0.093328)\n",
      "Testing 2793/4320\n",
      "1 6 3 log2 entropy True 50 76: Weighted 0.800338 (0.059751)\n",
      "1 6 3 log2 entropy True 50 76: Macro 0.693782 (0.077238)\n",
      "Testing 2794/4320\n",
      "1 6 3 log2 entropy True 100 76: Weighted 0.809527 (0.062607)\n",
      "1 6 3 log2 entropy True 100 76: Macro 0.704124 (0.082794)\n",
      "Testing 2795/4320\n",
      "1 6 3 log2 entropy True 200 76: Weighted 0.804317 (0.061898)\n",
      "1 6 3 log2 entropy True 200 76: Macro 0.697056 (0.080675)\n",
      "Testing 2796/4320\n",
      "1 6 3 log2 entropy True 500 76: Weighted 0.808523 (0.055575)\n",
      "1 6 3 log2 entropy True 500 76: Macro 0.702270 (0.072850)\n",
      "Testing 2797/4320\n",
      "1 6 3 log2 entropy False 50 76: Weighted 0.783166 (0.083890)\n",
      "1 6 3 log2 entropy False 50 76: Macro 0.673929 (0.100916)\n",
      "Testing 2798/4320\n",
      "1 6 3 log2 entropy False 100 76: Weighted 0.787834 (0.088117)\n",
      "1 6 3 log2 entropy False 100 76: Macro 0.680688 (0.106489)\n",
      "Testing 2799/4320\n",
      "1 6 3 log2 entropy False 200 76: Weighted 0.787834 (0.088117)\n",
      "1 6 3 log2 entropy False 200 76: Macro 0.680688 (0.106489)\n",
      "Testing 2800/4320\n",
      "1 6 3 log2 entropy False 500 76: Weighted 0.787834 (0.088117)\n",
      "1 6 3 log2 entropy False 500 76: Macro 0.680688 (0.106489)\n",
      "Testing 2801/4320\n",
      "1 6 3 sqrt gini True 50 76: Weighted 0.787471 (0.053416)\n",
      "1 6 3 sqrt gini True 50 76: Macro 0.672345 (0.065031)\n",
      "Testing 2802/4320\n",
      "1 6 3 sqrt gini True 100 76: Weighted 0.803906 (0.053199)\n",
      "1 6 3 sqrt gini True 100 76: Macro 0.692494 (0.066574)\n",
      "Testing 2803/4320\n",
      "1 6 3 sqrt gini True 200 76: Weighted 0.811959 (0.054829)\n",
      "1 6 3 sqrt gini True 200 76: Macro 0.707294 (0.071560)\n",
      "Testing 2804/4320\n",
      "1 6 3 sqrt gini True 500 76: Weighted 0.817457 (0.053455)\n",
      "1 6 3 sqrt gini True 500 76: Macro 0.714857 (0.072653)\n",
      "Testing 2805/4320\n",
      "1 6 3 sqrt gini False 50 76: Weighted 0.795387 (0.070889)\n",
      "1 6 3 sqrt gini False 50 76: Macro 0.689300 (0.089352)\n",
      "Testing 2806/4320\n",
      "1 6 3 sqrt gini False 100 76: Weighted 0.800099 (0.079756)\n",
      "1 6 3 sqrt gini False 100 76: Macro 0.693554 (0.104338)\n",
      "Testing 2807/4320\n",
      "1 6 3 sqrt gini False 200 76: Weighted 0.804540 (0.067263)\n",
      "1 6 3 sqrt gini False 200 76: Macro 0.700997 (0.088818)\n",
      "Testing 2808/4320\n",
      "1 6 3 sqrt gini False 500 76: Weighted 0.799923 (0.073917)\n",
      "1 6 3 sqrt gini False 500 76: Macro 0.697877 (0.093328)\n",
      "Testing 2809/4320\n",
      "1 6 3 sqrt entropy True 50 76: Weighted 0.800338 (0.059751)\n",
      "1 6 3 sqrt entropy True 50 76: Macro 0.693782 (0.077238)\n",
      "Testing 2810/4320\n",
      "1 6 3 sqrt entropy True 100 76: Weighted 0.809527 (0.062607)\n",
      "1 6 3 sqrt entropy True 100 76: Macro 0.704124 (0.082794)\n",
      "Testing 2811/4320\n",
      "1 6 3 sqrt entropy True 200 76: Weighted 0.804317 (0.061898)\n",
      "1 6 3 sqrt entropy True 200 76: Macro 0.697056 (0.080675)\n",
      "Testing 2812/4320\n",
      "1 6 3 sqrt entropy True 500 76: Weighted 0.808523 (0.055575)\n",
      "1 6 3 sqrt entropy True 500 76: Macro 0.702270 (0.072850)\n",
      "Testing 2813/4320\n",
      "1 6 3 sqrt entropy False 50 76: Weighted 0.783166 (0.083890)\n",
      "1 6 3 sqrt entropy False 50 76: Macro 0.673929 (0.100916)\n",
      "Testing 2814/4320\n",
      "1 6 3 sqrt entropy False 100 76: Weighted 0.787834 (0.088117)\n",
      "1 6 3 sqrt entropy False 100 76: Macro 0.680688 (0.106489)\n",
      "Testing 2815/4320\n",
      "1 6 3 sqrt entropy False 200 76: Weighted 0.787834 (0.088117)\n",
      "1 6 3 sqrt entropy False 200 76: Macro 0.680688 (0.106489)\n",
      "Testing 2816/4320\n",
      "1 6 3 sqrt entropy False 500 76: Weighted 0.787834 (0.088117)\n",
      "1 6 3 sqrt entropy False 500 76: Macro 0.680688 (0.106489)\n",
      "Testing 2817/4320\n",
      "1 6 5 log2 gini True 50 76: Weighted 0.802223 (0.058820)\n",
      "1 6 5 log2 gini True 50 76: Macro 0.693680 (0.074126)\n",
      "Testing 2818/4320\n",
      "1 6 5 log2 gini True 100 76: Weighted 0.807129 (0.059688)\n",
      "1 6 5 log2 gini True 100 76: Macro 0.700731 (0.075190)\n",
      "Testing 2819/4320\n",
      "1 6 5 log2 gini True 200 76: Weighted 0.807129 (0.059688)\n",
      "1 6 5 log2 gini True 200 76: Macro 0.700731 (0.075190)\n",
      "Testing 2820/4320\n",
      "1 6 5 log2 gini True 500 76: Weighted 0.807129 (0.059688)\n",
      "1 6 5 log2 gini True 500 76: Macro 0.700731 (0.075190)\n",
      "Testing 2821/4320\n",
      "1 6 5 log2 gini False 50 76: Weighted 0.806441 (0.079595)\n",
      "1 6 5 log2 gini False 50 76: Macro 0.703613 (0.107119)\n",
      "Testing 2822/4320\n",
      "1 6 5 log2 gini False 100 76: Weighted 0.800169 (0.074412)\n",
      "1 6 5 log2 gini False 100 76: Macro 0.691625 (0.101882)\n",
      "Testing 2823/4320\n",
      "1 6 5 log2 gini False 200 76: Weighted 0.800169 (0.074412)\n",
      "1 6 5 log2 gini False 200 76: Macro 0.691625 (0.101882)\n",
      "Testing 2824/4320\n",
      "1 6 5 log2 gini False 500 76: Weighted 0.808504 (0.076483)\n",
      "1 6 5 log2 gini False 500 76: Macro 0.704126 (0.106322)\n",
      "Testing 2825/4320\n",
      "1 6 5 log2 entropy True 50 76: Weighted 0.812019 (0.073108)\n",
      "1 6 5 log2 entropy True 50 76: Macro 0.708399 (0.101385)\n",
      "Testing 2826/4320\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 6 5 log2 entropy True 100 76: Weighted 0.802980 (0.065446)\n",
      "1 6 5 log2 entropy True 100 76: Macro 0.691662 (0.088433)\n",
      "Testing 2827/4320\n",
      "1 6 5 log2 entropy True 200 76: Weighted 0.807129 (0.059688)\n",
      "1 6 5 log2 entropy True 200 76: Macro 0.700731 (0.075190)\n",
      "Testing 2828/4320\n",
      "1 6 5 log2 entropy True 500 76: Weighted 0.807129 (0.059688)\n",
      "1 6 5 log2 entropy True 500 76: Macro 0.700731 (0.075190)\n",
      "Testing 2829/4320\n",
      "1 6 5 log2 entropy False 50 76: Weighted 0.793832 (0.083694)\n",
      "1 6 5 log2 entropy False 50 76: Macro 0.681393 (0.117520)\n",
      "Testing 2830/4320\n",
      "1 6 5 log2 entropy False 100 76: Weighted 0.790352 (0.084789)\n",
      "1 6 5 log2 entropy False 100 76: Macro 0.676473 (0.118638)\n",
      "Testing 2831/4320\n",
      "1 6 5 log2 entropy False 200 76: Weighted 0.790352 (0.084789)\n",
      "1 6 5 log2 entropy False 200 76: Macro 0.676473 (0.118638)\n",
      "Testing 2832/4320\n",
      "1 6 5 log2 entropy False 500 76: Weighted 0.794625 (0.078757)\n",
      "1 6 5 log2 entropy False 500 76: Macro 0.686191 (0.104389)\n",
      "Testing 2833/4320\n",
      "1 6 5 sqrt gini True 50 76: Weighted 0.802223 (0.058820)\n",
      "1 6 5 sqrt gini True 50 76: Macro 0.693680 (0.074126)\n",
      "Testing 2834/4320\n",
      "1 6 5 sqrt gini True 100 76: Weighted 0.807129 (0.059688)\n",
      "1 6 5 sqrt gini True 100 76: Macro 0.700731 (0.075190)\n",
      "Testing 2835/4320\n",
      "1 6 5 sqrt gini True 200 76: Weighted 0.807129 (0.059688)\n",
      "1 6 5 sqrt gini True 200 76: Macro 0.700731 (0.075190)\n",
      "Testing 2836/4320\n",
      "1 6 5 sqrt gini True 500 76: Weighted 0.807129 (0.059688)\n",
      "1 6 5 sqrt gini True 500 76: Macro 0.700731 (0.075190)\n",
      "Testing 2837/4320\n",
      "1 6 5 sqrt gini False 50 76: Weighted 0.806441 (0.079595)\n",
      "1 6 5 sqrt gini False 50 76: Macro 0.703613 (0.107119)\n",
      "Testing 2838/4320\n",
      "1 6 5 sqrt gini False 100 76: Weighted 0.800169 (0.074412)\n",
      "1 6 5 sqrt gini False 100 76: Macro 0.691625 (0.101882)\n",
      "Testing 2839/4320\n",
      "1 6 5 sqrt gini False 200 76: Weighted 0.800169 (0.074412)\n",
      "1 6 5 sqrt gini False 200 76: Macro 0.691625 (0.101882)\n",
      "Testing 2840/4320\n",
      "1 6 5 sqrt gini False 500 76: Weighted 0.808504 (0.076483)\n",
      "1 6 5 sqrt gini False 500 76: Macro 0.704126 (0.106322)\n",
      "Testing 2841/4320\n",
      "1 6 5 sqrt entropy True 50 76: Weighted 0.812019 (0.073108)\n",
      "1 6 5 sqrt entropy True 50 76: Macro 0.708399 (0.101385)\n",
      "Testing 2842/4320\n",
      "1 6 5 sqrt entropy True 100 76: Weighted 0.802980 (0.065446)\n",
      "1 6 5 sqrt entropy True 100 76: Macro 0.691662 (0.088433)\n",
      "Testing 2843/4320\n",
      "1 6 5 sqrt entropy True 200 76: Weighted 0.807129 (0.059688)\n",
      "1 6 5 sqrt entropy True 200 76: Macro 0.700731 (0.075190)\n",
      "Testing 2844/4320\n",
      "1 6 5 sqrt entropy True 500 76: Weighted 0.807129 (0.059688)\n",
      "1 6 5 sqrt entropy True 500 76: Macro 0.700731 (0.075190)\n",
      "Testing 2845/4320\n",
      "1 6 5 sqrt entropy False 50 76: Weighted 0.793832 (0.083694)\n",
      "1 6 5 sqrt entropy False 50 76: Macro 0.681393 (0.117520)\n",
      "Testing 2846/4320\n",
      "1 6 5 sqrt entropy False 100 76: Weighted 0.790352 (0.084789)\n",
      "1 6 5 sqrt entropy False 100 76: Macro 0.676473 (0.118638)\n",
      "Testing 2847/4320\n",
      "1 6 5 sqrt entropy False 200 76: Weighted 0.790352 (0.084789)\n",
      "1 6 5 sqrt entropy False 200 76: Macro 0.676473 (0.118638)\n",
      "Testing 2848/4320\n",
      "1 6 5 sqrt entropy False 500 76: Weighted 0.794625 (0.078757)\n",
      "1 6 5 sqrt entropy False 500 76: Macro 0.686191 (0.104389)\n",
      "Testing 2849/4320\n",
      "1 6 8 log2 gini True 50 76: Weighted 0.806616 (0.048024)\n",
      "1 6 8 log2 gini True 50 76: Macro 0.698999 (0.058847)\n",
      "Testing 2850/4320\n",
      "1 6 8 log2 gini True 100 76: Weighted 0.803722 (0.061157)\n",
      "1 6 8 log2 gini True 100 76: Macro 0.695738 (0.076918)\n",
      "Testing 2851/4320\n",
      "1 6 8 log2 gini True 200 76: Weighted 0.799202 (0.054903)\n",
      "1 6 8 log2 gini True 200 76: Macro 0.688926 (0.067724)\n",
      "Testing 2852/4320\n",
      "1 6 8 log2 gini True 500 76: Weighted 0.807729 (0.056302)\n",
      "1 6 8 log2 gini True 500 76: Macro 0.700817 (0.070492)\n",
      "Testing 2853/4320\n",
      "1 6 8 log2 gini False 50 76: Weighted 0.797064 (0.063229)\n",
      "1 6 8 log2 gini False 50 76: Macro 0.690673 (0.085415)\n",
      "Testing 2854/4320\n",
      "1 6 8 log2 gini False 100 76: Weighted 0.794155 (0.076103)\n",
      "1 6 8 log2 gini False 100 76: Macro 0.686207 (0.100280)\n",
      "Testing 2855/4320\n",
      "1 6 8 log2 gini False 200 76: Weighted 0.794155 (0.076103)\n",
      "1 6 8 log2 gini False 200 76: Macro 0.686207 (0.100280)\n",
      "Testing 2856/4320\n",
      "1 6 8 log2 gini False 500 76: Weighted 0.794155 (0.076103)\n",
      "1 6 8 log2 gini False 500 76: Macro 0.686207 (0.100280)\n",
      "Testing 2857/4320\n",
      "1 6 8 log2 entropy True 50 76: Weighted 0.814602 (0.062217)\n",
      "1 6 8 log2 entropy True 50 76: Macro 0.706138 (0.087115)\n",
      "Testing 2858/4320\n",
      "1 6 8 log2 entropy True 100 76: Weighted 0.806337 (0.059981)\n",
      "1 6 8 log2 entropy True 100 76: Macro 0.701360 (0.075040)\n",
      "Testing 2859/4320\n",
      "1 6 8 log2 entropy True 200 76: Weighted 0.806337 (0.059981)\n",
      "1 6 8 log2 entropy True 200 76: Macro 0.701360 (0.075040)\n",
      "Testing 2860/4320\n",
      "1 6 8 log2 entropy True 500 76: Weighted 0.801817 (0.053810)\n",
      "1 6 8 log2 entropy True 500 76: Macro 0.694549 (0.066165)\n",
      "Testing 2861/4320\n",
      "1 6 8 log2 entropy False 50 76: Weighted 0.794635 (0.063475)\n",
      "1 6 8 log2 entropy False 50 76: Macro 0.685876 (0.081275)\n",
      "Testing 2862/4320\n",
      "1 6 8 log2 entropy False 100 76: Weighted 0.794667 (0.070927)\n",
      "1 6 8 log2 entropy False 100 76: Macro 0.683740 (0.099640)\n",
      "Testing 2863/4320\n",
      "1 6 8 log2 entropy False 200 76: Weighted 0.795533 (0.069758)\n",
      "1 6 8 log2 entropy False 200 76: Macro 0.689724 (0.090728)\n",
      "Testing 2864/4320\n",
      "1 6 8 log2 entropy False 500 76: Weighted 0.799396 (0.064706)\n",
      "1 6 8 log2 entropy False 500 76: Macro 0.694509 (0.083840)\n",
      "Testing 2865/4320\n",
      "1 6 8 sqrt gini True 50 76: Weighted 0.806616 (0.048024)\n",
      "1 6 8 sqrt gini True 50 76: Macro 0.698999 (0.058847)\n",
      "Testing 2866/4320\n",
      "1 6 8 sqrt gini True 100 76: Weighted 0.803722 (0.061157)\n",
      "1 6 8 sqrt gini True 100 76: Macro 0.695738 (0.076918)\n",
      "Testing 2867/4320\n",
      "1 6 8 sqrt gini True 200 76: Weighted 0.799202 (0.054903)\n",
      "1 6 8 sqrt gini True 200 76: Macro 0.688926 (0.067724)\n",
      "Testing 2868/4320\n",
      "1 6 8 sqrt gini True 500 76: Weighted 0.807729 (0.056302)\n",
      "1 6 8 sqrt gini True 500 76: Macro 0.700817 (0.070492)\n",
      "Testing 2869/4320\n",
      "1 6 8 sqrt gini False 50 76: Weighted 0.797064 (0.063229)\n",
      "1 6 8 sqrt gini False 50 76: Macro 0.690673 (0.085415)\n",
      "Testing 2870/4320\n",
      "1 6 8 sqrt gini False 100 76: Weighted 0.794155 (0.076103)\n",
      "1 6 8 sqrt gini False 100 76: Macro 0.686207 (0.100280)\n",
      "Testing 2871/4320\n",
      "1 6 8 sqrt gini False 200 76: Weighted 0.794155 (0.076103)\n",
      "1 6 8 sqrt gini False 200 76: Macro 0.686207 (0.100280)\n",
      "Testing 2872/4320\n",
      "1 6 8 sqrt gini False 500 76: Weighted 0.794155 (0.076103)\n",
      "1 6 8 sqrt gini False 500 76: Macro 0.686207 (0.100280)\n",
      "Testing 2873/4320\n",
      "1 6 8 sqrt entropy True 50 76: Weighted 0.814602 (0.062217)\n",
      "1 6 8 sqrt entropy True 50 76: Macro 0.706138 (0.087115)\n",
      "Testing 2874/4320\n",
      "1 6 8 sqrt entropy True 100 76: Weighted 0.806337 (0.059981)\n",
      "1 6 8 sqrt entropy True 100 76: Macro 0.701360 (0.075040)\n",
      "Testing 2875/4320\n",
      "1 6 8 sqrt entropy True 200 76: Weighted 0.806337 (0.059981)\n",
      "1 6 8 sqrt entropy True 200 76: Macro 0.701360 (0.075040)\n",
      "Testing 2876/4320\n",
      "1 6 8 sqrt entropy True 500 76: Weighted 0.801817 (0.053810)\n",
      "1 6 8 sqrt entropy True 500 76: Macro 0.694549 (0.066165)\n",
      "Testing 2877/4320\n",
      "1 6 8 sqrt entropy False 50 76: Weighted 0.794635 (0.063475)\n",
      "1 6 8 sqrt entropy False 50 76: Macro 0.685876 (0.081275)\n",
      "Testing 2878/4320\n",
      "1 6 8 sqrt entropy False 100 76: Weighted 0.794667 (0.070927)\n",
      "1 6 8 sqrt entropy False 100 76: Macro 0.683740 (0.099640)\n",
      "Testing 2879/4320\n",
      "1 6 8 sqrt entropy False 200 76: Weighted 0.795533 (0.069758)\n",
      "1 6 8 sqrt entropy False 200 76: Macro 0.689724 (0.090728)\n",
      "Testing 2880/4320\n",
      "1 6 8 sqrt entropy False 500 76: Weighted 0.799396 (0.064706)\n",
      "1 6 8 sqrt entropy False 500 76: Macro 0.694509 (0.083840)\n",
      "Testing 2881/4320\n",
      "3 2 3 log2 gini True 50 76: Weighted 0.792097 (0.050181)\n",
      "3 2 3 log2 gini True 50 76: Macro 0.675829 (0.062604)\n",
      "Testing 2882/4320\n",
      "3 2 3 log2 gini True 100 76: Weighted 0.803906 (0.053199)\n",
      "3 2 3 log2 gini True 100 76: Macro 0.692494 (0.066574)\n",
      "Testing 2883/4320\n",
      "3 2 3 log2 gini True 200 76: Weighted 0.803906 (0.053199)\n",
      "3 2 3 log2 gini True 200 76: Macro 0.692494 (0.066574)\n",
      "Testing 2884/4320\n",
      "3 2 3 log2 gini True 500 76: Weighted 0.813941 (0.055478)\n",
      "3 2 3 log2 gini True 500 76: Macro 0.709900 (0.075733)\n",
      "Testing 2885/4320\n",
      "3 2 3 log2 gini False 50 76: Weighted 0.795387 (0.070889)\n",
      "3 2 3 log2 gini False 50 76: Macro 0.689300 (0.089352)\n",
      "Testing 2886/4320\n",
      "3 2 3 log2 gini False 100 76: Weighted 0.800099 (0.079756)\n",
      "3 2 3 log2 gini False 100 76: Macro 0.693554 (0.104338)\n",
      "Testing 2887/4320\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 2 3 log2 gini False 200 76: Weighted 0.809244 (0.065497)\n",
      "3 2 3 log2 gini False 200 76: Macro 0.704564 (0.087453)\n",
      "Testing 2888/4320\n",
      "3 2 3 log2 gini False 500 76: Weighted 0.804627 (0.072614)\n",
      "3 2 3 log2 gini False 500 76: Macro 0.701445 (0.092151)\n",
      "Testing 2889/4320\n",
      "3 2 3 log2 entropy True 50 76: Weighted 0.800339 (0.051763)\n",
      "3 2 3 log2 entropy True 50 76: Macro 0.690553 (0.068616)\n",
      "Testing 2890/4320\n",
      "3 2 3 log2 entropy True 100 76: Weighted 0.805007 (0.056975)\n",
      "3 2 3 log2 entropy True 100 76: Macro 0.697312 (0.075095)\n",
      "Testing 2891/4320\n",
      "3 2 3 log2 entropy True 200 76: Weighted 0.808523 (0.055575)\n",
      "3 2 3 log2 entropy True 200 76: Macro 0.702270 (0.072850)\n",
      "Testing 2892/4320\n",
      "3 2 3 log2 entropy True 500 76: Weighted 0.808523 (0.055575)\n",
      "3 2 3 log2 entropy True 500 76: Macro 0.702270 (0.072850)\n",
      "Testing 2893/4320\n",
      "3 2 3 log2 entropy False 50 76: Weighted 0.783166 (0.083890)\n",
      "3 2 3 log2 entropy False 50 76: Macro 0.673929 (0.100916)\n",
      "Testing 2894/4320\n",
      "3 2 3 log2 entropy False 100 76: Weighted 0.787834 (0.088117)\n",
      "3 2 3 log2 entropy False 100 76: Macro 0.680688 (0.106489)\n",
      "Testing 2895/4320\n",
      "3 2 3 log2 entropy False 200 76: Weighted 0.787834 (0.088117)\n",
      "3 2 3 log2 entropy False 200 76: Macro 0.680688 (0.106489)\n",
      "Testing 2896/4320\n",
      "3 2 3 log2 entropy False 500 76: Weighted 0.787834 (0.088117)\n",
      "3 2 3 log2 entropy False 500 76: Macro 0.680688 (0.106489)\n",
      "Testing 2897/4320\n",
      "3 2 3 sqrt gini True 50 76: Weighted 0.792097 (0.050181)\n",
      "3 2 3 sqrt gini True 50 76: Macro 0.675829 (0.062604)\n",
      "Testing 2898/4320\n",
      "3 2 3 sqrt gini True 100 76: Weighted 0.803906 (0.053199)\n",
      "3 2 3 sqrt gini True 100 76: Macro 0.692494 (0.066574)\n",
      "Testing 2899/4320\n",
      "3 2 3 sqrt gini True 200 76: Weighted 0.803906 (0.053199)\n",
      "3 2 3 sqrt gini True 200 76: Macro 0.692494 (0.066574)\n",
      "Testing 2900/4320\n",
      "3 2 3 sqrt gini True 500 76: Weighted 0.813941 (0.055478)\n",
      "3 2 3 sqrt gini True 500 76: Macro 0.709900 (0.075733)\n",
      "Testing 2901/4320\n",
      "3 2 3 sqrt gini False 50 76: Weighted 0.795387 (0.070889)\n",
      "3 2 3 sqrt gini False 50 76: Macro 0.689300 (0.089352)\n",
      "Testing 2902/4320\n",
      "3 2 3 sqrt gini False 100 76: Weighted 0.800099 (0.079756)\n",
      "3 2 3 sqrt gini False 100 76: Macro 0.693554 (0.104338)\n",
      "Testing 2903/4320\n",
      "3 2 3 sqrt gini False 200 76: Weighted 0.809244 (0.065497)\n",
      "3 2 3 sqrt gini False 200 76: Macro 0.704564 (0.087453)\n",
      "Testing 2904/4320\n",
      "3 2 3 sqrt gini False 500 76: Weighted 0.804627 (0.072614)\n",
      "3 2 3 sqrt gini False 500 76: Macro 0.701445 (0.092151)\n",
      "Testing 2905/4320\n",
      "3 2 3 sqrt entropy True 50 76: Weighted 0.800339 (0.051763)\n",
      "3 2 3 sqrt entropy True 50 76: Macro 0.690553 (0.068616)\n",
      "Testing 2906/4320\n",
      "3 2 3 sqrt entropy True 100 76: Weighted 0.805007 (0.056975)\n",
      "3 2 3 sqrt entropy True 100 76: Macro 0.697312 (0.075095)\n",
      "Testing 2907/4320\n",
      "3 2 3 sqrt entropy True 200 76: Weighted 0.808523 (0.055575)\n",
      "3 2 3 sqrt entropy True 200 76: Macro 0.702270 (0.072850)\n",
      "Testing 2908/4320\n",
      "3 2 3 sqrt entropy True 500 76: Weighted 0.808523 (0.055575)\n",
      "3 2 3 sqrt entropy True 500 76: Macro 0.702270 (0.072850)\n",
      "Testing 2909/4320\n",
      "3 2 3 sqrt entropy False 50 76: Weighted 0.783166 (0.083890)\n",
      "3 2 3 sqrt entropy False 50 76: Macro 0.673929 (0.100916)\n",
      "Testing 2910/4320\n",
      "3 2 3 sqrt entropy False 100 76: Weighted 0.787834 (0.088117)\n",
      "3 2 3 sqrt entropy False 100 76: Macro 0.680688 (0.106489)\n",
      "Testing 2911/4320\n",
      "3 2 3 sqrt entropy False 200 76: Weighted 0.787834 (0.088117)\n",
      "3 2 3 sqrt entropy False 200 76: Macro 0.680688 (0.106489)\n",
      "Testing 2912/4320\n",
      "3 2 3 sqrt entropy False 500 76: Weighted 0.787834 (0.088117)\n",
      "3 2 3 sqrt entropy False 500 76: Macro 0.680688 (0.106489)\n",
      "Testing 2913/4320\n",
      "3 2 5 log2 gini True 50 76: Weighted 0.816624 (0.060205)\n",
      "3 2 5 log2 gini True 50 76: Macro 0.711473 (0.077270)\n",
      "Testing 2914/4320\n",
      "3 2 5 log2 gini True 100 76: Weighted 0.816624 (0.060205)\n",
      "3 2 5 log2 gini True 100 76: Macro 0.711473 (0.077270)\n",
      "Testing 2915/4320\n",
      "3 2 5 log2 gini True 200 76: Weighted 0.816624 (0.060205)\n",
      "3 2 5 log2 gini True 200 76: Macro 0.711473 (0.077270)\n",
      "Testing 2916/4320\n",
      "3 2 5 log2 gini True 500 76: Weighted 0.811863 (0.058581)\n",
      "3 2 5 log2 gini True 500 76: Macro 0.704330 (0.074545)\n",
      "Testing 2917/4320\n",
      "3 2 5 log2 gini False 50 76: Weighted 0.809801 (0.076137)\n",
      "3 2 5 log2 gini False 50 76: Macro 0.702701 (0.106648)\n",
      "Testing 2918/4320\n",
      "3 2 5 log2 gini False 100 76: Weighted 0.808309 (0.072708)\n",
      "3 2 5 log2 gini False 100 76: Macro 0.700217 (0.100455)\n",
      "Testing 2919/4320\n",
      "3 2 5 log2 gini False 200 76: Weighted 0.808309 (0.072708)\n",
      "3 2 5 log2 gini False 200 76: Macro 0.700217 (0.100455)\n",
      "Testing 2920/4320\n",
      "3 2 5 log2 gini False 500 76: Weighted 0.813237 (0.075536)\n",
      "3 2 5 log2 gini False 500 76: Macro 0.707725 (0.105751)\n",
      "Testing 2921/4320\n",
      "3 2 5 log2 entropy True 50 76: Weighted 0.816752 (0.071886)\n",
      "3 2 5 log2 entropy True 50 76: Macro 0.711998 (0.100634)\n",
      "Testing 2922/4320\n",
      "3 2 5 log2 entropy True 100 76: Weighted 0.810977 (0.058703)\n",
      "3 2 5 log2 entropy True 100 76: Macro 0.704859 (0.074493)\n",
      "Testing 2923/4320\n",
      "3 2 5 log2 entropy True 200 76: Weighted 0.811863 (0.058581)\n",
      "3 2 5 log2 entropy True 200 76: Macro 0.704330 (0.074545)\n",
      "Testing 2924/4320\n",
      "3 2 5 log2 entropy True 500 76: Weighted 0.811863 (0.058581)\n",
      "3 2 5 log2 entropy True 500 76: Macro 0.704330 (0.074545)\n",
      "Testing 2925/4320\n",
      "3 2 5 log2 entropy False 50 76: Weighted 0.798537 (0.082892)\n",
      "3 2 5 log2 entropy False 50 76: Macro 0.684960 (0.117091)\n",
      "Testing 2926/4320\n",
      "3 2 5 log2 entropy False 100 76: Weighted 0.792137 (0.077612)\n",
      "3 2 5 log2 entropy False 100 76: Macro 0.673483 (0.111854)\n",
      "Testing 2927/4320\n",
      "3 2 5 log2 entropy False 200 76: Weighted 0.795021 (0.083417)\n",
      "3 2 5 log2 entropy False 200 76: Macro 0.680003 (0.117775)\n",
      "Testing 2928/4320\n",
      "3 2 5 log2 entropy False 500 76: Weighted 0.797222 (0.080101)\n",
      "3 2 5 log2 entropy False 500 76: Macro 0.680906 (0.116383)\n",
      "Testing 2929/4320\n",
      "3 2 5 sqrt gini True 50 76: Weighted 0.816624 (0.060205)\n",
      "3 2 5 sqrt gini True 50 76: Macro 0.711473 (0.077270)\n",
      "Testing 2930/4320\n",
      "3 2 5 sqrt gini True 100 76: Weighted 0.816624 (0.060205)\n",
      "3 2 5 sqrt gini True 100 76: Macro 0.711473 (0.077270)\n",
      "Testing 2931/4320\n",
      "3 2 5 sqrt gini True 200 76: Weighted 0.816624 (0.060205)\n",
      "3 2 5 sqrt gini True 200 76: Macro 0.711473 (0.077270)\n",
      "Testing 2932/4320\n",
      "3 2 5 sqrt gini True 500 76: Weighted 0.811863 (0.058581)\n",
      "3 2 5 sqrt gini True 500 76: Macro 0.704330 (0.074545)\n",
      "Testing 2933/4320\n",
      "3 2 5 sqrt gini False 50 76: Weighted 0.809801 (0.076137)\n",
      "3 2 5 sqrt gini False 50 76: Macro 0.702701 (0.106648)\n",
      "Testing 2934/4320\n",
      "3 2 5 sqrt gini False 100 76: Weighted 0.808309 (0.072708)\n",
      "3 2 5 sqrt gini False 100 76: Macro 0.700217 (0.100455)\n",
      "Testing 2935/4320\n",
      "3 2 5 sqrt gini False 200 76: Weighted 0.808309 (0.072708)\n",
      "3 2 5 sqrt gini False 200 76: Macro 0.700217 (0.100455)\n",
      "Testing 2936/4320\n",
      "3 2 5 sqrt gini False 500 76: Weighted 0.813237 (0.075536)\n",
      "3 2 5 sqrt gini False 500 76: Macro 0.707725 (0.105751)\n",
      "Testing 2937/4320\n",
      "3 2 5 sqrt entropy True 50 76: Weighted 0.816752 (0.071886)\n",
      "3 2 5 sqrt entropy True 50 76: Macro 0.711998 (0.100634)\n",
      "Testing 2938/4320\n",
      "3 2 5 sqrt entropy True 100 76: Weighted 0.810977 (0.058703)\n",
      "3 2 5 sqrt entropy True 100 76: Macro 0.704859 (0.074493)\n",
      "Testing 2939/4320\n",
      "3 2 5 sqrt entropy True 200 76: Weighted 0.811863 (0.058581)\n",
      "3 2 5 sqrt entropy True 200 76: Macro 0.704330 (0.074545)\n",
      "Testing 2940/4320\n",
      "3 2 5 sqrt entropy True 500 76: Weighted 0.811863 (0.058581)\n",
      "3 2 5 sqrt entropy True 500 76: Macro 0.704330 (0.074545)\n",
      "Testing 2941/4320\n",
      "3 2 5 sqrt entropy False 50 76: Weighted 0.798537 (0.082892)\n",
      "3 2 5 sqrt entropy False 50 76: Macro 0.684960 (0.117091)\n",
      "Testing 2942/4320\n",
      "3 2 5 sqrt entropy False 100 76: Weighted 0.792137 (0.077612)\n",
      "3 2 5 sqrt entropy False 100 76: Macro 0.673483 (0.111854)\n",
      "Testing 2943/4320\n",
      "3 2 5 sqrt entropy False 200 76: Weighted 0.795021 (0.083417)\n",
      "3 2 5 sqrt entropy False 200 76: Macro 0.680003 (0.117775)\n",
      "Testing 2944/4320\n",
      "3 2 5 sqrt entropy False 500 76: Weighted 0.797222 (0.080101)\n",
      "3 2 5 sqrt entropy False 500 76: Macro 0.680906 (0.116383)\n",
      "Testing 2945/4320\n",
      "3 2 8 log2 gini True 50 76: Weighted 0.813679 (0.057546)\n",
      "3 2 8 log2 gini True 50 76: Macro 0.706570 (0.074612)\n",
      "Testing 2946/4320\n",
      "3 2 8 log2 gini True 100 76: Weighted 0.814095 (0.068599)\n",
      "3 2 8 log2 gini True 100 76: Macro 0.708452 (0.090218)\n",
      "Testing 2947/4320\n",
      "3 2 8 log2 gini True 200 76: Weighted 0.812229 (0.061512)\n",
      "3 2 8 log2 gini True 200 76: Macro 0.706711 (0.078634)\n",
      "Testing 2948/4320\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 2 8 log2 gini True 500 76: Weighted 0.811473 (0.054301)\n",
      "3 2 8 log2 gini True 500 76: Macro 0.704647 (0.068668)\n",
      "Testing 2949/4320\n",
      "3 2 8 log2 gini False 50 76: Weighted 0.815656 (0.067395)\n",
      "3 2 8 log2 gini False 50 76: Macro 0.711890 (0.092868)\n",
      "Testing 2950/4320\n",
      "3 2 8 log2 gini False 100 76: Weighted 0.802550 (0.068292)\n",
      "3 2 8 log2 gini False 100 76: Macro 0.694373 (0.091976)\n",
      "Testing 2951/4320\n",
      "3 2 8 log2 gini False 200 76: Weighted 0.801343 (0.063970)\n",
      "3 2 8 log2 gini False 200 76: Macro 0.690561 (0.084097)\n",
      "Testing 2952/4320\n",
      "3 2 8 log2 gini False 500 76: Weighted 0.811131 (0.069449)\n",
      "3 2 8 log2 gini False 500 76: Macro 0.706988 (0.095113)\n",
      "Testing 2953/4320\n",
      "3 2 8 log2 entropy True 50 76: Weighted 0.815471 (0.065854)\n",
      "3 2 8 log2 entropy True 50 76: Macro 0.704951 (0.093172)\n",
      "Testing 2954/4320\n",
      "3 2 8 log2 entropy True 100 76: Weighted 0.811863 (0.058581)\n",
      "3 2 8 log2 entropy True 100 76: Macro 0.704330 (0.074545)\n",
      "Testing 2955/4320\n",
      "3 2 8 log2 entropy True 200 76: Weighted 0.802947 (0.053450)\n",
      "3 2 8 log2 entropy True 200 76: Macro 0.692757 (0.066512)\n",
      "Testing 2956/4320\n",
      "3 2 8 log2 entropy True 500 76: Weighted 0.802947 (0.053450)\n",
      "3 2 8 log2 entropy True 500 76: Macro 0.692757 (0.066512)\n",
      "Testing 2957/4320\n",
      "3 2 8 log2 entropy False 50 76: Weighted 0.808344 (0.069115)\n",
      "3 2 8 log2 entropy False 50 76: Macro 0.704844 (0.092144)\n",
      "Testing 2958/4320\n",
      "3 2 8 log2 entropy False 100 76: Weighted 0.804684 (0.062624)\n",
      "3 2 8 log2 entropy False 100 76: Macro 0.697221 (0.083059)\n",
      "Testing 2959/4320\n",
      "3 2 8 log2 entropy False 200 76: Weighted 0.800821 (0.068131)\n",
      "3 2 8 log2 entropy False 200 76: Macro 0.692436 (0.090150)\n",
      "Testing 2960/4320\n",
      "3 2 8 log2 entropy False 500 76: Weighted 0.804684 (0.062624)\n",
      "3 2 8 log2 entropy False 500 76: Macro 0.697221 (0.083059)\n",
      "Testing 2961/4320\n",
      "3 2 8 sqrt gini True 50 76: Weighted 0.813679 (0.057546)\n",
      "3 2 8 sqrt gini True 50 76: Macro 0.706570 (0.074612)\n",
      "Testing 2962/4320\n",
      "3 2 8 sqrt gini True 100 76: Weighted 0.814095 (0.068599)\n",
      "3 2 8 sqrt gini True 100 76: Macro 0.708452 (0.090218)\n",
      "Testing 2963/4320\n",
      "3 2 8 sqrt gini True 200 76: Weighted 0.812229 (0.061512)\n",
      "3 2 8 sqrt gini True 200 76: Macro 0.706711 (0.078634)\n",
      "Testing 2964/4320\n",
      "3 2 8 sqrt gini True 500 76: Weighted 0.811473 (0.054301)\n",
      "3 2 8 sqrt gini True 500 76: Macro 0.704647 (0.068668)\n",
      "Testing 2965/4320\n",
      "3 2 8 sqrt gini False 50 76: Weighted 0.815656 (0.067395)\n",
      "3 2 8 sqrt gini False 50 76: Macro 0.711890 (0.092868)\n",
      "Testing 2966/4320\n",
      "3 2 8 sqrt gini False 100 76: Weighted 0.802550 (0.068292)\n",
      "3 2 8 sqrt gini False 100 76: Macro 0.694373 (0.091976)\n",
      "Testing 2967/4320\n",
      "3 2 8 sqrt gini False 200 76: Weighted 0.801343 (0.063970)\n",
      "3 2 8 sqrt gini False 200 76: Macro 0.690561 (0.084097)\n",
      "Testing 2968/4320\n",
      "3 2 8 sqrt gini False 500 76: Weighted 0.811131 (0.069449)\n",
      "3 2 8 sqrt gini False 500 76: Macro 0.706988 (0.095113)\n",
      "Testing 2969/4320\n",
      "3 2 8 sqrt entropy True 50 76: Weighted 0.815471 (0.065854)\n",
      "3 2 8 sqrt entropy True 50 76: Macro 0.704951 (0.093172)\n",
      "Testing 2970/4320\n",
      "3 2 8 sqrt entropy True 100 76: Weighted 0.811863 (0.058581)\n",
      "3 2 8 sqrt entropy True 100 76: Macro 0.704330 (0.074545)\n",
      "Testing 2971/4320\n",
      "3 2 8 sqrt entropy True 200 76: Weighted 0.802947 (0.053450)\n",
      "3 2 8 sqrt entropy True 200 76: Macro 0.692757 (0.066512)\n",
      "Testing 2972/4320\n",
      "3 2 8 sqrt entropy True 500 76: Weighted 0.802947 (0.053450)\n",
      "3 2 8 sqrt entropy True 500 76: Macro 0.692757 (0.066512)\n",
      "Testing 2973/4320\n",
      "3 2 8 sqrt entropy False 50 76: Weighted 0.808344 (0.069115)\n",
      "3 2 8 sqrt entropy False 50 76: Macro 0.704844 (0.092144)\n",
      "Testing 2974/4320\n",
      "3 2 8 sqrt entropy False 100 76: Weighted 0.804684 (0.062624)\n",
      "3 2 8 sqrt entropy False 100 76: Macro 0.697221 (0.083059)\n",
      "Testing 2975/4320\n",
      "3 2 8 sqrt entropy False 200 76: Weighted 0.800821 (0.068131)\n",
      "3 2 8 sqrt entropy False 200 76: Macro 0.692436 (0.090150)\n",
      "Testing 2976/4320\n",
      "3 2 8 sqrt entropy False 500 76: Weighted 0.804684 (0.062624)\n",
      "3 2 8 sqrt entropy False 500 76: Macro 0.697221 (0.083059)\n",
      "Testing 2977/4320\n",
      "3 4 3 log2 gini True 50 76: Weighted 0.792097 (0.050181)\n",
      "3 4 3 log2 gini True 50 76: Macro 0.675829 (0.062604)\n",
      "Testing 2978/4320\n",
      "3 4 3 log2 gini True 100 76: Weighted 0.803906 (0.053199)\n",
      "3 4 3 log2 gini True 100 76: Macro 0.692494 (0.066574)\n",
      "Testing 2979/4320\n",
      "3 4 3 log2 gini True 200 76: Weighted 0.803906 (0.053199)\n",
      "3 4 3 log2 gini True 200 76: Macro 0.692494 (0.066574)\n",
      "Testing 2980/4320\n",
      "3 4 3 log2 gini True 500 76: Weighted 0.813941 (0.055478)\n",
      "3 4 3 log2 gini True 500 76: Macro 0.709900 (0.075733)\n",
      "Testing 2981/4320\n",
      "3 4 3 log2 gini False 50 76: Weighted 0.795387 (0.070889)\n",
      "3 4 3 log2 gini False 50 76: Macro 0.689300 (0.089352)\n",
      "Testing 2982/4320\n",
      "3 4 3 log2 gini False 100 76: Weighted 0.800099 (0.079756)\n",
      "3 4 3 log2 gini False 100 76: Macro 0.693554 (0.104338)\n",
      "Testing 2983/4320\n",
      "3 4 3 log2 gini False 200 76: Weighted 0.809244 (0.065497)\n",
      "3 4 3 log2 gini False 200 76: Macro 0.704564 (0.087453)\n",
      "Testing 2984/4320\n",
      "3 4 3 log2 gini False 500 76: Weighted 0.804627 (0.072614)\n",
      "3 4 3 log2 gini False 500 76: Macro 0.701445 (0.092151)\n",
      "Testing 2985/4320\n",
      "3 4 3 log2 entropy True 50 76: Weighted 0.800339 (0.051763)\n",
      "3 4 3 log2 entropy True 50 76: Macro 0.690553 (0.068616)\n",
      "Testing 2986/4320\n",
      "3 4 3 log2 entropy True 100 76: Weighted 0.805007 (0.056975)\n",
      "3 4 3 log2 entropy True 100 76: Macro 0.697312 (0.075095)\n",
      "Testing 2987/4320\n",
      "3 4 3 log2 entropy True 200 76: Weighted 0.808523 (0.055575)\n",
      "3 4 3 log2 entropy True 200 76: Macro 0.702270 (0.072850)\n",
      "Testing 2988/4320\n",
      "3 4 3 log2 entropy True 500 76: Weighted 0.808523 (0.055575)\n",
      "3 4 3 log2 entropy True 500 76: Macro 0.702270 (0.072850)\n",
      "Testing 2989/4320\n",
      "3 4 3 log2 entropy False 50 76: Weighted 0.783166 (0.083890)\n",
      "3 4 3 log2 entropy False 50 76: Macro 0.673929 (0.100916)\n",
      "Testing 2990/4320\n",
      "3 4 3 log2 entropy False 100 76: Weighted 0.787834 (0.088117)\n",
      "3 4 3 log2 entropy False 100 76: Macro 0.680688 (0.106489)\n",
      "Testing 2991/4320\n",
      "3 4 3 log2 entropy False 200 76: Weighted 0.787834 (0.088117)\n",
      "3 4 3 log2 entropy False 200 76: Macro 0.680688 (0.106489)\n",
      "Testing 2992/4320\n",
      "3 4 3 log2 entropy False 500 76: Weighted 0.787834 (0.088117)\n",
      "3 4 3 log2 entropy False 500 76: Macro 0.680688 (0.106489)\n",
      "Testing 2993/4320\n",
      "3 4 3 sqrt gini True 50 76: Weighted 0.792097 (0.050181)\n",
      "3 4 3 sqrt gini True 50 76: Macro 0.675829 (0.062604)\n",
      "Testing 2994/4320\n",
      "3 4 3 sqrt gini True 100 76: Weighted 0.803906 (0.053199)\n",
      "3 4 3 sqrt gini True 100 76: Macro 0.692494 (0.066574)\n",
      "Testing 2995/4320\n",
      "3 4 3 sqrt gini True 200 76: Weighted 0.803906 (0.053199)\n",
      "3 4 3 sqrt gini True 200 76: Macro 0.692494 (0.066574)\n",
      "Testing 2996/4320\n",
      "3 4 3 sqrt gini True 500 76: Weighted 0.813941 (0.055478)\n",
      "3 4 3 sqrt gini True 500 76: Macro 0.709900 (0.075733)\n",
      "Testing 2997/4320\n",
      "3 4 3 sqrt gini False 50 76: Weighted 0.795387 (0.070889)\n",
      "3 4 3 sqrt gini False 50 76: Macro 0.689300 (0.089352)\n",
      "Testing 2998/4320\n",
      "3 4 3 sqrt gini False 100 76: Weighted 0.800099 (0.079756)\n",
      "3 4 3 sqrt gini False 100 76: Macro 0.693554 (0.104338)\n",
      "Testing 2999/4320\n",
      "3 4 3 sqrt gini False 200 76: Weighted 0.809244 (0.065497)\n",
      "3 4 3 sqrt gini False 200 76: Macro 0.704564 (0.087453)\n",
      "Testing 3000/4320\n",
      "3 4 3 sqrt gini False 500 76: Weighted 0.804627 (0.072614)\n",
      "3 4 3 sqrt gini False 500 76: Macro 0.701445 (0.092151)\n",
      "Testing 3001/4320\n",
      "3 4 3 sqrt entropy True 50 76: Weighted 0.800339 (0.051763)\n",
      "3 4 3 sqrt entropy True 50 76: Macro 0.690553 (0.068616)\n",
      "Testing 3002/4320\n",
      "3 4 3 sqrt entropy True 100 76: Weighted 0.805007 (0.056975)\n",
      "3 4 3 sqrt entropy True 100 76: Macro 0.697312 (0.075095)\n",
      "Testing 3003/4320\n",
      "3 4 3 sqrt entropy True 200 76: Weighted 0.808523 (0.055575)\n",
      "3 4 3 sqrt entropy True 200 76: Macro 0.702270 (0.072850)\n",
      "Testing 3004/4320\n",
      "3 4 3 sqrt entropy True 500 76: Weighted 0.808523 (0.055575)\n",
      "3 4 3 sqrt entropy True 500 76: Macro 0.702270 (0.072850)\n",
      "Testing 3005/4320\n",
      "3 4 3 sqrt entropy False 50 76: Weighted 0.783166 (0.083890)\n",
      "3 4 3 sqrt entropy False 50 76: Macro 0.673929 (0.100916)\n",
      "Testing 3006/4320\n",
      "3 4 3 sqrt entropy False 100 76: Weighted 0.787834 (0.088117)\n",
      "3 4 3 sqrt entropy False 100 76: Macro 0.680688 (0.106489)\n",
      "Testing 3007/4320\n",
      "3 4 3 sqrt entropy False 200 76: Weighted 0.787834 (0.088117)\n",
      "3 4 3 sqrt entropy False 200 76: Macro 0.680688 (0.106489)\n",
      "Testing 3008/4320\n",
      "3 4 3 sqrt entropy False 500 76: Weighted 0.787834 (0.088117)\n",
      "3 4 3 sqrt entropy False 500 76: Macro 0.680688 (0.106489)\n",
      "Testing 3009/4320\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 4 5 log2 gini True 50 76: Weighted 0.816624 (0.060205)\n",
      "3 4 5 log2 gini True 50 76: Macro 0.711473 (0.077270)\n",
      "Testing 3010/4320\n",
      "3 4 5 log2 gini True 100 76: Weighted 0.816624 (0.060205)\n",
      "3 4 5 log2 gini True 100 76: Macro 0.711473 (0.077270)\n",
      "Testing 3011/4320\n",
      "3 4 5 log2 gini True 200 76: Weighted 0.816624 (0.060205)\n",
      "3 4 5 log2 gini True 200 76: Macro 0.711473 (0.077270)\n",
      "Testing 3012/4320\n",
      "3 4 5 log2 gini True 500 76: Weighted 0.811863 (0.058581)\n",
      "3 4 5 log2 gini True 500 76: Macro 0.704330 (0.074545)\n",
      "Testing 3013/4320\n",
      "3 4 5 log2 gini False 50 76: Weighted 0.809801 (0.076137)\n",
      "3 4 5 log2 gini False 50 76: Macro 0.702701 (0.106648)\n",
      "Testing 3014/4320\n",
      "3 4 5 log2 gini False 100 76: Weighted 0.808309 (0.072708)\n",
      "3 4 5 log2 gini False 100 76: Macro 0.700217 (0.100455)\n",
      "Testing 3015/4320\n",
      "3 4 5 log2 gini False 200 76: Weighted 0.808309 (0.072708)\n",
      "3 4 5 log2 gini False 200 76: Macro 0.700217 (0.100455)\n",
      "Testing 3016/4320\n",
      "3 4 5 log2 gini False 500 76: Weighted 0.813237 (0.075536)\n",
      "3 4 5 log2 gini False 500 76: Macro 0.707725 (0.105751)\n",
      "Testing 3017/4320\n",
      "3 4 5 log2 entropy True 50 76: Weighted 0.816752 (0.071886)\n",
      "3 4 5 log2 entropy True 50 76: Macro 0.711998 (0.100634)\n",
      "Testing 3018/4320\n",
      "3 4 5 log2 entropy True 100 76: Weighted 0.810977 (0.058703)\n",
      "3 4 5 log2 entropy True 100 76: Macro 0.704859 (0.074493)\n",
      "Testing 3019/4320\n",
      "3 4 5 log2 entropy True 200 76: Weighted 0.811863 (0.058581)\n",
      "3 4 5 log2 entropy True 200 76: Macro 0.704330 (0.074545)\n",
      "Testing 3020/4320\n",
      "3 4 5 log2 entropy True 500 76: Weighted 0.811863 (0.058581)\n",
      "3 4 5 log2 entropy True 500 76: Macro 0.704330 (0.074545)\n",
      "Testing 3021/4320\n",
      "3 4 5 log2 entropy False 50 76: Weighted 0.798537 (0.082892)\n",
      "3 4 5 log2 entropy False 50 76: Macro 0.684960 (0.117091)\n",
      "Testing 3022/4320\n",
      "3 4 5 log2 entropy False 100 76: Weighted 0.792137 (0.077612)\n",
      "3 4 5 log2 entropy False 100 76: Macro 0.673483 (0.111854)\n",
      "Testing 3023/4320\n",
      "3 4 5 log2 entropy False 200 76: Weighted 0.795021 (0.083417)\n",
      "3 4 5 log2 entropy False 200 76: Macro 0.680003 (0.117775)\n",
      "Testing 3024/4320\n",
      "3 4 5 log2 entropy False 500 76: Weighted 0.797222 (0.080101)\n",
      "3 4 5 log2 entropy False 500 76: Macro 0.680906 (0.116383)\n",
      "Testing 3025/4320\n",
      "3 4 5 sqrt gini True 50 76: Weighted 0.816624 (0.060205)\n",
      "3 4 5 sqrt gini True 50 76: Macro 0.711473 (0.077270)\n",
      "Testing 3026/4320\n",
      "3 4 5 sqrt gini True 100 76: Weighted 0.816624 (0.060205)\n",
      "3 4 5 sqrt gini True 100 76: Macro 0.711473 (0.077270)\n",
      "Testing 3027/4320\n",
      "3 4 5 sqrt gini True 200 76: Weighted 0.816624 (0.060205)\n",
      "3 4 5 sqrt gini True 200 76: Macro 0.711473 (0.077270)\n",
      "Testing 3028/4320\n",
      "3 4 5 sqrt gini True 500 76: Weighted 0.811863 (0.058581)\n",
      "3 4 5 sqrt gini True 500 76: Macro 0.704330 (0.074545)\n",
      "Testing 3029/4320\n",
      "3 4 5 sqrt gini False 50 76: Weighted 0.809801 (0.076137)\n",
      "3 4 5 sqrt gini False 50 76: Macro 0.702701 (0.106648)\n",
      "Testing 3030/4320\n",
      "3 4 5 sqrt gini False 100 76: Weighted 0.808309 (0.072708)\n",
      "3 4 5 sqrt gini False 100 76: Macro 0.700217 (0.100455)\n",
      "Testing 3031/4320\n",
      "3 4 5 sqrt gini False 200 76: Weighted 0.808309 (0.072708)\n",
      "3 4 5 sqrt gini False 200 76: Macro 0.700217 (0.100455)\n",
      "Testing 3032/4320\n",
      "3 4 5 sqrt gini False 500 76: Weighted 0.813237 (0.075536)\n",
      "3 4 5 sqrt gini False 500 76: Macro 0.707725 (0.105751)\n",
      "Testing 3033/4320\n",
      "3 4 5 sqrt entropy True 50 76: Weighted 0.816752 (0.071886)\n",
      "3 4 5 sqrt entropy True 50 76: Macro 0.711998 (0.100634)\n",
      "Testing 3034/4320\n",
      "3 4 5 sqrt entropy True 100 76: Weighted 0.810977 (0.058703)\n",
      "3 4 5 sqrt entropy True 100 76: Macro 0.704859 (0.074493)\n",
      "Testing 3035/4320\n",
      "3 4 5 sqrt entropy True 200 76: Weighted 0.811863 (0.058581)\n",
      "3 4 5 sqrt entropy True 200 76: Macro 0.704330 (0.074545)\n",
      "Testing 3036/4320\n",
      "3 4 5 sqrt entropy True 500 76: Weighted 0.811863 (0.058581)\n",
      "3 4 5 sqrt entropy True 500 76: Macro 0.704330 (0.074545)\n",
      "Testing 3037/4320\n",
      "3 4 5 sqrt entropy False 50 76: Weighted 0.798537 (0.082892)\n",
      "3 4 5 sqrt entropy False 50 76: Macro 0.684960 (0.117091)\n",
      "Testing 3038/4320\n",
      "3 4 5 sqrt entropy False 100 76: Weighted 0.792137 (0.077612)\n",
      "3 4 5 sqrt entropy False 100 76: Macro 0.673483 (0.111854)\n",
      "Testing 3039/4320\n",
      "3 4 5 sqrt entropy False 200 76: Weighted 0.795021 (0.083417)\n",
      "3 4 5 sqrt entropy False 200 76: Macro 0.680003 (0.117775)\n",
      "Testing 3040/4320\n",
      "3 4 5 sqrt entropy False 500 76: Weighted 0.797222 (0.080101)\n",
      "3 4 5 sqrt entropy False 500 76: Macro 0.680906 (0.116383)\n",
      "Testing 3041/4320\n",
      "3 4 8 log2 gini True 50 76: Weighted 0.813679 (0.057546)\n",
      "3 4 8 log2 gini True 50 76: Macro 0.706570 (0.074612)\n",
      "Testing 3042/4320\n",
      "3 4 8 log2 gini True 100 76: Weighted 0.814095 (0.068599)\n",
      "3 4 8 log2 gini True 100 76: Macro 0.708452 (0.090218)\n",
      "Testing 3043/4320\n",
      "3 4 8 log2 gini True 200 76: Weighted 0.812229 (0.061512)\n",
      "3 4 8 log2 gini True 200 76: Macro 0.706711 (0.078634)\n",
      "Testing 3044/4320\n",
      "3 4 8 log2 gini True 500 76: Weighted 0.811473 (0.054301)\n",
      "3 4 8 log2 gini True 500 76: Macro 0.704647 (0.068668)\n",
      "Testing 3045/4320\n",
      "3 4 8 log2 gini False 50 76: Weighted 0.815656 (0.067395)\n",
      "3 4 8 log2 gini False 50 76: Macro 0.711890 (0.092868)\n",
      "Testing 3046/4320\n",
      "3 4 8 log2 gini False 100 76: Weighted 0.802550 (0.068292)\n",
      "3 4 8 log2 gini False 100 76: Macro 0.694373 (0.091976)\n",
      "Testing 3047/4320\n",
      "3 4 8 log2 gini False 200 76: Weighted 0.801343 (0.063970)\n",
      "3 4 8 log2 gini False 200 76: Macro 0.690561 (0.084097)\n",
      "Testing 3048/4320\n",
      "3 4 8 log2 gini False 500 76: Weighted 0.811131 (0.069449)\n",
      "3 4 8 log2 gini False 500 76: Macro 0.706988 (0.095113)\n",
      "Testing 3049/4320\n",
      "3 4 8 log2 entropy True 50 76: Weighted 0.815471 (0.065854)\n",
      "3 4 8 log2 entropy True 50 76: Macro 0.704951 (0.093172)\n",
      "Testing 3050/4320\n",
      "3 4 8 log2 entropy True 100 76: Weighted 0.811863 (0.058581)\n",
      "3 4 8 log2 entropy True 100 76: Macro 0.704330 (0.074545)\n",
      "Testing 3051/4320\n",
      "3 4 8 log2 entropy True 200 76: Weighted 0.802947 (0.053450)\n",
      "3 4 8 log2 entropy True 200 76: Macro 0.692757 (0.066512)\n",
      "Testing 3052/4320\n",
      "3 4 8 log2 entropy True 500 76: Weighted 0.802947 (0.053450)\n",
      "3 4 8 log2 entropy True 500 76: Macro 0.692757 (0.066512)\n",
      "Testing 3053/4320\n",
      "3 4 8 log2 entropy False 50 76: Weighted 0.808344 (0.069115)\n",
      "3 4 8 log2 entropy False 50 76: Macro 0.704844 (0.092144)\n",
      "Testing 3054/4320\n",
      "3 4 8 log2 entropy False 100 76: Weighted 0.804684 (0.062624)\n",
      "3 4 8 log2 entropy False 100 76: Macro 0.697221 (0.083059)\n",
      "Testing 3055/4320\n",
      "3 4 8 log2 entropy False 200 76: Weighted 0.800821 (0.068131)\n",
      "3 4 8 log2 entropy False 200 76: Macro 0.692436 (0.090150)\n",
      "Testing 3056/4320\n",
      "3 4 8 log2 entropy False 500 76: Weighted 0.804684 (0.062624)\n",
      "3 4 8 log2 entropy False 500 76: Macro 0.697221 (0.083059)\n",
      "Testing 3057/4320\n",
      "3 4 8 sqrt gini True 50 76: Weighted 0.813679 (0.057546)\n",
      "3 4 8 sqrt gini True 50 76: Macro 0.706570 (0.074612)\n",
      "Testing 3058/4320\n",
      "3 4 8 sqrt gini True 100 76: Weighted 0.814095 (0.068599)\n",
      "3 4 8 sqrt gini True 100 76: Macro 0.708452 (0.090218)\n",
      "Testing 3059/4320\n",
      "3 4 8 sqrt gini True 200 76: Weighted 0.812229 (0.061512)\n",
      "3 4 8 sqrt gini True 200 76: Macro 0.706711 (0.078634)\n",
      "Testing 3060/4320\n",
      "3 4 8 sqrt gini True 500 76: Weighted 0.811473 (0.054301)\n",
      "3 4 8 sqrt gini True 500 76: Macro 0.704647 (0.068668)\n",
      "Testing 3061/4320\n",
      "3 4 8 sqrt gini False 50 76: Weighted 0.815656 (0.067395)\n",
      "3 4 8 sqrt gini False 50 76: Macro 0.711890 (0.092868)\n",
      "Testing 3062/4320\n",
      "3 4 8 sqrt gini False 100 76: Weighted 0.802550 (0.068292)\n",
      "3 4 8 sqrt gini False 100 76: Macro 0.694373 (0.091976)\n",
      "Testing 3063/4320\n",
      "3 4 8 sqrt gini False 200 76: Weighted 0.801343 (0.063970)\n",
      "3 4 8 sqrt gini False 200 76: Macro 0.690561 (0.084097)\n",
      "Testing 3064/4320\n",
      "3 4 8 sqrt gini False 500 76: Weighted 0.811131 (0.069449)\n",
      "3 4 8 sqrt gini False 500 76: Macro 0.706988 (0.095113)\n",
      "Testing 3065/4320\n",
      "3 4 8 sqrt entropy True 50 76: Weighted 0.815471 (0.065854)\n",
      "3 4 8 sqrt entropy True 50 76: Macro 0.704951 (0.093172)\n",
      "Testing 3066/4320\n",
      "3 4 8 sqrt entropy True 100 76: Weighted 0.811863 (0.058581)\n",
      "3 4 8 sqrt entropy True 100 76: Macro 0.704330 (0.074545)\n",
      "Testing 3067/4320\n",
      "3 4 8 sqrt entropy True 200 76: Weighted 0.802947 (0.053450)\n",
      "3 4 8 sqrt entropy True 200 76: Macro 0.692757 (0.066512)\n",
      "Testing 3068/4320\n",
      "3 4 8 sqrt entropy True 500 76: Weighted 0.802947 (0.053450)\n",
      "3 4 8 sqrt entropy True 500 76: Macro 0.692757 (0.066512)\n",
      "Testing 3069/4320\n",
      "3 4 8 sqrt entropy False 50 76: Weighted 0.808344 (0.069115)\n",
      "3 4 8 sqrt entropy False 50 76: Macro 0.704844 (0.092144)\n",
      "Testing 3070/4320\n",
      "3 4 8 sqrt entropy False 100 76: Weighted 0.804684 (0.062624)\n",
      "3 4 8 sqrt entropy False 100 76: Macro 0.697221 (0.083059)\n",
      "Testing 3071/4320\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 4 8 sqrt entropy False 200 76: Weighted 0.800821 (0.068131)\n",
      "3 4 8 sqrt entropy False 200 76: Macro 0.692436 (0.090150)\n",
      "Testing 3072/4320\n",
      "3 4 8 sqrt entropy False 500 76: Weighted 0.804684 (0.062624)\n",
      "3 4 8 sqrt entropy False 500 76: Macro 0.697221 (0.083059)\n",
      "Testing 3073/4320\n",
      "3 6 3 log2 gini True 50 76: Weighted 0.792097 (0.050181)\n",
      "3 6 3 log2 gini True 50 76: Macro 0.675829 (0.062604)\n",
      "Testing 3074/4320\n",
      "3 6 3 log2 gini True 100 76: Weighted 0.803906 (0.053199)\n",
      "3 6 3 log2 gini True 100 76: Macro 0.692494 (0.066574)\n",
      "Testing 3075/4320\n",
      "3 6 3 log2 gini True 200 76: Weighted 0.803906 (0.053199)\n",
      "3 6 3 log2 gini True 200 76: Macro 0.692494 (0.066574)\n",
      "Testing 3076/4320\n",
      "3 6 3 log2 gini True 500 76: Weighted 0.813941 (0.055478)\n",
      "3 6 3 log2 gini True 500 76: Macro 0.709900 (0.075733)\n",
      "Testing 3077/4320\n",
      "3 6 3 log2 gini False 50 76: Weighted 0.795387 (0.070889)\n",
      "3 6 3 log2 gini False 50 76: Macro 0.689300 (0.089352)\n",
      "Testing 3078/4320\n",
      "3 6 3 log2 gini False 100 76: Weighted 0.800099 (0.079756)\n",
      "3 6 3 log2 gini False 100 76: Macro 0.693554 (0.104338)\n",
      "Testing 3079/4320\n",
      "3 6 3 log2 gini False 200 76: Weighted 0.809244 (0.065497)\n",
      "3 6 3 log2 gini False 200 76: Macro 0.704564 (0.087453)\n",
      "Testing 3080/4320\n",
      "3 6 3 log2 gini False 500 76: Weighted 0.804627 (0.072614)\n",
      "3 6 3 log2 gini False 500 76: Macro 0.701445 (0.092151)\n",
      "Testing 3081/4320\n",
      "3 6 3 log2 entropy True 50 76: Weighted 0.800339 (0.051763)\n",
      "3 6 3 log2 entropy True 50 76: Macro 0.690553 (0.068616)\n",
      "Testing 3082/4320\n",
      "3 6 3 log2 entropy True 100 76: Weighted 0.805007 (0.056975)\n",
      "3 6 3 log2 entropy True 100 76: Macro 0.697312 (0.075095)\n",
      "Testing 3083/4320\n",
      "3 6 3 log2 entropy True 200 76: Weighted 0.808523 (0.055575)\n",
      "3 6 3 log2 entropy True 200 76: Macro 0.702270 (0.072850)\n",
      "Testing 3084/4320\n",
      "3 6 3 log2 entropy True 500 76: Weighted 0.808523 (0.055575)\n",
      "3 6 3 log2 entropy True 500 76: Macro 0.702270 (0.072850)\n",
      "Testing 3085/4320\n",
      "3 6 3 log2 entropy False 50 76: Weighted 0.783166 (0.083890)\n",
      "3 6 3 log2 entropy False 50 76: Macro 0.673929 (0.100916)\n",
      "Testing 3086/4320\n",
      "3 6 3 log2 entropy False 100 76: Weighted 0.787834 (0.088117)\n",
      "3 6 3 log2 entropy False 100 76: Macro 0.680688 (0.106489)\n",
      "Testing 3087/4320\n",
      "3 6 3 log2 entropy False 200 76: Weighted 0.787834 (0.088117)\n",
      "3 6 3 log2 entropy False 200 76: Macro 0.680688 (0.106489)\n",
      "Testing 3088/4320\n",
      "3 6 3 log2 entropy False 500 76: Weighted 0.787834 (0.088117)\n",
      "3 6 3 log2 entropy False 500 76: Macro 0.680688 (0.106489)\n",
      "Testing 3089/4320\n",
      "3 6 3 sqrt gini True 50 76: Weighted 0.792097 (0.050181)\n",
      "3 6 3 sqrt gini True 50 76: Macro 0.675829 (0.062604)\n",
      "Testing 3090/4320\n",
      "3 6 3 sqrt gini True 100 76: Weighted 0.803906 (0.053199)\n",
      "3 6 3 sqrt gini True 100 76: Macro 0.692494 (0.066574)\n",
      "Testing 3091/4320\n",
      "3 6 3 sqrt gini True 200 76: Weighted 0.803906 (0.053199)\n",
      "3 6 3 sqrt gini True 200 76: Macro 0.692494 (0.066574)\n",
      "Testing 3092/4320\n",
      "3 6 3 sqrt gini True 500 76: Weighted 0.813941 (0.055478)\n",
      "3 6 3 sqrt gini True 500 76: Macro 0.709900 (0.075733)\n",
      "Testing 3093/4320\n",
      "3 6 3 sqrt gini False 50 76: Weighted 0.795387 (0.070889)\n",
      "3 6 3 sqrt gini False 50 76: Macro 0.689300 (0.089352)\n",
      "Testing 3094/4320\n",
      "3 6 3 sqrt gini False 100 76: Weighted 0.800099 (0.079756)\n",
      "3 6 3 sqrt gini False 100 76: Macro 0.693554 (0.104338)\n",
      "Testing 3095/4320\n",
      "3 6 3 sqrt gini False 200 76: Weighted 0.809244 (0.065497)\n",
      "3 6 3 sqrt gini False 200 76: Macro 0.704564 (0.087453)\n",
      "Testing 3096/4320\n",
      "3 6 3 sqrt gini False 500 76: Weighted 0.804627 (0.072614)\n",
      "3 6 3 sqrt gini False 500 76: Macro 0.701445 (0.092151)\n",
      "Testing 3097/4320\n",
      "3 6 3 sqrt entropy True 50 76: Weighted 0.800339 (0.051763)\n",
      "3 6 3 sqrt entropy True 50 76: Macro 0.690553 (0.068616)\n",
      "Testing 3098/4320\n",
      "3 6 3 sqrt entropy True 100 76: Weighted 0.805007 (0.056975)\n",
      "3 6 3 sqrt entropy True 100 76: Macro 0.697312 (0.075095)\n",
      "Testing 3099/4320\n",
      "3 6 3 sqrt entropy True 200 76: Weighted 0.808523 (0.055575)\n",
      "3 6 3 sqrt entropy True 200 76: Macro 0.702270 (0.072850)\n",
      "Testing 3100/4320\n",
      "3 6 3 sqrt entropy True 500 76: Weighted 0.808523 (0.055575)\n",
      "3 6 3 sqrt entropy True 500 76: Macro 0.702270 (0.072850)\n",
      "Testing 3101/4320\n",
      "3 6 3 sqrt entropy False 50 76: Weighted 0.783166 (0.083890)\n",
      "3 6 3 sqrt entropy False 50 76: Macro 0.673929 (0.100916)\n",
      "Testing 3102/4320\n",
      "3 6 3 sqrt entropy False 100 76: Weighted 0.787834 (0.088117)\n",
      "3 6 3 sqrt entropy False 100 76: Macro 0.680688 (0.106489)\n",
      "Testing 3103/4320\n",
      "3 6 3 sqrt entropy False 200 76: Weighted 0.787834 (0.088117)\n",
      "3 6 3 sqrt entropy False 200 76: Macro 0.680688 (0.106489)\n",
      "Testing 3104/4320\n",
      "3 6 3 sqrt entropy False 500 76: Weighted 0.787834 (0.088117)\n",
      "3 6 3 sqrt entropy False 500 76: Macro 0.680688 (0.106489)\n",
      "Testing 3105/4320\n",
      "3 6 5 log2 gini True 50 76: Weighted 0.816624 (0.060205)\n",
      "3 6 5 log2 gini True 50 76: Macro 0.711473 (0.077270)\n",
      "Testing 3106/4320\n",
      "3 6 5 log2 gini True 100 76: Weighted 0.816624 (0.060205)\n",
      "3 6 5 log2 gini True 100 76: Macro 0.711473 (0.077270)\n",
      "Testing 3107/4320\n",
      "3 6 5 log2 gini True 200 76: Weighted 0.816624 (0.060205)\n",
      "3 6 5 log2 gini True 200 76: Macro 0.711473 (0.077270)\n",
      "Testing 3108/4320\n",
      "3 6 5 log2 gini True 500 76: Weighted 0.811863 (0.058581)\n",
      "3 6 5 log2 gini True 500 76: Macro 0.704330 (0.074545)\n",
      "Testing 3109/4320\n",
      "3 6 5 log2 gini False 50 76: Weighted 0.809801 (0.076137)\n",
      "3 6 5 log2 gini False 50 76: Macro 0.702701 (0.106648)\n",
      "Testing 3110/4320\n",
      "3 6 5 log2 gini False 100 76: Weighted 0.808309 (0.072708)\n",
      "3 6 5 log2 gini False 100 76: Macro 0.700217 (0.100455)\n",
      "Testing 3111/4320\n",
      "3 6 5 log2 gini False 200 76: Weighted 0.808309 (0.072708)\n",
      "3 6 5 log2 gini False 200 76: Macro 0.700217 (0.100455)\n",
      "Testing 3112/4320\n",
      "3 6 5 log2 gini False 500 76: Weighted 0.813237 (0.075536)\n",
      "3 6 5 log2 gini False 500 76: Macro 0.707725 (0.105751)\n",
      "Testing 3113/4320\n",
      "3 6 5 log2 entropy True 50 76: Weighted 0.816752 (0.071886)\n",
      "3 6 5 log2 entropy True 50 76: Macro 0.711998 (0.100634)\n",
      "Testing 3114/4320\n",
      "3 6 5 log2 entropy True 100 76: Weighted 0.810977 (0.058703)\n",
      "3 6 5 log2 entropy True 100 76: Macro 0.704859 (0.074493)\n",
      "Testing 3115/4320\n",
      "3 6 5 log2 entropy True 200 76: Weighted 0.811863 (0.058581)\n",
      "3 6 5 log2 entropy True 200 76: Macro 0.704330 (0.074545)\n",
      "Testing 3116/4320\n",
      "3 6 5 log2 entropy True 500 76: Weighted 0.811863 (0.058581)\n",
      "3 6 5 log2 entropy True 500 76: Macro 0.704330 (0.074545)\n",
      "Testing 3117/4320\n",
      "3 6 5 log2 entropy False 50 76: Weighted 0.798537 (0.082892)\n",
      "3 6 5 log2 entropy False 50 76: Macro 0.684960 (0.117091)\n",
      "Testing 3118/4320\n",
      "3 6 5 log2 entropy False 100 76: Weighted 0.792137 (0.077612)\n",
      "3 6 5 log2 entropy False 100 76: Macro 0.673483 (0.111854)\n",
      "Testing 3119/4320\n",
      "3 6 5 log2 entropy False 200 76: Weighted 0.795021 (0.083417)\n",
      "3 6 5 log2 entropy False 200 76: Macro 0.680003 (0.117775)\n",
      "Testing 3120/4320\n",
      "3 6 5 log2 entropy False 500 76: Weighted 0.797222 (0.080101)\n",
      "3 6 5 log2 entropy False 500 76: Macro 0.680906 (0.116383)\n",
      "Testing 3121/4320\n",
      "3 6 5 sqrt gini True 50 76: Weighted 0.816624 (0.060205)\n",
      "3 6 5 sqrt gini True 50 76: Macro 0.711473 (0.077270)\n",
      "Testing 3122/4320\n",
      "3 6 5 sqrt gini True 100 76: Weighted 0.816624 (0.060205)\n",
      "3 6 5 sqrt gini True 100 76: Macro 0.711473 (0.077270)\n",
      "Testing 3123/4320\n",
      "3 6 5 sqrt gini True 200 76: Weighted 0.816624 (0.060205)\n",
      "3 6 5 sqrt gini True 200 76: Macro 0.711473 (0.077270)\n",
      "Testing 3124/4320\n",
      "3 6 5 sqrt gini True 500 76: Weighted 0.811863 (0.058581)\n",
      "3 6 5 sqrt gini True 500 76: Macro 0.704330 (0.074545)\n",
      "Testing 3125/4320\n",
      "3 6 5 sqrt gini False 50 76: Weighted 0.809801 (0.076137)\n",
      "3 6 5 sqrt gini False 50 76: Macro 0.702701 (0.106648)\n",
      "Testing 3126/4320\n",
      "3 6 5 sqrt gini False 100 76: Weighted 0.808309 (0.072708)\n",
      "3 6 5 sqrt gini False 100 76: Macro 0.700217 (0.100455)\n",
      "Testing 3127/4320\n",
      "3 6 5 sqrt gini False 200 76: Weighted 0.808309 (0.072708)\n",
      "3 6 5 sqrt gini False 200 76: Macro 0.700217 (0.100455)\n",
      "Testing 3128/4320\n",
      "3 6 5 sqrt gini False 500 76: Weighted 0.813237 (0.075536)\n",
      "3 6 5 sqrt gini False 500 76: Macro 0.707725 (0.105751)\n",
      "Testing 3129/4320\n",
      "3 6 5 sqrt entropy True 50 76: Weighted 0.816752 (0.071886)\n",
      "3 6 5 sqrt entropy True 50 76: Macro 0.711998 (0.100634)\n",
      "Testing 3130/4320\n",
      "3 6 5 sqrt entropy True 100 76: Weighted 0.810977 (0.058703)\n",
      "3 6 5 sqrt entropy True 100 76: Macro 0.704859 (0.074493)\n",
      "Testing 3131/4320\n",
      "3 6 5 sqrt entropy True 200 76: Weighted 0.811863 (0.058581)\n",
      "3 6 5 sqrt entropy True 200 76: Macro 0.704330 (0.074545)\n",
      "Testing 3132/4320\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 6 5 sqrt entropy True 500 76: Weighted 0.811863 (0.058581)\n",
      "3 6 5 sqrt entropy True 500 76: Macro 0.704330 (0.074545)\n",
      "Testing 3133/4320\n",
      "3 6 5 sqrt entropy False 50 76: Weighted 0.798537 (0.082892)\n",
      "3 6 5 sqrt entropy False 50 76: Macro 0.684960 (0.117091)\n",
      "Testing 3134/4320\n",
      "3 6 5 sqrt entropy False 100 76: Weighted 0.792137 (0.077612)\n",
      "3 6 5 sqrt entropy False 100 76: Macro 0.673483 (0.111854)\n",
      "Testing 3135/4320\n",
      "3 6 5 sqrt entropy False 200 76: Weighted 0.795021 (0.083417)\n",
      "3 6 5 sqrt entropy False 200 76: Macro 0.680003 (0.117775)\n",
      "Testing 3136/4320\n",
      "3 6 5 sqrt entropy False 500 76: Weighted 0.797222 (0.080101)\n",
      "3 6 5 sqrt entropy False 500 76: Macro 0.680906 (0.116383)\n",
      "Testing 3137/4320\n",
      "3 6 8 log2 gini True 50 76: Weighted 0.813679 (0.057546)\n",
      "3 6 8 log2 gini True 50 76: Macro 0.706570 (0.074612)\n",
      "Testing 3138/4320\n",
      "3 6 8 log2 gini True 100 76: Weighted 0.814095 (0.068599)\n",
      "3 6 8 log2 gini True 100 76: Macro 0.708452 (0.090218)\n",
      "Testing 3139/4320\n",
      "3 6 8 log2 gini True 200 76: Weighted 0.812229 (0.061512)\n",
      "3 6 8 log2 gini True 200 76: Macro 0.706711 (0.078634)\n",
      "Testing 3140/4320\n",
      "3 6 8 log2 gini True 500 76: Weighted 0.811473 (0.054301)\n",
      "3 6 8 log2 gini True 500 76: Macro 0.704647 (0.068668)\n",
      "Testing 3141/4320\n",
      "3 6 8 log2 gini False 50 76: Weighted 0.815656 (0.067395)\n",
      "3 6 8 log2 gini False 50 76: Macro 0.711890 (0.092868)\n",
      "Testing 3142/4320\n",
      "3 6 8 log2 gini False 100 76: Weighted 0.802550 (0.068292)\n",
      "3 6 8 log2 gini False 100 76: Macro 0.694373 (0.091976)\n",
      "Testing 3143/4320\n",
      "3 6 8 log2 gini False 200 76: Weighted 0.801343 (0.063970)\n",
      "3 6 8 log2 gini False 200 76: Macro 0.690561 (0.084097)\n",
      "Testing 3144/4320\n",
      "3 6 8 log2 gini False 500 76: Weighted 0.811131 (0.069449)\n",
      "3 6 8 log2 gini False 500 76: Macro 0.706988 (0.095113)\n",
      "Testing 3145/4320\n",
      "3 6 8 log2 entropy True 50 76: Weighted 0.815471 (0.065854)\n",
      "3 6 8 log2 entropy True 50 76: Macro 0.704951 (0.093172)\n",
      "Testing 3146/4320\n",
      "3 6 8 log2 entropy True 100 76: Weighted 0.811863 (0.058581)\n",
      "3 6 8 log2 entropy True 100 76: Macro 0.704330 (0.074545)\n",
      "Testing 3147/4320\n",
      "3 6 8 log2 entropy True 200 76: Weighted 0.802947 (0.053450)\n",
      "3 6 8 log2 entropy True 200 76: Macro 0.692757 (0.066512)\n",
      "Testing 3148/4320\n",
      "3 6 8 log2 entropy True 500 76: Weighted 0.802947 (0.053450)\n",
      "3 6 8 log2 entropy True 500 76: Macro 0.692757 (0.066512)\n",
      "Testing 3149/4320\n",
      "3 6 8 log2 entropy False 50 76: Weighted 0.808344 (0.069115)\n",
      "3 6 8 log2 entropy False 50 76: Macro 0.704844 (0.092144)\n",
      "Testing 3150/4320\n",
      "3 6 8 log2 entropy False 100 76: Weighted 0.804684 (0.062624)\n",
      "3 6 8 log2 entropy False 100 76: Macro 0.697221 (0.083059)\n",
      "Testing 3151/4320\n",
      "3 6 8 log2 entropy False 200 76: Weighted 0.800821 (0.068131)\n",
      "3 6 8 log2 entropy False 200 76: Macro 0.692436 (0.090150)\n",
      "Testing 3152/4320\n",
      "3 6 8 log2 entropy False 500 76: Weighted 0.804684 (0.062624)\n",
      "3 6 8 log2 entropy False 500 76: Macro 0.697221 (0.083059)\n",
      "Testing 3153/4320\n",
      "3 6 8 sqrt gini True 50 76: Weighted 0.813679 (0.057546)\n",
      "3 6 8 sqrt gini True 50 76: Macro 0.706570 (0.074612)\n",
      "Testing 3154/4320\n",
      "3 6 8 sqrt gini True 100 76: Weighted 0.814095 (0.068599)\n",
      "3 6 8 sqrt gini True 100 76: Macro 0.708452 (0.090218)\n",
      "Testing 3155/4320\n",
      "3 6 8 sqrt gini True 200 76: Weighted 0.812229 (0.061512)\n",
      "3 6 8 sqrt gini True 200 76: Macro 0.706711 (0.078634)\n",
      "Testing 3156/4320\n",
      "3 6 8 sqrt gini True 500 76: Weighted 0.811473 (0.054301)\n",
      "3 6 8 sqrt gini True 500 76: Macro 0.704647 (0.068668)\n",
      "Testing 3157/4320\n",
      "3 6 8 sqrt gini False 50 76: Weighted 0.815656 (0.067395)\n",
      "3 6 8 sqrt gini False 50 76: Macro 0.711890 (0.092868)\n",
      "Testing 3158/4320\n",
      "3 6 8 sqrt gini False 100 76: Weighted 0.802550 (0.068292)\n",
      "3 6 8 sqrt gini False 100 76: Macro 0.694373 (0.091976)\n",
      "Testing 3159/4320\n",
      "3 6 8 sqrt gini False 200 76: Weighted 0.801343 (0.063970)\n",
      "3 6 8 sqrt gini False 200 76: Macro 0.690561 (0.084097)\n",
      "Testing 3160/4320\n",
      "3 6 8 sqrt gini False 500 76: Weighted 0.811131 (0.069449)\n",
      "3 6 8 sqrt gini False 500 76: Macro 0.706988 (0.095113)\n",
      "Testing 3161/4320\n",
      "3 6 8 sqrt entropy True 50 76: Weighted 0.815471 (0.065854)\n",
      "3 6 8 sqrt entropy True 50 76: Macro 0.704951 (0.093172)\n",
      "Testing 3162/4320\n",
      "3 6 8 sqrt entropy True 100 76: Weighted 0.811863 (0.058581)\n",
      "3 6 8 sqrt entropy True 100 76: Macro 0.704330 (0.074545)\n",
      "Testing 3163/4320\n",
      "3 6 8 sqrt entropy True 200 76: Weighted 0.802947 (0.053450)\n",
      "3 6 8 sqrt entropy True 200 76: Macro 0.692757 (0.066512)\n",
      "Testing 3164/4320\n",
      "3 6 8 sqrt entropy True 500 76: Weighted 0.802947 (0.053450)\n",
      "3 6 8 sqrt entropy True 500 76: Macro 0.692757 (0.066512)\n",
      "Testing 3165/4320\n",
      "3 6 8 sqrt entropy False 50 76: Weighted 0.808344 (0.069115)\n",
      "3 6 8 sqrt entropy False 50 76: Macro 0.704844 (0.092144)\n",
      "Testing 3166/4320\n",
      "3 6 8 sqrt entropy False 100 76: Weighted 0.804684 (0.062624)\n",
      "3 6 8 sqrt entropy False 100 76: Macro 0.697221 (0.083059)\n",
      "Testing 3167/4320\n",
      "3 6 8 sqrt entropy False 200 76: Weighted 0.800821 (0.068131)\n",
      "3 6 8 sqrt entropy False 200 76: Macro 0.692436 (0.090150)\n",
      "Testing 3168/4320\n",
      "3 6 8 sqrt entropy False 500 76: Weighted 0.804684 (0.062624)\n",
      "3 6 8 sqrt entropy False 500 76: Macro 0.697221 (0.083059)\n",
      "Testing 3169/4320\n",
      "5 2 3 log2 gini True 50 76: Weighted 0.796714 (0.053719)\n",
      "5 2 3 log2 gini True 50 76: Macro 0.685604 (0.071554)\n",
      "Testing 3170/4320\n",
      "5 2 3 log2 gini True 100 76: Weighted 0.812104 (0.054913)\n",
      "5 2 3 log2 gini True 100 76: Macro 0.704661 (0.069679)\n",
      "Testing 3171/4320\n",
      "5 2 3 log2 gini True 200 76: Weighted 0.807343 (0.052721)\n",
      "5 2 3 log2 gini True 200 76: Macro 0.697519 (0.065910)\n",
      "Testing 3172/4320\n",
      "5 2 3 log2 gini True 500 76: Weighted 0.817457 (0.053455)\n",
      "5 2 3 log2 gini True 500 76: Macro 0.714857 (0.072653)\n",
      "Testing 3173/4320\n",
      "5 2 3 log2 gini False 50 76: Weighted 0.801060 (0.062389)\n",
      "5 2 3 log2 gini False 50 76: Macro 0.692847 (0.084279)\n",
      "Testing 3174/4320\n",
      "5 2 3 log2 gini False 100 76: Weighted 0.809244 (0.065497)\n",
      "5 2 3 log2 gini False 100 76: Macro 0.704564 (0.087453)\n",
      "Testing 3175/4320\n",
      "5 2 3 log2 gini False 200 76: Weighted 0.809244 (0.065497)\n",
      "5 2 3 log2 gini False 200 76: Macro 0.704564 (0.087453)\n",
      "Testing 3176/4320\n",
      "5 2 3 log2 gini False 500 76: Weighted 0.813081 (0.059751)\n",
      "5 2 3 log2 gini False 500 76: Macro 0.712700 (0.075647)\n",
      "Testing 3177/4320\n",
      "5 2 3 log2 entropy True 50 76: Weighted 0.805007 (0.056975)\n",
      "5 2 3 log2 entropy True 50 76: Macro 0.697312 (0.075095)\n",
      "Testing 3178/4320\n",
      "5 2 3 log2 entropy True 100 76: Weighted 0.813043 (0.061075)\n",
      "5 2 3 log2 entropy True 100 76: Macro 0.709081 (0.080344)\n",
      "Testing 3179/4320\n",
      "5 2 3 log2 entropy True 200 76: Weighted 0.813043 (0.061075)\n",
      "5 2 3 log2 entropy True 200 76: Macro 0.709081 (0.080344)\n",
      "Testing 3180/4320\n",
      "5 2 3 log2 entropy True 500 76: Weighted 0.808523 (0.055575)\n",
      "5 2 3 log2 entropy True 500 76: Macro 0.702270 (0.072850)\n",
      "Testing 3181/4320\n",
      "5 2 3 log2 entropy False 50 76: Weighted 0.783967 (0.082559)\n",
      "5 2 3 log2 entropy False 50 76: Macro 0.674187 (0.100493)\n",
      "Testing 3182/4320\n",
      "5 2 3 log2 entropy False 100 76: Weighted 0.787834 (0.088117)\n",
      "5 2 3 log2 entropy False 100 76: Macro 0.680688 (0.106489)\n",
      "Testing 3183/4320\n",
      "5 2 3 log2 entropy False 200 76: Weighted 0.787834 (0.088117)\n",
      "5 2 3 log2 entropy False 200 76: Macro 0.680688 (0.106489)\n",
      "Testing 3184/4320\n",
      "5 2 3 log2 entropy False 500 76: Weighted 0.787834 (0.088117)\n",
      "5 2 3 log2 entropy False 500 76: Macro 0.680688 (0.106489)\n",
      "Testing 3185/4320\n",
      "5 2 3 sqrt gini True 50 76: Weighted 0.796714 (0.053719)\n",
      "5 2 3 sqrt gini True 50 76: Macro 0.685604 (0.071554)\n",
      "Testing 3186/4320\n",
      "5 2 3 sqrt gini True 100 76: Weighted 0.812104 (0.054913)\n",
      "5 2 3 sqrt gini True 100 76: Macro 0.704661 (0.069679)\n",
      "Testing 3187/4320\n",
      "5 2 3 sqrt gini True 200 76: Weighted 0.807343 (0.052721)\n",
      "5 2 3 sqrt gini True 200 76: Macro 0.697519 (0.065910)\n",
      "Testing 3188/4320\n",
      "5 2 3 sqrt gini True 500 76: Weighted 0.817457 (0.053455)\n",
      "5 2 3 sqrt gini True 500 76: Macro 0.714857 (0.072653)\n",
      "Testing 3189/4320\n",
      "5 2 3 sqrt gini False 50 76: Weighted 0.801060 (0.062389)\n",
      "5 2 3 sqrt gini False 50 76: Macro 0.692847 (0.084279)\n",
      "Testing 3190/4320\n",
      "5 2 3 sqrt gini False 100 76: Weighted 0.809244 (0.065497)\n",
      "5 2 3 sqrt gini False 100 76: Macro 0.704564 (0.087453)\n",
      "Testing 3191/4320\n",
      "5 2 3 sqrt gini False 200 76: Weighted 0.809244 (0.065497)\n",
      "5 2 3 sqrt gini False 200 76: Macro 0.704564 (0.087453)\n",
      "Testing 3192/4320\n",
      "5 2 3 sqrt gini False 500 76: Weighted 0.813081 (0.059751)\n",
      "5 2 3 sqrt gini False 500 76: Macro 0.712700 (0.075647)\n",
      "Testing 3193/4320\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 2 3 sqrt entropy True 50 76: Weighted 0.805007 (0.056975)\n",
      "5 2 3 sqrt entropy True 50 76: Macro 0.697312 (0.075095)\n",
      "Testing 3194/4320\n",
      "5 2 3 sqrt entropy True 100 76: Weighted 0.813043 (0.061075)\n",
      "5 2 3 sqrt entropy True 100 76: Macro 0.709081 (0.080344)\n",
      "Testing 3195/4320\n",
      "5 2 3 sqrt entropy True 200 76: Weighted 0.813043 (0.061075)\n",
      "5 2 3 sqrt entropy True 200 76: Macro 0.709081 (0.080344)\n",
      "Testing 3196/4320\n",
      "5 2 3 sqrt entropy True 500 76: Weighted 0.808523 (0.055575)\n",
      "5 2 3 sqrt entropy True 500 76: Macro 0.702270 (0.072850)\n",
      "Testing 3197/4320\n",
      "5 2 3 sqrt entropy False 50 76: Weighted 0.783967 (0.082559)\n",
      "5 2 3 sqrt entropy False 50 76: Macro 0.674187 (0.100493)\n",
      "Testing 3198/4320\n",
      "5 2 3 sqrt entropy False 100 76: Weighted 0.787834 (0.088117)\n",
      "5 2 3 sqrt entropy False 100 76: Macro 0.680688 (0.106489)\n",
      "Testing 3199/4320\n",
      "5 2 3 sqrt entropy False 200 76: Weighted 0.787834 (0.088117)\n",
      "5 2 3 sqrt entropy False 200 76: Macro 0.680688 (0.106489)\n",
      "Testing 3200/4320\n",
      "5 2 3 sqrt entropy False 500 76: Weighted 0.787834 (0.088117)\n",
      "5 2 3 sqrt entropy False 500 76: Macro 0.680688 (0.106489)\n",
      "Testing 3201/4320\n",
      "5 2 5 log2 gini True 50 76: Weighted 0.815739 (0.060394)\n",
      "5 2 5 log2 gini True 50 76: Macro 0.712002 (0.077172)\n",
      "Testing 3202/4320\n",
      "5 2 5 log2 gini True 100 76: Weighted 0.811590 (0.066628)\n",
      "5 2 5 log2 gini True 100 76: Macro 0.702933 (0.091251)\n",
      "Testing 3203/4320\n",
      "5 2 5 log2 gini True 200 76: Weighted 0.815739 (0.060394)\n",
      "5 2 5 log2 gini True 200 76: Macro 0.712002 (0.077172)\n",
      "Testing 3204/4320\n",
      "5 2 5 log2 gini True 500 76: Weighted 0.816624 (0.060205)\n",
      "5 2 5 log2 gini True 500 76: Macro 0.711473 (0.077270)\n",
      "Testing 3205/4320\n",
      "5 2 5 log2 gini False 50 76: Weighted 0.807389 (0.072746)\n",
      "5 2 5 log2 gini False 50 76: Macro 0.699038 (0.099441)\n",
      "Testing 3206/4320\n",
      "5 2 5 log2 gini False 100 76: Weighted 0.807424 (0.072763)\n",
      "5 2 5 log2 gini False 100 76: Macro 0.700746 (0.100438)\n",
      "Testing 3207/4320\n",
      "5 2 5 log2 gini False 200 76: Weighted 0.807424 (0.072763)\n",
      "5 2 5 log2 gini False 200 76: Macro 0.700746 (0.100438)\n",
      "Testing 3208/4320\n",
      "5 2 5 log2 gini False 500 76: Weighted 0.812352 (0.075646)\n",
      "5 2 5 log2 gini False 500 76: Macro 0.708254 (0.105698)\n",
      "Testing 3209/4320\n",
      "5 2 5 log2 entropy True 50 76: Weighted 0.817466 (0.066908)\n",
      "5 2 5 log2 entropy True 50 76: Macro 0.716043 (0.088972)\n",
      "Testing 3210/4320\n",
      "5 2 5 log2 entropy True 100 76: Weighted 0.810977 (0.058703)\n",
      "5 2 5 log2 entropy True 100 76: Macro 0.704859 (0.074493)\n",
      "Testing 3211/4320\n",
      "5 2 5 log2 entropy True 200 76: Weighted 0.811863 (0.058581)\n",
      "5 2 5 log2 entropy True 200 76: Macro 0.704330 (0.074545)\n",
      "Testing 3212/4320\n",
      "5 2 5 log2 entropy True 500 76: Weighted 0.811863 (0.058581)\n",
      "5 2 5 log2 entropy True 500 76: Macro 0.704330 (0.074545)\n",
      "Testing 3213/4320\n",
      "5 2 5 log2 entropy False 50 76: Weighted 0.803914 (0.073297)\n",
      "5 2 5 log2 entropy False 50 76: Macro 0.695455 (0.100978)\n",
      "Testing 3214/4320\n",
      "5 2 5 log2 entropy False 100 76: Weighted 0.795264 (0.071879)\n",
      "5 2 5 log2 entropy False 100 76: Macro 0.682868 (0.097827)\n",
      "Testing 3215/4320\n",
      "5 2 5 log2 entropy False 200 76: Weighted 0.799778 (0.079587)\n",
      "5 2 5 log2 entropy False 200 76: Macro 0.686126 (0.115632)\n",
      "Testing 3216/4320\n",
      "5 2 5 log2 entropy False 500 76: Weighted 0.804873 (0.073101)\n",
      "5 2 5 log2 entropy False 500 76: Macro 0.695192 (0.101026)\n",
      "Testing 3217/4320\n",
      "5 2 5 sqrt gini True 50 76: Weighted 0.815739 (0.060394)\n",
      "5 2 5 sqrt gini True 50 76: Macro 0.712002 (0.077172)\n",
      "Testing 3218/4320\n",
      "5 2 5 sqrt gini True 100 76: Weighted 0.811590 (0.066628)\n",
      "5 2 5 sqrt gini True 100 76: Macro 0.702933 (0.091251)\n",
      "Testing 3219/4320\n",
      "5 2 5 sqrt gini True 200 76: Weighted 0.815739 (0.060394)\n",
      "5 2 5 sqrt gini True 200 76: Macro 0.712002 (0.077172)\n",
      "Testing 3220/4320\n",
      "5 2 5 sqrt gini True 500 76: Weighted 0.816624 (0.060205)\n",
      "5 2 5 sqrt gini True 500 76: Macro 0.711473 (0.077270)\n",
      "Testing 3221/4320\n",
      "5 2 5 sqrt gini False 50 76: Weighted 0.807389 (0.072746)\n",
      "5 2 5 sqrt gini False 50 76: Macro 0.699038 (0.099441)\n",
      "Testing 3222/4320\n",
      "5 2 5 sqrt gini False 100 76: Weighted 0.807424 (0.072763)\n",
      "5 2 5 sqrt gini False 100 76: Macro 0.700746 (0.100438)\n",
      "Testing 3223/4320\n",
      "5 2 5 sqrt gini False 200 76: Weighted 0.807424 (0.072763)\n",
      "5 2 5 sqrt gini False 200 76: Macro 0.700746 (0.100438)\n",
      "Testing 3224/4320\n",
      "5 2 5 sqrt gini False 500 76: Weighted 0.812352 (0.075646)\n",
      "5 2 5 sqrt gini False 500 76: Macro 0.708254 (0.105698)\n",
      "Testing 3225/4320\n",
      "5 2 5 sqrt entropy True 50 76: Weighted 0.817466 (0.066908)\n",
      "5 2 5 sqrt entropy True 50 76: Macro 0.716043 (0.088972)\n",
      "Testing 3226/4320\n",
      "5 2 5 sqrt entropy True 100 76: Weighted 0.810977 (0.058703)\n",
      "5 2 5 sqrt entropy True 100 76: Macro 0.704859 (0.074493)\n",
      "Testing 3227/4320\n",
      "5 2 5 sqrt entropy True 200 76: Weighted 0.811863 (0.058581)\n",
      "5 2 5 sqrt entropy True 200 76: Macro 0.704330 (0.074545)\n",
      "Testing 3228/4320\n",
      "5 2 5 sqrt entropy True 500 76: Weighted 0.811863 (0.058581)\n",
      "5 2 5 sqrt entropy True 500 76: Macro 0.704330 (0.074545)\n",
      "Testing 3229/4320\n",
      "5 2 5 sqrt entropy False 50 76: Weighted 0.803914 (0.073297)\n",
      "5 2 5 sqrt entropy False 50 76: Macro 0.695455 (0.100978)\n",
      "Testing 3230/4320\n",
      "5 2 5 sqrt entropy False 100 76: Weighted 0.795264 (0.071879)\n",
      "5 2 5 sqrt entropy False 100 76: Macro 0.682868 (0.097827)\n",
      "Testing 3231/4320\n",
      "5 2 5 sqrt entropy False 200 76: Weighted 0.799778 (0.079587)\n",
      "5 2 5 sqrt entropy False 200 76: Macro 0.686126 (0.115632)\n",
      "Testing 3232/4320\n",
      "5 2 5 sqrt entropy False 500 76: Weighted 0.804873 (0.073101)\n",
      "5 2 5 sqrt entropy False 500 76: Macro 0.695192 (0.101026)\n",
      "Testing 3233/4320\n",
      "5 2 8 log2 gini True 50 76: Weighted 0.819407 (0.059556)\n",
      "5 2 8 log2 gini True 50 76: Macro 0.716900 (0.077191)\n",
      "Testing 3234/4320\n",
      "5 2 8 log2 gini True 100 76: Weighted 0.811590 (0.066628)\n",
      "5 2 8 log2 gini True 100 76: Macro 0.702933 (0.091251)\n",
      "Testing 3235/4320\n",
      "5 2 8 log2 gini True 200 76: Weighted 0.815739 (0.060394)\n",
      "5 2 8 log2 gini True 200 76: Macro 0.712002 (0.077172)\n",
      "Testing 3236/4320\n",
      "5 2 8 log2 gini True 500 76: Weighted 0.815739 (0.060394)\n",
      "5 2 8 log2 gini True 500 76: Macro 0.712002 (0.077172)\n",
      "Testing 3237/4320\n",
      "5 2 8 log2 gini False 50 76: Weighted 0.808858 (0.067062)\n",
      "5 2 8 log2 gini False 50 76: Macro 0.698304 (0.092582)\n",
      "Testing 3238/4320\n",
      "5 2 8 log2 gini False 100 76: Weighted 0.799509 (0.066413)\n",
      "5 2 8 log2 gini False 100 76: Macro 0.686191 (0.090167)\n",
      "Testing 3239/4320\n",
      "5 2 8 log2 gini False 200 76: Weighted 0.799509 (0.066413)\n",
      "5 2 8 log2 gini False 200 76: Macro 0.686191 (0.090167)\n",
      "Testing 3240/4320\n",
      "5 2 8 log2 gini False 500 76: Weighted 0.804333 (0.068679)\n",
      "5 2 8 log2 gini False 500 76: Macro 0.693402 (0.094129)\n",
      "Testing 3241/4320\n",
      "5 2 8 log2 entropy True 50 76: Weighted 0.811422 (0.065826)\n",
      "5 2 8 log2 entropy True 50 76: Macro 0.708883 (0.085948)\n",
      "Testing 3242/4320\n",
      "5 2 8 log2 entropy True 100 76: Weighted 0.810494 (0.064722)\n",
      "5 2 8 log2 entropy True 100 76: Macro 0.704769 (0.084062)\n",
      "Testing 3243/4320\n",
      "5 2 8 log2 entropy True 200 76: Weighted 0.810977 (0.058703)\n",
      "5 2 8 log2 entropy True 200 76: Macro 0.704859 (0.074493)\n",
      "Testing 3244/4320\n",
      "5 2 8 log2 entropy True 500 76: Weighted 0.810977 (0.058703)\n",
      "5 2 8 log2 entropy True 500 76: Macro 0.704859 (0.074493)\n",
      "Testing 3245/4320\n",
      "5 2 8 log2 entropy False 50 76: Weighted 0.790177 (0.070943)\n",
      "5 2 8 log2 entropy False 50 76: Macro 0.669258 (0.101797)\n",
      "Testing 3246/4320\n",
      "5 2 8 log2 entropy False 100 76: Weighted 0.799284 (0.066331)\n",
      "5 2 8 log2 entropy False 100 76: Macro 0.687687 (0.090862)\n",
      "Testing 3247/4320\n",
      "5 2 8 log2 entropy False 200 76: Weighted 0.799284 (0.066331)\n",
      "5 2 8 log2 entropy False 200 76: Macro 0.687687 (0.090862)\n",
      "Testing 3248/4320\n",
      "5 2 8 log2 entropy False 500 76: Weighted 0.799284 (0.066331)\n",
      "5 2 8 log2 entropy False 500 76: Macro 0.687687 (0.090862)\n",
      "Testing 3249/4320\n",
      "5 2 8 sqrt gini True 50 76: Weighted 0.819407 (0.059556)\n",
      "5 2 8 sqrt gini True 50 76: Macro 0.716900 (0.077191)\n",
      "Testing 3250/4320\n",
      "5 2 8 sqrt gini True 100 76: Weighted 0.811590 (0.066628)\n",
      "5 2 8 sqrt gini True 100 76: Macro 0.702933 (0.091251)\n",
      "Testing 3251/4320\n",
      "5 2 8 sqrt gini True 200 76: Weighted 0.815739 (0.060394)\n",
      "5 2 8 sqrt gini True 200 76: Macro 0.712002 (0.077172)\n",
      "Testing 3252/4320\n",
      "5 2 8 sqrt gini True 500 76: Weighted 0.815739 (0.060394)\n",
      "5 2 8 sqrt gini True 500 76: Macro 0.712002 (0.077172)\n",
      "Testing 3253/4320\n",
      "5 2 8 sqrt gini False 50 76: Weighted 0.808858 (0.067062)\n",
      "5 2 8 sqrt gini False 50 76: Macro 0.698304 (0.092582)\n",
      "Testing 3254/4320\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 2 8 sqrt gini False 100 76: Weighted 0.799509 (0.066413)\n",
      "5 2 8 sqrt gini False 100 76: Macro 0.686191 (0.090167)\n",
      "Testing 3255/4320\n",
      "5 2 8 sqrt gini False 200 76: Weighted 0.799509 (0.066413)\n",
      "5 2 8 sqrt gini False 200 76: Macro 0.686191 (0.090167)\n",
      "Testing 3256/4320\n",
      "5 2 8 sqrt gini False 500 76: Weighted 0.804333 (0.068679)\n",
      "5 2 8 sqrt gini False 500 76: Macro 0.693402 (0.094129)\n",
      "Testing 3257/4320\n",
      "5 2 8 sqrt entropy True 50 76: Weighted 0.811422 (0.065826)\n",
      "5 2 8 sqrt entropy True 50 76: Macro 0.708883 (0.085948)\n",
      "Testing 3258/4320\n",
      "5 2 8 sqrt entropy True 100 76: Weighted 0.810494 (0.064722)\n",
      "5 2 8 sqrt entropy True 100 76: Macro 0.704769 (0.084062)\n",
      "Testing 3259/4320\n",
      "5 2 8 sqrt entropy True 200 76: Weighted 0.810977 (0.058703)\n",
      "5 2 8 sqrt entropy True 200 76: Macro 0.704859 (0.074493)\n",
      "Testing 3260/4320\n",
      "5 2 8 sqrt entropy True 500 76: Weighted 0.810977 (0.058703)\n",
      "5 2 8 sqrt entropy True 500 76: Macro 0.704859 (0.074493)\n",
      "Testing 3261/4320\n",
      "5 2 8 sqrt entropy False 50 76: Weighted 0.790177 (0.070943)\n",
      "5 2 8 sqrt entropy False 50 76: Macro 0.669258 (0.101797)\n",
      "Testing 3262/4320\n",
      "5 2 8 sqrt entropy False 100 76: Weighted 0.799284 (0.066331)\n",
      "5 2 8 sqrt entropy False 100 76: Macro 0.687687 (0.090862)\n",
      "Testing 3263/4320\n",
      "5 2 8 sqrt entropy False 200 76: Weighted 0.799284 (0.066331)\n",
      "5 2 8 sqrt entropy False 200 76: Macro 0.687687 (0.090862)\n",
      "Testing 3264/4320\n",
      "5 2 8 sqrt entropy False 500 76: Weighted 0.799284 (0.066331)\n",
      "5 2 8 sqrt entropy False 500 76: Macro 0.687687 (0.090862)\n",
      "Testing 3265/4320\n",
      "5 4 3 log2 gini True 50 76: Weighted 0.796714 (0.053719)\n",
      "5 4 3 log2 gini True 50 76: Macro 0.685604 (0.071554)\n",
      "Testing 3266/4320\n",
      "5 4 3 log2 gini True 100 76: Weighted 0.812104 (0.054913)\n",
      "5 4 3 log2 gini True 100 76: Macro 0.704661 (0.069679)\n",
      "Testing 3267/4320\n",
      "5 4 3 log2 gini True 200 76: Weighted 0.807343 (0.052721)\n",
      "5 4 3 log2 gini True 200 76: Macro 0.697519 (0.065910)\n",
      "Testing 3268/4320\n",
      "5 4 3 log2 gini True 500 76: Weighted 0.817457 (0.053455)\n",
      "5 4 3 log2 gini True 500 76: Macro 0.714857 (0.072653)\n",
      "Testing 3269/4320\n",
      "5 4 3 log2 gini False 50 76: Weighted 0.801060 (0.062389)\n",
      "5 4 3 log2 gini False 50 76: Macro 0.692847 (0.084279)\n",
      "Testing 3270/4320\n",
      "5 4 3 log2 gini False 100 76: Weighted 0.809244 (0.065497)\n",
      "5 4 3 log2 gini False 100 76: Macro 0.704564 (0.087453)\n",
      "Testing 3271/4320\n",
      "5 4 3 log2 gini False 200 76: Weighted 0.809244 (0.065497)\n",
      "5 4 3 log2 gini False 200 76: Macro 0.704564 (0.087453)\n",
      "Testing 3272/4320\n",
      "5 4 3 log2 gini False 500 76: Weighted 0.813081 (0.059751)\n",
      "5 4 3 log2 gini False 500 76: Macro 0.712700 (0.075647)\n",
      "Testing 3273/4320\n",
      "5 4 3 log2 entropy True 50 76: Weighted 0.805007 (0.056975)\n",
      "5 4 3 log2 entropy True 50 76: Macro 0.697312 (0.075095)\n",
      "Testing 3274/4320\n",
      "5 4 3 log2 entropy True 100 76: Weighted 0.813043 (0.061075)\n",
      "5 4 3 log2 entropy True 100 76: Macro 0.709081 (0.080344)\n",
      "Testing 3275/4320\n",
      "5 4 3 log2 entropy True 200 76: Weighted 0.813043 (0.061075)\n",
      "5 4 3 log2 entropy True 200 76: Macro 0.709081 (0.080344)\n",
      "Testing 3276/4320\n",
      "5 4 3 log2 entropy True 500 76: Weighted 0.808523 (0.055575)\n",
      "5 4 3 log2 entropy True 500 76: Macro 0.702270 (0.072850)\n",
      "Testing 3277/4320\n",
      "5 4 3 log2 entropy False 50 76: Weighted 0.783967 (0.082559)\n",
      "5 4 3 log2 entropy False 50 76: Macro 0.674187 (0.100493)\n",
      "Testing 3278/4320\n",
      "5 4 3 log2 entropy False 100 76: Weighted 0.787834 (0.088117)\n",
      "5 4 3 log2 entropy False 100 76: Macro 0.680688 (0.106489)\n",
      "Testing 3279/4320\n",
      "5 4 3 log2 entropy False 200 76: Weighted 0.787834 (0.088117)\n",
      "5 4 3 log2 entropy False 200 76: Macro 0.680688 (0.106489)\n",
      "Testing 3280/4320\n",
      "5 4 3 log2 entropy False 500 76: Weighted 0.787834 (0.088117)\n",
      "5 4 3 log2 entropy False 500 76: Macro 0.680688 (0.106489)\n",
      "Testing 3281/4320\n",
      "5 4 3 sqrt gini True 50 76: Weighted 0.796714 (0.053719)\n",
      "5 4 3 sqrt gini True 50 76: Macro 0.685604 (0.071554)\n",
      "Testing 3282/4320\n",
      "5 4 3 sqrt gini True 100 76: Weighted 0.812104 (0.054913)\n",
      "5 4 3 sqrt gini True 100 76: Macro 0.704661 (0.069679)\n",
      "Testing 3283/4320\n",
      "5 4 3 sqrt gini True 200 76: Weighted 0.807343 (0.052721)\n",
      "5 4 3 sqrt gini True 200 76: Macro 0.697519 (0.065910)\n",
      "Testing 3284/4320\n",
      "5 4 3 sqrt gini True 500 76: Weighted 0.817457 (0.053455)\n",
      "5 4 3 sqrt gini True 500 76: Macro 0.714857 (0.072653)\n",
      "Testing 3285/4320\n",
      "5 4 3 sqrt gini False 50 76: Weighted 0.801060 (0.062389)\n",
      "5 4 3 sqrt gini False 50 76: Macro 0.692847 (0.084279)\n",
      "Testing 3286/4320\n",
      "5 4 3 sqrt gini False 100 76: Weighted 0.809244 (0.065497)\n",
      "5 4 3 sqrt gini False 100 76: Macro 0.704564 (0.087453)\n",
      "Testing 3287/4320\n",
      "5 4 3 sqrt gini False 200 76: Weighted 0.809244 (0.065497)\n",
      "5 4 3 sqrt gini False 200 76: Macro 0.704564 (0.087453)\n",
      "Testing 3288/4320\n",
      "5 4 3 sqrt gini False 500 76: Weighted 0.813081 (0.059751)\n",
      "5 4 3 sqrt gini False 500 76: Macro 0.712700 (0.075647)\n",
      "Testing 3289/4320\n",
      "5 4 3 sqrt entropy True 50 76: Weighted 0.805007 (0.056975)\n",
      "5 4 3 sqrt entropy True 50 76: Macro 0.697312 (0.075095)\n",
      "Testing 3290/4320\n",
      "5 4 3 sqrt entropy True 100 76: Weighted 0.813043 (0.061075)\n",
      "5 4 3 sqrt entropy True 100 76: Macro 0.709081 (0.080344)\n",
      "Testing 3291/4320\n",
      "5 4 3 sqrt entropy True 200 76: Weighted 0.813043 (0.061075)\n",
      "5 4 3 sqrt entropy True 200 76: Macro 0.709081 (0.080344)\n",
      "Testing 3292/4320\n",
      "5 4 3 sqrt entropy True 500 76: Weighted 0.808523 (0.055575)\n",
      "5 4 3 sqrt entropy True 500 76: Macro 0.702270 (0.072850)\n",
      "Testing 3293/4320\n",
      "5 4 3 sqrt entropy False 50 76: Weighted 0.783967 (0.082559)\n",
      "5 4 3 sqrt entropy False 50 76: Macro 0.674187 (0.100493)\n",
      "Testing 3294/4320\n",
      "5 4 3 sqrt entropy False 100 76: Weighted 0.787834 (0.088117)\n",
      "5 4 3 sqrt entropy False 100 76: Macro 0.680688 (0.106489)\n",
      "Testing 3295/4320\n",
      "5 4 3 sqrt entropy False 200 76: Weighted 0.787834 (0.088117)\n",
      "5 4 3 sqrt entropy False 200 76: Macro 0.680688 (0.106489)\n",
      "Testing 3296/4320\n",
      "5 4 3 sqrt entropy False 500 76: Weighted 0.787834 (0.088117)\n",
      "5 4 3 sqrt entropy False 500 76: Macro 0.680688 (0.106489)\n",
      "Testing 3297/4320\n",
      "5 4 5 log2 gini True 50 76: Weighted 0.815739 (0.060394)\n",
      "5 4 5 log2 gini True 50 76: Macro 0.712002 (0.077172)\n",
      "Testing 3298/4320\n",
      "5 4 5 log2 gini True 100 76: Weighted 0.811590 (0.066628)\n",
      "5 4 5 log2 gini True 100 76: Macro 0.702933 (0.091251)\n",
      "Testing 3299/4320\n",
      "5 4 5 log2 gini True 200 76: Weighted 0.815739 (0.060394)\n",
      "5 4 5 log2 gini True 200 76: Macro 0.712002 (0.077172)\n",
      "Testing 3300/4320\n",
      "5 4 5 log2 gini True 500 76: Weighted 0.816624 (0.060205)\n",
      "5 4 5 log2 gini True 500 76: Macro 0.711473 (0.077270)\n",
      "Testing 3301/4320\n",
      "5 4 5 log2 gini False 50 76: Weighted 0.807389 (0.072746)\n",
      "5 4 5 log2 gini False 50 76: Macro 0.699038 (0.099441)\n",
      "Testing 3302/4320\n",
      "5 4 5 log2 gini False 100 76: Weighted 0.807424 (0.072763)\n",
      "5 4 5 log2 gini False 100 76: Macro 0.700746 (0.100438)\n",
      "Testing 3303/4320\n",
      "5 4 5 log2 gini False 200 76: Weighted 0.807424 (0.072763)\n",
      "5 4 5 log2 gini False 200 76: Macro 0.700746 (0.100438)\n",
      "Testing 3304/4320\n",
      "5 4 5 log2 gini False 500 76: Weighted 0.812352 (0.075646)\n",
      "5 4 5 log2 gini False 500 76: Macro 0.708254 (0.105698)\n",
      "Testing 3305/4320\n",
      "5 4 5 log2 entropy True 50 76: Weighted 0.817466 (0.066908)\n",
      "5 4 5 log2 entropy True 50 76: Macro 0.716043 (0.088972)\n",
      "Testing 3306/4320\n",
      "5 4 5 log2 entropy True 100 76: Weighted 0.810977 (0.058703)\n",
      "5 4 5 log2 entropy True 100 76: Macro 0.704859 (0.074493)\n",
      "Testing 3307/4320\n",
      "5 4 5 log2 entropy True 200 76: Weighted 0.811863 (0.058581)\n",
      "5 4 5 log2 entropy True 200 76: Macro 0.704330 (0.074545)\n",
      "Testing 3308/4320\n",
      "5 4 5 log2 entropy True 500 76: Weighted 0.811863 (0.058581)\n",
      "5 4 5 log2 entropy True 500 76: Macro 0.704330 (0.074545)\n",
      "Testing 3309/4320\n",
      "5 4 5 log2 entropy False 50 76: Weighted 0.803914 (0.073297)\n",
      "5 4 5 log2 entropy False 50 76: Macro 0.695455 (0.100978)\n",
      "Testing 3310/4320\n",
      "5 4 5 log2 entropy False 100 76: Weighted 0.795264 (0.071879)\n",
      "5 4 5 log2 entropy False 100 76: Macro 0.682868 (0.097827)\n",
      "Testing 3311/4320\n",
      "5 4 5 log2 entropy False 200 76: Weighted 0.799778 (0.079587)\n",
      "5 4 5 log2 entropy False 200 76: Macro 0.686126 (0.115632)\n",
      "Testing 3312/4320\n",
      "5 4 5 log2 entropy False 500 76: Weighted 0.804873 (0.073101)\n",
      "5 4 5 log2 entropy False 500 76: Macro 0.695192 (0.101026)\n",
      "Testing 3313/4320\n",
      "5 4 5 sqrt gini True 50 76: Weighted 0.815739 (0.060394)\n",
      "5 4 5 sqrt gini True 50 76: Macro 0.712002 (0.077172)\n",
      "Testing 3314/4320\n",
      "5 4 5 sqrt gini True 100 76: Weighted 0.811590 (0.066628)\n",
      "5 4 5 sqrt gini True 100 76: Macro 0.702933 (0.091251)\n",
      "Testing 3315/4320\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 4 5 sqrt gini True 200 76: Weighted 0.815739 (0.060394)\n",
      "5 4 5 sqrt gini True 200 76: Macro 0.712002 (0.077172)\n",
      "Testing 3316/4320\n",
      "5 4 5 sqrt gini True 500 76: Weighted 0.816624 (0.060205)\n",
      "5 4 5 sqrt gini True 500 76: Macro 0.711473 (0.077270)\n",
      "Testing 3317/4320\n",
      "5 4 5 sqrt gini False 50 76: Weighted 0.807389 (0.072746)\n",
      "5 4 5 sqrt gini False 50 76: Macro 0.699038 (0.099441)\n",
      "Testing 3318/4320\n",
      "5 4 5 sqrt gini False 100 76: Weighted 0.807424 (0.072763)\n",
      "5 4 5 sqrt gini False 100 76: Macro 0.700746 (0.100438)\n",
      "Testing 3319/4320\n",
      "5 4 5 sqrt gini False 200 76: Weighted 0.807424 (0.072763)\n",
      "5 4 5 sqrt gini False 200 76: Macro 0.700746 (0.100438)\n",
      "Testing 3320/4320\n",
      "5 4 5 sqrt gini False 500 76: Weighted 0.812352 (0.075646)\n",
      "5 4 5 sqrt gini False 500 76: Macro 0.708254 (0.105698)\n",
      "Testing 3321/4320\n",
      "5 4 5 sqrt entropy True 50 76: Weighted 0.817466 (0.066908)\n",
      "5 4 5 sqrt entropy True 50 76: Macro 0.716043 (0.088972)\n",
      "Testing 3322/4320\n",
      "5 4 5 sqrt entropy True 100 76: Weighted 0.810977 (0.058703)\n",
      "5 4 5 sqrt entropy True 100 76: Macro 0.704859 (0.074493)\n",
      "Testing 3323/4320\n",
      "5 4 5 sqrt entropy True 200 76: Weighted 0.811863 (0.058581)\n",
      "5 4 5 sqrt entropy True 200 76: Macro 0.704330 (0.074545)\n",
      "Testing 3324/4320\n",
      "5 4 5 sqrt entropy True 500 76: Weighted 0.811863 (0.058581)\n",
      "5 4 5 sqrt entropy True 500 76: Macro 0.704330 (0.074545)\n",
      "Testing 3325/4320\n",
      "5 4 5 sqrt entropy False 50 76: Weighted 0.803914 (0.073297)\n",
      "5 4 5 sqrt entropy False 50 76: Macro 0.695455 (0.100978)\n",
      "Testing 3326/4320\n",
      "5 4 5 sqrt entropy False 100 76: Weighted 0.795264 (0.071879)\n",
      "5 4 5 sqrt entropy False 100 76: Macro 0.682868 (0.097827)\n",
      "Testing 3327/4320\n",
      "5 4 5 sqrt entropy False 200 76: Weighted 0.799778 (0.079587)\n",
      "5 4 5 sqrt entropy False 200 76: Macro 0.686126 (0.115632)\n",
      "Testing 3328/4320\n",
      "5 4 5 sqrt entropy False 500 76: Weighted 0.804873 (0.073101)\n",
      "5 4 5 sqrt entropy False 500 76: Macro 0.695192 (0.101026)\n",
      "Testing 3329/4320\n",
      "5 4 8 log2 gini True 50 76: Weighted 0.819407 (0.059556)\n",
      "5 4 8 log2 gini True 50 76: Macro 0.716900 (0.077191)\n",
      "Testing 3330/4320\n",
      "5 4 8 log2 gini True 100 76: Weighted 0.811590 (0.066628)\n",
      "5 4 8 log2 gini True 100 76: Macro 0.702933 (0.091251)\n",
      "Testing 3331/4320\n",
      "5 4 8 log2 gini True 200 76: Weighted 0.815739 (0.060394)\n",
      "5 4 8 log2 gini True 200 76: Macro 0.712002 (0.077172)\n",
      "Testing 3332/4320\n",
      "5 4 8 log2 gini True 500 76: Weighted 0.815739 (0.060394)\n",
      "5 4 8 log2 gini True 500 76: Macro 0.712002 (0.077172)\n",
      "Testing 3333/4320\n",
      "5 4 8 log2 gini False 50 76: Weighted 0.808858 (0.067062)\n",
      "5 4 8 log2 gini False 50 76: Macro 0.698304 (0.092582)\n",
      "Testing 3334/4320\n",
      "5 4 8 log2 gini False 100 76: Weighted 0.799509 (0.066413)\n",
      "5 4 8 log2 gini False 100 76: Macro 0.686191 (0.090167)\n",
      "Testing 3335/4320\n",
      "5 4 8 log2 gini False 200 76: Weighted 0.799509 (0.066413)\n",
      "5 4 8 log2 gini False 200 76: Macro 0.686191 (0.090167)\n",
      "Testing 3336/4320\n",
      "5 4 8 log2 gini False 500 76: Weighted 0.804333 (0.068679)\n",
      "5 4 8 log2 gini False 500 76: Macro 0.693402 (0.094129)\n",
      "Testing 3337/4320\n",
      "5 4 8 log2 entropy True 50 76: Weighted 0.811422 (0.065826)\n",
      "5 4 8 log2 entropy True 50 76: Macro 0.708883 (0.085948)\n",
      "Testing 3338/4320\n",
      "5 4 8 log2 entropy True 100 76: Weighted 0.810494 (0.064722)\n",
      "5 4 8 log2 entropy True 100 76: Macro 0.704769 (0.084062)\n",
      "Testing 3339/4320\n",
      "5 4 8 log2 entropy True 200 76: Weighted 0.810977 (0.058703)\n",
      "5 4 8 log2 entropy True 200 76: Macro 0.704859 (0.074493)\n",
      "Testing 3340/4320\n",
      "5 4 8 log2 entropy True 500 76: Weighted 0.810977 (0.058703)\n",
      "5 4 8 log2 entropy True 500 76: Macro 0.704859 (0.074493)\n",
      "Testing 3341/4320\n",
      "5 4 8 log2 entropy False 50 76: Weighted 0.790177 (0.070943)\n",
      "5 4 8 log2 entropy False 50 76: Macro 0.669258 (0.101797)\n",
      "Testing 3342/4320\n",
      "5 4 8 log2 entropy False 100 76: Weighted 0.799284 (0.066331)\n",
      "5 4 8 log2 entropy False 100 76: Macro 0.687687 (0.090862)\n",
      "Testing 3343/4320\n",
      "5 4 8 log2 entropy False 200 76: Weighted 0.799284 (0.066331)\n",
      "5 4 8 log2 entropy False 200 76: Macro 0.687687 (0.090862)\n",
      "Testing 3344/4320\n",
      "5 4 8 log2 entropy False 500 76: Weighted 0.799284 (0.066331)\n",
      "5 4 8 log2 entropy False 500 76: Macro 0.687687 (0.090862)\n",
      "Testing 3345/4320\n",
      "5 4 8 sqrt gini True 50 76: Weighted 0.819407 (0.059556)\n",
      "5 4 8 sqrt gini True 50 76: Macro 0.716900 (0.077191)\n",
      "Testing 3346/4320\n",
      "5 4 8 sqrt gini True 100 76: Weighted 0.811590 (0.066628)\n",
      "5 4 8 sqrt gini True 100 76: Macro 0.702933 (0.091251)\n",
      "Testing 3347/4320\n",
      "5 4 8 sqrt gini True 200 76: Weighted 0.815739 (0.060394)\n",
      "5 4 8 sqrt gini True 200 76: Macro 0.712002 (0.077172)\n",
      "Testing 3348/4320\n",
      "5 4 8 sqrt gini True 500 76: Weighted 0.815739 (0.060394)\n",
      "5 4 8 sqrt gini True 500 76: Macro 0.712002 (0.077172)\n",
      "Testing 3349/4320\n",
      "5 4 8 sqrt gini False 50 76: Weighted 0.808858 (0.067062)\n",
      "5 4 8 sqrt gini False 50 76: Macro 0.698304 (0.092582)\n",
      "Testing 3350/4320\n",
      "5 4 8 sqrt gini False 100 76: Weighted 0.799509 (0.066413)\n",
      "5 4 8 sqrt gini False 100 76: Macro 0.686191 (0.090167)\n",
      "Testing 3351/4320\n",
      "5 4 8 sqrt gini False 200 76: Weighted 0.799509 (0.066413)\n",
      "5 4 8 sqrt gini False 200 76: Macro 0.686191 (0.090167)\n",
      "Testing 3352/4320\n",
      "5 4 8 sqrt gini False 500 76: Weighted 0.804333 (0.068679)\n",
      "5 4 8 sqrt gini False 500 76: Macro 0.693402 (0.094129)\n",
      "Testing 3353/4320\n",
      "5 4 8 sqrt entropy True 50 76: Weighted 0.811422 (0.065826)\n",
      "5 4 8 sqrt entropy True 50 76: Macro 0.708883 (0.085948)\n",
      "Testing 3354/4320\n",
      "5 4 8 sqrt entropy True 100 76: Weighted 0.810494 (0.064722)\n",
      "5 4 8 sqrt entropy True 100 76: Macro 0.704769 (0.084062)\n",
      "Testing 3355/4320\n",
      "5 4 8 sqrt entropy True 200 76: Weighted 0.810977 (0.058703)\n",
      "5 4 8 sqrt entropy True 200 76: Macro 0.704859 (0.074493)\n",
      "Testing 3356/4320\n",
      "5 4 8 sqrt entropy True 500 76: Weighted 0.810977 (0.058703)\n",
      "5 4 8 sqrt entropy True 500 76: Macro 0.704859 (0.074493)\n",
      "Testing 3357/4320\n",
      "5 4 8 sqrt entropy False 50 76: Weighted 0.790177 (0.070943)\n",
      "5 4 8 sqrt entropy False 50 76: Macro 0.669258 (0.101797)\n",
      "Testing 3358/4320\n",
      "5 4 8 sqrt entropy False 100 76: Weighted 0.799284 (0.066331)\n",
      "5 4 8 sqrt entropy False 100 76: Macro 0.687687 (0.090862)\n",
      "Testing 3359/4320\n",
      "5 4 8 sqrt entropy False 200 76: Weighted 0.799284 (0.066331)\n",
      "5 4 8 sqrt entropy False 200 76: Macro 0.687687 (0.090862)\n",
      "Testing 3360/4320\n",
      "5 4 8 sqrt entropy False 500 76: Weighted 0.799284 (0.066331)\n",
      "5 4 8 sqrt entropy False 500 76: Macro 0.687687 (0.090862)\n",
      "Testing 3361/4320\n",
      "5 6 3 log2 gini True 50 76: Weighted 0.796714 (0.053719)\n",
      "5 6 3 log2 gini True 50 76: Macro 0.685604 (0.071554)\n",
      "Testing 3362/4320\n",
      "5 6 3 log2 gini True 100 76: Weighted 0.812104 (0.054913)\n",
      "5 6 3 log2 gini True 100 76: Macro 0.704661 (0.069679)\n",
      "Testing 3363/4320\n",
      "5 6 3 log2 gini True 200 76: Weighted 0.807343 (0.052721)\n",
      "5 6 3 log2 gini True 200 76: Macro 0.697519 (0.065910)\n",
      "Testing 3364/4320\n",
      "5 6 3 log2 gini True 500 76: Weighted 0.817457 (0.053455)\n",
      "5 6 3 log2 gini True 500 76: Macro 0.714857 (0.072653)\n",
      "Testing 3365/4320\n",
      "5 6 3 log2 gini False 50 76: Weighted 0.801060 (0.062389)\n",
      "5 6 3 log2 gini False 50 76: Macro 0.692847 (0.084279)\n",
      "Testing 3366/4320\n",
      "5 6 3 log2 gini False 100 76: Weighted 0.809244 (0.065497)\n",
      "5 6 3 log2 gini False 100 76: Macro 0.704564 (0.087453)\n",
      "Testing 3367/4320\n",
      "5 6 3 log2 gini False 200 76: Weighted 0.809244 (0.065497)\n",
      "5 6 3 log2 gini False 200 76: Macro 0.704564 (0.087453)\n",
      "Testing 3368/4320\n",
      "5 6 3 log2 gini False 500 76: Weighted 0.813081 (0.059751)\n",
      "5 6 3 log2 gini False 500 76: Macro 0.712700 (0.075647)\n",
      "Testing 3369/4320\n",
      "5 6 3 log2 entropy True 50 76: Weighted 0.805007 (0.056975)\n",
      "5 6 3 log2 entropy True 50 76: Macro 0.697312 (0.075095)\n",
      "Testing 3370/4320\n",
      "5 6 3 log2 entropy True 100 76: Weighted 0.813043 (0.061075)\n",
      "5 6 3 log2 entropy True 100 76: Macro 0.709081 (0.080344)\n",
      "Testing 3371/4320\n",
      "5 6 3 log2 entropy True 200 76: Weighted 0.813043 (0.061075)\n",
      "5 6 3 log2 entropy True 200 76: Macro 0.709081 (0.080344)\n",
      "Testing 3372/4320\n",
      "5 6 3 log2 entropy True 500 76: Weighted 0.808523 (0.055575)\n",
      "5 6 3 log2 entropy True 500 76: Macro 0.702270 (0.072850)\n",
      "Testing 3373/4320\n",
      "5 6 3 log2 entropy False 50 76: Weighted 0.783967 (0.082559)\n",
      "5 6 3 log2 entropy False 50 76: Macro 0.674187 (0.100493)\n",
      "Testing 3374/4320\n",
      "5 6 3 log2 entropy False 100 76: Weighted 0.787834 (0.088117)\n",
      "5 6 3 log2 entropy False 100 76: Macro 0.680688 (0.106489)\n",
      "Testing 3375/4320\n",
      "5 6 3 log2 entropy False 200 76: Weighted 0.787834 (0.088117)\n",
      "5 6 3 log2 entropy False 200 76: Macro 0.680688 (0.106489)\n",
      "Testing 3376/4320\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 6 3 log2 entropy False 500 76: Weighted 0.787834 (0.088117)\n",
      "5 6 3 log2 entropy False 500 76: Macro 0.680688 (0.106489)\n",
      "Testing 3377/4320\n",
      "5 6 3 sqrt gini True 50 76: Weighted 0.796714 (0.053719)\n",
      "5 6 3 sqrt gini True 50 76: Macro 0.685604 (0.071554)\n",
      "Testing 3378/4320\n",
      "5 6 3 sqrt gini True 100 76: Weighted 0.812104 (0.054913)\n",
      "5 6 3 sqrt gini True 100 76: Macro 0.704661 (0.069679)\n",
      "Testing 3379/4320\n",
      "5 6 3 sqrt gini True 200 76: Weighted 0.807343 (0.052721)\n",
      "5 6 3 sqrt gini True 200 76: Macro 0.697519 (0.065910)\n",
      "Testing 3380/4320\n",
      "5 6 3 sqrt gini True 500 76: Weighted 0.817457 (0.053455)\n",
      "5 6 3 sqrt gini True 500 76: Macro 0.714857 (0.072653)\n",
      "Testing 3381/4320\n",
      "5 6 3 sqrt gini False 50 76: Weighted 0.801060 (0.062389)\n",
      "5 6 3 sqrt gini False 50 76: Macro 0.692847 (0.084279)\n",
      "Testing 3382/4320\n",
      "5 6 3 sqrt gini False 100 76: Weighted 0.809244 (0.065497)\n",
      "5 6 3 sqrt gini False 100 76: Macro 0.704564 (0.087453)\n",
      "Testing 3383/4320\n",
      "5 6 3 sqrt gini False 200 76: Weighted 0.809244 (0.065497)\n",
      "5 6 3 sqrt gini False 200 76: Macro 0.704564 (0.087453)\n",
      "Testing 3384/4320\n",
      "5 6 3 sqrt gini False 500 76: Weighted 0.813081 (0.059751)\n",
      "5 6 3 sqrt gini False 500 76: Macro 0.712700 (0.075647)\n",
      "Testing 3385/4320\n",
      "5 6 3 sqrt entropy True 50 76: Weighted 0.805007 (0.056975)\n",
      "5 6 3 sqrt entropy True 50 76: Macro 0.697312 (0.075095)\n",
      "Testing 3386/4320\n",
      "5 6 3 sqrt entropy True 100 76: Weighted 0.813043 (0.061075)\n",
      "5 6 3 sqrt entropy True 100 76: Macro 0.709081 (0.080344)\n",
      "Testing 3387/4320\n",
      "5 6 3 sqrt entropy True 200 76: Weighted 0.813043 (0.061075)\n",
      "5 6 3 sqrt entropy True 200 76: Macro 0.709081 (0.080344)\n",
      "Testing 3388/4320\n",
      "5 6 3 sqrt entropy True 500 76: Weighted 0.808523 (0.055575)\n",
      "5 6 3 sqrt entropy True 500 76: Macro 0.702270 (0.072850)\n",
      "Testing 3389/4320\n",
      "5 6 3 sqrt entropy False 50 76: Weighted 0.783967 (0.082559)\n",
      "5 6 3 sqrt entropy False 50 76: Macro 0.674187 (0.100493)\n",
      "Testing 3390/4320\n",
      "5 6 3 sqrt entropy False 100 76: Weighted 0.787834 (0.088117)\n",
      "5 6 3 sqrt entropy False 100 76: Macro 0.680688 (0.106489)\n",
      "Testing 3391/4320\n",
      "5 6 3 sqrt entropy False 200 76: Weighted 0.787834 (0.088117)\n",
      "5 6 3 sqrt entropy False 200 76: Macro 0.680688 (0.106489)\n",
      "Testing 3392/4320\n",
      "5 6 3 sqrt entropy False 500 76: Weighted 0.787834 (0.088117)\n",
      "5 6 3 sqrt entropy False 500 76: Macro 0.680688 (0.106489)\n",
      "Testing 3393/4320\n",
      "5 6 5 log2 gini True 50 76: Weighted 0.815739 (0.060394)\n",
      "5 6 5 log2 gini True 50 76: Macro 0.712002 (0.077172)\n",
      "Testing 3394/4320\n",
      "5 6 5 log2 gini True 100 76: Weighted 0.811590 (0.066628)\n",
      "5 6 5 log2 gini True 100 76: Macro 0.702933 (0.091251)\n",
      "Testing 3395/4320\n",
      "5 6 5 log2 gini True 200 76: Weighted 0.815739 (0.060394)\n",
      "5 6 5 log2 gini True 200 76: Macro 0.712002 (0.077172)\n",
      "Testing 3396/4320\n",
      "5 6 5 log2 gini True 500 76: Weighted 0.816624 (0.060205)\n",
      "5 6 5 log2 gini True 500 76: Macro 0.711473 (0.077270)\n",
      "Testing 3397/4320\n",
      "5 6 5 log2 gini False 50 76: Weighted 0.807389 (0.072746)\n",
      "5 6 5 log2 gini False 50 76: Macro 0.699038 (0.099441)\n",
      "Testing 3398/4320\n",
      "5 6 5 log2 gini False 100 76: Weighted 0.807424 (0.072763)\n",
      "5 6 5 log2 gini False 100 76: Macro 0.700746 (0.100438)\n",
      "Testing 3399/4320\n",
      "5 6 5 log2 gini False 200 76: Weighted 0.807424 (0.072763)\n",
      "5 6 5 log2 gini False 200 76: Macro 0.700746 (0.100438)\n",
      "Testing 3400/4320\n",
      "5 6 5 log2 gini False 500 76: Weighted 0.812352 (0.075646)\n",
      "5 6 5 log2 gini False 500 76: Macro 0.708254 (0.105698)\n",
      "Testing 3401/4320\n",
      "5 6 5 log2 entropy True 50 76: Weighted 0.817466 (0.066908)\n",
      "5 6 5 log2 entropy True 50 76: Macro 0.716043 (0.088972)\n",
      "Testing 3402/4320\n",
      "5 6 5 log2 entropy True 100 76: Weighted 0.810977 (0.058703)\n",
      "5 6 5 log2 entropy True 100 76: Macro 0.704859 (0.074493)\n",
      "Testing 3403/4320\n",
      "5 6 5 log2 entropy True 200 76: Weighted 0.811863 (0.058581)\n",
      "5 6 5 log2 entropy True 200 76: Macro 0.704330 (0.074545)\n",
      "Testing 3404/4320\n",
      "5 6 5 log2 entropy True 500 76: Weighted 0.811863 (0.058581)\n",
      "5 6 5 log2 entropy True 500 76: Macro 0.704330 (0.074545)\n",
      "Testing 3405/4320\n",
      "5 6 5 log2 entropy False 50 76: Weighted 0.803914 (0.073297)\n",
      "5 6 5 log2 entropy False 50 76: Macro 0.695455 (0.100978)\n",
      "Testing 3406/4320\n",
      "5 6 5 log2 entropy False 100 76: Weighted 0.795264 (0.071879)\n",
      "5 6 5 log2 entropy False 100 76: Macro 0.682868 (0.097827)\n",
      "Testing 3407/4320\n",
      "5 6 5 log2 entropy False 200 76: Weighted 0.799778 (0.079587)\n",
      "5 6 5 log2 entropy False 200 76: Macro 0.686126 (0.115632)\n",
      "Testing 3408/4320\n",
      "5 6 5 log2 entropy False 500 76: Weighted 0.804873 (0.073101)\n",
      "5 6 5 log2 entropy False 500 76: Macro 0.695192 (0.101026)\n",
      "Testing 3409/4320\n",
      "5 6 5 sqrt gini True 50 76: Weighted 0.815739 (0.060394)\n",
      "5 6 5 sqrt gini True 50 76: Macro 0.712002 (0.077172)\n",
      "Testing 3410/4320\n",
      "5 6 5 sqrt gini True 100 76: Weighted 0.811590 (0.066628)\n",
      "5 6 5 sqrt gini True 100 76: Macro 0.702933 (0.091251)\n",
      "Testing 3411/4320\n",
      "5 6 5 sqrt gini True 200 76: Weighted 0.815739 (0.060394)\n",
      "5 6 5 sqrt gini True 200 76: Macro 0.712002 (0.077172)\n",
      "Testing 3412/4320\n",
      "5 6 5 sqrt gini True 500 76: Weighted 0.816624 (0.060205)\n",
      "5 6 5 sqrt gini True 500 76: Macro 0.711473 (0.077270)\n",
      "Testing 3413/4320\n",
      "5 6 5 sqrt gini False 50 76: Weighted 0.807389 (0.072746)\n",
      "5 6 5 sqrt gini False 50 76: Macro 0.699038 (0.099441)\n",
      "Testing 3414/4320\n",
      "5 6 5 sqrt gini False 100 76: Weighted 0.807424 (0.072763)\n",
      "5 6 5 sqrt gini False 100 76: Macro 0.700746 (0.100438)\n",
      "Testing 3415/4320\n",
      "5 6 5 sqrt gini False 200 76: Weighted 0.807424 (0.072763)\n",
      "5 6 5 sqrt gini False 200 76: Macro 0.700746 (0.100438)\n",
      "Testing 3416/4320\n",
      "5 6 5 sqrt gini False 500 76: Weighted 0.812352 (0.075646)\n",
      "5 6 5 sqrt gini False 500 76: Macro 0.708254 (0.105698)\n",
      "Testing 3417/4320\n",
      "5 6 5 sqrt entropy True 50 76: Weighted 0.817466 (0.066908)\n",
      "5 6 5 sqrt entropy True 50 76: Macro 0.716043 (0.088972)\n",
      "Testing 3418/4320\n",
      "5 6 5 sqrt entropy True 100 76: Weighted 0.810977 (0.058703)\n",
      "5 6 5 sqrt entropy True 100 76: Macro 0.704859 (0.074493)\n",
      "Testing 3419/4320\n",
      "5 6 5 sqrt entropy True 200 76: Weighted 0.811863 (0.058581)\n",
      "5 6 5 sqrt entropy True 200 76: Macro 0.704330 (0.074545)\n",
      "Testing 3420/4320\n",
      "5 6 5 sqrt entropy True 500 76: Weighted 0.811863 (0.058581)\n",
      "5 6 5 sqrt entropy True 500 76: Macro 0.704330 (0.074545)\n",
      "Testing 3421/4320\n",
      "5 6 5 sqrt entropy False 50 76: Weighted 0.803914 (0.073297)\n",
      "5 6 5 sqrt entropy False 50 76: Macro 0.695455 (0.100978)\n",
      "Testing 3422/4320\n",
      "5 6 5 sqrt entropy False 100 76: Weighted 0.795264 (0.071879)\n",
      "5 6 5 sqrt entropy False 100 76: Macro 0.682868 (0.097827)\n",
      "Testing 3423/4320\n",
      "5 6 5 sqrt entropy False 200 76: Weighted 0.799778 (0.079587)\n",
      "5 6 5 sqrt entropy False 200 76: Macro 0.686126 (0.115632)\n",
      "Testing 3424/4320\n",
      "5 6 5 sqrt entropy False 500 76: Weighted 0.804873 (0.073101)\n",
      "5 6 5 sqrt entropy False 500 76: Macro 0.695192 (0.101026)\n",
      "Testing 3425/4320\n",
      "5 6 8 log2 gini True 50 76: Weighted 0.819407 (0.059556)\n",
      "5 6 8 log2 gini True 50 76: Macro 0.716900 (0.077191)\n",
      "Testing 3426/4320\n",
      "5 6 8 log2 gini True 100 76: Weighted 0.811590 (0.066628)\n",
      "5 6 8 log2 gini True 100 76: Macro 0.702933 (0.091251)\n",
      "Testing 3427/4320\n",
      "5 6 8 log2 gini True 200 76: Weighted 0.815739 (0.060394)\n",
      "5 6 8 log2 gini True 200 76: Macro 0.712002 (0.077172)\n",
      "Testing 3428/4320\n",
      "5 6 8 log2 gini True 500 76: Weighted 0.815739 (0.060394)\n",
      "5 6 8 log2 gini True 500 76: Macro 0.712002 (0.077172)\n",
      "Testing 3429/4320\n",
      "5 6 8 log2 gini False 50 76: Weighted 0.808858 (0.067062)\n",
      "5 6 8 log2 gini False 50 76: Macro 0.698304 (0.092582)\n",
      "Testing 3430/4320\n",
      "5 6 8 log2 gini False 100 76: Weighted 0.799509 (0.066413)\n",
      "5 6 8 log2 gini False 100 76: Macro 0.686191 (0.090167)\n",
      "Testing 3431/4320\n",
      "5 6 8 log2 gini False 200 76: Weighted 0.799509 (0.066413)\n",
      "5 6 8 log2 gini False 200 76: Macro 0.686191 (0.090167)\n",
      "Testing 3432/4320\n",
      "5 6 8 log2 gini False 500 76: Weighted 0.804333 (0.068679)\n",
      "5 6 8 log2 gini False 500 76: Macro 0.693402 (0.094129)\n",
      "Testing 3433/4320\n",
      "5 6 8 log2 entropy True 50 76: Weighted 0.811422 (0.065826)\n",
      "5 6 8 log2 entropy True 50 76: Macro 0.708883 (0.085948)\n",
      "Testing 3434/4320\n",
      "5 6 8 log2 entropy True 100 76: Weighted 0.810494 (0.064722)\n",
      "5 6 8 log2 entropy True 100 76: Macro 0.704769 (0.084062)\n",
      "Testing 3435/4320\n",
      "5 6 8 log2 entropy True 200 76: Weighted 0.810977 (0.058703)\n",
      "5 6 8 log2 entropy True 200 76: Macro 0.704859 (0.074493)\n",
      "Testing 3436/4320\n",
      "5 6 8 log2 entropy True 500 76: Weighted 0.810977 (0.058703)\n",
      "5 6 8 log2 entropy True 500 76: Macro 0.704859 (0.074493)\n",
      "Testing 3437/4320\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 6 8 log2 entropy False 50 76: Weighted 0.790177 (0.070943)\n",
      "5 6 8 log2 entropy False 50 76: Macro 0.669258 (0.101797)\n",
      "Testing 3438/4320\n",
      "5 6 8 log2 entropy False 100 76: Weighted 0.799284 (0.066331)\n",
      "5 6 8 log2 entropy False 100 76: Macro 0.687687 (0.090862)\n",
      "Testing 3439/4320\n",
      "5 6 8 log2 entropy False 200 76: Weighted 0.799284 (0.066331)\n",
      "5 6 8 log2 entropy False 200 76: Macro 0.687687 (0.090862)\n",
      "Testing 3440/4320\n",
      "5 6 8 log2 entropy False 500 76: Weighted 0.799284 (0.066331)\n",
      "5 6 8 log2 entropy False 500 76: Macro 0.687687 (0.090862)\n",
      "Testing 3441/4320\n",
      "5 6 8 sqrt gini True 50 76: Weighted 0.819407 (0.059556)\n",
      "5 6 8 sqrt gini True 50 76: Macro 0.716900 (0.077191)\n",
      "Testing 3442/4320\n",
      "5 6 8 sqrt gini True 100 76: Weighted 0.811590 (0.066628)\n",
      "5 6 8 sqrt gini True 100 76: Macro 0.702933 (0.091251)\n",
      "Testing 3443/4320\n",
      "5 6 8 sqrt gini True 200 76: Weighted 0.815739 (0.060394)\n",
      "5 6 8 sqrt gini True 200 76: Macro 0.712002 (0.077172)\n",
      "Testing 3444/4320\n",
      "5 6 8 sqrt gini True 500 76: Weighted 0.815739 (0.060394)\n",
      "5 6 8 sqrt gini True 500 76: Macro 0.712002 (0.077172)\n",
      "Testing 3445/4320\n",
      "5 6 8 sqrt gini False 50 76: Weighted 0.808858 (0.067062)\n",
      "5 6 8 sqrt gini False 50 76: Macro 0.698304 (0.092582)\n",
      "Testing 3446/4320\n",
      "5 6 8 sqrt gini False 100 76: Weighted 0.799509 (0.066413)\n",
      "5 6 8 sqrt gini False 100 76: Macro 0.686191 (0.090167)\n",
      "Testing 3447/4320\n",
      "5 6 8 sqrt gini False 200 76: Weighted 0.799509 (0.066413)\n",
      "5 6 8 sqrt gini False 200 76: Macro 0.686191 (0.090167)\n",
      "Testing 3448/4320\n",
      "5 6 8 sqrt gini False 500 76: Weighted 0.804333 (0.068679)\n",
      "5 6 8 sqrt gini False 500 76: Macro 0.693402 (0.094129)\n",
      "Testing 3449/4320\n",
      "5 6 8 sqrt entropy True 50 76: Weighted 0.811422 (0.065826)\n",
      "5 6 8 sqrt entropy True 50 76: Macro 0.708883 (0.085948)\n",
      "Testing 3450/4320\n",
      "5 6 8 sqrt entropy True 100 76: Weighted 0.810494 (0.064722)\n",
      "5 6 8 sqrt entropy True 100 76: Macro 0.704769 (0.084062)\n",
      "Testing 3451/4320\n",
      "5 6 8 sqrt entropy True 200 76: Weighted 0.810977 (0.058703)\n",
      "5 6 8 sqrt entropy True 200 76: Macro 0.704859 (0.074493)\n",
      "Testing 3452/4320\n",
      "5 6 8 sqrt entropy True 500 76: Weighted 0.810977 (0.058703)\n",
      "5 6 8 sqrt entropy True 500 76: Macro 0.704859 (0.074493)\n",
      "Testing 3453/4320\n",
      "5 6 8 sqrt entropy False 50 76: Weighted 0.790177 (0.070943)\n",
      "5 6 8 sqrt entropy False 50 76: Macro 0.669258 (0.101797)\n",
      "Testing 3454/4320\n",
      "5 6 8 sqrt entropy False 100 76: Weighted 0.799284 (0.066331)\n",
      "5 6 8 sqrt entropy False 100 76: Macro 0.687687 (0.090862)\n",
      "Testing 3455/4320\n",
      "5 6 8 sqrt entropy False 200 76: Weighted 0.799284 (0.066331)\n",
      "5 6 8 sqrt entropy False 200 76: Macro 0.687687 (0.090862)\n",
      "Testing 3456/4320\n",
      "5 6 8 sqrt entropy False 500 76: Weighted 0.799284 (0.066331)\n",
      "5 6 8 sqrt entropy False 500 76: Macro 0.687687 (0.090862)\n",
      "Testing 3457/4320\n",
      "1 2 3 log2 gini True 50 112: Weighted 0.809272 (0.059036)\n",
      "1 2 3 log2 gini True 50 112: Macro 0.706370 (0.078427)\n",
      "Testing 3458/4320\n",
      "1 2 3 log2 gini True 100 112: Weighted 0.813733 (0.055258)\n",
      "1 2 3 log2 gini True 100 112: Macro 0.706814 (0.073173)\n",
      "Testing 3459/4320\n",
      "1 2 3 log2 gini True 200 112: Weighted 0.813941 (0.055478)\n",
      "1 2 3 log2 gini True 200 112: Macro 0.709900 (0.075733)\n",
      "Testing 3460/4320\n",
      "1 2 3 log2 gini True 500 112: Weighted 0.813941 (0.055478)\n",
      "1 2 3 log2 gini True 500 112: Macro 0.709900 (0.075733)\n",
      "Testing 3461/4320\n",
      "1 2 3 log2 gini False 50 112: Weighted 0.795620 (0.075964)\n",
      "1 2 3 log2 gini False 50 112: Macro 0.689937 (0.101621)\n",
      "Testing 3462/4320\n",
      "1 2 3 log2 gini False 100 112: Weighted 0.784660 (0.083529)\n",
      "1 2 3 log2 gini False 100 112: Macro 0.681324 (0.107388)\n",
      "Testing 3463/4320\n",
      "1 2 3 log2 gini False 200 112: Weighted 0.800099 (0.079756)\n",
      "1 2 3 log2 gini False 200 112: Macro 0.693554 (0.104338)\n",
      "Testing 3464/4320\n",
      "1 2 3 log2 gini False 500 112: Weighted 0.792762 (0.091573)\n",
      "1 2 3 log2 gini False 500 112: Macro 0.688197 (0.112806)\n",
      "Testing 3465/4320\n",
      "1 2 3 log2 entropy True 50 112: Weighted 0.809269 (0.059039)\n",
      "1 2 3 log2 entropy True 50 112: Macro 0.709761 (0.074612)\n",
      "Testing 3466/4320\n",
      "1 2 3 log2 entropy True 100 112: Weighted 0.818105 (0.050354)\n",
      "1 2 3 log2 entropy True 100 112: Macro 0.718709 (0.065572)\n",
      "Testing 3467/4320\n",
      "1 2 3 log2 entropy True 200 112: Weighted 0.818105 (0.050354)\n",
      "1 2 3 log2 entropy True 200 112: Macro 0.718709 (0.065572)\n",
      "Testing 3468/4320\n",
      "1 2 3 log2 entropy True 500 112: Weighted 0.814217 (0.055124)\n",
      "1 2 3 log2 entropy True 500 112: Macro 0.711260 (0.074050)\n",
      "Testing 3469/4320\n",
      "1 2 3 log2 entropy False 50 112: Weighted 0.777336 (0.094091)\n",
      "1 2 3 log2 entropy False 50 112: Macro 0.670083 (0.114844)\n",
      "Testing 3470/4320\n",
      "1 2 3 log2 entropy False 100 112: Weighted 0.772913 (0.090700)\n",
      "1 2 3 log2 entropy False 100 112: Macro 0.666569 (0.112166)\n",
      "Testing 3471/4320\n",
      "1 2 3 log2 entropy False 200 112: Weighted 0.777336 (0.094091)\n",
      "1 2 3 log2 entropy False 200 112: Macro 0.670083 (0.114844)\n",
      "Testing 3472/4320\n",
      "1 2 3 log2 entropy False 500 112: Weighted 0.781816 (0.098017)\n",
      "1 2 3 log2 entropy False 500 112: Macro 0.673700 (0.117866)\n",
      "Testing 3473/4320\n",
      "1 2 3 sqrt gini True 50 112: Weighted 0.809272 (0.059036)\n",
      "1 2 3 sqrt gini True 50 112: Macro 0.706370 (0.078427)\n",
      "Testing 3474/4320\n",
      "1 2 3 sqrt gini True 100 112: Weighted 0.813733 (0.055258)\n",
      "1 2 3 sqrt gini True 100 112: Macro 0.706814 (0.073173)\n",
      "Testing 3475/4320\n",
      "1 2 3 sqrt gini True 200 112: Weighted 0.813941 (0.055478)\n",
      "1 2 3 sqrt gini True 200 112: Macro 0.709900 (0.075733)\n",
      "Testing 3476/4320\n",
      "1 2 3 sqrt gini True 500 112: Weighted 0.813941 (0.055478)\n",
      "1 2 3 sqrt gini True 500 112: Macro 0.709900 (0.075733)\n",
      "Testing 3477/4320\n",
      "1 2 3 sqrt gini False 50 112: Weighted 0.795620 (0.075964)\n",
      "1 2 3 sqrt gini False 50 112: Macro 0.689937 (0.101621)\n",
      "Testing 3478/4320\n",
      "1 2 3 sqrt gini False 100 112: Weighted 0.784660 (0.083529)\n",
      "1 2 3 sqrt gini False 100 112: Macro 0.681324 (0.107388)\n",
      "Testing 3479/4320\n",
      "1 2 3 sqrt gini False 200 112: Weighted 0.800099 (0.079756)\n",
      "1 2 3 sqrt gini False 200 112: Macro 0.693554 (0.104338)\n",
      "Testing 3480/4320\n",
      "1 2 3 sqrt gini False 500 112: Weighted 0.792762 (0.091573)\n",
      "1 2 3 sqrt gini False 500 112: Macro 0.688197 (0.112806)\n",
      "Testing 3481/4320\n",
      "1 2 3 sqrt entropy True 50 112: Weighted 0.809269 (0.059039)\n",
      "1 2 3 sqrt entropy True 50 112: Macro 0.709761 (0.074612)\n",
      "Testing 3482/4320\n",
      "1 2 3 sqrt entropy True 100 112: Weighted 0.818105 (0.050354)\n",
      "1 2 3 sqrt entropy True 100 112: Macro 0.718709 (0.065572)\n",
      "Testing 3483/4320\n",
      "1 2 3 sqrt entropy True 200 112: Weighted 0.818105 (0.050354)\n",
      "1 2 3 sqrt entropy True 200 112: Macro 0.718709 (0.065572)\n",
      "Testing 3484/4320\n",
      "1 2 3 sqrt entropy True 500 112: Weighted 0.814217 (0.055124)\n",
      "1 2 3 sqrt entropy True 500 112: Macro 0.711260 (0.074050)\n",
      "Testing 3485/4320\n",
      "1 2 3 sqrt entropy False 50 112: Weighted 0.777336 (0.094091)\n",
      "1 2 3 sqrt entropy False 50 112: Macro 0.670083 (0.114844)\n",
      "Testing 3486/4320\n",
      "1 2 3 sqrt entropy False 100 112: Weighted 0.772913 (0.090700)\n",
      "1 2 3 sqrt entropy False 100 112: Macro 0.666569 (0.112166)\n",
      "Testing 3487/4320\n",
      "1 2 3 sqrt entropy False 200 112: Weighted 0.777336 (0.094091)\n",
      "1 2 3 sqrt entropy False 200 112: Macro 0.670083 (0.114844)\n",
      "Testing 3488/4320\n",
      "1 2 3 sqrt entropy False 500 112: Weighted 0.781816 (0.098017)\n",
      "1 2 3 sqrt entropy False 500 112: Macro 0.673700 (0.117866)\n",
      "Testing 3489/4320\n",
      "1 2 5 log2 gini True 50 112: Weighted 0.802923 (0.065526)\n",
      "1 2 5 log2 gini True 50 112: Macro 0.695518 (0.082698)\n",
      "Testing 3490/4320\n",
      "1 2 5 log2 gini True 100 112: Weighted 0.804858 (0.065466)\n",
      "1 2 5 log2 gini True 100 112: Macro 0.700594 (0.085026)\n",
      "Testing 3491/4320\n",
      "1 2 5 log2 gini True 200 112: Weighted 0.813266 (0.066477)\n",
      "1 2 5 log2 gini True 200 112: Macro 0.713022 (0.087980)\n",
      "Testing 3492/4320\n",
      "1 2 5 log2 gini True 500 112: Weighted 0.812762 (0.069199)\n",
      "1 2 5 log2 gini True 500 112: Macro 0.712475 (0.090767)\n",
      "Testing 3493/4320\n",
      "1 2 5 log2 gini False 50 112: Weighted 0.796094 (0.068822)\n",
      "1 2 5 log2 gini False 50 112: Macro 0.691894 (0.101224)\n",
      "Testing 3494/4320\n",
      "1 2 5 log2 gini False 100 112: Weighted 0.796094 (0.068822)\n",
      "1 2 5 log2 gini False 100 112: Macro 0.691894 (0.101224)\n",
      "Testing 3495/4320\n",
      "1 2 5 log2 gini False 200 112: Weighted 0.799501 (0.067904)\n",
      "1 2 5 log2 gini False 200 112: Macro 0.696888 (0.100110)\n",
      "Testing 3496/4320\n",
      "1 2 5 log2 gini False 500 112: Weighted 0.799501 (0.067904)\n",
      "1 2 5 log2 gini False 500 112: Macro 0.696888 (0.100110)\n",
      "Testing 3497/4320\n",
      "1 2 5 log2 entropy True 50 112: Weighted 0.809060 (0.072124)\n",
      "1 2 5 log2 entropy True 50 112: Macro 0.707808 (0.095153)\n",
      "Testing 3498/4320\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 2 5 log2 entropy True 100 112: Weighted 0.804132 (0.068859)\n",
      "1 2 5 log2 entropy True 100 112: Macro 0.700300 (0.089236)\n",
      "Testing 3499/4320\n",
      "1 2 5 log2 entropy True 200 112: Weighted 0.811746 (0.061575)\n",
      "1 2 5 log2 entropy True 200 112: Macro 0.710507 (0.079796)\n",
      "Testing 3500/4320\n",
      "1 2 5 log2 entropy True 500 112: Weighted 0.811962 (0.073188)\n",
      "1 2 5 log2 entropy True 500 112: Macro 0.712255 (0.095752)\n",
      "Testing 3501/4320\n",
      "1 2 5 log2 entropy False 50 112: Weighted 0.788093 (0.057755)\n",
      "1 2 5 log2 entropy False 50 112: Macro 0.685438 (0.076267)\n",
      "Testing 3502/4320\n",
      "1 2 5 log2 entropy False 100 112: Weighted 0.784019 (0.063935)\n",
      "1 2 5 log2 entropy False 100 112: Macro 0.676449 (0.089869)\n",
      "Testing 3503/4320\n",
      "1 2 5 log2 entropy False 200 112: Weighted 0.776265 (0.071203)\n",
      "1 2 5 log2 entropy False 200 112: Macro 0.661812 (0.105759)\n",
      "Testing 3504/4320\n",
      "1 2 5 log2 entropy False 500 112: Weighted 0.776265 (0.071203)\n",
      "1 2 5 log2 entropy False 500 112: Macro 0.661812 (0.105759)\n",
      "Testing 3505/4320\n",
      "1 2 5 sqrt gini True 50 112: Weighted 0.802923 (0.065526)\n",
      "1 2 5 sqrt gini True 50 112: Macro 0.695518 (0.082698)\n",
      "Testing 3506/4320\n",
      "1 2 5 sqrt gini True 100 112: Weighted 0.804858 (0.065466)\n",
      "1 2 5 sqrt gini True 100 112: Macro 0.700594 (0.085026)\n",
      "Testing 3507/4320\n",
      "1 2 5 sqrt gini True 200 112: Weighted 0.813266 (0.066477)\n",
      "1 2 5 sqrt gini True 200 112: Macro 0.713022 (0.087980)\n",
      "Testing 3508/4320\n",
      "1 2 5 sqrt gini True 500 112: Weighted 0.812762 (0.069199)\n",
      "1 2 5 sqrt gini True 500 112: Macro 0.712475 (0.090767)\n",
      "Testing 3509/4320\n",
      "1 2 5 sqrt gini False 50 112: Weighted 0.796094 (0.068822)\n",
      "1 2 5 sqrt gini False 50 112: Macro 0.691894 (0.101224)\n",
      "Testing 3510/4320\n",
      "1 2 5 sqrt gini False 100 112: Weighted 0.796094 (0.068822)\n",
      "1 2 5 sqrt gini False 100 112: Macro 0.691894 (0.101224)\n",
      "Testing 3511/4320\n",
      "1 2 5 sqrt gini False 200 112: Weighted 0.799501 (0.067904)\n",
      "1 2 5 sqrt gini False 200 112: Macro 0.696888 (0.100110)\n",
      "Testing 3512/4320\n",
      "1 2 5 sqrt gini False 500 112: Weighted 0.799501 (0.067904)\n",
      "1 2 5 sqrt gini False 500 112: Macro 0.696888 (0.100110)\n",
      "Testing 3513/4320\n",
      "1 2 5 sqrt entropy True 50 112: Weighted 0.809060 (0.072124)\n",
      "1 2 5 sqrt entropy True 50 112: Macro 0.707808 (0.095153)\n",
      "Testing 3514/4320\n",
      "1 2 5 sqrt entropy True 100 112: Weighted 0.804132 (0.068859)\n",
      "1 2 5 sqrt entropy True 100 112: Macro 0.700300 (0.089236)\n",
      "Testing 3515/4320\n",
      "1 2 5 sqrt entropy True 200 112: Weighted 0.811746 (0.061575)\n",
      "1 2 5 sqrt entropy True 200 112: Macro 0.710507 (0.079796)\n",
      "Testing 3516/4320\n",
      "1 2 5 sqrt entropy True 500 112: Weighted 0.811962 (0.073188)\n",
      "1 2 5 sqrt entropy True 500 112: Macro 0.712255 (0.095752)\n",
      "Testing 3517/4320\n",
      "1 2 5 sqrt entropy False 50 112: Weighted 0.788093 (0.057755)\n",
      "1 2 5 sqrt entropy False 50 112: Macro 0.685438 (0.076267)\n",
      "Testing 3518/4320\n",
      "1 2 5 sqrt entropy False 100 112: Weighted 0.784019 (0.063935)\n",
      "1 2 5 sqrt entropy False 100 112: Macro 0.676449 (0.089869)\n",
      "Testing 3519/4320\n",
      "1 2 5 sqrt entropy False 200 112: Weighted 0.776265 (0.071203)\n",
      "1 2 5 sqrt entropy False 200 112: Macro 0.661812 (0.105759)\n",
      "Testing 3520/4320\n",
      "1 2 5 sqrt entropy False 500 112: Weighted 0.776265 (0.071203)\n",
      "1 2 5 sqrt entropy False 500 112: Macro 0.661812 (0.105759)\n",
      "Testing 3521/4320\n",
      "1 2 8 log2 gini True 50 112: Weighted 0.807813 (0.071951)\n",
      "1 2 8 log2 gini True 50 112: Macro 0.706096 (0.091186)\n",
      "Testing 3522/4320\n",
      "1 2 8 log2 gini True 100 112: Weighted 0.809010 (0.060963)\n",
      "1 2 8 log2 gini True 100 112: Macro 0.703040 (0.077192)\n",
      "Testing 3523/4320\n",
      "1 2 8 log2 gini True 200 112: Weighted 0.812518 (0.067834)\n",
      "1 2 8 log2 gini True 200 112: Macro 0.710160 (0.086501)\n",
      "Testing 3524/4320\n",
      "1 2 8 log2 gini True 500 112: Weighted 0.803333 (0.059473)\n",
      "1 2 8 log2 gini True 500 112: Macro 0.696055 (0.073536)\n",
      "Testing 3525/4320\n",
      "1 2 8 log2 gini False 50 112: Weighted 0.799985 (0.059396)\n",
      "1 2 8 log2 gini False 50 112: Macro 0.694994 (0.088783)\n",
      "Testing 3526/4320\n",
      "1 2 8 log2 gini False 100 112: Weighted 0.789551 (0.069512)\n",
      "1 2 8 log2 gini False 100 112: Macro 0.681143 (0.102225)\n",
      "Testing 3527/4320\n",
      "1 2 8 log2 gini False 200 112: Weighted 0.792963 (0.066427)\n",
      "1 2 8 log2 gini False 200 112: Macro 0.685706 (0.098026)\n",
      "Testing 3528/4320\n",
      "1 2 8 log2 gini False 500 112: Weighted 0.793943 (0.065612)\n",
      "1 2 8 log2 gini False 500 112: Macro 0.691262 (0.093563)\n",
      "Testing 3529/4320\n",
      "1 2 8 log2 entropy True 50 112: Weighted 0.810270 (0.079928)\n",
      "1 2 8 log2 entropy True 50 112: Macro 0.707765 (0.106689)\n",
      "Testing 3530/4320\n",
      "1 2 8 log2 entropy True 100 112: Weighted 0.806286 (0.074611)\n",
      "1 2 8 log2 entropy True 100 112: Macro 0.699020 (0.096914)\n",
      "Testing 3531/4320\n",
      "1 2 8 log2 entropy True 200 112: Weighted 0.814550 (0.064317)\n",
      "1 2 8 log2 entropy True 200 112: Macro 0.718536 (0.081010)\n",
      "Testing 3532/4320\n",
      "1 2 8 log2 entropy True 500 112: Weighted 0.801476 (0.061425)\n",
      "1 2 8 log2 entropy True 500 112: Macro 0.696126 (0.073458)\n",
      "Testing 3533/4320\n",
      "1 2 8 log2 entropy False 50 112: Weighted 0.782036 (0.052135)\n",
      "1 2 8 log2 entropy False 50 112: Macro 0.673253 (0.072647)\n",
      "Testing 3534/4320\n",
      "1 2 8 log2 entropy False 100 112: Weighted 0.782068 (0.060995)\n",
      "1 2 8 log2 entropy False 100 112: Macro 0.671117 (0.092446)\n",
      "Testing 3535/4320\n",
      "1 2 8 log2 entropy False 200 112: Weighted 0.786797 (0.054734)\n",
      "1 2 8 log2 entropy False 200 112: Macro 0.681886 (0.076936)\n",
      "Testing 3536/4320\n",
      "1 2 8 log2 entropy False 500 112: Weighted 0.790393 (0.052767)\n",
      "1 2 8 log2 entropy False 500 112: Macro 0.687270 (0.074883)\n",
      "Testing 3537/4320\n",
      "1 2 8 sqrt gini True 50 112: Weighted 0.807813 (0.071951)\n",
      "1 2 8 sqrt gini True 50 112: Macro 0.706096 (0.091186)\n",
      "Testing 3538/4320\n",
      "1 2 8 sqrt gini True 100 112: Weighted 0.809010 (0.060963)\n",
      "1 2 8 sqrt gini True 100 112: Macro 0.703040 (0.077192)\n",
      "Testing 3539/4320\n",
      "1 2 8 sqrt gini True 200 112: Weighted 0.812518 (0.067834)\n",
      "1 2 8 sqrt gini True 200 112: Macro 0.710160 (0.086501)\n",
      "Testing 3540/4320\n",
      "1 2 8 sqrt gini True 500 112: Weighted 0.803333 (0.059473)\n",
      "1 2 8 sqrt gini True 500 112: Macro 0.696055 (0.073536)\n",
      "Testing 3541/4320\n",
      "1 2 8 sqrt gini False 50 112: Weighted 0.799985 (0.059396)\n",
      "1 2 8 sqrt gini False 50 112: Macro 0.694994 (0.088783)\n",
      "Testing 3542/4320\n",
      "1 2 8 sqrt gini False 100 112: Weighted 0.789551 (0.069512)\n",
      "1 2 8 sqrt gini False 100 112: Macro 0.681143 (0.102225)\n",
      "Testing 3543/4320\n",
      "1 2 8 sqrt gini False 200 112: Weighted 0.792963 (0.066427)\n",
      "1 2 8 sqrt gini False 200 112: Macro 0.685706 (0.098026)\n",
      "Testing 3544/4320\n",
      "1 2 8 sqrt gini False 500 112: Weighted 0.793943 (0.065612)\n",
      "1 2 8 sqrt gini False 500 112: Macro 0.691262 (0.093563)\n",
      "Testing 3545/4320\n",
      "1 2 8 sqrt entropy True 50 112: Weighted 0.810270 (0.079928)\n",
      "1 2 8 sqrt entropy True 50 112: Macro 0.707765 (0.106689)\n",
      "Testing 3546/4320\n",
      "1 2 8 sqrt entropy True 100 112: Weighted 0.806286 (0.074611)\n",
      "1 2 8 sqrt entropy True 100 112: Macro 0.699020 (0.096914)\n",
      "Testing 3547/4320\n",
      "1 2 8 sqrt entropy True 200 112: Weighted 0.814550 (0.064317)\n",
      "1 2 8 sqrt entropy True 200 112: Macro 0.718536 (0.081010)\n",
      "Testing 3548/4320\n",
      "1 2 8 sqrt entropy True 500 112: Weighted 0.801476 (0.061425)\n",
      "1 2 8 sqrt entropy True 500 112: Macro 0.696126 (0.073458)\n",
      "Testing 3549/4320\n",
      "1 2 8 sqrt entropy False 50 112: Weighted 0.782036 (0.052135)\n",
      "1 2 8 sqrt entropy False 50 112: Macro 0.673253 (0.072647)\n",
      "Testing 3550/4320\n",
      "1 2 8 sqrt entropy False 100 112: Weighted 0.782068 (0.060995)\n",
      "1 2 8 sqrt entropy False 100 112: Macro 0.671117 (0.092446)\n",
      "Testing 3551/4320\n",
      "1 2 8 sqrt entropy False 200 112: Weighted 0.786797 (0.054734)\n",
      "1 2 8 sqrt entropy False 200 112: Macro 0.681886 (0.076936)\n",
      "Testing 3552/4320\n",
      "1 2 8 sqrt entropy False 500 112: Weighted 0.790393 (0.052767)\n",
      "1 2 8 sqrt entropy False 500 112: Macro 0.687270 (0.074883)\n",
      "Testing 3553/4320\n",
      "1 4 3 log2 gini True 50 112: Weighted 0.809272 (0.059036)\n",
      "1 4 3 log2 gini True 50 112: Macro 0.706370 (0.078427)\n",
      "Testing 3554/4320\n",
      "1 4 3 log2 gini True 100 112: Weighted 0.813941 (0.055478)\n",
      "1 4 3 log2 gini True 100 112: Macro 0.709900 (0.075733)\n",
      "Testing 3555/4320\n",
      "1 4 3 log2 gini True 200 112: Weighted 0.813941 (0.055478)\n",
      "1 4 3 log2 gini True 200 112: Macro 0.709900 (0.075733)\n",
      "Testing 3556/4320\n",
      "1 4 3 log2 gini True 500 112: Weighted 0.813941 (0.055478)\n",
      "1 4 3 log2 gini True 500 112: Macro 0.709900 (0.075733)\n",
      "Testing 3557/4320\n",
      "1 4 3 log2 gini False 50 112: Weighted 0.785021 (0.096793)\n",
      "1 4 3 log2 gini False 50 112: Macro 0.677877 (0.123950)\n",
      "Testing 3558/4320\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 4 3 log2 gini False 100 112: Weighted 0.782658 (0.100551)\n",
      "1 4 3 log2 gini False 100 112: Macro 0.677747 (0.124156)\n",
      "Testing 3559/4320\n",
      "1 4 3 log2 gini False 200 112: Weighted 0.788859 (0.090750)\n",
      "1 4 3 log2 gini False 200 112: Macro 0.684887 (0.112953)\n",
      "Testing 3560/4320\n",
      "1 4 3 log2 gini False 500 112: Weighted 0.788859 (0.090750)\n",
      "1 4 3 log2 gini False 500 112: Macro 0.684887 (0.112953)\n",
      "Testing 3561/4320\n",
      "1 4 3 log2 entropy True 50 112: Weighted 0.809269 (0.059039)\n",
      "1 4 3 log2 entropy True 50 112: Macro 0.709761 (0.074612)\n",
      "Testing 3562/4320\n",
      "1 4 3 log2 entropy True 100 112: Weighted 0.818105 (0.050354)\n",
      "1 4 3 log2 entropy True 100 112: Macro 0.718709 (0.065572)\n",
      "Testing 3563/4320\n",
      "1 4 3 log2 entropy True 200 112: Weighted 0.813938 (0.055482)\n",
      "1 4 3 log2 entropy True 200 112: Macro 0.713290 (0.071608)\n",
      "Testing 3564/4320\n",
      "1 4 3 log2 entropy True 500 112: Weighted 0.814217 (0.055124)\n",
      "1 4 3 log2 entropy True 500 112: Macro 0.711260 (0.074050)\n",
      "Testing 3565/4320\n",
      "1 4 3 log2 entropy False 50 112: Weighted 0.781816 (0.098017)\n",
      "1 4 3 log2 entropy False 50 112: Macro 0.673700 (0.117866)\n",
      "Testing 3566/4320\n",
      "1 4 3 log2 entropy False 100 112: Weighted 0.781816 (0.098017)\n",
      "1 4 3 log2 entropy False 100 112: Macro 0.673700 (0.117866)\n",
      "Testing 3567/4320\n",
      "1 4 3 log2 entropy False 200 112: Weighted 0.781816 (0.098017)\n",
      "1 4 3 log2 entropy False 200 112: Macro 0.673700 (0.117866)\n",
      "Testing 3568/4320\n",
      "1 4 3 log2 entropy False 500 112: Weighted 0.781816 (0.098017)\n",
      "1 4 3 log2 entropy False 500 112: Macro 0.673700 (0.117866)\n",
      "Testing 3569/4320\n",
      "1 4 3 sqrt gini True 50 112: Weighted 0.809272 (0.059036)\n",
      "1 4 3 sqrt gini True 50 112: Macro 0.706370 (0.078427)\n",
      "Testing 3570/4320\n",
      "1 4 3 sqrt gini True 100 112: Weighted 0.813941 (0.055478)\n",
      "1 4 3 sqrt gini True 100 112: Macro 0.709900 (0.075733)\n",
      "Testing 3571/4320\n",
      "1 4 3 sqrt gini True 200 112: Weighted 0.813941 (0.055478)\n",
      "1 4 3 sqrt gini True 200 112: Macro 0.709900 (0.075733)\n",
      "Testing 3572/4320\n",
      "1 4 3 sqrt gini True 500 112: Weighted 0.813941 (0.055478)\n",
      "1 4 3 sqrt gini True 500 112: Macro 0.709900 (0.075733)\n",
      "Testing 3573/4320\n",
      "1 4 3 sqrt gini False 50 112: Weighted 0.785021 (0.096793)\n",
      "1 4 3 sqrt gini False 50 112: Macro 0.677877 (0.123950)\n",
      "Testing 3574/4320\n",
      "1 4 3 sqrt gini False 100 112: Weighted 0.782658 (0.100551)\n",
      "1 4 3 sqrt gini False 100 112: Macro 0.677747 (0.124156)\n",
      "Testing 3575/4320\n",
      "1 4 3 sqrt gini False 200 112: Weighted 0.788859 (0.090750)\n",
      "1 4 3 sqrt gini False 200 112: Macro 0.684887 (0.112953)\n",
      "Testing 3576/4320\n",
      "1 4 3 sqrt gini False 500 112: Weighted 0.788859 (0.090750)\n",
      "1 4 3 sqrt gini False 500 112: Macro 0.684887 (0.112953)\n",
      "Testing 3577/4320\n",
      "1 4 3 sqrt entropy True 50 112: Weighted 0.809269 (0.059039)\n",
      "1 4 3 sqrt entropy True 50 112: Macro 0.709761 (0.074612)\n",
      "Testing 3578/4320\n",
      "1 4 3 sqrt entropy True 100 112: Weighted 0.818105 (0.050354)\n",
      "1 4 3 sqrt entropy True 100 112: Macro 0.718709 (0.065572)\n",
      "Testing 3579/4320\n",
      "1 4 3 sqrt entropy True 200 112: Weighted 0.813938 (0.055482)\n",
      "1 4 3 sqrt entropy True 200 112: Macro 0.713290 (0.071608)\n",
      "Testing 3580/4320\n",
      "1 4 3 sqrt entropy True 500 112: Weighted 0.814217 (0.055124)\n",
      "1 4 3 sqrt entropy True 500 112: Macro 0.711260 (0.074050)\n",
      "Testing 3581/4320\n",
      "1 4 3 sqrt entropy False 50 112: Weighted 0.781816 (0.098017)\n",
      "1 4 3 sqrt entropy False 50 112: Macro 0.673700 (0.117866)\n",
      "Testing 3582/4320\n",
      "1 4 3 sqrt entropy False 100 112: Weighted 0.781816 (0.098017)\n",
      "1 4 3 sqrt entropy False 100 112: Macro 0.673700 (0.117866)\n",
      "Testing 3583/4320\n",
      "1 4 3 sqrt entropy False 200 112: Weighted 0.781816 (0.098017)\n",
      "1 4 3 sqrt entropy False 200 112: Macro 0.673700 (0.117866)\n",
      "Testing 3584/4320\n",
      "1 4 3 sqrt entropy False 500 112: Weighted 0.781816 (0.098017)\n",
      "1 4 3 sqrt entropy False 500 112: Macro 0.673700 (0.117866)\n",
      "Testing 3585/4320\n",
      "1 4 5 log2 gini True 50 112: Weighted 0.802923 (0.065526)\n",
      "1 4 5 log2 gini True 50 112: Macro 0.695518 (0.082698)\n",
      "Testing 3586/4320\n",
      "1 4 5 log2 gini True 100 112: Weighted 0.804132 (0.068859)\n",
      "1 4 5 log2 gini True 100 112: Macro 0.700300 (0.089236)\n",
      "Testing 3587/4320\n",
      "1 4 5 log2 gini True 200 112: Weighted 0.813266 (0.066477)\n",
      "1 4 5 log2 gini True 200 112: Macro 0.713022 (0.087980)\n",
      "Testing 3588/4320\n",
      "1 4 5 log2 gini True 500 112: Weighted 0.808339 (0.063249)\n",
      "1 4 5 log2 gini True 500 112: Macro 0.705513 (0.082024)\n",
      "Testing 3589/4320\n",
      "1 4 5 log2 gini False 50 112: Weighted 0.805096 (0.077695)\n",
      "1 4 5 log2 gini False 50 112: Macro 0.699133 (0.107709)\n",
      "Testing 3590/4320\n",
      "1 4 5 log2 gini False 100 112: Weighted 0.805096 (0.077695)\n",
      "1 4 5 log2 gini False 100 112: Macro 0.699133 (0.107709)\n",
      "Testing 3591/4320\n",
      "1 4 5 log2 gini False 200 112: Weighted 0.808504 (0.076483)\n",
      "1 4 5 log2 gini False 200 112: Macro 0.704126 (0.106322)\n",
      "Testing 3592/4320\n",
      "1 4 5 log2 gini False 500 112: Weighted 0.808504 (0.076483)\n",
      "1 4 5 log2 gini False 500 112: Macro 0.704126 (0.106322)\n",
      "Testing 3593/4320\n",
      "1 4 5 log2 entropy True 50 112: Weighted 0.809060 (0.072124)\n",
      "1 4 5 log2 entropy True 50 112: Macro 0.707808 (0.095153)\n",
      "Testing 3594/4320\n",
      "1 4 5 log2 entropy True 100 112: Weighted 0.795792 (0.068210)\n",
      "1 4 5 log2 entropy True 100 112: Macro 0.686462 (0.086425)\n",
      "Testing 3595/4320\n",
      "1 4 5 log2 entropy True 200 112: Weighted 0.812467 (0.070626)\n",
      "1 4 5 log2 entropy True 200 112: Macro 0.712802 (0.093116)\n",
      "Testing 3596/4320\n",
      "1 4 5 log2 entropy True 500 112: Weighted 0.807540 (0.067537)\n",
      "1 4 5 log2 entropy True 500 112: Macro 0.705293 (0.087491)\n",
      "Testing 3597/4320\n",
      "1 4 5 log2 entropy False 50 112: Weighted 0.792575 (0.063197)\n",
      "1 4 5 log2 entropy False 50 112: Macro 0.685865 (0.076768)\n",
      "Testing 3598/4320\n",
      "1 4 5 log2 entropy False 100 112: Weighted 0.793021 (0.074867)\n",
      "1 4 5 log2 entropy False 100 112: Macro 0.683688 (0.098259)\n",
      "Testing 3599/4320\n",
      "1 4 5 log2 entropy False 200 112: Weighted 0.788748 (0.081104)\n",
      "1 4 5 log2 entropy False 200 112: Macro 0.673970 (0.113068)\n",
      "Testing 3600/4320\n",
      "1 4 5 log2 entropy False 500 112: Weighted 0.789541 (0.076051)\n",
      "1 4 5 log2 entropy False 500 112: Macro 0.678769 (0.099708)\n",
      "Testing 3601/4320\n",
      "1 4 5 sqrt gini True 50 112: Weighted 0.802923 (0.065526)\n",
      "1 4 5 sqrt gini True 50 112: Macro 0.695518 (0.082698)\n",
      "Testing 3602/4320\n",
      "1 4 5 sqrt gini True 100 112: Weighted 0.804132 (0.068859)\n",
      "1 4 5 sqrt gini True 100 112: Macro 0.700300 (0.089236)\n",
      "Testing 3603/4320\n",
      "1 4 5 sqrt gini True 200 112: Weighted 0.813266 (0.066477)\n",
      "1 4 5 sqrt gini True 200 112: Macro 0.713022 (0.087980)\n",
      "Testing 3604/4320\n",
      "1 4 5 sqrt gini True 500 112: Weighted 0.808339 (0.063249)\n",
      "1 4 5 sqrt gini True 500 112: Macro 0.705513 (0.082024)\n",
      "Testing 3605/4320\n",
      "1 4 5 sqrt gini False 50 112: Weighted 0.805096 (0.077695)\n",
      "1 4 5 sqrt gini False 50 112: Macro 0.699133 (0.107709)\n",
      "Testing 3606/4320\n",
      "1 4 5 sqrt gini False 100 112: Weighted 0.805096 (0.077695)\n",
      "1 4 5 sqrt gini False 100 112: Macro 0.699133 (0.107709)\n",
      "Testing 3607/4320\n",
      "1 4 5 sqrt gini False 200 112: Weighted 0.808504 (0.076483)\n",
      "1 4 5 sqrt gini False 200 112: Macro 0.704126 (0.106322)\n",
      "Testing 3608/4320\n",
      "1 4 5 sqrt gini False 500 112: Weighted 0.808504 (0.076483)\n",
      "1 4 5 sqrt gini False 500 112: Macro 0.704126 (0.106322)\n",
      "Testing 3609/4320\n",
      "1 4 5 sqrt entropy True 50 112: Weighted 0.809060 (0.072124)\n",
      "1 4 5 sqrt entropy True 50 112: Macro 0.707808 (0.095153)\n",
      "Testing 3610/4320\n",
      "1 4 5 sqrt entropy True 100 112: Weighted 0.795792 (0.068210)\n",
      "1 4 5 sqrt entropy True 100 112: Macro 0.686462 (0.086425)\n",
      "Testing 3611/4320\n",
      "1 4 5 sqrt entropy True 200 112: Weighted 0.812467 (0.070626)\n",
      "1 4 5 sqrt entropy True 200 112: Macro 0.712802 (0.093116)\n",
      "Testing 3612/4320\n",
      "1 4 5 sqrt entropy True 500 112: Weighted 0.807540 (0.067537)\n",
      "1 4 5 sqrt entropy True 500 112: Macro 0.705293 (0.087491)\n",
      "Testing 3613/4320\n",
      "1 4 5 sqrt entropy False 50 112: Weighted 0.792575 (0.063197)\n",
      "1 4 5 sqrt entropy False 50 112: Macro 0.685865 (0.076768)\n",
      "Testing 3614/4320\n",
      "1 4 5 sqrt entropy False 100 112: Weighted 0.793021 (0.074867)\n",
      "1 4 5 sqrt entropy False 100 112: Macro 0.683688 (0.098259)\n",
      "Testing 3615/4320\n",
      "1 4 5 sqrt entropy False 200 112: Weighted 0.788748 (0.081104)\n",
      "1 4 5 sqrt entropy False 200 112: Macro 0.673970 (0.113068)\n",
      "Testing 3616/4320\n",
      "1 4 5 sqrt entropy False 500 112: Weighted 0.789541 (0.076051)\n",
      "1 4 5 sqrt entropy False 500 112: Macro 0.678769 (0.099708)\n",
      "Testing 3617/4320\n",
      "1 4 8 log2 gini True 50 112: Weighted 0.808912 (0.071101)\n",
      "1 4 8 log2 gini True 50 112: Macro 0.699743 (0.095967)\n",
      "Testing 3618/4320\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 4 8 log2 gini True 100 112: Weighted 0.815867 (0.064982)\n",
      "1 4 8 log2 gini True 100 112: Macro 0.716210 (0.083310)\n",
      "Testing 3619/4320\n",
      "1 4 8 log2 gini True 200 112: Weighted 0.816913 (0.064448)\n",
      "1 4 8 log2 gini True 200 112: Macro 0.714921 (0.083125)\n",
      "Testing 3620/4320\n",
      "1 4 8 log2 gini True 500 112: Weighted 0.807729 (0.056302)\n",
      "1 4 8 log2 gini True 500 112: Macro 0.700817 (0.070492)\n",
      "Testing 3621/4320\n",
      "1 4 8 log2 gini False 50 112: Weighted 0.797108 (0.063265)\n",
      "1 4 8 log2 gini False 50 112: Macro 0.689240 (0.083349)\n",
      "Testing 3622/4320\n",
      "1 4 8 log2 gini False 100 112: Weighted 0.802946 (0.075124)\n",
      "1 4 8 log2 gini False 100 112: Macro 0.698501 (0.100589)\n",
      "Testing 3623/4320\n",
      "1 4 8 log2 gini False 200 112: Weighted 0.801628 (0.068900)\n",
      "1 4 8 log2 gini False 200 112: Macro 0.696052 (0.090954)\n",
      "Testing 3624/4320\n",
      "1 4 8 log2 gini False 500 112: Weighted 0.798018 (0.071576)\n",
      "1 4 8 log2 gini False 500 112: Macro 0.690992 (0.094273)\n",
      "Testing 3625/4320\n",
      "1 4 8 log2 entropy True 50 112: Weighted 0.812020 (0.068020)\n",
      "1 4 8 log2 entropy True 50 112: Macro 0.705099 (0.092113)\n",
      "Testing 3626/4320\n",
      "1 4 8 log2 entropy True 100 112: Weighted 0.819528 (0.062787)\n",
      "1 4 8 log2 entropy True 100 112: Macro 0.720544 (0.080054)\n",
      "Testing 3627/4320\n",
      "1 4 8 log2 entropy True 200 112: Weighted 0.816047 (0.065059)\n",
      "1 4 8 log2 entropy True 200 112: Macro 0.715285 (0.082895)\n",
      "Testing 3628/4320\n",
      "1 4 8 log2 entropy True 500 112: Weighted 0.801817 (0.053810)\n",
      "1 4 8 log2 entropy True 500 112: Macro 0.694549 (0.066165)\n",
      "Testing 3629/4320\n",
      "1 4 8 log2 entropy False 50 112: Weighted 0.800265 (0.061821)\n",
      "1 4 8 log2 entropy False 50 112: Macro 0.698975 (0.074046)\n",
      "Testing 3630/4320\n",
      "1 4 8 log2 entropy False 100 112: Weighted 0.795800 (0.066806)\n",
      "1 4 8 log2 entropy False 100 112: Macro 0.689125 (0.086133)\n",
      "Testing 3631/4320\n",
      "1 4 8 log2 entropy False 200 112: Weighted 0.803819 (0.071092)\n",
      "1 4 8 log2 entropy False 200 112: Macro 0.701471 (0.093237)\n",
      "Testing 3632/4320\n",
      "1 4 8 log2 entropy False 500 112: Weighted 0.799396 (0.064706)\n",
      "1 4 8 log2 entropy False 500 112: Macro 0.694509 (0.083840)\n",
      "Testing 3633/4320\n",
      "1 4 8 sqrt gini True 50 112: Weighted 0.808912 (0.071101)\n",
      "1 4 8 sqrt gini True 50 112: Macro 0.699743 (0.095967)\n",
      "Testing 3634/4320\n",
      "1 4 8 sqrt gini True 100 112: Weighted 0.815867 (0.064982)\n",
      "1 4 8 sqrt gini True 100 112: Macro 0.716210 (0.083310)\n",
      "Testing 3635/4320\n",
      "1 4 8 sqrt gini True 200 112: Weighted 0.816913 (0.064448)\n",
      "1 4 8 sqrt gini True 200 112: Macro 0.714921 (0.083125)\n",
      "Testing 3636/4320\n",
      "1 4 8 sqrt gini True 500 112: Weighted 0.807729 (0.056302)\n",
      "1 4 8 sqrt gini True 500 112: Macro 0.700817 (0.070492)\n",
      "Testing 3637/4320\n",
      "1 4 8 sqrt gini False 50 112: Weighted 0.797108 (0.063265)\n",
      "1 4 8 sqrt gini False 50 112: Macro 0.689240 (0.083349)\n",
      "Testing 3638/4320\n",
      "1 4 8 sqrt gini False 100 112: Weighted 0.802946 (0.075124)\n",
      "1 4 8 sqrt gini False 100 112: Macro 0.698501 (0.100589)\n",
      "Testing 3639/4320\n",
      "1 4 8 sqrt gini False 200 112: Weighted 0.801628 (0.068900)\n",
      "1 4 8 sqrt gini False 200 112: Macro 0.696052 (0.090954)\n",
      "Testing 3640/4320\n",
      "1 4 8 sqrt gini False 500 112: Weighted 0.798018 (0.071576)\n",
      "1 4 8 sqrt gini False 500 112: Macro 0.690992 (0.094273)\n",
      "Testing 3641/4320\n",
      "1 4 8 sqrt entropy True 50 112: Weighted 0.812020 (0.068020)\n",
      "1 4 8 sqrt entropy True 50 112: Macro 0.705099 (0.092113)\n",
      "Testing 3642/4320\n",
      "1 4 8 sqrt entropy True 100 112: Weighted 0.819528 (0.062787)\n",
      "1 4 8 sqrt entropy True 100 112: Macro 0.720544 (0.080054)\n",
      "Testing 3643/4320\n",
      "1 4 8 sqrt entropy True 200 112: Weighted 0.816047 (0.065059)\n",
      "1 4 8 sqrt entropy True 200 112: Macro 0.715285 (0.082895)\n",
      "Testing 3644/4320\n",
      "1 4 8 sqrt entropy True 500 112: Weighted 0.801817 (0.053810)\n",
      "1 4 8 sqrt entropy True 500 112: Macro 0.694549 (0.066165)\n",
      "Testing 3645/4320\n",
      "1 4 8 sqrt entropy False 50 112: Weighted 0.800265 (0.061821)\n",
      "1 4 8 sqrt entropy False 50 112: Macro 0.698975 (0.074046)\n",
      "Testing 3646/4320\n",
      "1 4 8 sqrt entropy False 100 112: Weighted 0.795800 (0.066806)\n",
      "1 4 8 sqrt entropy False 100 112: Macro 0.689125 (0.086133)\n",
      "Testing 3647/4320\n",
      "1 4 8 sqrt entropy False 200 112: Weighted 0.803819 (0.071092)\n",
      "1 4 8 sqrt entropy False 200 112: Macro 0.701471 (0.093237)\n",
      "Testing 3648/4320\n",
      "1 4 8 sqrt entropy False 500 112: Weighted 0.799396 (0.064706)\n",
      "1 4 8 sqrt entropy False 500 112: Macro 0.694509 (0.083840)\n",
      "Testing 3649/4320\n",
      "1 6 3 log2 gini True 50 112: Weighted 0.809272 (0.059036)\n",
      "1 6 3 log2 gini True 50 112: Macro 0.706370 (0.078427)\n",
      "Testing 3650/4320\n",
      "1 6 3 log2 gini True 100 112: Weighted 0.813941 (0.055478)\n",
      "1 6 3 log2 gini True 100 112: Macro 0.709900 (0.075733)\n",
      "Testing 3651/4320\n",
      "1 6 3 log2 gini True 200 112: Weighted 0.809935 (0.060810)\n",
      "1 6 3 log2 gini True 200 112: Macro 0.704820 (0.082311)\n",
      "Testing 3652/4320\n",
      "1 6 3 log2 gini True 500 112: Weighted 0.813941 (0.055478)\n",
      "1 6 3 log2 gini True 500 112: Macro 0.709900 (0.075733)\n",
      "Testing 3653/4320\n",
      "1 6 3 log2 gini False 50 112: Weighted 0.788859 (0.090750)\n",
      "1 6 3 log2 gini False 50 112: Macro 0.684887 (0.112953)\n",
      "Testing 3654/4320\n",
      "1 6 3 log2 gini False 100 112: Weighted 0.782658 (0.100551)\n",
      "1 6 3 log2 gini False 100 112: Macro 0.677747 (0.124156)\n",
      "Testing 3655/4320\n",
      "1 6 3 log2 gini False 200 112: Weighted 0.788859 (0.090750)\n",
      "1 6 3 log2 gini False 200 112: Macro 0.684887 (0.112953)\n",
      "Testing 3656/4320\n",
      "1 6 3 log2 gini False 500 112: Weighted 0.788859 (0.090750)\n",
      "1 6 3 log2 gini False 500 112: Macro 0.684887 (0.112953)\n",
      "Testing 3657/4320\n",
      "1 6 3 log2 entropy True 50 112: Weighted 0.809269 (0.059039)\n",
      "1 6 3 log2 entropy True 50 112: Macro 0.709761 (0.074612)\n",
      "Testing 3658/4320\n",
      "1 6 3 log2 entropy True 100 112: Weighted 0.822625 (0.055592)\n",
      "1 6 3 log2 entropy True 100 112: Macro 0.725521 (0.072275)\n",
      "Testing 3659/4320\n",
      "1 6 3 log2 entropy True 200 112: Weighted 0.809566 (0.061318)\n",
      "1 6 3 log2 entropy True 200 112: Macro 0.707742 (0.078474)\n",
      "Testing 3660/4320\n",
      "1 6 3 log2 entropy True 500 112: Weighted 0.814217 (0.055124)\n",
      "1 6 3 log2 entropy True 500 112: Macro 0.711260 (0.074050)\n",
      "Testing 3661/4320\n",
      "1 6 3 log2 entropy False 50 112: Weighted 0.781816 (0.098017)\n",
      "1 6 3 log2 entropy False 50 112: Macro 0.673700 (0.117866)\n",
      "Testing 3662/4320\n",
      "1 6 3 log2 entropy False 100 112: Weighted 0.781816 (0.098017)\n",
      "1 6 3 log2 entropy False 100 112: Macro 0.673700 (0.117866)\n",
      "Testing 3663/4320\n",
      "1 6 3 log2 entropy False 200 112: Weighted 0.781816 (0.098017)\n",
      "1 6 3 log2 entropy False 200 112: Macro 0.673700 (0.117866)\n",
      "Testing 3664/4320\n",
      "1 6 3 log2 entropy False 500 112: Weighted 0.781816 (0.098017)\n",
      "1 6 3 log2 entropy False 500 112: Macro 0.673700 (0.117866)\n",
      "Testing 3665/4320\n",
      "1 6 3 sqrt gini True 50 112: Weighted 0.809272 (0.059036)\n",
      "1 6 3 sqrt gini True 50 112: Macro 0.706370 (0.078427)\n",
      "Testing 3666/4320\n",
      "1 6 3 sqrt gini True 100 112: Weighted 0.813941 (0.055478)\n",
      "1 6 3 sqrt gini True 100 112: Macro 0.709900 (0.075733)\n",
      "Testing 3667/4320\n",
      "1 6 3 sqrt gini True 200 112: Weighted 0.809935 (0.060810)\n",
      "1 6 3 sqrt gini True 200 112: Macro 0.704820 (0.082311)\n",
      "Testing 3668/4320\n",
      "1 6 3 sqrt gini True 500 112: Weighted 0.813941 (0.055478)\n",
      "1 6 3 sqrt gini True 500 112: Macro 0.709900 (0.075733)\n",
      "Testing 3669/4320\n",
      "1 6 3 sqrt gini False 50 112: Weighted 0.788859 (0.090750)\n",
      "1 6 3 sqrt gini False 50 112: Macro 0.684887 (0.112953)\n",
      "Testing 3670/4320\n",
      "1 6 3 sqrt gini False 100 112: Weighted 0.782658 (0.100551)\n",
      "1 6 3 sqrt gini False 100 112: Macro 0.677747 (0.124156)\n",
      "Testing 3671/4320\n",
      "1 6 3 sqrt gini False 200 112: Weighted 0.788859 (0.090750)\n",
      "1 6 3 sqrt gini False 200 112: Macro 0.684887 (0.112953)\n",
      "Testing 3672/4320\n",
      "1 6 3 sqrt gini False 500 112: Weighted 0.788859 (0.090750)\n",
      "1 6 3 sqrt gini False 500 112: Macro 0.684887 (0.112953)\n",
      "Testing 3673/4320\n",
      "1 6 3 sqrt entropy True 50 112: Weighted 0.809269 (0.059039)\n",
      "1 6 3 sqrt entropy True 50 112: Macro 0.709761 (0.074612)\n",
      "Testing 3674/4320\n",
      "1 6 3 sqrt entropy True 100 112: Weighted 0.822625 (0.055592)\n",
      "1 6 3 sqrt entropy True 100 112: Macro 0.725521 (0.072275)\n",
      "Testing 3675/4320\n",
      "1 6 3 sqrt entropy True 200 112: Weighted 0.809566 (0.061318)\n",
      "1 6 3 sqrt entropy True 200 112: Macro 0.707742 (0.078474)\n",
      "Testing 3676/4320\n",
      "1 6 3 sqrt entropy True 500 112: Weighted 0.814217 (0.055124)\n",
      "1 6 3 sqrt entropy True 500 112: Macro 0.711260 (0.074050)\n",
      "Testing 3677/4320\n",
      "1 6 3 sqrt entropy False 50 112: Weighted 0.781816 (0.098017)\n",
      "1 6 3 sqrt entropy False 50 112: Macro 0.673700 (0.117866)\n",
      "Testing 3678/4320\n",
      "1 6 3 sqrt entropy False 100 112: Weighted 0.781816 (0.098017)\n",
      "1 6 3 sqrt entropy False 100 112: Macro 0.673700 (0.117866)\n",
      "Testing 3679/4320\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 6 3 sqrt entropy False 200 112: Weighted 0.781816 (0.098017)\n",
      "1 6 3 sqrt entropy False 200 112: Macro 0.673700 (0.117866)\n",
      "Testing 3680/4320\n",
      "1 6 3 sqrt entropy False 500 112: Weighted 0.781816 (0.098017)\n",
      "1 6 3 sqrt entropy False 500 112: Macro 0.673700 (0.117866)\n",
      "Testing 3681/4320\n",
      "1 6 5 log2 gini True 50 112: Weighted 0.804277 (0.068943)\n",
      "1 6 5 log2 gini True 50 112: Macro 0.697667 (0.087525)\n",
      "Testing 3682/4320\n",
      "1 6 5 log2 gini True 100 112: Weighted 0.800797 (0.070783)\n",
      "1 6 5 log2 gini True 100 112: Macro 0.692748 (0.089916)\n",
      "Testing 3683/4320\n",
      "1 6 5 log2 gini True 200 112: Weighted 0.813266 (0.066477)\n",
      "1 6 5 log2 gini True 200 112: Macro 0.713022 (0.087980)\n",
      "Testing 3684/4320\n",
      "1 6 5 log2 gini True 500 112: Weighted 0.803722 (0.061157)\n",
      "1 6 5 log2 gini True 500 112: Macro 0.695738 (0.076918)\n",
      "Testing 3685/4320\n",
      "1 6 5 log2 gini False 50 112: Weighted 0.805096 (0.077695)\n",
      "1 6 5 log2 gini False 50 112: Macro 0.699133 (0.107709)\n",
      "Testing 3686/4320\n",
      "1 6 5 log2 gini False 100 112: Weighted 0.805096 (0.077695)\n",
      "1 6 5 log2 gini False 100 112: Macro 0.699133 (0.107709)\n",
      "Testing 3687/4320\n",
      "1 6 5 log2 gini False 200 112: Weighted 0.808504 (0.076483)\n",
      "1 6 5 log2 gini False 200 112: Macro 0.704126 (0.106322)\n",
      "Testing 3688/4320\n",
      "1 6 5 log2 gini False 500 112: Weighted 0.808504 (0.076483)\n",
      "1 6 5 log2 gini False 500 112: Macro 0.704126 (0.106322)\n",
      "Testing 3689/4320\n",
      "1 6 5 log2 entropy True 50 112: Weighted 0.812467 (0.070626)\n",
      "1 6 5 log2 entropy True 50 112: Macro 0.712802 (0.093116)\n",
      "Testing 3690/4320\n",
      "1 6 5 log2 entropy True 100 112: Weighted 0.808837 (0.067164)\n",
      "1 6 5 log2 entropy True 100 112: Macro 0.703868 (0.087906)\n",
      "Testing 3691/4320\n",
      "1 6 5 log2 entropy True 200 112: Weighted 0.817200 (0.069329)\n",
      "1 6 5 log2 entropy True 200 112: Macro 0.716401 (0.092125)\n",
      "Testing 3692/4320\n",
      "1 6 5 log2 entropy True 500 112: Weighted 0.812273 (0.066532)\n",
      "1 6 5 log2 entropy True 500 112: Macro 0.708892 (0.086748)\n",
      "Testing 3693/4320\n",
      "1 6 5 log2 entropy False 50 112: Weighted 0.797095 (0.069135)\n",
      "1 6 5 log2 entropy False 50 112: Macro 0.692677 (0.085235)\n",
      "Testing 3694/4320\n",
      "1 6 5 log2 entropy False 100 112: Weighted 0.793021 (0.074867)\n",
      "1 6 5 log2 entropy False 100 112: Macro 0.683688 (0.098259)\n",
      "Testing 3695/4320\n",
      "1 6 5 log2 entropy False 200 112: Weighted 0.789541 (0.076051)\n",
      "1 6 5 log2 entropy False 200 112: Macro 0.678769 (0.099708)\n",
      "Testing 3696/4320\n",
      "1 6 5 log2 entropy False 500 112: Weighted 0.789541 (0.076051)\n",
      "1 6 5 log2 entropy False 500 112: Macro 0.678769 (0.099708)\n",
      "Testing 3697/4320\n",
      "1 6 5 sqrt gini True 50 112: Weighted 0.804277 (0.068943)\n",
      "1 6 5 sqrt gini True 50 112: Macro 0.697667 (0.087525)\n",
      "Testing 3698/4320\n",
      "1 6 5 sqrt gini True 100 112: Weighted 0.800797 (0.070783)\n",
      "1 6 5 sqrt gini True 100 112: Macro 0.692748 (0.089916)\n",
      "Testing 3699/4320\n",
      "1 6 5 sqrt gini True 200 112: Weighted 0.813266 (0.066477)\n",
      "1 6 5 sqrt gini True 200 112: Macro 0.713022 (0.087980)\n",
      "Testing 3700/4320\n",
      "1 6 5 sqrt gini True 500 112: Weighted 0.803722 (0.061157)\n",
      "1 6 5 sqrt gini True 500 112: Macro 0.695738 (0.076918)\n",
      "Testing 3701/4320\n",
      "1 6 5 sqrt gini False 50 112: Weighted 0.805096 (0.077695)\n",
      "1 6 5 sqrt gini False 50 112: Macro 0.699133 (0.107709)\n",
      "Testing 3702/4320\n",
      "1 6 5 sqrt gini False 100 112: Weighted 0.805096 (0.077695)\n",
      "1 6 5 sqrt gini False 100 112: Macro 0.699133 (0.107709)\n",
      "Testing 3703/4320\n",
      "1 6 5 sqrt gini False 200 112: Weighted 0.808504 (0.076483)\n",
      "1 6 5 sqrt gini False 200 112: Macro 0.704126 (0.106322)\n",
      "Testing 3704/4320\n",
      "1 6 5 sqrt gini False 500 112: Weighted 0.808504 (0.076483)\n",
      "1 6 5 sqrt gini False 500 112: Macro 0.704126 (0.106322)\n",
      "Testing 3705/4320\n",
      "1 6 5 sqrt entropy True 50 112: Weighted 0.812467 (0.070626)\n",
      "1 6 5 sqrt entropy True 50 112: Macro 0.712802 (0.093116)\n",
      "Testing 3706/4320\n",
      "1 6 5 sqrt entropy True 100 112: Weighted 0.808837 (0.067164)\n",
      "1 6 5 sqrt entropy True 100 112: Macro 0.703868 (0.087906)\n",
      "Testing 3707/4320\n",
      "1 6 5 sqrt entropy True 200 112: Weighted 0.817200 (0.069329)\n",
      "1 6 5 sqrt entropy True 200 112: Macro 0.716401 (0.092125)\n",
      "Testing 3708/4320\n",
      "1 6 5 sqrt entropy True 500 112: Weighted 0.812273 (0.066532)\n",
      "1 6 5 sqrt entropy True 500 112: Macro 0.708892 (0.086748)\n",
      "Testing 3709/4320\n",
      "1 6 5 sqrt entropy False 50 112: Weighted 0.797095 (0.069135)\n",
      "1 6 5 sqrt entropy False 50 112: Macro 0.692677 (0.085235)\n",
      "Testing 3710/4320\n",
      "1 6 5 sqrt entropy False 100 112: Weighted 0.793021 (0.074867)\n",
      "1 6 5 sqrt entropy False 100 112: Macro 0.683688 (0.098259)\n",
      "Testing 3711/4320\n",
      "1 6 5 sqrt entropy False 200 112: Weighted 0.789541 (0.076051)\n",
      "1 6 5 sqrt entropy False 200 112: Macro 0.678769 (0.099708)\n",
      "Testing 3712/4320\n",
      "1 6 5 sqrt entropy False 500 112: Weighted 0.789541 (0.076051)\n",
      "1 6 5 sqrt entropy False 500 112: Macro 0.678769 (0.099708)\n",
      "Testing 3713/4320\n",
      "1 6 8 log2 gini True 50 112: Weighted 0.809167 (0.068329)\n",
      "1 6 8 log2 gini True 50 112: Macro 0.700139 (0.092429)\n",
      "Testing 3714/4320\n",
      "1 6 8 log2 gini True 100 112: Weighted 0.811624 (0.058938)\n",
      "1 6 8 log2 gini True 100 112: Macro 0.708324 (0.073485)\n",
      "Testing 3715/4320\n",
      "1 6 8 log2 gini True 200 112: Weighted 0.816047 (0.065059)\n",
      "1 6 8 log2 gini True 200 112: Macro 0.715285 (0.082895)\n",
      "Testing 3716/4320\n",
      "1 6 8 log2 gini True 500 112: Weighted 0.807729 (0.056302)\n",
      "1 6 8 log2 gini True 500 112: Macro 0.700817 (0.070492)\n",
      "Testing 3717/4320\n",
      "1 6 8 log2 gini False 50 112: Weighted 0.801628 (0.068900)\n",
      "1 6 8 log2 gini False 50 112: Macro 0.696052 (0.090954)\n",
      "Testing 3718/4320\n",
      "1 6 8 log2 gini False 100 112: Weighted 0.805158 (0.066749)\n",
      "1 6 8 log2 gini False 100 112: Macro 0.701177 (0.088353)\n",
      "Testing 3719/4320\n",
      "1 6 8 log2 gini False 200 112: Weighted 0.799083 (0.079689)\n",
      "1 6 8 log2 gini False 200 112: Macro 0.693715 (0.106576)\n",
      "Testing 3720/4320\n",
      "1 6 8 log2 gini False 500 112: Weighted 0.794155 (0.076103)\n",
      "1 6 8 log2 gini False 500 112: Macro 0.686207 (0.100280)\n",
      "Testing 3721/4320\n",
      "1 6 8 log2 entropy True 50 112: Weighted 0.813266 (0.066477)\n",
      "1 6 8 log2 entropy True 50 112: Macro 0.713022 (0.087980)\n",
      "Testing 3722/4320\n",
      "1 6 8 log2 entropy True 100 112: Weighted 0.811099 (0.061995)\n",
      "1 6 8 log2 entropy True 100 112: Macro 0.708503 (0.078021)\n",
      "Testing 3723/4320\n",
      "1 6 8 log2 entropy True 200 112: Weighted 0.819887 (0.059659)\n",
      "1 6 8 log2 entropy True 200 112: Macro 0.723724 (0.077980)\n",
      "Testing 3724/4320\n",
      "1 6 8 log2 entropy True 500 112: Weighted 0.806457 (0.052780)\n",
      "1 6 8 log2 entropy True 500 112: Macro 0.698048 (0.065906)\n",
      "Testing 3725/4320\n",
      "1 6 8 log2 entropy False 50 112: Weighted 0.795582 (0.065875)\n",
      "1 6 8 log2 entropy False 50 112: Macro 0.687950 (0.083909)\n",
      "Testing 3726/4320\n",
      "1 6 8 log2 entropy False 100 112: Weighted 0.795800 (0.066806)\n",
      "1 6 8 log2 entropy False 100 112: Macro 0.689125 (0.086133)\n",
      "Testing 3727/4320\n",
      "1 6 8 log2 entropy False 200 112: Weighted 0.799396 (0.064706)\n",
      "1 6 8 log2 entropy False 200 112: Macro 0.694509 (0.083840)\n",
      "Testing 3728/4320\n",
      "1 6 8 log2 entropy False 500 112: Weighted 0.799396 (0.064706)\n",
      "1 6 8 log2 entropy False 500 112: Macro 0.694509 (0.083840)\n",
      "Testing 3729/4320\n",
      "1 6 8 sqrt gini True 50 112: Weighted 0.809167 (0.068329)\n",
      "1 6 8 sqrt gini True 50 112: Macro 0.700139 (0.092429)\n",
      "Testing 3730/4320\n",
      "1 6 8 sqrt gini True 100 112: Weighted 0.811624 (0.058938)\n",
      "1 6 8 sqrt gini True 100 112: Macro 0.708324 (0.073485)\n",
      "Testing 3731/4320\n",
      "1 6 8 sqrt gini True 200 112: Weighted 0.816047 (0.065059)\n",
      "1 6 8 sqrt gini True 200 112: Macro 0.715285 (0.082895)\n",
      "Testing 3732/4320\n",
      "1 6 8 sqrt gini True 500 112: Weighted 0.807729 (0.056302)\n",
      "1 6 8 sqrt gini True 500 112: Macro 0.700817 (0.070492)\n",
      "Testing 3733/4320\n",
      "1 6 8 sqrt gini False 50 112: Weighted 0.801628 (0.068900)\n",
      "1 6 8 sqrt gini False 50 112: Macro 0.696052 (0.090954)\n",
      "Testing 3734/4320\n",
      "1 6 8 sqrt gini False 100 112: Weighted 0.805158 (0.066749)\n",
      "1 6 8 sqrt gini False 100 112: Macro 0.701177 (0.088353)\n",
      "Testing 3735/4320\n",
      "1 6 8 sqrt gini False 200 112: Weighted 0.799083 (0.079689)\n",
      "1 6 8 sqrt gini False 200 112: Macro 0.693715 (0.106576)\n",
      "Testing 3736/4320\n",
      "1 6 8 sqrt gini False 500 112: Weighted 0.794155 (0.076103)\n",
      "1 6 8 sqrt gini False 500 112: Macro 0.686207 (0.100280)\n",
      "Testing 3737/4320\n",
      "1 6 8 sqrt entropy True 50 112: Weighted 0.813266 (0.066477)\n",
      "1 6 8 sqrt entropy True 50 112: Macro 0.713022 (0.087980)\n",
      "Testing 3738/4320\n",
      "1 6 8 sqrt entropy True 100 112: Weighted 0.811099 (0.061995)\n",
      "1 6 8 sqrt entropy True 100 112: Macro 0.708503 (0.078021)\n",
      "Testing 3739/4320\n",
      "1 6 8 sqrt entropy True 200 112: Weighted 0.819887 (0.059659)\n",
      "1 6 8 sqrt entropy True 200 112: Macro 0.723724 (0.077980)\n",
      "Testing 3740/4320\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 6 8 sqrt entropy True 500 112: Weighted 0.806457 (0.052780)\n",
      "1 6 8 sqrt entropy True 500 112: Macro 0.698048 (0.065906)\n",
      "Testing 3741/4320\n",
      "1 6 8 sqrt entropy False 50 112: Weighted 0.795582 (0.065875)\n",
      "1 6 8 sqrt entropy False 50 112: Macro 0.687950 (0.083909)\n",
      "Testing 3742/4320\n",
      "1 6 8 sqrt entropy False 100 112: Weighted 0.795800 (0.066806)\n",
      "1 6 8 sqrt entropy False 100 112: Macro 0.689125 (0.086133)\n",
      "Testing 3743/4320\n",
      "1 6 8 sqrt entropy False 200 112: Weighted 0.799396 (0.064706)\n",
      "1 6 8 sqrt entropy False 200 112: Macro 0.694509 (0.083840)\n",
      "Testing 3744/4320\n",
      "1 6 8 sqrt entropy False 500 112: Weighted 0.799396 (0.064706)\n",
      "1 6 8 sqrt entropy False 500 112: Macro 0.694509 (0.083840)\n",
      "Testing 3745/4320\n",
      "3 2 3 log2 gini True 50 112: Weighted 0.813941 (0.055478)\n",
      "3 2 3 log2 gini True 50 112: Macro 0.709900 (0.075733)\n",
      "Testing 3746/4320\n",
      "3 2 3 log2 gini True 100 112: Weighted 0.809361 (0.051013)\n",
      "3 2 3 log2 gini True 100 112: Macro 0.700342 (0.068847)\n",
      "Testing 3747/4320\n",
      "3 2 3 log2 gini True 200 112: Weighted 0.809935 (0.060810)\n",
      "3 2 3 log2 gini True 200 112: Macro 0.704820 (0.082311)\n",
      "Testing 3748/4320\n",
      "3 2 3 log2 gini True 500 112: Weighted 0.813941 (0.055478)\n",
      "3 2 3 log2 gini True 500 112: Macro 0.709900 (0.075733)\n",
      "Testing 3749/4320\n",
      "3 2 3 log2 gini False 50 112: Weighted 0.793563 (0.090270)\n",
      "3 2 3 log2 gini False 50 112: Macro 0.688455 (0.112395)\n",
      "Testing 3750/4320\n",
      "3 2 3 log2 gini False 100 112: Weighted 0.787362 (0.100409)\n",
      "3 2 3 log2 gini False 100 112: Macro 0.681315 (0.123855)\n",
      "Testing 3751/4320\n",
      "3 2 3 log2 gini False 200 112: Weighted 0.793563 (0.090270)\n",
      "3 2 3 log2 gini False 200 112: Macro 0.688455 (0.112395)\n",
      "Testing 3752/4320\n",
      "3 2 3 log2 gini False 500 112: Weighted 0.793563 (0.090270)\n",
      "3 2 3 log2 gini False 500 112: Macro 0.688455 (0.112395)\n",
      "Testing 3753/4320\n",
      "3 2 3 log2 entropy True 50 112: Weighted 0.813938 (0.055482)\n",
      "3 2 3 log2 entropy True 50 112: Macro 0.713290 (0.071608)\n",
      "Testing 3754/4320\n",
      "3 2 3 log2 entropy True 100 112: Weighted 0.822625 (0.055592)\n",
      "3 2 3 log2 entropy True 100 112: Macro 0.725521 (0.072275)\n",
      "Testing 3755/4320\n",
      "3 2 3 log2 entropy True 200 112: Weighted 0.813938 (0.055482)\n",
      "3 2 3 log2 entropy True 200 112: Macro 0.713290 (0.071608)\n",
      "Testing 3756/4320\n",
      "3 2 3 log2 entropy True 500 112: Weighted 0.818669 (0.049700)\n",
      "3 2 3 log2 entropy True 500 112: Macro 0.716892 (0.067511)\n",
      "Testing 3757/4320\n",
      "3 2 3 log2 entropy False 50 112: Weighted 0.781816 (0.098017)\n",
      "3 2 3 log2 entropy False 50 112: Macro 0.673700 (0.117866)\n",
      "Testing 3758/4320\n",
      "3 2 3 log2 entropy False 100 112: Weighted 0.782434 (0.096994)\n",
      "3 2 3 log2 entropy False 100 112: Macro 0.673806 (0.117692)\n",
      "Testing 3759/4320\n",
      "3 2 3 log2 entropy False 200 112: Weighted 0.781816 (0.098017)\n",
      "3 2 3 log2 entropy False 200 112: Macro 0.673700 (0.117866)\n",
      "Testing 3760/4320\n",
      "3 2 3 log2 entropy False 500 112: Weighted 0.781816 (0.098017)\n",
      "3 2 3 log2 entropy False 500 112: Macro 0.673700 (0.117866)\n",
      "Testing 3761/4320\n",
      "3 2 3 sqrt gini True 50 112: Weighted 0.813941 (0.055478)\n",
      "3 2 3 sqrt gini True 50 112: Macro 0.709900 (0.075733)\n",
      "Testing 3762/4320\n",
      "3 2 3 sqrt gini True 100 112: Weighted 0.809361 (0.051013)\n",
      "3 2 3 sqrt gini True 100 112: Macro 0.700342 (0.068847)\n",
      "Testing 3763/4320\n",
      "3 2 3 sqrt gini True 200 112: Weighted 0.809935 (0.060810)\n",
      "3 2 3 sqrt gini True 200 112: Macro 0.704820 (0.082311)\n",
      "Testing 3764/4320\n",
      "3 2 3 sqrt gini True 500 112: Weighted 0.813941 (0.055478)\n",
      "3 2 3 sqrt gini True 500 112: Macro 0.709900 (0.075733)\n",
      "Testing 3765/4320\n",
      "3 2 3 sqrt gini False 50 112: Weighted 0.793563 (0.090270)\n",
      "3 2 3 sqrt gini False 50 112: Macro 0.688455 (0.112395)\n",
      "Testing 3766/4320\n",
      "3 2 3 sqrt gini False 100 112: Weighted 0.787362 (0.100409)\n",
      "3 2 3 sqrt gini False 100 112: Macro 0.681315 (0.123855)\n",
      "Testing 3767/4320\n",
      "3 2 3 sqrt gini False 200 112: Weighted 0.793563 (0.090270)\n",
      "3 2 3 sqrt gini False 200 112: Macro 0.688455 (0.112395)\n",
      "Testing 3768/4320\n",
      "3 2 3 sqrt gini False 500 112: Weighted 0.793563 (0.090270)\n",
      "3 2 3 sqrt gini False 500 112: Macro 0.688455 (0.112395)\n",
      "Testing 3769/4320\n",
      "3 2 3 sqrt entropy True 50 112: Weighted 0.813938 (0.055482)\n",
      "3 2 3 sqrt entropy True 50 112: Macro 0.713290 (0.071608)\n",
      "Testing 3770/4320\n",
      "3 2 3 sqrt entropy True 100 112: Weighted 0.822625 (0.055592)\n",
      "3 2 3 sqrt entropy True 100 112: Macro 0.725521 (0.072275)\n",
      "Testing 3771/4320\n",
      "3 2 3 sqrt entropy True 200 112: Weighted 0.813938 (0.055482)\n",
      "3 2 3 sqrt entropy True 200 112: Macro 0.713290 (0.071608)\n",
      "Testing 3772/4320\n",
      "3 2 3 sqrt entropy True 500 112: Weighted 0.818669 (0.049700)\n",
      "3 2 3 sqrt entropy True 500 112: Macro 0.716892 (0.067511)\n",
      "Testing 3773/4320\n",
      "3 2 3 sqrt entropy False 50 112: Weighted 0.781816 (0.098017)\n",
      "3 2 3 sqrt entropy False 50 112: Macro 0.673700 (0.117866)\n",
      "Testing 3774/4320\n",
      "3 2 3 sqrt entropy False 100 112: Weighted 0.782434 (0.096994)\n",
      "3 2 3 sqrt entropy False 100 112: Macro 0.673806 (0.117692)\n",
      "Testing 3775/4320\n",
      "3 2 3 sqrt entropy False 200 112: Weighted 0.781816 (0.098017)\n",
      "3 2 3 sqrt entropy False 200 112: Macro 0.673700 (0.117866)\n",
      "Testing 3776/4320\n",
      "3 2 3 sqrt entropy False 500 112: Weighted 0.781816 (0.098017)\n",
      "3 2 3 sqrt entropy False 500 112: Macro 0.673700 (0.117866)\n",
      "Testing 3777/4320\n",
      "3 2 5 log2 gini True 50 112: Weighted 0.808982 (0.067239)\n",
      "3 2 5 log2 gini True 50 112: Macro 0.701235 (0.086278)\n",
      "Testing 3778/4320\n",
      "3 2 5 log2 gini True 100 112: Weighted 0.809673 (0.062686)\n",
      "3 2 5 log2 gini True 100 112: Macro 0.701491 (0.081072)\n",
      "Testing 3779/4320\n",
      "3 2 5 log2 gini True 200 112: Weighted 0.813188 (0.061148)\n",
      "3 2 5 log2 gini True 200 112: Macro 0.706448 (0.078733)\n",
      "Testing 3780/4320\n",
      "3 2 5 log2 gini True 500 112: Weighted 0.809673 (0.062686)\n",
      "3 2 5 log2 gini True 500 112: Macro 0.701491 (0.081072)\n",
      "Testing 3781/4320\n",
      "3 2 5 log2 gini False 50 112: Weighted 0.813237 (0.075536)\n",
      "3 2 5 log2 gini False 50 112: Macro 0.707725 (0.105751)\n",
      "Testing 3782/4320\n",
      "3 2 5 log2 gini False 100 112: Weighted 0.807711 (0.076726)\n",
      "3 2 5 log2 gini False 100 112: Macro 0.704755 (0.106196)\n",
      "Testing 3783/4320\n",
      "3 2 5 log2 gini False 200 112: Weighted 0.808504 (0.076483)\n",
      "3 2 5 log2 gini False 200 112: Macro 0.704126 (0.106322)\n",
      "Testing 3784/4320\n",
      "3 2 5 log2 gini False 500 112: Weighted 0.813237 (0.075536)\n",
      "3 2 5 log2 gini False 500 112: Macro 0.707725 (0.105751)\n",
      "Testing 3785/4320\n",
      "3 2 5 log2 entropy True 50 112: Weighted 0.805466 (0.068425)\n",
      "3 2 5 log2 entropy True 50 112: Macro 0.696277 (0.088124)\n",
      "Testing 3786/4320\n",
      "3 2 5 log2 entropy True 100 112: Weighted 0.800704 (0.066202)\n",
      "3 2 5 log2 entropy True 100 112: Macro 0.689134 (0.084469)\n",
      "Testing 3787/4320\n",
      "3 2 5 log2 entropy True 200 112: Weighted 0.817971 (0.064052)\n",
      "3 2 5 log2 entropy True 200 112: Macro 0.716589 (0.086105)\n",
      "Testing 3788/4320\n",
      "3 2 5 log2 entropy True 500 112: Weighted 0.817466 (0.066908)\n",
      "3 2 5 log2 entropy True 500 112: Macro 0.716043 (0.088972)\n",
      "Testing 3789/4320\n",
      "3 2 5 log2 entropy False 50 112: Weighted 0.799232 (0.059254)\n",
      "3 2 5 log2 entropy False 50 112: Macro 0.689633 (0.075593)\n",
      "Testing 3790/4320\n",
      "3 2 5 log2 entropy False 100 112: Weighted 0.799789 (0.070916)\n",
      "3 2 5 log2 entropy False 100 112: Macro 0.687770 (0.096874)\n",
      "Testing 3791/4320\n",
      "3 2 5 log2 entropy False 200 112: Weighted 0.792648 (0.072816)\n",
      "3 2 5 log2 entropy False 200 112: Macro 0.677864 (0.099540)\n",
      "Testing 3792/4320\n",
      "3 2 5 log2 entropy False 500 112: Weighted 0.794210 (0.074570)\n",
      "3 2 5 log2 entropy False 500 112: Macro 0.682298 (0.098596)\n",
      "Testing 3793/4320\n",
      "3 2 5 sqrt gini True 50 112: Weighted 0.808982 (0.067239)\n",
      "3 2 5 sqrt gini True 50 112: Macro 0.701235 (0.086278)\n",
      "Testing 3794/4320\n",
      "3 2 5 sqrt gini True 100 112: Weighted 0.809673 (0.062686)\n",
      "3 2 5 sqrt gini True 100 112: Macro 0.701491 (0.081072)\n",
      "Testing 3795/4320\n",
      "3 2 5 sqrt gini True 200 112: Weighted 0.813188 (0.061148)\n",
      "3 2 5 sqrt gini True 200 112: Macro 0.706448 (0.078733)\n",
      "Testing 3796/4320\n",
      "3 2 5 sqrt gini True 500 112: Weighted 0.809673 (0.062686)\n",
      "3 2 5 sqrt gini True 500 112: Macro 0.701491 (0.081072)\n",
      "Testing 3797/4320\n",
      "3 2 5 sqrt gini False 50 112: Weighted 0.813237 (0.075536)\n",
      "3 2 5 sqrt gini False 50 112: Macro 0.707725 (0.105751)\n",
      "Testing 3798/4320\n",
      "3 2 5 sqrt gini False 100 112: Weighted 0.807711 (0.076726)\n",
      "3 2 5 sqrt gini False 100 112: Macro 0.704755 (0.106196)\n",
      "Testing 3799/4320\n",
      "3 2 5 sqrt gini False 200 112: Weighted 0.808504 (0.076483)\n",
      "3 2 5 sqrt gini False 200 112: Macro 0.704126 (0.106322)\n",
      "Testing 3800/4320\n",
      "3 2 5 sqrt gini False 500 112: Weighted 0.813237 (0.075536)\n",
      "3 2 5 sqrt gini False 500 112: Macro 0.707725 (0.105751)\n",
      "Testing 3801/4320\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 2 5 sqrt entropy True 50 112: Weighted 0.805466 (0.068425)\n",
      "3 2 5 sqrt entropy True 50 112: Macro 0.696277 (0.088124)\n",
      "Testing 3802/4320\n",
      "3 2 5 sqrt entropy True 100 112: Weighted 0.800704 (0.066202)\n",
      "3 2 5 sqrt entropy True 100 112: Macro 0.689134 (0.084469)\n",
      "Testing 3803/4320\n",
      "3 2 5 sqrt entropy True 200 112: Weighted 0.817971 (0.064052)\n",
      "3 2 5 sqrt entropy True 200 112: Macro 0.716589 (0.086105)\n",
      "Testing 3804/4320\n",
      "3 2 5 sqrt entropy True 500 112: Weighted 0.817466 (0.066908)\n",
      "3 2 5 sqrt entropy True 500 112: Macro 0.716043 (0.088972)\n",
      "Testing 3805/4320\n",
      "3 2 5 sqrt entropy False 50 112: Weighted 0.799232 (0.059254)\n",
      "3 2 5 sqrt entropy False 50 112: Macro 0.689633 (0.075593)\n",
      "Testing 3806/4320\n",
      "3 2 5 sqrt entropy False 100 112: Weighted 0.799789 (0.070916)\n",
      "3 2 5 sqrt entropy False 100 112: Macro 0.687770 (0.096874)\n",
      "Testing 3807/4320\n",
      "3 2 5 sqrt entropy False 200 112: Weighted 0.792648 (0.072816)\n",
      "3 2 5 sqrt entropy False 200 112: Macro 0.677864 (0.099540)\n",
      "Testing 3808/4320\n",
      "3 2 5 sqrt entropy False 500 112: Weighted 0.794210 (0.074570)\n",
      "3 2 5 sqrt entropy False 500 112: Macro 0.682298 (0.098596)\n",
      "Testing 3809/4320\n",
      "3 2 8 log2 gini True 50 112: Weighted 0.812670 (0.058207)\n",
      "3 2 8 log2 gini True 50 112: Macro 0.706626 (0.074574)\n",
      "Testing 3810/4320\n",
      "3 2 8 log2 gini True 100 112: Weighted 0.817093 (0.064326)\n",
      "3 2 8 log2 gini True 100 112: Macro 0.713587 (0.084003)\n",
      "Testing 3811/4320\n",
      "3 2 8 log2 gini True 200 112: Weighted 0.813440 (0.067066)\n",
      "3 2 8 log2 gini True 200 112: Macro 0.708481 (0.087845)\n",
      "Testing 3812/4320\n",
      "3 2 8 log2 gini True 500 112: Weighted 0.812331 (0.062843)\n",
      "3 2 8 log2 gini True 500 112: Macro 0.706444 (0.081688)\n",
      "Testing 3813/4320\n",
      "3 2 8 log2 gini False 50 112: Weighted 0.804934 (0.072903)\n",
      "3 2 8 log2 gini False 50 112: Macro 0.698802 (0.100222)\n",
      "Testing 3814/4320\n",
      "3 2 8 log2 gini False 100 112: Weighted 0.808544 (0.069922)\n",
      "3 2 8 log2 gini False 100 112: Macro 0.703862 (0.096699)\n",
      "Testing 3815/4320\n",
      "3 2 8 log2 gini False 200 112: Weighted 0.808544 (0.069922)\n",
      "3 2 8 log2 gini False 200 112: Macro 0.703862 (0.096699)\n",
      "Testing 3816/4320\n",
      "3 2 8 log2 gini False 500 112: Weighted 0.807478 (0.071691)\n",
      "3 2 8 log2 gini False 500 112: Macro 0.701882 (0.098180)\n",
      "Testing 3817/4320\n",
      "3 2 8 log2 entropy True 50 112: Weighted 0.813086 (0.069160)\n",
      "3 2 8 log2 entropy True 50 112: Macro 0.708508 (0.090186)\n",
      "Testing 3818/4320\n",
      "3 2 8 log2 entropy True 100 112: Weighted 0.808663 (0.063229)\n",
      "3 2 8 log2 entropy True 100 112: Macro 0.701546 (0.081041)\n",
      "Testing 3819/4320\n",
      "3 2 8 log2 entropy True 200 112: Weighted 0.821875 (0.066813)\n",
      "3 2 8 log2 entropy True 200 112: Macro 0.723728 (0.090149)\n",
      "Testing 3820/4320\n",
      "3 2 8 log2 entropy True 500 112: Weighted 0.817093 (0.064326)\n",
      "3 2 8 log2 entropy True 500 112: Macro 0.713587 (0.084003)\n",
      "Testing 3821/4320\n",
      "3 2 8 log2 entropy False 50 112: Weighted 0.792705 (0.064415)\n",
      "3 2 8 log2 entropy False 50 112: Macro 0.678318 (0.084092)\n",
      "Testing 3822/4320\n",
      "3 2 8 log2 entropy False 100 112: Weighted 0.797466 (0.065768)\n",
      "3 2 8 log2 entropy False 100 112: Macro 0.686951 (0.087324)\n",
      "Testing 3823/4320\n",
      "3 2 8 log2 entropy False 200 112: Weighted 0.801119 (0.063891)\n",
      "3 2 8 log2 entropy False 200 112: Macro 0.692057 (0.084765)\n",
      "Testing 3824/4320\n",
      "3 2 8 log2 entropy False 500 112: Weighted 0.801119 (0.063891)\n",
      "3 2 8 log2 entropy False 500 112: Macro 0.692057 (0.084765)\n",
      "Testing 3825/4320\n",
      "3 2 8 sqrt gini True 50 112: Weighted 0.812670 (0.058207)\n",
      "3 2 8 sqrt gini True 50 112: Macro 0.706626 (0.074574)\n",
      "Testing 3826/4320\n",
      "3 2 8 sqrt gini True 100 112: Weighted 0.817093 (0.064326)\n",
      "3 2 8 sqrt gini True 100 112: Macro 0.713587 (0.084003)\n",
      "Testing 3827/4320\n",
      "3 2 8 sqrt gini True 200 112: Weighted 0.813440 (0.067066)\n",
      "3 2 8 sqrt gini True 200 112: Macro 0.708481 (0.087845)\n",
      "Testing 3828/4320\n",
      "3 2 8 sqrt gini True 500 112: Weighted 0.812331 (0.062843)\n",
      "3 2 8 sqrt gini True 500 112: Macro 0.706444 (0.081688)\n",
      "Testing 3829/4320\n",
      "3 2 8 sqrt gini False 50 112: Weighted 0.804934 (0.072903)\n",
      "3 2 8 sqrt gini False 50 112: Macro 0.698802 (0.100222)\n",
      "Testing 3830/4320\n",
      "3 2 8 sqrt gini False 100 112: Weighted 0.808544 (0.069922)\n",
      "3 2 8 sqrt gini False 100 112: Macro 0.703862 (0.096699)\n",
      "Testing 3831/4320\n",
      "3 2 8 sqrt gini False 200 112: Weighted 0.808544 (0.069922)\n",
      "3 2 8 sqrt gini False 200 112: Macro 0.703862 (0.096699)\n",
      "Testing 3832/4320\n",
      "3 2 8 sqrt gini False 500 112: Weighted 0.807478 (0.071691)\n",
      "3 2 8 sqrt gini False 500 112: Macro 0.701882 (0.098180)\n",
      "Testing 3833/4320\n",
      "3 2 8 sqrt entropy True 50 112: Weighted 0.813086 (0.069160)\n",
      "3 2 8 sqrt entropy True 50 112: Macro 0.708508 (0.090186)\n",
      "Testing 3834/4320\n",
      "3 2 8 sqrt entropy True 100 112: Weighted 0.808663 (0.063229)\n",
      "3 2 8 sqrt entropy True 100 112: Macro 0.701546 (0.081041)\n",
      "Testing 3835/4320\n",
      "3 2 8 sqrt entropy True 200 112: Weighted 0.821875 (0.066813)\n",
      "3 2 8 sqrt entropy True 200 112: Macro 0.723728 (0.090149)\n",
      "Testing 3836/4320\n",
      "3 2 8 sqrt entropy True 500 112: Weighted 0.817093 (0.064326)\n",
      "3 2 8 sqrt entropy True 500 112: Macro 0.713587 (0.084003)\n",
      "Testing 3837/4320\n",
      "3 2 8 sqrt entropy False 50 112: Weighted 0.792705 (0.064415)\n",
      "3 2 8 sqrt entropy False 50 112: Macro 0.678318 (0.084092)\n",
      "Testing 3838/4320\n",
      "3 2 8 sqrt entropy False 100 112: Weighted 0.797466 (0.065768)\n",
      "3 2 8 sqrt entropy False 100 112: Macro 0.686951 (0.087324)\n",
      "Testing 3839/4320\n",
      "3 2 8 sqrt entropy False 200 112: Weighted 0.801119 (0.063891)\n",
      "3 2 8 sqrt entropy False 200 112: Macro 0.692057 (0.084765)\n",
      "Testing 3840/4320\n",
      "3 2 8 sqrt entropy False 500 112: Weighted 0.801119 (0.063891)\n",
      "3 2 8 sqrt entropy False 500 112: Macro 0.692057 (0.084765)\n",
      "Testing 3841/4320\n",
      "3 4 3 log2 gini True 50 112: Weighted 0.813941 (0.055478)\n",
      "3 4 3 log2 gini True 50 112: Macro 0.709900 (0.075733)\n",
      "Testing 3842/4320\n",
      "3 4 3 log2 gini True 100 112: Weighted 0.809361 (0.051013)\n",
      "3 4 3 log2 gini True 100 112: Macro 0.700342 (0.068847)\n",
      "Testing 3843/4320\n",
      "3 4 3 log2 gini True 200 112: Weighted 0.809935 (0.060810)\n",
      "3 4 3 log2 gini True 200 112: Macro 0.704820 (0.082311)\n",
      "Testing 3844/4320\n",
      "3 4 3 log2 gini True 500 112: Weighted 0.813941 (0.055478)\n",
      "3 4 3 log2 gini True 500 112: Macro 0.709900 (0.075733)\n",
      "Testing 3845/4320\n",
      "3 4 3 log2 gini False 50 112: Weighted 0.793563 (0.090270)\n",
      "3 4 3 log2 gini False 50 112: Macro 0.688455 (0.112395)\n",
      "Testing 3846/4320\n",
      "3 4 3 log2 gini False 100 112: Weighted 0.787362 (0.100409)\n",
      "3 4 3 log2 gini False 100 112: Macro 0.681315 (0.123855)\n",
      "Testing 3847/4320\n",
      "3 4 3 log2 gini False 200 112: Weighted 0.793563 (0.090270)\n",
      "3 4 3 log2 gini False 200 112: Macro 0.688455 (0.112395)\n",
      "Testing 3848/4320\n",
      "3 4 3 log2 gini False 500 112: Weighted 0.793563 (0.090270)\n",
      "3 4 3 log2 gini False 500 112: Macro 0.688455 (0.112395)\n",
      "Testing 3849/4320\n",
      "3 4 3 log2 entropy True 50 112: Weighted 0.813938 (0.055482)\n",
      "3 4 3 log2 entropy True 50 112: Macro 0.713290 (0.071608)\n",
      "Testing 3850/4320\n",
      "3 4 3 log2 entropy True 100 112: Weighted 0.822625 (0.055592)\n",
      "3 4 3 log2 entropy True 100 112: Macro 0.725521 (0.072275)\n",
      "Testing 3851/4320\n",
      "3 4 3 log2 entropy True 200 112: Weighted 0.813938 (0.055482)\n",
      "3 4 3 log2 entropy True 200 112: Macro 0.713290 (0.071608)\n",
      "Testing 3852/4320\n",
      "3 4 3 log2 entropy True 500 112: Weighted 0.818669 (0.049700)\n",
      "3 4 3 log2 entropy True 500 112: Macro 0.716892 (0.067511)\n",
      "Testing 3853/4320\n",
      "3 4 3 log2 entropy False 50 112: Weighted 0.781816 (0.098017)\n",
      "3 4 3 log2 entropy False 50 112: Macro 0.673700 (0.117866)\n",
      "Testing 3854/4320\n",
      "3 4 3 log2 entropy False 100 112: Weighted 0.782434 (0.096994)\n",
      "3 4 3 log2 entropy False 100 112: Macro 0.673806 (0.117692)\n",
      "Testing 3855/4320\n",
      "3 4 3 log2 entropy False 200 112: Weighted 0.781816 (0.098017)\n",
      "3 4 3 log2 entropy False 200 112: Macro 0.673700 (0.117866)\n",
      "Testing 3856/4320\n",
      "3 4 3 log2 entropy False 500 112: Weighted 0.781816 (0.098017)\n",
      "3 4 3 log2 entropy False 500 112: Macro 0.673700 (0.117866)\n",
      "Testing 3857/4320\n",
      "3 4 3 sqrt gini True 50 112: Weighted 0.813941 (0.055478)\n",
      "3 4 3 sqrt gini True 50 112: Macro 0.709900 (0.075733)\n",
      "Testing 3858/4320\n",
      "3 4 3 sqrt gini True 100 112: Weighted 0.809361 (0.051013)\n",
      "3 4 3 sqrt gini True 100 112: Macro 0.700342 (0.068847)\n",
      "Testing 3859/4320\n",
      "3 4 3 sqrt gini True 200 112: Weighted 0.809935 (0.060810)\n",
      "3 4 3 sqrt gini True 200 112: Macro 0.704820 (0.082311)\n",
      "Testing 3860/4320\n",
      "3 4 3 sqrt gini True 500 112: Weighted 0.813941 (0.055478)\n",
      "3 4 3 sqrt gini True 500 112: Macro 0.709900 (0.075733)\n",
      "Testing 3861/4320\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 4 3 sqrt gini False 50 112: Weighted 0.793563 (0.090270)\n",
      "3 4 3 sqrt gini False 50 112: Macro 0.688455 (0.112395)\n",
      "Testing 3862/4320\n",
      "3 4 3 sqrt gini False 100 112: Weighted 0.787362 (0.100409)\n",
      "3 4 3 sqrt gini False 100 112: Macro 0.681315 (0.123855)\n",
      "Testing 3863/4320\n",
      "3 4 3 sqrt gini False 200 112: Weighted 0.793563 (0.090270)\n",
      "3 4 3 sqrt gini False 200 112: Macro 0.688455 (0.112395)\n",
      "Testing 3864/4320\n",
      "3 4 3 sqrt gini False 500 112: Weighted 0.793563 (0.090270)\n",
      "3 4 3 sqrt gini False 500 112: Macro 0.688455 (0.112395)\n",
      "Testing 3865/4320\n",
      "3 4 3 sqrt entropy True 50 112: Weighted 0.813938 (0.055482)\n",
      "3 4 3 sqrt entropy True 50 112: Macro 0.713290 (0.071608)\n",
      "Testing 3866/4320\n",
      "3 4 3 sqrt entropy True 100 112: Weighted 0.822625 (0.055592)\n",
      "3 4 3 sqrt entropy True 100 112: Macro 0.725521 (0.072275)\n",
      "Testing 3867/4320\n",
      "3 4 3 sqrt entropy True 200 112: Weighted 0.813938 (0.055482)\n",
      "3 4 3 sqrt entropy True 200 112: Macro 0.713290 (0.071608)\n",
      "Testing 3868/4320\n",
      "3 4 3 sqrt entropy True 500 112: Weighted 0.818669 (0.049700)\n",
      "3 4 3 sqrt entropy True 500 112: Macro 0.716892 (0.067511)\n",
      "Testing 3869/4320\n",
      "3 4 3 sqrt entropy False 50 112: Weighted 0.781816 (0.098017)\n",
      "3 4 3 sqrt entropy False 50 112: Macro 0.673700 (0.117866)\n",
      "Testing 3870/4320\n",
      "3 4 3 sqrt entropy False 100 112: Weighted 0.782434 (0.096994)\n",
      "3 4 3 sqrt entropy False 100 112: Macro 0.673806 (0.117692)\n",
      "Testing 3871/4320\n",
      "3 4 3 sqrt entropy False 200 112: Weighted 0.781816 (0.098017)\n",
      "3 4 3 sqrt entropy False 200 112: Macro 0.673700 (0.117866)\n",
      "Testing 3872/4320\n",
      "3 4 3 sqrt entropy False 500 112: Weighted 0.781816 (0.098017)\n",
      "3 4 3 sqrt entropy False 500 112: Macro 0.673700 (0.117866)\n",
      "Testing 3873/4320\n",
      "3 4 5 log2 gini True 50 112: Weighted 0.808982 (0.067239)\n",
      "3 4 5 log2 gini True 50 112: Macro 0.701235 (0.086278)\n",
      "Testing 3874/4320\n",
      "3 4 5 log2 gini True 100 112: Weighted 0.809673 (0.062686)\n",
      "3 4 5 log2 gini True 100 112: Macro 0.701491 (0.081072)\n",
      "Testing 3875/4320\n",
      "3 4 5 log2 gini True 200 112: Weighted 0.813188 (0.061148)\n",
      "3 4 5 log2 gini True 200 112: Macro 0.706448 (0.078733)\n",
      "Testing 3876/4320\n",
      "3 4 5 log2 gini True 500 112: Weighted 0.809673 (0.062686)\n",
      "3 4 5 log2 gini True 500 112: Macro 0.701491 (0.081072)\n",
      "Testing 3877/4320\n",
      "3 4 5 log2 gini False 50 112: Weighted 0.813237 (0.075536)\n",
      "3 4 5 log2 gini False 50 112: Macro 0.707725 (0.105751)\n",
      "Testing 3878/4320\n",
      "3 4 5 log2 gini False 100 112: Weighted 0.807711 (0.076726)\n",
      "3 4 5 log2 gini False 100 112: Macro 0.704755 (0.106196)\n",
      "Testing 3879/4320\n",
      "3 4 5 log2 gini False 200 112: Weighted 0.808504 (0.076483)\n",
      "3 4 5 log2 gini False 200 112: Macro 0.704126 (0.106322)\n",
      "Testing 3880/4320\n",
      "3 4 5 log2 gini False 500 112: Weighted 0.813237 (0.075536)\n",
      "3 4 5 log2 gini False 500 112: Macro 0.707725 (0.105751)\n",
      "Testing 3881/4320\n",
      "3 4 5 log2 entropy True 50 112: Weighted 0.805466 (0.068425)\n",
      "3 4 5 log2 entropy True 50 112: Macro 0.696277 (0.088124)\n",
      "Testing 3882/4320\n",
      "3 4 5 log2 entropy True 100 112: Weighted 0.800704 (0.066202)\n",
      "3 4 5 log2 entropy True 100 112: Macro 0.689134 (0.084469)\n",
      "Testing 3883/4320\n",
      "3 4 5 log2 entropy True 200 112: Weighted 0.817971 (0.064052)\n",
      "3 4 5 log2 entropy True 200 112: Macro 0.716589 (0.086105)\n",
      "Testing 3884/4320\n",
      "3 4 5 log2 entropy True 500 112: Weighted 0.817466 (0.066908)\n",
      "3 4 5 log2 entropy True 500 112: Macro 0.716043 (0.088972)\n",
      "Testing 3885/4320\n",
      "3 4 5 log2 entropy False 50 112: Weighted 0.799232 (0.059254)\n",
      "3 4 5 log2 entropy False 50 112: Macro 0.689633 (0.075593)\n",
      "Testing 3886/4320\n",
      "3 4 5 log2 entropy False 100 112: Weighted 0.799789 (0.070916)\n",
      "3 4 5 log2 entropy False 100 112: Macro 0.687770 (0.096874)\n",
      "Testing 3887/4320\n",
      "3 4 5 log2 entropy False 200 112: Weighted 0.792648 (0.072816)\n",
      "3 4 5 log2 entropy False 200 112: Macro 0.677864 (0.099540)\n",
      "Testing 3888/4320\n",
      "3 4 5 log2 entropy False 500 112: Weighted 0.794210 (0.074570)\n",
      "3 4 5 log2 entropy False 500 112: Macro 0.682298 (0.098596)\n",
      "Testing 3889/4320\n",
      "3 4 5 sqrt gini True 50 112: Weighted 0.808982 (0.067239)\n",
      "3 4 5 sqrt gini True 50 112: Macro 0.701235 (0.086278)\n",
      "Testing 3890/4320\n",
      "3 4 5 sqrt gini True 100 112: Weighted 0.809673 (0.062686)\n",
      "3 4 5 sqrt gini True 100 112: Macro 0.701491 (0.081072)\n",
      "Testing 3891/4320\n",
      "3 4 5 sqrt gini True 200 112: Weighted 0.813188 (0.061148)\n",
      "3 4 5 sqrt gini True 200 112: Macro 0.706448 (0.078733)\n",
      "Testing 3892/4320\n",
      "3 4 5 sqrt gini True 500 112: Weighted 0.809673 (0.062686)\n",
      "3 4 5 sqrt gini True 500 112: Macro 0.701491 (0.081072)\n",
      "Testing 3893/4320\n",
      "3 4 5 sqrt gini False 50 112: Weighted 0.813237 (0.075536)\n",
      "3 4 5 sqrt gini False 50 112: Macro 0.707725 (0.105751)\n",
      "Testing 3894/4320\n",
      "3 4 5 sqrt gini False 100 112: Weighted 0.807711 (0.076726)\n",
      "3 4 5 sqrt gini False 100 112: Macro 0.704755 (0.106196)\n",
      "Testing 3895/4320\n",
      "3 4 5 sqrt gini False 200 112: Weighted 0.808504 (0.076483)\n",
      "3 4 5 sqrt gini False 200 112: Macro 0.704126 (0.106322)\n",
      "Testing 3896/4320\n",
      "3 4 5 sqrt gini False 500 112: Weighted 0.813237 (0.075536)\n",
      "3 4 5 sqrt gini False 500 112: Macro 0.707725 (0.105751)\n",
      "Testing 3897/4320\n",
      "3 4 5 sqrt entropy True 50 112: Weighted 0.805466 (0.068425)\n",
      "3 4 5 sqrt entropy True 50 112: Macro 0.696277 (0.088124)\n",
      "Testing 3898/4320\n",
      "3 4 5 sqrt entropy True 100 112: Weighted 0.800704 (0.066202)\n",
      "3 4 5 sqrt entropy True 100 112: Macro 0.689134 (0.084469)\n",
      "Testing 3899/4320\n",
      "3 4 5 sqrt entropy True 200 112: Weighted 0.817971 (0.064052)\n",
      "3 4 5 sqrt entropy True 200 112: Macro 0.716589 (0.086105)\n",
      "Testing 3900/4320\n",
      "3 4 5 sqrt entropy True 500 112: Weighted 0.817466 (0.066908)\n",
      "3 4 5 sqrt entropy True 500 112: Macro 0.716043 (0.088972)\n",
      "Testing 3901/4320\n",
      "3 4 5 sqrt entropy False 50 112: Weighted 0.799232 (0.059254)\n",
      "3 4 5 sqrt entropy False 50 112: Macro 0.689633 (0.075593)\n",
      "Testing 3902/4320\n",
      "3 4 5 sqrt entropy False 100 112: Weighted 0.799789 (0.070916)\n",
      "3 4 5 sqrt entropy False 100 112: Macro 0.687770 (0.096874)\n",
      "Testing 3903/4320\n",
      "3 4 5 sqrt entropy False 200 112: Weighted 0.792648 (0.072816)\n",
      "3 4 5 sqrt entropy False 200 112: Macro 0.677864 (0.099540)\n",
      "Testing 3904/4320\n",
      "3 4 5 sqrt entropy False 500 112: Weighted 0.794210 (0.074570)\n",
      "3 4 5 sqrt entropy False 500 112: Macro 0.682298 (0.098596)\n",
      "Testing 3905/4320\n",
      "3 4 8 log2 gini True 50 112: Weighted 0.812670 (0.058207)\n",
      "3 4 8 log2 gini True 50 112: Macro 0.706626 (0.074574)\n",
      "Testing 3906/4320\n",
      "3 4 8 log2 gini True 100 112: Weighted 0.817093 (0.064326)\n",
      "3 4 8 log2 gini True 100 112: Macro 0.713587 (0.084003)\n",
      "Testing 3907/4320\n",
      "3 4 8 log2 gini True 200 112: Weighted 0.813440 (0.067066)\n",
      "3 4 8 log2 gini True 200 112: Macro 0.708481 (0.087845)\n",
      "Testing 3908/4320\n",
      "3 4 8 log2 gini True 500 112: Weighted 0.812331 (0.062843)\n",
      "3 4 8 log2 gini True 500 112: Macro 0.706444 (0.081688)\n",
      "Testing 3909/4320\n",
      "3 4 8 log2 gini False 50 112: Weighted 0.804934 (0.072903)\n",
      "3 4 8 log2 gini False 50 112: Macro 0.698802 (0.100222)\n",
      "Testing 3910/4320\n",
      "3 4 8 log2 gini False 100 112: Weighted 0.808544 (0.069922)\n",
      "3 4 8 log2 gini False 100 112: Macro 0.703862 (0.096699)\n",
      "Testing 3911/4320\n",
      "3 4 8 log2 gini False 200 112: Weighted 0.808544 (0.069922)\n",
      "3 4 8 log2 gini False 200 112: Macro 0.703862 (0.096699)\n",
      "Testing 3912/4320\n",
      "3 4 8 log2 gini False 500 112: Weighted 0.807478 (0.071691)\n",
      "3 4 8 log2 gini False 500 112: Macro 0.701882 (0.098180)\n",
      "Testing 3913/4320\n",
      "3 4 8 log2 entropy True 50 112: Weighted 0.813086 (0.069160)\n",
      "3 4 8 log2 entropy True 50 112: Macro 0.708508 (0.090186)\n",
      "Testing 3914/4320\n",
      "3 4 8 log2 entropy True 100 112: Weighted 0.808663 (0.063229)\n",
      "3 4 8 log2 entropy True 100 112: Macro 0.701546 (0.081041)\n",
      "Testing 3915/4320\n",
      "3 4 8 log2 entropy True 200 112: Weighted 0.821875 (0.066813)\n",
      "3 4 8 log2 entropy True 200 112: Macro 0.723728 (0.090149)\n",
      "Testing 3916/4320\n",
      "3 4 8 log2 entropy True 500 112: Weighted 0.817093 (0.064326)\n",
      "3 4 8 log2 entropy True 500 112: Macro 0.713587 (0.084003)\n",
      "Testing 3917/4320\n",
      "3 4 8 log2 entropy False 50 112: Weighted 0.792705 (0.064415)\n",
      "3 4 8 log2 entropy False 50 112: Macro 0.678318 (0.084092)\n",
      "Testing 3918/4320\n",
      "3 4 8 log2 entropy False 100 112: Weighted 0.797466 (0.065768)\n",
      "3 4 8 log2 entropy False 100 112: Macro 0.686951 (0.087324)\n",
      "Testing 3919/4320\n",
      "3 4 8 log2 entropy False 200 112: Weighted 0.801119 (0.063891)\n",
      "3 4 8 log2 entropy False 200 112: Macro 0.692057 (0.084765)\n",
      "Testing 3920/4320\n",
      "3 4 8 log2 entropy False 500 112: Weighted 0.801119 (0.063891)\n",
      "3 4 8 log2 entropy False 500 112: Macro 0.692057 (0.084765)\n",
      "Testing 3921/4320\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 4 8 sqrt gini True 50 112: Weighted 0.812670 (0.058207)\n",
      "3 4 8 sqrt gini True 50 112: Macro 0.706626 (0.074574)\n",
      "Testing 3922/4320\n",
      "3 4 8 sqrt gini True 100 112: Weighted 0.817093 (0.064326)\n",
      "3 4 8 sqrt gini True 100 112: Macro 0.713587 (0.084003)\n",
      "Testing 3923/4320\n",
      "3 4 8 sqrt gini True 200 112: Weighted 0.813440 (0.067066)\n",
      "3 4 8 sqrt gini True 200 112: Macro 0.708481 (0.087845)\n",
      "Testing 3924/4320\n",
      "3 4 8 sqrt gini True 500 112: Weighted 0.812331 (0.062843)\n",
      "3 4 8 sqrt gini True 500 112: Macro 0.706444 (0.081688)\n",
      "Testing 3925/4320\n",
      "3 4 8 sqrt gini False 50 112: Weighted 0.804934 (0.072903)\n",
      "3 4 8 sqrt gini False 50 112: Macro 0.698802 (0.100222)\n",
      "Testing 3926/4320\n",
      "3 4 8 sqrt gini False 100 112: Weighted 0.808544 (0.069922)\n",
      "3 4 8 sqrt gini False 100 112: Macro 0.703862 (0.096699)\n",
      "Testing 3927/4320\n",
      "3 4 8 sqrt gini False 200 112: Weighted 0.808544 (0.069922)\n",
      "3 4 8 sqrt gini False 200 112: Macro 0.703862 (0.096699)\n",
      "Testing 3928/4320\n",
      "3 4 8 sqrt gini False 500 112: Weighted 0.807478 (0.071691)\n",
      "3 4 8 sqrt gini False 500 112: Macro 0.701882 (0.098180)\n",
      "Testing 3929/4320\n",
      "3 4 8 sqrt entropy True 50 112: Weighted 0.813086 (0.069160)\n",
      "3 4 8 sqrt entropy True 50 112: Macro 0.708508 (0.090186)\n",
      "Testing 3930/4320\n",
      "3 4 8 sqrt entropy True 100 112: Weighted 0.808663 (0.063229)\n",
      "3 4 8 sqrt entropy True 100 112: Macro 0.701546 (0.081041)\n",
      "Testing 3931/4320\n",
      "3 4 8 sqrt entropy True 200 112: Weighted 0.821875 (0.066813)\n",
      "3 4 8 sqrt entropy True 200 112: Macro 0.723728 (0.090149)\n",
      "Testing 3932/4320\n",
      "3 4 8 sqrt entropy True 500 112: Weighted 0.817093 (0.064326)\n",
      "3 4 8 sqrt entropy True 500 112: Macro 0.713587 (0.084003)\n",
      "Testing 3933/4320\n",
      "3 4 8 sqrt entropy False 50 112: Weighted 0.792705 (0.064415)\n",
      "3 4 8 sqrt entropy False 50 112: Macro 0.678318 (0.084092)\n",
      "Testing 3934/4320\n",
      "3 4 8 sqrt entropy False 100 112: Weighted 0.797466 (0.065768)\n",
      "3 4 8 sqrt entropy False 100 112: Macro 0.686951 (0.087324)\n",
      "Testing 3935/4320\n",
      "3 4 8 sqrt entropy False 200 112: Weighted 0.801119 (0.063891)\n",
      "3 4 8 sqrt entropy False 200 112: Macro 0.692057 (0.084765)\n",
      "Testing 3936/4320\n",
      "3 4 8 sqrt entropy False 500 112: Weighted 0.801119 (0.063891)\n",
      "3 4 8 sqrt entropy False 500 112: Macro 0.692057 (0.084765)\n",
      "Testing 3937/4320\n",
      "3 6 3 log2 gini True 50 112: Weighted 0.813941 (0.055478)\n",
      "3 6 3 log2 gini True 50 112: Macro 0.709900 (0.075733)\n",
      "Testing 3938/4320\n",
      "3 6 3 log2 gini True 100 112: Weighted 0.809361 (0.051013)\n",
      "3 6 3 log2 gini True 100 112: Macro 0.700342 (0.068847)\n",
      "Testing 3939/4320\n",
      "3 6 3 log2 gini True 200 112: Weighted 0.809935 (0.060810)\n",
      "3 6 3 log2 gini True 200 112: Macro 0.704820 (0.082311)\n",
      "Testing 3940/4320\n",
      "3 6 3 log2 gini True 500 112: Weighted 0.813941 (0.055478)\n",
      "3 6 3 log2 gini True 500 112: Macro 0.709900 (0.075733)\n",
      "Testing 3941/4320\n",
      "3 6 3 log2 gini False 50 112: Weighted 0.793563 (0.090270)\n",
      "3 6 3 log2 gini False 50 112: Macro 0.688455 (0.112395)\n",
      "Testing 3942/4320\n",
      "3 6 3 log2 gini False 100 112: Weighted 0.787362 (0.100409)\n",
      "3 6 3 log2 gini False 100 112: Macro 0.681315 (0.123855)\n",
      "Testing 3943/4320\n",
      "3 6 3 log2 gini False 200 112: Weighted 0.793563 (0.090270)\n",
      "3 6 3 log2 gini False 200 112: Macro 0.688455 (0.112395)\n",
      "Testing 3944/4320\n",
      "3 6 3 log2 gini False 500 112: Weighted 0.793563 (0.090270)\n",
      "3 6 3 log2 gini False 500 112: Macro 0.688455 (0.112395)\n",
      "Testing 3945/4320\n",
      "3 6 3 log2 entropy True 50 112: Weighted 0.813938 (0.055482)\n",
      "3 6 3 log2 entropy True 50 112: Macro 0.713290 (0.071608)\n",
      "Testing 3946/4320\n",
      "3 6 3 log2 entropy True 100 112: Weighted 0.822625 (0.055592)\n",
      "3 6 3 log2 entropy True 100 112: Macro 0.725521 (0.072275)\n",
      "Testing 3947/4320\n",
      "3 6 3 log2 entropy True 200 112: Weighted 0.813938 (0.055482)\n",
      "3 6 3 log2 entropy True 200 112: Macro 0.713290 (0.071608)\n",
      "Testing 3948/4320\n",
      "3 6 3 log2 entropy True 500 112: Weighted 0.818669 (0.049700)\n",
      "3 6 3 log2 entropy True 500 112: Macro 0.716892 (0.067511)\n",
      "Testing 3949/4320\n",
      "3 6 3 log2 entropy False 50 112: Weighted 0.781816 (0.098017)\n",
      "3 6 3 log2 entropy False 50 112: Macro 0.673700 (0.117866)\n",
      "Testing 3950/4320\n",
      "3 6 3 log2 entropy False 100 112: Weighted 0.782434 (0.096994)\n",
      "3 6 3 log2 entropy False 100 112: Macro 0.673806 (0.117692)\n",
      "Testing 3951/4320\n",
      "3 6 3 log2 entropy False 200 112: Weighted 0.781816 (0.098017)\n",
      "3 6 3 log2 entropy False 200 112: Macro 0.673700 (0.117866)\n",
      "Testing 3952/4320\n",
      "3 6 3 log2 entropy False 500 112: Weighted 0.781816 (0.098017)\n",
      "3 6 3 log2 entropy False 500 112: Macro 0.673700 (0.117866)\n",
      "Testing 3953/4320\n",
      "3 6 3 sqrt gini True 50 112: Weighted 0.813941 (0.055478)\n",
      "3 6 3 sqrt gini True 50 112: Macro 0.709900 (0.075733)\n",
      "Testing 3954/4320\n",
      "3 6 3 sqrt gini True 100 112: Weighted 0.809361 (0.051013)\n",
      "3 6 3 sqrt gini True 100 112: Macro 0.700342 (0.068847)\n",
      "Testing 3955/4320\n",
      "3 6 3 sqrt gini True 200 112: Weighted 0.809935 (0.060810)\n",
      "3 6 3 sqrt gini True 200 112: Macro 0.704820 (0.082311)\n",
      "Testing 3956/4320\n",
      "3 6 3 sqrt gini True 500 112: Weighted 0.813941 (0.055478)\n",
      "3 6 3 sqrt gini True 500 112: Macro 0.709900 (0.075733)\n",
      "Testing 3957/4320\n",
      "3 6 3 sqrt gini False 50 112: Weighted 0.793563 (0.090270)\n",
      "3 6 3 sqrt gini False 50 112: Macro 0.688455 (0.112395)\n",
      "Testing 3958/4320\n",
      "3 6 3 sqrt gini False 100 112: Weighted 0.787362 (0.100409)\n",
      "3 6 3 sqrt gini False 100 112: Macro 0.681315 (0.123855)\n",
      "Testing 3959/4320\n",
      "3 6 3 sqrt gini False 200 112: Weighted 0.793563 (0.090270)\n",
      "3 6 3 sqrt gini False 200 112: Macro 0.688455 (0.112395)\n",
      "Testing 3960/4320\n",
      "3 6 3 sqrt gini False 500 112: Weighted 0.793563 (0.090270)\n",
      "3 6 3 sqrt gini False 500 112: Macro 0.688455 (0.112395)\n",
      "Testing 3961/4320\n",
      "3 6 3 sqrt entropy True 50 112: Weighted 0.813938 (0.055482)\n",
      "3 6 3 sqrt entropy True 50 112: Macro 0.713290 (0.071608)\n",
      "Testing 3962/4320\n",
      "3 6 3 sqrt entropy True 100 112: Weighted 0.822625 (0.055592)\n",
      "3 6 3 sqrt entropy True 100 112: Macro 0.725521 (0.072275)\n",
      "Testing 3963/4320\n",
      "3 6 3 sqrt entropy True 200 112: Weighted 0.813938 (0.055482)\n",
      "3 6 3 sqrt entropy True 200 112: Macro 0.713290 (0.071608)\n",
      "Testing 3964/4320\n",
      "3 6 3 sqrt entropy True 500 112: Weighted 0.818669 (0.049700)\n",
      "3 6 3 sqrt entropy True 500 112: Macro 0.716892 (0.067511)\n",
      "Testing 3965/4320\n",
      "3 6 3 sqrt entropy False 50 112: Weighted 0.781816 (0.098017)\n",
      "3 6 3 sqrt entropy False 50 112: Macro 0.673700 (0.117866)\n",
      "Testing 3966/4320\n",
      "3 6 3 sqrt entropy False 100 112: Weighted 0.782434 (0.096994)\n",
      "3 6 3 sqrt entropy False 100 112: Macro 0.673806 (0.117692)\n",
      "Testing 3967/4320\n",
      "3 6 3 sqrt entropy False 200 112: Weighted 0.781816 (0.098017)\n",
      "3 6 3 sqrt entropy False 200 112: Macro 0.673700 (0.117866)\n",
      "Testing 3968/4320\n",
      "3 6 3 sqrt entropy False 500 112: Weighted 0.781816 (0.098017)\n",
      "3 6 3 sqrt entropy False 500 112: Macro 0.673700 (0.117866)\n",
      "Testing 3969/4320\n",
      "3 6 5 log2 gini True 50 112: Weighted 0.808982 (0.067239)\n",
      "3 6 5 log2 gini True 50 112: Macro 0.701235 (0.086278)\n",
      "Testing 3970/4320\n",
      "3 6 5 log2 gini True 100 112: Weighted 0.809673 (0.062686)\n",
      "3 6 5 log2 gini True 100 112: Macro 0.701491 (0.081072)\n",
      "Testing 3971/4320\n",
      "3 6 5 log2 gini True 200 112: Weighted 0.813188 (0.061148)\n",
      "3 6 5 log2 gini True 200 112: Macro 0.706448 (0.078733)\n",
      "Testing 3972/4320\n",
      "3 6 5 log2 gini True 500 112: Weighted 0.809673 (0.062686)\n",
      "3 6 5 log2 gini True 500 112: Macro 0.701491 (0.081072)\n",
      "Testing 3973/4320\n",
      "3 6 5 log2 gini False 50 112: Weighted 0.813237 (0.075536)\n",
      "3 6 5 log2 gini False 50 112: Macro 0.707725 (0.105751)\n",
      "Testing 3974/4320\n",
      "3 6 5 log2 gini False 100 112: Weighted 0.807711 (0.076726)\n",
      "3 6 5 log2 gini False 100 112: Macro 0.704755 (0.106196)\n",
      "Testing 3975/4320\n",
      "3 6 5 log2 gini False 200 112: Weighted 0.808504 (0.076483)\n",
      "3 6 5 log2 gini False 200 112: Macro 0.704126 (0.106322)\n",
      "Testing 3976/4320\n",
      "3 6 5 log2 gini False 500 112: Weighted 0.813237 (0.075536)\n",
      "3 6 5 log2 gini False 500 112: Macro 0.707725 (0.105751)\n",
      "Testing 3977/4320\n",
      "3 6 5 log2 entropy True 50 112: Weighted 0.805466 (0.068425)\n",
      "3 6 5 log2 entropy True 50 112: Macro 0.696277 (0.088124)\n",
      "Testing 3978/4320\n",
      "3 6 5 log2 entropy True 100 112: Weighted 0.800704 (0.066202)\n",
      "3 6 5 log2 entropy True 100 112: Macro 0.689134 (0.084469)\n",
      "Testing 3979/4320\n",
      "3 6 5 log2 entropy True 200 112: Weighted 0.817971 (0.064052)\n",
      "3 6 5 log2 entropy True 200 112: Macro 0.716589 (0.086105)\n",
      "Testing 3980/4320\n",
      "3 6 5 log2 entropy True 500 112: Weighted 0.817466 (0.066908)\n",
      "3 6 5 log2 entropy True 500 112: Macro 0.716043 (0.088972)\n",
      "Testing 3981/4320\n",
      "3 6 5 log2 entropy False 50 112: Weighted 0.799232 (0.059254)\n",
      "3 6 5 log2 entropy False 50 112: Macro 0.689633 (0.075593)\n",
      "Testing 3982/4320\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 6 5 log2 entropy False 100 112: Weighted 0.799789 (0.070916)\n",
      "3 6 5 log2 entropy False 100 112: Macro 0.687770 (0.096874)\n",
      "Testing 3983/4320\n",
      "3 6 5 log2 entropy False 200 112: Weighted 0.792648 (0.072816)\n",
      "3 6 5 log2 entropy False 200 112: Macro 0.677864 (0.099540)\n",
      "Testing 3984/4320\n",
      "3 6 5 log2 entropy False 500 112: Weighted 0.794210 (0.074570)\n",
      "3 6 5 log2 entropy False 500 112: Macro 0.682298 (0.098596)\n",
      "Testing 3985/4320\n",
      "3 6 5 sqrt gini True 50 112: Weighted 0.808982 (0.067239)\n",
      "3 6 5 sqrt gini True 50 112: Macro 0.701235 (0.086278)\n",
      "Testing 3986/4320\n",
      "3 6 5 sqrt gini True 100 112: Weighted 0.809673 (0.062686)\n",
      "3 6 5 sqrt gini True 100 112: Macro 0.701491 (0.081072)\n",
      "Testing 3987/4320\n",
      "3 6 5 sqrt gini True 200 112: Weighted 0.813188 (0.061148)\n",
      "3 6 5 sqrt gini True 200 112: Macro 0.706448 (0.078733)\n",
      "Testing 3988/4320\n",
      "3 6 5 sqrt gini True 500 112: Weighted 0.809673 (0.062686)\n",
      "3 6 5 sqrt gini True 500 112: Macro 0.701491 (0.081072)\n",
      "Testing 3989/4320\n",
      "3 6 5 sqrt gini False 50 112: Weighted 0.813237 (0.075536)\n",
      "3 6 5 sqrt gini False 50 112: Macro 0.707725 (0.105751)\n",
      "Testing 3990/4320\n",
      "3 6 5 sqrt gini False 100 112: Weighted 0.807711 (0.076726)\n",
      "3 6 5 sqrt gini False 100 112: Macro 0.704755 (0.106196)\n",
      "Testing 3991/4320\n",
      "3 6 5 sqrt gini False 200 112: Weighted 0.808504 (0.076483)\n",
      "3 6 5 sqrt gini False 200 112: Macro 0.704126 (0.106322)\n",
      "Testing 3992/4320\n",
      "3 6 5 sqrt gini False 500 112: Weighted 0.813237 (0.075536)\n",
      "3 6 5 sqrt gini False 500 112: Macro 0.707725 (0.105751)\n",
      "Testing 3993/4320\n",
      "3 6 5 sqrt entropy True 50 112: Weighted 0.805466 (0.068425)\n",
      "3 6 5 sqrt entropy True 50 112: Macro 0.696277 (0.088124)\n",
      "Testing 3994/4320\n",
      "3 6 5 sqrt entropy True 100 112: Weighted 0.800704 (0.066202)\n",
      "3 6 5 sqrt entropy True 100 112: Macro 0.689134 (0.084469)\n",
      "Testing 3995/4320\n",
      "3 6 5 sqrt entropy True 200 112: Weighted 0.817971 (0.064052)\n",
      "3 6 5 sqrt entropy True 200 112: Macro 0.716589 (0.086105)\n",
      "Testing 3996/4320\n",
      "3 6 5 sqrt entropy True 500 112: Weighted 0.817466 (0.066908)\n",
      "3 6 5 sqrt entropy True 500 112: Macro 0.716043 (0.088972)\n",
      "Testing 3997/4320\n",
      "3 6 5 sqrt entropy False 50 112: Weighted 0.799232 (0.059254)\n",
      "3 6 5 sqrt entropy False 50 112: Macro 0.689633 (0.075593)\n",
      "Testing 3998/4320\n",
      "3 6 5 sqrt entropy False 100 112: Weighted 0.799789 (0.070916)\n",
      "3 6 5 sqrt entropy False 100 112: Macro 0.687770 (0.096874)\n",
      "Testing 3999/4320\n",
      "3 6 5 sqrt entropy False 200 112: Weighted 0.792648 (0.072816)\n",
      "3 6 5 sqrt entropy False 200 112: Macro 0.677864 (0.099540)\n",
      "Testing 4000/4320\n",
      "3 6 5 sqrt entropy False 500 112: Weighted 0.794210 (0.074570)\n",
      "3 6 5 sqrt entropy False 500 112: Macro 0.682298 (0.098596)\n",
      "Testing 4001/4320\n",
      "3 6 8 log2 gini True 50 112: Weighted 0.812670 (0.058207)\n",
      "3 6 8 log2 gini True 50 112: Macro 0.706626 (0.074574)\n",
      "Testing 4002/4320\n",
      "3 6 8 log2 gini True 100 112: Weighted 0.817093 (0.064326)\n",
      "3 6 8 log2 gini True 100 112: Macro 0.713587 (0.084003)\n",
      "Testing 4003/4320\n",
      "3 6 8 log2 gini True 200 112: Weighted 0.813440 (0.067066)\n",
      "3 6 8 log2 gini True 200 112: Macro 0.708481 (0.087845)\n",
      "Testing 4004/4320\n",
      "3 6 8 log2 gini True 500 112: Weighted 0.812331 (0.062843)\n",
      "3 6 8 log2 gini True 500 112: Macro 0.706444 (0.081688)\n",
      "Testing 4005/4320\n",
      "3 6 8 log2 gini False 50 112: Weighted 0.804934 (0.072903)\n",
      "3 6 8 log2 gini False 50 112: Macro 0.698802 (0.100222)\n",
      "Testing 4006/4320\n",
      "3 6 8 log2 gini False 100 112: Weighted 0.808544 (0.069922)\n",
      "3 6 8 log2 gini False 100 112: Macro 0.703862 (0.096699)\n",
      "Testing 4007/4320\n",
      "3 6 8 log2 gini False 200 112: Weighted 0.808544 (0.069922)\n",
      "3 6 8 log2 gini False 200 112: Macro 0.703862 (0.096699)\n",
      "Testing 4008/4320\n",
      "3 6 8 log2 gini False 500 112: Weighted 0.807478 (0.071691)\n",
      "3 6 8 log2 gini False 500 112: Macro 0.701882 (0.098180)\n",
      "Testing 4009/4320\n",
      "3 6 8 log2 entropy True 50 112: Weighted 0.813086 (0.069160)\n",
      "3 6 8 log2 entropy True 50 112: Macro 0.708508 (0.090186)\n",
      "Testing 4010/4320\n",
      "3 6 8 log2 entropy True 100 112: Weighted 0.808663 (0.063229)\n",
      "3 6 8 log2 entropy True 100 112: Macro 0.701546 (0.081041)\n",
      "Testing 4011/4320\n",
      "3 6 8 log2 entropy True 200 112: Weighted 0.821875 (0.066813)\n",
      "3 6 8 log2 entropy True 200 112: Macro 0.723728 (0.090149)\n",
      "Testing 4012/4320\n",
      "3 6 8 log2 entropy True 500 112: Weighted 0.817093 (0.064326)\n",
      "3 6 8 log2 entropy True 500 112: Macro 0.713587 (0.084003)\n",
      "Testing 4013/4320\n",
      "3 6 8 log2 entropy False 50 112: Weighted 0.792705 (0.064415)\n",
      "3 6 8 log2 entropy False 50 112: Macro 0.678318 (0.084092)\n",
      "Testing 4014/4320\n",
      "3 6 8 log2 entropy False 100 112: Weighted 0.797466 (0.065768)\n",
      "3 6 8 log2 entropy False 100 112: Macro 0.686951 (0.087324)\n",
      "Testing 4015/4320\n",
      "3 6 8 log2 entropy False 200 112: Weighted 0.801119 (0.063891)\n",
      "3 6 8 log2 entropy False 200 112: Macro 0.692057 (0.084765)\n",
      "Testing 4016/4320\n",
      "3 6 8 log2 entropy False 500 112: Weighted 0.801119 (0.063891)\n",
      "3 6 8 log2 entropy False 500 112: Macro 0.692057 (0.084765)\n",
      "Testing 4017/4320\n",
      "3 6 8 sqrt gini True 50 112: Weighted 0.812670 (0.058207)\n",
      "3 6 8 sqrt gini True 50 112: Macro 0.706626 (0.074574)\n",
      "Testing 4018/4320\n",
      "3 6 8 sqrt gini True 100 112: Weighted 0.817093 (0.064326)\n",
      "3 6 8 sqrt gini True 100 112: Macro 0.713587 (0.084003)\n",
      "Testing 4019/4320\n",
      "3 6 8 sqrt gini True 200 112: Weighted 0.813440 (0.067066)\n",
      "3 6 8 sqrt gini True 200 112: Macro 0.708481 (0.087845)\n",
      "Testing 4020/4320\n",
      "3 6 8 sqrt gini True 500 112: Weighted 0.812331 (0.062843)\n",
      "3 6 8 sqrt gini True 500 112: Macro 0.706444 (0.081688)\n",
      "Testing 4021/4320\n",
      "3 6 8 sqrt gini False 50 112: Weighted 0.804934 (0.072903)\n",
      "3 6 8 sqrt gini False 50 112: Macro 0.698802 (0.100222)\n",
      "Testing 4022/4320\n",
      "3 6 8 sqrt gini False 100 112: Weighted 0.808544 (0.069922)\n",
      "3 6 8 sqrt gini False 100 112: Macro 0.703862 (0.096699)\n",
      "Testing 4023/4320\n",
      "3 6 8 sqrt gini False 200 112: Weighted 0.808544 (0.069922)\n",
      "3 6 8 sqrt gini False 200 112: Macro 0.703862 (0.096699)\n",
      "Testing 4024/4320\n",
      "3 6 8 sqrt gini False 500 112: Weighted 0.807478 (0.071691)\n",
      "3 6 8 sqrt gini False 500 112: Macro 0.701882 (0.098180)\n",
      "Testing 4025/4320\n",
      "3 6 8 sqrt entropy True 50 112: Weighted 0.813086 (0.069160)\n",
      "3 6 8 sqrt entropy True 50 112: Macro 0.708508 (0.090186)\n",
      "Testing 4026/4320\n",
      "3 6 8 sqrt entropy True 100 112: Weighted 0.808663 (0.063229)\n",
      "3 6 8 sqrt entropy True 100 112: Macro 0.701546 (0.081041)\n",
      "Testing 4027/4320\n",
      "3 6 8 sqrt entropy True 200 112: Weighted 0.821875 (0.066813)\n",
      "3 6 8 sqrt entropy True 200 112: Macro 0.723728 (0.090149)\n",
      "Testing 4028/4320\n",
      "3 6 8 sqrt entropy True 500 112: Weighted 0.817093 (0.064326)\n",
      "3 6 8 sqrt entropy True 500 112: Macro 0.713587 (0.084003)\n",
      "Testing 4029/4320\n",
      "3 6 8 sqrt entropy False 50 112: Weighted 0.792705 (0.064415)\n",
      "3 6 8 sqrt entropy False 50 112: Macro 0.678318 (0.084092)\n",
      "Testing 4030/4320\n",
      "3 6 8 sqrt entropy False 100 112: Weighted 0.797466 (0.065768)\n",
      "3 6 8 sqrt entropy False 100 112: Macro 0.686951 (0.087324)\n",
      "Testing 4031/4320\n",
      "3 6 8 sqrt entropy False 200 112: Weighted 0.801119 (0.063891)\n",
      "3 6 8 sqrt entropy False 200 112: Macro 0.692057 (0.084765)\n",
      "Testing 4032/4320\n",
      "3 6 8 sqrt entropy False 500 112: Weighted 0.801119 (0.063891)\n",
      "3 6 8 sqrt entropy False 500 112: Macro 0.692057 (0.084765)\n",
      "Testing 4033/4320\n",
      "5 2 3 log2 gini True 50 112: Weighted 0.809159 (0.051727)\n",
      "5 2 3 log2 gini True 50 112: Macro 0.699758 (0.066217)\n",
      "Testing 4034/4320\n",
      "5 2 3 log2 gini True 100 112: Weighted 0.813733 (0.055258)\n",
      "5 2 3 log2 gini True 100 112: Macro 0.706814 (0.073173)\n",
      "Testing 4035/4320\n",
      "5 2 3 log2 gini True 200 112: Weighted 0.805355 (0.056442)\n",
      "5 2 3 log2 gini True 200 112: Macro 0.695263 (0.075381)\n",
      "Testing 4036/4320\n",
      "5 2 3 log2 gini True 500 112: Weighted 0.813941 (0.055478)\n",
      "5 2 3 log2 gini True 500 112: Macro 0.709900 (0.075733)\n",
      "Testing 4037/4320\n",
      "5 2 3 log2 gini False 50 112: Weighted 0.793563 (0.090270)\n",
      "5 2 3 log2 gini False 50 112: Macro 0.688455 (0.112395)\n",
      "Testing 4038/4320\n",
      "5 2 3 log2 gini False 100 112: Weighted 0.787362 (0.100409)\n",
      "5 2 3 log2 gini False 100 112: Macro 0.681315 (0.123855)\n",
      "Testing 4039/4320\n",
      "5 2 3 log2 gini False 200 112: Weighted 0.787362 (0.100409)\n",
      "5 2 3 log2 gini False 200 112: Macro 0.681315 (0.123855)\n",
      "Testing 4040/4320\n",
      "5 2 3 log2 gini False 500 112: Weighted 0.793563 (0.090270)\n",
      "5 2 3 log2 gini False 500 112: Macro 0.688455 (0.112395)\n",
      "Testing 4041/4320\n",
      "5 2 3 log2 entropy True 50 112: Weighted 0.809566 (0.061318)\n",
      "5 2 3 log2 entropy True 50 112: Macro 0.707742 (0.078474)\n",
      "Testing 4042/4320\n",
      "5 2 3 log2 entropy True 100 112: Weighted 0.818459 (0.060588)\n",
      "5 2 3 log2 entropy True 100 112: Macro 0.720102 (0.078267)\n",
      "Testing 4043/4320\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 2 3 log2 entropy True 200 112: Weighted 0.813938 (0.055482)\n",
      "5 2 3 log2 entropy True 200 112: Macro 0.713290 (0.071608)\n",
      "Testing 4044/4320\n",
      "5 2 3 log2 entropy True 500 112: Weighted 0.814217 (0.055124)\n",
      "5 2 3 log2 entropy True 500 112: Macro 0.711260 (0.074050)\n",
      "Testing 4045/4320\n",
      "5 2 3 log2 entropy False 50 112: Weighted 0.781816 (0.098017)\n",
      "5 2 3 log2 entropy False 50 112: Macro 0.673700 (0.117866)\n",
      "Testing 4046/4320\n",
      "5 2 3 log2 entropy False 100 112: Weighted 0.782434 (0.096994)\n",
      "5 2 3 log2 entropy False 100 112: Macro 0.673806 (0.117692)\n",
      "Testing 4047/4320\n",
      "5 2 3 log2 entropy False 200 112: Weighted 0.782434 (0.096994)\n",
      "5 2 3 log2 entropy False 200 112: Macro 0.673806 (0.117692)\n",
      "Testing 4048/4320\n",
      "5 2 3 log2 entropy False 500 112: Weighted 0.782434 (0.096994)\n",
      "5 2 3 log2 entropy False 500 112: Macro 0.673806 (0.117692)\n",
      "Testing 4049/4320\n",
      "5 2 3 sqrt gini True 50 112: Weighted 0.809159 (0.051727)\n",
      "5 2 3 sqrt gini True 50 112: Macro 0.699758 (0.066217)\n",
      "Testing 4050/4320\n",
      "5 2 3 sqrt gini True 100 112: Weighted 0.813733 (0.055258)\n",
      "5 2 3 sqrt gini True 100 112: Macro 0.706814 (0.073173)\n",
      "Testing 4051/4320\n",
      "5 2 3 sqrt gini True 200 112: Weighted 0.805355 (0.056442)\n",
      "5 2 3 sqrt gini True 200 112: Macro 0.695263 (0.075381)\n",
      "Testing 4052/4320\n",
      "5 2 3 sqrt gini True 500 112: Weighted 0.813941 (0.055478)\n",
      "5 2 3 sqrt gini True 500 112: Macro 0.709900 (0.075733)\n",
      "Testing 4053/4320\n",
      "5 2 3 sqrt gini False 50 112: Weighted 0.793563 (0.090270)\n",
      "5 2 3 sqrt gini False 50 112: Macro 0.688455 (0.112395)\n",
      "Testing 4054/4320\n",
      "5 2 3 sqrt gini False 100 112: Weighted 0.787362 (0.100409)\n",
      "5 2 3 sqrt gini False 100 112: Macro 0.681315 (0.123855)\n",
      "Testing 4055/4320\n",
      "5 2 3 sqrt gini False 200 112: Weighted 0.787362 (0.100409)\n",
      "5 2 3 sqrt gini False 200 112: Macro 0.681315 (0.123855)\n",
      "Testing 4056/4320\n",
      "5 2 3 sqrt gini False 500 112: Weighted 0.793563 (0.090270)\n",
      "5 2 3 sqrt gini False 500 112: Macro 0.688455 (0.112395)\n",
      "Testing 4057/4320\n",
      "5 2 3 sqrt entropy True 50 112: Weighted 0.809566 (0.061318)\n",
      "5 2 3 sqrt entropy True 50 112: Macro 0.707742 (0.078474)\n",
      "Testing 4058/4320\n",
      "5 2 3 sqrt entropy True 100 112: Weighted 0.818459 (0.060588)\n",
      "5 2 3 sqrt entropy True 100 112: Macro 0.720102 (0.078267)\n",
      "Testing 4059/4320\n",
      "5 2 3 sqrt entropy True 200 112: Weighted 0.813938 (0.055482)\n",
      "5 2 3 sqrt entropy True 200 112: Macro 0.713290 (0.071608)\n",
      "Testing 4060/4320\n",
      "5 2 3 sqrt entropy True 500 112: Weighted 0.814217 (0.055124)\n",
      "5 2 3 sqrt entropy True 500 112: Macro 0.711260 (0.074050)\n",
      "Testing 4061/4320\n",
      "5 2 3 sqrt entropy False 50 112: Weighted 0.781816 (0.098017)\n",
      "5 2 3 sqrt entropy False 50 112: Macro 0.673700 (0.117866)\n",
      "Testing 4062/4320\n",
      "5 2 3 sqrt entropy False 100 112: Weighted 0.782434 (0.096994)\n",
      "5 2 3 sqrt entropy False 100 112: Macro 0.673806 (0.117692)\n",
      "Testing 4063/4320\n",
      "5 2 3 sqrt entropy False 200 112: Weighted 0.782434 (0.096994)\n",
      "5 2 3 sqrt entropy False 200 112: Macro 0.673806 (0.117692)\n",
      "Testing 4064/4320\n",
      "5 2 3 sqrt entropy False 500 112: Weighted 0.782434 (0.096994)\n",
      "5 2 3 sqrt entropy False 500 112: Macro 0.673806 (0.117692)\n",
      "Testing 4065/4320\n",
      "5 2 5 log2 gini True 50 112: Weighted 0.810128 (0.066968)\n",
      "5 2 5 log2 gini True 50 112: Macro 0.701328 (0.086251)\n",
      "Testing 4066/4320\n",
      "5 2 5 log2 gini True 100 112: Weighted 0.809673 (0.062686)\n",
      "5 2 5 log2 gini True 100 112: Macro 0.701491 (0.081072)\n",
      "Testing 4067/4320\n",
      "5 2 5 log2 gini True 200 112: Weighted 0.813679 (0.057546)\n",
      "5 2 5 log2 gini True 200 112: Macro 0.706570 (0.074612)\n",
      "Testing 4068/4320\n",
      "5 2 5 log2 gini True 500 112: Weighted 0.809673 (0.062686)\n",
      "5 2 5 log2 gini True 500 112: Macro 0.701491 (0.081072)\n",
      "Testing 4069/4320\n",
      "5 2 5 log2 gini False 50 112: Weighted 0.812352 (0.075646)\n",
      "5 2 5 log2 gini False 50 112: Macro 0.708254 (0.105698)\n",
      "Testing 4070/4320\n",
      "5 2 5 log2 gini False 100 112: Weighted 0.812352 (0.075646)\n",
      "5 2 5 log2 gini False 100 112: Macro 0.708254 (0.105698)\n",
      "Testing 4071/4320\n",
      "5 2 5 log2 gini False 200 112: Weighted 0.812352 (0.075646)\n",
      "5 2 5 log2 gini False 200 112: Macro 0.708254 (0.105698)\n",
      "Testing 4072/4320\n",
      "5 2 5 log2 gini False 500 112: Weighted 0.812352 (0.075646)\n",
      "5 2 5 log2 gini False 500 112: Macro 0.708254 (0.105698)\n",
      "Testing 4073/4320\n",
      "5 2 5 log2 entropy True 50 112: Weighted 0.810248 (0.071550)\n",
      "5 2 5 log2 entropy True 50 112: Macro 0.706418 (0.095851)\n",
      "Testing 4074/4320\n",
      "5 2 5 log2 entropy True 100 112: Weighted 0.805466 (0.068425)\n",
      "5 2 5 log2 entropy True 100 112: Macro 0.696277 (0.088124)\n",
      "Testing 4075/4320\n",
      "5 2 5 log2 entropy True 200 112: Weighted 0.817971 (0.064052)\n",
      "5 2 5 log2 entropy True 200 112: Macro 0.716589 (0.086105)\n",
      "Testing 4076/4320\n",
      "5 2 5 log2 entropy True 500 112: Weighted 0.813043 (0.061075)\n",
      "5 2 5 log2 entropy True 500 112: Macro 0.709081 (0.080344)\n",
      "Testing 4077/4320\n",
      "5 2 5 log2 entropy False 50 112: Weighted 0.808837 (0.067164)\n",
      "5 2 5 log2 entropy False 50 112: Macro 0.703868 (0.087906)\n",
      "Testing 4078/4320\n",
      "5 2 5 log2 entropy False 100 112: Weighted 0.799789 (0.070916)\n",
      "5 2 5 log2 entropy False 100 112: Macro 0.687770 (0.096874)\n",
      "Testing 4079/4320\n",
      "5 2 5 log2 entropy False 200 112: Weighted 0.799789 (0.070916)\n",
      "5 2 5 log2 entropy False 200 112: Macro 0.687770 (0.096874)\n",
      "Testing 4080/4320\n",
      "5 2 5 log2 entropy False 500 112: Weighted 0.799789 (0.070916)\n",
      "5 2 5 log2 entropy False 500 112: Macro 0.687770 (0.096874)\n",
      "Testing 4081/4320\n",
      "5 2 5 sqrt gini True 50 112: Weighted 0.810128 (0.066968)\n",
      "5 2 5 sqrt gini True 50 112: Macro 0.701328 (0.086251)\n",
      "Testing 4082/4320\n",
      "5 2 5 sqrt gini True 100 112: Weighted 0.809673 (0.062686)\n",
      "5 2 5 sqrt gini True 100 112: Macro 0.701491 (0.081072)\n",
      "Testing 4083/4320\n",
      "5 2 5 sqrt gini True 200 112: Weighted 0.813679 (0.057546)\n",
      "5 2 5 sqrt gini True 200 112: Macro 0.706570 (0.074612)\n",
      "Testing 4084/4320\n",
      "5 2 5 sqrt gini True 500 112: Weighted 0.809673 (0.062686)\n",
      "5 2 5 sqrt gini True 500 112: Macro 0.701491 (0.081072)\n",
      "Testing 4085/4320\n",
      "5 2 5 sqrt gini False 50 112: Weighted 0.812352 (0.075646)\n",
      "5 2 5 sqrt gini False 50 112: Macro 0.708254 (0.105698)\n",
      "Testing 4086/4320\n",
      "5 2 5 sqrt gini False 100 112: Weighted 0.812352 (0.075646)\n",
      "5 2 5 sqrt gini False 100 112: Macro 0.708254 (0.105698)\n",
      "Testing 4087/4320\n",
      "5 2 5 sqrt gini False 200 112: Weighted 0.812352 (0.075646)\n",
      "5 2 5 sqrt gini False 200 112: Macro 0.708254 (0.105698)\n",
      "Testing 4088/4320\n",
      "5 2 5 sqrt gini False 500 112: Weighted 0.812352 (0.075646)\n",
      "5 2 5 sqrt gini False 500 112: Macro 0.708254 (0.105698)\n",
      "Testing 4089/4320\n",
      "5 2 5 sqrt entropy True 50 112: Weighted 0.810248 (0.071550)\n",
      "5 2 5 sqrt entropy True 50 112: Macro 0.706418 (0.095851)\n",
      "Testing 4090/4320\n",
      "5 2 5 sqrt entropy True 100 112: Weighted 0.805466 (0.068425)\n",
      "5 2 5 sqrt entropy True 100 112: Macro 0.696277 (0.088124)\n",
      "Testing 4091/4320\n",
      "5 2 5 sqrt entropy True 200 112: Weighted 0.817971 (0.064052)\n",
      "5 2 5 sqrt entropy True 200 112: Macro 0.716589 (0.086105)\n",
      "Testing 4092/4320\n",
      "5 2 5 sqrt entropy True 500 112: Weighted 0.813043 (0.061075)\n",
      "5 2 5 sqrt entropy True 500 112: Macro 0.709081 (0.080344)\n",
      "Testing 4093/4320\n",
      "5 2 5 sqrt entropy False 50 112: Weighted 0.808837 (0.067164)\n",
      "5 2 5 sqrt entropy False 50 112: Macro 0.703868 (0.087906)\n",
      "Testing 4094/4320\n",
      "5 2 5 sqrt entropy False 100 112: Weighted 0.799789 (0.070916)\n",
      "5 2 5 sqrt entropy False 100 112: Macro 0.687770 (0.096874)\n",
      "Testing 4095/4320\n",
      "5 2 5 sqrt entropy False 200 112: Weighted 0.799789 (0.070916)\n",
      "5 2 5 sqrt entropy False 200 112: Macro 0.687770 (0.096874)\n",
      "Testing 4096/4320\n",
      "5 2 5 sqrt entropy False 500 112: Weighted 0.799789 (0.070916)\n",
      "5 2 5 sqrt entropy False 500 112: Macro 0.687770 (0.096874)\n",
      "Testing 4097/4320\n",
      "5 2 8 log2 gini True 50 112: Weighted 0.821873 (0.058393)\n",
      "5 2 8 log2 gini True 50 112: Macro 0.718885 (0.076736)\n",
      "Testing 4098/4320\n",
      "5 2 8 log2 gini True 100 112: Weighted 0.817348 (0.061213)\n",
      "5 2 8 log2 gini True 100 112: Macro 0.713983 (0.079868)\n",
      "Testing 4099/4320\n",
      "5 2 8 log2 gini True 200 112: Weighted 0.820658 (0.062157)\n",
      "5 2 8 log2 gini True 200 112: Macro 0.718752 (0.080918)\n",
      "Testing 4100/4320\n",
      "5 2 8 log2 gini True 500 112: Weighted 0.817093 (0.064326)\n",
      "5 2 8 log2 gini True 500 112: Macro 0.713587 (0.084003)\n",
      "Testing 4101/4320\n",
      "5 2 8 log2 gini False 50 112: Weighted 0.809765 (0.073972)\n",
      "5 2 8 log2 gini False 50 112: Macro 0.700308 (0.102686)\n",
      "Testing 4102/4320\n",
      "5 2 8 log2 gini False 100 112: Weighted 0.809765 (0.073972)\n",
      "5 2 8 log2 gini False 100 112: Macro 0.700308 (0.102686)\n",
      "Testing 4103/4320\n",
      "5 2 8 log2 gini False 200 112: Weighted 0.804369 (0.068699)\n",
      "5 2 8 log2 gini False 200 112: Macro 0.695110 (0.095284)\n",
      "Testing 4104/4320\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 2 8 log2 gini False 500 112: Weighted 0.804333 (0.068679)\n",
      "5 2 8 log2 gini False 500 112: Macro 0.693402 (0.094129)\n",
      "Testing 4105/4320\n",
      "5 2 8 log2 entropy True 50 112: Weighted 0.808663 (0.063229)\n",
      "5 2 8 log2 entropy True 50 112: Macro 0.701546 (0.081041)\n",
      "Testing 4106/4320\n",
      "5 2 8 log2 entropy True 100 112: Weighted 0.812670 (0.058207)\n",
      "5 2 8 log2 entropy True 100 112: Macro 0.706626 (0.074574)\n",
      "Testing 4107/4320\n",
      "5 2 8 log2 entropy True 200 112: Weighted 0.817093 (0.064326)\n",
      "5 2 8 log2 entropy True 200 112: Macro 0.713587 (0.084003)\n",
      "Testing 4108/4320\n",
      "5 2 8 log2 entropy True 500 112: Weighted 0.813086 (0.069160)\n",
      "5 2 8 log2 entropy True 500 112: Macro 0.708508 (0.090186)\n",
      "Testing 4109/4320\n",
      "5 2 8 log2 entropy False 50 112: Weighted 0.796836 (0.067663)\n",
      "5 2 8 log2 entropy False 50 112: Macro 0.685043 (0.087182)\n",
      "Testing 4110/4320\n",
      "5 2 8 log2 entropy False 100 112: Weighted 0.795264 (0.071879)\n",
      "5 2 8 log2 entropy False 100 112: Macro 0.682868 (0.097827)\n",
      "Testing 4111/4320\n",
      "5 2 8 log2 entropy False 200 112: Weighted 0.799284 (0.066331)\n",
      "5 2 8 log2 entropy False 200 112: Macro 0.687687 (0.090862)\n",
      "Testing 4112/4320\n",
      "5 2 8 log2 entropy False 500 112: Weighted 0.799284 (0.066331)\n",
      "5 2 8 log2 entropy False 500 112: Macro 0.687687 (0.090862)\n",
      "Testing 4113/4320\n",
      "5 2 8 sqrt gini True 50 112: Weighted 0.821873 (0.058393)\n",
      "5 2 8 sqrt gini True 50 112: Macro 0.718885 (0.076736)\n",
      "Testing 4114/4320\n",
      "5 2 8 sqrt gini True 100 112: Weighted 0.817348 (0.061213)\n",
      "5 2 8 sqrt gini True 100 112: Macro 0.713983 (0.079868)\n",
      "Testing 4115/4320\n",
      "5 2 8 sqrt gini True 200 112: Weighted 0.820658 (0.062157)\n",
      "5 2 8 sqrt gini True 200 112: Macro 0.718752 (0.080918)\n",
      "Testing 4116/4320\n",
      "5 2 8 sqrt gini True 500 112: Weighted 0.817093 (0.064326)\n",
      "5 2 8 sqrt gini True 500 112: Macro 0.713587 (0.084003)\n",
      "Testing 4117/4320\n",
      "5 2 8 sqrt gini False 50 112: Weighted 0.809765 (0.073972)\n",
      "5 2 8 sqrt gini False 50 112: Macro 0.700308 (0.102686)\n",
      "Testing 4118/4320\n",
      "5 2 8 sqrt gini False 100 112: Weighted 0.809765 (0.073972)\n",
      "5 2 8 sqrt gini False 100 112: Macro 0.700308 (0.102686)\n",
      "Testing 4119/4320\n",
      "5 2 8 sqrt gini False 200 112: Weighted 0.804369 (0.068699)\n",
      "5 2 8 sqrt gini False 200 112: Macro 0.695110 (0.095284)\n",
      "Testing 4120/4320\n",
      "5 2 8 sqrt gini False 500 112: Weighted 0.804333 (0.068679)\n",
      "5 2 8 sqrt gini False 500 112: Macro 0.693402 (0.094129)\n",
      "Testing 4121/4320\n",
      "5 2 8 sqrt entropy True 50 112: Weighted 0.808663 (0.063229)\n",
      "5 2 8 sqrt entropy True 50 112: Macro 0.701546 (0.081041)\n",
      "Testing 4122/4320\n",
      "5 2 8 sqrt entropy True 100 112: Weighted 0.812670 (0.058207)\n",
      "5 2 8 sqrt entropy True 100 112: Macro 0.706626 (0.074574)\n",
      "Testing 4123/4320\n",
      "5 2 8 sqrt entropy True 200 112: Weighted 0.817093 (0.064326)\n",
      "5 2 8 sqrt entropy True 200 112: Macro 0.713587 (0.084003)\n",
      "Testing 4124/4320\n",
      "5 2 8 sqrt entropy True 500 112: Weighted 0.813086 (0.069160)\n",
      "5 2 8 sqrt entropy True 500 112: Macro 0.708508 (0.090186)\n",
      "Testing 4125/4320\n",
      "5 2 8 sqrt entropy False 50 112: Weighted 0.796836 (0.067663)\n",
      "5 2 8 sqrt entropy False 50 112: Macro 0.685043 (0.087182)\n",
      "Testing 4126/4320\n",
      "5 2 8 sqrt entropy False 100 112: Weighted 0.795264 (0.071879)\n",
      "5 2 8 sqrt entropy False 100 112: Macro 0.682868 (0.097827)\n",
      "Testing 4127/4320\n",
      "5 2 8 sqrt entropy False 200 112: Weighted 0.799284 (0.066331)\n",
      "5 2 8 sqrt entropy False 200 112: Macro 0.687687 (0.090862)\n",
      "Testing 4128/4320\n",
      "5 2 8 sqrt entropy False 500 112: Weighted 0.799284 (0.066331)\n",
      "5 2 8 sqrt entropy False 500 112: Macro 0.687687 (0.090862)\n",
      "Testing 4129/4320\n",
      "5 4 3 log2 gini True 50 112: Weighted 0.809159 (0.051727)\n",
      "5 4 3 log2 gini True 50 112: Macro 0.699758 (0.066217)\n",
      "Testing 4130/4320\n",
      "5 4 3 log2 gini True 100 112: Weighted 0.813733 (0.055258)\n",
      "5 4 3 log2 gini True 100 112: Macro 0.706814 (0.073173)\n",
      "Testing 4131/4320\n",
      "5 4 3 log2 gini True 200 112: Weighted 0.805355 (0.056442)\n",
      "5 4 3 log2 gini True 200 112: Macro 0.695263 (0.075381)\n",
      "Testing 4132/4320\n",
      "5 4 3 log2 gini True 500 112: Weighted 0.813941 (0.055478)\n",
      "5 4 3 log2 gini True 500 112: Macro 0.709900 (0.075733)\n",
      "Testing 4133/4320\n",
      "5 4 3 log2 gini False 50 112: Weighted 0.793563 (0.090270)\n",
      "5 4 3 log2 gini False 50 112: Macro 0.688455 (0.112395)\n",
      "Testing 4134/4320\n",
      "5 4 3 log2 gini False 100 112: Weighted 0.787362 (0.100409)\n",
      "5 4 3 log2 gini False 100 112: Macro 0.681315 (0.123855)\n",
      "Testing 4135/4320\n",
      "5 4 3 log2 gini False 200 112: Weighted 0.787362 (0.100409)\n",
      "5 4 3 log2 gini False 200 112: Macro 0.681315 (0.123855)\n",
      "Testing 4136/4320\n",
      "5 4 3 log2 gini False 500 112: Weighted 0.793563 (0.090270)\n",
      "5 4 3 log2 gini False 500 112: Macro 0.688455 (0.112395)\n",
      "Testing 4137/4320\n",
      "5 4 3 log2 entropy True 50 112: Weighted 0.809566 (0.061318)\n",
      "5 4 3 log2 entropy True 50 112: Macro 0.707742 (0.078474)\n",
      "Testing 4138/4320\n",
      "5 4 3 log2 entropy True 100 112: Weighted 0.818459 (0.060588)\n",
      "5 4 3 log2 entropy True 100 112: Macro 0.720102 (0.078267)\n",
      "Testing 4139/4320\n",
      "5 4 3 log2 entropy True 200 112: Weighted 0.813938 (0.055482)\n",
      "5 4 3 log2 entropy True 200 112: Macro 0.713290 (0.071608)\n",
      "Testing 4140/4320\n",
      "5 4 3 log2 entropy True 500 112: Weighted 0.814217 (0.055124)\n",
      "5 4 3 log2 entropy True 500 112: Macro 0.711260 (0.074050)\n",
      "Testing 4141/4320\n",
      "5 4 3 log2 entropy False 50 112: Weighted 0.781816 (0.098017)\n",
      "5 4 3 log2 entropy False 50 112: Macro 0.673700 (0.117866)\n",
      "Testing 4142/4320\n",
      "5 4 3 log2 entropy False 100 112: Weighted 0.782434 (0.096994)\n",
      "5 4 3 log2 entropy False 100 112: Macro 0.673806 (0.117692)\n",
      "Testing 4143/4320\n",
      "5 4 3 log2 entropy False 200 112: Weighted 0.782434 (0.096994)\n",
      "5 4 3 log2 entropy False 200 112: Macro 0.673806 (0.117692)\n",
      "Testing 4144/4320\n",
      "5 4 3 log2 entropy False 500 112: Weighted 0.782434 (0.096994)\n",
      "5 4 3 log2 entropy False 500 112: Macro 0.673806 (0.117692)\n",
      "Testing 4145/4320\n",
      "5 4 3 sqrt gini True 50 112: Weighted 0.809159 (0.051727)\n",
      "5 4 3 sqrt gini True 50 112: Macro 0.699758 (0.066217)\n",
      "Testing 4146/4320\n",
      "5 4 3 sqrt gini True 100 112: Weighted 0.813733 (0.055258)\n",
      "5 4 3 sqrt gini True 100 112: Macro 0.706814 (0.073173)\n",
      "Testing 4147/4320\n",
      "5 4 3 sqrt gini True 200 112: Weighted 0.805355 (0.056442)\n",
      "5 4 3 sqrt gini True 200 112: Macro 0.695263 (0.075381)\n",
      "Testing 4148/4320\n",
      "5 4 3 sqrt gini True 500 112: Weighted 0.813941 (0.055478)\n",
      "5 4 3 sqrt gini True 500 112: Macro 0.709900 (0.075733)\n",
      "Testing 4149/4320\n",
      "5 4 3 sqrt gini False 50 112: Weighted 0.793563 (0.090270)\n",
      "5 4 3 sqrt gini False 50 112: Macro 0.688455 (0.112395)\n",
      "Testing 4150/4320\n",
      "5 4 3 sqrt gini False 100 112: Weighted 0.787362 (0.100409)\n",
      "5 4 3 sqrt gini False 100 112: Macro 0.681315 (0.123855)\n",
      "Testing 4151/4320\n",
      "5 4 3 sqrt gini False 200 112: Weighted 0.787362 (0.100409)\n",
      "5 4 3 sqrt gini False 200 112: Macro 0.681315 (0.123855)\n",
      "Testing 4152/4320\n",
      "5 4 3 sqrt gini False 500 112: Weighted 0.793563 (0.090270)\n",
      "5 4 3 sqrt gini False 500 112: Macro 0.688455 (0.112395)\n",
      "Testing 4153/4320\n",
      "5 4 3 sqrt entropy True 50 112: Weighted 0.809566 (0.061318)\n",
      "5 4 3 sqrt entropy True 50 112: Macro 0.707742 (0.078474)\n",
      "Testing 4154/4320\n",
      "5 4 3 sqrt entropy True 100 112: Weighted 0.818459 (0.060588)\n",
      "5 4 3 sqrt entropy True 100 112: Macro 0.720102 (0.078267)\n",
      "Testing 4155/4320\n",
      "5 4 3 sqrt entropy True 200 112: Weighted 0.813938 (0.055482)\n",
      "5 4 3 sqrt entropy True 200 112: Macro 0.713290 (0.071608)\n",
      "Testing 4156/4320\n",
      "5 4 3 sqrt entropy True 500 112: Weighted 0.814217 (0.055124)\n",
      "5 4 3 sqrt entropy True 500 112: Macro 0.711260 (0.074050)\n",
      "Testing 4157/4320\n",
      "5 4 3 sqrt entropy False 50 112: Weighted 0.781816 (0.098017)\n",
      "5 4 3 sqrt entropy False 50 112: Macro 0.673700 (0.117866)\n",
      "Testing 4158/4320\n",
      "5 4 3 sqrt entropy False 100 112: Weighted 0.782434 (0.096994)\n",
      "5 4 3 sqrt entropy False 100 112: Macro 0.673806 (0.117692)\n",
      "Testing 4159/4320\n",
      "5 4 3 sqrt entropy False 200 112: Weighted 0.782434 (0.096994)\n",
      "5 4 3 sqrt entropy False 200 112: Macro 0.673806 (0.117692)\n",
      "Testing 4160/4320\n",
      "5 4 3 sqrt entropy False 500 112: Weighted 0.782434 (0.096994)\n",
      "5 4 3 sqrt entropy False 500 112: Macro 0.673806 (0.117692)\n",
      "Testing 4161/4320\n",
      "5 4 5 log2 gini True 50 112: Weighted 0.810128 (0.066968)\n",
      "5 4 5 log2 gini True 50 112: Macro 0.701328 (0.086251)\n",
      "Testing 4162/4320\n",
      "5 4 5 log2 gini True 100 112: Weighted 0.809673 (0.062686)\n",
      "5 4 5 log2 gini True 100 112: Macro 0.701491 (0.081072)\n",
      "Testing 4163/4320\n",
      "5 4 5 log2 gini True 200 112: Weighted 0.813679 (0.057546)\n",
      "5 4 5 log2 gini True 200 112: Macro 0.706570 (0.074612)\n",
      "Testing 4164/4320\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 4 5 log2 gini True 500 112: Weighted 0.809673 (0.062686)\n",
      "5 4 5 log2 gini True 500 112: Macro 0.701491 (0.081072)\n",
      "Testing 4165/4320\n",
      "5 4 5 log2 gini False 50 112: Weighted 0.812352 (0.075646)\n",
      "5 4 5 log2 gini False 50 112: Macro 0.708254 (0.105698)\n",
      "Testing 4166/4320\n",
      "5 4 5 log2 gini False 100 112: Weighted 0.812352 (0.075646)\n",
      "5 4 5 log2 gini False 100 112: Macro 0.708254 (0.105698)\n",
      "Testing 4167/4320\n",
      "5 4 5 log2 gini False 200 112: Weighted 0.812352 (0.075646)\n",
      "5 4 5 log2 gini False 200 112: Macro 0.708254 (0.105698)\n",
      "Testing 4168/4320\n",
      "5 4 5 log2 gini False 500 112: Weighted 0.812352 (0.075646)\n",
      "5 4 5 log2 gini False 500 112: Macro 0.708254 (0.105698)\n",
      "Testing 4169/4320\n",
      "5 4 5 log2 entropy True 50 112: Weighted 0.810248 (0.071550)\n",
      "5 4 5 log2 entropy True 50 112: Macro 0.706418 (0.095851)\n",
      "Testing 4170/4320\n",
      "5 4 5 log2 entropy True 100 112: Weighted 0.805466 (0.068425)\n",
      "5 4 5 log2 entropy True 100 112: Macro 0.696277 (0.088124)\n",
      "Testing 4171/4320\n",
      "5 4 5 log2 entropy True 200 112: Weighted 0.817971 (0.064052)\n",
      "5 4 5 log2 entropy True 200 112: Macro 0.716589 (0.086105)\n",
      "Testing 4172/4320\n",
      "5 4 5 log2 entropy True 500 112: Weighted 0.813043 (0.061075)\n",
      "5 4 5 log2 entropy True 500 112: Macro 0.709081 (0.080344)\n",
      "Testing 4173/4320\n",
      "5 4 5 log2 entropy False 50 112: Weighted 0.808837 (0.067164)\n",
      "5 4 5 log2 entropy False 50 112: Macro 0.703868 (0.087906)\n",
      "Testing 4174/4320\n",
      "5 4 5 log2 entropy False 100 112: Weighted 0.799789 (0.070916)\n",
      "5 4 5 log2 entropy False 100 112: Macro 0.687770 (0.096874)\n",
      "Testing 4175/4320\n",
      "5 4 5 log2 entropy False 200 112: Weighted 0.799789 (0.070916)\n",
      "5 4 5 log2 entropy False 200 112: Macro 0.687770 (0.096874)\n",
      "Testing 4176/4320\n",
      "5 4 5 log2 entropy False 500 112: Weighted 0.799789 (0.070916)\n",
      "5 4 5 log2 entropy False 500 112: Macro 0.687770 (0.096874)\n",
      "Testing 4177/4320\n",
      "5 4 5 sqrt gini True 50 112: Weighted 0.810128 (0.066968)\n",
      "5 4 5 sqrt gini True 50 112: Macro 0.701328 (0.086251)\n",
      "Testing 4178/4320\n",
      "5 4 5 sqrt gini True 100 112: Weighted 0.809673 (0.062686)\n",
      "5 4 5 sqrt gini True 100 112: Macro 0.701491 (0.081072)\n",
      "Testing 4179/4320\n",
      "5 4 5 sqrt gini True 200 112: Weighted 0.813679 (0.057546)\n",
      "5 4 5 sqrt gini True 200 112: Macro 0.706570 (0.074612)\n",
      "Testing 4180/4320\n",
      "5 4 5 sqrt gini True 500 112: Weighted 0.809673 (0.062686)\n",
      "5 4 5 sqrt gini True 500 112: Macro 0.701491 (0.081072)\n",
      "Testing 4181/4320\n",
      "5 4 5 sqrt gini False 50 112: Weighted 0.812352 (0.075646)\n",
      "5 4 5 sqrt gini False 50 112: Macro 0.708254 (0.105698)\n",
      "Testing 4182/4320\n",
      "5 4 5 sqrt gini False 100 112: Weighted 0.812352 (0.075646)\n",
      "5 4 5 sqrt gini False 100 112: Macro 0.708254 (0.105698)\n",
      "Testing 4183/4320\n",
      "5 4 5 sqrt gini False 200 112: Weighted 0.812352 (0.075646)\n",
      "5 4 5 sqrt gini False 200 112: Macro 0.708254 (0.105698)\n",
      "Testing 4184/4320\n",
      "5 4 5 sqrt gini False 500 112: Weighted 0.812352 (0.075646)\n",
      "5 4 5 sqrt gini False 500 112: Macro 0.708254 (0.105698)\n",
      "Testing 4185/4320\n",
      "5 4 5 sqrt entropy True 50 112: Weighted 0.810248 (0.071550)\n",
      "5 4 5 sqrt entropy True 50 112: Macro 0.706418 (0.095851)\n",
      "Testing 4186/4320\n",
      "5 4 5 sqrt entropy True 100 112: Weighted 0.805466 (0.068425)\n",
      "5 4 5 sqrt entropy True 100 112: Macro 0.696277 (0.088124)\n",
      "Testing 4187/4320\n",
      "5 4 5 sqrt entropy True 200 112: Weighted 0.817971 (0.064052)\n",
      "5 4 5 sqrt entropy True 200 112: Macro 0.716589 (0.086105)\n",
      "Testing 4188/4320\n",
      "5 4 5 sqrt entropy True 500 112: Weighted 0.813043 (0.061075)\n",
      "5 4 5 sqrt entropy True 500 112: Macro 0.709081 (0.080344)\n",
      "Testing 4189/4320\n",
      "5 4 5 sqrt entropy False 50 112: Weighted 0.808837 (0.067164)\n",
      "5 4 5 sqrt entropy False 50 112: Macro 0.703868 (0.087906)\n",
      "Testing 4190/4320\n",
      "5 4 5 sqrt entropy False 100 112: Weighted 0.799789 (0.070916)\n",
      "5 4 5 sqrt entropy False 100 112: Macro 0.687770 (0.096874)\n",
      "Testing 4191/4320\n",
      "5 4 5 sqrt entropy False 200 112: Weighted 0.799789 (0.070916)\n",
      "5 4 5 sqrt entropy False 200 112: Macro 0.687770 (0.096874)\n",
      "Testing 4192/4320\n",
      "5 4 5 sqrt entropy False 500 112: Weighted 0.799789 (0.070916)\n",
      "5 4 5 sqrt entropy False 500 112: Macro 0.687770 (0.096874)\n",
      "Testing 4193/4320\n",
      "5 4 8 log2 gini True 50 112: Weighted 0.821873 (0.058393)\n",
      "5 4 8 log2 gini True 50 112: Macro 0.718885 (0.076736)\n",
      "Testing 4194/4320\n",
      "5 4 8 log2 gini True 100 112: Weighted 0.817348 (0.061213)\n",
      "5 4 8 log2 gini True 100 112: Macro 0.713983 (0.079868)\n",
      "Testing 4195/4320\n",
      "5 4 8 log2 gini True 200 112: Weighted 0.820658 (0.062157)\n",
      "5 4 8 log2 gini True 200 112: Macro 0.718752 (0.080918)\n",
      "Testing 4196/4320\n",
      "5 4 8 log2 gini True 500 112: Weighted 0.817093 (0.064326)\n",
      "5 4 8 log2 gini True 500 112: Macro 0.713587 (0.084003)\n",
      "Testing 4197/4320\n",
      "5 4 8 log2 gini False 50 112: Weighted 0.809765 (0.073972)\n",
      "5 4 8 log2 gini False 50 112: Macro 0.700308 (0.102686)\n",
      "Testing 4198/4320\n",
      "5 4 8 log2 gini False 100 112: Weighted 0.809765 (0.073972)\n",
      "5 4 8 log2 gini False 100 112: Macro 0.700308 (0.102686)\n",
      "Testing 4199/4320\n",
      "5 4 8 log2 gini False 200 112: Weighted 0.804369 (0.068699)\n",
      "5 4 8 log2 gini False 200 112: Macro 0.695110 (0.095284)\n",
      "Testing 4200/4320\n",
      "5 4 8 log2 gini False 500 112: Weighted 0.804333 (0.068679)\n",
      "5 4 8 log2 gini False 500 112: Macro 0.693402 (0.094129)\n",
      "Testing 4201/4320\n",
      "5 4 8 log2 entropy True 50 112: Weighted 0.808663 (0.063229)\n",
      "5 4 8 log2 entropy True 50 112: Macro 0.701546 (0.081041)\n",
      "Testing 4202/4320\n",
      "5 4 8 log2 entropy True 100 112: Weighted 0.812670 (0.058207)\n",
      "5 4 8 log2 entropy True 100 112: Macro 0.706626 (0.074574)\n",
      "Testing 4203/4320\n",
      "5 4 8 log2 entropy True 200 112: Weighted 0.817093 (0.064326)\n",
      "5 4 8 log2 entropy True 200 112: Macro 0.713587 (0.084003)\n",
      "Testing 4204/4320\n",
      "5 4 8 log2 entropy True 500 112: Weighted 0.813086 (0.069160)\n",
      "5 4 8 log2 entropy True 500 112: Macro 0.708508 (0.090186)\n",
      "Testing 4205/4320\n",
      "5 4 8 log2 entropy False 50 112: Weighted 0.796836 (0.067663)\n",
      "5 4 8 log2 entropy False 50 112: Macro 0.685043 (0.087182)\n",
      "Testing 4206/4320\n",
      "5 4 8 log2 entropy False 100 112: Weighted 0.795264 (0.071879)\n",
      "5 4 8 log2 entropy False 100 112: Macro 0.682868 (0.097827)\n",
      "Testing 4207/4320\n",
      "5 4 8 log2 entropy False 200 112: Weighted 0.799284 (0.066331)\n",
      "5 4 8 log2 entropy False 200 112: Macro 0.687687 (0.090862)\n",
      "Testing 4208/4320\n",
      "5 4 8 log2 entropy False 500 112: Weighted 0.799284 (0.066331)\n",
      "5 4 8 log2 entropy False 500 112: Macro 0.687687 (0.090862)\n",
      "Testing 4209/4320\n",
      "5 4 8 sqrt gini True 50 112: Weighted 0.821873 (0.058393)\n",
      "5 4 8 sqrt gini True 50 112: Macro 0.718885 (0.076736)\n",
      "Testing 4210/4320\n",
      "5 4 8 sqrt gini True 100 112: Weighted 0.817348 (0.061213)\n",
      "5 4 8 sqrt gini True 100 112: Macro 0.713983 (0.079868)\n",
      "Testing 4211/4320\n",
      "5 4 8 sqrt gini True 200 112: Weighted 0.820658 (0.062157)\n",
      "5 4 8 sqrt gini True 200 112: Macro 0.718752 (0.080918)\n",
      "Testing 4212/4320\n",
      "5 4 8 sqrt gini True 500 112: Weighted 0.817093 (0.064326)\n",
      "5 4 8 sqrt gini True 500 112: Macro 0.713587 (0.084003)\n",
      "Testing 4213/4320\n",
      "5 4 8 sqrt gini False 50 112: Weighted 0.809765 (0.073972)\n",
      "5 4 8 sqrt gini False 50 112: Macro 0.700308 (0.102686)\n",
      "Testing 4214/4320\n",
      "5 4 8 sqrt gini False 100 112: Weighted 0.809765 (0.073972)\n",
      "5 4 8 sqrt gini False 100 112: Macro 0.700308 (0.102686)\n",
      "Testing 4215/4320\n",
      "5 4 8 sqrt gini False 200 112: Weighted 0.804369 (0.068699)\n",
      "5 4 8 sqrt gini False 200 112: Macro 0.695110 (0.095284)\n",
      "Testing 4216/4320\n",
      "5 4 8 sqrt gini False 500 112: Weighted 0.804333 (0.068679)\n",
      "5 4 8 sqrt gini False 500 112: Macro 0.693402 (0.094129)\n",
      "Testing 4217/4320\n",
      "5 4 8 sqrt entropy True 50 112: Weighted 0.808663 (0.063229)\n",
      "5 4 8 sqrt entropy True 50 112: Macro 0.701546 (0.081041)\n",
      "Testing 4218/4320\n",
      "5 4 8 sqrt entropy True 100 112: Weighted 0.812670 (0.058207)\n",
      "5 4 8 sqrt entropy True 100 112: Macro 0.706626 (0.074574)\n",
      "Testing 4219/4320\n",
      "5 4 8 sqrt entropy True 200 112: Weighted 0.817093 (0.064326)\n",
      "5 4 8 sqrt entropy True 200 112: Macro 0.713587 (0.084003)\n",
      "Testing 4220/4320\n",
      "5 4 8 sqrt entropy True 500 112: Weighted 0.813086 (0.069160)\n",
      "5 4 8 sqrt entropy True 500 112: Macro 0.708508 (0.090186)\n",
      "Testing 4221/4320\n",
      "5 4 8 sqrt entropy False 50 112: Weighted 0.796836 (0.067663)\n",
      "5 4 8 sqrt entropy False 50 112: Macro 0.685043 (0.087182)\n",
      "Testing 4222/4320\n",
      "5 4 8 sqrt entropy False 100 112: Weighted 0.795264 (0.071879)\n",
      "5 4 8 sqrt entropy False 100 112: Macro 0.682868 (0.097827)\n",
      "Testing 4223/4320\n",
      "5 4 8 sqrt entropy False 200 112: Weighted 0.799284 (0.066331)\n",
      "5 4 8 sqrt entropy False 200 112: Macro 0.687687 (0.090862)\n",
      "Testing 4224/4320\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 4 8 sqrt entropy False 500 112: Weighted 0.799284 (0.066331)\n",
      "5 4 8 sqrt entropy False 500 112: Macro 0.687687 (0.090862)\n",
      "Testing 4225/4320\n",
      "5 6 3 log2 gini True 50 112: Weighted 0.809159 (0.051727)\n",
      "5 6 3 log2 gini True 50 112: Macro 0.699758 (0.066217)\n",
      "Testing 4226/4320\n",
      "5 6 3 log2 gini True 100 112: Weighted 0.813733 (0.055258)\n",
      "5 6 3 log2 gini True 100 112: Macro 0.706814 (0.073173)\n",
      "Testing 4227/4320\n",
      "5 6 3 log2 gini True 200 112: Weighted 0.805355 (0.056442)\n",
      "5 6 3 log2 gini True 200 112: Macro 0.695263 (0.075381)\n",
      "Testing 4228/4320\n",
      "5 6 3 log2 gini True 500 112: Weighted 0.813941 (0.055478)\n",
      "5 6 3 log2 gini True 500 112: Macro 0.709900 (0.075733)\n",
      "Testing 4229/4320\n",
      "5 6 3 log2 gini False 50 112: Weighted 0.793563 (0.090270)\n",
      "5 6 3 log2 gini False 50 112: Macro 0.688455 (0.112395)\n",
      "Testing 4230/4320\n",
      "5 6 3 log2 gini False 100 112: Weighted 0.787362 (0.100409)\n",
      "5 6 3 log2 gini False 100 112: Macro 0.681315 (0.123855)\n",
      "Testing 4231/4320\n",
      "5 6 3 log2 gini False 200 112: Weighted 0.787362 (0.100409)\n",
      "5 6 3 log2 gini False 200 112: Macro 0.681315 (0.123855)\n",
      "Testing 4232/4320\n",
      "5 6 3 log2 gini False 500 112: Weighted 0.793563 (0.090270)\n",
      "5 6 3 log2 gini False 500 112: Macro 0.688455 (0.112395)\n",
      "Testing 4233/4320\n",
      "5 6 3 log2 entropy True 50 112: Weighted 0.809566 (0.061318)\n",
      "5 6 3 log2 entropy True 50 112: Macro 0.707742 (0.078474)\n",
      "Testing 4234/4320\n",
      "5 6 3 log2 entropy True 100 112: Weighted 0.818459 (0.060588)\n",
      "5 6 3 log2 entropy True 100 112: Macro 0.720102 (0.078267)\n",
      "Testing 4235/4320\n",
      "5 6 3 log2 entropy True 200 112: Weighted 0.813938 (0.055482)\n",
      "5 6 3 log2 entropy True 200 112: Macro 0.713290 (0.071608)\n",
      "Testing 4236/4320\n",
      "5 6 3 log2 entropy True 500 112: Weighted 0.814217 (0.055124)\n",
      "5 6 3 log2 entropy True 500 112: Macro 0.711260 (0.074050)\n",
      "Testing 4237/4320\n",
      "5 6 3 log2 entropy False 50 112: Weighted 0.781816 (0.098017)\n",
      "5 6 3 log2 entropy False 50 112: Macro 0.673700 (0.117866)\n",
      "Testing 4238/4320\n",
      "5 6 3 log2 entropy False 100 112: Weighted 0.782434 (0.096994)\n",
      "5 6 3 log2 entropy False 100 112: Macro 0.673806 (0.117692)\n",
      "Testing 4239/4320\n",
      "5 6 3 log2 entropy False 200 112: Weighted 0.782434 (0.096994)\n",
      "5 6 3 log2 entropy False 200 112: Macro 0.673806 (0.117692)\n",
      "Testing 4240/4320\n",
      "5 6 3 log2 entropy False 500 112: Weighted 0.782434 (0.096994)\n",
      "5 6 3 log2 entropy False 500 112: Macro 0.673806 (0.117692)\n",
      "Testing 4241/4320\n",
      "5 6 3 sqrt gini True 50 112: Weighted 0.809159 (0.051727)\n",
      "5 6 3 sqrt gini True 50 112: Macro 0.699758 (0.066217)\n",
      "Testing 4242/4320\n",
      "5 6 3 sqrt gini True 100 112: Weighted 0.813733 (0.055258)\n",
      "5 6 3 sqrt gini True 100 112: Macro 0.706814 (0.073173)\n",
      "Testing 4243/4320\n",
      "5 6 3 sqrt gini True 200 112: Weighted 0.805355 (0.056442)\n",
      "5 6 3 sqrt gini True 200 112: Macro 0.695263 (0.075381)\n",
      "Testing 4244/4320\n",
      "5 6 3 sqrt gini True 500 112: Weighted 0.813941 (0.055478)\n",
      "5 6 3 sqrt gini True 500 112: Macro 0.709900 (0.075733)\n",
      "Testing 4245/4320\n",
      "5 6 3 sqrt gini False 50 112: Weighted 0.793563 (0.090270)\n",
      "5 6 3 sqrt gini False 50 112: Macro 0.688455 (0.112395)\n",
      "Testing 4246/4320\n",
      "5 6 3 sqrt gini False 100 112: Weighted 0.787362 (0.100409)\n",
      "5 6 3 sqrt gini False 100 112: Macro 0.681315 (0.123855)\n",
      "Testing 4247/4320\n",
      "5 6 3 sqrt gini False 200 112: Weighted 0.787362 (0.100409)\n",
      "5 6 3 sqrt gini False 200 112: Macro 0.681315 (0.123855)\n",
      "Testing 4248/4320\n",
      "5 6 3 sqrt gini False 500 112: Weighted 0.793563 (0.090270)\n",
      "5 6 3 sqrt gini False 500 112: Macro 0.688455 (0.112395)\n",
      "Testing 4249/4320\n",
      "5 6 3 sqrt entropy True 50 112: Weighted 0.809566 (0.061318)\n",
      "5 6 3 sqrt entropy True 50 112: Macro 0.707742 (0.078474)\n",
      "Testing 4250/4320\n",
      "5 6 3 sqrt entropy True 100 112: Weighted 0.818459 (0.060588)\n",
      "5 6 3 sqrt entropy True 100 112: Macro 0.720102 (0.078267)\n",
      "Testing 4251/4320\n",
      "5 6 3 sqrt entropy True 200 112: Weighted 0.813938 (0.055482)\n",
      "5 6 3 sqrt entropy True 200 112: Macro 0.713290 (0.071608)\n",
      "Testing 4252/4320\n",
      "5 6 3 sqrt entropy True 500 112: Weighted 0.814217 (0.055124)\n",
      "5 6 3 sqrt entropy True 500 112: Macro 0.711260 (0.074050)\n",
      "Testing 4253/4320\n",
      "5 6 3 sqrt entropy False 50 112: Weighted 0.781816 (0.098017)\n",
      "5 6 3 sqrt entropy False 50 112: Macro 0.673700 (0.117866)\n",
      "Testing 4254/4320\n",
      "5 6 3 sqrt entropy False 100 112: Weighted 0.782434 (0.096994)\n",
      "5 6 3 sqrt entropy False 100 112: Macro 0.673806 (0.117692)\n",
      "Testing 4255/4320\n",
      "5 6 3 sqrt entropy False 200 112: Weighted 0.782434 (0.096994)\n",
      "5 6 3 sqrt entropy False 200 112: Macro 0.673806 (0.117692)\n",
      "Testing 4256/4320\n",
      "5 6 3 sqrt entropy False 500 112: Weighted 0.782434 (0.096994)\n",
      "5 6 3 sqrt entropy False 500 112: Macro 0.673806 (0.117692)\n",
      "Testing 4257/4320\n",
      "5 6 5 log2 gini True 50 112: Weighted 0.810128 (0.066968)\n",
      "5 6 5 log2 gini True 50 112: Macro 0.701328 (0.086251)\n",
      "Testing 4258/4320\n",
      "5 6 5 log2 gini True 100 112: Weighted 0.809673 (0.062686)\n",
      "5 6 5 log2 gini True 100 112: Macro 0.701491 (0.081072)\n",
      "Testing 4259/4320\n",
      "5 6 5 log2 gini True 200 112: Weighted 0.813679 (0.057546)\n",
      "5 6 5 log2 gini True 200 112: Macro 0.706570 (0.074612)\n",
      "Testing 4260/4320\n",
      "5 6 5 log2 gini True 500 112: Weighted 0.809673 (0.062686)\n",
      "5 6 5 log2 gini True 500 112: Macro 0.701491 (0.081072)\n",
      "Testing 4261/4320\n",
      "5 6 5 log2 gini False 50 112: Weighted 0.812352 (0.075646)\n",
      "5 6 5 log2 gini False 50 112: Macro 0.708254 (0.105698)\n",
      "Testing 4262/4320\n",
      "5 6 5 log2 gini False 100 112: Weighted 0.812352 (0.075646)\n",
      "5 6 5 log2 gini False 100 112: Macro 0.708254 (0.105698)\n",
      "Testing 4263/4320\n",
      "5 6 5 log2 gini False 200 112: Weighted 0.812352 (0.075646)\n",
      "5 6 5 log2 gini False 200 112: Macro 0.708254 (0.105698)\n",
      "Testing 4264/4320\n",
      "5 6 5 log2 gini False 500 112: Weighted 0.812352 (0.075646)\n",
      "5 6 5 log2 gini False 500 112: Macro 0.708254 (0.105698)\n",
      "Testing 4265/4320\n",
      "5 6 5 log2 entropy True 50 112: Weighted 0.810248 (0.071550)\n",
      "5 6 5 log2 entropy True 50 112: Macro 0.706418 (0.095851)\n",
      "Testing 4266/4320\n",
      "5 6 5 log2 entropy True 100 112: Weighted 0.805466 (0.068425)\n",
      "5 6 5 log2 entropy True 100 112: Macro 0.696277 (0.088124)\n",
      "Testing 4267/4320\n",
      "5 6 5 log2 entropy True 200 112: Weighted 0.817971 (0.064052)\n",
      "5 6 5 log2 entropy True 200 112: Macro 0.716589 (0.086105)\n",
      "Testing 4268/4320\n",
      "5 6 5 log2 entropy True 500 112: Weighted 0.813043 (0.061075)\n",
      "5 6 5 log2 entropy True 500 112: Macro 0.709081 (0.080344)\n",
      "Testing 4269/4320\n",
      "5 6 5 log2 entropy False 50 112: Weighted 0.808837 (0.067164)\n",
      "5 6 5 log2 entropy False 50 112: Macro 0.703868 (0.087906)\n",
      "Testing 4270/4320\n",
      "5 6 5 log2 entropy False 100 112: Weighted 0.799789 (0.070916)\n",
      "5 6 5 log2 entropy False 100 112: Macro 0.687770 (0.096874)\n",
      "Testing 4271/4320\n",
      "5 6 5 log2 entropy False 200 112: Weighted 0.799789 (0.070916)\n",
      "5 6 5 log2 entropy False 200 112: Macro 0.687770 (0.096874)\n",
      "Testing 4272/4320\n",
      "5 6 5 log2 entropy False 500 112: Weighted 0.799789 (0.070916)\n",
      "5 6 5 log2 entropy False 500 112: Macro 0.687770 (0.096874)\n",
      "Testing 4273/4320\n",
      "5 6 5 sqrt gini True 50 112: Weighted 0.810128 (0.066968)\n",
      "5 6 5 sqrt gini True 50 112: Macro 0.701328 (0.086251)\n",
      "Testing 4274/4320\n",
      "5 6 5 sqrt gini True 100 112: Weighted 0.809673 (0.062686)\n",
      "5 6 5 sqrt gini True 100 112: Macro 0.701491 (0.081072)\n",
      "Testing 4275/4320\n",
      "5 6 5 sqrt gini True 200 112: Weighted 0.813679 (0.057546)\n",
      "5 6 5 sqrt gini True 200 112: Macro 0.706570 (0.074612)\n",
      "Testing 4276/4320\n",
      "5 6 5 sqrt gini True 500 112: Weighted 0.809673 (0.062686)\n",
      "5 6 5 sqrt gini True 500 112: Macro 0.701491 (0.081072)\n",
      "Testing 4277/4320\n",
      "5 6 5 sqrt gini False 50 112: Weighted 0.812352 (0.075646)\n",
      "5 6 5 sqrt gini False 50 112: Macro 0.708254 (0.105698)\n",
      "Testing 4278/4320\n",
      "5 6 5 sqrt gini False 100 112: Weighted 0.812352 (0.075646)\n",
      "5 6 5 sqrt gini False 100 112: Macro 0.708254 (0.105698)\n",
      "Testing 4279/4320\n",
      "5 6 5 sqrt gini False 200 112: Weighted 0.812352 (0.075646)\n",
      "5 6 5 sqrt gini False 200 112: Macro 0.708254 (0.105698)\n",
      "Testing 4280/4320\n",
      "5 6 5 sqrt gini False 500 112: Weighted 0.812352 (0.075646)\n",
      "5 6 5 sqrt gini False 500 112: Macro 0.708254 (0.105698)\n",
      "Testing 4281/4320\n",
      "5 6 5 sqrt entropy True 50 112: Weighted 0.810248 (0.071550)\n",
      "5 6 5 sqrt entropy True 50 112: Macro 0.706418 (0.095851)\n",
      "Testing 4282/4320\n",
      "5 6 5 sqrt entropy True 100 112: Weighted 0.805466 (0.068425)\n",
      "5 6 5 sqrt entropy True 100 112: Macro 0.696277 (0.088124)\n",
      "Testing 4283/4320\n",
      "5 6 5 sqrt entropy True 200 112: Weighted 0.817971 (0.064052)\n",
      "5 6 5 sqrt entropy True 200 112: Macro 0.716589 (0.086105)\n",
      "Testing 4284/4320\n",
      "5 6 5 sqrt entropy True 500 112: Weighted 0.813043 (0.061075)\n",
      "5 6 5 sqrt entropy True 500 112: Macro 0.709081 (0.080344)\n",
      "Testing 4285/4320\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 6 5 sqrt entropy False 50 112: Weighted 0.808837 (0.067164)\n",
      "5 6 5 sqrt entropy False 50 112: Macro 0.703868 (0.087906)\n",
      "Testing 4286/4320\n",
      "5 6 5 sqrt entropy False 100 112: Weighted 0.799789 (0.070916)\n",
      "5 6 5 sqrt entropy False 100 112: Macro 0.687770 (0.096874)\n",
      "Testing 4287/4320\n",
      "5 6 5 sqrt entropy False 200 112: Weighted 0.799789 (0.070916)\n",
      "5 6 5 sqrt entropy False 200 112: Macro 0.687770 (0.096874)\n",
      "Testing 4288/4320\n",
      "5 6 5 sqrt entropy False 500 112: Weighted 0.799789 (0.070916)\n",
      "5 6 5 sqrt entropy False 500 112: Macro 0.687770 (0.096874)\n",
      "Testing 4289/4320\n",
      "5 6 8 log2 gini True 50 112: Weighted 0.821873 (0.058393)\n",
      "5 6 8 log2 gini True 50 112: Macro 0.718885 (0.076736)\n",
      "Testing 4290/4320\n",
      "5 6 8 log2 gini True 100 112: Weighted 0.817348 (0.061213)\n",
      "5 6 8 log2 gini True 100 112: Macro 0.713983 (0.079868)\n",
      "Testing 4291/4320\n",
      "5 6 8 log2 gini True 200 112: Weighted 0.820658 (0.062157)\n",
      "5 6 8 log2 gini True 200 112: Macro 0.718752 (0.080918)\n",
      "Testing 4292/4320\n",
      "5 6 8 log2 gini True 500 112: Weighted 0.817093 (0.064326)\n",
      "5 6 8 log2 gini True 500 112: Macro 0.713587 (0.084003)\n",
      "Testing 4293/4320\n",
      "5 6 8 log2 gini False 50 112: Weighted 0.809765 (0.073972)\n",
      "5 6 8 log2 gini False 50 112: Macro 0.700308 (0.102686)\n",
      "Testing 4294/4320\n",
      "5 6 8 log2 gini False 100 112: Weighted 0.809765 (0.073972)\n",
      "5 6 8 log2 gini False 100 112: Macro 0.700308 (0.102686)\n",
      "Testing 4295/4320\n",
      "5 6 8 log2 gini False 200 112: Weighted 0.804369 (0.068699)\n",
      "5 6 8 log2 gini False 200 112: Macro 0.695110 (0.095284)\n",
      "Testing 4296/4320\n",
      "5 6 8 log2 gini False 500 112: Weighted 0.804333 (0.068679)\n",
      "5 6 8 log2 gini False 500 112: Macro 0.693402 (0.094129)\n",
      "Testing 4297/4320\n",
      "5 6 8 log2 entropy True 50 112: Weighted 0.808663 (0.063229)\n",
      "5 6 8 log2 entropy True 50 112: Macro 0.701546 (0.081041)\n",
      "Testing 4298/4320\n",
      "5 6 8 log2 entropy True 100 112: Weighted 0.812670 (0.058207)\n",
      "5 6 8 log2 entropy True 100 112: Macro 0.706626 (0.074574)\n",
      "Testing 4299/4320\n",
      "5 6 8 log2 entropy True 200 112: Weighted 0.817093 (0.064326)\n",
      "5 6 8 log2 entropy True 200 112: Macro 0.713587 (0.084003)\n",
      "Testing 4300/4320\n",
      "5 6 8 log2 entropy True 500 112: Weighted 0.813086 (0.069160)\n",
      "5 6 8 log2 entropy True 500 112: Macro 0.708508 (0.090186)\n",
      "Testing 4301/4320\n",
      "5 6 8 log2 entropy False 50 112: Weighted 0.796836 (0.067663)\n",
      "5 6 8 log2 entropy False 50 112: Macro 0.685043 (0.087182)\n",
      "Testing 4302/4320\n",
      "5 6 8 log2 entropy False 100 112: Weighted 0.795264 (0.071879)\n",
      "5 6 8 log2 entropy False 100 112: Macro 0.682868 (0.097827)\n",
      "Testing 4303/4320\n",
      "5 6 8 log2 entropy False 200 112: Weighted 0.799284 (0.066331)\n",
      "5 6 8 log2 entropy False 200 112: Macro 0.687687 (0.090862)\n",
      "Testing 4304/4320\n",
      "5 6 8 log2 entropy False 500 112: Weighted 0.799284 (0.066331)\n",
      "5 6 8 log2 entropy False 500 112: Macro 0.687687 (0.090862)\n",
      "Testing 4305/4320\n",
      "5 6 8 sqrt gini True 50 112: Weighted 0.821873 (0.058393)\n",
      "5 6 8 sqrt gini True 50 112: Macro 0.718885 (0.076736)\n",
      "Testing 4306/4320\n",
      "5 6 8 sqrt gini True 100 112: Weighted 0.817348 (0.061213)\n",
      "5 6 8 sqrt gini True 100 112: Macro 0.713983 (0.079868)\n",
      "Testing 4307/4320\n",
      "5 6 8 sqrt gini True 200 112: Weighted 0.820658 (0.062157)\n",
      "5 6 8 sqrt gini True 200 112: Macro 0.718752 (0.080918)\n",
      "Testing 4308/4320\n",
      "5 6 8 sqrt gini True 500 112: Weighted 0.817093 (0.064326)\n",
      "5 6 8 sqrt gini True 500 112: Macro 0.713587 (0.084003)\n",
      "Testing 4309/4320\n",
      "5 6 8 sqrt gini False 50 112: Weighted 0.809765 (0.073972)\n",
      "5 6 8 sqrt gini False 50 112: Macro 0.700308 (0.102686)\n",
      "Testing 4310/4320\n",
      "5 6 8 sqrt gini False 100 112: Weighted 0.809765 (0.073972)\n",
      "5 6 8 sqrt gini False 100 112: Macro 0.700308 (0.102686)\n",
      "Testing 4311/4320\n",
      "5 6 8 sqrt gini False 200 112: Weighted 0.804369 (0.068699)\n",
      "5 6 8 sqrt gini False 200 112: Macro 0.695110 (0.095284)\n",
      "Testing 4312/4320\n",
      "5 6 8 sqrt gini False 500 112: Weighted 0.804333 (0.068679)\n",
      "5 6 8 sqrt gini False 500 112: Macro 0.693402 (0.094129)\n",
      "Testing 4313/4320\n",
      "5 6 8 sqrt entropy True 50 112: Weighted 0.808663 (0.063229)\n",
      "5 6 8 sqrt entropy True 50 112: Macro 0.701546 (0.081041)\n",
      "Testing 4314/4320\n",
      "5 6 8 sqrt entropy True 100 112: Weighted 0.812670 (0.058207)\n",
      "5 6 8 sqrt entropy True 100 112: Macro 0.706626 (0.074574)\n",
      "Testing 4315/4320\n",
      "5 6 8 sqrt entropy True 200 112: Weighted 0.817093 (0.064326)\n",
      "5 6 8 sqrt entropy True 200 112: Macro 0.713587 (0.084003)\n",
      "Testing 4316/4320\n",
      "5 6 8 sqrt entropy True 500 112: Weighted 0.813086 (0.069160)\n",
      "5 6 8 sqrt entropy True 500 112: Macro 0.708508 (0.090186)\n",
      "Testing 4317/4320\n",
      "5 6 8 sqrt entropy False 50 112: Weighted 0.796836 (0.067663)\n",
      "5 6 8 sqrt entropy False 50 112: Macro 0.685043 (0.087182)\n",
      "Testing 4318/4320\n",
      "5 6 8 sqrt entropy False 100 112: Weighted 0.795264 (0.071879)\n",
      "5 6 8 sqrt entropy False 100 112: Macro 0.682868 (0.097827)\n",
      "Testing 4319/4320\n",
      "5 6 8 sqrt entropy False 200 112: Weighted 0.799284 (0.066331)\n",
      "5 6 8 sqrt entropy False 200 112: Macro 0.687687 (0.090862)\n",
      "Testing 4320/4320\n",
      "5 6 8 sqrt entropy False 500 112: Weighted 0.799284 (0.066331)\n",
      "5 6 8 sqrt entropy False 500 112: Macro 0.687687 (0.090862)\n"
     ]
    }
   ],
   "source": [
    "results_weighted = []\n",
    "results_macro = []\n",
    "names = []\n",
    "num_tests = 5*3*3*3*2*2*2*4\n",
    "i = 1\n",
    "\n",
    "for random_state in [17, 29, 42, 76, 112]:\n",
    "    for min_samples_leaf in [1,3,5]:\n",
    "        for min_samples_split in [2,4,6]:\n",
    "            for max_depth in [3,5,8]:\n",
    "                for max_features in [\"log2\",\"sqrt\"]:\n",
    "                    for criterion in [\"gini\",  \"entropy\"]:\n",
    "                        for bootstrap in [True, False]:\n",
    "                            for n_estimators in [50, 100, 200, 500]:\n",
    "                                print(\"Testing {}/{}\".format(i,num_tests))\n",
    "                                i+=1\n",
    "                                kf = StratifiedKFold(n_splits=num_folds, random_state=seed)\n",
    "                                sm = SMOTE(random_state=seed, k_neighbors=7, sampling_strategy=\"not majority\")\n",
    "                                cv_results_weighted = np.array([])\n",
    "                                cv_results_macro = np.array([])\n",
    "                                for train_idx, test_idx, in kf.split(X_train, y_train):\n",
    "                                    X_cross_train, y_cross_train = X_train.iloc[train_idx], y_train.iloc[train_idx]\n",
    "                                    X_cross_test, y_cross_test = X_train.iloc[test_idx], y_train.iloc[test_idx]\n",
    "                                    X_cross_train, y_cross_train = sm.fit_sample(X_cross_train, y_cross_train)\n",
    "                                    model = RandomForestClassifier(min_samples_leaf=min_samples_leaf, random_state=random_state, \n",
    "                                            min_samples_split=min_samples_split, max_depth=max_depth, max_features=max_features,                           \n",
    "                                            criterion=criterion, bootstrap=bootstrap, n_estimators=n_estimators)\n",
    "                                    model.fit(X_cross_train, y_cross_train)  \n",
    "                                    y_pred = model.predict(X_cross_test)\n",
    "                                    f1s_weight = f1_score(y_cross_test, y_pred, average=\"weighted\")\n",
    "                                    f1s_macro = f1_score(y_cross_test, y_pred, average=\"macro\")\n",
    "                                    cv_results_weighted = np.append(cv_results_weighted, [f1s_weight])\n",
    "                                    cv_results_macro = np.append(cv_results_macro, [f1s_macro])\n",
    "                                results_weighted.append(cv_results_weighted)\n",
    "                                results_macro.append(cv_results_macro)\n",
    "                                name = \"{} {} {} {} {} {} {} {}\".format(min_samples_leaf, min_samples_split, max_depth, \n",
    "                                    max_features, criterion, bootstrap, n_estimators, random_state)\n",
    "                                names.append(name)\n",
    "                                msg = \"%s: Weighted %f (%f)\" % (name, cv_results_weighted.mean(), cv_results_weighted.std())\n",
    "                                print(msg)\n",
    "                                msg = \"%s: Macro %f (%f)\" % (name, cv_results_macro.mean(), cv_results_macro.std())\n",
    "                                print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('names.pkl', 'wb') as f:\n",
    "    pickle.dump(names, f)\n",
    "with open('results_weighted.pkl', 'wb') as f:\n",
    "    pickle.dump(results_weighted, f)\n",
    "with open('results_macro.pkl', 'wb') as f:\n",
    "    pickle.dump(results_macro, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 2 5 log2 entropy True 200 42 - Weighted: 0.7291046413589981 - Normal: 0.8249443320486309\n"
     ]
    }
   ],
   "source": [
    "avg_values_macro = [np.average(item) for item in results_macro]\n",
    "avg_values_weighted = [np.average(item) for item in results_weighted]\n",
    "max_index = avg_values_macro.index(max(avg_values_macro))\n",
    "print(\"{} - Weighted: {} - Normal: {}\".format(names[max_index], avg_values_macro[max_index], avg_values_weighted[max_index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(min_samples_leaf=5, min_samples_split= 2, max_depth=2, max_features=\"log2\", \n",
    "                                   criterion='entropy',  bootstrap=True ,  n_estimators=200, random_state=42)\n",
    "\n",
    "pipeline = Pipeline([('Scaler', StandardScaler()),('Model', model)])\n",
    "\n",
    "pipeline.fit(X_train_res, y_train_res) \n",
    "\n",
    "y_pred = pipeline.predict(X_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1fd5171e128>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(y_test, y_pred, classes=class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.50      0.59        16\n",
      "           1       0.18      0.33      0.24         6\n",
      "           2       0.90      0.90      0.90        30\n",
      "\n",
      "    accuracy                           0.71        52\n",
      "   macro avg       0.60      0.58      0.58        52\n",
      "weighted avg       0.76      0.71      0.73        52\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing 1/5184\n",
      "0.01 1 2 3 log2 friedman_mse 0.5 50: Weighted 0.824584 (0.048793)\n",
      "0.01 1 2 3 log2 friedman_mse 0.5 50: Macro 0.717955 (0.067713)\n",
      "Testing 2/5184\n",
      "0.01 1 2 3 log2 friedman_mse 0.5 100: Weighted 0.823429 (0.050375)\n",
      "0.01 1 2 3 log2 friedman_mse 0.5 100: Macro 0.713676 (0.073970)\n",
      "Testing 3/5184\n",
      "0.01 1 2 3 log2 friedman_mse 0.5 200: Weighted 0.819671 (0.051220)\n",
      "0.01 1 2 3 log2 friedman_mse 0.5 200: Macro 0.715281 (0.069645)\n",
      "Testing 4/5184\n",
      "0.01 1 2 3 log2 friedman_mse 0.5 500: Weighted 0.810853 (0.062021)\n",
      "0.01 1 2 3 log2 friedman_mse 0.5 500: Macro 0.706601 (0.082666)\n",
      "Testing 5/5184\n",
      "0.01 1 2 3 log2 friedman_mse 0.75 50: Weighted 0.804891 (0.068104)\n",
      "0.01 1 2 3 log2 friedman_mse 0.75 50: Macro 0.696498 (0.089185)\n",
      "Testing 6/5184\n",
      "0.01 1 2 3 log2 friedman_mse 0.75 100: Weighted 0.809078 (0.065610)\n",
      "0.01 1 2 3 log2 friedman_mse 0.75 100: Macro 0.701225 (0.088057)\n",
      "Testing 7/5184\n",
      "0.01 1 2 3 log2 friedman_mse 0.75 200: Weighted 0.808298 (0.066729)\n",
      "0.01 1 2 3 log2 friedman_mse 0.75 200: Macro 0.701491 (0.087656)\n",
      "Testing 8/5184\n",
      "0.01 1 2 3 log2 friedman_mse 0.75 500: Weighted 0.798663 (0.062386)\n",
      "0.01 1 2 3 log2 friedman_mse 0.75 500: Macro 0.693646 (0.085447)\n",
      "Testing 9/5184\n",
      "0.01 1 2 3 log2 friedman_mse 1.0 50: Weighted 0.799232 (0.072203)\n",
      "0.01 1 2 3 log2 friedman_mse 1.0 50: Macro 0.695198 (0.089272)\n",
      "Testing 10/5184\n",
      "0.01 1 2 3 log2 friedman_mse 1.0 100: Weighted 0.790206 (0.058675)\n",
      "0.01 1 2 3 log2 friedman_mse 1.0 100: Macro 0.685395 (0.081332)\n",
      "Testing 11/5184\n",
      "0.01 1 2 3 log2 friedman_mse 1.0 200: Weighted 0.801679 (0.055826)\n",
      "0.01 1 2 3 log2 friedman_mse 1.0 200: Macro 0.692052 (0.073971)\n",
      "Testing 12/5184\n",
      "0.01 1 2 3 log2 friedman_mse 1.0 500: Weighted 0.789680 (0.063625)\n",
      "0.01 1 2 3 log2 friedman_mse 1.0 500: Macro 0.683182 (0.095510)\n",
      "Testing 13/5184\n",
      "0.01 1 2 3 log2 mae 0.5 50: Weighted 0.805916 (0.063724)\n",
      "0.01 1 2 3 log2 mae 0.5 50: Macro 0.692614 (0.086971)\n",
      "Testing 14/5184\n",
      "0.01 1 2 3 log2 mae 0.5 100: Weighted 0.802270 (0.055143)\n",
      "0.01 1 2 3 log2 mae 0.5 100: Macro 0.685553 (0.078766)\n",
      "Testing 15/5184\n",
      "0.01 1 2 3 log2 mae 0.5 200: Weighted 0.803177 (0.061849)\n",
      "0.01 1 2 3 log2 mae 0.5 200: Macro 0.687701 (0.087929)\n",
      "Testing 16/5184\n",
      "0.01 1 2 3 log2 mae 0.5 500: Weighted 0.802066 (0.057488)\n",
      "0.01 1 2 3 log2 mae 0.5 500: Macro 0.682604 (0.082551)\n",
      "Testing 17/5184\n",
      "0.01 1 2 3 log2 mae 0.75 50: Weighted 0.797659 (0.038184)\n",
      "0.01 1 2 3 log2 mae 0.75 50: Macro 0.687642 (0.056580)\n",
      "Testing 18/5184\n",
      "0.01 1 2 3 log2 mae 0.75 100: Weighted 0.794140 (0.058447)\n",
      "0.01 1 2 3 log2 mae 0.75 100: Macro 0.670235 (0.084821)\n",
      "Testing 19/5184\n",
      "0.01 1 2 3 log2 mae 0.75 200: Weighted 0.791189 (0.061153)\n",
      "0.01 1 2 3 log2 mae 0.75 200: Macro 0.669443 (0.090130)\n",
      "Testing 20/5184\n",
      "0.01 1 2 3 log2 mae 0.75 500: Weighted 0.781529 (0.059430)\n",
      "0.01 1 2 3 log2 mae 0.75 500: Macro 0.666463 (0.082593)\n",
      "Testing 21/5184\n",
      "0.01 1 2 3 log2 mae 1.0 50: Weighted 0.804737 (0.058074)\n",
      "0.01 1 2 3 log2 mae 1.0 50: Macro 0.701192 (0.069989)\n",
      "Testing 22/5184\n",
      "0.01 1 2 3 log2 mae 1.0 100: Weighted 0.775736 (0.047694)\n",
      "0.01 1 2 3 log2 mae 1.0 100: Macro 0.664084 (0.064971)\n",
      "Testing 23/5184\n",
      "0.01 1 2 3 log2 mae 1.0 200: Weighted 0.777844 (0.045887)\n",
      "0.01 1 2 3 log2 mae 1.0 200: Macro 0.656358 (0.063618)\n",
      "Testing 24/5184\n",
      "0.01 1 2 3 log2 mae 1.0 500: Weighted 0.780251 (0.065069)\n",
      "0.01 1 2 3 log2 mae 1.0 500: Macro 0.663693 (0.090899)\n",
      "Testing 25/5184\n",
      "0.01 1 2 3 sqrt friedman_mse 0.5 50: Weighted 0.815283 (0.054938)\n",
      "0.01 1 2 3 sqrt friedman_mse 0.5 50: Macro 0.708909 (0.072035)\n",
      "Testing 26/5184\n",
      "0.01 1 2 3 sqrt friedman_mse 0.5 100: Weighted 0.819822 (0.047577)\n",
      "0.01 1 2 3 sqrt friedman_mse 0.5 100: Macro 0.710813 (0.065298)\n",
      "Testing 27/5184\n",
      "0.01 1 2 3 sqrt friedman_mse 0.5 200: Weighted 0.823862 (0.061897)\n",
      "0.01 1 2 3 sqrt friedman_mse 0.5 200: Macro 0.715717 (0.089956)\n",
      "Testing 28/5184\n",
      "0.01 1 2 3 sqrt friedman_mse 0.5 500: Weighted 0.813119 (0.059430)\n",
      "0.01 1 2 3 sqrt friedman_mse 0.5 500: Macro 0.720384 (0.079879)\n",
      "Testing 29/5184\n",
      "0.01 1 2 3 sqrt friedman_mse 0.75 50: Weighted 0.813258 (0.058069)\n",
      "0.01 1 2 3 sqrt friedman_mse 0.75 50: Macro 0.698452 (0.085137)\n",
      "Testing 30/5184\n",
      "0.01 1 2 3 sqrt friedman_mse 0.75 100: Weighted 0.812443 (0.064689)\n",
      "0.01 1 2 3 sqrt friedman_mse 0.75 100: Macro 0.706359 (0.087377)\n",
      "Testing 31/5184\n",
      "0.01 1 2 3 sqrt friedman_mse 0.75 200: Weighted 0.804558 (0.060227)\n",
      "0.01 1 2 3 sqrt friedman_mse 0.75 200: Macro 0.694414 (0.080616)\n",
      "Testing 32/5184\n",
      "0.01 1 2 3 sqrt friedman_mse 0.75 500: Weighted 0.795373 (0.064962)\n",
      "0.01 1 2 3 sqrt friedman_mse 0.75 500: Macro 0.689215 (0.089566)\n",
      "Testing 33/5184\n",
      "0.01 1 2 3 sqrt friedman_mse 1.0 50: Weighted 0.795158 (0.078534)\n",
      "0.01 1 2 3 sqrt friedman_mse 1.0 50: Macro 0.687325 (0.104281)\n",
      "Testing 34/5184\n",
      "0.01 1 2 3 sqrt friedman_mse 1.0 100: Weighted 0.789867 (0.047358)\n",
      "0.01 1 2 3 sqrt friedman_mse 1.0 100: Macro 0.681537 (0.070592)\n",
      "Testing 35/5184\n",
      "0.01 1 2 3 sqrt friedman_mse 1.0 200: Weighted 0.794625 (0.059182)\n",
      "0.01 1 2 3 sqrt friedman_mse 1.0 200: Macro 0.686606 (0.079130)\n",
      "Testing 36/5184\n",
      "0.01 1 2 3 sqrt friedman_mse 1.0 500: Weighted 0.793310 (0.061283)\n",
      "0.01 1 2 3 sqrt friedman_mse 1.0 500: Macro 0.687880 (0.091165)\n",
      "Testing 37/5184\n",
      "0.01 1 2 3 sqrt mae 0.5 50: Weighted 0.799751 (0.053788)\n",
      "0.01 1 2 3 sqrt mae 0.5 50: Macro 0.689413 (0.066221)\n",
      "Testing 38/5184\n",
      "0.01 1 2 3 sqrt mae 0.5 100: Weighted 0.802513 (0.055240)\n",
      "0.01 1 2 3 sqrt mae 0.5 100: Macro 0.684697 (0.078339)\n",
      "Testing 39/5184\n",
      "0.01 1 2 3 sqrt mae 0.5 200: Weighted 0.814162 (0.050607)\n",
      "0.01 1 2 3 sqrt mae 0.5 200: Macro 0.699881 (0.070093)\n",
      "Testing 40/5184\n",
      "0.01 1 2 3 sqrt mae 0.5 500: Weighted 0.800586 (0.062285)\n",
      "0.01 1 2 3 sqrt mae 0.5 500: Macro 0.681638 (0.087337)\n",
      "Testing 41/5184\n",
      "0.01 1 2 3 sqrt mae 0.75 50: Weighted 0.779093 (0.059999)\n",
      "0.01 1 2 3 sqrt mae 0.75 50: Macro 0.656455 (0.086261)\n",
      "Testing 42/5184\n",
      "0.01 1 2 3 sqrt mae 0.75 100: Weighted 0.800724 (0.067375)\n",
      "0.01 1 2 3 sqrt mae 0.75 100: Macro 0.689066 (0.089101)\n",
      "Testing 43/5184\n",
      "0.01 1 2 3 sqrt mae 0.75 200: Weighted 0.803800 (0.063005)\n",
      "0.01 1 2 3 sqrt mae 0.75 200: Macro 0.688379 (0.088057)\n",
      "Testing 44/5184\n",
      "0.01 1 2 3 sqrt mae 0.75 500: Weighted 0.771548 (0.052180)\n",
      "0.01 1 2 3 sqrt mae 0.75 500: Macro 0.656049 (0.072156)\n",
      "Testing 45/5184\n",
      "0.01 1 2 3 sqrt mae 1.0 50: Weighted 0.796374 (0.070422)\n",
      "0.01 1 2 3 sqrt mae 1.0 50: Macro 0.692074 (0.091915)\n",
      "Testing 46/5184\n",
      "0.01 1 2 3 sqrt mae 1.0 100: Weighted 0.799625 (0.057246)\n",
      "0.01 1 2 3 sqrt mae 1.0 100: Macro 0.689728 (0.075384)\n",
      "Testing 47/5184\n",
      "0.01 1 2 3 sqrt mae 1.0 200: Weighted 0.773516 (0.055744)\n",
      "0.01 1 2 3 sqrt mae 1.0 200: Macro 0.657584 (0.075209)\n",
      "Testing 48/5184\n",
      "0.01 1 2 3 sqrt mae 1.0 500: Weighted 0.777091 (0.069336)\n",
      "0.01 1 2 3 sqrt mae 1.0 500: Macro 0.658567 (0.097192)\n",
      "Testing 49/5184\n",
      "0.01 1 2 5 log2 friedman_mse 0.5 50: Weighted 0.816577 (0.050453)\n",
      "0.01 1 2 5 log2 friedman_mse 0.5 50: Macro 0.712406 (0.064927)\n",
      "Testing 50/5184\n",
      "0.01 1 2 5 log2 friedman_mse 0.5 100: Weighted 0.814403 (0.046300)\n",
      "0.01 1 2 5 log2 friedman_mse 0.5 100: Macro 0.700213 (0.064918)\n",
      "Testing 51/5184\n",
      "0.01 1 2 5 log2 friedman_mse 0.5 200: Weighted 0.810576 (0.041950)\n",
      "0.01 1 2 5 log2 friedman_mse 0.5 200: Macro 0.701768 (0.058717)\n",
      "Testing 52/5184\n",
      "0.01 1 2 5 log2 friedman_mse 0.5 500: Weighted 0.814307 (0.081680)\n",
      "0.01 1 2 5 log2 friedman_mse 0.5 500: Macro 0.705208 (0.118119)\n",
      "Testing 53/5184\n",
      "0.01 1 2 5 log2 friedman_mse 0.75 50: Weighted 0.797015 (0.047072)\n",
      "0.01 1 2 5 log2 friedman_mse 0.75 50: Macro 0.681460 (0.068650)\n",
      "Testing 54/5184\n",
      "0.01 1 2 5 log2 friedman_mse 0.75 100: Weighted 0.794297 (0.055817)\n",
      "0.01 1 2 5 log2 friedman_mse 0.75 100: Macro 0.679243 (0.078045)\n",
      "Testing 55/5184\n",
      "0.01 1 2 5 log2 friedman_mse 0.75 200: Weighted 0.784442 (0.044945)\n",
      "0.01 1 2 5 log2 friedman_mse 0.75 200: Macro 0.672073 (0.069737)\n",
      "Testing 56/5184\n",
      "0.01 1 2 5 log2 friedman_mse 0.75 500: Weighted 0.799073 (0.082934)\n",
      "0.01 1 2 5 log2 friedman_mse 0.75 500: Macro 0.690982 (0.115125)\n",
      "Testing 57/5184\n",
      "0.01 1 2 5 log2 friedman_mse 1.0 50: Weighted 0.771721 (0.056330)\n",
      "0.01 1 2 5 log2 friedman_mse 1.0 50: Macro 0.656820 (0.079395)\n",
      "Testing 58/5184\n",
      "0.01 1 2 5 log2 friedman_mse 1.0 100: Weighted 0.775965 (0.045071)\n",
      "0.01 1 2 5 log2 friedman_mse 1.0 100: Macro 0.666443 (0.068442)\n",
      "Testing 59/5184\n",
      "0.01 1 2 5 log2 friedman_mse 1.0 200: Weighted 0.781335 (0.045680)\n",
      "0.01 1 2 5 log2 friedman_mse 1.0 200: Macro 0.673815 (0.071570)\n",
      "Testing 60/5184\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01 1 2 5 log2 friedman_mse 1.0 500: Weighted 0.785153 (0.069619)\n",
      "0.01 1 2 5 log2 friedman_mse 1.0 500: Macro 0.683412 (0.106523)\n",
      "Testing 61/5184\n",
      "0.01 1 2 5 log2 mae 0.5 50: Weighted 0.792828 (0.064267)\n",
      "0.01 1 2 5 log2 mae 0.5 50: Macro 0.675874 (0.083846)\n",
      "Testing 62/5184\n",
      "0.01 1 2 5 log2 mae 0.5 100: Weighted 0.793792 (0.047293)\n",
      "0.01 1 2 5 log2 mae 0.5 100: Macro 0.676446 (0.067541)\n",
      "Testing 63/5184\n",
      "0.01 1 2 5 log2 mae 0.5 200: Weighted 0.796752 (0.054839)\n",
      "0.01 1 2 5 log2 mae 0.5 200: Macro 0.675384 (0.076467)\n",
      "Testing 64/5184\n",
      "0.01 1 2 5 log2 mae 0.5 500: Weighted 0.795561 (0.045598)\n",
      "0.01 1 2 5 log2 mae 0.5 500: Macro 0.676198 (0.067749)\n",
      "Testing 65/5184\n",
      "0.01 1 2 5 log2 mae 0.75 50: Weighted 0.783817 (0.061140)\n",
      "0.01 1 2 5 log2 mae 0.75 50: Macro 0.662230 (0.087024)\n",
      "Testing 66/5184\n",
      "0.01 1 2 5 log2 mae 0.75 100: Weighted 0.773643 (0.039227)\n",
      "0.01 1 2 5 log2 mae 0.75 100: Macro 0.652019 (0.057345)\n",
      "Testing 67/5184\n",
      "0.01 1 2 5 log2 mae 0.75 200: Weighted 0.773115 (0.050616)\n",
      "0.01 1 2 5 log2 mae 0.75 200: Macro 0.654417 (0.069948)\n",
      "Testing 68/5184\n",
      "0.01 1 2 5 log2 mae 0.75 500: Weighted 0.778681 (0.061996)\n",
      "0.01 1 2 5 log2 mae 0.75 500: Macro 0.655365 (0.094166)\n",
      "Testing 69/5184\n",
      "0.01 1 2 5 log2 mae 1.0 50: Weighted 0.778255 (0.049756)\n",
      "0.01 1 2 5 log2 mae 1.0 50: Macro 0.658339 (0.071256)\n",
      "Testing 70/5184\n",
      "0.01 1 2 5 log2 mae 1.0 100: Weighted 0.778930 (0.053184)\n",
      "0.01 1 2 5 log2 mae 1.0 100: Macro 0.661564 (0.074757)\n",
      "Testing 71/5184\n",
      "0.01 1 2 5 log2 mae 1.0 200: Weighted 0.759749 (0.049674)\n",
      "0.01 1 2 5 log2 mae 1.0 200: Macro 0.633244 (0.078447)\n",
      "Testing 72/5184\n",
      "0.01 1 2 5 log2 mae 1.0 500: Weighted 0.789117 (0.068764)\n",
      "0.01 1 2 5 log2 mae 1.0 500: Macro 0.663456 (0.107778)\n",
      "Testing 73/5184\n",
      "0.01 1 2 5 sqrt friedman_mse 0.5 50: Weighted 0.817877 (0.048325)\n",
      "0.01 1 2 5 sqrt friedman_mse 0.5 50: Macro 0.714048 (0.065353)\n",
      "Testing 74/5184\n",
      "0.01 1 2 5 sqrt friedman_mse 0.5 100: Weighted 0.804368 (0.048854)\n",
      "0.01 1 2 5 sqrt friedman_mse 0.5 100: Macro 0.695156 (0.069994)\n",
      "Testing 75/5184\n",
      "0.01 1 2 5 sqrt friedman_mse 0.5 200: Weighted 0.809007 (0.043179)\n",
      "0.01 1 2 5 sqrt friedman_mse 0.5 200: Macro 0.704109 (0.055163)\n",
      "Testing 76/5184\n",
      "0.01 1 2 5 sqrt friedman_mse 0.5 500: Weighted 0.820406 (0.075719)\n",
      "0.01 1 2 5 sqrt friedman_mse 0.5 500: Macro 0.720664 (0.106619)\n",
      "Testing 77/5184\n",
      "0.01 1 2 5 sqrt friedman_mse 0.75 50: Weighted 0.794318 (0.059198)\n",
      "0.01 1 2 5 sqrt friedman_mse 0.75 50: Macro 0.685335 (0.078463)\n",
      "Testing 78/5184\n",
      "0.01 1 2 5 sqrt friedman_mse 0.75 100: Weighted 0.790652 (0.049980)\n",
      "0.01 1 2 5 sqrt friedman_mse 0.75 100: Macro 0.677942 (0.073416)\n",
      "Testing 79/5184\n",
      "0.01 1 2 5 sqrt friedman_mse 0.75 200: Weighted 0.788542 (0.046866)\n",
      "0.01 1 2 5 sqrt friedman_mse 0.75 200: Macro 0.679470 (0.065963)\n",
      "Testing 80/5184\n",
      "0.01 1 2 5 sqrt friedman_mse 0.75 500: Weighted 0.798854 (0.082600)\n",
      "0.01 1 2 5 sqrt friedman_mse 0.75 500: Macro 0.694842 (0.120855)\n",
      "Testing 81/5184\n",
      "0.01 1 2 5 sqrt friedman_mse 1.0 50: Weighted 0.770206 (0.058878)\n",
      "0.01 1 2 5 sqrt friedman_mse 1.0 50: Macro 0.656004 (0.079860)\n",
      "Testing 82/5184\n",
      "0.01 1 2 5 sqrt friedman_mse 1.0 100: Weighted 0.777366 (0.050906)\n",
      "0.01 1 2 5 sqrt friedman_mse 1.0 100: Macro 0.668730 (0.077918)\n",
      "Testing 83/5184\n",
      "0.01 1 2 5 sqrt friedman_mse 1.0 200: Weighted 0.778013 (0.048255)\n",
      "0.01 1 2 5 sqrt friedman_mse 1.0 200: Macro 0.669225 (0.075436)\n",
      "Testing 84/5184\n",
      "0.01 1 2 5 sqrt friedman_mse 1.0 500: Weighted 0.797466 (0.057859)\n",
      "0.01 1 2 5 sqrt friedman_mse 1.0 500: Macro 0.694701 (0.095799)\n",
      "Testing 85/5184\n",
      "0.01 1 2 5 sqrt mae 0.5 50: Weighted 0.782036 (0.045868)\n",
      "0.01 1 2 5 sqrt mae 0.5 50: Macro 0.666569 (0.067626)\n",
      "Testing 86/5184\n",
      "0.01 1 2 5 sqrt mae 0.5 100: Weighted 0.804614 (0.048072)\n",
      "0.01 1 2 5 sqrt mae 0.5 100: Macro 0.688682 (0.063767)\n",
      "Testing 87/5184\n",
      "0.01 1 2 5 sqrt mae 0.5 200: Weighted 0.803283 (0.048673)\n",
      "0.01 1 2 5 sqrt mae 0.5 200: Macro 0.685228 (0.066993)\n",
      "Testing 88/5184\n",
      "0.01 1 2 5 sqrt mae 0.5 500: Weighted 0.794937 (0.046240)\n",
      "0.01 1 2 5 sqrt mae 0.5 500: Macro 0.679827 (0.071407)\n",
      "Testing 89/5184\n",
      "0.01 1 2 5 sqrt mae 0.75 50: Weighted 0.787227 (0.044070)\n",
      "0.01 1 2 5 sqrt mae 0.75 50: Macro 0.668693 (0.067098)\n",
      "Testing 90/5184\n",
      "0.01 1 2 5 sqrt mae 0.75 100: Weighted 0.795514 (0.046219)\n",
      "0.01 1 2 5 sqrt mae 0.75 100: Macro 0.677179 (0.066953)\n",
      "Testing 91/5184\n",
      "0.01 1 2 5 sqrt mae 0.75 200: Weighted 0.779998 (0.051243)\n",
      "0.01 1 2 5 sqrt mae 0.75 200: Macro 0.660443 (0.075296)\n",
      "Testing 92/5184\n",
      "0.01 1 2 5 sqrt mae 0.75 500: Weighted 0.772914 (0.067908)\n",
      "0.01 1 2 5 sqrt mae 0.75 500: Macro 0.654899 (0.094654)\n",
      "Testing 93/5184\n",
      "0.01 1 2 5 sqrt mae 1.0 50: Weighted 0.769197 (0.041772)\n",
      "0.01 1 2 5 sqrt mae 1.0 50: Macro 0.648184 (0.063907)\n",
      "Testing 94/5184\n",
      "0.01 1 2 5 sqrt mae 1.0 100: Weighted 0.774721 (0.049310)\n",
      "0.01 1 2 5 sqrt mae 1.0 100: Macro 0.651564 (0.072812)\n",
      "Testing 95/5184\n",
      "0.01 1 2 5 sqrt mae 1.0 200: Weighted 0.772715 (0.051967)\n",
      "0.01 1 2 5 sqrt mae 1.0 200: Macro 0.648521 (0.081885)\n",
      "Testing 96/5184\n",
      "0.01 1 2 5 sqrt mae 1.0 500: Weighted 0.778043 (0.072375)\n",
      "0.01 1 2 5 sqrt mae 1.0 500: Macro 0.651128 (0.108409)\n",
      "Testing 97/5184\n",
      "0.01 1 2 8 log2 friedman_mse 0.5 50: Weighted 0.806602 (0.045501)\n",
      "0.01 1 2 8 log2 friedman_mse 0.5 50: Macro 0.702901 (0.050900)\n",
      "Testing 98/5184\n",
      "0.01 1 2 8 log2 friedman_mse 0.5 100: Weighted 0.804281 (0.056912)\n",
      "0.01 1 2 8 log2 friedman_mse 0.5 100: Macro 0.696037 (0.076773)\n",
      "Testing 99/5184\n",
      "0.01 1 2 8 log2 friedman_mse 0.5 200: Weighted 0.816725 (0.069039)\n",
      "0.01 1 2 8 log2 friedman_mse 0.5 200: Macro 0.712173 (0.093079)\n",
      "Testing 100/5184\n",
      "0.01 1 2 8 log2 friedman_mse 0.5 500: Weighted 0.810506 (0.073005)\n",
      "0.01 1 2 8 log2 friedman_mse 0.5 500: Macro 0.702959 (0.103325)\n",
      "Testing 101/5184\n",
      "0.01 1 2 8 log2 friedman_mse 0.75 50: Weighted 0.784442 (0.044945)\n",
      "0.01 1 2 8 log2 friedman_mse 0.75 50: Macro 0.672073 (0.069737)\n",
      "Testing 102/5184\n",
      "0.01 1 2 8 log2 friedman_mse 0.75 100: Weighted 0.786253 (0.043250)\n",
      "0.01 1 2 8 log2 friedman_mse 0.75 100: Macro 0.678173 (0.060792)\n",
      "Testing 103/5184\n",
      "0.01 1 2 8 log2 friedman_mse 0.75 200: Weighted 0.797865 (0.063042)\n",
      "0.01 1 2 8 log2 friedman_mse 0.75 200: Macro 0.686015 (0.086937)\n",
      "Testing 104/5184\n",
      "0.01 1 2 8 log2 friedman_mse 0.75 500: Weighted 0.802510 (0.079792)\n",
      "0.01 1 2 8 log2 friedman_mse 0.75 500: Macro 0.695697 (0.110868)\n",
      "Testing 105/5184\n",
      "0.01 1 2 8 log2 friedman_mse 1.0 50: Weighted 0.768969 (0.049100)\n",
      "0.01 1 2 8 log2 friedman_mse 1.0 50: Macro 0.650580 (0.083029)\n",
      "Testing 106/5184\n",
      "0.01 1 2 8 log2 friedman_mse 1.0 100: Weighted 0.786057 (0.054075)\n",
      "0.01 1 2 8 log2 friedman_mse 1.0 100: Macro 0.676729 (0.081604)\n",
      "Testing 107/5184\n",
      "0.01 1 2 8 log2 friedman_mse 1.0 200: Weighted 0.767121 (0.054532)\n",
      "0.01 1 2 8 log2 friedman_mse 1.0 200: Macro 0.652140 (0.084851)\n",
      "Testing 108/5184\n",
      "0.01 1 2 8 log2 friedman_mse 1.0 500: Weighted 0.772172 (0.057450)\n",
      "0.01 1 2 8 log2 friedman_mse 1.0 500: Macro 0.659676 (0.090532)\n",
      "Testing 109/5184\n",
      "0.01 1 2 8 log2 mae 0.5 50: Weighted 0.786231 (0.036796)\n",
      "0.01 1 2 8 log2 mae 0.5 50: Macro 0.665633 (0.058911)\n",
      "Testing 110/5184\n",
      "0.01 1 2 8 log2 mae 0.5 100: Weighted 0.792392 (0.038887)\n",
      "0.01 1 2 8 log2 mae 0.5 100: Macro 0.673251 (0.062811)\n",
      "Testing 111/5184\n",
      "0.01 1 2 8 log2 mae 0.5 200: Weighted 0.790516 (0.040836)\n",
      "0.01 1 2 8 log2 mae 0.5 200: Macro 0.673124 (0.062952)\n",
      "Testing 112/5184\n",
      "0.01 1 2 8 log2 mae 0.5 500: Weighted 0.799369 (0.042019)\n",
      "0.01 1 2 8 log2 mae 0.5 500: Macro 0.684305 (0.066878)\n",
      "Testing 113/5184\n",
      "0.01 1 2 8 log2 mae 0.75 50: Weighted 0.790655 (0.043151)\n",
      "0.01 1 2 8 log2 mae 0.75 50: Macro 0.669100 (0.072094)\n",
      "Testing 114/5184\n",
      "0.01 1 2 8 log2 mae 0.75 100: Weighted 0.774467 (0.026726)\n",
      "0.01 1 2 8 log2 mae 0.75 100: Macro 0.654801 (0.047002)\n",
      "Testing 115/5184\n",
      "0.01 1 2 8 log2 mae 0.75 200: Weighted 0.794863 (0.046318)\n",
      "0.01 1 2 8 log2 mae 0.75 200: Macro 0.680886 (0.070286)\n",
      "Testing 116/5184\n",
      "0.01 1 2 8 log2 mae 0.75 500: Weighted 0.786831 (0.054125)\n",
      "0.01 1 2 8 log2 mae 0.75 500: Macro 0.671395 (0.079488)\n",
      "Testing 117/5184\n",
      "0.01 1 2 8 log2 mae 1.0 50: Weighted 0.762822 (0.045079)\n",
      "0.01 1 2 8 log2 mae 1.0 50: Macro 0.639605 (0.075702)\n",
      "Testing 118/5184\n",
      "0.01 1 2 8 log2 mae 1.0 100: Weighted 0.771042 (0.043412)\n",
      "0.01 1 2 8 log2 mae 1.0 100: Macro 0.644966 (0.072573)\n",
      "Testing 119/5184\n",
      "0.01 1 2 8 log2 mae 1.0 200: Weighted 0.781480 (0.047127)\n",
      "0.01 1 2 8 log2 mae 1.0 200: Macro 0.665897 (0.075039)\n",
      "Testing 120/5184\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01 1 2 8 log2 mae 1.0 500: Weighted 0.777545 (0.050953)\n",
      "0.01 1 2 8 log2 mae 1.0 500: Macro 0.657338 (0.076509)\n",
      "Testing 121/5184\n",
      "0.01 1 2 8 sqrt friedman_mse 0.5 50: Weighted 0.797715 (0.075164)\n",
      "0.01 1 2 8 sqrt friedman_mse 0.5 50: Macro 0.680074 (0.109733)\n",
      "Testing 122/5184\n",
      "0.01 1 2 8 sqrt friedman_mse 0.5 100: Weighted 0.801942 (0.060486)\n",
      "0.01 1 2 8 sqrt friedman_mse 0.5 100: Macro 0.695407 (0.078679)\n",
      "Testing 123/5184\n",
      "0.01 1 2 8 sqrt friedman_mse 0.5 200: Weighted 0.811295 (0.072326)\n",
      "0.01 1 2 8 sqrt friedman_mse 0.5 200: Macro 0.702669 (0.103559)\n",
      "Testing 124/5184\n",
      "0.01 1 2 8 sqrt friedman_mse 0.5 500: Weighted 0.815692 (0.079359)\n",
      "0.01 1 2 8 sqrt friedman_mse 0.5 500: Macro 0.710294 (0.115339)\n",
      "Testing 125/5184\n",
      "0.01 1 2 8 sqrt friedman_mse 0.75 50: Weighted 0.785504 (0.071522)\n",
      "0.01 1 2 8 sqrt friedman_mse 0.75 50: Macro 0.675642 (0.101123)\n",
      "Testing 126/5184\n",
      "0.01 1 2 8 sqrt friedman_mse 0.75 100: Weighted 0.782839 (0.043115)\n",
      "0.01 1 2 8 sqrt friedman_mse 0.75 100: Macro 0.670253 (0.067805)\n",
      "Testing 127/5184\n",
      "0.01 1 2 8 sqrt friedman_mse 0.75 200: Weighted 0.793707 (0.066521)\n",
      "0.01 1 2 8 sqrt friedman_mse 0.75 200: Macro 0.681511 (0.090690)\n",
      "Testing 128/5184\n",
      "0.01 1 2 8 sqrt friedman_mse 0.75 500: Weighted 0.810488 (0.072850)\n",
      "0.01 1 2 8 sqrt friedman_mse 0.75 500: Macro 0.710751 (0.097248)\n",
      "Testing 129/5184\n",
      "0.01 1 2 8 sqrt friedman_mse 1.0 50: Weighted 0.764516 (0.054892)\n",
      "0.01 1 2 8 sqrt friedman_mse 1.0 50: Macro 0.647262 (0.087385)\n",
      "Testing 130/5184\n",
      "0.01 1 2 8 sqrt friedman_mse 1.0 100: Weighted 0.774698 (0.042556)\n",
      "0.01 1 2 8 sqrt friedman_mse 1.0 100: Macro 0.661649 (0.069964)\n",
      "Testing 131/5184\n",
      "0.01 1 2 8 sqrt friedman_mse 1.0 200: Weighted 0.770381 (0.053790)\n",
      "0.01 1 2 8 sqrt friedman_mse 1.0 200: Macro 0.656816 (0.083387)\n",
      "Testing 132/5184\n",
      "0.01 1 2 8 sqrt friedman_mse 1.0 500: Weighted 0.768802 (0.059210)\n",
      "0.01 1 2 8 sqrt friedman_mse 1.0 500: Macro 0.654881 (0.092985)\n",
      "Testing 133/5184\n",
      "0.01 1 2 8 sqrt mae 0.5 50: Weighted 0.790408 (0.049912)\n",
      "0.01 1 2 8 sqrt mae 0.5 50: Macro 0.676562 (0.078244)\n",
      "Testing 134/5184\n",
      "0.01 1 2 8 sqrt mae 0.5 100: Weighted 0.798991 (0.032546)\n",
      "0.01 1 2 8 sqrt mae 0.5 100: Macro 0.681564 (0.054473)\n",
      "Testing 135/5184\n",
      "0.01 1 2 8 sqrt mae 0.5 200: Weighted 0.780476 (0.050790)\n",
      "0.01 1 2 8 sqrt mae 0.5 200: Macro 0.658818 (0.076896)\n",
      "Testing 136/5184\n",
      "0.01 1 2 8 sqrt mae 0.5 500: Weighted 0.795558 (0.045594)\n",
      "0.01 1 2 8 sqrt mae 0.5 500: Macro 0.679388 (0.071881)\n",
      "Testing 137/5184\n",
      "0.01 1 2 8 sqrt mae 0.75 50: Weighted 0.785682 (0.056386)\n",
      "0.01 1 2 8 sqrt mae 0.75 50: Macro 0.666444 (0.084013)\n",
      "Testing 138/5184\n",
      "0.01 1 2 8 sqrt mae 0.75 100: Weighted 0.777235 (0.036146)\n",
      "0.01 1 2 8 sqrt mae 0.75 100: Macro 0.655647 (0.054176)\n",
      "Testing 139/5184\n",
      "0.01 1 2 8 sqrt mae 0.75 200: Weighted 0.778348 (0.052876)\n",
      "0.01 1 2 8 sqrt mae 0.75 200: Macro 0.661970 (0.073859)\n",
      "Testing 140/5184\n",
      "0.01 1 2 8 sqrt mae 0.75 500: Weighted 0.793911 (0.047185)\n",
      "0.01 1 2 8 sqrt mae 0.75 500: Macro 0.680846 (0.070321)\n",
      "Testing 141/5184\n",
      "0.01 1 2 8 sqrt mae 1.0 50: Weighted 0.766657 (0.052430)\n",
      "0.01 1 2 8 sqrt mae 1.0 50: Macro 0.634037 (0.085044)\n",
      "Testing 142/5184\n",
      "0.01 1 2 8 sqrt mae 1.0 100: Weighted 0.758232 (0.051867)\n",
      "0.01 1 2 8 sqrt mae 1.0 100: Macro 0.630835 (0.076067)\n",
      "Testing 143/5184\n",
      "0.01 1 2 8 sqrt mae 1.0 200: Weighted 0.775684 (0.052920)\n",
      "0.01 1 2 8 sqrt mae 1.0 200: Macro 0.652731 (0.082018)\n",
      "Testing 144/5184\n",
      "0.01 1 2 8 sqrt mae 1.0 500: Weighted 0.774426 (0.075106)\n",
      "0.01 1 2 8 sqrt mae 1.0 500: Macro 0.652456 (0.106019)\n",
      "Testing 145/5184\n",
      "0.01 1 4 3 log2 friedman_mse 0.5 50: Weighted 0.805870 (0.063771)\n",
      "0.01 1 4 3 log2 friedman_mse 0.5 50: Macro 0.688513 (0.091549)\n",
      "Testing 146/5184\n",
      "0.01 1 4 3 log2 friedman_mse 0.5 100: Weighted 0.808124 (0.056184)\n",
      "0.01 1 4 3 log2 friedman_mse 0.5 100: Macro 0.698274 (0.074021)\n",
      "Testing 147/5184\n",
      "0.01 1 4 3 log2 friedman_mse 0.5 200: Weighted 0.815448 (0.053466)\n",
      "0.01 1 4 3 log2 friedman_mse 0.5 200: Macro 0.701291 (0.079056)\n",
      "Testing 148/5184\n",
      "0.01 1 4 3 log2 friedman_mse 0.5 500: Weighted 0.817171 (0.062819)\n",
      "0.01 1 4 3 log2 friedman_mse 0.5 500: Macro 0.714888 (0.090088)\n",
      "Testing 149/5184\n",
      "0.01 1 4 3 log2 friedman_mse 0.75 50: Weighted 0.804891 (0.068104)\n",
      "0.01 1 4 3 log2 friedman_mse 0.75 50: Macro 0.696498 (0.089185)\n",
      "Testing 150/5184\n",
      "0.01 1 4 3 log2 friedman_mse 0.75 100: Weighted 0.811077 (0.062782)\n",
      "0.01 1 4 3 log2 friedman_mse 0.75 100: Macro 0.701533 (0.087592)\n",
      "Testing 151/5184\n",
      "0.01 1 4 3 log2 friedman_mse 0.75 200: Weighted 0.808298 (0.066729)\n",
      "0.01 1 4 3 log2 friedman_mse 0.75 200: Macro 0.701491 (0.087656)\n",
      "Testing 152/5184\n",
      "0.01 1 4 3 log2 friedman_mse 0.75 500: Weighted 0.804125 (0.079662)\n",
      "0.01 1 4 3 log2 friedman_mse 0.75 500: Macro 0.701381 (0.104842)\n",
      "Testing 153/5184\n",
      "0.01 1 4 3 log2 friedman_mse 1.0 50: Weighted 0.791978 (0.062641)\n",
      "0.01 1 4 3 log2 friedman_mse 1.0 50: Macro 0.684604 (0.074555)\n",
      "Testing 154/5184\n",
      "0.01 1 4 3 log2 friedman_mse 1.0 100: Weighted 0.791742 (0.064834)\n",
      "0.01 1 4 3 log2 friedman_mse 1.0 100: Macro 0.679875 (0.082594)\n",
      "Testing 155/5184\n",
      "0.01 1 4 3 log2 friedman_mse 1.0 200: Weighted 0.787945 (0.056980)\n",
      "0.01 1 4 3 log2 friedman_mse 1.0 200: Macro 0.676101 (0.073290)\n",
      "Testing 156/5184\n",
      "0.01 1 4 3 log2 friedman_mse 1.0 500: Weighted 0.793078 (0.060401)\n",
      "0.01 1 4 3 log2 friedman_mse 1.0 500: Macro 0.690164 (0.090071)\n",
      "Testing 157/5184\n",
      "0.01 1 4 3 log2 mae 0.5 50: Weighted 0.813950 (0.066239)\n",
      "0.01 1 4 3 log2 mae 0.5 50: Macro 0.703472 (0.093691)\n",
      "Testing 158/5184\n",
      "0.01 1 4 3 log2 mae 0.5 100: Weighted 0.807095 (0.057622)\n",
      "0.01 1 4 3 log2 mae 0.5 100: Macro 0.692764 (0.083327)\n",
      "Testing 159/5184\n",
      "0.01 1 4 3 log2 mae 0.5 200: Weighted 0.799306 (0.063035)\n",
      "0.01 1 4 3 log2 mae 0.5 200: Macro 0.677520 (0.090457)\n",
      "Testing 160/5184\n",
      "0.01 1 4 3 log2 mae 0.5 500: Weighted 0.808701 (0.061051)\n",
      "0.01 1 4 3 log2 mae 0.5 500: Macro 0.694209 (0.085375)\n",
      "Testing 161/5184\n",
      "0.01 1 4 3 log2 mae 0.75 50: Weighted 0.787101 (0.056047)\n",
      "0.01 1 4 3 log2 mae 0.75 50: Macro 0.667774 (0.074005)\n",
      "Testing 162/5184\n",
      "0.01 1 4 3 log2 mae 0.75 100: Weighted 0.791719 (0.049208)\n",
      "0.01 1 4 3 log2 mae 0.75 100: Macro 0.675727 (0.072765)\n",
      "Testing 163/5184\n",
      "0.01 1 4 3 log2 mae 0.75 200: Weighted 0.790152 (0.070216)\n",
      "0.01 1 4 3 log2 mae 0.75 200: Macro 0.669768 (0.096087)\n",
      "Testing 164/5184\n",
      "0.01 1 4 3 log2 mae 0.75 500: Weighted 0.779677 (0.062071)\n",
      "0.01 1 4 3 log2 mae 0.75 500: Macro 0.666349 (0.082746)\n",
      "Testing 165/5184\n",
      "0.01 1 4 3 log2 mae 1.0 50: Weighted 0.796392 (0.055665)\n",
      "0.01 1 4 3 log2 mae 1.0 50: Macro 0.688375 (0.066319)\n",
      "Testing 166/5184\n",
      "0.01 1 4 3 log2 mae 1.0 100: Weighted 0.778125 (0.064444)\n",
      "0.01 1 4 3 log2 mae 1.0 100: Macro 0.668750 (0.082602)\n",
      "Testing 167/5184\n",
      "0.01 1 4 3 log2 mae 1.0 200: Weighted 0.786962 (0.066206)\n",
      "0.01 1 4 3 log2 mae 1.0 200: Macro 0.681704 (0.086404)\n",
      "Testing 168/5184\n",
      "0.01 1 4 3 log2 mae 1.0 500: Weighted 0.767081 (0.073044)\n",
      "0.01 1 4 3 log2 mae 1.0 500: Macro 0.648486 (0.101535)\n",
      "Testing 169/5184\n",
      "0.01 1 4 3 sqrt friedman_mse 0.5 50: Weighted 0.820209 (0.054931)\n",
      "0.01 1 4 3 sqrt friedman_mse 0.5 50: Macro 0.708434 (0.081897)\n",
      "Testing 170/5184\n",
      "0.01 1 4 3 sqrt friedman_mse 0.5 100: Weighted 0.819410 (0.043881)\n",
      "0.01 1 4 3 sqrt friedman_mse 0.5 100: Macro 0.711588 (0.058976)\n",
      "Testing 171/5184\n",
      "0.01 1 4 3 sqrt friedman_mse 0.5 200: Weighted 0.815476 (0.056810)\n",
      "0.01 1 4 3 sqrt friedman_mse 0.5 200: Macro 0.704835 (0.082664)\n",
      "Testing 172/5184\n",
      "0.01 1 4 3 sqrt friedman_mse 0.5 500: Weighted 0.801796 (0.059427)\n",
      "0.01 1 4 3 sqrt friedman_mse 0.5 500: Macro 0.693245 (0.088186)\n",
      "Testing 173/5184\n",
      "0.01 1 4 3 sqrt friedman_mse 0.75 50: Weighted 0.820081 (0.055117)\n",
      "0.01 1 4 3 sqrt friedman_mse 0.75 50: Macro 0.714542 (0.072685)\n",
      "Testing 174/5184\n",
      "0.01 1 4 3 sqrt friedman_mse 0.75 100: Weighted 0.803255 (0.070353)\n",
      "0.01 1 4 3 sqrt friedman_mse 0.75 100: Macro 0.693274 (0.093835)\n",
      "Testing 175/5184\n",
      "0.01 1 4 3 sqrt friedman_mse 0.75 200: Weighted 0.797138 (0.071533)\n",
      "0.01 1 4 3 sqrt friedman_mse 0.75 200: Macro 0.686660 (0.092927)\n",
      "Testing 176/5184\n",
      "0.01 1 4 3 sqrt friedman_mse 0.75 500: Weighted 0.804458 (0.070490)\n",
      "0.01 1 4 3 sqrt friedman_mse 0.75 500: Macro 0.704903 (0.087073)\n",
      "Testing 177/5184\n",
      "0.01 1 4 3 sqrt friedman_mse 1.0 50: Weighted 0.804154 (0.051475)\n",
      "0.01 1 4 3 sqrt friedman_mse 1.0 50: Macro 0.694058 (0.075297)\n",
      "Testing 178/5184\n",
      "0.01 1 4 3 sqrt friedman_mse 1.0 100: Weighted 0.789891 (0.064029)\n",
      "0.01 1 4 3 sqrt friedman_mse 1.0 100: Macro 0.679985 (0.086985)\n",
      "Testing 179/5184\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01 1 4 3 sqrt friedman_mse 1.0 200: Weighted 0.797332 (0.051684)\n",
      "0.01 1 4 3 sqrt friedman_mse 1.0 200: Macro 0.693020 (0.060210)\n",
      "Testing 180/5184\n",
      "0.01 1 4 3 sqrt friedman_mse 1.0 500: Weighted 0.797623 (0.067722)\n",
      "0.01 1 4 3 sqrt friedman_mse 1.0 500: Macro 0.693810 (0.095800)\n",
      "Testing 181/5184\n",
      "0.01 1 4 3 sqrt mae 0.5 50: Weighted 0.798848 (0.064842)\n",
      "0.01 1 4 3 sqrt mae 0.5 50: Macro 0.683021 (0.089445)\n",
      "Testing 182/5184\n",
      "0.01 1 4 3 sqrt mae 0.5 100: Weighted 0.816386 (0.048990)\n",
      "0.01 1 4 3 sqrt mae 0.5 100: Macro 0.705788 (0.066974)\n",
      "Testing 183/5184\n",
      "0.01 1 4 3 sqrt mae 0.5 200: Weighted 0.808201 (0.054866)\n",
      "0.01 1 4 3 sqrt mae 0.5 200: Macro 0.697301 (0.072138)\n",
      "Testing 184/5184\n",
      "0.01 1 4 3 sqrt mae 0.5 500: Weighted 0.800828 (0.058895)\n",
      "0.01 1 4 3 sqrt mae 0.5 500: Macro 0.681969 (0.083313)\n",
      "Testing 185/5184\n",
      "0.01 1 4 3 sqrt mae 0.75 50: Weighted 0.787322 (0.064692)\n",
      "0.01 1 4 3 sqrt mae 0.75 50: Macro 0.669603 (0.086992)\n",
      "Testing 186/5184\n",
      "0.01 1 4 3 sqrt mae 0.75 100: Weighted 0.793311 (0.054838)\n",
      "0.01 1 4 3 sqrt mae 0.75 100: Macro 0.687867 (0.069888)\n",
      "Testing 187/5184\n",
      "0.01 1 4 3 sqrt mae 0.75 200: Weighted 0.780242 (0.058244)\n",
      "0.01 1 4 3 sqrt mae 0.75 200: Macro 0.657088 (0.084328)\n",
      "Testing 188/5184\n",
      "0.01 1 4 3 sqrt mae 0.75 500: Weighted 0.791404 (0.059883)\n",
      "0.01 1 4 3 sqrt mae 0.75 500: Macro 0.676652 (0.081460)\n",
      "Testing 189/5184\n",
      "0.01 1 4 3 sqrt mae 1.0 50: Weighted 0.797564 (0.060384)\n",
      "0.01 1 4 3 sqrt mae 1.0 50: Macro 0.693678 (0.082379)\n",
      "Testing 190/5184\n",
      "0.01 1 4 3 sqrt mae 1.0 100: Weighted 0.788059 (0.065078)\n",
      "0.01 1 4 3 sqrt mae 1.0 100: Macro 0.676962 (0.087865)\n",
      "Testing 191/5184\n",
      "0.01 1 4 3 sqrt mae 1.0 200: Weighted 0.783509 (0.066484)\n",
      "0.01 1 4 3 sqrt mae 1.0 200: Macro 0.675482 (0.084866)\n",
      "Testing 192/5184\n",
      "0.01 1 4 3 sqrt mae 1.0 500: Weighted 0.781394 (0.078808)\n",
      "0.01 1 4 3 sqrt mae 1.0 500: Macro 0.666300 (0.108509)\n",
      "Testing 193/5184\n",
      "0.01 1 4 5 log2 friedman_mse 0.5 50: Weighted 0.817365 (0.037860)\n",
      "0.01 1 4 5 log2 friedman_mse 0.5 50: Macro 0.710382 (0.048335)\n",
      "Testing 194/5184\n",
      "0.01 1 4 5 log2 friedman_mse 0.5 100: Weighted 0.805839 (0.048473)\n",
      "0.01 1 4 5 log2 friedman_mse 0.5 100: Macro 0.692833 (0.069812)\n",
      "Testing 195/5184\n",
      "0.01 1 4 5 log2 friedman_mse 0.5 200: Weighted 0.808161 (0.053626)\n",
      "0.01 1 4 5 log2 friedman_mse 0.5 200: Macro 0.698005 (0.073826)\n",
      "Testing 196/5184\n",
      "0.01 1 4 5 log2 friedman_mse 0.5 500: Weighted 0.815692 (0.079359)\n",
      "0.01 1 4 5 log2 friedman_mse 0.5 500: Macro 0.710294 (0.115339)\n",
      "Testing 197/5184\n",
      "0.01 1 4 5 log2 friedman_mse 0.75 50: Weighted 0.793123 (0.051771)\n",
      "0.01 1 4 5 log2 friedman_mse 0.75 50: Macro 0.680224 (0.064864)\n",
      "Testing 198/5184\n",
      "0.01 1 4 5 log2 friedman_mse 0.75 100: Weighted 0.795098 (0.058122)\n",
      "0.01 1 4 5 log2 friedman_mse 0.75 100: Macro 0.685069 (0.078856)\n",
      "Testing 199/5184\n",
      "0.01 1 4 5 log2 friedman_mse 0.75 200: Weighted 0.803640 (0.059874)\n",
      "0.01 1 4 5 log2 friedman_mse 0.75 200: Macro 0.695861 (0.080493)\n",
      "Testing 200/5184\n",
      "0.01 1 4 5 log2 friedman_mse 0.75 500: Weighted 0.807917 (0.085989)\n",
      "0.01 1 4 5 log2 friedman_mse 0.75 500: Macro 0.702340 (0.122238)\n",
      "Testing 201/5184\n",
      "0.01 1 4 5 log2 friedman_mse 1.0 50: Weighted 0.772121 (0.062296)\n",
      "0.01 1 4 5 log2 friedman_mse 1.0 50: Macro 0.657904 (0.081834)\n",
      "Testing 202/5184\n",
      "0.01 1 4 5 log2 friedman_mse 1.0 100: Weighted 0.784168 (0.067775)\n",
      "0.01 1 4 5 log2 friedman_mse 1.0 100: Macro 0.671195 (0.088031)\n",
      "Testing 203/5184\n",
      "0.01 1 4 5 log2 friedman_mse 1.0 200: Weighted 0.787914 (0.065794)\n",
      "0.01 1 4 5 log2 friedman_mse 1.0 200: Macro 0.675666 (0.085586)\n",
      "Testing 204/5184\n",
      "0.01 1 4 5 log2 friedman_mse 1.0 500: Weighted 0.799180 (0.078302)\n",
      "0.01 1 4 5 log2 friedman_mse 1.0 500: Macro 0.698748 (0.119270)\n",
      "Testing 205/5184\n",
      "0.01 1 4 5 log2 mae 0.5 50: Weighted 0.792769 (0.051867)\n",
      "0.01 1 4 5 log2 mae 0.5 50: Macro 0.672812 (0.077438)\n",
      "Testing 206/5184\n",
      "0.01 1 4 5 log2 mae 0.5 100: Weighted 0.797997 (0.053761)\n",
      "0.01 1 4 5 log2 mae 0.5 100: Macro 0.679092 (0.080154)\n",
      "Testing 207/5184\n",
      "0.01 1 4 5 log2 mae 0.5 200: Weighted 0.799411 (0.052285)\n",
      "0.01 1 4 5 log2 mae 0.5 200: Macro 0.683396 (0.076248)\n",
      "Testing 208/5184\n",
      "0.01 1 4 5 log2 mae 0.5 500: Weighted 0.787848 (0.043502)\n",
      "0.01 1 4 5 log2 mae 0.5 500: Macro 0.668253 (0.067530)\n",
      "Testing 209/5184\n",
      "0.01 1 4 5 log2 mae 0.75 50: Weighted 0.783025 (0.050218)\n",
      "0.01 1 4 5 log2 mae 0.75 50: Macro 0.661480 (0.072219)\n",
      "Testing 210/5184\n",
      "0.01 1 4 5 log2 mae 0.75 100: Weighted 0.779281 (0.051939)\n",
      "0.01 1 4 5 log2 mae 0.75 100: Macro 0.660776 (0.074976)\n",
      "Testing 211/5184\n",
      "0.01 1 4 5 log2 mae 0.75 200: Weighted 0.782784 (0.058871)\n",
      "0.01 1 4 5 log2 mae 0.75 200: Macro 0.668611 (0.081434)\n",
      "Testing 212/5184\n",
      "0.01 1 4 5 log2 mae 0.75 500: Weighted 0.778751 (0.070837)\n",
      "0.01 1 4 5 log2 mae 0.75 500: Macro 0.658866 (0.104615)\n",
      "Testing 213/5184\n",
      "0.01 1 4 5 log2 mae 1.0 50: Weighted 0.780064 (0.052396)\n",
      "0.01 1 4 5 log2 mae 1.0 50: Macro 0.660499 (0.075635)\n",
      "Testing 214/5184\n",
      "0.01 1 4 5 log2 mae 1.0 100: Weighted 0.765718 (0.043814)\n",
      "0.01 1 4 5 log2 mae 1.0 100: Macro 0.645156 (0.066451)\n",
      "Testing 215/5184\n",
      "0.01 1 4 5 log2 mae 1.0 200: Weighted 0.772628 (0.047583)\n",
      "0.01 1 4 5 log2 mae 1.0 200: Macro 0.648326 (0.076376)\n",
      "Testing 216/5184\n",
      "0.01 1 4 5 log2 mae 1.0 500: Weighted 0.772950 (0.068494)\n",
      "0.01 1 4 5 log2 mae 1.0 500: Macro 0.642677 (0.101629)\n",
      "Testing 217/5184\n",
      "0.01 1 4 5 sqrt friedman_mse 0.5 50: Weighted 0.818792 (0.050836)\n",
      "0.01 1 4 5 sqrt friedman_mse 0.5 50: Macro 0.717704 (0.071132)\n",
      "Testing 218/5184\n",
      "0.01 1 4 5 sqrt friedman_mse 0.5 100: Weighted 0.813691 (0.041371)\n",
      "0.01 1 4 5 sqrt friedman_mse 0.5 100: Macro 0.706392 (0.056162)\n",
      "Testing 219/5184\n",
      "0.01 1 4 5 sqrt friedman_mse 0.5 200: Weighted 0.816712 (0.046345)\n",
      "0.01 1 4 5 sqrt friedman_mse 0.5 200: Macro 0.715544 (0.059258)\n",
      "Testing 220/5184\n",
      "0.01 1 4 5 sqrt friedman_mse 0.5 500: Weighted 0.806841 (0.076469)\n",
      "0.01 1 4 5 sqrt friedman_mse 0.5 500: Macro 0.699305 (0.106956)\n",
      "Testing 221/5184\n",
      "0.01 1 4 5 sqrt friedman_mse 0.75 50: Weighted 0.796025 (0.057418)\n",
      "0.01 1 4 5 sqrt friedman_mse 0.75 50: Macro 0.678614 (0.077800)\n",
      "Testing 222/5184\n",
      "0.01 1 4 5 sqrt friedman_mse 0.75 100: Weighted 0.798505 (0.057091)\n",
      "0.01 1 4 5 sqrt friedman_mse 0.75 100: Macro 0.690062 (0.077859)\n",
      "Testing 223/5184\n",
      "0.01 1 4 5 sqrt friedman_mse 0.75 200: Weighted 0.796605 (0.054260)\n",
      "0.01 1 4 5 sqrt friedman_mse 0.75 200: Macro 0.683880 (0.074808)\n",
      "Testing 224/5184\n",
      "0.01 1 4 5 sqrt friedman_mse 0.75 500: Weighted 0.807119 (0.075965)\n",
      "0.01 1 4 5 sqrt friedman_mse 0.75 500: Macro 0.705956 (0.101966)\n",
      "Testing 225/5184\n",
      "0.01 1 4 5 sqrt friedman_mse 1.0 50: Weighted 0.783654 (0.066519)\n",
      "0.01 1 4 5 sqrt friedman_mse 1.0 50: Macro 0.676013 (0.089488)\n",
      "Testing 226/5184\n",
      "0.01 1 4 5 sqrt friedman_mse 1.0 100: Weighted 0.773908 (0.056887)\n",
      "0.01 1 4 5 sqrt friedman_mse 1.0 100: Macro 0.658299 (0.076450)\n",
      "Testing 227/5184\n",
      "0.01 1 4 5 sqrt friedman_mse 1.0 200: Weighted 0.787575 (0.059993)\n",
      "0.01 1 4 5 sqrt friedman_mse 1.0 200: Macro 0.677576 (0.084175)\n",
      "Testing 228/5184\n",
      "0.01 1 4 5 sqrt friedman_mse 1.0 500: Weighted 0.798836 (0.076729)\n",
      "0.01 1 4 5 sqrt friedman_mse 1.0 500: Macro 0.700705 (0.114010)\n",
      "Testing 229/5184\n",
      "0.01 1 4 5 sqrt mae 0.5 50: Weighted 0.806521 (0.056401)\n",
      "0.01 1 4 5 sqrt mae 0.5 50: Macro 0.686804 (0.081686)\n",
      "Testing 230/5184\n",
      "0.01 1 4 5 sqrt mae 0.5 100: Weighted 0.786356 (0.055375)\n",
      "0.01 1 4 5 sqrt mae 0.5 100: Macro 0.670836 (0.080228)\n",
      "Testing 231/5184\n",
      "0.01 1 4 5 sqrt mae 0.5 200: Weighted 0.791137 (0.040172)\n",
      "0.01 1 4 5 sqrt mae 0.5 200: Macro 0.672685 (0.063443)\n",
      "Testing 232/5184\n",
      "0.01 1 4 5 sqrt mae 0.5 500: Weighted 0.790516 (0.040836)\n",
      "0.01 1 4 5 sqrt mae 0.5 500: Macro 0.673124 (0.062952)\n",
      "Testing 233/5184\n",
      "0.01 1 4 5 sqrt mae 0.75 50: Weighted 0.783189 (0.048186)\n",
      "0.01 1 4 5 sqrt mae 0.75 50: Macro 0.663636 (0.072398)\n",
      "Testing 234/5184\n",
      "0.01 1 4 5 sqrt mae 0.75 100: Weighted 0.783395 (0.047960)\n",
      "0.01 1 4 5 sqrt mae 0.75 100: Macro 0.664890 (0.071020)\n",
      "Testing 235/5184\n",
      "0.01 1 4 5 sqrt mae 0.75 200: Weighted 0.787693 (0.045259)\n",
      "0.01 1 4 5 sqrt mae 0.75 200: Macro 0.669219 (0.068032)\n",
      "Testing 236/5184\n",
      "0.01 1 4 5 sqrt mae 0.75 500: Weighted 0.773031 (0.065163)\n",
      "0.01 1 4 5 sqrt mae 0.75 500: Macro 0.653863 (0.099303)\n",
      "Testing 237/5184\n",
      "0.01 1 4 5 sqrt mae 1.0 50: Weighted 0.773636 (0.046098)\n",
      "0.01 1 4 5 sqrt mae 1.0 50: Macro 0.657588 (0.072237)\n",
      "Testing 238/5184\n",
      "0.01 1 4 5 sqrt mae 1.0 100: Weighted 0.774213 (0.050209)\n",
      "0.01 1 4 5 sqrt mae 1.0 100: Macro 0.655785 (0.074454)\n",
      "Testing 239/5184\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01 1 4 5 sqrt mae 1.0 200: Weighted 0.775619 (0.046984)\n",
      "0.01 1 4 5 sqrt mae 1.0 200: Macro 0.650894 (0.075539)\n",
      "Testing 240/5184\n",
      "0.01 1 4 5 sqrt mae 1.0 500: Weighted 0.776878 (0.065683)\n",
      "0.01 1 4 5 sqrt mae 1.0 500: Macro 0.645403 (0.099170)\n",
      "Testing 241/5184\n",
      "0.01 1 4 8 log2 friedman_mse 0.5 50: Weighted 0.817111 (0.048979)\n",
      "0.01 1 4 8 log2 friedman_mse 0.5 50: Macro 0.714555 (0.062414)\n",
      "Testing 242/5184\n",
      "0.01 1 4 8 log2 friedman_mse 0.5 100: Weighted 0.802645 (0.048768)\n",
      "0.01 1 4 8 log2 friedman_mse 0.5 100: Macro 0.693199 (0.064084)\n",
      "Testing 243/5184\n",
      "0.01 1 4 8 log2 friedman_mse 0.5 200: Weighted 0.804281 (0.056912)\n",
      "0.01 1 4 8 log2 friedman_mse 0.5 200: Macro 0.696037 (0.076773)\n",
      "Testing 244/5184\n",
      "0.01 1 4 8 log2 friedman_mse 0.5 500: Weighted 0.811902 (0.079400)\n",
      "0.01 1 4 8 log2 friedman_mse 0.5 500: Macro 0.701348 (0.114838)\n",
      "Testing 245/5184\n",
      "0.01 1 4 8 log2 friedman_mse 0.75 50: Weighted 0.805932 (0.061871)\n",
      "0.01 1 4 8 log2 friedman_mse 0.75 50: Macro 0.700206 (0.081116)\n",
      "Testing 246/5184\n",
      "0.01 1 4 8 log2 friedman_mse 0.75 100: Weighted 0.793399 (0.068058)\n",
      "0.01 1 4 8 log2 friedman_mse 0.75 100: Macro 0.682690 (0.090793)\n",
      "Testing 247/5184\n",
      "0.01 1 4 8 log2 friedman_mse 0.75 200: Weighted 0.797865 (0.063042)\n",
      "0.01 1 4 8 log2 friedman_mse 0.75 200: Macro 0.686015 (0.086937)\n",
      "Testing 248/5184\n",
      "0.01 1 4 8 log2 friedman_mse 0.75 500: Weighted 0.810276 (0.083957)\n",
      "0.01 1 4 8 log2 friedman_mse 0.75 500: Macro 0.708117 (0.118584)\n",
      "Testing 249/5184\n",
      "0.01 1 4 8 log2 friedman_mse 1.0 50: Weighted 0.774730 (0.054634)\n",
      "0.01 1 4 8 log2 friedman_mse 1.0 50: Macro 0.657053 (0.072474)\n",
      "Testing 250/5184\n",
      "0.01 1 4 8 log2 friedman_mse 1.0 100: Weighted 0.783597 (0.055378)\n",
      "0.01 1 4 8 log2 friedman_mse 1.0 100: Macro 0.668777 (0.079829)\n",
      "Testing 251/5184\n",
      "0.01 1 4 8 log2 friedman_mse 1.0 200: Weighted 0.788180 (0.072505)\n",
      "0.01 1 4 8 log2 friedman_mse 1.0 200: Macro 0.670737 (0.102854)\n",
      "Testing 252/5184\n",
      "0.01 1 4 8 log2 friedman_mse 1.0 500: Weighted 0.784841 (0.054848)\n",
      "0.01 1 4 8 log2 friedman_mse 1.0 500: Macro 0.670844 (0.087635)\n",
      "Testing 253/5184\n",
      "0.01 1 4 8 log2 mae 0.5 50: Weighted 0.789276 (0.056049)\n",
      "0.01 1 4 8 log2 mae 0.5 50: Macro 0.670789 (0.079472)\n",
      "Testing 254/5184\n",
      "0.01 1 4 8 log2 mae 0.5 100: Weighted 0.786829 (0.046922)\n",
      "0.01 1 4 8 log2 mae 0.5 100: Macro 0.661861 (0.077375)\n",
      "Testing 255/5184\n",
      "0.01 1 4 8 log2 mae 0.5 200: Weighted 0.794242 (0.048089)\n",
      "0.01 1 4 8 log2 mae 0.5 200: Macro 0.679924 (0.071436)\n",
      "Testing 256/5184\n",
      "0.01 1 4 8 log2 mae 0.5 500: Weighted 0.801677 (0.039634)\n",
      "0.01 1 4 8 log2 mae 0.5 500: Macro 0.688942 (0.062697)\n",
      "Testing 257/5184\n",
      "0.01 1 4 8 log2 mae 0.75 50: Weighted 0.774739 (0.047268)\n",
      "0.01 1 4 8 log2 mae 0.75 50: Macro 0.654153 (0.067825)\n",
      "Testing 258/5184\n",
      "0.01 1 4 8 log2 mae 0.75 100: Weighted 0.777796 (0.042073)\n",
      "0.01 1 4 8 log2 mae 0.75 100: Macro 0.660041 (0.065194)\n",
      "Testing 259/5184\n",
      "0.01 1 4 8 log2 mae 0.75 200: Weighted 0.772663 (0.049887)\n",
      "0.01 1 4 8 log2 mae 0.75 200: Macro 0.646340 (0.077886)\n",
      "Testing 260/5184\n",
      "0.01 1 4 8 log2 mae 0.75 500: Weighted 0.782778 (0.048746)\n",
      "0.01 1 4 8 log2 mae 0.75 500: Macro 0.665257 (0.071001)\n",
      "Testing 261/5184\n",
      "0.01 1 4 8 log2 mae 1.0 50: Weighted 0.763699 (0.040111)\n",
      "0.01 1 4 8 log2 mae 1.0 50: Macro 0.634025 (0.064297)\n",
      "Testing 262/5184\n",
      "0.01 1 4 8 log2 mae 1.0 100: Weighted 0.769082 (0.053754)\n",
      "0.01 1 4 8 log2 mae 1.0 100: Macro 0.635570 (0.087618)\n",
      "Testing 263/5184\n",
      "0.01 1 4 8 log2 mae 1.0 200: Weighted 0.767179 (0.064363)\n",
      "0.01 1 4 8 log2 mae 1.0 200: Macro 0.634437 (0.101185)\n",
      "Testing 264/5184\n",
      "0.01 1 4 8 log2 mae 1.0 500: Weighted 0.777769 (0.071337)\n",
      "0.01 1 4 8 log2 mae 1.0 500: Macro 0.656512 (0.101137)\n",
      "Testing 265/5184\n",
      "0.01 1 4 8 sqrt friedman_mse 0.5 50: Weighted 0.803091 (0.068644)\n",
      "0.01 1 4 8 sqrt friedman_mse 0.5 50: Macro 0.692157 (0.097724)\n",
      "Testing 266/5184\n",
      "0.01 1 4 8 sqrt friedman_mse 0.5 100: Weighted 0.808849 (0.053535)\n",
      "0.01 1 4 8 sqrt friedman_mse 0.5 100: Macro 0.699518 (0.073872)\n",
      "Testing 267/5184\n",
      "0.01 1 4 8 sqrt friedman_mse 0.5 200: Weighted 0.803270 (0.057799)\n",
      "0.01 1 4 8 sqrt friedman_mse 0.5 200: Macro 0.689418 (0.083228)\n",
      "Testing 268/5184\n",
      "0.01 1 4 8 sqrt friedman_mse 0.5 500: Weighted 0.822562 (0.079338)\n",
      "0.01 1 4 8 sqrt friedman_mse 0.5 500: Macro 0.716935 (0.116471)\n",
      "Testing 269/5184\n",
      "0.01 1 4 8 sqrt friedman_mse 0.75 50: Weighted 0.798966 (0.072361)\n",
      "0.01 1 4 8 sqrt friedman_mse 0.75 50: Macro 0.688386 (0.100422)\n",
      "Testing 270/5184\n",
      "0.01 1 4 8 sqrt friedman_mse 0.75 100: Weighted 0.798039 (0.063104)\n",
      "0.01 1 4 8 sqrt friedman_mse 0.75 100: Macro 0.685118 (0.086458)\n",
      "Testing 271/5184\n",
      "0.01 1 4 8 sqrt friedman_mse 0.75 200: Weighted 0.797865 (0.063042)\n",
      "0.01 1 4 8 sqrt friedman_mse 0.75 200: Macro 0.686015 (0.086937)\n",
      "Testing 272/5184\n",
      "0.01 1 4 8 sqrt friedman_mse 0.75 500: Weighted 0.805660 (0.076693)\n",
      "0.01 1 4 8 sqrt friedman_mse 0.75 500: Macro 0.704353 (0.112823)\n",
      "Testing 273/5184\n",
      "0.01 1 4 8 sqrt friedman_mse 1.0 50: Weighted 0.777667 (0.051012)\n",
      "0.01 1 4 8 sqrt friedman_mse 1.0 50: Macro 0.662942 (0.070392)\n",
      "Testing 274/5184\n",
      "0.01 1 4 8 sqrt friedman_mse 1.0 100: Weighted 0.781448 (0.053599)\n",
      "0.01 1 4 8 sqrt friedman_mse 1.0 100: Macro 0.669792 (0.074930)\n",
      "Testing 275/5184\n",
      "0.01 1 4 8 sqrt friedman_mse 1.0 200: Weighted 0.785111 (0.060626)\n",
      "0.01 1 4 8 sqrt friedman_mse 1.0 200: Macro 0.668800 (0.089286)\n",
      "Testing 276/5184\n",
      "0.01 1 4 8 sqrt friedman_mse 1.0 500: Weighted 0.784172 (0.068627)\n",
      "0.01 1 4 8 sqrt friedman_mse 1.0 500: Macro 0.675945 (0.099359)\n",
      "Testing 277/5184\n",
      "0.01 1 4 8 sqrt mae 0.5 50: Weighted 0.792259 (0.055622)\n",
      "0.01 1 4 8 sqrt mae 0.5 50: Macro 0.671845 (0.078544)\n",
      "Testing 278/5184\n",
      "0.01 1 4 8 sqrt mae 0.5 100: Weighted 0.801587 (0.042609)\n",
      "0.01 1 4 8 sqrt mae 0.5 100: Macro 0.687388 (0.066243)\n",
      "Testing 279/5184\n",
      "0.01 1 4 8 sqrt mae 0.5 200: Weighted 0.787227 (0.044070)\n",
      "0.01 1 4 8 sqrt mae 0.5 200: Macro 0.668693 (0.067098)\n",
      "Testing 280/5184\n",
      "0.01 1 4 8 sqrt mae 0.5 500: Weighted 0.802575 (0.038778)\n",
      "0.01 1 4 8 sqrt mae 0.5 500: Macro 0.688770 (0.062839)\n",
      "Testing 281/5184\n",
      "0.01 1 4 8 sqrt mae 0.75 50: Weighted 0.783878 (0.025586)\n",
      "0.01 1 4 8 sqrt mae 0.75 50: Macro 0.666155 (0.046112)\n",
      "Testing 282/5184\n",
      "0.01 1 4 8 sqrt mae 0.75 100: Weighted 0.777644 (0.056317)\n",
      "0.01 1 4 8 sqrt mae 0.75 100: Macro 0.661456 (0.078877)\n",
      "Testing 283/5184\n",
      "0.01 1 4 8 sqrt mae 0.75 200: Weighted 0.802006 (0.039352)\n",
      "0.01 1 4 8 sqrt mae 0.75 200: Macro 0.689266 (0.062309)\n",
      "Testing 284/5184\n",
      "0.01 1 4 8 sqrt mae 0.75 500: Weighted 0.788732 (0.052948)\n",
      "0.01 1 4 8 sqrt mae 0.75 500: Macro 0.668895 (0.084433)\n",
      "Testing 285/5184\n",
      "0.01 1 4 8 sqrt mae 1.0 50: Weighted 0.771134 (0.060075)\n",
      "0.01 1 4 8 sqrt mae 1.0 50: Macro 0.645876 (0.090668)\n",
      "Testing 286/5184\n",
      "0.01 1 4 8 sqrt mae 1.0 100: Weighted 0.780520 (0.038923)\n",
      "0.01 1 4 8 sqrt mae 1.0 100: Macro 0.660150 (0.056696)\n",
      "Testing 287/5184\n",
      "0.01 1 4 8 sqrt mae 1.0 200: Weighted 0.783295 (0.075861)\n",
      "0.01 1 4 8 sqrt mae 1.0 200: Macro 0.665370 (0.112260)\n",
      "Testing 288/5184\n",
      "0.01 1 4 8 sqrt mae 1.0 500: Weighted 0.773974 (0.064848)\n",
      "0.01 1 4 8 sqrt mae 1.0 500: Macro 0.651255 (0.102380)\n",
      "Testing 289/5184\n",
      "0.01 1 6 3 log2 friedman_mse 0.5 50: Weighted 0.823749 (0.049614)\n",
      "0.01 1 6 3 log2 friedman_mse 0.5 50: Macro 0.719324 (0.067545)\n",
      "Testing 290/5184\n",
      "0.01 1 6 3 log2 friedman_mse 0.5 100: Weighted 0.827972 (0.047784)\n",
      "0.01 1 6 3 log2 friedman_mse 0.5 100: Macro 0.723114 (0.066644)\n",
      "Testing 291/5184\n",
      "0.01 1 6 3 log2 friedman_mse 0.5 200: Weighted 0.823930 (0.049686)\n",
      "0.01 1 6 3 log2 friedman_mse 0.5 200: Macro 0.718400 (0.067077)\n",
      "Testing 292/5184\n",
      "0.01 1 6 3 log2 friedman_mse 0.5 500: Weighted 0.810630 (0.051333)\n",
      "0.01 1 6 3 log2 friedman_mse 0.5 500: Macro 0.711892 (0.068890)\n",
      "Testing 293/5184\n",
      "0.01 1 6 3 log2 friedman_mse 0.75 50: Weighted 0.811363 (0.051750)\n",
      "0.01 1 6 3 log2 friedman_mse 0.75 50: Macro 0.703033 (0.065864)\n",
      "Testing 294/5184\n",
      "0.01 1 6 3 log2 friedman_mse 0.75 100: Weighted 0.815167 (0.056889)\n",
      "0.01 1 6 3 log2 friedman_mse 0.75 100: Macro 0.711868 (0.074365)\n",
      "Testing 295/5184\n",
      "0.01 1 6 3 log2 friedman_mse 0.75 200: Weighted 0.802143 (0.063843)\n",
      "0.01 1 6 3 log2 friedman_mse 0.75 200: Macro 0.691456 (0.085272)\n",
      "Testing 296/5184\n",
      "0.01 1 6 3 log2 friedman_mse 0.75 500: Weighted 0.812646 (0.064221)\n",
      "0.01 1 6 3 log2 friedman_mse 0.75 500: Macro 0.711673 (0.081391)\n",
      "Testing 297/5184\n",
      "0.01 1 6 3 log2 friedman_mse 1.0 50: Weighted 0.805743 (0.069275)\n",
      "0.01 1 6 3 log2 friedman_mse 1.0 50: Macro 0.698146 (0.083324)\n",
      "Testing 298/5184\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01 1 6 3 log2 friedman_mse 1.0 100: Weighted 0.795282 (0.059792)\n",
      "0.01 1 6 3 log2 friedman_mse 1.0 100: Macro 0.689830 (0.068099)\n",
      "Testing 299/5184\n",
      "0.01 1 6 3 log2 friedman_mse 1.0 200: Weighted 0.794035 (0.063983)\n",
      "0.01 1 6 3 log2 friedman_mse 1.0 200: Macro 0.681503 (0.079425)\n",
      "Testing 300/5184\n",
      "0.01 1 6 3 log2 friedman_mse 1.0 500: Weighted 0.802343 (0.065761)\n",
      "0.01 1 6 3 log2 friedman_mse 1.0 500: Macro 0.703261 (0.088796)\n",
      "Testing 301/5184\n",
      "0.01 1 6 3 log2 mae 0.5 50: Weighted 0.816087 (0.057114)\n",
      "0.01 1 6 3 log2 mae 0.5 50: Macro 0.707871 (0.076731)\n",
      "Testing 302/5184\n",
      "0.01 1 6 3 log2 mae 0.5 100: Weighted 0.807809 (0.056932)\n",
      "0.01 1 6 3 log2 mae 0.5 100: Macro 0.695770 (0.075758)\n",
      "Testing 303/5184\n",
      "0.01 1 6 3 log2 mae 0.5 200: Weighted 0.804365 (0.061292)\n",
      "0.01 1 6 3 log2 mae 0.5 200: Macro 0.686311 (0.088368)\n",
      "Testing 304/5184\n",
      "0.01 1 6 3 log2 mae 0.5 500: Weighted 0.799524 (0.057326)\n",
      "0.01 1 6 3 log2 mae 0.5 500: Macro 0.683667 (0.085264)\n",
      "Testing 305/5184\n",
      "0.01 1 6 3 log2 mae 0.75 50: Weighted 0.796283 (0.062009)\n",
      "0.01 1 6 3 log2 mae 0.75 50: Macro 0.675877 (0.085120)\n",
      "Testing 306/5184\n",
      "0.01 1 6 3 log2 mae 0.75 100: Weighted 0.801764 (0.055550)\n",
      "0.01 1 6 3 log2 mae 0.75 100: Macro 0.697545 (0.069461)\n",
      "Testing 307/5184\n",
      "0.01 1 6 3 log2 mae 0.75 200: Weighted 0.794673 (0.067403)\n",
      "0.01 1 6 3 log2 mae 0.75 200: Macro 0.680027 (0.090233)\n",
      "Testing 308/5184\n",
      "0.01 1 6 3 log2 mae 0.75 500: Weighted 0.778202 (0.061614)\n",
      "0.01 1 6 3 log2 mae 0.75 500: Macro 0.661921 (0.086800)\n",
      "Testing 309/5184\n",
      "0.01 1 6 3 log2 mae 1.0 50: Weighted 0.805444 (0.067307)\n",
      "0.01 1 6 3 log2 mae 1.0 50: Macro 0.698038 (0.088755)\n",
      "Testing 310/5184\n",
      "0.01 1 6 3 log2 mae 1.0 100: Weighted 0.787165 (0.070542)\n",
      "0.01 1 6 3 log2 mae 1.0 100: Macro 0.680318 (0.092860)\n",
      "Testing 311/5184\n",
      "0.01 1 6 3 log2 mae 1.0 200: Weighted 0.769556 (0.059740)\n",
      "0.01 1 6 3 log2 mae 1.0 200: Macro 0.651880 (0.074660)\n",
      "Testing 312/5184\n",
      "0.01 1 6 3 log2 mae 1.0 500: Weighted 0.773396 (0.077523)\n",
      "0.01 1 6 3 log2 mae 1.0 500: Macro 0.647158 (0.111844)\n",
      "Testing 313/5184\n",
      "0.01 1 6 3 sqrt friedman_mse 0.5 50: Weighted 0.820968 (0.050415)\n",
      "0.01 1 6 3 sqrt friedman_mse 0.5 50: Macro 0.713855 (0.070368)\n",
      "Testing 314/5184\n",
      "0.01 1 6 3 sqrt friedman_mse 0.5 100: Weighted 0.819851 (0.051304)\n",
      "0.01 1 6 3 sqrt friedman_mse 0.5 100: Macro 0.714356 (0.069136)\n",
      "Testing 315/5184\n",
      "0.01 1 6 3 sqrt friedman_mse 0.5 200: Weighted 0.828619 (0.043250)\n",
      "0.01 1 6 3 sqrt friedman_mse 0.5 200: Macro 0.727745 (0.056088)\n",
      "Testing 316/5184\n",
      "0.01 1 6 3 sqrt friedman_mse 0.5 500: Weighted 0.819577 (0.065569)\n",
      "0.01 1 6 3 sqrt friedman_mse 0.5 500: Macro 0.722828 (0.085990)\n",
      "Testing 317/5184\n",
      "0.01 1 6 3 sqrt friedman_mse 0.75 50: Weighted 0.811883 (0.054620)\n",
      "0.01 1 6 3 sqrt friedman_mse 0.75 50: Macro 0.702375 (0.071418)\n",
      "Testing 318/5184\n",
      "0.01 1 6 3 sqrt friedman_mse 0.75 100: Weighted 0.816644 (0.056356)\n",
      "0.01 1 6 3 sqrt friedman_mse 0.75 100: Macro 0.709518 (0.074446)\n",
      "Testing 319/5184\n",
      "0.01 1 6 3 sqrt friedman_mse 0.75 200: Weighted 0.803778 (0.061386)\n",
      "0.01 1 6 3 sqrt friedman_mse 0.75 200: Macro 0.694680 (0.080200)\n",
      "Testing 320/5184\n",
      "0.01 1 6 3 sqrt friedman_mse 0.75 500: Weighted 0.807840 (0.066317)\n",
      "0.01 1 6 3 sqrt friedman_mse 0.75 500: Macro 0.700824 (0.088018)\n",
      "Testing 321/5184\n",
      "0.01 1 6 3 sqrt friedman_mse 1.0 50: Weighted 0.788445 (0.066174)\n",
      "0.01 1 6 3 sqrt friedman_mse 1.0 50: Macro 0.677035 (0.091466)\n",
      "Testing 322/5184\n",
      "0.01 1 6 3 sqrt friedman_mse 1.0 100: Weighted 0.791920 (0.073240)\n",
      "0.01 1 6 3 sqrt friedman_mse 1.0 100: Macro 0.681940 (0.092453)\n",
      "Testing 323/5184\n",
      "0.01 1 6 3 sqrt friedman_mse 1.0 200: Weighted 0.795282 (0.059792)\n",
      "0.01 1 6 3 sqrt friedman_mse 1.0 200: Macro 0.689830 (0.068099)\n",
      "Testing 324/5184\n",
      "0.01 1 6 3 sqrt friedman_mse 1.0 500: Weighted 0.802341 (0.054111)\n",
      "0.01 1 6 3 sqrt friedman_mse 1.0 500: Macro 0.709175 (0.073487)\n",
      "Testing 325/5184\n",
      "0.01 1 6 3 sqrt mae 0.5 50: Weighted 0.811212 (0.043127)\n",
      "0.01 1 6 3 sqrt mae 0.5 50: Macro 0.699421 (0.056777)\n",
      "Testing 326/5184\n",
      "0.01 1 6 3 sqrt mae 0.5 100: Weighted 0.807033 (0.061216)\n",
      "0.01 1 6 3 sqrt mae 0.5 100: Macro 0.691508 (0.086743)\n",
      "Testing 327/5184\n",
      "0.01 1 6 3 sqrt mae 0.5 200: Weighted 0.815523 (0.056748)\n",
      "0.01 1 6 3 sqrt mae 0.5 200: Macro 0.708936 (0.076696)\n",
      "Testing 328/5184\n",
      "0.01 1 6 3 sqrt mae 0.5 500: Weighted 0.807357 (0.062455)\n",
      "0.01 1 6 3 sqrt mae 0.5 500: Macro 0.689094 (0.091097)\n",
      "Testing 329/5184\n",
      "0.01 1 6 3 sqrt mae 0.75 50: Weighted 0.788199 (0.072671)\n",
      "0.01 1 6 3 sqrt mae 0.75 50: Macro 0.669395 (0.096551)\n",
      "Testing 330/5184\n",
      "0.01 1 6 3 sqrt mae 0.75 100: Weighted 0.790907 (0.063066)\n",
      "0.01 1 6 3 sqrt mae 0.75 100: Macro 0.665917 (0.088706)\n",
      "Testing 331/5184\n",
      "0.01 1 6 3 sqrt mae 0.75 200: Weighted 0.779999 (0.058059)\n",
      "0.01 1 6 3 sqrt mae 0.75 200: Macro 0.657944 (0.085004)\n",
      "Testing 332/5184\n",
      "0.01 1 6 3 sqrt mae 0.75 500: Weighted 0.774842 (0.063545)\n",
      "0.01 1 6 3 sqrt mae 0.75 500: Macro 0.657585 (0.088893)\n",
      "Testing 333/5184\n",
      "0.01 1 6 3 sqrt mae 1.0 50: Weighted 0.781284 (0.059613)\n",
      "0.01 1 6 3 sqrt mae 1.0 50: Macro 0.660051 (0.078255)\n",
      "Testing 334/5184\n",
      "0.01 1 6 3 sqrt mae 1.0 100: Weighted 0.784545 (0.067118)\n",
      "0.01 1 6 3 sqrt mae 1.0 100: Macro 0.672732 (0.086236)\n",
      "Testing 335/5184\n",
      "0.01 1 6 3 sqrt mae 1.0 200: Weighted 0.771841 (0.062710)\n",
      "0.01 1 6 3 sqrt mae 1.0 200: Macro 0.658555 (0.080628)\n",
      "Testing 336/5184\n",
      "0.01 1 6 3 sqrt mae 1.0 500: Weighted 0.776509 (0.074359)\n",
      "0.01 1 6 3 sqrt mae 1.0 500: Macro 0.651445 (0.107131)\n",
      "Testing 337/5184\n",
      "0.01 1 6 5 log2 friedman_mse 0.5 50: Weighted 0.808765 (0.065722)\n",
      "0.01 1 6 5 log2 friedman_mse 0.5 50: Macro 0.700536 (0.088216)\n",
      "Testing 338/5184\n",
      "0.01 1 6 5 log2 friedman_mse 0.5 100: Weighted 0.814398 (0.050165)\n",
      "0.01 1 6 5 log2 friedman_mse 0.5 100: Macro 0.703402 (0.072911)\n",
      "Testing 339/5184\n",
      "0.01 1 6 5 log2 friedman_mse 0.5 200: Weighted 0.806646 (0.066834)\n",
      "0.01 1 6 5 log2 friedman_mse 0.5 200: Macro 0.695878 (0.090927)\n",
      "Testing 340/5184\n",
      "0.01 1 6 5 log2 friedman_mse 0.5 500: Weighted 0.812191 (0.082701)\n",
      "0.01 1 6 5 log2 friedman_mse 0.5 500: Macro 0.706970 (0.118586)\n",
      "Testing 341/5184\n",
      "0.01 1 6 5 log2 friedman_mse 0.75 50: Weighted 0.800111 (0.062531)\n",
      "0.01 1 6 5 log2 friedman_mse 0.75 50: Macro 0.685906 (0.089573)\n",
      "Testing 342/5184\n",
      "0.01 1 6 5 log2 friedman_mse 0.75 100: Weighted 0.800883 (0.052945)\n",
      "0.01 1 6 5 log2 friedman_mse 0.75 100: Macro 0.686781 (0.071097)\n",
      "Testing 343/5184\n",
      "0.01 1 6 5 log2 friedman_mse 0.75 200: Weighted 0.793954 (0.067408)\n",
      "0.01 1 6 5 log2 friedman_mse 0.75 200: Macro 0.681093 (0.092714)\n",
      "Testing 344/5184\n",
      "0.01 1 6 5 log2 friedman_mse 0.75 500: Weighted 0.807743 (0.085964)\n",
      "0.01 1 6 5 log2 friedman_mse 0.75 500: Macro 0.703237 (0.122451)\n",
      "Testing 345/5184\n",
      "0.01 1 6 5 log2 friedman_mse 1.0 50: Weighted 0.784518 (0.071789)\n",
      "0.01 1 6 5 log2 friedman_mse 1.0 50: Macro 0.670513 (0.092991)\n",
      "Testing 346/5184\n",
      "0.01 1 6 5 log2 friedman_mse 1.0 100: Weighted 0.783204 (0.064160)\n",
      "0.01 1 6 5 log2 friedman_mse 1.0 100: Macro 0.668166 (0.081449)\n",
      "Testing 347/5184\n",
      "0.01 1 6 5 log2 friedman_mse 1.0 200: Weighted 0.789278 (0.071267)\n",
      "0.01 1 6 5 log2 friedman_mse 1.0 200: Macro 0.678338 (0.094043)\n",
      "Testing 348/5184\n",
      "0.01 1 6 5 log2 friedman_mse 1.0 500: Weighted 0.789834 (0.069831)\n",
      "0.01 1 6 5 log2 friedman_mse 1.0 500: Macro 0.683471 (0.104812)\n",
      "Testing 349/5184\n",
      "0.01 1 6 5 log2 mae 0.5 50: Weighted 0.805285 (0.047344)\n",
      "0.01 1 6 5 log2 mae 0.5 50: Macro 0.695468 (0.059029)\n",
      "Testing 350/5184\n",
      "0.01 1 6 5 log2 mae 0.5 100: Weighted 0.806489 (0.045629)\n",
      "0.01 1 6 5 log2 mae 0.5 100: Macro 0.689693 (0.062896)\n",
      "Testing 351/5184\n",
      "0.01 1 6 5 log2 mae 0.5 200: Weighted 0.799901 (0.063037)\n",
      "0.01 1 6 5 log2 mae 0.5 200: Macro 0.682009 (0.086912)\n",
      "Testing 352/5184\n",
      "0.01 1 6 5 log2 mae 0.5 500: Weighted 0.799411 (0.052285)\n",
      "0.01 1 6 5 log2 mae 0.5 500: Macro 0.683396 (0.076248)\n",
      "Testing 353/5184\n",
      "0.01 1 6 5 log2 mae 0.75 50: Weighted 0.786188 (0.047036)\n",
      "0.01 1 6 5 log2 mae 0.75 50: Macro 0.670174 (0.067710)\n",
      "Testing 354/5184\n",
      "0.01 1 6 5 log2 mae 0.75 100: Weighted 0.776166 (0.043379)\n",
      "0.01 1 6 5 log2 mae 0.75 100: Macro 0.661809 (0.063824)\n",
      "Testing 355/5184\n",
      "0.01 1 6 5 log2 mae 0.75 200: Weighted 0.772229 (0.051742)\n",
      "0.01 1 6 5 log2 mae 0.75 200: Macro 0.654563 (0.069781)\n",
      "Testing 356/5184\n",
      "0.01 1 6 5 log2 mae 0.75 500: Weighted 0.783338 (0.057283)\n",
      "0.01 1 6 5 log2 mae 0.75 500: Macro 0.660496 (0.089387)\n",
      "Testing 357/5184\n",
      "0.01 1 6 5 log2 mae 1.0 50: Weighted 0.768259 (0.053595)\n",
      "0.01 1 6 5 log2 mae 1.0 50: Macro 0.651618 (0.074795)\n",
      "Testing 358/5184\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01 1 6 5 log2 mae 1.0 100: Weighted 0.763060 (0.046418)\n",
      "0.01 1 6 5 log2 mae 1.0 100: Macro 0.637335 (0.074122)\n",
      "Testing 359/5184\n",
      "0.01 1 6 5 log2 mae 1.0 200: Weighted 0.776334 (0.043173)\n",
      "0.01 1 6 5 log2 mae 1.0 200: Macro 0.653131 (0.072074)\n",
      "Testing 360/5184\n",
      "0.01 1 6 5 log2 mae 1.0 500: Weighted 0.766099 (0.065294)\n",
      "0.01 1 6 5 log2 mae 1.0 500: Macro 0.635178 (0.100481)\n",
      "Testing 361/5184\n",
      "0.01 1 6 5 sqrt friedman_mse 0.5 50: Weighted 0.815868 (0.036469)\n",
      "0.01 1 6 5 sqrt friedman_mse 0.5 50: Macro 0.714015 (0.048892)\n",
      "Testing 362/5184\n",
      "0.01 1 6 5 sqrt friedman_mse 0.5 100: Weighted 0.810827 (0.051243)\n",
      "0.01 1 6 5 sqrt friedman_mse 0.5 100: Macro 0.704132 (0.065808)\n",
      "Testing 363/5184\n",
      "0.01 1 6 5 sqrt friedman_mse 0.5 200: Weighted 0.818439 (0.067398)\n",
      "0.01 1 6 5 sqrt friedman_mse 0.5 200: Macro 0.712482 (0.095393)\n",
      "Testing 364/5184\n",
      "0.01 1 6 5 sqrt friedman_mse 0.5 500: Weighted 0.815692 (0.079359)\n",
      "0.01 1 6 5 sqrt friedman_mse 0.5 500: Macro 0.710294 (0.115339)\n",
      "Testing 365/5184\n",
      "0.01 1 6 5 sqrt friedman_mse 0.75 50: Weighted 0.793879 (0.057399)\n",
      "0.01 1 6 5 sqrt friedman_mse 0.75 50: Macro 0.691618 (0.070511)\n",
      "Testing 366/5184\n",
      "0.01 1 6 5 sqrt friedman_mse 0.75 100: Weighted 0.805273 (0.049103)\n",
      "0.01 1 6 5 sqrt friedman_mse 0.75 100: Macro 0.697618 (0.061597)\n",
      "Testing 367/5184\n",
      "0.01 1 6 5 sqrt friedman_mse 0.75 200: Weighted 0.806632 (0.055099)\n",
      "0.01 1 6 5 sqrt friedman_mse 0.75 200: Macro 0.700778 (0.072283)\n",
      "Testing 368/5184\n",
      "0.01 1 6 5 sqrt friedman_mse 0.75 500: Weighted 0.804332 (0.088938)\n",
      "0.01 1 6 5 sqrt friedman_mse 0.75 500: Macro 0.698673 (0.126472)\n",
      "Testing 369/5184\n",
      "0.01 1 6 5 sqrt friedman_mse 1.0 50: Weighted 0.789727 (0.075746)\n",
      "0.01 1 6 5 sqrt friedman_mse 1.0 50: Macro 0.679684 (0.095356)\n",
      "Testing 370/5184\n",
      "0.01 1 6 5 sqrt friedman_mse 1.0 100: Weighted 0.789831 (0.061166)\n",
      "0.01 1 6 5 sqrt friedman_mse 1.0 100: Macro 0.675918 (0.082045)\n",
      "Testing 371/5184\n",
      "0.01 1 6 5 sqrt friedman_mse 1.0 200: Weighted 0.806028 (0.077474)\n",
      "0.01 1 6 5 sqrt friedman_mse 1.0 200: Macro 0.698988 (0.108154)\n",
      "Testing 372/5184\n",
      "0.01 1 6 5 sqrt friedman_mse 1.0 500: Weighted 0.798307 (0.069889)\n",
      "0.01 1 6 5 sqrt friedman_mse 1.0 500: Macro 0.695932 (0.105294)\n",
      "Testing 373/5184\n",
      "0.01 1 6 5 sqrt mae 0.5 50: Weighted 0.784045 (0.047270)\n",
      "0.01 1 6 5 sqrt mae 0.5 50: Macro 0.663628 (0.072420)\n",
      "Testing 374/5184\n",
      "0.01 1 6 5 sqrt mae 0.5 100: Weighted 0.802792 (0.059813)\n",
      "0.01 1 6 5 sqrt mae 0.5 100: Macro 0.686875 (0.081666)\n",
      "Testing 375/5184\n",
      "0.01 1 6 5 sqrt mae 0.5 200: Weighted 0.796133 (0.038085)\n",
      "0.01 1 6 5 sqrt mae 0.5 200: Macro 0.684665 (0.056343)\n",
      "Testing 376/5184\n",
      "0.01 1 6 5 sqrt mae 0.5 500: Weighted 0.795278 (0.045430)\n",
      "0.01 1 6 5 sqrt mae 0.5 500: Macro 0.680267 (0.069445)\n",
      "Testing 377/5184\n",
      "0.01 1 6 5 sqrt mae 0.75 50: Weighted 0.769355 (0.045053)\n",
      "0.01 1 6 5 sqrt mae 0.75 50: Macro 0.645736 (0.068507)\n",
      "Testing 378/5184\n",
      "0.01 1 6 5 sqrt mae 0.75 100: Weighted 0.773115 (0.050616)\n",
      "0.01 1 6 5 sqrt mae 0.75 100: Macro 0.654417 (0.069948)\n",
      "Testing 379/5184\n",
      "0.01 1 6 5 sqrt mae 0.75 200: Weighted 0.786031 (0.045216)\n",
      "0.01 1 6 5 sqrt mae 0.75 200: Macro 0.668289 (0.067494)\n",
      "Testing 380/5184\n",
      "0.01 1 6 5 sqrt mae 0.75 500: Weighted 0.769664 (0.062929)\n",
      "0.01 1 6 5 sqrt mae 0.75 500: Macro 0.645303 (0.092476)\n",
      "Testing 381/5184\n",
      "0.01 1 6 5 sqrt mae 1.0 50: Weighted 0.778754 (0.051081)\n",
      "0.01 1 6 5 sqrt mae 1.0 50: Macro 0.660952 (0.078531)\n",
      "Testing 382/5184\n",
      "0.01 1 6 5 sqrt mae 1.0 100: Weighted 0.752383 (0.057606)\n",
      "0.01 1 6 5 sqrt mae 1.0 100: Macro 0.625601 (0.089084)\n",
      "Testing 383/5184\n",
      "0.01 1 6 5 sqrt mae 1.0 200: Weighted 0.769604 (0.052845)\n",
      "0.01 1 6 5 sqrt mae 1.0 200: Macro 0.643442 (0.079586)\n",
      "Testing 384/5184\n",
      "0.01 1 6 5 sqrt mae 1.0 500: Weighted 0.777206 (0.053595)\n",
      "0.01 1 6 5 sqrt mae 1.0 500: Macro 0.653584 (0.084192)\n",
      "Testing 385/5184\n",
      "0.01 1 6 8 log2 friedman_mse 0.5 50: Weighted 0.801638 (0.068430)\n",
      "0.01 1 6 8 log2 friedman_mse 0.5 50: Macro 0.684577 (0.094863)\n",
      "Testing 386/5184\n",
      "0.01 1 6 8 log2 friedman_mse 0.5 100: Weighted 0.807893 (0.055923)\n",
      "0.01 1 6 8 log2 friedman_mse 0.5 100: Macro 0.700942 (0.078067)\n",
      "Testing 387/5184\n",
      "0.01 1 6 8 log2 friedman_mse 0.5 200: Weighted 0.814889 (0.058578)\n",
      "0.01 1 6 8 log2 friedman_mse 0.5 200: Macro 0.710491 (0.078912)\n",
      "Testing 388/5184\n",
      "0.01 1 6 8 log2 friedman_mse 0.5 500: Weighted 0.820406 (0.075719)\n",
      "0.01 1 6 8 log2 friedman_mse 0.5 500: Macro 0.720664 (0.106619)\n",
      "Testing 389/5184\n",
      "0.01 1 6 8 log2 friedman_mse 0.75 50: Weighted 0.792604 (0.057097)\n",
      "0.01 1 6 8 log2 friedman_mse 0.75 50: Macro 0.686325 (0.070359)\n",
      "Testing 390/5184\n",
      "0.01 1 6 8 log2 friedman_mse 0.75 100: Weighted 0.796002 (0.059839)\n",
      "0.01 1 6 8 log2 friedman_mse 0.75 100: Macro 0.683158 (0.080724)\n",
      "Testing 391/5184\n",
      "0.01 1 6 8 log2 friedman_mse 0.75 200: Weighted 0.806897 (0.065277)\n",
      "0.01 1 6 8 log2 friedman_mse 0.75 200: Macro 0.703235 (0.086610)\n",
      "Testing 392/5184\n",
      "0.01 1 6 8 log2 friedman_mse 0.75 500: Weighted 0.806278 (0.071788)\n",
      "0.01 1 6 8 log2 friedman_mse 0.75 500: Macro 0.704449 (0.105088)\n",
      "Testing 393/5184\n",
      "0.01 1 6 8 log2 friedman_mse 1.0 50: Weighted 0.788691 (0.055847)\n",
      "0.01 1 6 8 log2 friedman_mse 1.0 50: Macro 0.670466 (0.072792)\n",
      "Testing 394/5184\n",
      "0.01 1 6 8 log2 friedman_mse 1.0 100: Weighted 0.787013 (0.068079)\n",
      "0.01 1 6 8 log2 friedman_mse 1.0 100: Macro 0.667412 (0.096854)\n",
      "Testing 395/5184\n",
      "0.01 1 6 8 log2 friedman_mse 1.0 200: Weighted 0.793827 (0.066473)\n",
      "0.01 1 6 8 log2 friedman_mse 1.0 200: Macro 0.681758 (0.090425)\n",
      "Testing 396/5184\n",
      "0.01 1 6 8 log2 friedman_mse 1.0 500: Weighted 0.793340 (0.065649)\n",
      "0.01 1 6 8 log2 friedman_mse 1.0 500: Macro 0.686968 (0.107438)\n",
      "Testing 397/5184\n",
      "0.01 1 6 8 log2 mae 0.5 50: Weighted 0.809412 (0.055387)\n",
      "0.01 1 6 8 log2 mae 0.5 50: Macro 0.701857 (0.078944)\n",
      "Testing 398/5184\n",
      "0.01 1 6 8 log2 mae 0.5 100: Weighted 0.778879 (0.052922)\n",
      "0.01 1 6 8 log2 mae 0.5 100: Macro 0.659187 (0.076528)\n",
      "Testing 399/5184\n",
      "0.01 1 6 8 log2 mae 0.5 200: Weighted 0.797586 (0.033772)\n",
      "0.01 1 6 8 log2 mae 0.5 200: Macro 0.682562 (0.053600)\n",
      "Testing 400/5184\n",
      "0.01 1 6 8 log2 mae 0.5 500: Weighted 0.802575 (0.038778)\n",
      "0.01 1 6 8 log2 mae 0.5 500: Macro 0.688770 (0.062839)\n",
      "Testing 401/5184\n",
      "0.01 1 6 8 log2 mae 0.75 50: Weighted 0.768265 (0.062923)\n",
      "0.01 1 6 8 log2 mae 0.75 50: Macro 0.652411 (0.083341)\n",
      "Testing 402/5184\n",
      "0.01 1 6 8 log2 mae 0.75 100: Weighted 0.776205 (0.055061)\n",
      "0.01 1 6 8 log2 mae 0.75 100: Macro 0.655603 (0.081211)\n",
      "Testing 403/5184\n",
      "0.01 1 6 8 log2 mae 0.75 200: Weighted 0.787342 (0.046799)\n",
      "0.01 1 6 8 log2 mae 0.75 200: Macro 0.666071 (0.075174)\n",
      "Testing 404/5184\n",
      "0.01 1 6 8 log2 mae 0.75 500: Weighted 0.790030 (0.059909)\n",
      "0.01 1 6 8 log2 mae 0.75 500: Macro 0.671021 (0.093546)\n",
      "Testing 405/5184\n",
      "0.01 1 6 8 log2 mae 1.0 50: Weighted 0.767792 (0.051707)\n",
      "0.01 1 6 8 log2 mae 1.0 50: Macro 0.644936 (0.080081)\n",
      "Testing 406/5184\n",
      "0.01 1 6 8 log2 mae 1.0 100: Weighted 0.763948 (0.051052)\n",
      "0.01 1 6 8 log2 mae 1.0 100: Macro 0.634333 (0.079650)\n",
      "Testing 407/5184\n",
      "0.01 1 6 8 log2 mae 1.0 200: Weighted 0.785954 (0.043587)\n",
      "0.01 1 6 8 log2 mae 1.0 200: Macro 0.669231 (0.072930)\n",
      "Testing 408/5184\n",
      "0.01 1 6 8 log2 mae 1.0 500: Weighted 0.767014 (0.079567)\n",
      "0.01 1 6 8 log2 mae 1.0 500: Macro 0.637042 (0.117670)\n",
      "Testing 409/5184\n",
      "0.01 1 6 8 sqrt friedman_mse 0.5 50: Weighted 0.820008 (0.051002)\n",
      "0.01 1 6 8 sqrt friedman_mse 0.5 50: Macro 0.714118 (0.070229)\n",
      "Testing 410/5184\n",
      "0.01 1 6 8 sqrt friedman_mse 0.5 100: Weighted 0.812111 (0.040430)\n",
      "0.01 1 6 8 sqrt friedman_mse 0.5 100: Macro 0.699428 (0.053770)\n",
      "Testing 411/5184\n",
      "0.01 1 6 8 sqrt friedman_mse 0.5 200: Weighted 0.814938 (0.048892)\n",
      "0.01 1 6 8 sqrt friedman_mse 0.5 200: Macro 0.707877 (0.062643)\n",
      "Testing 412/5184\n",
      "0.01 1 6 8 sqrt friedman_mse 0.5 500: Weighted 0.817652 (0.077762)\n",
      "0.01 1 6 8 sqrt friedman_mse 0.5 500: Macro 0.710471 (0.115172)\n",
      "Testing 413/5184\n",
      "0.01 1 6 8 sqrt friedman_mse 0.75 50: Weighted 0.788603 (0.048653)\n",
      "0.01 1 6 8 sqrt friedman_mse 0.75 50: Macro 0.673864 (0.074726)\n",
      "Testing 414/5184\n",
      "0.01 1 6 8 sqrt friedman_mse 0.75 100: Weighted 0.794501 (0.076834)\n",
      "0.01 1 6 8 sqrt friedman_mse 0.75 100: Macro 0.685061 (0.103854)\n",
      "Testing 415/5184\n",
      "0.01 1 6 8 sqrt friedman_mse 0.75 200: Weighted 0.801685 (0.059211)\n",
      "0.01 1 6 8 sqrt friedman_mse 0.75 200: Macro 0.696564 (0.076271)\n",
      "Testing 416/5184\n",
      "0.01 1 6 8 sqrt friedman_mse 0.75 500: Weighted 0.810654 (0.078090)\n",
      "0.01 1 6 8 sqrt friedman_mse 0.75 500: Macro 0.712052 (0.115583)\n",
      "Testing 417/5184\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01 1 6 8 sqrt friedman_mse 1.0 50: Weighted 0.769097 (0.057431)\n",
      "0.01 1 6 8 sqrt friedman_mse 1.0 50: Macro 0.653838 (0.077510)\n",
      "Testing 418/5184\n",
      "0.01 1 6 8 sqrt friedman_mse 1.0 100: Weighted 0.792742 (0.061872)\n",
      "0.01 1 6 8 sqrt friedman_mse 1.0 100: Macro 0.678482 (0.083721)\n",
      "Testing 419/5184\n",
      "0.01 1 6 8 sqrt friedman_mse 1.0 200: Weighted 0.798966 (0.072361)\n",
      "0.01 1 6 8 sqrt friedman_mse 1.0 200: Macro 0.688386 (0.100422)\n",
      "Testing 420/5184\n",
      "0.01 1 6 8 sqrt friedman_mse 1.0 500: Weighted 0.785004 (0.062765)\n",
      "0.01 1 6 8 sqrt friedman_mse 1.0 500: Macro 0.675387 (0.100945)\n",
      "Testing 421/5184\n",
      "0.01 1 6 8 sqrt mae 0.5 50: Weighted 0.793114 (0.030293)\n",
      "0.01 1 6 8 sqrt mae 0.5 50: Macro 0.680515 (0.044811)\n",
      "Testing 422/5184\n",
      "0.01 1 6 8 sqrt mae 0.5 100: Weighted 0.802628 (0.029243)\n",
      "0.01 1 6 8 sqrt mae 0.5 100: Macro 0.693561 (0.043899)\n",
      "Testing 423/5184\n",
      "0.01 1 6 8 sqrt mae 0.5 200: Weighted 0.791659 (0.040472)\n",
      "0.01 1 6 8 sqrt mae 0.5 200: Macro 0.673171 (0.063052)\n",
      "Testing 424/5184\n",
      "0.01 1 6 8 sqrt mae 0.5 500: Weighted 0.802575 (0.038778)\n",
      "0.01 1 6 8 sqrt mae 0.5 500: Macro 0.688770 (0.062839)\n",
      "Testing 425/5184\n",
      "0.01 1 6 8 sqrt mae 0.75 50: Weighted 0.790410 (0.049742)\n",
      "0.01 1 6 8 sqrt mae 0.75 50: Macro 0.672634 (0.078372)\n",
      "Testing 426/5184\n",
      "0.01 1 6 8 sqrt mae 0.75 100: Weighted 0.775421 (0.056264)\n",
      "0.01 1 6 8 sqrt mae 0.75 100: Macro 0.654242 (0.081442)\n",
      "Testing 427/5184\n",
      "0.01 1 6 8 sqrt mae 0.75 200: Weighted 0.779800 (0.043065)\n",
      "0.01 1 6 8 sqrt mae 0.75 200: Macro 0.655576 (0.069479)\n",
      "Testing 428/5184\n",
      "0.01 1 6 8 sqrt mae 0.75 500: Weighted 0.787661 (0.062723)\n",
      "0.01 1 6 8 sqrt mae 0.75 500: Macro 0.667436 (0.098012)\n",
      "Testing 429/5184\n",
      "0.01 1 6 8 sqrt mae 1.0 50: Weighted 0.772174 (0.049933)\n",
      "0.01 1 6 8 sqrt mae 1.0 50: Macro 0.647016 (0.075690)\n",
      "Testing 430/5184\n",
      "0.01 1 6 8 sqrt mae 1.0 100: Weighted 0.770257 (0.052203)\n",
      "0.01 1 6 8 sqrt mae 1.0 100: Macro 0.639062 (0.084174)\n",
      "Testing 431/5184\n",
      "0.01 1 6 8 sqrt mae 1.0 200: Weighted 0.771684 (0.055699)\n",
      "0.01 1 6 8 sqrt mae 1.0 200: Macro 0.647313 (0.085739)\n",
      "Testing 432/5184\n",
      "0.01 1 6 8 sqrt mae 1.0 500: Weighted 0.770480 (0.062116)\n",
      "0.01 1 6 8 sqrt mae 1.0 500: Macro 0.644461 (0.088442)\n",
      "Testing 433/5184\n",
      "0.01 3 2 3 log2 friedman_mse 0.5 50: Weighted 0.801907 (0.066336)\n",
      "0.01 3 2 3 log2 friedman_mse 0.5 50: Macro 0.692490 (0.090574)\n",
      "Testing 434/5184\n",
      "0.01 3 2 3 log2 friedman_mse 0.5 100: Weighted 0.824404 (0.048722)\n",
      "0.01 3 2 3 log2 friedman_mse 0.5 100: Macro 0.718880 (0.068183)\n",
      "Testing 435/5184\n",
      "0.01 3 2 3 log2 friedman_mse 0.5 200: Weighted 0.819229 (0.043780)\n",
      "0.01 3 2 3 log2 friedman_mse 0.5 200: Macro 0.712513 (0.059614)\n",
      "Testing 436/5184\n",
      "0.01 3 2 3 log2 friedman_mse 0.5 500: Weighted 0.807653 (0.069104)\n",
      "0.01 3 2 3 log2 friedman_mse 0.5 500: Macro 0.695184 (0.095388)\n",
      "Testing 437/5184\n",
      "0.01 3 2 3 log2 friedman_mse 0.75 50: Weighted 0.818959 (0.061494)\n",
      "0.01 3 2 3 log2 friedman_mse 0.75 50: Macro 0.716335 (0.077243)\n",
      "Testing 438/5184\n",
      "0.01 3 2 3 log2 friedman_mse 0.75 100: Weighted 0.807779 (0.068660)\n",
      "0.01 3 2 3 log2 friedman_mse 0.75 100: Macro 0.697766 (0.093394)\n",
      "Testing 439/5184\n",
      "0.01 3 2 3 log2 friedman_mse 0.75 200: Weighted 0.810446 (0.069658)\n",
      "0.01 3 2 3 log2 friedman_mse 0.75 200: Macro 0.701988 (0.091938)\n",
      "Testing 440/5184\n",
      "0.01 3 2 3 log2 friedman_mse 0.75 500: Weighted 0.812598 (0.068179)\n",
      "0.01 3 2 3 log2 friedman_mse 0.75 500: Macro 0.713496 (0.084051)\n",
      "Testing 441/5184\n",
      "0.01 3 2 3 log2 friedman_mse 1.0 50: Weighted 0.805504 (0.056597)\n",
      "0.01 3 2 3 log2 friedman_mse 1.0 50: Macro 0.696134 (0.082504)\n",
      "Testing 442/5184\n",
      "0.01 3 2 3 log2 friedman_mse 1.0 100: Weighted 0.800451 (0.054271)\n",
      "0.01 3 2 3 log2 friedman_mse 1.0 100: Macro 0.694973 (0.069219)\n",
      "Testing 443/5184\n",
      "0.01 3 2 3 log2 friedman_mse 1.0 200: Weighted 0.784831 (0.056365)\n",
      "0.01 3 2 3 log2 friedman_mse 1.0 200: Macro 0.670305 (0.072147)\n",
      "Testing 444/5184\n",
      "0.01 3 2 3 log2 friedman_mse 1.0 500: Weighted 0.802758 (0.075877)\n",
      "0.01 3 2 3 log2 friedman_mse 1.0 500: Macro 0.701351 (0.097636)\n",
      "Testing 445/5184\n",
      "0.01 3 2 3 log2 mae 0.5 50: Weighted 0.804034 (0.047606)\n",
      "0.01 3 2 3 log2 mae 0.5 50: Macro 0.685258 (0.069344)\n",
      "Testing 446/5184\n",
      "0.01 3 2 3 log2 mae 0.5 100: Weighted 0.807275 (0.057736)\n",
      "0.01 3 2 3 log2 mae 0.5 100: Macro 0.691839 (0.082651)\n",
      "Testing 447/5184\n",
      "0.01 3 2 3 log2 mae 0.5 200: Weighted 0.816773 (0.056182)\n",
      "0.01 3 2 3 log2 mae 0.5 200: Macro 0.703409 (0.083095)\n",
      "Testing 448/5184\n",
      "0.01 3 2 3 log2 mae 0.5 500: Weighted 0.816646 (0.061930)\n",
      "0.01 3 2 3 log2 mae 0.5 500: Macro 0.699919 (0.094196)\n",
      "Testing 449/5184\n",
      "0.01 3 2 3 log2 mae 0.75 50: Weighted 0.797853 (0.061786)\n",
      "0.01 3 2 3 log2 mae 0.75 50: Macro 0.682228 (0.083951)\n",
      "Testing 450/5184\n",
      "0.01 3 2 3 log2 mae 0.75 100: Weighted 0.802230 (0.063372)\n",
      "0.01 3 2 3 log2 mae 0.75 100: Macro 0.682028 (0.089609)\n",
      "Testing 451/5184\n",
      "0.01 3 2 3 log2 mae 0.75 200: Weighted 0.789965 (0.064326)\n",
      "0.01 3 2 3 log2 mae 0.75 200: Macro 0.666052 (0.088529)\n",
      "Testing 452/5184\n",
      "0.01 3 2 3 log2 mae 0.75 500: Weighted 0.784826 (0.063263)\n",
      "0.01 3 2 3 log2 mae 0.75 500: Macro 0.664485 (0.089686)\n",
      "Testing 453/5184\n",
      "0.01 3 2 3 log2 mae 1.0 50: Weighted 0.780474 (0.057887)\n",
      "0.01 3 2 3 log2 mae 1.0 50: Macro 0.665618 (0.079890)\n",
      "Testing 454/5184\n",
      "0.01 3 2 3 log2 mae 1.0 100: Weighted 0.797853 (0.061786)\n",
      "0.01 3 2 3 log2 mae 1.0 100: Macro 0.682228 (0.083951)\n",
      "Testing 455/5184\n",
      "0.01 3 2 3 log2 mae 1.0 200: Weighted 0.781859 (0.071844)\n",
      "0.01 3 2 3 log2 mae 1.0 200: Macro 0.659136 (0.096080)\n",
      "Testing 456/5184\n",
      "0.01 3 2 3 log2 mae 1.0 500: Weighted 0.778678 (0.072275)\n",
      "0.01 3 2 3 log2 mae 1.0 500: Macro 0.658338 (0.096865)\n",
      "Testing 457/5184\n",
      "0.01 3 2 3 sqrt friedman_mse 0.5 50: Weighted 0.816593 (0.056095)\n",
      "0.01 3 2 3 sqrt friedman_mse 0.5 50: Macro 0.704334 (0.083640)\n",
      "Testing 458/5184\n",
      "0.01 3 2 3 sqrt friedman_mse 0.5 100: Weighted 0.824736 (0.057507)\n",
      "0.01 3 2 3 sqrt friedman_mse 0.5 100: Macro 0.721261 (0.079107)\n",
      "Testing 459/5184\n",
      "0.01 3 2 3 sqrt friedman_mse 0.5 200: Weighted 0.824245 (0.054315)\n",
      "0.01 3 2 3 sqrt friedman_mse 0.5 200: Macro 0.717774 (0.075503)\n",
      "Testing 460/5184\n",
      "0.01 3 2 3 sqrt friedman_mse 0.5 500: Weighted 0.806363 (0.068816)\n",
      "0.01 3 2 3 sqrt friedman_mse 0.5 500: Macro 0.697975 (0.096308)\n",
      "Testing 461/5184\n",
      "0.01 3 2 3 sqrt friedman_mse 0.75 50: Weighted 0.814991 (0.062665)\n",
      "0.01 3 2 3 sqrt friedman_mse 0.75 50: Macro 0.709448 (0.080344)\n",
      "Testing 462/5184\n",
      "0.01 3 2 3 sqrt friedman_mse 0.75 100: Weighted 0.816003 (0.057229)\n",
      "0.01 3 2 3 sqrt friedman_mse 0.75 100: Macro 0.703731 (0.082629)\n",
      "Testing 463/5184\n",
      "0.01 3 2 3 sqrt friedman_mse 0.75 200: Weighted 0.810446 (0.069658)\n",
      "0.01 3 2 3 sqrt friedman_mse 0.75 200: Macro 0.701988 (0.091938)\n",
      "Testing 464/5184\n",
      "0.01 3 2 3 sqrt friedman_mse 0.75 500: Weighted 0.804357 (0.070536)\n",
      "0.01 3 2 3 sqrt friedman_mse 0.75 500: Macro 0.697623 (0.091468)\n",
      "Testing 465/5184\n",
      "0.01 3 2 3 sqrt friedman_mse 1.0 50: Weighted 0.791147 (0.050884)\n",
      "0.01 3 2 3 sqrt friedman_mse 1.0 50: Macro 0.682765 (0.062507)\n",
      "Testing 466/5184\n",
      "0.01 3 2 3 sqrt friedman_mse 1.0 100: Weighted 0.813921 (0.059772)\n",
      "0.01 3 2 3 sqrt friedman_mse 1.0 100: Macro 0.710884 (0.074371)\n",
      "Testing 467/5184\n",
      "0.01 3 2 3 sqrt friedman_mse 1.0 200: Weighted 0.803845 (0.067671)\n",
      "0.01 3 2 3 sqrt friedman_mse 1.0 200: Macro 0.695851 (0.085929)\n",
      "Testing 468/5184\n",
      "0.01 3 2 3 sqrt friedman_mse 1.0 500: Weighted 0.803804 (0.074834)\n",
      "0.01 3 2 3 sqrt friedman_mse 1.0 500: Macro 0.701442 (0.097551)\n",
      "Testing 469/5184\n",
      "0.01 3 2 3 sqrt mae 0.5 50: Weighted 0.806582 (0.056038)\n",
      "0.01 3 2 3 sqrt mae 0.5 50: Macro 0.697470 (0.072887)\n",
      "Testing 470/5184\n",
      "0.01 3 2 3 sqrt mae 0.5 100: Weighted 0.813112 (0.046863)\n",
      "0.01 3 2 3 sqrt mae 0.5 100: Macro 0.701162 (0.064445)\n",
      "Testing 471/5184\n",
      "0.01 3 2 3 sqrt mae 0.5 200: Weighted 0.824584 (0.048793)\n",
      "0.01 3 2 3 sqrt mae 0.5 200: Macro 0.717955 (0.067713)\n",
      "Testing 472/5184\n",
      "0.01 3 2 3 sqrt mae 0.5 500: Weighted 0.816773 (0.056182)\n",
      "0.01 3 2 3 sqrt mae 0.5 500: Macro 0.703409 (0.083095)\n",
      "Testing 473/5184\n",
      "0.01 3 2 3 sqrt mae 0.75 50: Weighted 0.798757 (0.056608)\n",
      "0.01 3 2 3 sqrt mae 0.75 50: Macro 0.685512 (0.071099)\n",
      "Testing 474/5184\n",
      "0.01 3 2 3 sqrt mae 0.75 100: Weighted 0.787223 (0.064925)\n",
      "0.01 3 2 3 sqrt mae 0.75 100: Macro 0.662281 (0.092166)\n",
      "Testing 475/5184\n",
      "0.01 3 2 3 sqrt mae 0.75 200: Weighted 0.793127 (0.067285)\n",
      "0.01 3 2 3 sqrt mae 0.75 200: Macro 0.671697 (0.089571)\n",
      "Testing 476/5184\n",
      "0.01 3 2 3 sqrt mae 0.75 500: Weighted 0.790209 (0.059542)\n",
      "0.01 3 2 3 sqrt mae 0.75 500: Macro 0.674722 (0.083194)\n",
      "Testing 477/5184\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01 3 2 3 sqrt mae 1.0 50: Weighted 0.803629 (0.059835)\n",
      "0.01 3 2 3 sqrt mae 1.0 50: Macro 0.692889 (0.083709)\n",
      "Testing 478/5184\n",
      "0.01 3 2 3 sqrt mae 1.0 100: Weighted 0.790955 (0.063869)\n",
      "0.01 3 2 3 sqrt mae 1.0 100: Macro 0.671465 (0.085860)\n",
      "Testing 479/5184\n",
      "0.01 3 2 3 sqrt mae 1.0 200: Weighted 0.777192 (0.070839)\n",
      "0.01 3 2 3 sqrt mae 1.0 200: Macro 0.655458 (0.098579)\n",
      "Testing 480/5184\n",
      "0.01 3 2 3 sqrt mae 1.0 500: Weighted 0.778546 (0.072123)\n",
      "0.01 3 2 3 sqrt mae 1.0 500: Macro 0.659316 (0.098106)\n",
      "Testing 481/5184\n",
      "0.01 3 2 5 log2 friedman_mse 0.5 50: Weighted 0.818912 (0.051958)\n",
      "0.01 3 2 5 log2 friedman_mse 0.5 50: Macro 0.716404 (0.067585)\n",
      "Testing 482/5184\n",
      "0.01 3 2 5 log2 friedman_mse 0.5 100: Weighted 0.821138 (0.046966)\n",
      "0.01 3 2 5 log2 friedman_mse 0.5 100: Macro 0.719633 (0.065217)\n",
      "Testing 483/5184\n",
      "0.01 3 2 5 log2 friedman_mse 0.5 200: Weighted 0.816182 (0.045100)\n",
      "0.01 3 2 5 log2 friedman_mse 0.5 200: Macro 0.707932 (0.059020)\n",
      "Testing 484/5184\n",
      "0.01 3 2 5 log2 friedman_mse 0.5 500: Weighted 0.820217 (0.075921)\n",
      "0.01 3 2 5 log2 friedman_mse 0.5 500: Macro 0.713668 (0.112782)\n",
      "Testing 485/5184\n",
      "0.01 3 2 5 log2 friedman_mse 0.75 50: Weighted 0.792234 (0.048144)\n",
      "0.01 3 2 5 log2 friedman_mse 0.75 50: Macro 0.676706 (0.071435)\n",
      "Testing 486/5184\n",
      "0.01 3 2 5 log2 friedman_mse 0.75 100: Weighted 0.799240 (0.063995)\n",
      "0.01 3 2 5 log2 friedman_mse 0.75 100: Macro 0.688140 (0.081748)\n",
      "Testing 487/5184\n",
      "0.01 3 2 5 log2 friedman_mse 0.75 200: Weighted 0.806755 (0.050008)\n",
      "0.01 3 2 5 log2 friedman_mse 0.75 200: Macro 0.703973 (0.062203)\n",
      "Testing 488/5184\n",
      "0.01 3 2 5 log2 friedman_mse 0.75 500: Weighted 0.799247 (0.082978)\n",
      "0.01 3 2 5 log2 friedman_mse 0.75 500: Macro 0.690085 (0.114802)\n",
      "Testing 489/5184\n",
      "0.01 3 2 5 log2 friedman_mse 1.0 50: Weighted 0.786564 (0.070976)\n",
      "0.01 3 2 5 log2 friedman_mse 1.0 50: Macro 0.668802 (0.092692)\n",
      "Testing 490/5184\n",
      "0.01 3 2 5 log2 friedman_mse 1.0 100: Weighted 0.783406 (0.062038)\n",
      "0.01 3 2 5 log2 friedman_mse 1.0 100: Macro 0.676146 (0.081931)\n",
      "Testing 491/5184\n",
      "0.01 3 2 5 log2 friedman_mse 1.0 200: Weighted 0.792275 (0.065351)\n",
      "0.01 3 2 5 log2 friedman_mse 1.0 200: Macro 0.686546 (0.081896)\n",
      "Testing 492/5184\n",
      "0.01 3 2 5 log2 friedman_mse 1.0 500: Weighted 0.803121 (0.085404)\n",
      "0.01 3 2 5 log2 friedman_mse 1.0 500: Macro 0.698789 (0.118597)\n",
      "Testing 493/5184\n",
      "0.01 3 2 5 log2 mae 0.5 50: Weighted 0.817187 (0.053382)\n",
      "0.01 3 2 5 log2 mae 0.5 50: Macro 0.709786 (0.070783)\n",
      "Testing 494/5184\n",
      "0.01 3 2 5 log2 mae 0.5 100: Weighted 0.798533 (0.063765)\n",
      "0.01 3 2 5 log2 mae 0.5 100: Macro 0.676333 (0.091476)\n",
      "Testing 495/5184\n",
      "0.01 3 2 5 log2 mae 0.5 200: Weighted 0.807206 (0.056855)\n",
      "0.01 3 2 5 log2 mae 0.5 200: Macro 0.685418 (0.084642)\n",
      "Testing 496/5184\n",
      "0.01 3 2 5 log2 mae 0.5 500: Weighted 0.790387 (0.061154)\n",
      "0.01 3 2 5 log2 mae 0.5 500: Macro 0.667407 (0.084960)\n",
      "Testing 497/5184\n",
      "0.01 3 2 5 log2 mae 0.75 50: Weighted 0.804666 (0.064927)\n",
      "0.01 3 2 5 log2 mae 0.75 50: Macro 0.685081 (0.094169)\n",
      "Testing 498/5184\n",
      "0.01 3 2 5 log2 mae 0.75 100: Weighted 0.787092 (0.075222)\n",
      "0.01 3 2 5 log2 mae 0.75 100: Macro 0.664994 (0.102516)\n",
      "Testing 499/5184\n",
      "0.01 3 2 5 log2 mae 0.75 200: Weighted 0.786142 (0.075948)\n",
      "0.01 3 2 5 log2 mae 0.75 200: Macro 0.666175 (0.101538)\n",
      "Testing 500/5184\n",
      "0.01 3 2 5 log2 mae 0.75 500: Weighted 0.767073 (0.083797)\n",
      "0.01 3 2 5 log2 mae 0.75 500: Macro 0.633433 (0.117676)\n",
      "Testing 501/5184\n",
      "0.01 3 2 5 log2 mae 1.0 50: Weighted 0.777756 (0.073417)\n",
      "0.01 3 2 5 log2 mae 1.0 50: Macro 0.649262 (0.101188)\n",
      "Testing 502/5184\n",
      "0.01 3 2 5 log2 mae 1.0 100: Weighted 0.778048 (0.061920)\n",
      "0.01 3 2 5 log2 mae 1.0 100: Macro 0.651020 (0.091493)\n",
      "Testing 503/5184\n",
      "0.01 3 2 5 log2 mae 1.0 200: Weighted 0.781488 (0.060357)\n",
      "0.01 3 2 5 log2 mae 1.0 200: Macro 0.655513 (0.089139)\n",
      "Testing 504/5184\n",
      "0.01 3 2 5 log2 mae 1.0 500: Weighted 0.766651 (0.082928)\n",
      "0.01 3 2 5 log2 mae 1.0 500: Macro 0.632028 (0.114235)\n",
      "Testing 505/5184\n",
      "0.01 3 2 5 sqrt friedman_mse 0.5 50: Weighted 0.813245 (0.061259)\n",
      "0.01 3 2 5 sqrt friedman_mse 0.5 50: Macro 0.709514 (0.088824)\n",
      "Testing 506/5184\n",
      "0.01 3 2 5 sqrt friedman_mse 0.5 100: Weighted 0.821474 (0.047499)\n",
      "0.01 3 2 5 sqrt friedman_mse 0.5 100: Macro 0.720575 (0.062521)\n",
      "Testing 507/5184\n",
      "0.01 3 2 5 sqrt friedman_mse 0.5 200: Weighted 0.832205 (0.050656)\n",
      "0.01 3 2 5 sqrt friedman_mse 0.5 200: Macro 0.732284 (0.068034)\n",
      "Testing 508/5184\n",
      "0.01 3 2 5 sqrt friedman_mse 0.5 500: Weighted 0.815764 (0.080374)\n",
      "0.01 3 2 5 sqrt friedman_mse 0.5 500: Macro 0.710304 (0.116228)\n",
      "Testing 509/5184\n",
      "0.01 3 2 5 sqrt friedman_mse 0.75 50: Weighted 0.811396 (0.068181)\n",
      "0.01 3 2 5 sqrt friedman_mse 0.75 50: Macro 0.701866 (0.092129)\n",
      "Testing 510/5184\n",
      "0.01 3 2 5 sqrt friedman_mse 0.75 100: Weighted 0.801235 (0.062845)\n",
      "0.01 3 2 5 sqrt friedman_mse 0.75 100: Macro 0.689656 (0.086082)\n",
      "Testing 511/5184\n",
      "0.01 3 2 5 sqrt friedman_mse 0.75 200: Weighted 0.812075 (0.057134)\n",
      "0.01 3 2 5 sqrt friedman_mse 0.75 200: Macro 0.703132 (0.077059)\n",
      "Testing 512/5184\n",
      "0.01 3 2 5 sqrt friedman_mse 0.75 500: Weighted 0.803790 (0.089567)\n",
      "0.01 3 2 5 sqrt friedman_mse 0.75 500: Macro 0.698110 (0.125944)\n",
      "Testing 513/5184\n",
      "0.01 3 2 5 sqrt friedman_mse 1.0 50: Weighted 0.790961 (0.057467)\n",
      "0.01 3 2 5 sqrt friedman_mse 1.0 50: Macro 0.679843 (0.081349)\n",
      "Testing 514/5184\n",
      "0.01 3 2 5 sqrt friedman_mse 1.0 100: Weighted 0.784268 (0.060806)\n",
      "0.01 3 2 5 sqrt friedman_mse 1.0 100: Macro 0.675973 (0.082185)\n",
      "Testing 515/5184\n",
      "0.01 3 2 5 sqrt friedman_mse 1.0 200: Weighted 0.788746 (0.066870)\n",
      "0.01 3 2 5 sqrt friedman_mse 1.0 200: Macro 0.681420 (0.083805)\n",
      "Testing 516/5184\n",
      "0.01 3 2 5 sqrt friedman_mse 1.0 500: Weighted 0.810093 (0.089538)\n",
      "0.01 3 2 5 sqrt friedman_mse 1.0 500: Macro 0.711064 (0.124951)\n",
      "Testing 517/5184\n",
      "0.01 3 2 5 sqrt mae 0.5 50: Weighted 0.815757 (0.054143)\n",
      "0.01 3 2 5 sqrt mae 0.5 50: Macro 0.709389 (0.073129)\n",
      "Testing 518/5184\n",
      "0.01 3 2 5 sqrt mae 0.5 100: Weighted 0.800440 (0.062000)\n",
      "0.01 3 2 5 sqrt mae 0.5 100: Macro 0.676455 (0.091370)\n",
      "Testing 519/5184\n",
      "0.01 3 2 5 sqrt mae 0.5 200: Weighted 0.803881 (0.059149)\n",
      "0.01 3 2 5 sqrt mae 0.5 200: Macro 0.680948 (0.087719)\n",
      "Testing 520/5184\n",
      "0.01 3 2 5 sqrt mae 0.5 500: Weighted 0.796271 (0.073049)\n",
      "0.01 3 2 5 sqrt mae 0.5 500: Macro 0.676915 (0.102261)\n",
      "Testing 521/5184\n",
      "0.01 3 2 5 sqrt mae 0.75 50: Weighted 0.790981 (0.072381)\n",
      "0.01 3 2 5 sqrt mae 0.75 50: Macro 0.667776 (0.101002)\n",
      "Testing 522/5184\n",
      "0.01 3 2 5 sqrt mae 0.75 100: Weighted 0.797882 (0.058744)\n",
      "0.01 3 2 5 sqrt mae 0.75 100: Macro 0.674989 (0.085037)\n",
      "Testing 523/5184\n",
      "0.01 3 2 5 sqrt mae 0.75 200: Weighted 0.797221 (0.072161)\n",
      "0.01 3 2 5 sqrt mae 0.75 200: Macro 0.675734 (0.103355)\n",
      "Testing 524/5184\n",
      "0.01 3 2 5 sqrt mae 0.75 500: Weighted 0.775169 (0.085953)\n",
      "0.01 3 2 5 sqrt mae 0.75 500: Macro 0.644539 (0.121950)\n",
      "Testing 525/5184\n",
      "0.01 3 2 5 sqrt mae 1.0 50: Weighted 0.770423 (0.071453)\n",
      "0.01 3 2 5 sqrt mae 1.0 50: Macro 0.643018 (0.104506)\n",
      "Testing 526/5184\n",
      "0.01 3 2 5 sqrt mae 1.0 100: Weighted 0.781371 (0.060749)\n",
      "0.01 3 2 5 sqrt mae 1.0 100: Macro 0.655223 (0.090990)\n",
      "Testing 527/5184\n",
      "0.01 3 2 5 sqrt mae 1.0 200: Weighted 0.768978 (0.071388)\n",
      "0.01 3 2 5 sqrt mae 1.0 200: Macro 0.643327 (0.101203)\n",
      "Testing 528/5184\n",
      "0.01 3 2 5 sqrt mae 1.0 500: Weighted 0.773963 (0.082718)\n",
      "0.01 3 2 5 sqrt mae 1.0 500: Macro 0.647091 (0.120994)\n",
      "Testing 529/5184\n",
      "0.01 3 2 8 log2 friedman_mse 0.5 50: Weighted 0.821740 (0.047579)\n",
      "0.01 3 2 8 log2 friedman_mse 0.5 50: Macro 0.719511 (0.062197)\n",
      "Testing 530/5184\n",
      "0.01 3 2 8 log2 friedman_mse 0.5 100: Weighted 0.805043 (0.046757)\n",
      "0.01 3 2 8 log2 friedman_mse 0.5 100: Macro 0.697480 (0.057642)\n",
      "Testing 531/5184\n",
      "0.01 3 2 8 log2 friedman_mse 0.5 200: Weighted 0.813691 (0.049813)\n",
      "0.01 3 2 8 log2 friedman_mse 0.5 200: Macro 0.710654 (0.065395)\n",
      "Testing 532/5184\n",
      "0.01 3 2 8 log2 friedman_mse 0.5 500: Weighted 0.827189 (0.075404)\n",
      "0.01 3 2 8 log2 friedman_mse 0.5 500: Macro 0.719298 (0.113572)\n",
      "Testing 533/5184\n",
      "0.01 3 2 8 log2 friedman_mse 0.75 50: Weighted 0.810273 (0.055465)\n",
      "0.01 3 2 8 log2 friedman_mse 0.75 50: Macro 0.698870 (0.077965)\n",
      "Testing 534/5184\n",
      "0.01 3 2 8 log2 friedman_mse 0.75 100: Weighted 0.794066 (0.051553)\n",
      "0.01 3 2 8 log2 friedman_mse 0.75 100: Macro 0.681122 (0.068647)\n",
      "Testing 535/5184\n",
      "0.01 3 2 8 log2 friedman_mse 0.75 200: Weighted 0.804289 (0.058440)\n",
      "0.01 3 2 8 log2 friedman_mse 0.75 200: Macro 0.700003 (0.069495)\n",
      "Testing 536/5184\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01 3 2 8 log2 friedman_mse 0.75 500: Weighted 0.807503 (0.081329)\n",
      "0.01 3 2 8 log2 friedman_mse 0.75 500: Macro 0.703396 (0.114260)\n",
      "Testing 537/5184\n",
      "0.01 3 2 8 log2 friedman_mse 1.0 50: Weighted 0.779517 (0.061306)\n",
      "0.01 3 2 8 log2 friedman_mse 1.0 50: Macro 0.664153 (0.082405)\n",
      "Testing 538/5184\n",
      "0.01 3 2 8 log2 friedman_mse 1.0 100: Weighted 0.776867 (0.052033)\n",
      "0.01 3 2 8 log2 friedman_mse 1.0 100: Macro 0.663181 (0.070093)\n",
      "Testing 539/5184\n",
      "0.01 3 2 8 log2 friedman_mse 1.0 200: Weighted 0.783757 (0.059787)\n",
      "0.01 3 2 8 log2 friedman_mse 1.0 200: Macro 0.668345 (0.077680)\n",
      "Testing 540/5184\n",
      "0.01 3 2 8 log2 friedman_mse 1.0 500: Weighted 0.786419 (0.084335)\n",
      "0.01 3 2 8 log2 friedman_mse 1.0 500: Macro 0.676834 (0.117518)\n",
      "Testing 541/5184\n",
      "0.01 3 2 8 log2 mae 0.5 50: Weighted 0.804118 (0.065418)\n",
      "0.01 3 2 8 log2 mae 0.5 50: Macro 0.683189 (0.096083)\n",
      "Testing 542/5184\n",
      "0.01 3 2 8 log2 mae 0.5 100: Weighted 0.806507 (0.054030)\n",
      "0.01 3 2 8 log2 mae 0.5 100: Macro 0.693616 (0.074856)\n",
      "Testing 543/5184\n",
      "0.01 3 2 8 log2 mae 0.5 200: Weighted 0.802275 (0.060545)\n",
      "0.01 3 2 8 log2 mae 0.5 200: Macro 0.682140 (0.086310)\n",
      "Testing 544/5184\n",
      "0.01 3 2 8 log2 mae 0.5 500: Weighted 0.797185 (0.072202)\n",
      "0.01 3 2 8 log2 mae 0.5 500: Macro 0.681213 (0.097940)\n",
      "Testing 545/5184\n",
      "0.01 3 2 8 log2 mae 0.75 50: Weighted 0.808643 (0.061381)\n",
      "0.01 3 2 8 log2 mae 0.75 50: Macro 0.688091 (0.091883)\n",
      "Testing 546/5184\n",
      "0.01 3 2 8 log2 mae 0.75 100: Weighted 0.804881 (0.059640)\n",
      "0.01 3 2 8 log2 mae 0.75 100: Macro 0.688060 (0.081502)\n",
      "Testing 547/5184\n",
      "0.01 3 2 8 log2 mae 0.75 200: Weighted 0.777071 (0.074073)\n",
      "0.01 3 2 8 log2 mae 0.75 200: Macro 0.647946 (0.104418)\n",
      "Testing 548/5184\n",
      "0.01 3 2 8 log2 mae 0.75 500: Weighted 0.777487 (0.083812)\n",
      "0.01 3 2 8 log2 mae 0.75 500: Macro 0.647038 (0.119710)\n",
      "Testing 549/5184\n",
      "0.01 3 2 8 log2 mae 1.0 50: Weighted 0.773724 (0.072491)\n",
      "0.01 3 2 8 log2 mae 1.0 50: Macro 0.644990 (0.099396)\n",
      "Testing 550/5184\n",
      "0.01 3 2 8 log2 mae 1.0 100: Weighted 0.780247 (0.063593)\n",
      "0.01 3 2 8 log2 mae 1.0 100: Macro 0.654241 (0.087370)\n",
      "Testing 551/5184\n",
      "0.01 3 2 8 log2 mae 1.0 200: Weighted 0.766553 (0.062196)\n",
      "0.01 3 2 8 log2 mae 1.0 200: Macro 0.634212 (0.092837)\n",
      "Testing 552/5184\n",
      "0.01 3 2 8 log2 mae 1.0 500: Weighted 0.771500 (0.100357)\n",
      "0.01 3 2 8 log2 mae 1.0 500: Macro 0.641199 (0.142788)\n",
      "Testing 553/5184\n",
      "0.01 3 2 8 sqrt friedman_mse 0.5 50: Weighted 0.818056 (0.052536)\n",
      "0.01 3 2 8 sqrt friedman_mse 0.5 50: Macro 0.716965 (0.067282)\n",
      "Testing 554/5184\n",
      "0.01 3 2 8 sqrt friedman_mse 0.5 100: Weighted 0.826296 (0.056659)\n",
      "0.01 3 2 8 sqrt friedman_mse 0.5 100: Macro 0.728659 (0.073815)\n",
      "Testing 555/5184\n",
      "0.01 3 2 8 sqrt friedman_mse 0.5 200: Weighted 0.818608 (0.055878)\n",
      "0.01 3 2 8 sqrt friedman_mse 0.5 200: Macro 0.711371 (0.080030)\n",
      "Testing 556/5184\n",
      "0.01 3 2 8 sqrt friedman_mse 0.5 500: Weighted 0.825203 (0.077096)\n",
      "0.01 3 2 8 sqrt friedman_mse 0.5 500: Macro 0.726940 (0.107279)\n",
      "Testing 557/5184\n",
      "0.01 3 2 8 sqrt friedman_mse 0.75 50: Weighted 0.812536 (0.060627)\n",
      "0.01 3 2 8 sqrt friedman_mse 0.75 50: Macro 0.705681 (0.083223)\n",
      "Testing 558/5184\n",
      "0.01 3 2 8 sqrt friedman_mse 0.75 100: Weighted 0.793021 (0.052004)\n",
      "0.01 3 2 8 sqrt friedman_mse 0.75 100: Macro 0.682820 (0.068101)\n",
      "Testing 559/5184\n",
      "0.01 3 2 8 sqrt friedman_mse 0.75 200: Weighted 0.808322 (0.058026)\n",
      "0.01 3 2 8 sqrt friedman_mse 0.75 200: Macro 0.698698 (0.078209)\n",
      "Testing 560/5184\n",
      "0.01 3 2 8 sqrt friedman_mse 0.75 500: Weighted 0.806787 (0.082010)\n",
      "0.01 3 2 8 sqrt friedman_mse 0.75 500: Macro 0.703729 (0.113924)\n",
      "Testing 561/5184\n",
      "0.01 3 2 8 sqrt friedman_mse 1.0 50: Weighted 0.790178 (0.050778)\n",
      "0.01 3 2 8 sqrt friedman_mse 1.0 50: Macro 0.678044 (0.073235)\n",
      "Testing 562/5184\n",
      "0.01 3 2 8 sqrt friedman_mse 1.0 100: Weighted 0.779312 (0.060212)\n",
      "0.01 3 2 8 sqrt friedman_mse 1.0 100: Macro 0.671246 (0.079167)\n",
      "Testing 563/5184\n",
      "0.01 3 2 8 sqrt friedman_mse 1.0 200: Weighted 0.782169 (0.061183)\n",
      "0.01 3 2 8 sqrt friedman_mse 1.0 200: Macro 0.668874 (0.077207)\n",
      "Testing 564/5184\n",
      "0.01 3 2 8 sqrt friedman_mse 1.0 500: Weighted 0.794085 (0.075959)\n",
      "0.01 3 2 8 sqrt friedman_mse 1.0 500: Macro 0.682710 (0.110485)\n",
      "Testing 565/5184\n",
      "0.01 3 2 8 sqrt mae 0.5 50: Weighted 0.798830 (0.064581)\n",
      "0.01 3 2 8 sqrt mae 0.5 50: Macro 0.676488 (0.091609)\n",
      "Testing 566/5184\n",
      "0.01 3 2 8 sqrt mae 0.5 100: Weighted 0.808643 (0.061381)\n",
      "0.01 3 2 8 sqrt mae 0.5 100: Macro 0.688091 (0.091883)\n",
      "Testing 567/5184\n",
      "0.01 3 2 8 sqrt mae 0.5 200: Weighted 0.803282 (0.059620)\n",
      "0.01 3 2 8 sqrt mae 0.5 200: Macro 0.680899 (0.087057)\n",
      "Testing 568/5184\n",
      "0.01 3 2 8 sqrt mae 0.5 500: Weighted 0.794741 (0.075455)\n",
      "0.01 3 2 8 sqrt mae 0.5 500: Macro 0.676623 (0.102826)\n",
      "Testing 569/5184\n",
      "0.01 3 2 8 sqrt mae 0.75 50: Weighted 0.793537 (0.062495)\n",
      "0.01 3 2 8 sqrt mae 0.75 50: Macro 0.675576 (0.083014)\n",
      "Testing 570/5184\n",
      "0.01 3 2 8 sqrt mae 0.75 100: Weighted 0.803345 (0.059724)\n",
      "0.01 3 2 8 sqrt mae 0.75 100: Macro 0.682432 (0.086080)\n",
      "Testing 571/5184\n",
      "0.01 3 2 8 sqrt mae 0.75 200: Weighted 0.775427 (0.075372)\n",
      "0.01 3 2 8 sqrt mae 0.75 200: Macro 0.637085 (0.113996)\n",
      "Testing 572/5184\n",
      "0.01 3 2 8 sqrt mae 0.75 500: Weighted 0.772673 (0.088400)\n",
      "0.01 3 2 8 sqrt mae 0.75 500: Macro 0.641896 (0.124524)\n",
      "Testing 573/5184\n",
      "0.01 3 2 8 sqrt mae 1.0 50: Weighted 0.780602 (0.080996)\n",
      "0.01 3 2 8 sqrt mae 1.0 50: Macro 0.648379 (0.118249)\n",
      "Testing 574/5184\n",
      "0.01 3 2 8 sqrt mae 1.0 100: Weighted 0.765397 (0.074352)\n",
      "0.01 3 2 8 sqrt mae 1.0 100: Macro 0.632204 (0.111104)\n",
      "Testing 575/5184\n",
      "0.01 3 2 8 sqrt mae 1.0 200: Weighted 0.765738 (0.077805)\n",
      "0.01 3 2 8 sqrt mae 1.0 200: Macro 0.631410 (0.108735)\n",
      "Testing 576/5184\n",
      "0.01 3 2 8 sqrt mae 1.0 500: Weighted 0.774481 (0.097645)\n",
      "0.01 3 2 8 sqrt mae 1.0 500: Macro 0.650257 (0.133304)\n",
      "Testing 577/5184\n",
      "0.01 3 4 3 log2 friedman_mse 0.5 50: Weighted 0.812213 (0.062188)\n",
      "0.01 3 4 3 log2 friedman_mse 0.5 50: Macro 0.705104 (0.082524)\n",
      "Testing 578/5184\n",
      "0.01 3 4 3 log2 friedman_mse 0.5 100: Weighted 0.816593 (0.056095)\n",
      "0.01 3 4 3 log2 friedman_mse 0.5 100: Macro 0.704334 (0.083640)\n",
      "Testing 579/5184\n",
      "0.01 3 4 3 log2 friedman_mse 0.5 200: Weighted 0.828826 (0.054953)\n",
      "0.01 3 4 3 log2 friedman_mse 0.5 200: Macro 0.725841 (0.077289)\n",
      "Testing 580/5184\n",
      "0.01 3 4 3 log2 friedman_mse 0.5 500: Weighted 0.815748 (0.061852)\n",
      "0.01 3 4 3 log2 friedman_mse 0.5 500: Macro 0.707689 (0.083664)\n",
      "Testing 581/5184\n",
      "0.01 3 4 3 log2 friedman_mse 0.75 50: Weighted 0.812135 (0.062650)\n",
      "0.01 3 4 3 log2 friedman_mse 0.75 50: Macro 0.706151 (0.079155)\n",
      "Testing 582/5184\n",
      "0.01 3 4 3 log2 friedman_mse 0.75 100: Weighted 0.815571 (0.061789)\n",
      "0.01 3 4 3 log2 friedman_mse 0.75 100: Macro 0.711176 (0.077719)\n",
      "Testing 583/5184\n",
      "0.01 3 4 3 log2 friedman_mse 0.75 200: Weighted 0.805926 (0.064708)\n",
      "0.01 3 4 3 log2 friedman_mse 0.75 200: Macro 0.695176 (0.084899)\n",
      "Testing 584/5184\n",
      "0.01 3 4 3 log2 friedman_mse 0.75 500: Weighted 0.805646 (0.069980)\n",
      "0.01 3 4 3 log2 friedman_mse 0.75 500: Macro 0.703514 (0.087789)\n",
      "Testing 585/5184\n",
      "0.01 3 4 3 log2 friedman_mse 1.0 50: Weighted 0.800202 (0.060354)\n",
      "0.01 3 4 3 log2 friedman_mse 1.0 50: Macro 0.695245 (0.078388)\n",
      "Testing 586/5184\n",
      "0.01 3 4 3 log2 friedman_mse 1.0 100: Weighted 0.795251 (0.057598)\n",
      "0.01 3 4 3 log2 friedman_mse 1.0 100: Macro 0.683708 (0.079841)\n",
      "Testing 587/5184\n",
      "0.01 3 4 3 log2 friedman_mse 1.0 200: Weighted 0.787060 (0.056733)\n",
      "0.01 3 4 3 log2 friedman_mse 1.0 200: Macro 0.676630 (0.073441)\n",
      "Testing 588/5184\n",
      "0.01 3 4 3 log2 friedman_mse 1.0 500: Weighted 0.804841 (0.074227)\n",
      "0.01 3 4 3 log2 friedman_mse 1.0 500: Macro 0.701544 (0.097482)\n",
      "Testing 589/5184\n",
      "0.01 3 4 3 log2 mae 0.5 50: Weighted 0.819229 (0.043780)\n",
      "0.01 3 4 3 log2 mae 0.5 50: Macro 0.712513 (0.059614)\n",
      "Testing 590/5184\n",
      "0.01 3 4 3 log2 mae 0.5 100: Weighted 0.819342 (0.055848)\n",
      "0.01 3 4 3 log2 mae 0.5 100: Macro 0.713820 (0.075620)\n",
      "Testing 591/5184\n",
      "0.01 3 4 3 log2 mae 0.5 200: Weighted 0.812870 (0.051117)\n",
      "0.01 3 4 3 log2 mae 0.5 200: Macro 0.700830 (0.069660)\n",
      "Testing 592/5184\n",
      "0.01 3 4 3 log2 mae 0.5 500: Weighted 0.811968 (0.058905)\n",
      "0.01 3 4 3 log2 mae 0.5 500: Macro 0.692561 (0.088590)\n",
      "Testing 593/5184\n",
      "0.01 3 4 3 log2 mae 0.75 50: Weighted 0.794330 (0.066037)\n",
      "0.01 3 4 3 log2 mae 0.75 50: Macro 0.680894 (0.088298)\n",
      "Testing 594/5184\n",
      "0.01 3 4 3 log2 mae 0.75 100: Weighted 0.791328 (0.072080)\n",
      "0.01 3 4 3 log2 mae 0.75 100: Macro 0.669873 (0.098221)\n",
      "Testing 595/5184\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01 3 4 3 log2 mae 0.75 200: Weighted 0.786525 (0.066237)\n",
      "0.01 3 4 3 log2 mae 0.75 200: Macro 0.661559 (0.091420)\n",
      "Testing 596/5184\n",
      "0.01 3 4 3 log2 mae 0.75 500: Weighted 0.790564 (0.067191)\n",
      "0.01 3 4 3 log2 mae 0.75 500: Macro 0.671916 (0.096950)\n",
      "Testing 597/5184\n",
      "0.01 3 4 3 log2 mae 1.0 50: Weighted 0.789317 (0.067004)\n",
      "0.01 3 4 3 log2 mae 1.0 50: Macro 0.676373 (0.086767)\n",
      "Testing 598/5184\n",
      "0.01 3 4 3 log2 mae 1.0 100: Weighted 0.798096 (0.061890)\n",
      "0.01 3 4 3 log2 mae 1.0 100: Macro 0.681371 (0.083516)\n",
      "Testing 599/5184\n",
      "0.01 3 4 3 log2 mae 1.0 200: Weighted 0.772430 (0.066706)\n",
      "0.01 3 4 3 log2 mae 1.0 200: Macro 0.648316 (0.092216)\n",
      "Testing 600/5184\n",
      "0.01 3 4 3 log2 mae 1.0 500: Weighted 0.769249 (0.075418)\n",
      "0.01 3 4 3 log2 mae 1.0 500: Macro 0.642357 (0.107772)\n",
      "Testing 601/5184\n",
      "0.01 3 4 3 sqrt friedman_mse 0.5 50: Weighted 0.816593 (0.056095)\n",
      "0.01 3 4 3 sqrt friedman_mse 0.5 50: Macro 0.704334 (0.083640)\n",
      "Testing 602/5184\n",
      "0.01 3 4 3 sqrt friedman_mse 0.5 100: Weighted 0.818925 (0.048401)\n",
      "0.01 3 4 3 sqrt friedman_mse 0.5 100: Macro 0.712114 (0.064854)\n",
      "Testing 603/5184\n",
      "0.01 3 4 3 sqrt friedman_mse 0.5 200: Weighted 0.832395 (0.053831)\n",
      "0.01 3 4 3 sqrt friedman_mse 0.5 200: Macro 0.730076 (0.075545)\n",
      "Testing 604/5184\n",
      "0.01 3 4 3 sqrt friedman_mse 0.5 500: Weighted 0.818765 (0.060732)\n",
      "0.01 3 4 3 sqrt friedman_mse 0.5 500: Macro 0.718170 (0.084719)\n",
      "Testing 605/5184\n",
      "0.01 3 4 3 sqrt friedman_mse 0.75 50: Weighted 0.805391 (0.061740)\n",
      "0.01 3 4 3 sqrt friedman_mse 0.75 50: Macro 0.697677 (0.087345)\n",
      "Testing 606/5184\n",
      "0.01 3 4 3 sqrt friedman_mse 0.75 100: Weighted 0.824584 (0.048793)\n",
      "0.01 3 4 3 sqrt friedman_mse 0.75 100: Macro 0.717955 (0.067713)\n",
      "Testing 607/5184\n",
      "0.01 3 4 3 sqrt friedman_mse 0.75 200: Weighted 0.810196 (0.057904)\n",
      "0.01 3 4 3 sqrt friedman_mse 0.75 200: Macro 0.704586 (0.069798)\n",
      "Testing 608/5184\n",
      "0.01 3 4 3 sqrt friedman_mse 0.75 500: Weighted 0.810279 (0.069023)\n",
      "0.01 3 4 3 sqrt friedman_mse 0.75 500: Macro 0.706577 (0.085099)\n",
      "Testing 609/5184\n",
      "0.01 3 4 3 sqrt friedman_mse 1.0 50: Weighted 0.810097 (0.065244)\n",
      "0.01 3 4 3 sqrt friedman_mse 1.0 50: Macro 0.707147 (0.079594)\n",
      "Testing 610/5184\n",
      "0.01 3 4 3 sqrt friedman_mse 1.0 100: Weighted 0.798766 (0.056821)\n",
      "0.01 3 4 3 sqrt friedman_mse 1.0 100: Macro 0.688665 (0.078596)\n",
      "Testing 611/5184\n",
      "0.01 3 4 3 sqrt friedman_mse 1.0 200: Weighted 0.803422 (0.058344)\n",
      "0.01 3 4 3 sqrt friedman_mse 1.0 200: Macro 0.698423 (0.066177)\n",
      "Testing 612/5184\n",
      "0.01 3 4 3 sqrt friedman_mse 1.0 500: Weighted 0.803804 (0.074834)\n",
      "0.01 3 4 3 sqrt friedman_mse 1.0 500: Macro 0.701442 (0.097551)\n",
      "Testing 613/5184\n",
      "0.01 3 4 3 sqrt mae 0.5 50: Weighted 0.799036 (0.060904)\n",
      "0.01 3 4 3 sqrt mae 0.5 50: Macro 0.682906 (0.087161)\n",
      "Testing 614/5184\n",
      "0.01 3 4 3 sqrt mae 0.5 100: Weighted 0.816593 (0.056095)\n",
      "0.01 3 4 3 sqrt mae 0.5 100: Macro 0.704334 (0.083640)\n",
      "Testing 615/5184\n",
      "0.01 3 4 3 sqrt mae 0.5 200: Weighted 0.819439 (0.056048)\n",
      "0.01 3 4 3 sqrt mae 0.5 200: Macro 0.708755 (0.081404)\n",
      "Testing 616/5184\n",
      "0.01 3 4 3 sqrt mae 0.5 500: Weighted 0.811968 (0.058905)\n",
      "0.01 3 4 3 sqrt mae 0.5 500: Macro 0.692561 (0.088590)\n",
      "Testing 617/5184\n",
      "0.01 3 4 3 sqrt mae 0.75 50: Weighted 0.795522 (0.061200)\n",
      "0.01 3 4 3 sqrt mae 0.75 50: Macro 0.676278 (0.084464)\n",
      "Testing 618/5184\n",
      "0.01 3 4 3 sqrt mae 0.75 100: Weighted 0.798795 (0.060349)\n",
      "0.01 3 4 3 sqrt mae 0.75 100: Macro 0.682093 (0.084163)\n",
      "Testing 619/5184\n",
      "0.01 3 4 3 sqrt mae 0.75 200: Weighted 0.801288 (0.064791)\n",
      "0.01 3 4 3 sqrt mae 0.75 200: Macro 0.682163 (0.089410)\n",
      "Testing 620/5184\n",
      "0.01 3 4 3 sqrt mae 0.75 500: Weighted 0.780023 (0.077865)\n",
      "0.01 3 4 3 sqrt mae 0.75 500: Macro 0.663280 (0.105837)\n",
      "Testing 621/5184\n",
      "0.01 3 4 3 sqrt mae 1.0 50: Weighted 0.791774 (0.068867)\n",
      "0.01 3 4 3 sqrt mae 1.0 50: Macro 0.674542 (0.094315)\n",
      "Testing 622/5184\n",
      "0.01 3 4 3 sqrt mae 1.0 100: Weighted 0.784929 (0.067071)\n",
      "0.01 3 4 3 sqrt mae 1.0 100: Macro 0.666854 (0.086349)\n",
      "Testing 623/5184\n",
      "0.01 3 4 3 sqrt mae 1.0 200: Weighted 0.779453 (0.063345)\n",
      "0.01 3 4 3 sqrt mae 1.0 200: Macro 0.657371 (0.086540)\n",
      "Testing 624/5184\n",
      "0.01 3 4 3 sqrt mae 1.0 500: Weighted 0.778955 (0.082173)\n",
      "0.01 3 4 3 sqrt mae 1.0 500: Macro 0.657842 (0.117880)\n",
      "Testing 625/5184\n",
      "0.01 3 4 5 log2 friedman_mse 0.5 50: Weighted 0.821871 (0.050420)\n",
      "0.01 3 4 5 log2 friedman_mse 0.5 50: Macro 0.715216 (0.074183)\n",
      "Testing 626/5184\n",
      "0.01 3 4 5 log2 friedman_mse 0.5 100: Weighted 0.809787 (0.051670)\n",
      "0.01 3 4 5 log2 friedman_mse 0.5 100: Macro 0.697895 (0.075044)\n",
      "Testing 627/5184\n",
      "0.01 3 4 5 log2 friedman_mse 0.5 200: Weighted 0.814028 (0.053459)\n",
      "0.01 3 4 5 log2 friedman_mse 0.5 200: Macro 0.710191 (0.070861)\n",
      "Testing 628/5184\n",
      "0.01 3 4 5 log2 friedman_mse 0.5 500: Weighted 0.815583 (0.068312)\n",
      "0.01 3 4 5 log2 friedman_mse 0.5 500: Macro 0.717695 (0.100506)\n",
      "Testing 629/5184\n",
      "0.01 3 4 5 log2 friedman_mse 0.75 50: Weighted 0.798430 (0.067878)\n",
      "0.01 3 4 5 log2 friedman_mse 0.75 50: Macro 0.685654 (0.090929)\n",
      "Testing 630/5184\n",
      "0.01 3 4 5 log2 friedman_mse 0.75 100: Weighted 0.807369 (0.060336)\n",
      "0.01 3 4 5 log2 friedman_mse 0.75 100: Macro 0.693822 (0.084919)\n",
      "Testing 631/5184\n",
      "0.01 3 4 5 log2 friedman_mse 0.75 200: Weighted 0.803874 (0.064569)\n",
      "0.01 3 4 5 log2 friedman_mse 0.75 200: Macro 0.693185 (0.084618)\n",
      "Testing 632/5184\n",
      "0.01 3 4 5 log2 friedman_mse 0.75 500: Weighted 0.802754 (0.090321)\n",
      "0.01 3 4 5 log2 friedman_mse 0.75 500: Macro 0.698940 (0.126243)\n",
      "Testing 633/5184\n",
      "0.01 3 4 5 log2 friedman_mse 1.0 50: Weighted 0.794796 (0.068338)\n",
      "0.01 3 4 5 log2 friedman_mse 1.0 50: Macro 0.684655 (0.088488)\n",
      "Testing 634/5184\n",
      "0.01 3 4 5 log2 friedman_mse 1.0 100: Weighted 0.788708 (0.063914)\n",
      "0.01 3 4 5 log2 friedman_mse 1.0 100: Macro 0.682345 (0.085791)\n",
      "Testing 635/5184\n",
      "0.01 3 4 5 log2 friedman_mse 1.0 200: Weighted 0.788746 (0.066870)\n",
      "0.01 3 4 5 log2 friedman_mse 1.0 200: Macro 0.681420 (0.083805)\n",
      "Testing 636/5184\n",
      "0.01 3 4 5 log2 friedman_mse 1.0 500: Weighted 0.812519 (0.093970)\n",
      "0.01 3 4 5 log2 friedman_mse 1.0 500: Macro 0.713418 (0.132908)\n",
      "Testing 637/5184\n",
      "0.01 3 4 5 log2 mae 0.5 50: Weighted 0.806801 (0.057108)\n",
      "0.01 3 4 5 log2 mae 0.5 50: Macro 0.691800 (0.081332)\n",
      "Testing 638/5184\n",
      "0.01 3 4 5 log2 mae 0.5 100: Weighted 0.802807 (0.062241)\n",
      "0.01 3 4 5 log2 mae 0.5 100: Macro 0.682116 (0.088742)\n",
      "Testing 639/5184\n",
      "0.01 3 4 5 log2 mae 0.5 200: Weighted 0.800440 (0.062000)\n",
      "0.01 3 4 5 log2 mae 0.5 200: Macro 0.676455 (0.091370)\n",
      "Testing 640/5184\n",
      "0.01 3 4 5 log2 mae 0.5 500: Weighted 0.803555 (0.076191)\n",
      "0.01 3 4 5 log2 mae 0.5 500: Macro 0.687309 (0.107829)\n",
      "Testing 641/5184\n",
      "0.01 3 4 5 log2 mae 0.75 50: Weighted 0.789555 (0.066603)\n",
      "0.01 3 4 5 log2 mae 0.75 50: Macro 0.667295 (0.090698)\n",
      "Testing 642/5184\n",
      "0.01 3 4 5 log2 mae 0.75 100: Weighted 0.788096 (0.073591)\n",
      "0.01 3 4 5 log2 mae 0.75 100: Macro 0.665374 (0.101955)\n",
      "Testing 643/5184\n",
      "0.01 3 4 5 log2 mae 0.75 200: Weighted 0.788734 (0.075163)\n",
      "0.01 3 4 5 log2 mae 0.75 200: Macro 0.669390 (0.099109)\n",
      "Testing 644/5184\n",
      "0.01 3 4 5 log2 mae 0.75 500: Weighted 0.765770 (0.082168)\n",
      "0.01 3 4 5 log2 mae 0.75 500: Macro 0.635130 (0.119755)\n",
      "Testing 645/5184\n",
      "0.01 3 4 5 log2 mae 1.0 50: Weighted 0.768797 (0.068030)\n",
      "0.01 3 4 5 log2 mae 1.0 50: Macro 0.640407 (0.099177)\n",
      "Testing 646/5184\n",
      "0.01 3 4 5 log2 mae 1.0 100: Weighted 0.778384 (0.062147)\n",
      "0.01 3 4 5 log2 mae 1.0 100: Macro 0.658143 (0.087376)\n",
      "Testing 647/5184\n",
      "0.01 3 4 5 log2 mae 1.0 200: Weighted 0.774577 (0.060270)\n",
      "0.01 3 4 5 log2 mae 1.0 200: Macro 0.647916 (0.085320)\n",
      "Testing 648/5184\n",
      "0.01 3 4 5 log2 mae 1.0 500: Weighted 0.768362 (0.090582)\n",
      "0.01 3 4 5 log2 mae 1.0 500: Macro 0.637190 (0.126871)\n",
      "Testing 649/5184\n",
      "0.01 3 4 5 sqrt friedman_mse 0.5 50: Weighted 0.814310 (0.049327)\n",
      "0.01 3 4 5 sqrt friedman_mse 0.5 50: Macro 0.707945 (0.067406)\n",
      "Testing 650/5184\n",
      "0.01 3 4 5 sqrt friedman_mse 0.5 100: Weighted 0.802159 (0.062358)\n",
      "0.01 3 4 5 sqrt friedman_mse 0.5 100: Macro 0.689355 (0.086189)\n",
      "Testing 651/5184\n",
      "0.01 3 4 5 sqrt friedman_mse 0.5 200: Weighted 0.817590 (0.053226)\n",
      "0.01 3 4 5 sqrt friedman_mse 0.5 200: Macro 0.714453 (0.070194)\n",
      "Testing 652/5184\n",
      "0.01 3 4 5 sqrt friedman_mse 0.5 500: Weighted 0.822006 (0.074132)\n",
      "0.01 3 4 5 sqrt friedman_mse 0.5 500: Macro 0.721223 (0.106668)\n",
      "Testing 653/5184\n",
      "0.01 3 4 5 sqrt friedman_mse 0.75 50: Weighted 0.801995 (0.066830)\n",
      "0.01 3 4 5 sqrt friedman_mse 0.75 50: Macro 0.690818 (0.089710)\n",
      "Testing 654/5184\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01 3 4 5 sqrt friedman_mse 0.75 100: Weighted 0.814194 (0.059682)\n",
      "0.01 3 4 5 sqrt friedman_mse 0.75 100: Macro 0.704005 (0.084637)\n",
      "Testing 655/5184\n",
      "0.01 3 4 5 sqrt friedman_mse 0.75 200: Weighted 0.814614 (0.041592)\n",
      "0.01 3 4 5 sqrt friedman_mse 0.75 200: Macro 0.706670 (0.053652)\n",
      "Testing 656/5184\n",
      "0.01 3 4 5 sqrt friedman_mse 0.75 500: Weighted 0.803616 (0.089535)\n",
      "0.01 3 4 5 sqrt friedman_mse 0.75 500: Macro 0.699006 (0.126181)\n",
      "Testing 657/5184\n",
      "0.01 3 4 5 sqrt friedman_mse 1.0 50: Weighted 0.789572 (0.067425)\n",
      "0.01 3 4 5 sqrt friedman_mse 1.0 50: Macro 0.678074 (0.089569)\n",
      "Testing 658/5184\n",
      "0.01 3 4 5 sqrt friedman_mse 1.0 100: Weighted 0.788710 (0.064739)\n",
      "0.01 3 4 5 sqrt friedman_mse 1.0 100: Macro 0.682109 (0.084263)\n",
      "Testing 659/5184\n",
      "0.01 3 4 5 sqrt friedman_mse 1.0 200: Weighted 0.788746 (0.066870)\n",
      "0.01 3 4 5 sqrt friedman_mse 1.0 200: Macro 0.681420 (0.083805)\n",
      "Testing 660/5184\n",
      "0.01 3 4 5 sqrt friedman_mse 1.0 500: Weighted 0.804172 (0.095163)\n",
      "0.01 3 4 5 sqrt friedman_mse 1.0 500: Macro 0.702321 (0.131747)\n",
      "Testing 661/5184\n",
      "0.01 3 4 5 sqrt mae 0.5 50: Weighted 0.811563 (0.059182)\n",
      "0.01 3 4 5 sqrt mae 0.5 50: Macro 0.698943 (0.084898)\n",
      "Testing 662/5184\n",
      "0.01 3 4 5 sqrt mae 0.5 100: Weighted 0.802031 (0.060626)\n",
      "0.01 3 4 5 sqrt mae 0.5 100: Macro 0.680990 (0.087687)\n",
      "Testing 663/5184\n",
      "0.01 3 4 5 sqrt mae 0.5 200: Weighted 0.802031 (0.060626)\n",
      "0.01 3 4 5 sqrt mae 0.5 200: Macro 0.680990 (0.087687)\n",
      "Testing 664/5184\n",
      "0.01 3 4 5 sqrt mae 0.5 500: Weighted 0.783479 (0.078008)\n",
      "0.01 3 4 5 sqrt mae 0.5 500: Macro 0.655039 (0.112522)\n",
      "Testing 665/5184\n",
      "0.01 3 4 5 sqrt mae 0.75 50: Weighted 0.804666 (0.064927)\n",
      "0.01 3 4 5 sqrt mae 0.75 50: Macro 0.685081 (0.094169)\n",
      "Testing 666/5184\n",
      "0.01 3 4 5 sqrt mae 0.75 100: Weighted 0.784633 (0.071590)\n",
      "0.01 3 4 5 sqrt mae 0.75 100: Macro 0.663570 (0.095130)\n",
      "Testing 667/5184\n",
      "0.01 3 4 5 sqrt mae 0.75 200: Weighted 0.798851 (0.063567)\n",
      "0.01 3 4 5 sqrt mae 0.75 200: Macro 0.677586 (0.090224)\n",
      "Testing 668/5184\n",
      "0.01 3 4 5 sqrt mae 0.75 500: Weighted 0.763639 (0.082668)\n",
      "0.01 3 4 5 sqrt mae 0.75 500: Macro 0.634447 (0.118564)\n",
      "Testing 669/5184\n",
      "0.01 3 4 5 sqrt mae 1.0 50: Weighted 0.775403 (0.068739)\n",
      "0.01 3 4 5 sqrt mae 1.0 50: Macro 0.651737 (0.090013)\n",
      "Testing 670/5184\n",
      "0.01 3 4 5 sqrt mae 1.0 100: Weighted 0.787663 (0.061526)\n",
      "0.01 3 4 5 sqrt mae 1.0 100: Macro 0.669327 (0.086579)\n",
      "Testing 671/5184\n",
      "0.01 3 4 5 sqrt mae 1.0 200: Weighted 0.777063 (0.053566)\n",
      "0.01 3 4 5 sqrt mae 1.0 200: Macro 0.655079 (0.073110)\n",
      "Testing 672/5184\n",
      "0.01 3 4 5 sqrt mae 1.0 500: Weighted 0.769177 (0.077560)\n",
      "0.01 3 4 5 sqrt mae 1.0 500: Macro 0.639991 (0.113399)\n",
      "Testing 673/5184\n",
      "0.01 3 4 8 log2 friedman_mse 0.5 50: Weighted 0.813522 (0.039221)\n",
      "0.01 3 4 8 log2 friedman_mse 0.5 50: Macro 0.705567 (0.049812)\n",
      "Testing 674/5184\n",
      "0.01 3 4 8 log2 friedman_mse 0.5 100: Weighted 0.806365 (0.063417)\n",
      "0.01 3 4 8 log2 friedman_mse 0.5 100: Macro 0.695377 (0.085855)\n",
      "Testing 675/5184\n",
      "0.01 3 4 8 log2 friedman_mse 0.5 200: Weighted 0.835354 (0.055623)\n",
      "0.01 3 4 8 log2 friedman_mse 0.5 200: Macro 0.736322 (0.078610)\n",
      "Testing 676/5184\n",
      "0.01 3 4 8 log2 friedman_mse 0.5 500: Weighted 0.828206 (0.069774)\n",
      "0.01 3 4 8 log2 friedman_mse 0.5 500: Macro 0.719803 (0.106581)\n",
      "Testing 677/5184\n",
      "0.01 3 4 8 log2 friedman_mse 0.75 50: Weighted 0.790785 (0.057520)\n",
      "0.01 3 4 8 log2 friedman_mse 0.75 50: Macro 0.676259 (0.072752)\n",
      "Testing 678/5184\n",
      "0.01 3 4 8 log2 friedman_mse 0.75 100: Weighted 0.800080 (0.062556)\n",
      "0.01 3 4 8 log2 friedman_mse 0.75 100: Macro 0.682825 (0.086910)\n",
      "Testing 679/5184\n",
      "0.01 3 4 8 log2 friedman_mse 0.75 200: Weighted 0.807363 (0.045227)\n",
      "0.01 3 4 8 log2 friedman_mse 0.75 200: Macro 0.704079 (0.055805)\n",
      "Testing 680/5184\n",
      "0.01 3 4 8 log2 friedman_mse 0.75 500: Weighted 0.814896 (0.080901)\n",
      "0.01 3 4 8 log2 friedman_mse 0.75 500: Macro 0.710509 (0.116091)\n",
      "Testing 681/5184\n",
      "0.01 3 4 8 log2 friedman_mse 1.0 50: Weighted 0.786590 (0.053032)\n",
      "0.01 3 4 8 log2 friedman_mse 1.0 50: Macro 0.680136 (0.072158)\n",
      "Testing 682/5184\n",
      "0.01 3 4 8 log2 friedman_mse 1.0 100: Weighted 0.783637 (0.058239)\n",
      "0.01 3 4 8 log2 friedman_mse 1.0 100: Macro 0.668505 (0.079456)\n",
      "Testing 683/5184\n",
      "0.01 3 4 8 log2 friedman_mse 1.0 200: Weighted 0.788277 (0.066633)\n",
      "0.01 3 4 8 log2 friedman_mse 1.0 200: Macro 0.675156 (0.087432)\n",
      "Testing 684/5184\n",
      "0.01 3 4 8 log2 friedman_mse 1.0 500: Weighted 0.784362 (0.079386)\n",
      "0.01 3 4 8 log2 friedman_mse 1.0 500: Macro 0.671337 (0.110718)\n",
      "Testing 685/5184\n",
      "0.01 3 4 8 log2 mae 0.5 50: Weighted 0.798439 (0.058540)\n",
      "0.01 3 4 8 log2 mae 0.5 50: Macro 0.675381 (0.083622)\n",
      "Testing 686/5184\n",
      "0.01 3 4 8 log2 mae 0.5 100: Weighted 0.802217 (0.049597)\n",
      "0.01 3 4 8 log2 mae 0.5 100: Macro 0.678697 (0.073378)\n",
      "Testing 687/5184\n",
      "0.01 3 4 8 log2 mae 0.5 200: Weighted 0.807101 (0.055893)\n",
      "0.01 3 4 8 log2 mae 0.5 200: Macro 0.686190 (0.082141)\n",
      "Testing 688/5184\n",
      "0.01 3 4 8 log2 mae 0.5 500: Weighted 0.788896 (0.073228)\n",
      "0.01 3 4 8 log2 mae 0.5 500: Macro 0.669483 (0.098247)\n",
      "Testing 689/5184\n",
      "0.01 3 4 8 log2 mae 0.75 50: Weighted 0.796355 (0.073058)\n",
      "0.01 3 4 8 log2 mae 0.75 50: Macro 0.675949 (0.103134)\n",
      "Testing 690/5184\n",
      "0.01 3 4 8 log2 mae 0.75 100: Weighted 0.802715 (0.066964)\n",
      "0.01 3 4 8 log2 mae 0.75 100: Macro 0.684909 (0.094345)\n",
      "Testing 691/5184\n",
      "0.01 3 4 8 log2 mae 0.75 200: Weighted 0.798025 (0.071349)\n",
      "0.01 3 4 8 log2 mae 0.75 200: Macro 0.674084 (0.105627)\n",
      "Testing 692/5184\n",
      "0.01 3 4 8 log2 mae 0.75 500: Weighted 0.790407 (0.086951)\n",
      "0.01 3 4 8 log2 mae 0.75 500: Macro 0.671877 (0.120757)\n",
      "Testing 693/5184\n",
      "0.01 3 4 8 log2 mae 1.0 50: Weighted 0.775076 (0.063690)\n",
      "0.01 3 4 8 log2 mae 1.0 50: Macro 0.652135 (0.090853)\n",
      "Testing 694/5184\n",
      "0.01 3 4 8 log2 mae 1.0 100: Weighted 0.763046 (0.065948)\n",
      "0.01 3 4 8 log2 mae 1.0 100: Macro 0.635078 (0.092873)\n",
      "Testing 695/5184\n",
      "0.01 3 4 8 log2 mae 1.0 200: Weighted 0.762138 (0.056607)\n",
      "0.01 3 4 8 log2 mae 1.0 200: Macro 0.630663 (0.088325)\n",
      "Testing 696/5184\n",
      "0.01 3 4 8 log2 mae 1.0 500: Weighted 0.775689 (0.085843)\n",
      "0.01 3 4 8 log2 mae 1.0 500: Macro 0.645686 (0.123315)\n",
      "Testing 697/5184\n",
      "0.01 3 4 8 sqrt friedman_mse 0.5 50: Weighted 0.819521 (0.063301)\n",
      "0.01 3 4 8 sqrt friedman_mse 0.5 50: Macro 0.713042 (0.090159)\n",
      "Testing 698/5184\n",
      "0.01 3 4 8 sqrt friedman_mse 0.5 100: Weighted 0.809264 (0.048155)\n",
      "0.01 3 4 8 sqrt friedman_mse 0.5 100: Macro 0.697349 (0.068693)\n",
      "Testing 699/5184\n",
      "0.01 3 4 8 sqrt friedman_mse 0.5 200: Weighted 0.815061 (0.051214)\n",
      "0.01 3 4 8 sqrt friedman_mse 0.5 200: Macro 0.715648 (0.062212)\n",
      "Testing 700/5184\n",
      "0.01 3 4 8 sqrt friedman_mse 0.5 500: Weighted 0.831578 (0.071406)\n",
      "0.01 3 4 8 sqrt friedman_mse 0.5 500: Macro 0.730185 (0.104426)\n",
      "Testing 701/5184\n",
      "0.01 3 4 8 sqrt friedman_mse 0.75 50: Weighted 0.803856 (0.064172)\n",
      "0.01 3 4 8 sqrt friedman_mse 0.75 50: Macro 0.695372 (0.082984)\n",
      "Testing 702/5184\n",
      "0.01 3 4 8 sqrt friedman_mse 0.75 100: Weighted 0.795667 (0.054032)\n",
      "0.01 3 4 8 sqrt friedman_mse 0.75 100: Macro 0.683596 (0.073973)\n",
      "Testing 703/5184\n",
      "0.01 3 4 8 sqrt friedman_mse 0.75 200: Weighted 0.815543 (0.059160)\n",
      "0.01 3 4 8 sqrt friedman_mse 0.75 200: Macro 0.718514 (0.074973)\n",
      "Testing 704/5184\n",
      "0.01 3 4 8 sqrt friedman_mse 0.75 500: Weighted 0.810873 (0.078411)\n",
      "0.01 3 4 8 sqrt friedman_mse 0.75 500: Macro 0.708191 (0.110182)\n",
      "Testing 705/5184\n",
      "0.01 3 4 8 sqrt friedman_mse 1.0 50: Weighted 0.784805 (0.057595)\n",
      "0.01 3 4 8 sqrt friedman_mse 1.0 50: Macro 0.667249 (0.080268)\n",
      "Testing 706/5184\n",
      "0.01 3 4 8 sqrt friedman_mse 1.0 100: Weighted 0.783721 (0.057183)\n",
      "0.01 3 4 8 sqrt friedman_mse 1.0 100: Macro 0.676067 (0.076816)\n",
      "Testing 707/5184\n",
      "0.01 3 4 8 sqrt friedman_mse 1.0 200: Weighted 0.786689 (0.067995)\n",
      "0.01 3 4 8 sqrt friedman_mse 1.0 200: Macro 0.675686 (0.086971)\n",
      "Testing 708/5184\n",
      "0.01 3 4 8 sqrt friedman_mse 1.0 500: Weighted 0.789653 (0.080641)\n",
      "0.01 3 4 8 sqrt friedman_mse 1.0 500: Macro 0.679359 (0.114438)\n",
      "Testing 709/5184\n",
      "0.01 3 4 8 sqrt mae 0.5 50: Weighted 0.800464 (0.072958)\n",
      "0.01 3 4 8 sqrt mae 0.5 50: Macro 0.680114 (0.104697)\n",
      "Testing 710/5184\n",
      "0.01 3 4 8 sqrt mae 0.5 100: Weighted 0.802810 (0.059987)\n",
      "0.01 3 4 8 sqrt mae 0.5 100: Macro 0.680656 (0.087940)\n",
      "Testing 711/5184\n",
      "0.01 3 4 8 sqrt mae 0.5 200: Weighted 0.801393 (0.071727)\n",
      "0.01 3 4 8 sqrt mae 0.5 200: Macro 0.684534 (0.100182)\n",
      "Testing 712/5184\n",
      "0.01 3 4 8 sqrt mae 0.5 500: Weighted 0.798111 (0.072628)\n",
      "0.01 3 4 8 sqrt mae 0.5 500: Macro 0.679990 (0.100008)\n",
      "Testing 713/5184\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01 3 4 8 sqrt mae 0.75 50: Weighted 0.797953 (0.064489)\n",
      "0.01 3 4 8 sqrt mae 0.75 50: Macro 0.677766 (0.090043)\n",
      "Testing 714/5184\n",
      "0.01 3 4 8 sqrt mae 0.75 100: Weighted 0.795067 (0.069586)\n",
      "0.01 3 4 8 sqrt mae 0.75 100: Macro 0.674380 (0.095469)\n",
      "Testing 715/5184\n",
      "0.01 3 4 8 sqrt mae 0.75 200: Weighted 0.781440 (0.069609)\n",
      "0.01 3 4 8 sqrt mae 0.75 200: Macro 0.644630 (0.106609)\n",
      "Testing 716/5184\n",
      "0.01 3 4 8 sqrt mae 0.75 500: Weighted 0.775669 (0.086068)\n",
      "0.01 3 4 8 sqrt mae 0.75 500: Macro 0.646648 (0.120275)\n",
      "Testing 717/5184\n",
      "0.01 3 4 8 sqrt mae 1.0 50: Weighted 0.795295 (0.065383)\n",
      "0.01 3 4 8 sqrt mae 1.0 50: Macro 0.670020 (0.092736)\n",
      "Testing 718/5184\n",
      "0.01 3 4 8 sqrt mae 1.0 100: Weighted 0.769908 (0.058942)\n",
      "0.01 3 4 8 sqrt mae 1.0 100: Macro 0.647289 (0.080215)\n",
      "Testing 719/5184\n",
      "0.01 3 4 8 sqrt mae 1.0 200: Weighted 0.772382 (0.064902)\n",
      "0.01 3 4 8 sqrt mae 1.0 200: Macro 0.646748 (0.092900)\n",
      "Testing 720/5184\n",
      "0.01 3 4 8 sqrt mae 1.0 500: Weighted 0.773349 (0.105478)\n",
      "0.01 3 4 8 sqrt mae 1.0 500: Macro 0.643124 (0.150942)\n",
      "Testing 721/5184\n",
      "0.01 3 6 3 log2 friedman_mse 0.5 50: Weighted 0.814738 (0.050470)\n",
      "0.01 3 6 3 log2 friedman_mse 0.5 50: Macro 0.702868 (0.074617)\n",
      "Testing 722/5184\n",
      "0.01 3 6 3 log2 friedman_mse 0.5 100: Weighted 0.824584 (0.048793)\n",
      "0.01 3 6 3 log2 friedman_mse 0.5 100: Macro 0.717955 (0.067713)\n",
      "Testing 723/5184\n",
      "0.01 3 6 3 log2 friedman_mse 0.5 200: Weighted 0.814434 (0.054502)\n",
      "0.01 3 6 3 log2 friedman_mse 0.5 200: Macro 0.702469 (0.078817)\n",
      "Testing 724/5184\n",
      "0.01 3 6 3 log2 friedman_mse 0.5 500: Weighted 0.820775 (0.065572)\n",
      "0.01 3 6 3 log2 friedman_mse 0.5 500: Macro 0.716318 (0.091119)\n",
      "Testing 725/5184\n",
      "0.01 3 6 3 log2 friedman_mse 0.75 50: Weighted 0.800898 (0.051903)\n",
      "0.01 3 6 3 log2 friedman_mse 0.75 50: Macro 0.688109 (0.074859)\n",
      "Testing 726/5184\n",
      "0.01 3 6 3 log2 friedman_mse 0.75 100: Weighted 0.811396 (0.068181)\n",
      "0.01 3 6 3 log2 friedman_mse 0.75 100: Macro 0.701866 (0.092129)\n",
      "Testing 727/5184\n",
      "0.01 3 6 3 log2 friedman_mse 0.75 200: Weighted 0.814716 (0.063082)\n",
      "0.01 3 6 3 log2 friedman_mse 0.75 200: Macro 0.711398 (0.077384)\n",
      "Testing 728/5184\n",
      "0.01 3 6 3 log2 friedman_mse 0.75 500: Weighted 0.812646 (0.064221)\n",
      "0.01 3 6 3 log2 friedman_mse 0.75 500: Macro 0.711673 (0.081391)\n",
      "Testing 729/5184\n",
      "0.01 3 6 3 log2 friedman_mse 1.0 50: Weighted 0.800996 (0.057496)\n",
      "0.01 3 6 3 log2 friedman_mse 1.0 50: Macro 0.692268 (0.066906)\n",
      "Testing 730/5184\n",
      "0.01 3 6 3 log2 friedman_mse 1.0 100: Weighted 0.795010 (0.073019)\n",
      "0.01 3 6 3 log2 friedman_mse 1.0 100: Macro 0.687492 (0.095940)\n",
      "Testing 731/5184\n",
      "0.01 3 6 3 log2 friedman_mse 1.0 200: Weighted 0.796713 (0.059488)\n",
      "0.01 3 6 3 log2 friedman_mse 1.0 200: Macro 0.687584 (0.068254)\n",
      "Testing 732/5184\n",
      "0.01 3 6 3 log2 friedman_mse 1.0 500: Weighted 0.808848 (0.075109)\n",
      "0.01 3 6 3 log2 friedman_mse 1.0 500: Macro 0.708890 (0.098319)\n",
      "Testing 733/5184\n",
      "0.01 3 6 3 log2 mae 0.5 50: Weighted 0.807275 (0.057736)\n",
      "0.01 3 6 3 log2 mae 0.5 50: Macro 0.691839 (0.082651)\n",
      "Testing 734/5184\n",
      "0.01 3 6 3 log2 mae 0.5 100: Weighted 0.816087 (0.057114)\n",
      "0.01 3 6 3 log2 mae 0.5 100: Macro 0.707871 (0.076731)\n",
      "Testing 735/5184\n",
      "0.01 3 6 3 log2 mae 0.5 200: Weighted 0.823429 (0.050375)\n",
      "0.01 3 6 3 log2 mae 0.5 200: Macro 0.713676 (0.073970)\n",
      "Testing 736/5184\n",
      "0.01 3 6 3 log2 mae 0.5 500: Weighted 0.808643 (0.061381)\n",
      "0.01 3 6 3 log2 mae 0.5 500: Macro 0.688091 (0.091883)\n",
      "Testing 737/5184\n",
      "0.01 3 6 3 log2 mae 0.75 50: Weighted 0.799342 (0.065362)\n",
      "0.01 3 6 3 log2 mae 0.75 50: Macro 0.683556 (0.088953)\n",
      "Testing 738/5184\n",
      "0.01 3 6 3 log2 mae 0.75 100: Weighted 0.798096 (0.061890)\n",
      "0.01 3 6 3 log2 mae 0.75 100: Macro 0.681371 (0.083516)\n",
      "Testing 739/5184\n",
      "0.01 3 6 3 log2 mae 0.75 200: Weighted 0.798052 (0.065833)\n",
      "0.01 3 6 3 log2 mae 0.75 200: Macro 0.677665 (0.091307)\n",
      "Testing 740/5184\n",
      "0.01 3 6 3 log2 mae 0.75 500: Weighted 0.789615 (0.068400)\n",
      "0.01 3 6 3 log2 mae 0.75 500: Macro 0.672037 (0.096806)\n",
      "Testing 741/5184\n",
      "0.01 3 6 3 log2 mae 1.0 50: Weighted 0.797408 (0.060660)\n",
      "0.01 3 6 3 log2 mae 1.0 50: Macro 0.684988 (0.083015)\n",
      "Testing 742/5184\n",
      "0.01 3 6 3 log2 mae 1.0 100: Weighted 0.797853 (0.061786)\n",
      "0.01 3 6 3 log2 mae 1.0 100: Macro 0.682228 (0.083951)\n",
      "Testing 743/5184\n",
      "0.01 3 6 3 log2 mae 1.0 200: Weighted 0.781614 (0.065321)\n",
      "0.01 3 6 3 log2 mae 1.0 200: Macro 0.658738 (0.094735)\n",
      "Testing 744/5184\n",
      "0.01 3 6 3 log2 mae 1.0 500: Weighted 0.774262 (0.077690)\n",
      "0.01 3 6 3 log2 mae 1.0 500: Macro 0.647646 (0.107757)\n",
      "Testing 745/5184\n",
      "0.01 3 6 3 sqrt friedman_mse 0.5 50: Weighted 0.822897 (0.049384)\n",
      "0.01 3 6 3 sqrt friedman_mse 0.5 50: Macro 0.719914 (0.067864)\n",
      "Testing 746/5184\n",
      "0.01 3 6 3 sqrt friedman_mse 0.5 100: Weighted 0.820029 (0.054853)\n",
      "0.01 3 6 3 sqrt friedman_mse 0.5 100: Macro 0.709358 (0.082393)\n",
      "Testing 747/5184\n",
      "0.01 3 6 3 sqrt friedman_mse 0.5 200: Weighted 0.823749 (0.049614)\n",
      "0.01 3 6 3 sqrt friedman_mse 0.5 200: Macro 0.719324 (0.067545)\n",
      "Testing 748/5184\n",
      "0.01 3 6 3 sqrt friedman_mse 0.5 500: Weighted 0.815588 (0.049555)\n",
      "0.01 3 6 3 sqrt friedman_mse 0.5 500: Macro 0.709483 (0.071239)\n",
      "Testing 749/5184\n",
      "0.01 3 6 3 sqrt friedman_mse 0.75 50: Weighted 0.820493 (0.051316)\n",
      "0.01 3 6 3 sqrt friedman_mse 0.75 50: Macro 0.713375 (0.069261)\n",
      "Testing 750/5184\n",
      "0.01 3 6 3 sqrt friedman_mse 0.75 100: Weighted 0.811396 (0.068181)\n",
      "0.01 3 6 3 sqrt friedman_mse 0.75 100: Macro 0.701866 (0.092129)\n",
      "Testing 751/5184\n",
      "0.01 3 6 3 sqrt friedman_mse 0.75 200: Weighted 0.805926 (0.064708)\n",
      "0.01 3 6 3 sqrt friedman_mse 0.75 200: Macro 0.695176 (0.084899)\n",
      "Testing 752/5184\n",
      "0.01 3 6 3 sqrt friedman_mse 0.75 500: Weighted 0.811847 (0.074325)\n",
      "0.01 3 6 3 sqrt friedman_mse 0.75 500: Macro 0.710762 (0.098521)\n",
      "Testing 753/5184\n",
      "0.01 3 6 3 sqrt friedman_mse 1.0 50: Weighted 0.801413 (0.073846)\n",
      "0.01 3 6 3 sqrt friedman_mse 1.0 50: Macro 0.692680 (0.095107)\n",
      "Testing 754/5184\n",
      "0.01 3 6 3 sqrt friedman_mse 1.0 100: Weighted 0.808097 (0.052716)\n",
      "0.01 3 6 3 sqrt friedman_mse 1.0 100: Macro 0.705770 (0.068276)\n",
      "Testing 755/5184\n",
      "0.01 3 6 3 sqrt friedman_mse 1.0 200: Weighted 0.800105 (0.070855)\n",
      "0.01 3 6 3 sqrt friedman_mse 1.0 200: Macro 0.690427 (0.089944)\n",
      "Testing 756/5184\n",
      "0.01 3 6 3 sqrt friedman_mse 1.0 500: Weighted 0.798434 (0.066136)\n",
      "0.01 3 6 3 sqrt friedman_mse 1.0 500: Macro 0.696819 (0.090063)\n",
      "Testing 757/5184\n",
      "0.01 3 6 3 sqrt mae 0.5 50: Weighted 0.802962 (0.050526)\n",
      "0.01 3 6 3 sqrt mae 0.5 50: Macro 0.685675 (0.072527)\n",
      "Testing 758/5184\n",
      "0.01 3 6 3 sqrt mae 0.5 100: Weighted 0.816342 (0.065890)\n",
      "0.01 3 6 3 sqrt mae 0.5 100: Macro 0.706986 (0.095943)\n",
      "Testing 759/5184\n",
      "0.01 3 6 3 sqrt mae 0.5 200: Weighted 0.820209 (0.054931)\n",
      "0.01 3 6 3 sqrt mae 0.5 200: Macro 0.708434 (0.081897)\n",
      "Testing 760/5184\n",
      "0.01 3 6 3 sqrt mae 0.5 500: Weighted 0.807206 (0.056855)\n",
      "0.01 3 6 3 sqrt mae 0.5 500: Macro 0.685418 (0.084642)\n",
      "Testing 761/5184\n",
      "0.01 3 6 3 sqrt mae 0.75 50: Weighted 0.807095 (0.057622)\n",
      "0.01 3 6 3 sqrt mae 0.75 50: Macro 0.692764 (0.083327)\n",
      "Testing 762/5184\n",
      "0.01 3 6 3 sqrt mae 0.75 100: Weighted 0.798096 (0.061890)\n",
      "0.01 3 6 3 sqrt mae 0.75 100: Macro 0.681371 (0.083516)\n",
      "Testing 763/5184\n",
      "0.01 3 6 3 sqrt mae 0.75 200: Weighted 0.787887 (0.073854)\n",
      "0.01 3 6 3 sqrt mae 0.75 200: Macro 0.665379 (0.101003)\n",
      "Testing 764/5184\n",
      "0.01 3 6 3 sqrt mae 0.75 500: Weighted 0.790564 (0.067191)\n",
      "0.01 3 6 3 sqrt mae 0.75 500: Macro 0.671916 (0.096950)\n",
      "Testing 765/5184\n",
      "0.01 3 6 3 sqrt mae 1.0 50: Weighted 0.789595 (0.061068)\n",
      "0.01 3 6 3 sqrt mae 1.0 50: Macro 0.675981 (0.078599)\n",
      "Testing 766/5184\n",
      "0.01 3 6 3 sqrt mae 1.0 100: Weighted 0.787116 (0.061981)\n",
      "0.01 3 6 3 sqrt mae 1.0 100: Macro 0.675042 (0.084522)\n",
      "Testing 767/5184\n",
      "0.01 3 6 3 sqrt mae 1.0 200: Weighted 0.788247 (0.055287)\n",
      "0.01 3 6 3 sqrt mae 1.0 200: Macro 0.671868 (0.078731)\n",
      "Testing 768/5184\n",
      "0.01 3 6 3 sqrt mae 1.0 500: Weighted 0.774253 (0.078580)\n",
      "0.01 3 6 3 sqrt mae 1.0 500: Macro 0.648190 (0.110358)\n",
      "Testing 769/5184\n",
      "0.01 3 6 5 log2 friedman_mse 0.5 50: Weighted 0.827504 (0.079715)\n",
      "0.01 3 6 5 log2 friedman_mse 0.5 50: Macro 0.727978 (0.115027)\n",
      "Testing 770/5184\n",
      "0.01 3 6 5 log2 friedman_mse 0.5 100: Weighted 0.813162 (0.047352)\n",
      "0.01 3 6 5 log2 friedman_mse 0.5 100: Macro 0.707474 (0.061880)\n",
      "Testing 771/5184\n",
      "0.01 3 6 5 log2 friedman_mse 0.5 200: Weighted 0.815154 (0.050215)\n",
      "0.01 3 6 5 log2 friedman_mse 0.5 200: Macro 0.703106 (0.072138)\n",
      "Testing 772/5184\n",
      "0.01 3 6 5 log2 friedman_mse 0.5 500: Weighted 0.818556 (0.069133)\n",
      "0.01 3 6 5 log2 friedman_mse 0.5 500: Macro 0.712861 (0.097919)\n",
      "Testing 773/5184\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01 3 6 5 log2 friedman_mse 0.75 50: Weighted 0.800498 (0.052218)\n",
      "0.01 3 6 5 log2 friedman_mse 0.75 50: Macro 0.690642 (0.079516)\n",
      "Testing 774/5184\n",
      "0.01 3 6 5 log2 friedman_mse 0.75 100: Weighted 0.792344 (0.053991)\n",
      "0.01 3 6 5 log2 friedman_mse 0.75 100: Macro 0.678342 (0.075777)\n",
      "Testing 775/5184\n",
      "0.01 3 6 5 log2 friedman_mse 0.75 200: Weighted 0.803860 (0.052152)\n",
      "0.01 3 6 5 log2 friedman_mse 0.75 200: Macro 0.696268 (0.061428)\n",
      "Testing 776/5184\n",
      "0.01 3 6 5 log2 friedman_mse 0.75 500: Weighted 0.804506 (0.088968)\n",
      "0.01 3 6 5 log2 friedman_mse 0.75 500: Macro 0.697776 (0.126233)\n",
      "Testing 777/5184\n",
      "0.01 3 6 5 log2 friedman_mse 1.0 50: Weighted 0.777451 (0.064308)\n",
      "0.01 3 6 5 log2 friedman_mse 1.0 50: Macro 0.659257 (0.088019)\n",
      "Testing 778/5184\n",
      "0.01 3 6 5 log2 friedman_mse 1.0 100: Weighted 0.777754 (0.055904)\n",
      "0.01 3 6 5 log2 friedman_mse 1.0 100: Macro 0.669410 (0.073077)\n",
      "Testing 779/5184\n",
      "0.01 3 6 5 log2 friedman_mse 1.0 200: Weighted 0.781653 (0.058826)\n",
      "0.01 3 6 5 log2 friedman_mse 1.0 200: Macro 0.670281 (0.079775)\n",
      "Testing 780/5184\n",
      "0.01 3 6 5 log2 friedman_mse 1.0 500: Weighted 0.800702 (0.081457)\n",
      "0.01 3 6 5 log2 friedman_mse 1.0 500: Macro 0.695739 (0.110827)\n",
      "Testing 781/5184\n",
      "0.01 3 6 5 log2 mae 0.5 50: Weighted 0.812471 (0.051359)\n",
      "0.01 3 6 5 log2 mae 0.5 50: Macro 0.699334 (0.071390)\n",
      "Testing 782/5184\n",
      "0.01 3 6 5 log2 mae 0.5 100: Weighted 0.799482 (0.064117)\n",
      "0.01 3 6 5 log2 mae 0.5 100: Macro 0.677646 (0.091520)\n",
      "Testing 783/5184\n",
      "0.01 3 6 5 log2 mae 0.5 200: Weighted 0.799482 (0.064117)\n",
      "0.01 3 6 5 log2 mae 0.5 200: Macro 0.677646 (0.091520)\n",
      "Testing 784/5184\n",
      "0.01 3 6 5 log2 mae 0.5 500: Weighted 0.795716 (0.066091)\n",
      "0.01 3 6 5 log2 mae 0.5 500: Macro 0.666731 (0.102067)\n",
      "Testing 785/5184\n",
      "0.01 3 6 5 log2 mae 0.75 50: Weighted 0.802193 (0.063030)\n",
      "0.01 3 6 5 log2 mae 0.75 50: Macro 0.683570 (0.086915)\n",
      "Testing 786/5184\n",
      "0.01 3 6 5 log2 mae 0.75 100: Weighted 0.795067 (0.069586)\n",
      "0.01 3 6 5 log2 mae 0.75 100: Macro 0.674380 (0.095469)\n",
      "Testing 787/5184\n",
      "0.01 3 6 5 log2 mae 0.75 200: Weighted 0.780042 (0.075125)\n",
      "0.01 3 6 5 log2 mae 0.75 200: Macro 0.651709 (0.104648)\n",
      "Testing 788/5184\n",
      "0.01 3 6 5 log2 mae 0.75 500: Weighted 0.775002 (0.075931)\n",
      "0.01 3 6 5 log2 mae 0.75 500: Macro 0.642309 (0.108881)\n",
      "Testing 789/5184\n",
      "0.01 3 6 5 log2 mae 1.0 50: Weighted 0.778816 (0.079103)\n",
      "0.01 3 6 5 log2 mae 1.0 50: Macro 0.652051 (0.109740)\n",
      "Testing 790/5184\n",
      "0.01 3 6 5 log2 mae 1.0 100: Weighted 0.777041 (0.066228)\n",
      "0.01 3 6 5 log2 mae 1.0 100: Macro 0.651214 (0.095914)\n",
      "Testing 791/5184\n",
      "0.01 3 6 5 log2 mae 1.0 200: Weighted 0.769985 (0.067531)\n",
      "0.01 3 6 5 log2 mae 1.0 200: Macro 0.643133 (0.097008)\n",
      "Testing 792/5184\n",
      "0.01 3 6 5 log2 mae 1.0 500: Weighted 0.761050 (0.076190)\n",
      "0.01 3 6 5 log2 mae 1.0 500: Macro 0.628819 (0.110502)\n",
      "Testing 793/5184\n",
      "0.01 3 6 5 sqrt friedman_mse 0.5 50: Weighted 0.823518 (0.049095)\n",
      "0.01 3 6 5 sqrt friedman_mse 0.5 50: Macro 0.719409 (0.068014)\n",
      "Testing 794/5184\n",
      "0.01 3 6 5 sqrt friedman_mse 0.5 100: Weighted 0.817811 (0.053122)\n",
      "0.01 3 6 5 sqrt friedman_mse 0.5 100: Macro 0.708177 (0.079543)\n",
      "Testing 795/5184\n",
      "0.01 3 6 5 sqrt friedman_mse 0.5 200: Weighted 0.811944 (0.050553)\n",
      "0.01 3 6 5 sqrt friedman_mse 0.5 200: Macro 0.703631 (0.067024)\n",
      "Testing 796/5184\n",
      "0.01 3 6 5 sqrt friedman_mse 0.5 500: Weighted 0.818832 (0.078423)\n",
      "0.01 3 6 5 sqrt friedman_mse 0.5 500: Macro 0.708582 (0.115772)\n",
      "Testing 797/5184\n",
      "0.01 3 6 5 sqrt friedman_mse 0.75 50: Weighted 0.806634 (0.066377)\n",
      "0.01 3 6 5 sqrt friedman_mse 0.75 50: Macro 0.694724 (0.089089)\n",
      "Testing 798/5184\n",
      "0.01 3 6 5 sqrt friedman_mse 0.75 100: Weighted 0.800823 (0.060435)\n",
      "0.01 3 6 5 sqrt friedman_mse 0.75 100: Macro 0.690703 (0.082523)\n",
      "Testing 799/5184\n",
      "0.01 3 6 5 sqrt friedman_mse 0.75 200: Weighted 0.805548 (0.051801)\n",
      "0.01 3 6 5 sqrt friedman_mse 0.75 200: Macro 0.699445 (0.069320)\n",
      "Testing 800/5184\n",
      "0.01 3 6 5 sqrt friedman_mse 0.75 500: Weighted 0.804324 (0.084451)\n",
      "0.01 3 6 5 sqrt friedman_mse 0.75 500: Macro 0.698116 (0.117803)\n",
      "Testing 801/5184\n",
      "0.01 3 6 5 sqrt friedman_mse 1.0 50: Weighted 0.787502 (0.066998)\n",
      "0.01 3 6 5 sqrt friedman_mse 1.0 50: Macro 0.680141 (0.090043)\n",
      "Testing 802/5184\n",
      "0.01 3 6 5 sqrt friedman_mse 1.0 100: Weighted 0.784710 (0.063821)\n",
      "0.01 3 6 5 sqrt friedman_mse 1.0 100: Macro 0.674449 (0.079738)\n",
      "Testing 803/5184\n",
      "0.01 3 6 5 sqrt friedman_mse 1.0 200: Weighted 0.788746 (0.066870)\n",
      "0.01 3 6 5 sqrt friedman_mse 1.0 200: Macro 0.681420 (0.083805)\n",
      "Testing 804/5184\n",
      "0.01 3 6 5 sqrt friedman_mse 1.0 500: Weighted 0.813921 (0.086021)\n",
      "0.01 3 6 5 sqrt friedman_mse 1.0 500: Macro 0.716123 (0.120189)\n",
      "Testing 805/5184\n",
      "0.01 3 6 5 sqrt mae 0.5 50: Weighted 0.806030 (0.058006)\n",
      "0.01 3 6 5 sqrt mae 0.5 50: Macro 0.692122 (0.080902)\n",
      "Testing 806/5184\n",
      "0.01 3 6 5 sqrt mae 0.5 100: Weighted 0.812011 (0.054451)\n",
      "0.01 3 6 5 sqrt mae 0.5 100: Macro 0.696267 (0.079849)\n",
      "Testing 807/5184\n",
      "0.01 3 6 5 sqrt mae 0.5 200: Weighted 0.804097 (0.061643)\n",
      "0.01 3 6 5 sqrt mae 0.5 200: Macro 0.688007 (0.086013)\n",
      "Testing 808/5184\n",
      "0.01 3 6 5 sqrt mae 0.5 500: Weighted 0.795384 (0.056109)\n",
      "0.01 3 6 5 sqrt mae 0.5 500: Macro 0.671127 (0.080651)\n",
      "Testing 809/5184\n",
      "0.01 3 6 5 sqrt mae 0.75 50: Weighted 0.792211 (0.067882)\n",
      "0.01 3 6 5 sqrt mae 0.75 50: Macro 0.672239 (0.091044)\n",
      "Testing 810/5184\n",
      "0.01 3 6 5 sqrt mae 0.75 100: Weighted 0.800189 (0.069756)\n",
      "0.01 3 6 5 sqrt mae 0.75 100: Macro 0.681749 (0.097692)\n",
      "Testing 811/5184\n",
      "0.01 3 6 5 sqrt mae 0.75 200: Weighted 0.790674 (0.072755)\n",
      "0.01 3 6 5 sqrt mae 0.75 200: Macro 0.669556 (0.098917)\n",
      "Testing 812/5184\n",
      "0.01 3 6 5 sqrt mae 0.75 500: Weighted 0.767073 (0.083797)\n",
      "0.01 3 6 5 sqrt mae 0.75 500: Macro 0.633433 (0.117676)\n",
      "Testing 813/5184\n",
      "0.01 3 6 5 sqrt mae 1.0 50: Weighted 0.782133 (0.058608)\n",
      "0.01 3 6 5 sqrt mae 1.0 50: Macro 0.662814 (0.082361)\n",
      "Testing 814/5184\n",
      "0.01 3 6 5 sqrt mae 1.0 100: Weighted 0.778365 (0.070984)\n",
      "0.01 3 6 5 sqrt mae 1.0 100: Macro 0.653704 (0.102855)\n",
      "Testing 815/5184\n",
      "0.01 3 6 5 sqrt mae 1.0 200: Weighted 0.773579 (0.065224)\n",
      "0.01 3 6 5 sqrt mae 1.0 200: Macro 0.646604 (0.094301)\n",
      "Testing 816/5184\n",
      "0.01 3 6 5 sqrt mae 1.0 500: Weighted 0.766978 (0.070389)\n",
      "0.01 3 6 5 sqrt mae 1.0 500: Macro 0.636501 (0.102895)\n",
      "Testing 817/5184\n",
      "0.01 3 6 8 log2 friedman_mse 0.5 50: Weighted 0.805660 (0.056953)\n",
      "0.01 3 6 8 log2 friedman_mse 0.5 50: Macro 0.695640 (0.080735)\n",
      "Testing 818/5184\n",
      "0.01 3 6 8 log2 friedman_mse 0.5 100: Weighted 0.808849 (0.062730)\n",
      "0.01 3 6 8 log2 friedman_mse 0.5 100: Macro 0.704752 (0.089689)\n",
      "Testing 819/5184\n",
      "0.01 3 6 8 log2 friedman_mse 0.5 200: Weighted 0.817461 (0.041287)\n",
      "0.01 3 6 8 log2 friedman_mse 0.5 200: Macro 0.705361 (0.063672)\n",
      "Testing 820/5184\n",
      "0.01 3 6 8 log2 friedman_mse 0.5 500: Weighted 0.826096 (0.076623)\n",
      "0.01 3 6 8 log2 friedman_mse 0.5 500: Macro 0.718916 (0.113910)\n",
      "Testing 821/5184\n",
      "0.01 3 6 8 log2 friedman_mse 0.75 50: Weighted 0.797479 (0.059161)\n",
      "0.01 3 6 8 log2 friedman_mse 0.75 50: Macro 0.684237 (0.084196)\n",
      "Testing 822/5184\n",
      "0.01 3 6 8 log2 friedman_mse 0.75 100: Weighted 0.794021 (0.057662)\n",
      "0.01 3 6 8 log2 friedman_mse 0.75 100: Macro 0.675397 (0.077038)\n",
      "Testing 823/5184\n",
      "0.01 3 6 8 log2 friedman_mse 0.75 200: Weighted 0.800440 (0.057849)\n",
      "0.01 3 6 8 log2 friedman_mse 0.75 200: Macro 0.695978 (0.076410)\n",
      "Testing 824/5184\n",
      "0.01 3 6 8 log2 friedman_mse 0.75 500: Weighted 0.811295 (0.088535)\n",
      "0.01 3 6 8 log2 friedman_mse 0.75 500: Macro 0.710390 (0.124264)\n",
      "Testing 825/5184\n",
      "0.01 3 6 8 log2 friedman_mse 1.0 50: Weighted 0.780981 (0.065760)\n",
      "0.01 3 6 8 log2 friedman_mse 1.0 50: Macro 0.660285 (0.092965)\n",
      "Testing 826/5184\n",
      "0.01 3 6 8 log2 friedman_mse 1.0 100: Weighted 0.784955 (0.068760)\n",
      "0.01 3 6 8 log2 friedman_mse 1.0 100: Macro 0.670566 (0.090693)\n",
      "Testing 827/5184\n",
      "0.01 3 6 8 log2 friedman_mse 1.0 200: Weighted 0.791911 (0.073992)\n",
      "0.01 3 6 8 log2 friedman_mse 1.0 200: Macro 0.682408 (0.097679)\n",
      "Testing 828/5184\n",
      "0.01 3 6 8 log2 friedman_mse 1.0 500: Weighted 0.788793 (0.074939)\n",
      "0.01 3 6 8 log2 friedman_mse 1.0 500: Macro 0.674688 (0.106879)\n",
      "Testing 829/5184\n",
      "0.01 3 6 8 log2 mae 0.5 50: Weighted 0.811787 (0.058807)\n",
      "0.01 3 6 8 log2 mae 0.5 50: Macro 0.693485 (0.089214)\n",
      "Testing 830/5184\n",
      "0.01 3 6 8 log2 mae 0.5 100: Weighted 0.802275 (0.060545)\n",
      "0.01 3 6 8 log2 mae 0.5 100: Macro 0.682140 (0.086310)\n",
      "Testing 831/5184\n",
      "0.01 3 6 8 log2 mae 0.5 200: Weighted 0.807960 (0.056748)\n",
      "0.01 3 6 8 log2 mae 0.5 200: Macro 0.692793 (0.079579)\n",
      "Testing 832/5184\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01 3 6 8 log2 mae 0.5 500: Weighted 0.794407 (0.074862)\n",
      "0.01 3 6 8 log2 mae 0.5 500: Macro 0.670616 (0.109113)\n",
      "Testing 833/5184\n",
      "0.01 3 6 8 log2 mae 0.75 50: Weighted 0.782425 (0.068534)\n",
      "0.01 3 6 8 log2 mae 0.75 50: Macro 0.651306 (0.100088)\n",
      "Testing 834/5184\n",
      "0.01 3 6 8 log2 mae 0.75 100: Weighted 0.807858 (0.044689)\n",
      "0.01 3 6 8 log2 mae 0.75 100: Macro 0.688951 (0.064133)\n",
      "Testing 835/5184\n",
      "0.01 3 6 8 log2 mae 0.75 200: Weighted 0.775924 (0.075176)\n",
      "0.01 3 6 8 log2 mae 0.75 200: Macro 0.640641 (0.110533)\n",
      "Testing 836/5184\n",
      "0.01 3 6 8 log2 mae 0.75 500: Weighted 0.776060 (0.085921)\n",
      "0.01 3 6 8 log2 mae 0.75 500: Macro 0.643477 (0.123702)\n",
      "Testing 837/5184\n",
      "0.01 3 6 8 log2 mae 1.0 50: Weighted 0.772415 (0.068466)\n",
      "0.01 3 6 8 log2 mae 1.0 50: Macro 0.640530 (0.103482)\n",
      "Testing 838/5184\n",
      "0.01 3 6 8 log2 mae 1.0 100: Weighted 0.772703 (0.081218)\n",
      "0.01 3 6 8 log2 mae 1.0 100: Macro 0.641049 (0.114916)\n",
      "Testing 839/5184\n",
      "0.01 3 6 8 log2 mae 1.0 200: Weighted 0.762353 (0.066422)\n",
      "0.01 3 6 8 log2 mae 1.0 200: Macro 0.630384 (0.096864)\n",
      "Testing 840/5184\n",
      "0.01 3 6 8 log2 mae 1.0 500: Weighted 0.775310 (0.092355)\n",
      "0.01 3 6 8 log2 mae 1.0 500: Macro 0.644846 (0.127875)\n",
      "Testing 841/5184\n",
      "0.01 3 6 8 sqrt friedman_mse 0.5 50: Weighted 0.808599 (0.051168)\n",
      "0.01 3 6 8 sqrt friedman_mse 0.5 50: Macro 0.707351 (0.068452)\n",
      "Testing 842/5184\n",
      "0.01 3 6 8 sqrt friedman_mse 0.5 100: Weighted 0.809044 (0.059900)\n",
      "0.01 3 6 8 sqrt friedman_mse 0.5 100: Macro 0.704075 (0.084944)\n",
      "Testing 843/5184\n",
      "0.01 3 6 8 sqrt friedman_mse 0.5 200: Weighted 0.821693 (0.050338)\n",
      "0.01 3 6 8 sqrt friedman_mse 0.5 200: Macro 0.722622 (0.064964)\n",
      "Testing 844/5184\n",
      "0.01 3 6 8 sqrt friedman_mse 0.5 500: Weighted 0.819716 (0.081663)\n",
      "0.01 3 6 8 sqrt friedman_mse 0.5 500: Macro 0.719105 (0.118476)\n",
      "Testing 845/5184\n",
      "0.01 3 6 8 sqrt friedman_mse 0.75 50: Weighted 0.796126 (0.058656)\n",
      "0.01 3 6 8 sqrt friedman_mse 0.75 50: Macro 0.688170 (0.074573)\n",
      "Testing 846/5184\n",
      "0.01 3 6 8 sqrt friedman_mse 0.75 100: Weighted 0.793893 (0.059139)\n",
      "0.01 3 6 8 sqrt friedman_mse 0.75 100: Macro 0.685733 (0.076823)\n",
      "Testing 847/5184\n",
      "0.01 3 6 8 sqrt friedman_mse 0.75 200: Weighted 0.806511 (0.058046)\n",
      "0.01 3 6 8 sqrt friedman_mse 0.75 200: Macro 0.701293 (0.078765)\n",
      "Testing 848/5184\n",
      "0.01 3 6 8 sqrt friedman_mse 0.75 500: Weighted 0.815270 (0.084964)\n",
      "0.01 3 6 8 sqrt friedman_mse 0.75 500: Macro 0.715817 (0.120973)\n",
      "Testing 849/5184\n",
      "0.01 3 6 8 sqrt friedman_mse 1.0 50: Weighted 0.783637 (0.058239)\n",
      "0.01 3 6 8 sqrt friedman_mse 1.0 50: Macro 0.668505 (0.079456)\n",
      "Testing 850/5184\n",
      "0.01 3 6 8 sqrt friedman_mse 1.0 100: Weighted 0.787477 (0.067544)\n",
      "0.01 3 6 8 sqrt friedman_mse 1.0 100: Macro 0.675395 (0.087158)\n",
      "Testing 851/5184\n",
      "0.01 3 6 8 sqrt friedman_mse 1.0 200: Weighted 0.795660 (0.070185)\n",
      "0.01 3 6 8 sqrt friedman_mse 1.0 200: Macro 0.686067 (0.093771)\n",
      "Testing 852/5184\n",
      "0.01 3 6 8 sqrt friedman_mse 1.0 500: Weighted 0.786419 (0.084335)\n",
      "0.01 3 6 8 sqrt friedman_mse 1.0 500: Macro 0.676834 (0.117518)\n",
      "Testing 853/5184\n",
      "0.01 3 6 8 sqrt mae 0.5 50: Weighted 0.808462 (0.061278)\n",
      "0.01 3 6 8 sqrt mae 0.5 50: Macro 0.689015 (0.092529)\n",
      "Testing 854/5184\n",
      "0.01 3 6 8 sqrt mae 0.5 100: Weighted 0.816541 (0.061065)\n",
      "0.01 3 6 8 sqrt mae 0.5 100: Macro 0.700690 (0.091833)\n",
      "Testing 855/5184\n",
      "0.01 3 6 8 sqrt mae 0.5 200: Weighted 0.799904 (0.062519)\n",
      "0.01 3 6 8 sqrt mae 0.5 200: Macro 0.677938 (0.089872)\n",
      "Testing 856/5184\n",
      "0.01 3 6 8 sqrt mae 0.5 500: Weighted 0.797572 (0.075444)\n",
      "0.01 3 6 8 sqrt mae 0.5 500: Macro 0.673570 (0.111714)\n",
      "Testing 857/5184\n",
      "0.01 3 6 8 sqrt mae 0.75 50: Weighted 0.796539 (0.065092)\n",
      "0.01 3 6 8 sqrt mae 0.75 50: Macro 0.678957 (0.092712)\n",
      "Testing 858/5184\n",
      "0.01 3 6 8 sqrt mae 0.75 100: Weighted 0.787361 (0.071773)\n",
      "0.01 3 6 8 sqrt mae 0.75 100: Macro 0.652646 (0.111485)\n",
      "Testing 859/5184\n",
      "0.01 3 6 8 sqrt mae 0.75 200: Weighted 0.801394 (0.061892)\n",
      "0.01 3 6 8 sqrt mae 0.75 200: Macro 0.682260 (0.086267)\n",
      "Testing 860/5184\n",
      "0.01 3 6 8 sqrt mae 0.75 500: Weighted 0.781282 (0.083189)\n",
      "0.01 3 6 8 sqrt mae 0.75 500: Macro 0.651245 (0.123235)\n",
      "Testing 861/5184\n",
      "0.01 3 6 8 sqrt mae 1.0 50: Weighted 0.762371 (0.066253)\n",
      "0.01 3 6 8 sqrt mae 1.0 50: Macro 0.637829 (0.089351)\n",
      "Testing 862/5184\n",
      "0.01 3 6 8 sqrt mae 1.0 100: Weighted 0.755925 (0.065944)\n",
      "0.01 3 6 8 sqrt mae 1.0 100: Macro 0.625994 (0.093034)\n",
      "Testing 863/5184\n",
      "0.01 3 6 8 sqrt mae 1.0 200: Weighted 0.777162 (0.066525)\n",
      "0.01 3 6 8 sqrt mae 1.0 200: Macro 0.642987 (0.096846)\n",
      "Testing 864/5184\n",
      "0.01 3 6 8 sqrt mae 1.0 500: Weighted 0.767488 (0.089060)\n",
      "0.01 3 6 8 sqrt mae 1.0 500: Macro 0.641386 (0.123582)\n",
      "Testing 865/5184\n",
      "0.01 5 2 3 log2 friedman_mse 0.5 50: Weighted 0.819579 (0.047553)\n",
      "0.01 5 2 3 log2 friedman_mse 0.5 50: Macro 0.711669 (0.065469)\n",
      "Testing 866/5184\n",
      "0.01 5 2 3 log2 friedman_mse 0.5 100: Weighted 0.827792 (0.047725)\n",
      "0.01 5 2 3 log2 friedman_mse 0.5 100: Macro 0.724039 (0.067051)\n",
      "Testing 867/5184\n",
      "0.01 5 2 3 log2 friedman_mse 0.5 200: Weighted 0.815509 (0.049299)\n",
      "0.01 5 2 3 log2 friedman_mse 0.5 200: Macro 0.702547 (0.075129)\n",
      "Testing 868/5184\n",
      "0.01 5 2 3 log2 friedman_mse 0.5 500: Weighted 0.819681 (0.068752)\n",
      "0.01 5 2 3 log2 friedman_mse 0.5 500: Macro 0.717745 (0.092284)\n",
      "Testing 869/5184\n",
      "0.01 5 2 3 log2 friedman_mse 0.75 50: Weighted 0.820081 (0.055117)\n",
      "0.01 5 2 3 log2 friedman_mse 0.75 50: Macro 0.714542 (0.072685)\n",
      "Testing 870/5184\n",
      "0.01 5 2 3 log2 friedman_mse 0.75 100: Weighted 0.811215 (0.068096)\n",
      "0.01 5 2 3 log2 friedman_mse 0.75 100: Macro 0.702791 (0.092636)\n",
      "Testing 871/5184\n",
      "0.01 5 2 3 log2 friedman_mse 0.75 200: Weighted 0.806876 (0.063184)\n",
      "0.01 5 2 3 log2 friedman_mse 0.75 200: Macro 0.695055 (0.085097)\n",
      "Testing 872/5184\n",
      "0.01 5 2 3 log2 friedman_mse 0.75 500: Weighted 0.819915 (0.072088)\n",
      "0.01 5 2 3 log2 friedman_mse 0.75 500: Macro 0.718850 (0.094310)\n",
      "Testing 873/5184\n",
      "0.01 5 2 3 log2 friedman_mse 1.0 50: Weighted 0.807415 (0.074420)\n",
      "0.01 5 2 3 log2 friedman_mse 1.0 50: Macro 0.697028 (0.099827)\n",
      "Testing 874/5184\n",
      "0.01 5 2 3 log2 friedman_mse 1.0 100: Weighted 0.803857 (0.061958)\n",
      "0.01 5 2 3 log2 friedman_mse 1.0 100: Macro 0.694051 (0.077946)\n",
      "Testing 875/5184\n",
      "0.01 5 2 3 log2 friedman_mse 1.0 200: Weighted 0.805434 (0.055666)\n",
      "0.01 5 2 3 log2 friedman_mse 1.0 200: Macro 0.697443 (0.066027)\n",
      "Testing 876/5184\n",
      "0.01 5 2 3 log2 friedman_mse 1.0 500: Weighted 0.799214 (0.079618)\n",
      "0.01 5 2 3 log2 friedman_mse 1.0 500: Macro 0.697978 (0.100961)\n",
      "Testing 877/5184\n",
      "0.01 5 2 3 log2 mae 0.5 50: Weighted 0.811429 (0.059028)\n",
      "0.01 5 2 3 log2 mae 0.5 50: Macro 0.703968 (0.079978)\n",
      "Testing 878/5184\n",
      "0.01 5 2 3 log2 mae 0.5 100: Weighted 0.821452 (0.058967)\n",
      "0.01 5 2 3 log2 mae 0.5 100: Macro 0.710767 (0.088146)\n",
      "Testing 879/5184\n",
      "0.01 5 2 3 log2 mae 0.5 200: Weighted 0.828706 (0.043428)\n",
      "0.01 5 2 3 log2 mae 0.5 200: Macro 0.723249 (0.060337)\n",
      "Testing 880/5184\n",
      "0.01 5 2 3 log2 mae 0.5 500: Weighted 0.817936 (0.061038)\n",
      "0.01 5 2 3 log2 mae 0.5 500: Macro 0.705809 (0.090478)\n",
      "Testing 881/5184\n",
      "0.01 5 2 3 log2 mae 0.75 50: Weighted 0.802855 (0.055420)\n",
      "0.01 5 2 3 log2 mae 0.75 50: Macro 0.691787 (0.075939)\n",
      "Testing 882/5184\n",
      "0.01 5 2 3 log2 mae 0.75 100: Weighted 0.799278 (0.069641)\n",
      "0.01 5 2 3 log2 mae 0.75 100: Macro 0.686116 (0.093767)\n",
      "Testing 883/5184\n",
      "0.01 5 2 3 log2 mae 0.75 200: Weighted 0.804339 (0.058201)\n",
      "0.01 5 2 3 log2 mae 0.75 200: Macro 0.688339 (0.081899)\n",
      "Testing 884/5184\n",
      "0.01 5 2 3 log2 mae 0.75 500: Weighted 0.800819 (0.071532)\n",
      "0.01 5 2 3 log2 mae 0.75 500: Macro 0.686936 (0.096555)\n",
      "Testing 885/5184\n",
      "0.01 5 2 3 log2 mae 1.0 50: Weighted 0.785953 (0.065563)\n",
      "0.01 5 2 3 log2 mae 1.0 50: Macro 0.666811 (0.086414)\n",
      "Testing 886/5184\n",
      "0.01 5 2 3 log2 mae 1.0 100: Weighted 0.787351 (0.074725)\n",
      "0.01 5 2 3 log2 mae 1.0 100: Macro 0.671263 (0.098701)\n",
      "Testing 887/5184\n",
      "0.01 5 2 3 log2 mae 1.0 200: Weighted 0.787887 (0.073854)\n",
      "0.01 5 2 3 log2 mae 1.0 200: Macro 0.665379 (0.101003)\n",
      "Testing 888/5184\n",
      "0.01 5 2 3 log2 mae 1.0 500: Weighted 0.792765 (0.088121)\n",
      "0.01 5 2 3 log2 mae 1.0 500: Macro 0.670898 (0.128130)\n",
      "Testing 889/5184\n",
      "0.01 5 2 3 sqrt friedman_mse 0.5 50: Weighted 0.819131 (0.048132)\n",
      "0.01 5 2 3 sqrt friedman_mse 0.5 50: Macro 0.707001 (0.072111)\n",
      "Testing 890/5184\n",
      "0.01 5 2 3 sqrt friedman_mse 0.5 100: Weighted 0.819900 (0.055039)\n",
      "0.01 5 2 3 sqrt friedman_mse 0.5 100: Macro 0.715467 (0.073167)\n",
      "Testing 891/5184\n",
      "0.01 5 2 3 sqrt friedman_mse 0.5 200: Weighted 0.824584 (0.048793)\n",
      "0.01 5 2 3 sqrt friedman_mse 0.5 200: Macro 0.717955 (0.067713)\n",
      "Testing 892/5184\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01 5 2 3 sqrt friedman_mse 0.5 500: Weighted 0.824686 (0.069608)\n",
      "0.01 5 2 3 sqrt friedman_mse 0.5 500: Macro 0.724031 (0.093481)\n",
      "Testing 893/5184\n",
      "0.01 5 2 3 sqrt friedman_mse 0.75 50: Weighted 0.815571 (0.061789)\n",
      "0.01 5 2 3 sqrt friedman_mse 0.75 50: Macro 0.711176 (0.077719)\n",
      "Testing 894/5184\n",
      "0.01 5 2 3 sqrt friedman_mse 0.75 100: Weighted 0.807130 (0.060671)\n",
      "0.01 5 2 3 sqrt friedman_mse 0.75 100: Macro 0.699865 (0.076278)\n",
      "Testing 895/5184\n",
      "0.01 5 2 3 sqrt friedman_mse 0.75 200: Weighted 0.806876 (0.063184)\n",
      "0.01 5 2 3 sqrt friedman_mse 0.75 200: Macro 0.695055 (0.085097)\n",
      "Testing 896/5184\n",
      "0.01 5 2 3 sqrt friedman_mse 0.75 500: Weighted 0.818095 (0.074549)\n",
      "0.01 5 2 3 sqrt friedman_mse 0.75 500: Macro 0.718826 (0.094341)\n",
      "Testing 897/5184\n",
      "0.01 5 2 3 sqrt friedman_mse 1.0 50: Weighted 0.808438 (0.063995)\n",
      "0.01 5 2 3 sqrt friedman_mse 1.0 50: Macro 0.702118 (0.082044)\n",
      "Testing 898/5184\n",
      "0.01 5 2 3 sqrt friedman_mse 1.0 100: Weighted 0.795814 (0.068989)\n",
      "0.01 5 2 3 sqrt friedman_mse 1.0 100: Macro 0.680650 (0.092920)\n",
      "Testing 899/5184\n",
      "0.01 5 2 3 sqrt friedman_mse 1.0 200: Weighted 0.798974 (0.065903)\n",
      "0.01 5 2 3 sqrt friedman_mse 1.0 200: Macro 0.685194 (0.086513)\n",
      "Testing 900/5184\n",
      "0.01 5 2 3 sqrt friedman_mse 1.0 500: Weighted 0.803876 (0.077629)\n",
      "0.01 5 2 3 sqrt friedman_mse 1.0 500: Macro 0.703028 (0.098210)\n",
      "Testing 901/5184\n",
      "0.01 5 2 3 sqrt mae 0.5 50: Weighted 0.815938 (0.054236)\n",
      "0.01 5 2 3 sqrt mae 0.5 50: Macro 0.708465 (0.072570)\n",
      "Testing 902/5184\n",
      "0.01 5 2 3 sqrt mae 0.5 100: Weighted 0.813463 (0.055870)\n",
      "0.01 5 2 3 sqrt mae 0.5 100: Macro 0.703098 (0.078041)\n",
      "Testing 903/5184\n",
      "0.01 5 2 3 sqrt mae 0.5 200: Weighted 0.824934 (0.057429)\n",
      "0.01 5 2 3 sqrt mae 0.5 200: Macro 0.719892 (0.080356)\n",
      "Testing 904/5184\n",
      "0.01 5 2 3 sqrt mae 0.5 500: Weighted 0.813406 (0.066698)\n",
      "0.01 5 2 3 sqrt mae 0.5 500: Macro 0.703485 (0.095850)\n",
      "Testing 905/5184\n",
      "0.01 5 2 3 sqrt mae 0.75 50: Weighted 0.806698 (0.053256)\n",
      "0.01 5 2 3 sqrt mae 0.75 50: Macro 0.692999 (0.074758)\n",
      "Testing 906/5184\n",
      "0.01 5 2 3 sqrt mae 0.75 100: Weighted 0.802474 (0.060310)\n",
      "0.01 5 2 3 sqrt mae 0.75 100: Macro 0.686261 (0.083878)\n",
      "Testing 907/5184\n",
      "0.01 5 2 3 sqrt mae 0.75 200: Weighted 0.795943 (0.070426)\n",
      "0.01 5 2 3 sqrt mae 0.75 200: Macro 0.680234 (0.093972)\n",
      "Testing 908/5184\n",
      "0.01 5 2 3 sqrt mae 0.75 500: Weighted 0.799224 (0.070866)\n",
      "0.01 5 2 3 sqrt mae 0.75 500: Macro 0.681489 (0.097976)\n",
      "Testing 909/5184\n",
      "0.01 5 2 3 sqrt mae 1.0 50: Weighted 0.795326 (0.067021)\n",
      "0.01 5 2 3 sqrt mae 1.0 50: Macro 0.683467 (0.089413)\n",
      "Testing 910/5184\n",
      "0.01 5 2 3 sqrt mae 1.0 100: Weighted 0.792318 (0.071653)\n",
      "0.01 5 2 3 sqrt mae 1.0 100: Macro 0.675285 (0.095605)\n",
      "Testing 911/5184\n",
      "0.01 5 2 3 sqrt mae 1.0 200: Weighted 0.787887 (0.073854)\n",
      "0.01 5 2 3 sqrt mae 1.0 200: Macro 0.665379 (0.101003)\n",
      "Testing 912/5184\n",
      "0.01 5 2 3 sqrt mae 1.0 500: Weighted 0.788075 (0.090985)\n",
      "0.01 5 2 3 sqrt mae 1.0 500: Macro 0.660072 (0.135536)\n",
      "Testing 913/5184\n",
      "0.01 5 2 5 log2 friedman_mse 0.5 50: Weighted 0.818501 (0.052018)\n",
      "0.01 5 2 5 log2 friedman_mse 0.5 50: Macro 0.715152 (0.069707)\n",
      "Testing 914/5184\n",
      "0.01 5 2 5 log2 friedman_mse 0.5 100: Weighted 0.827346 (0.048375)\n",
      "0.01 5 2 5 log2 friedman_mse 0.5 100: Macro 0.725851 (0.064276)\n",
      "Testing 915/5184\n",
      "0.01 5 2 5 log2 friedman_mse 0.5 200: Weighted 0.814194 (0.059682)\n",
      "0.01 5 2 5 log2 friedman_mse 0.5 200: Macro 0.704005 (0.084637)\n",
      "Testing 916/5184\n",
      "0.01 5 2 5 log2 friedman_mse 0.5 500: Weighted 0.818723 (0.072351)\n",
      "0.01 5 2 5 log2 friedman_mse 0.5 500: Macro 0.713562 (0.103287)\n",
      "Testing 917/5184\n",
      "0.01 5 2 5 log2 friedman_mse 0.75 50: Weighted 0.808997 (0.066415)\n",
      "0.01 5 2 5 log2 friedman_mse 0.75 50: Macro 0.701609 (0.090024)\n",
      "Testing 918/5184\n",
      "0.01 5 2 5 log2 friedman_mse 0.75 100: Weighted 0.800985 (0.060762)\n",
      "0.01 5 2 5 log2 friedman_mse 0.75 100: Macro 0.689298 (0.081630)\n",
      "Testing 919/5184\n",
      "0.01 5 2 5 log2 friedman_mse 0.75 200: Weighted 0.801797 (0.061689)\n",
      "0.01 5 2 5 log2 friedman_mse 0.75 200: Macro 0.690854 (0.087240)\n",
      "Testing 920/5184\n",
      "0.01 5 2 5 log2 friedman_mse 0.75 500: Weighted 0.811490 (0.083204)\n",
      "0.01 5 2 5 log2 friedman_mse 0.75 500: Macro 0.705674 (0.119565)\n",
      "Testing 921/5184\n",
      "0.01 5 2 5 log2 friedman_mse 1.0 50: Weighted 0.805505 (0.066346)\n",
      "0.01 5 2 5 log2 friedman_mse 1.0 50: Macro 0.696109 (0.089377)\n",
      "Testing 922/5184\n",
      "0.01 5 2 5 log2 friedman_mse 1.0 100: Weighted 0.795825 (0.065642)\n",
      "0.01 5 2 5 log2 friedman_mse 1.0 100: Macro 0.685219 (0.088022)\n",
      "Testing 923/5184\n",
      "0.01 5 2 5 log2 friedman_mse 1.0 200: Weighted 0.794723 (0.058819)\n",
      "0.01 5 2 5 log2 friedman_mse 1.0 200: Macro 0.685331 (0.076970)\n",
      "Testing 924/5184\n",
      "0.01 5 2 5 log2 friedman_mse 1.0 500: Weighted 0.812878 (0.086967)\n",
      "0.01 5 2 5 log2 friedman_mse 1.0 500: Macro 0.716340 (0.120179)\n",
      "Testing 925/5184\n",
      "0.01 5 2 5 log2 mae 0.5 50: Weighted 0.812374 (0.062307)\n",
      "0.01 5 2 5 log2 mae 0.5 50: Macro 0.700108 (0.087946)\n",
      "Testing 926/5184\n",
      "0.01 5 2 5 log2 mae 0.5 100: Weighted 0.829948 (0.048214)\n",
      "0.01 5 2 5 log2 mae 0.5 100: Macro 0.725582 (0.068074)\n",
      "Testing 927/5184\n",
      "0.01 5 2 5 log2 mae 0.5 200: Weighted 0.821862 (0.056274)\n",
      "0.01 5 2 5 log2 mae 0.5 200: Macro 0.710662 (0.084037)\n",
      "Testing 928/5184\n",
      "0.01 5 2 5 log2 mae 0.5 500: Weighted 0.809105 (0.078320)\n",
      "0.01 5 2 5 log2 mae 0.5 500: Macro 0.694350 (0.113166)\n",
      "Testing 929/5184\n",
      "0.01 5 2 5 log2 mae 0.75 50: Weighted 0.796709 (0.066025)\n",
      "0.01 5 2 5 log2 mae 0.75 50: Macro 0.678069 (0.091233)\n",
      "Testing 930/5184\n",
      "0.01 5 2 5 log2 mae 0.75 100: Weighted 0.796388 (0.074246)\n",
      "0.01 5 2 5 log2 mae 0.75 100: Macro 0.677030 (0.103029)\n",
      "Testing 931/5184\n",
      "0.01 5 2 5 log2 mae 0.75 200: Weighted 0.799482 (0.064117)\n",
      "0.01 5 2 5 log2 mae 0.75 200: Macro 0.677646 (0.091520)\n",
      "Testing 932/5184\n",
      "0.01 5 2 5 log2 mae 0.75 500: Weighted 0.778204 (0.073148)\n",
      "0.01 5 2 5 log2 mae 0.75 500: Macro 0.642270 (0.109106)\n",
      "Testing 933/5184\n",
      "0.01 5 2 5 log2 mae 1.0 50: Weighted 0.798392 (0.068077)\n",
      "0.01 5 2 5 log2 mae 1.0 50: Macro 0.678851 (0.092966)\n",
      "Testing 934/5184\n",
      "0.01 5 2 5 log2 mae 1.0 100: Weighted 0.790150 (0.072600)\n",
      "0.01 5 2 5 log2 mae 1.0 100: Macro 0.662978 (0.104213)\n",
      "Testing 935/5184\n",
      "0.01 5 2 5 log2 mae 1.0 200: Weighted 0.786095 (0.075948)\n",
      "0.01 5 2 5 log2 mae 1.0 200: Macro 0.653105 (0.113881)\n",
      "Testing 936/5184\n",
      "0.01 5 2 5 log2 mae 1.0 500: Weighted 0.780966 (0.096402)\n",
      "0.01 5 2 5 log2 mae 1.0 500: Macro 0.654599 (0.137752)\n",
      "Testing 937/5184\n",
      "0.01 5 2 5 sqrt friedman_mse 0.5 50: Weighted 0.812194 (0.062216)\n",
      "0.01 5 2 5 sqrt friedman_mse 0.5 50: Macro 0.701032 (0.088495)\n",
      "Testing 938/5184\n",
      "0.01 5 2 5 sqrt friedman_mse 0.5 100: Weighted 0.822507 (0.054522)\n",
      "0.01 5 2 5 sqrt friedman_mse 0.5 100: Macro 0.721496 (0.072327)\n",
      "Testing 939/5184\n",
      "0.01 5 2 5 sqrt friedman_mse 0.5 200: Weighted 0.818464 (0.053295)\n",
      "0.01 5 2 5 sqrt friedman_mse 0.5 200: Macro 0.713415 (0.069985)\n",
      "Testing 940/5184\n",
      "0.01 5 2 5 sqrt friedman_mse 0.5 500: Weighted 0.822529 (0.076032)\n",
      "0.01 5 2 5 sqrt friedman_mse 0.5 500: Macro 0.717916 (0.107992)\n",
      "Testing 941/5184\n",
      "0.01 5 2 5 sqrt friedman_mse 0.75 50: Weighted 0.809728 (0.063180)\n",
      "0.01 5 2 5 sqrt friedman_mse 0.75 50: Macro 0.702329 (0.088159)\n",
      "Testing 942/5184\n",
      "0.01 5 2 5 sqrt friedman_mse 0.75 100: Weighted 0.801995 (0.066830)\n",
      "0.01 5 2 5 sqrt friedman_mse 0.75 100: Macro 0.690818 (0.089710)\n",
      "Testing 943/5184\n",
      "0.01 5 2 5 sqrt friedman_mse 0.75 200: Weighted 0.806410 (0.060612)\n",
      "0.01 5 2 5 sqrt friedman_mse 0.75 200: Macro 0.694084 (0.084866)\n",
      "Testing 944/5184\n",
      "0.01 5 2 5 sqrt friedman_mse 0.75 500: Weighted 0.825257 (0.072813)\n",
      "0.01 5 2 5 sqrt friedman_mse 0.75 500: Macro 0.731806 (0.098532)\n",
      "Testing 945/5184\n",
      "0.01 5 2 5 sqrt friedman_mse 1.0 50: Weighted 0.806820 (0.068909)\n",
      "0.01 5 2 5 sqrt friedman_mse 1.0 50: Macro 0.698029 (0.093335)\n",
      "Testing 946/5184\n",
      "0.01 5 2 5 sqrt friedman_mse 1.0 100: Weighted 0.795825 (0.065642)\n",
      "0.01 5 2 5 sqrt friedman_mse 1.0 100: Macro 0.685219 (0.088022)\n",
      "Testing 947/5184\n",
      "0.01 5 2 5 sqrt friedman_mse 1.0 200: Weighted 0.789600 (0.057283)\n",
      "0.01 5 2 5 sqrt friedman_mse 1.0 200: Macro 0.677797 (0.073248)\n",
      "Testing 948/5184\n",
      "0.01 5 2 5 sqrt friedman_mse 1.0 500: Weighted 0.806954 (0.086624)\n",
      "0.01 5 2 5 sqrt friedman_mse 1.0 500: Macro 0.710154 (0.116364)\n",
      "Testing 949/5184\n",
      "0.01 5 2 5 sqrt mae 0.5 50: Weighted 0.822311 (0.055757)\n",
      "0.01 5 2 5 sqrt mae 0.5 50: Macro 0.715331 (0.078193)\n",
      "Testing 950/5184\n",
      "0.01 5 2 5 sqrt mae 0.5 100: Weighted 0.821865 (0.056271)\n",
      "0.01 5 2 5 sqrt mae 0.5 100: Macro 0.717143 (0.076035)\n",
      "Testing 951/5184\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01 5 2 5 sqrt mae 0.5 200: Weighted 0.812722 (0.058740)\n",
      "0.01 5 2 5 sqrt mae 0.5 200: Macro 0.699936 (0.083135)\n",
      "Testing 952/5184\n",
      "0.01 5 2 5 sqrt mae 0.5 500: Weighted 0.803582 (0.065941)\n",
      "0.01 5 2 5 sqrt mae 0.5 500: Macro 0.684673 (0.094553)\n",
      "Testing 953/5184\n",
      "0.01 5 2 5 sqrt mae 0.75 50: Weighted 0.787956 (0.066380)\n",
      "0.01 5 2 5 sqrt mae 0.75 50: Macro 0.665397 (0.089493)\n",
      "Testing 954/5184\n",
      "0.01 5 2 5 sqrt mae 0.75 100: Weighted 0.790674 (0.072755)\n",
      "0.01 5 2 5 sqrt mae 0.75 100: Macro 0.669556 (0.098917)\n",
      "Testing 955/5184\n",
      "0.01 5 2 5 sqrt mae 0.75 200: Weighted 0.792459 (0.069494)\n",
      "0.01 5 2 5 sqrt mae 0.75 200: Macro 0.668591 (0.098782)\n",
      "Testing 956/5184\n",
      "0.01 5 2 5 sqrt mae 0.75 500: Weighted 0.774638 (0.076612)\n",
      "0.01 5 2 5 sqrt mae 0.75 500: Macro 0.638086 (0.113235)\n",
      "Testing 957/5184\n",
      "0.01 5 2 5 sqrt mae 1.0 50: Weighted 0.794825 (0.078822)\n",
      "0.01 5 2 5 sqrt mae 1.0 50: Macro 0.676727 (0.105947)\n",
      "Testing 958/5184\n",
      "0.01 5 2 5 sqrt mae 1.0 100: Weighted 0.786095 (0.075948)\n",
      "0.01 5 2 5 sqrt mae 1.0 100: Macro 0.653105 (0.113881)\n",
      "Testing 959/5184\n",
      "0.01 5 2 5 sqrt mae 1.0 200: Weighted 0.790857 (0.078781)\n",
      "0.01 5 2 5 sqrt mae 1.0 200: Macro 0.660247 (0.118805)\n",
      "Testing 960/5184\n",
      "0.01 5 2 5 sqrt mae 1.0 500: Weighted 0.785283 (0.092587)\n",
      "0.01 5 2 5 sqrt mae 1.0 500: Macro 0.657747 (0.134785)\n",
      "Testing 961/5184\n",
      "0.01 5 2 8 log2 friedman_mse 0.5 50: Weighted 0.817676 (0.072298)\n",
      "0.01 5 2 8 log2 friedman_mse 0.5 50: Macro 0.715496 (0.103574)\n",
      "Testing 962/5184\n",
      "0.01 5 2 8 log2 friedman_mse 0.5 100: Weighted 0.804489 (0.049812)\n",
      "0.01 5 2 8 log2 friedman_mse 0.5 100: Macro 0.692236 (0.068628)\n",
      "Testing 963/5184\n",
      "0.01 5 2 8 log2 friedman_mse 0.5 200: Weighted 0.827051 (0.062075)\n",
      "0.01 5 2 8 log2 friedman_mse 0.5 200: Macro 0.728197 (0.084227)\n",
      "Testing 964/5184\n",
      "0.01 5 2 8 log2 friedman_mse 0.5 500: Weighted 0.823171 (0.077201)\n",
      "0.01 5 2 8 log2 friedman_mse 0.5 500: Macro 0.716358 (0.113124)\n",
      "Testing 965/5184\n",
      "0.01 5 2 8 log2 friedman_mse 0.75 50: Weighted 0.808997 (0.066415)\n",
      "0.01 5 2 8 log2 friedman_mse 0.75 50: Macro 0.701609 (0.090024)\n",
      "Testing 966/5184\n",
      "0.01 5 2 8 log2 friedman_mse 0.75 100: Weighted 0.813784 (0.054349)\n",
      "0.01 5 2 8 log2 friedman_mse 0.75 100: Macro 0.704161 (0.077031)\n",
      "Testing 967/5184\n",
      "0.01 5 2 8 log2 friedman_mse 0.75 200: Weighted 0.822671 (0.055172)\n",
      "0.01 5 2 8 log2 friedman_mse 0.75 200: Macro 0.720972 (0.073087)\n",
      "Testing 968/5184\n",
      "0.01 5 2 8 log2 friedman_mse 0.75 500: Weighted 0.810450 (0.083977)\n",
      "0.01 5 2 8 log2 friedman_mse 0.75 500: Macro 0.707221 (0.118400)\n",
      "Testing 969/5184\n",
      "0.01 5 2 8 log2 friedman_mse 1.0 50: Weighted 0.797010 (0.065737)\n",
      "0.01 5 2 8 log2 friedman_mse 1.0 50: Macro 0.683682 (0.087741)\n",
      "Testing 970/5184\n",
      "0.01 5 2 8 log2 friedman_mse 1.0 100: Weighted 0.800811 (0.060581)\n",
      "0.01 5 2 8 log2 friedman_mse 1.0 100: Macro 0.688401 (0.081020)\n",
      "Testing 971/5184\n",
      "0.01 5 2 8 log2 friedman_mse 1.0 200: Weighted 0.788801 (0.066337)\n",
      "0.01 5 2 8 log2 friedman_mse 1.0 200: Macro 0.681677 (0.083885)\n",
      "Testing 972/5184\n",
      "0.01 5 2 8 log2 friedman_mse 1.0 500: Weighted 0.800554 (0.088004)\n",
      "0.01 5 2 8 log2 friedman_mse 1.0 500: Macro 0.700802 (0.117044)\n",
      "Testing 973/5184\n",
      "0.01 5 2 8 log2 mae 0.5 50: Weighted 0.813258 (0.058069)\n",
      "0.01 5 2 8 log2 mae 0.5 50: Macro 0.698452 (0.085137)\n",
      "Testing 974/5184\n",
      "0.01 5 2 8 log2 mae 0.5 100: Weighted 0.818240 (0.059404)\n",
      "0.01 5 2 8 log2 mae 0.5 100: Macro 0.712195 (0.080351)\n",
      "Testing 975/5184\n",
      "0.01 5 2 8 log2 mae 0.5 200: Weighted 0.803173 (0.067249)\n",
      "0.01 5 2 8 log2 mae 0.5 200: Macro 0.684497 (0.095979)\n",
      "Testing 976/5184\n",
      "0.01 5 2 8 log2 mae 0.5 500: Weighted 0.804469 (0.065946)\n",
      "0.01 5 2 8 log2 mae 0.5 500: Macro 0.689881 (0.091244)\n",
      "Testing 977/5184\n",
      "0.01 5 2 8 log2 mae 0.75 50: Weighted 0.802807 (0.062241)\n",
      "0.01 5 2 8 log2 mae 0.75 50: Macro 0.682116 (0.088742)\n",
      "Testing 978/5184\n",
      "0.01 5 2 8 log2 mae 0.75 100: Weighted 0.799904 (0.062519)\n",
      "0.01 5 2 8 log2 mae 0.75 100: Macro 0.677938 (0.089872)\n",
      "Testing 979/5184\n",
      "0.01 5 2 8 log2 mae 0.75 200: Weighted 0.791593 (0.070367)\n",
      "0.01 5 2 8 log2 mae 0.75 200: Macro 0.662607 (0.105124)\n",
      "Testing 980/5184\n",
      "0.01 5 2 8 log2 mae 0.75 500: Weighted 0.783545 (0.070853)\n",
      "0.01 5 2 8 log2 mae 0.75 500: Macro 0.653396 (0.100174)\n",
      "Testing 981/5184\n",
      "0.01 5 2 8 log2 mae 1.0 50: Weighted 0.793994 (0.068274)\n",
      "0.01 5 2 8 log2 mae 1.0 50: Macro 0.664356 (0.096893)\n",
      "Testing 982/5184\n",
      "0.01 5 2 8 log2 mae 1.0 100: Weighted 0.794828 (0.075402)\n",
      "0.01 5 2 8 log2 mae 1.0 100: Macro 0.663160 (0.116588)\n",
      "Testing 983/5184\n",
      "0.01 5 2 8 log2 mae 1.0 200: Weighted 0.783911 (0.077578)\n",
      "0.01 5 2 8 log2 mae 1.0 200: Macro 0.649948 (0.116697)\n",
      "Testing 984/5184\n",
      "0.01 5 2 8 log2 mae 1.0 500: Weighted 0.788674 (0.082613)\n",
      "0.01 5 2 8 log2 mae 1.0 500: Macro 0.666618 (0.113292)\n",
      "Testing 985/5184\n",
      "0.01 5 2 8 sqrt friedman_mse 0.5 50: Weighted 0.832215 (0.053793)\n",
      "0.01 5 2 8 sqrt friedman_mse 0.5 50: Macro 0.731000 (0.075819)\n",
      "Testing 986/5184\n",
      "0.01 5 2 8 sqrt friedman_mse 0.5 100: Weighted 0.818553 (0.043795)\n",
      "0.01 5 2 8 sqrt friedman_mse 0.5 100: Macro 0.714410 (0.057408)\n",
      "Testing 987/5184\n",
      "0.01 5 2 8 sqrt friedman_mse 0.5 200: Weighted 0.818491 (0.048441)\n",
      "0.01 5 2 8 sqrt friedman_mse 0.5 200: Macro 0.713154 (0.062697)\n",
      "Testing 988/5184\n",
      "0.01 5 2 8 sqrt friedman_mse 0.5 500: Weighted 0.831808 (0.074503)\n",
      "0.01 5 2 8 sqrt friedman_mse 0.5 500: Macro 0.733183 (0.108877)\n",
      "Testing 989/5184\n",
      "0.01 5 2 8 sqrt friedman_mse 0.75 50: Weighted 0.808568 (0.049973)\n",
      "0.01 5 2 8 sqrt friedman_mse 0.75 50: Macro 0.703121 (0.064022)\n",
      "Testing 990/5184\n",
      "0.01 5 2 8 sqrt friedman_mse 0.75 100: Weighted 0.810758 (0.051649)\n",
      "0.01 5 2 8 sqrt friedman_mse 0.75 100: Macro 0.698344 (0.073053)\n",
      "Testing 991/5184\n",
      "0.01 5 2 8 sqrt friedman_mse 0.75 200: Weighted 0.803801 (0.051795)\n",
      "0.01 5 2 8 sqrt friedman_mse 0.75 200: Macro 0.691886 (0.069478)\n",
      "Testing 992/5184\n",
      "0.01 5 2 8 sqrt friedman_mse 0.75 500: Weighted 0.820775 (0.081944)\n",
      "0.01 5 2 8 sqrt friedman_mse 0.75 500: Macro 0.715757 (0.117328)\n",
      "Testing 993/5184\n",
      "0.01 5 2 8 sqrt friedman_mse 1.0 50: Weighted 0.792597 (0.072015)\n",
      "0.01 5 2 8 sqrt friedman_mse 1.0 50: Macro 0.673547 (0.102887)\n",
      "Testing 994/5184\n",
      "0.01 5 2 8 sqrt friedman_mse 1.0 100: Weighted 0.805796 (0.061458)\n",
      "0.01 5 2 8 sqrt friedman_mse 1.0 100: Macro 0.695538 (0.082743)\n",
      "Testing 995/5184\n",
      "0.01 5 2 8 sqrt friedman_mse 1.0 200: Weighted 0.803093 (0.064379)\n",
      "0.01 5 2 8 sqrt friedman_mse 1.0 200: Macro 0.696034 (0.082847)\n",
      "Testing 996/5184\n",
      "0.01 5 2 8 sqrt friedman_mse 1.0 500: Weighted 0.804951 (0.094371)\n",
      "0.01 5 2 8 sqrt friedman_mse 1.0 500: Macro 0.708427 (0.127697)\n",
      "Testing 997/5184\n",
      "0.01 5 2 8 sqrt mae 0.5 50: Weighted 0.816112 (0.062381)\n",
      "0.01 5 2 8 sqrt mae 0.5 50: Macro 0.712409 (0.082100)\n",
      "Testing 998/5184\n",
      "0.01 5 2 8 sqrt mae 0.5 100: Weighted 0.805234 (0.065840)\n",
      "0.01 5 2 8 sqrt mae 0.5 100: Macro 0.690202 (0.092209)\n",
      "Testing 999/5184\n",
      "0.01 5 2 8 sqrt mae 0.5 200: Weighted 0.810394 (0.060262)\n",
      "0.01 5 2 8 sqrt mae 0.5 200: Macro 0.693913 (0.086863)\n",
      "Testing 1000/5184\n",
      "0.01 5 2 8 sqrt mae 0.5 500: Weighted 0.803582 (0.065941)\n",
      "0.01 5 2 8 sqrt mae 0.5 500: Macro 0.684673 (0.094553)\n",
      "Testing 1001/5184\n",
      "0.01 5 2 8 sqrt mae 0.75 50: Weighted 0.792459 (0.069494)\n",
      "0.01 5 2 8 sqrt mae 0.75 50: Macro 0.668591 (0.098782)\n",
      "Testing 1002/5184\n",
      "0.01 5 2 8 sqrt mae 0.75 100: Weighted 0.796041 (0.066528)\n",
      "0.01 5 2 8 sqrt mae 0.75 100: Macro 0.673153 (0.094870)\n",
      "Testing 1003/5184\n",
      "0.01 5 2 8 sqrt mae 0.75 200: Weighted 0.796322 (0.065877)\n",
      "0.01 5 2 8 sqrt mae 0.75 200: Macro 0.673377 (0.094225)\n",
      "Testing 1004/5184\n",
      "0.01 5 2 8 sqrt mae 0.75 500: Weighted 0.791799 (0.069251)\n",
      "0.01 5 2 8 sqrt mae 0.75 500: Macro 0.670775 (0.091973)\n",
      "Testing 1005/5184\n",
      "0.01 5 2 8 sqrt mae 1.0 50: Weighted 0.788035 (0.072924)\n",
      "0.01 5 2 8 sqrt mae 1.0 50: Macro 0.661532 (0.104064)\n",
      "Testing 1006/5184\n",
      "0.01 5 2 8 sqrt mae 1.0 100: Weighted 0.786095 (0.075948)\n",
      "0.01 5 2 8 sqrt mae 1.0 100: Macro 0.653105 (0.113881)\n",
      "Testing 1007/5184\n",
      "0.01 5 2 8 sqrt mae 1.0 200: Weighted 0.798853 (0.070912)\n",
      "0.01 5 2 8 sqrt mae 1.0 200: Macro 0.673903 (0.106566)\n",
      "Testing 1008/5184\n",
      "0.01 5 2 8 sqrt mae 1.0 500: Weighted 0.797579 (0.081915)\n",
      "0.01 5 2 8 sqrt mae 1.0 500: Macro 0.669796 (0.124774)\n",
      "Testing 1009/5184\n",
      "0.01 5 4 3 log2 friedman_mse 0.5 50: Weighted 0.823955 (0.049332)\n",
      "0.01 5 4 3 log2 friedman_mse 0.5 50: Macro 0.714211 (0.075034)\n",
      "Testing 1010/5184\n",
      "0.01 5 4 3 log2 friedman_mse 0.5 100: Weighted 0.828526 (0.043365)\n",
      "0.01 5 4 3 log2 friedman_mse 0.5 100: Macro 0.724173 (0.060784)\n",
      "Testing 1011/5184\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01 5 4 3 log2 friedman_mse 0.5 200: Weighted 0.819900 (0.055039)\n",
      "0.01 5 4 3 log2 friedman_mse 0.5 200: Macro 0.715467 (0.073167)\n",
      "Testing 1012/5184\n",
      "0.01 5 4 3 log2 friedman_mse 0.5 500: Weighted 0.824291 (0.063492)\n",
      "0.01 5 4 3 log2 friedman_mse 0.5 500: Macro 0.721276 (0.088216)\n",
      "Testing 1013/5184\n",
      "0.01 5 4 3 log2 friedman_mse 0.75 50: Weighted 0.807960 (0.068755)\n",
      "0.01 5 4 3 log2 friedman_mse 0.75 50: Macro 0.696842 (0.092841)\n",
      "Testing 1014/5184\n",
      "0.01 5 4 3 log2 friedman_mse 0.75 100: Weighted 0.815571 (0.061789)\n",
      "0.01 5 4 3 log2 friedman_mse 0.75 100: Macro 0.711176 (0.077719)\n",
      "Testing 1015/5184\n",
      "0.01 5 4 3 log2 friedman_mse 0.75 200: Weighted 0.806695 (0.063078)\n",
      "0.01 5 4 3 log2 friedman_mse 0.75 200: Macro 0.695979 (0.085719)\n",
      "Testing 1016/5184\n",
      "0.01 5 4 3 log2 friedman_mse 0.75 500: Weighted 0.814650 (0.065922)\n",
      "0.01 5 4 3 log2 friedman_mse 0.75 500: Macro 0.712154 (0.083615)\n",
      "Testing 1017/5184\n",
      "0.01 5 4 3 log2 friedman_mse 1.0 50: Weighted 0.804263 (0.069761)\n",
      "0.01 5 4 3 log2 friedman_mse 1.0 50: Macro 0.696860 (0.089188)\n",
      "Testing 1018/5184\n",
      "0.01 5 4 3 log2 friedman_mse 1.0 100: Weighted 0.807130 (0.060671)\n",
      "0.01 5 4 3 log2 friedman_mse 1.0 100: Macro 0.699865 (0.076278)\n",
      "Testing 1019/5184\n",
      "0.01 5 4 3 log2 friedman_mse 1.0 200: Weighted 0.806289 (0.054342)\n",
      "0.01 5 4 3 log2 friedman_mse 1.0 200: Macro 0.697221 (0.066373)\n",
      "Testing 1020/5184\n",
      "0.01 5 4 3 log2 friedman_mse 1.0 500: Weighted 0.800321 (0.078417)\n",
      "0.01 5 4 3 log2 friedman_mse 1.0 500: Macro 0.698240 (0.100694)\n",
      "Testing 1021/5184\n",
      "0.01 5 4 3 log2 mae 0.5 50: Weighted 0.798240 (0.053273)\n",
      "0.01 5 4 3 log2 mae 0.5 50: Macro 0.685496 (0.068065)\n",
      "Testing 1022/5184\n",
      "0.01 5 4 3 log2 mae 0.5 100: Weighted 0.820968 (0.050415)\n",
      "0.01 5 4 3 log2 mae 0.5 100: Macro 0.713855 (0.070368)\n",
      "Testing 1023/5184\n",
      "0.01 5 4 3 log2 mae 0.5 200: Weighted 0.824888 (0.057497)\n",
      "0.01 5 4 3 log2 mae 0.5 200: Macro 0.715792 (0.086591)\n",
      "Testing 1024/5184\n",
      "0.01 5 4 3 log2 mae 0.5 500: Weighted 0.823955 (0.049332)\n",
      "0.01 5 4 3 log2 mae 0.5 500: Macro 0.714211 (0.075034)\n",
      "Testing 1025/5184\n",
      "0.01 5 4 3 log2 mae 0.75 50: Weighted 0.799278 (0.069641)\n",
      "0.01 5 4 3 log2 mae 0.75 50: Macro 0.686116 (0.093767)\n",
      "Testing 1026/5184\n",
      "0.01 5 4 3 log2 mae 0.75 100: Weighted 0.808159 (0.062497)\n",
      "0.01 5 4 3 log2 mae 0.75 100: Macro 0.699200 (0.088922)\n",
      "Testing 1027/5184\n",
      "0.01 5 4 3 log2 mae 0.75 200: Weighted 0.800284 (0.063984)\n",
      "0.01 5 4 3 log2 mae 0.75 200: Macro 0.683421 (0.089155)\n",
      "Testing 1028/5184\n",
      "0.01 5 4 3 log2 mae 0.75 500: Weighted 0.800189 (0.069756)\n",
      "0.01 5 4 3 log2 mae 0.75 500: Macro 0.681749 (0.097692)\n",
      "Testing 1029/5184\n",
      "0.01 5 4 3 log2 mae 1.0 50: Weighted 0.783550 (0.070132)\n",
      "0.01 5 4 3 log2 mae 1.0 50: Macro 0.664009 (0.093292)\n",
      "Testing 1030/5184\n",
      "0.01 5 4 3 log2 mae 1.0 100: Weighted 0.792137 (0.071524)\n",
      "0.01 5 4 3 log2 mae 1.0 100: Macro 0.676210 (0.096349)\n",
      "Testing 1031/5184\n",
      "0.01 5 4 3 log2 mae 1.0 200: Weighted 0.786683 (0.075087)\n",
      "0.01 5 4 3 log2 mae 1.0 200: Macro 0.666347 (0.101744)\n",
      "Testing 1032/5184\n",
      "0.01 5 4 3 log2 mae 1.0 500: Weighted 0.788075 (0.090985)\n",
      "0.01 5 4 3 log2 mae 1.0 500: Macro 0.660072 (0.135536)\n",
      "Testing 1033/5184\n",
      "0.01 5 4 3 sqrt friedman_mse 0.5 50: Weighted 0.821320 (0.058875)\n",
      "0.01 5 4 3 sqrt friedman_mse 0.5 50: Macro 0.711745 (0.088933)\n",
      "Testing 1034/5184\n",
      "0.01 5 4 3 sqrt friedman_mse 0.5 100: Weighted 0.820029 (0.054853)\n",
      "0.01 5 4 3 sqrt friedman_mse 0.5 100: Macro 0.709358 (0.082393)\n",
      "Testing 1035/5184\n",
      "0.01 5 4 3 sqrt friedman_mse 0.5 200: Weighted 0.820053 (0.066984)\n",
      "0.01 5 4 3 sqrt friedman_mse 0.5 200: Macro 0.713018 (0.095712)\n",
      "Testing 1036/5184\n",
      "0.01 5 4 3 sqrt friedman_mse 0.5 500: Weighted 0.818952 (0.057055)\n",
      "0.01 5 4 3 sqrt friedman_mse 0.5 500: Macro 0.714313 (0.076875)\n",
      "Testing 1037/5184\n",
      "0.01 5 4 3 sqrt friedman_mse 0.75 50: Weighted 0.816464 (0.056270)\n",
      "0.01 5 4 3 sqrt friedman_mse 0.75 50: Macro 0.710442 (0.074978)\n",
      "Testing 1038/5184\n",
      "0.01 5 4 3 sqrt friedman_mse 0.75 100: Weighted 0.815571 (0.061789)\n",
      "0.01 5 4 3 sqrt friedman_mse 0.75 100: Macro 0.711176 (0.077719)\n",
      "Testing 1039/5184\n",
      "0.01 5 4 3 sqrt friedman_mse 0.75 200: Weighted 0.815571 (0.061789)\n",
      "0.01 5 4 3 sqrt friedman_mse 0.75 200: Macro 0.711176 (0.077719)\n",
      "Testing 1040/5184\n",
      "0.01 5 4 3 sqrt friedman_mse 0.75 500: Weighted 0.814659 (0.075379)\n",
      "0.01 5 4 3 sqrt friedman_mse 0.75 500: Macro 0.713802 (0.095929)\n",
      "Testing 1041/5184\n",
      "0.01 5 4 3 sqrt friedman_mse 1.0 50: Weighted 0.804263 (0.069761)\n",
      "0.01 5 4 3 sqrt friedman_mse 1.0 50: Macro 0.692809 (0.094921)\n",
      "Testing 1042/5184\n",
      "0.01 5 4 3 sqrt friedman_mse 1.0 100: Weighted 0.811954 (0.062559)\n",
      "0.01 5 4 3 sqrt friedman_mse 1.0 100: Macro 0.707076 (0.079695)\n",
      "Testing 1043/5184\n",
      "0.01 5 4 3 sqrt friedman_mse 1.0 200: Weighted 0.801998 (0.056002)\n",
      "0.01 5 4 3 sqrt friedman_mse 1.0 200: Macro 0.692419 (0.066684)\n",
      "Testing 1044/5184\n",
      "0.01 5 4 3 sqrt friedman_mse 1.0 500: Weighted 0.805294 (0.079595)\n",
      "0.01 5 4 3 sqrt friedman_mse 1.0 500: Macro 0.705528 (0.101887)\n",
      "Testing 1045/5184\n",
      "0.01 5 4 3 sqrt mae 0.5 50: Weighted 0.817249 (0.061910)\n",
      "0.01 5 4 3 sqrt mae 0.5 50: Macro 0.710271 (0.084544)\n",
      "Testing 1046/5184\n",
      "0.01 5 4 3 sqrt mae 0.5 100: Weighted 0.813124 (0.057916)\n",
      "0.01 5 4 3 sqrt mae 0.5 100: Macro 0.703477 (0.080262)\n",
      "Testing 1047/5184\n",
      "0.01 5 4 3 sqrt mae 0.5 200: Weighted 0.817632 (0.052880)\n",
      "0.01 5 4 3 sqrt mae 0.5 200: Macro 0.707973 (0.072913)\n",
      "Testing 1048/5184\n",
      "0.01 5 4 3 sqrt mae 0.5 500: Weighted 0.813537 (0.066795)\n",
      "0.01 5 4 3 sqrt mae 0.5 500: Macro 0.702508 (0.095036)\n",
      "Testing 1049/5184\n",
      "0.01 5 4 3 sqrt mae 0.75 50: Weighted 0.801232 (0.073810)\n",
      "0.01 5 4 3 sqrt mae 0.75 50: Macro 0.691801 (0.099131)\n",
      "Testing 1050/5184\n",
      "0.01 5 4 3 sqrt mae 0.75 100: Weighted 0.802714 (0.069506)\n",
      "0.01 5 4 3 sqrt mae 0.75 100: Macro 0.691140 (0.093640)\n",
      "Testing 1051/5184\n",
      "0.01 5 4 3 sqrt mae 0.75 200: Weighted 0.798193 (0.074185)\n",
      "0.01 5 4 3 sqrt mae 0.75 200: Macro 0.684903 (0.096664)\n",
      "Testing 1052/5184\n",
      "0.01 5 4 3 sqrt mae 0.75 500: Weighted 0.796388 (0.074246)\n",
      "0.01 5 4 3 sqrt mae 0.75 500: Macro 0.677030 (0.103029)\n",
      "Testing 1053/5184\n",
      "0.01 5 4 3 sqrt mae 1.0 50: Weighted 0.783550 (0.070132)\n",
      "0.01 5 4 3 sqrt mae 1.0 50: Macro 0.664009 (0.093292)\n",
      "Testing 1054/5184\n",
      "0.01 5 4 3 sqrt mae 1.0 100: Weighted 0.795192 (0.062407)\n",
      "0.01 5 4 3 sqrt mae 1.0 100: Macro 0.680623 (0.083573)\n",
      "Testing 1055/5184\n",
      "0.01 5 4 3 sqrt mae 1.0 200: Weighted 0.779543 (0.072793)\n",
      "0.01 5 4 3 sqrt mae 1.0 200: Macro 0.653675 (0.098747)\n",
      "Testing 1056/5184\n",
      "0.01 5 4 3 sqrt mae 1.0 500: Weighted 0.792264 (0.085828)\n",
      "0.01 5 4 3 sqrt mae 1.0 500: Macro 0.669701 (0.124652)\n",
      "Testing 1057/5184\n",
      "0.01 5 4 5 log2 friedman_mse 0.5 50: Weighted 0.822897 (0.049384)\n",
      "0.01 5 4 5 log2 friedman_mse 0.5 50: Macro 0.719914 (0.067864)\n",
      "Testing 1058/5184\n",
      "0.01 5 4 5 log2 friedman_mse 0.5 100: Weighted 0.809135 (0.054093)\n",
      "0.01 5 4 5 log2 friedman_mse 0.5 100: Macro 0.697207 (0.077053)\n",
      "Testing 1059/5184\n",
      "0.01 5 4 5 log2 friedman_mse 0.5 200: Weighted 0.822507 (0.054522)\n",
      "0.01 5 4 5 log2 friedman_mse 0.5 200: Macro 0.721496 (0.072327)\n",
      "Testing 1060/5184\n",
      "0.01 5 4 5 log2 friedman_mse 0.5 500: Weighted 0.830997 (0.062257)\n",
      "0.01 5 4 5 log2 friedman_mse 0.5 500: Macro 0.737831 (0.085618)\n",
      "Testing 1061/5184\n",
      "0.01 5 4 5 log2 friedman_mse 0.75 50: Weighted 0.814686 (0.061957)\n",
      "0.01 5 4 5 log2 friedman_mse 0.75 50: Macro 0.711705 (0.077623)\n",
      "Testing 1062/5184\n",
      "0.01 5 4 5 log2 friedman_mse 0.75 100: Weighted 0.810225 (0.056195)\n",
      "0.01 5 4 5 log2 friedman_mse 0.75 100: Macro 0.699774 (0.080412)\n",
      "Testing 1063/5184\n",
      "0.01 5 4 5 log2 friedman_mse 0.75 200: Weighted 0.809264 (0.048155)\n",
      "0.01 5 4 5 log2 friedman_mse 0.75 200: Macro 0.697349 (0.068693)\n",
      "Testing 1064/5184\n",
      "0.01 5 4 5 log2 friedman_mse 0.75 500: Weighted 0.810068 (0.085319)\n",
      "0.01 5 4 5 log2 friedman_mse 0.75 500: Macro 0.699170 (0.122913)\n",
      "Testing 1065/5184\n",
      "0.01 5 4 5 log2 friedman_mse 1.0 50: Weighted 0.802955 (0.066643)\n",
      "0.01 5 4 5 log2 friedman_mse 1.0 50: Macro 0.690556 (0.089751)\n",
      "Testing 1066/5184\n",
      "0.01 5 4 5 log2 friedman_mse 1.0 100: Weighted 0.792260 (0.066378)\n",
      "0.01 5 4 5 log2 friedman_mse 1.0 100: Macro 0.680055 (0.088940)\n",
      "Testing 1067/5184\n",
      "0.01 5 4 5 log2 friedman_mse 1.0 200: Weighted 0.789600 (0.057283)\n",
      "0.01 5 4 5 log2 friedman_mse 1.0 200: Macro 0.677797 (0.073248)\n",
      "Testing 1068/5184\n",
      "0.01 5 4 5 log2 friedman_mse 1.0 500: Weighted 0.811844 (0.088892)\n",
      "0.01 5 4 5 log2 friedman_mse 1.0 500: Macro 0.710945 (0.125744)\n",
      "Testing 1069/5184\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01 5 4 5 log2 mae 0.5 50: Weighted 0.817184 (0.053385)\n",
      "0.01 5 4 5 log2 mae 0.5 50: Macro 0.703305 (0.078713)\n",
      "Testing 1070/5184\n",
      "0.01 5 4 5 log2 mae 0.5 100: Weighted 0.823660 (0.046907)\n",
      "0.01 5 4 5 log2 mae 0.5 100: Macro 0.718961 (0.062664)\n",
      "Testing 1071/5184\n",
      "0.01 5 4 5 log2 mae 0.5 200: Weighted 0.820700 (0.051056)\n",
      "0.01 5 4 5 log2 mae 0.5 200: Macro 0.708262 (0.076184)\n",
      "Testing 1072/5184\n",
      "0.01 5 4 5 log2 mae 0.5 500: Weighted 0.804683 (0.072895)\n",
      "0.01 5 4 5 log2 mae 0.5 500: Macro 0.687388 (0.105088)\n",
      "Testing 1073/5184\n",
      "0.01 5 4 5 log2 mae 0.75 50: Weighted 0.797901 (0.061062)\n",
      "0.01 5 4 5 log2 mae 0.75 50: Macro 0.675065 (0.086335)\n",
      "Testing 1074/5184\n",
      "0.01 5 4 5 log2 mae 0.75 100: Weighted 0.788044 (0.074153)\n",
      "0.01 5 4 5 log2 mae 0.75 100: Macro 0.665325 (0.102162)\n",
      "Testing 1075/5184\n",
      "0.01 5 4 5 log2 mae 0.75 200: Weighted 0.791626 (0.071602)\n",
      "0.01 5 4 5 log2 mae 0.75 200: Macro 0.669887 (0.098535)\n",
      "Testing 1076/5184\n",
      "0.01 5 4 5 log2 mae 0.75 500: Weighted 0.782724 (0.079160)\n",
      "0.01 5 4 5 log2 mae 0.75 500: Macro 0.649082 (0.117769)\n",
      "Testing 1077/5184\n",
      "0.01 5 4 5 log2 mae 1.0 50: Weighted 0.778049 (0.077356)\n",
      "0.01 5 4 5 log2 mae 1.0 50: Macro 0.647172 (0.109034)\n",
      "Testing 1078/5184\n",
      "0.01 5 4 5 log2 mae 1.0 100: Weighted 0.782465 (0.072285)\n",
      "0.01 5 4 5 log2 mae 1.0 100: Macro 0.652701 (0.104582)\n",
      "Testing 1079/5184\n",
      "0.01 5 4 5 log2 mae 1.0 200: Weighted 0.787286 (0.082931)\n",
      "0.01 5 4 5 log2 mae 1.0 200: Macro 0.656070 (0.123423)\n",
      "Testing 1080/5184\n",
      "0.01 5 4 5 log2 mae 1.0 500: Weighted 0.788680 (0.079537)\n",
      "0.01 5 4 5 log2 mae 1.0 500: Macro 0.657012 (0.115728)\n",
      "Testing 1081/5184\n",
      "0.01 5 4 5 sqrt friedman_mse 0.5 50: Weighted 0.815685 (0.056809)\n",
      "0.01 5 4 5 sqrt friedman_mse 0.5 50: Macro 0.709781 (0.074330)\n",
      "Testing 1082/5184\n",
      "0.01 5 4 5 sqrt friedman_mse 0.5 100: Weighted 0.808662 (0.047753)\n",
      "0.01 5 4 5 sqrt friedman_mse 0.5 100: Macro 0.696409 (0.070809)\n",
      "Testing 1083/5184\n",
      "0.01 5 4 5 sqrt friedman_mse 0.5 200: Weighted 0.813412 (0.059639)\n",
      "0.01 5 4 5 sqrt friedman_mse 0.5 200: Macro 0.704875 (0.084783)\n",
      "Testing 1084/5184\n",
      "0.01 5 4 5 sqrt friedman_mse 0.5 500: Weighted 0.827945 (0.079465)\n",
      "0.01 5 4 5 sqrt friedman_mse 0.5 500: Macro 0.728398 (0.115353)\n",
      "Testing 1085/5184\n",
      "0.01 5 4 5 sqrt friedman_mse 0.75 50: Weighted 0.808873 (0.059600)\n",
      "0.01 5 4 5 sqrt friedman_mse 0.75 50: Macro 0.701310 (0.084984)\n",
      "Testing 1086/5184\n",
      "0.01 5 4 5 sqrt friedman_mse 0.75 100: Weighted 0.806410 (0.060612)\n",
      "0.01 5 4 5 sqrt friedman_mse 0.75 100: Macro 0.694084 (0.084866)\n",
      "Testing 1087/5184\n",
      "0.01 5 4 5 sqrt friedman_mse 0.75 200: Weighted 0.798568 (0.055905)\n",
      "0.01 5 4 5 sqrt friedman_mse 0.75 200: Macro 0.681251 (0.077204)\n",
      "Testing 1088/5184\n",
      "0.01 5 4 5 sqrt friedman_mse 0.75 500: Weighted 0.809034 (0.086174)\n",
      "0.01 5 4 5 sqrt friedman_mse 0.75 500: Macro 0.700445 (0.121850)\n",
      "Testing 1089/5184\n",
      "0.01 5 4 5 sqrt friedman_mse 1.0 50: Weighted 0.796785 (0.065542)\n",
      "0.01 5 4 5 sqrt friedman_mse 1.0 50: Macro 0.684957 (0.088047)\n",
      "Testing 1090/5184\n",
      "0.01 5 4 5 sqrt friedman_mse 1.0 100: Weighted 0.795825 (0.065642)\n",
      "0.01 5 4 5 sqrt friedman_mse 1.0 100: Macro 0.685219 (0.088022)\n",
      "Testing 1091/5184\n",
      "0.01 5 4 5 sqrt friedman_mse 1.0 200: Weighted 0.785751 (0.062569)\n",
      "0.01 5 4 5 sqrt friedman_mse 1.0 200: Macro 0.672942 (0.080234)\n",
      "Testing 1092/5184\n",
      "0.01 5 4 5 sqrt friedman_mse 1.0 500: Weighted 0.797655 (0.096195)\n",
      "0.01 5 4 5 sqrt friedman_mse 1.0 500: Macro 0.687422 (0.138531)\n",
      "Testing 1093/5184\n",
      "0.01 5 4 5 sqrt mae 0.5 50: Weighted 0.805053 (0.065734)\n",
      "0.01 5 4 5 sqrt mae 0.5 50: Macro 0.691126 (0.092832)\n",
      "Testing 1094/5184\n",
      "0.01 5 4 5 sqrt mae 0.5 100: Weighted 0.816773 (0.056182)\n",
      "0.01 5 4 5 sqrt mae 0.5 100: Macro 0.703409 (0.083095)\n",
      "Testing 1095/5184\n",
      "0.01 5 4 5 sqrt mae 0.5 200: Weighted 0.807569 (0.064445)\n",
      "0.01 5 4 5 sqrt mae 0.5 200: Macro 0.689259 (0.092770)\n",
      "Testing 1096/5184\n",
      "0.01 5 4 5 sqrt mae 0.5 500: Weighted 0.799824 (0.069428)\n",
      "0.01 5 4 5 sqrt mae 0.5 500: Macro 0.680955 (0.099843)\n",
      "Testing 1097/5184\n",
      "0.01 5 4 5 sqrt mae 0.75 50: Weighted 0.796041 (0.066528)\n",
      "0.01 5 4 5 sqrt mae 0.75 50: Macro 0.673153 (0.094870)\n",
      "Testing 1098/5184\n",
      "0.01 5 4 5 sqrt mae 0.75 100: Weighted 0.800472 (0.063509)\n",
      "0.01 5 4 5 sqrt mae 0.75 100: Macro 0.683059 (0.088232)\n",
      "Testing 1099/5184\n",
      "0.01 5 4 5 sqrt mae 0.75 200: Weighted 0.795427 (0.067204)\n",
      "0.01 5 4 5 sqrt mae 0.75 200: Macro 0.674606 (0.093302)\n",
      "Testing 1100/5184\n",
      "0.01 5 4 5 sqrt mae 0.75 500: Weighted 0.783440 (0.068148)\n",
      "0.01 5 4 5 sqrt mae 0.75 500: Macro 0.651553 (0.101288)\n",
      "Testing 1101/5184\n",
      "0.01 5 4 5 sqrt mae 1.0 50: Weighted 0.798868 (0.064851)\n",
      "0.01 5 4 5 sqrt mae 1.0 50: Macro 0.679100 (0.089822)\n",
      "Testing 1102/5184\n",
      "0.01 5 4 5 sqrt mae 1.0 100: Weighted 0.777617 (0.077851)\n",
      "0.01 5 4 5 sqrt mae 1.0 100: Macro 0.641875 (0.114623)\n",
      "Testing 1103/5184\n",
      "0.01 5 4 5 sqrt mae 1.0 200: Weighted 0.786095 (0.075948)\n",
      "0.01 5 4 5 sqrt mae 1.0 200: Macro 0.653105 (0.113881)\n",
      "Testing 1104/5184\n",
      "0.01 5 4 5 sqrt mae 1.0 500: Weighted 0.783255 (0.084583)\n",
      "0.01 5 4 5 sqrt mae 1.0 500: Macro 0.653532 (0.124963)\n",
      "Testing 1105/5184\n",
      "0.01 5 4 8 log2 friedman_mse 0.5 50: Weighted 0.819195 (0.055378)\n",
      "0.01 5 4 8 log2 friedman_mse 0.5 50: Macro 0.715072 (0.072558)\n",
      "Testing 1106/5184\n",
      "0.01 5 4 8 log2 friedman_mse 0.5 100: Weighted 0.826745 (0.048596)\n",
      "0.01 5 4 8 log2 friedman_mse 0.5 100: Macro 0.725797 (0.063787)\n",
      "Testing 1107/5184\n",
      "0.01 5 4 8 log2 friedman_mse 0.5 200: Weighted 0.821740 (0.047579)\n",
      "0.01 5 4 8 log2 friedman_mse 0.5 200: Macro 0.719511 (0.062197)\n",
      "Testing 1108/5184\n",
      "0.01 5 4 8 log2 friedman_mse 0.5 500: Weighted 0.822307 (0.070480)\n",
      "0.01 5 4 8 log2 friedman_mse 0.5 500: Macro 0.713733 (0.103373)\n",
      "Testing 1109/5184\n",
      "0.01 5 4 8 log2 friedman_mse 0.75 50: Weighted 0.805878 (0.057742)\n",
      "0.01 5 4 8 log2 friedman_mse 0.75 50: Macro 0.694108 (0.079703)\n",
      "Testing 1110/5184\n",
      "0.01 5 4 8 log2 friedman_mse 0.75 100: Weighted 0.809264 (0.048155)\n",
      "0.01 5 4 8 log2 friedman_mse 0.75 100: Macro 0.697349 (0.068693)\n",
      "Testing 1111/5184\n",
      "0.01 5 4 8 log2 friedman_mse 0.75 200: Weighted 0.809510 (0.055793)\n",
      "0.01 5 4 8 log2 friedman_mse 0.75 200: Macro 0.699531 (0.077790)\n",
      "Testing 1112/5184\n",
      "0.01 5 4 8 log2 friedman_mse 0.75 500: Weighted 0.819000 (0.082447)\n",
      "0.01 5 4 8 log2 friedman_mse 0.75 500: Macro 0.719438 (0.118108)\n",
      "Testing 1113/5184\n",
      "0.01 5 4 8 log2 friedman_mse 1.0 50: Weighted 0.798430 (0.067878)\n",
      "0.01 5 4 8 log2 friedman_mse 1.0 50: Macro 0.685654 (0.090929)\n",
      "Testing 1114/5184\n",
      "0.01 5 4 8 log2 friedman_mse 1.0 100: Weighted 0.798288 (0.057836)\n",
      "0.01 5 4 8 log2 friedman_mse 1.0 100: Macro 0.690495 (0.075548)\n",
      "Testing 1115/5184\n",
      "0.01 5 4 8 log2 friedman_mse 1.0 200: Weighted 0.802836 (0.071744)\n",
      "0.01 5 4 8 log2 friedman_mse 1.0 200: Macro 0.699506 (0.094691)\n",
      "Testing 1116/5184\n",
      "0.01 5 4 8 log2 friedman_mse 1.0 500: Weighted 0.805381 (0.072693)\n",
      "0.01 5 4 8 log2 friedman_mse 1.0 500: Macro 0.712054 (0.099453)\n",
      "Testing 1117/5184\n",
      "0.01 5 4 8 log2 mae 0.5 50: Weighted 0.805870 (0.063771)\n",
      "0.01 5 4 8 log2 mae 0.5 50: Macro 0.688513 (0.091549)\n",
      "Testing 1118/5184\n",
      "0.01 5 4 8 log2 mae 0.5 100: Weighted 0.810214 (0.060162)\n",
      "0.01 5 4 8 log2 mae 0.5 100: Macro 0.694837 (0.087484)\n",
      "Testing 1119/5184\n",
      "0.01 5 4 8 log2 mae 0.5 200: Weighted 0.807852 (0.070500)\n",
      "0.01 5 4 8 log2 mae 0.5 200: Macro 0.691855 (0.101761)\n",
      "Testing 1120/5184\n",
      "0.01 5 4 8 log2 mae 0.5 500: Weighted 0.811459 (0.068917)\n",
      "0.01 5 4 8 log2 mae 0.5 500: Macro 0.696244 (0.099583)\n",
      "Testing 1121/5184\n",
      "0.01 5 4 8 log2 mae 0.75 50: Weighted 0.795175 (0.067485)\n",
      "0.01 5 4 8 log2 mae 0.75 50: Macro 0.673368 (0.094635)\n",
      "Testing 1122/5184\n",
      "0.01 5 4 8 log2 mae 0.75 100: Weighted 0.792459 (0.069494)\n",
      "0.01 5 4 8 log2 mae 0.75 100: Macro 0.668591 (0.098782)\n",
      "Testing 1123/5184\n",
      "0.01 5 4 8 log2 mae 0.75 200: Weighted 0.799937 (0.070044)\n",
      "0.01 5 4 8 log2 mae 0.75 200: Macro 0.674312 (0.106267)\n",
      "Testing 1124/5184\n",
      "0.01 5 4 8 log2 mae 0.75 500: Weighted 0.790103 (0.076295)\n",
      "0.01 5 4 8 log2 mae 0.75 500: Macro 0.664284 (0.108528)\n",
      "Testing 1125/5184\n",
      "0.01 5 4 8 log2 mae 1.0 50: Weighted 0.780219 (0.072802)\n",
      "0.01 5 4 8 log2 mae 1.0 50: Macro 0.650792 (0.103858)\n",
      "Testing 1126/5184\n",
      "0.01 5 4 8 log2 mae 1.0 100: Weighted 0.784680 (0.070316)\n",
      "0.01 5 4 8 log2 mae 1.0 100: Macro 0.649473 (0.106759)\n",
      "Testing 1127/5184\n",
      "0.01 5 4 8 log2 mae 1.0 200: Weighted 0.798461 (0.071236)\n",
      "0.01 5 4 8 log2 mae 1.0 200: Macro 0.667402 (0.111826)\n",
      "Testing 1128/5184\n",
      "0.01 5 4 8 log2 mae 1.0 500: Weighted 0.801432 (0.083010)\n",
      "0.01 5 4 8 log2 mae 1.0 500: Macro 0.677148 (0.125052)\n",
      "Testing 1129/5184\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01 5 4 8 sqrt friedman_mse 0.5 50: Weighted 0.809563 (0.053472)\n",
      "0.01 5 4 8 sqrt friedman_mse 0.5 50: Macro 0.704292 (0.067349)\n",
      "Testing 1130/5184\n",
      "0.01 5 4 8 sqrt friedman_mse 0.5 100: Weighted 0.812810 (0.054164)\n",
      "0.01 5 4 8 sqrt friedman_mse 0.5 100: Macro 0.710186 (0.070046)\n",
      "Testing 1131/5184\n",
      "0.01 5 4 8 sqrt friedman_mse 0.5 200: Weighted 0.814190 (0.053789)\n",
      "0.01 5 4 8 sqrt friedman_mse 0.5 200: Macro 0.708785 (0.070211)\n",
      "Testing 1132/5184\n",
      "0.01 5 4 8 sqrt friedman_mse 0.5 500: Weighted 0.832270 (0.069649)\n",
      "0.01 5 4 8 sqrt friedman_mse 0.5 500: Macro 0.731991 (0.100626)\n",
      "Testing 1133/5184\n",
      "0.01 5 4 8 sqrt friedman_mse 0.75 50: Weighted 0.815098 (0.057261)\n",
      "0.01 5 4 8 sqrt friedman_mse 0.75 50: Macro 0.706080 (0.081400)\n",
      "Testing 1134/5184\n",
      "0.01 5 4 8 sqrt friedman_mse 0.75 100: Weighted 0.801890 (0.054519)\n",
      "0.01 5 4 8 sqrt friedman_mse 0.75 100: Macro 0.687273 (0.076484)\n",
      "Testing 1135/5184\n",
      "0.01 5 4 8 sqrt friedman_mse 0.75 200: Weighted 0.803038 (0.052051)\n",
      "0.01 5 4 8 sqrt friedman_mse 0.75 200: Macro 0.692547 (0.069348)\n",
      "Testing 1136/5184\n",
      "0.01 5 4 8 sqrt friedman_mse 0.75 500: Weighted 0.830442 (0.080405)\n",
      "0.01 5 4 8 sqrt friedman_mse 0.75 500: Macro 0.734815 (0.112931)\n",
      "Testing 1137/5184\n",
      "0.01 5 4 8 sqrt friedman_mse 1.0 50: Weighted 0.801183 (0.062474)\n",
      "0.01 5 4 8 sqrt friedman_mse 1.0 50: Macro 0.692308 (0.085232)\n",
      "Testing 1138/5184\n",
      "0.01 5 4 8 sqrt friedman_mse 1.0 100: Weighted 0.804749 (0.061173)\n",
      "0.01 5 4 8 sqrt friedman_mse 1.0 100: Macro 0.697472 (0.083520)\n",
      "Testing 1139/5184\n",
      "0.01 5 4 8 sqrt friedman_mse 1.0 200: Weighted 0.807039 (0.066003)\n",
      "0.01 5 4 8 sqrt friedman_mse 1.0 200: Macro 0.705667 (0.087861)\n",
      "Testing 1140/5184\n",
      "0.01 5 4 8 sqrt friedman_mse 1.0 500: Weighted 0.805427 (0.084229)\n",
      "0.01 5 4 8 sqrt friedman_mse 1.0 500: Macro 0.712377 (0.108770)\n",
      "Testing 1141/5184\n",
      "0.01 5 4 8 sqrt mae 0.5 50: Weighted 0.811716 (0.052371)\n",
      "0.01 5 4 8 sqrt mae 0.5 50: Macro 0.696551 (0.074783)\n",
      "Testing 1142/5184\n",
      "0.01 5 4 8 sqrt mae 0.5 100: Weighted 0.811713 (0.059371)\n",
      "0.01 5 4 8 sqrt mae 0.5 100: Macro 0.699991 (0.083106)\n",
      "Testing 1143/5184\n",
      "0.01 5 4 8 sqrt mae 0.5 200: Weighted 0.802993 (0.067140)\n",
      "0.01 5 4 8 sqrt mae 0.5 200: Macro 0.685422 (0.096632)\n",
      "Testing 1144/5184\n",
      "0.01 5 4 8 sqrt mae 0.5 500: Weighted 0.808047 (0.061879)\n",
      "0.01 5 4 8 sqrt mae 0.5 500: Macro 0.694523 (0.085672)\n",
      "Testing 1145/5184\n",
      "0.01 5 4 8 sqrt mae 0.75 50: Weighted 0.812391 (0.057186)\n",
      "0.01 5 4 8 sqrt mae 0.75 50: Macro 0.700349 (0.080854)\n",
      "Testing 1146/5184\n",
      "0.01 5 4 8 sqrt mae 0.75 100: Weighted 0.799904 (0.062519)\n",
      "0.01 5 4 8 sqrt mae 0.75 100: Macro 0.677938 (0.089872)\n",
      "Testing 1147/5184\n",
      "0.01 5 4 8 sqrt mae 0.75 200: Weighted 0.795175 (0.067485)\n",
      "0.01 5 4 8 sqrt mae 0.75 200: Macro 0.667169 (0.101725)\n",
      "Testing 1148/5184\n",
      "0.01 5 4 8 sqrt mae 0.75 500: Weighted 0.806919 (0.080559)\n",
      "0.01 5 4 8 sqrt mae 0.75 500: Macro 0.689498 (0.119464)\n",
      "Testing 1149/5184\n",
      "0.01 5 4 8 sqrt mae 1.0 50: Weighted 0.794462 (0.068288)\n",
      "0.01 5 4 8 sqrt mae 1.0 50: Macro 0.674346 (0.093579)\n",
      "Testing 1150/5184\n",
      "0.01 5 4 8 sqrt mae 1.0 100: Weighted 0.784944 (0.070060)\n",
      "0.01 5 4 8 sqrt mae 1.0 100: Macro 0.656917 (0.100138)\n",
      "Testing 1151/5184\n",
      "0.01 5 4 8 sqrt mae 1.0 200: Weighted 0.789309 (0.073587)\n",
      "0.01 5 4 8 sqrt mae 1.0 200: Macro 0.657020 (0.110617)\n",
      "Testing 1152/5184\n",
      "0.01 5 4 8 sqrt mae 1.0 500: Weighted 0.778724 (0.075546)\n",
      "0.01 5 4 8 sqrt mae 1.0 500: Macro 0.642401 (0.109406)\n",
      "Testing 1153/5184\n",
      "0.01 5 6 3 log2 friedman_mse 0.5 50: Weighted 0.812627 (0.051061)\n",
      "0.01 5 6 3 log2 friedman_mse 0.5 50: Macro 0.701687 (0.069943)\n",
      "Testing 1154/5184\n",
      "0.01 5 6 3 log2 friedman_mse 0.5 100: Weighted 0.810525 (0.063242)\n",
      "0.01 5 6 3 log2 friedman_mse 0.5 100: Macro 0.706888 (0.078886)\n",
      "Testing 1155/5184\n",
      "0.01 5 6 3 log2 friedman_mse 0.5 200: Weighted 0.820029 (0.054853)\n",
      "0.01 5 6 3 log2 friedman_mse 0.5 200: Macro 0.709358 (0.082393)\n",
      "Testing 1156/5184\n",
      "0.01 5 6 3 log2 friedman_mse 0.5 500: Weighted 0.815301 (0.062073)\n",
      "0.01 5 6 3 log2 friedman_mse 0.5 500: Macro 0.710520 (0.081319)\n",
      "Testing 1157/5184\n",
      "0.01 5 6 3 log2 friedman_mse 0.75 50: Weighted 0.807779 (0.068660)\n",
      "0.01 5 6 3 log2 friedman_mse 0.75 50: Macro 0.697766 (0.093394)\n",
      "Testing 1158/5184\n",
      "0.01 5 6 3 log2 friedman_mse 0.75 100: Weighted 0.811215 (0.068096)\n",
      "0.01 5 6 3 log2 friedman_mse 0.75 100: Macro 0.702791 (0.092636)\n",
      "Testing 1159/5184\n",
      "0.01 5 6 3 log2 friedman_mse 0.75 200: Weighted 0.815390 (0.061706)\n",
      "0.01 5 6 3 log2 friedman_mse 0.75 200: Macro 0.712100 (0.078209)\n",
      "Testing 1160/5184\n",
      "0.01 5 6 3 log2 friedman_mse 0.75 500: Weighted 0.819915 (0.072088)\n",
      "0.01 5 6 3 log2 friedman_mse 0.75 500: Macro 0.718850 (0.094310)\n",
      "Testing 1161/5184\n",
      "0.01 5 6 3 log2 friedman_mse 1.0 50: Weighted 0.815571 (0.061789)\n",
      "0.01 5 6 3 log2 friedman_mse 1.0 50: Macro 0.711176 (0.077719)\n",
      "Testing 1162/5184\n",
      "0.01 5 6 3 log2 friedman_mse 1.0 100: Weighted 0.807779 (0.068660)\n",
      "0.01 5 6 3 log2 friedman_mse 1.0 100: Macro 0.697766 (0.093394)\n",
      "Testing 1163/5184\n",
      "0.01 5 6 3 log2 friedman_mse 1.0 200: Weighted 0.801229 (0.060856)\n",
      "0.01 5 6 3 log2 friedman_mse 1.0 200: Macro 0.688441 (0.081258)\n",
      "Testing 1164/5184\n",
      "0.01 5 6 3 log2 friedman_mse 1.0 500: Weighted 0.800251 (0.079109)\n",
      "0.01 5 6 3 log2 friedman_mse 1.0 500: Macro 0.698080 (0.100898)\n",
      "Testing 1165/5184\n",
      "0.01 5 6 3 log2 mae 0.5 50: Weighted 0.806742 (0.053784)\n",
      "0.01 5 6 3 log2 mae 0.5 50: Macro 0.697698 (0.075603)\n",
      "Testing 1166/5184\n",
      "0.01 5 6 3 log2 mae 0.5 100: Weighted 0.824934 (0.057429)\n",
      "0.01 5 6 3 log2 mae 0.5 100: Macro 0.719892 (0.080356)\n",
      "Testing 1167/5184\n",
      "0.01 5 6 3 log2 mae 0.5 200: Weighted 0.828814 (0.051889)\n",
      "0.01 5 6 3 log2 mae 0.5 200: Macro 0.720644 (0.079229)\n",
      "Testing 1168/5184\n",
      "0.01 5 6 3 log2 mae 0.5 500: Weighted 0.813537 (0.066795)\n",
      "0.01 5 6 3 log2 mae 0.5 500: Macro 0.702508 (0.095036)\n",
      "Testing 1169/5184\n",
      "0.01 5 6 3 log2 mae 0.75 50: Weighted 0.812663 (0.055670)\n",
      "0.01 5 6 3 log2 mae 0.75 50: Macro 0.701497 (0.082956)\n",
      "Testing 1170/5184\n",
      "0.01 5 6 3 log2 mae 0.75 100: Weighted 0.798133 (0.067247)\n",
      "0.01 5 6 3 log2 mae 0.75 100: Macro 0.683073 (0.089082)\n",
      "Testing 1171/5184\n",
      "0.01 5 6 3 log2 mae 0.75 200: Weighted 0.799100 (0.068427)\n",
      "0.01 5 6 3 log2 mae 0.75 200: Macro 0.683225 (0.092738)\n",
      "Testing 1172/5184\n",
      "0.01 5 6 3 log2 mae 0.75 500: Weighted 0.796388 (0.074246)\n",
      "0.01 5 6 3 log2 mae 0.75 500: Macro 0.677030 (0.103029)\n",
      "Testing 1173/5184\n",
      "0.01 5 6 3 log2 mae 1.0 50: Weighted 0.794454 (0.067044)\n",
      "0.01 5 6 3 log2 mae 1.0 50: Macro 0.678905 (0.089202)\n",
      "Testing 1174/5184\n",
      "0.01 5 6 3 log2 mae 1.0 100: Weighted 0.787313 (0.068496)\n",
      "0.01 5 6 3 log2 mae 1.0 100: Macro 0.668999 (0.091132)\n",
      "Testing 1175/5184\n",
      "0.01 5 6 3 log2 mae 1.0 200: Weighted 0.796118 (0.065937)\n",
      "0.01 5 6 3 log2 mae 1.0 200: Macro 0.681049 (0.089482)\n",
      "Testing 1176/5184\n",
      "0.01 5 6 3 log2 mae 1.0 500: Weighted 0.787211 (0.092360)\n",
      "0.01 5 6 3 log2 mae 1.0 500: Macro 0.658377 (0.135505)\n",
      "Testing 1177/5184\n",
      "0.01 5 6 3 sqrt friedman_mse 0.5 50: Weighted 0.828826 (0.054953)\n",
      "0.01 5 6 3 sqrt friedman_mse 0.5 50: Macro 0.725841 (0.077289)\n",
      "Testing 1178/5184\n",
      "0.01 5 6 3 sqrt friedman_mse 0.5 100: Weighted 0.810158 (0.055065)\n",
      "0.01 5 6 3 sqrt friedman_mse 0.5 100: Macro 0.697860 (0.079962)\n",
      "Testing 1179/5184\n",
      "0.01 5 6 3 sqrt friedman_mse 0.5 200: Weighted 0.810555 (0.047435)\n",
      "0.01 5 6 3 sqrt friedman_mse 0.5 200: Macro 0.701445 (0.061499)\n",
      "Testing 1180/5184\n",
      "0.01 5 6 3 sqrt friedman_mse 0.5 500: Weighted 0.815306 (0.074194)\n",
      "0.01 5 6 3 sqrt friedman_mse 0.5 500: Macro 0.708223 (0.104257)\n",
      "Testing 1181/5184\n",
      "0.01 5 6 3 sqrt friedman_mse 0.75 50: Weighted 0.816644 (0.056356)\n",
      "0.01 5 6 3 sqrt friedman_mse 0.75 50: Macro 0.709518 (0.074446)\n",
      "Testing 1182/5184\n",
      "0.01 5 6 3 sqrt friedman_mse 0.75 100: Weighted 0.815571 (0.061789)\n",
      "0.01 5 6 3 sqrt friedman_mse 0.75 100: Macro 0.711176 (0.077719)\n",
      "Testing 1183/5184\n",
      "0.01 5 6 3 sqrt friedman_mse 0.75 200: Weighted 0.806695 (0.063078)\n",
      "0.01 5 6 3 sqrt friedman_mse 0.75 200: Macro 0.695979 (0.085719)\n",
      "Testing 1184/5184\n",
      "0.01 5 6 3 sqrt friedman_mse 0.75 500: Weighted 0.819915 (0.072088)\n",
      "0.01 5 6 3 sqrt friedman_mse 0.75 500: Macro 0.718850 (0.094310)\n",
      "Testing 1185/5184\n",
      "0.01 5 6 3 sqrt friedman_mse 1.0 50: Weighted 0.803259 (0.063443)\n",
      "0.01 5 6 3 sqrt friedman_mse 1.0 50: Macro 0.695006 (0.079873)\n",
      "Testing 1186/5184\n",
      "0.01 5 6 3 sqrt friedman_mse 1.0 100: Weighted 0.799682 (0.067616)\n",
      "0.01 5 6 3 sqrt friedman_mse 1.0 100: Macro 0.684741 (0.090578)\n",
      "Testing 1187/5184\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01 5 6 3 sqrt friedman_mse 1.0 200: Weighted 0.801164 (0.062389)\n",
      "0.01 5 6 3 sqrt friedman_mse 1.0 200: Macro 0.688033 (0.081002)\n",
      "Testing 1188/5184\n",
      "0.01 5 6 3 sqrt friedman_mse 1.0 500: Weighted 0.808920 (0.077890)\n",
      "0.01 5 6 3 sqrt friedman_mse 1.0 500: Macro 0.710476 (0.098853)\n",
      "Testing 1189/5184\n",
      "0.01 5 6 3 sqrt mae 0.5 50: Weighted 0.809679 (0.060544)\n",
      "0.01 5 6 3 sqrt mae 0.5 50: Macro 0.697604 (0.082947)\n",
      "Testing 1190/5184\n",
      "0.01 5 6 3 sqrt mae 0.5 100: Weighted 0.817632 (0.052880)\n",
      "0.01 5 6 3 sqrt mae 0.5 100: Macro 0.707973 (0.072913)\n",
      "Testing 1191/5184\n",
      "0.01 5 6 3 sqrt mae 0.5 200: Weighted 0.824584 (0.048793)\n",
      "0.01 5 6 3 sqrt mae 0.5 200: Macro 0.717955 (0.067713)\n",
      "Testing 1192/5184\n",
      "0.01 5 6 3 sqrt mae 0.5 500: Weighted 0.821452 (0.058967)\n",
      "0.01 5 6 3 sqrt mae 0.5 500: Macro 0.710767 (0.088146)\n",
      "Testing 1193/5184\n",
      "0.01 5 6 3 sqrt mae 0.75 50: Weighted 0.803619 (0.062890)\n",
      "0.01 5 6 3 sqrt mae 0.75 50: Macro 0.689303 (0.088728)\n",
      "Testing 1194/5184\n",
      "0.01 5 6 3 sqrt mae 0.75 100: Weighted 0.791181 (0.067601)\n",
      "0.01 5 6 3 sqrt mae 0.75 100: Macro 0.673091 (0.089278)\n",
      "Testing 1195/5184\n",
      "0.01 5 6 3 sqrt mae 0.75 200: Weighted 0.806751 (0.065765)\n",
      "0.01 5 6 3 sqrt mae 0.75 200: Macro 0.693929 (0.091948)\n",
      "Testing 1196/5184\n",
      "0.01 5 6 3 sqrt mae 0.75 500: Weighted 0.796388 (0.074246)\n",
      "0.01 5 6 3 sqrt mae 0.75 500: Macro 0.677030 (0.103029)\n",
      "Testing 1197/5184\n",
      "0.01 5 6 3 sqrt mae 1.0 50: Weighted 0.798993 (0.067297)\n",
      "0.01 5 6 3 sqrt mae 1.0 50: Macro 0.688802 (0.090539)\n",
      "Testing 1198/5184\n",
      "0.01 5 6 3 sqrt mae 1.0 100: Weighted 0.782527 (0.071511)\n",
      "0.01 5 6 3 sqrt mae 1.0 100: Macro 0.664052 (0.093234)\n",
      "Testing 1199/5184\n",
      "0.01 5 6 3 sqrt mae 1.0 200: Weighted 0.782882 (0.070482)\n",
      "0.01 5 6 3 sqrt mae 1.0 200: Macro 0.659093 (0.096135)\n",
      "Testing 1200/5184\n",
      "0.01 5 6 3 sqrt mae 1.0 500: Weighted 0.791833 (0.086346)\n",
      "0.01 5 6 3 sqrt mae 1.0 500: Macro 0.664405 (0.130487)\n",
      "Testing 1201/5184\n",
      "0.01 5 6 5 log2 friedman_mse 0.5 50: Weighted 0.816866 (0.048945)\n",
      "0.01 5 6 5 log2 friedman_mse 0.5 50: Macro 0.708930 (0.071902)\n",
      "Testing 1202/5184\n",
      "0.01 5 6 5 log2 friedman_mse 0.5 100: Weighted 0.810745 (0.066444)\n",
      "0.01 5 6 5 log2 friedman_mse 0.5 100: Macro 0.702718 (0.094834)\n",
      "Testing 1203/5184\n",
      "0.01 5 6 5 log2 friedman_mse 0.5 200: Weighted 0.813412 (0.059639)\n",
      "0.01 5 6 5 log2 friedman_mse 0.5 200: Macro 0.704875 (0.084783)\n",
      "Testing 1204/5184\n",
      "0.01 5 6 5 log2 friedman_mse 0.5 500: Weighted 0.819853 (0.080167)\n",
      "0.01 5 6 5 log2 friedman_mse 0.5 500: Macro 0.715039 (0.115718)\n",
      "Testing 1205/5184\n",
      "0.01 5 6 5 log2 friedman_mse 0.75 50: Weighted 0.807669 (0.064192)\n",
      "0.01 5 6 5 log2 friedman_mse 0.75 50: Macro 0.696130 (0.090261)\n",
      "Testing 1206/5184\n",
      "0.01 5 6 5 log2 friedman_mse 0.75 100: Weighted 0.806410 (0.060612)\n",
      "0.01 5 6 5 log2 friedman_mse 0.75 100: Macro 0.694084 (0.084866)\n",
      "Testing 1207/5184\n",
      "0.01 5 6 5 log2 friedman_mse 0.75 200: Weighted 0.802133 (0.054619)\n",
      "0.01 5 6 5 log2 friedman_mse 0.75 200: Macro 0.686416 (0.076064)\n",
      "Testing 1208/5184\n",
      "0.01 5 6 5 log2 friedman_mse 0.75 500: Weighted 0.809126 (0.075831)\n",
      "0.01 5 6 5 log2 friedman_mse 0.75 500: Macro 0.696154 (0.107404)\n",
      "Testing 1209/5184\n",
      "0.01 5 6 5 log2 friedman_mse 1.0 50: Weighted 0.793029 (0.071389)\n",
      "0.01 5 6 5 log2 friedman_mse 1.0 50: Macro 0.678843 (0.094869)\n",
      "Testing 1210/5184\n",
      "0.01 5 6 5 log2 friedman_mse 1.0 100: Weighted 0.791305 (0.059259)\n",
      "0.01 5 6 5 log2 friedman_mse 1.0 100: Macro 0.678408 (0.079213)\n",
      "Testing 1211/5184\n",
      "0.01 5 6 5 log2 friedman_mse 1.0 200: Weighted 0.789600 (0.057283)\n",
      "0.01 5 6 5 log2 friedman_mse 1.0 200: Macro 0.677797 (0.073248)\n",
      "Testing 1212/5184\n",
      "0.01 5 6 5 log2 friedman_mse 1.0 500: Weighted 0.811045 (0.089787)\n",
      "0.01 5 6 5 log2 friedman_mse 1.0 500: Macro 0.711184 (0.125485)\n",
      "Testing 1213/5184\n",
      "0.01 5 6 5 log2 mae 0.5 50: Weighted 0.808862 (0.061480)\n",
      "0.01 5 6 5 log2 mae 0.5 50: Macro 0.693825 (0.087564)\n",
      "Testing 1214/5184\n",
      "0.01 5 6 5 log2 mae 0.5 100: Weighted 0.822311 (0.055757)\n",
      "0.01 5 6 5 log2 mae 0.5 100: Macro 0.715331 (0.078193)\n",
      "Testing 1215/5184\n",
      "0.01 5 6 5 log2 mae 0.5 200: Weighted 0.805234 (0.065840)\n",
      "0.01 5 6 5 log2 mae 0.5 200: Macro 0.690202 (0.092209)\n",
      "Testing 1216/5184\n",
      "0.01 5 6 5 log2 mae 0.5 500: Weighted 0.804683 (0.072895)\n",
      "0.01 5 6 5 log2 mae 0.5 500: Macro 0.687388 (0.105088)\n",
      "Testing 1217/5184\n",
      "0.01 5 6 5 log2 mae 0.75 50: Weighted 0.791135 (0.064917)\n",
      "0.01 5 6 5 log2 mae 0.75 50: Macro 0.666102 (0.091937)\n",
      "Testing 1218/5184\n",
      "0.01 5 6 5 log2 mae 0.75 100: Weighted 0.796041 (0.066528)\n",
      "0.01 5 6 5 log2 mae 0.75 100: Macro 0.673153 (0.094870)\n",
      "Testing 1219/5184\n",
      "0.01 5 6 5 log2 mae 0.75 200: Weighted 0.790613 (0.064941)\n",
      "0.01 5 6 5 log2 mae 0.75 200: Macro 0.666608 (0.091049)\n",
      "Testing 1220/5184\n",
      "0.01 5 6 5 log2 mae 0.75 500: Weighted 0.782724 (0.079160)\n",
      "0.01 5 6 5 log2 mae 0.75 500: Macro 0.649082 (0.117769)\n",
      "Testing 1221/5184\n",
      "0.01 5 6 5 log2 mae 1.0 50: Weighted 0.783456 (0.082050)\n",
      "0.01 5 6 5 log2 mae 1.0 50: Macro 0.655419 (0.116703)\n",
      "Testing 1222/5184\n",
      "0.01 5 6 5 log2 mae 1.0 100: Weighted 0.790150 (0.072600)\n",
      "0.01 5 6 5 log2 mae 1.0 100: Macro 0.662978 (0.104213)\n",
      "Testing 1223/5184\n",
      "0.01 5 6 5 log2 mae 1.0 200: Weighted 0.782730 (0.078768)\n",
      "0.01 5 6 5 log2 mae 1.0 200: Macro 0.649075 (0.117555)\n",
      "Testing 1224/5184\n",
      "0.01 5 6 5 log2 mae 1.0 500: Weighted 0.786442 (0.091639)\n",
      "0.01 5 6 5 log2 mae 1.0 500: Macro 0.658620 (0.133990)\n",
      "Testing 1225/5184\n",
      "0.01 5 6 5 sqrt friedman_mse 0.5 50: Weighted 0.814178 (0.057610)\n",
      "0.01 5 6 5 sqrt friedman_mse 0.5 50: Macro 0.710815 (0.073898)\n",
      "Testing 1226/5184\n",
      "0.01 5 6 5 sqrt friedman_mse 0.5 100: Weighted 0.819018 (0.061045)\n",
      "0.01 5 6 5 sqrt friedman_mse 0.5 100: Macro 0.711215 (0.087388)\n",
      "Testing 1227/5184\n",
      "0.01 5 6 5 sqrt friedman_mse 0.5 200: Weighted 0.827039 (0.072379)\n",
      "0.01 5 6 5 sqrt friedman_mse 0.5 200: Macro 0.726272 (0.104156)\n",
      "Testing 1228/5184\n",
      "0.01 5 6 5 sqrt friedman_mse 0.5 500: Weighted 0.822286 (0.076026)\n",
      "0.01 5 6 5 sqrt friedman_mse 0.5 500: Macro 0.718772 (0.108039)\n",
      "Testing 1229/5184\n",
      "0.01 5 6 5 sqrt friedman_mse 0.75 50: Weighted 0.806653 (0.060685)\n",
      "0.01 5 6 5 sqrt friedman_mse 0.75 50: Macro 0.693228 (0.084556)\n",
      "Testing 1230/5184\n",
      "0.01 5 6 5 sqrt friedman_mse 0.75 100: Weighted 0.809920 (0.059820)\n",
      "0.01 5 6 5 sqrt friedman_mse 0.75 100: Macro 0.699375 (0.084309)\n",
      "Testing 1231/5184\n",
      "0.01 5 6 5 sqrt friedman_mse 0.75 200: Weighted 0.809264 (0.048155)\n",
      "0.01 5 6 5 sqrt friedman_mse 0.75 200: Macro 0.697349 (0.068693)\n",
      "Testing 1232/5184\n",
      "0.01 5 6 5 sqrt friedman_mse 0.75 500: Weighted 0.817083 (0.079619)\n",
      "0.01 5 6 5 sqrt friedman_mse 0.75 500: Macro 0.716383 (0.112566)\n",
      "Testing 1233/5184\n",
      "0.01 5 6 5 sqrt friedman_mse 1.0 50: Weighted 0.797010 (0.065737)\n",
      "0.01 5 6 5 sqrt friedman_mse 1.0 50: Macro 0.683682 (0.087741)\n",
      "Testing 1234/5184\n",
      "0.01 5 6 5 sqrt friedman_mse 1.0 100: Weighted 0.795825 (0.065642)\n",
      "0.01 5 6 5 sqrt friedman_mse 1.0 100: Macro 0.685219 (0.088022)\n",
      "Testing 1235/5184\n",
      "0.01 5 6 5 sqrt friedman_mse 1.0 200: Weighted 0.794723 (0.058819)\n",
      "0.01 5 6 5 sqrt friedman_mse 1.0 200: Macro 0.685331 (0.076970)\n",
      "Testing 1236/5184\n",
      "0.01 5 6 5 sqrt friedman_mse 1.0 500: Weighted 0.801951 (0.091573)\n",
      "0.01 5 6 5 sqrt friedman_mse 1.0 500: Macro 0.699112 (0.126214)\n",
      "Testing 1237/5184\n",
      "0.01 5 6 5 sqrt mae 0.5 50: Weighted 0.821323 (0.059143)\n",
      "0.01 5 6 5 sqrt mae 0.5 50: Macro 0.716876 (0.079481)\n",
      "Testing 1238/5184\n",
      "0.01 5 6 5 sqrt mae 0.5 100: Weighted 0.821754 (0.048567)\n",
      "0.01 5 6 5 sqrt mae 0.5 100: Macro 0.713267 (0.066915)\n",
      "Testing 1239/5184\n",
      "0.01 5 6 5 sqrt mae 0.5 200: Weighted 0.805234 (0.065840)\n",
      "0.01 5 6 5 sqrt mae 0.5 200: Macro 0.690202 (0.092209)\n",
      "Testing 1240/5184\n",
      "0.01 5 6 5 sqrt mae 0.5 500: Weighted 0.808261 (0.069226)\n",
      "0.01 5 6 5 sqrt mae 0.5 500: Macro 0.692030 (0.100404)\n",
      "Testing 1241/5184\n",
      "0.01 5 6 5 sqrt mae 0.75 50: Weighted 0.791177 (0.070429)\n",
      "0.01 5 6 5 sqrt mae 0.75 50: Macro 0.669025 (0.099688)\n",
      "Testing 1242/5184\n",
      "0.01 5 6 5 sqrt mae 0.75 100: Weighted 0.799682 (0.067616)\n",
      "0.01 5 6 5 sqrt mae 0.75 100: Macro 0.684741 (0.090578)\n",
      "Testing 1243/5184\n",
      "0.01 5 6 5 sqrt mae 0.75 200: Weighted 0.801471 (0.068531)\n",
      "0.01 5 6 5 sqrt mae 0.75 200: Macro 0.685211 (0.095459)\n",
      "Testing 1244/5184\n",
      "0.01 5 6 5 sqrt mae 0.75 500: Weighted 0.791874 (0.077366)\n",
      "0.01 5 6 5 sqrt mae 0.75 500: Macro 0.666425 (0.112693)\n",
      "Testing 1245/5184\n",
      "0.01 5 6 5 sqrt mae 1.0 50: Weighted 0.774756 (0.064115)\n",
      "0.01 5 6 5 sqrt mae 1.0 50: Macro 0.642959 (0.091346)\n",
      "Testing 1246/5184\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01 5 6 5 sqrt mae 1.0 100: Weighted 0.790785 (0.072619)\n",
      "0.01 5 6 5 sqrt mae 1.0 100: Macro 0.663930 (0.105675)\n",
      "Testing 1247/5184\n",
      "0.01 5 6 5 sqrt mae 1.0 200: Weighted 0.782878 (0.086747)\n",
      "0.01 5 6 5 sqrt mae 1.0 200: Macro 0.651316 (0.127695)\n",
      "Testing 1248/5184\n",
      "0.01 5 6 5 sqrt mae 1.0 500: Weighted 0.783182 (0.076385)\n",
      "0.01 5 6 5 sqrt mae 1.0 500: Macro 0.652731 (0.113130)\n",
      "Testing 1249/5184\n",
      "0.01 5 6 8 log2 friedman_mse 0.5 50: Weighted 0.827046 (0.054065)\n",
      "0.01 5 6 8 log2 friedman_mse 0.5 50: Macro 0.727407 (0.072436)\n",
      "Testing 1250/5184\n",
      "0.01 5 6 8 log2 friedman_mse 0.5 100: Weighted 0.812404 (0.054710)\n",
      "0.01 5 6 8 log2 friedman_mse 0.5 100: Macro 0.705561 (0.076965)\n",
      "Testing 1251/5184\n",
      "0.01 5 6 8 log2 friedman_mse 0.5 200: Weighted 0.822195 (0.049353)\n",
      "0.01 5 6 8 log2 friedman_mse 0.5 200: Macro 0.723644 (0.066775)\n",
      "Testing 1252/5184\n",
      "0.01 5 6 8 log2 friedman_mse 0.5 500: Weighted 0.826704 (0.077055)\n",
      "0.01 5 6 8 log2 friedman_mse 0.5 500: Macro 0.721358 (0.114438)\n",
      "Testing 1253/5184\n",
      "0.01 5 6 8 log2 friedman_mse 0.75 50: Weighted 0.808749 (0.059357)\n",
      "0.01 5 6 8 log2 friedman_mse 0.75 50: Macro 0.696967 (0.083914)\n",
      "Testing 1254/5184\n",
      "0.01 5 6 8 log2 friedman_mse 0.75 100: Weighted 0.810578 (0.051534)\n",
      "0.01 5 6 8 log2 friedman_mse 0.75 100: Macro 0.699269 (0.073736)\n",
      "Testing 1255/5184\n",
      "0.01 5 6 8 log2 friedman_mse 0.75 200: Weighted 0.809264 (0.048155)\n",
      "0.01 5 6 8 log2 friedman_mse 0.75 200: Macro 0.697349 (0.068693)\n",
      "Testing 1256/5184\n",
      "0.01 5 6 8 log2 friedman_mse 0.75 500: Weighted 0.829140 (0.089821)\n",
      "0.01 5 6 8 log2 friedman_mse 0.75 500: Macro 0.735324 (0.133582)\n",
      "Testing 1257/5184\n",
      "0.01 5 6 8 log2 friedman_mse 1.0 50: Weighted 0.797010 (0.065737)\n",
      "0.01 5 6 8 log2 friedman_mse 1.0 50: Macro 0.683682 (0.087741)\n",
      "Testing 1258/5184\n",
      "0.01 5 6 8 log2 friedman_mse 1.0 100: Weighted 0.798959 (0.069385)\n",
      "0.01 5 6 8 log2 friedman_mse 1.0 100: Macro 0.692451 (0.090982)\n",
      "Testing 1259/5184\n",
      "0.01 5 6 8 log2 friedman_mse 1.0 200: Weighted 0.802045 (0.064064)\n",
      "0.01 5 6 8 log2 friedman_mse 1.0 200: Macro 0.697968 (0.083611)\n",
      "Testing 1260/5184\n",
      "0.01 5 6 8 log2 friedman_mse 1.0 500: Weighted 0.810517 (0.081041)\n",
      "0.01 5 6 8 log2 friedman_mse 1.0 500: Macro 0.716719 (0.106477)\n",
      "Testing 1261/5184\n",
      "0.01 5 6 8 log2 mae 0.5 50: Weighted 0.807206 (0.056855)\n",
      "0.01 5 6 8 log2 mae 0.5 50: Macro 0.685418 (0.084642)\n",
      "Testing 1262/5184\n",
      "0.01 5 6 8 log2 mae 0.5 100: Weighted 0.811713 (0.059371)\n",
      "0.01 5 6 8 log2 mae 0.5 100: Macro 0.699991 (0.083106)\n",
      "Testing 1263/5184\n",
      "0.01 5 6 8 log2 mae 0.5 200: Weighted 0.811715 (0.066043)\n",
      "0.01 5 6 8 log2 mae 0.5 200: Macro 0.696640 (0.096192)\n",
      "Testing 1264/5184\n",
      "0.01 5 6 8 log2 mae 0.5 500: Weighted 0.803527 (0.056055)\n",
      "0.01 5 6 8 log2 mae 0.5 500: Macro 0.687711 (0.077417)\n",
      "Testing 1265/5184\n",
      "0.01 5 6 8 log2 mae 0.75 50: Weighted 0.803863 (0.065752)\n",
      "0.01 5 6 8 log2 mae 0.75 50: Macro 0.685364 (0.093880)\n",
      "Testing 1266/5184\n",
      "0.01 5 6 8 log2 mae 0.75 100: Weighted 0.804666 (0.064927)\n",
      "0.01 5 6 8 log2 mae 0.75 100: Macro 0.685081 (0.094169)\n",
      "Testing 1267/5184\n",
      "0.01 5 6 8 log2 mae 0.75 200: Weighted 0.798853 (0.070912)\n",
      "0.01 5 6 8 log2 mae 0.75 200: Macro 0.673903 (0.106566)\n",
      "Testing 1268/5184\n",
      "0.01 5 6 8 log2 mae 0.75 500: Weighted 0.792335 (0.074075)\n",
      "0.01 5 6 8 log2 mae 0.75 500: Macro 0.663560 (0.108625)\n",
      "Testing 1269/5184\n",
      "0.01 5 6 8 log2 mae 1.0 50: Weighted 0.799969 (0.063541)\n",
      "0.01 5 6 8 log2 mae 1.0 50: Macro 0.679589 (0.089259)\n",
      "Testing 1270/5184\n",
      "0.01 5 6 8 log2 mae 1.0 100: Weighted 0.780116 (0.075044)\n",
      "0.01 5 6 8 log2 mae 1.0 100: Macro 0.645347 (0.110905)\n",
      "Testing 1271/5184\n",
      "0.01 5 6 8 log2 mae 1.0 200: Weighted 0.798616 (0.065155)\n",
      "0.01 5 6 8 log2 mae 1.0 200: Macro 0.671662 (0.098882)\n",
      "Testing 1272/5184\n",
      "0.01 5 6 8 log2 mae 1.0 500: Weighted 0.776500 (0.073992)\n",
      "0.01 5 6 8 log2 mae 1.0 500: Macro 0.638188 (0.107655)\n",
      "Testing 1273/5184\n",
      "0.01 5 6 8 sqrt friedman_mse 0.5 50: Weighted 0.812365 (0.059480)\n",
      "0.01 5 6 8 sqrt friedman_mse 0.5 50: Macro 0.706810 (0.085330)\n",
      "Testing 1274/5184\n",
      "0.01 5 6 8 sqrt friedman_mse 0.5 100: Weighted 0.813971 (0.041883)\n",
      "0.01 5 6 8 sqrt friedman_mse 0.5 100: Macro 0.706343 (0.053277)\n",
      "Testing 1275/5184\n",
      "0.01 5 6 8 sqrt friedman_mse 0.5 200: Weighted 0.817654 (0.057715)\n",
      "0.01 5 6 8 sqrt friedman_mse 0.5 200: Macro 0.716715 (0.074754)\n",
      "Testing 1276/5184\n",
      "0.01 5 6 8 sqrt friedman_mse 0.5 500: Weighted 0.826373 (0.072918)\n",
      "0.01 5 6 8 sqrt friedman_mse 0.5 500: Macro 0.720643 (0.106179)\n",
      "Testing 1277/5184\n",
      "0.01 5 6 8 sqrt friedman_mse 0.75 50: Weighted 0.801433 (0.072178)\n",
      "0.01 5 6 8 sqrt friedman_mse 0.75 50: Macro 0.690643 (0.097535)\n",
      "Testing 1278/5184\n",
      "0.01 5 6 8 sqrt friedman_mse 0.75 100: Weighted 0.815098 (0.057261)\n",
      "0.01 5 6 8 sqrt friedman_mse 0.75 100: Macro 0.706080 (0.081400)\n",
      "Testing 1279/5184\n",
      "0.01 5 6 8 sqrt friedman_mse 0.75 200: Weighted 0.810342 (0.052863)\n",
      "0.01 5 6 8 sqrt friedman_mse 0.75 200: Macro 0.703958 (0.067573)\n",
      "Testing 1280/5184\n",
      "0.01 5 6 8 sqrt friedman_mse 0.75 500: Weighted 0.814006 (0.081638)\n",
      "0.01 5 6 8 sqrt friedman_mse 0.75 500: Macro 0.711739 (0.115900)\n",
      "Testing 1281/5184\n",
      "0.01 5 6 8 sqrt friedman_mse 1.0 50: Weighted 0.795825 (0.065642)\n",
      "0.01 5 6 8 sqrt friedman_mse 1.0 50: Macro 0.685219 (0.088022)\n",
      "Testing 1282/5184\n",
      "0.01 5 6 8 sqrt friedman_mse 1.0 100: Weighted 0.804749 (0.061173)\n",
      "0.01 5 6 8 sqrt friedman_mse 1.0 100: Macro 0.697472 (0.083520)\n",
      "Testing 1283/5184\n",
      "0.01 5 6 8 sqrt friedman_mse 1.0 200: Weighted 0.792398 (0.064612)\n",
      "0.01 5 6 8 sqrt friedman_mse 1.0 200: Macro 0.687061 (0.082020)\n",
      "Testing 1284/5184\n",
      "0.01 5 6 8 sqrt friedman_mse 1.0 500: Weighted 0.810471 (0.068977)\n",
      "0.01 5 6 8 sqrt friedman_mse 1.0 500: Macro 0.716397 (0.096955)\n",
      "Testing 1285/5184\n",
      "0.01 5 6 8 sqrt mae 0.5 50: Weighted 0.819740 (0.051631)\n",
      "0.01 5 6 8 sqrt mae 0.5 50: Macro 0.708525 (0.076075)\n",
      "Testing 1286/5184\n",
      "0.01 5 6 8 sqrt mae 0.5 100: Weighted 0.809345 (0.068187)\n",
      "0.01 5 6 8 sqrt mae 0.5 100: Macro 0.692439 (0.100012)\n",
      "Testing 1287/5184\n",
      "0.01 5 6 8 sqrt mae 0.5 200: Weighted 0.804244 (0.066497)\n",
      "0.01 5 6 8 sqrt mae 0.5 200: Macro 0.684789 (0.095765)\n",
      "Testing 1288/5184\n",
      "0.01 5 6 8 sqrt mae 0.5 500: Weighted 0.811459 (0.068917)\n",
      "0.01 5 6 8 sqrt mae 0.5 500: Macro 0.696244 (0.099583)\n",
      "Testing 1289/5184\n",
      "0.01 5 6 8 sqrt mae 0.75 50: Weighted 0.807196 (0.051115)\n",
      "0.01 5 6 8 sqrt mae 0.75 50: Macro 0.696363 (0.066635)\n",
      "Testing 1290/5184\n",
      "0.01 5 6 8 sqrt mae 0.75 100: Weighted 0.795519 (0.066590)\n",
      "0.01 5 6 8 sqrt mae 0.75 100: Macro 0.673659 (0.093971)\n",
      "Testing 1291/5184\n",
      "0.01 5 6 8 sqrt mae 0.75 200: Weighted 0.795175 (0.067485)\n",
      "0.01 5 6 8 sqrt mae 0.75 200: Macro 0.667169 (0.101725)\n",
      "Testing 1292/5184\n",
      "0.01 5 6 8 sqrt mae 0.75 500: Weighted 0.791406 (0.077839)\n",
      "0.01 5 6 8 sqrt mae 0.75 500: Macro 0.669846 (0.109975)\n",
      "Testing 1293/5184\n",
      "0.01 5 6 8 sqrt mae 1.0 50: Weighted 0.793951 (0.068349)\n",
      "0.01 5 6 8 sqrt mae 1.0 50: Macro 0.667697 (0.099607)\n",
      "Testing 1294/5184\n",
      "0.01 5 6 8 sqrt mae 1.0 100: Weighted 0.782371 (0.072639)\n",
      "0.01 5 6 8 sqrt mae 1.0 100: Macro 0.646926 (0.109282)\n",
      "Testing 1295/5184\n",
      "0.01 5 6 8 sqrt mae 1.0 200: Weighted 0.787286 (0.082931)\n",
      "0.01 5 6 8 sqrt mae 1.0 200: Macro 0.656070 (0.123423)\n",
      "Testing 1296/5184\n",
      "0.01 5 6 8 sqrt mae 1.0 500: Weighted 0.788736 (0.082740)\n",
      "0.01 5 6 8 sqrt mae 1.0 500: Macro 0.655962 (0.122341)\n",
      "Testing 1297/5184\n",
      "0.05 1 2 3 log2 friedman_mse 0.5 50: Weighted 0.822868 (0.042689)\n",
      "0.05 1 2 3 log2 friedman_mse 0.5 50: Macro 0.722556 (0.051079)\n",
      "Testing 1298/5184\n",
      "0.05 1 2 3 log2 friedman_mse 0.5 100: Weighted 0.816247 (0.063024)\n",
      "0.05 1 2 3 log2 friedman_mse 0.5 100: Macro 0.720150 (0.091430)\n",
      "Testing 1299/5184\n",
      "0.05 1 2 3 log2 friedman_mse 0.5 200: Weighted 0.802207 (0.072811)\n",
      "0.05 1 2 3 log2 friedman_mse 0.5 200: Macro 0.700800 (0.104302)\n",
      "Testing 1300/5184\n",
      "0.05 1 2 3 log2 friedman_mse 0.5 500: Weighted 0.820029 (0.059449)\n",
      "0.05 1 2 3 log2 friedman_mse 0.5 500: Macro 0.721172 (0.091887)\n",
      "Testing 1301/5184\n",
      "0.05 1 2 3 log2 friedman_mse 0.75 50: Weighted 0.809397 (0.062157)\n",
      "0.05 1 2 3 log2 friedman_mse 0.75 50: Macro 0.706392 (0.075706)\n",
      "Testing 1302/5184\n",
      "0.05 1 2 3 log2 friedman_mse 0.75 100: Weighted 0.807120 (0.057847)\n",
      "0.05 1 2 3 log2 friedman_mse 0.75 100: Macro 0.708224 (0.075898)\n",
      "Testing 1303/5184\n",
      "0.05 1 2 3 log2 friedman_mse 0.75 200: Weighted 0.798968 (0.071440)\n",
      "0.05 1 2 3 log2 friedman_mse 0.75 200: Macro 0.699557 (0.105081)\n",
      "Testing 1304/5184\n",
      "0.05 1 2 3 log2 friedman_mse 0.75 500: Weighted 0.802186 (0.052977)\n",
      "0.05 1 2 3 log2 friedman_mse 0.75 500: Macro 0.703995 (0.084800)\n",
      "Testing 1305/5184\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05 1 2 3 log2 friedman_mse 1.0 50: Weighted 0.787801 (0.046706)\n",
      "0.05 1 2 3 log2 friedman_mse 1.0 50: Macro 0.678354 (0.064893)\n",
      "Testing 1306/5184\n",
      "0.05 1 2 3 log2 friedman_mse 1.0 100: Weighted 0.802218 (0.075237)\n",
      "0.05 1 2 3 log2 friedman_mse 1.0 100: Macro 0.697552 (0.101754)\n",
      "Testing 1307/5184\n",
      "0.05 1 2 3 log2 friedman_mse 1.0 200: Weighted 0.798620 (0.046925)\n",
      "0.05 1 2 3 log2 friedman_mse 1.0 200: Macro 0.695488 (0.077148)\n",
      "Testing 1308/5184\n",
      "0.05 1 2 3 log2 friedman_mse 1.0 500: Weighted 0.788623 (0.058444)\n",
      "0.05 1 2 3 log2 friedman_mse 1.0 500: Macro 0.680589 (0.095327)\n",
      "Testing 1309/5184\n",
      "0.05 1 2 3 log2 mae 0.5 50: Weighted 0.794907 (0.067420)\n",
      "0.05 1 2 3 log2 mae 0.5 50: Macro 0.674219 (0.094028)\n",
      "Testing 1310/5184\n",
      "0.05 1 2 3 log2 mae 0.5 100: Weighted 0.803940 (0.058812)\n",
      "0.05 1 2 3 log2 mae 0.5 100: Macro 0.687066 (0.081416)\n",
      "Testing 1311/5184\n",
      "0.05 1 2 3 log2 mae 0.5 200: Weighted 0.770638 (0.052471)\n",
      "0.05 1 2 3 log2 mae 0.5 200: Macro 0.648200 (0.075706)\n",
      "Testing 1312/5184\n",
      "0.05 1 2 3 log2 mae 0.5 500: Weighted 0.779886 (0.052753)\n",
      "0.05 1 2 3 log2 mae 0.5 500: Macro 0.650278 (0.082498)\n",
      "Testing 1313/5184\n",
      "0.05 1 2 3 log2 mae 0.75 50: Weighted 0.782159 (0.043581)\n",
      "0.05 1 2 3 log2 mae 0.75 50: Macro 0.670090 (0.061766)\n",
      "Testing 1314/5184\n",
      "0.05 1 2 3 log2 mae 0.75 100: Weighted 0.781889 (0.062610)\n",
      "0.05 1 2 3 log2 mae 0.75 100: Macro 0.664459 (0.082214)\n",
      "Testing 1315/5184\n",
      "0.05 1 2 3 log2 mae 0.75 200: Weighted 0.768869 (0.059756)\n",
      "0.05 1 2 3 log2 mae 0.75 200: Macro 0.643658 (0.090358)\n",
      "Testing 1316/5184\n",
      "0.05 1 2 3 log2 mae 0.75 500: Weighted 0.771534 (0.064763)\n",
      "0.05 1 2 3 log2 mae 0.75 500: Macro 0.640264 (0.095757)\n",
      "Testing 1317/5184\n",
      "0.05 1 2 3 log2 mae 1.0 50: Weighted 0.774800 (0.055476)\n",
      "0.05 1 2 3 log2 mae 1.0 50: Macro 0.655961 (0.081096)\n",
      "Testing 1318/5184\n",
      "0.05 1 2 3 log2 mae 1.0 100: Weighted 0.772573 (0.072456)\n",
      "0.05 1 2 3 log2 mae 1.0 100: Macro 0.654100 (0.100242)\n",
      "Testing 1319/5184\n",
      "0.05 1 2 3 log2 mae 1.0 200: Weighted 0.772615 (0.073762)\n",
      "0.05 1 2 3 log2 mae 1.0 200: Macro 0.647774 (0.107886)\n",
      "Testing 1320/5184\n",
      "0.05 1 2 3 log2 mae 1.0 500: Weighted 0.748208 (0.060538)\n",
      "0.05 1 2 3 log2 mae 1.0 500: Macro 0.603039 (0.087301)\n",
      "Testing 1321/5184\n",
      "0.05 1 2 3 sqrt friedman_mse 0.5 50: Weighted 0.824648 (0.074060)\n",
      "0.05 1 2 3 sqrt friedman_mse 0.5 50: Macro 0.722685 (0.106873)\n",
      "Testing 1322/5184\n",
      "0.05 1 2 3 sqrt friedman_mse 0.5 100: Weighted 0.813636 (0.060785)\n",
      "0.05 1 2 3 sqrt friedman_mse 0.5 100: Macro 0.714713 (0.082555)\n",
      "Testing 1323/5184\n",
      "0.05 1 2 3 sqrt friedman_mse 0.5 200: Weighted 0.821349 (0.070446)\n",
      "0.05 1 2 3 sqrt friedman_mse 0.5 200: Macro 0.726530 (0.105251)\n",
      "Testing 1324/5184\n",
      "0.05 1 2 3 sqrt friedman_mse 0.5 500: Weighted 0.792011 (0.053752)\n",
      "0.05 1 2 3 sqrt friedman_mse 0.5 500: Macro 0.683830 (0.086398)\n",
      "Testing 1325/5184\n",
      "0.05 1 2 3 sqrt friedman_mse 0.75 50: Weighted 0.803514 (0.064578)\n",
      "0.05 1 2 3 sqrt friedman_mse 0.75 50: Macro 0.692769 (0.082717)\n",
      "Testing 1326/5184\n",
      "0.05 1 2 3 sqrt friedman_mse 0.75 100: Weighted 0.787302 (0.062803)\n",
      "0.05 1 2 3 sqrt friedman_mse 0.75 100: Macro 0.685471 (0.095571)\n",
      "Testing 1327/5184\n",
      "0.05 1 2 3 sqrt friedman_mse 0.75 200: Weighted 0.791298 (0.068817)\n",
      "0.05 1 2 3 sqrt friedman_mse 0.75 200: Macro 0.683420 (0.103551)\n",
      "Testing 1328/5184\n",
      "0.05 1 2 3 sqrt friedman_mse 0.75 500: Weighted 0.801004 (0.068780)\n",
      "0.05 1 2 3 sqrt friedman_mse 0.75 500: Macro 0.697853 (0.106785)\n",
      "Testing 1329/5184\n",
      "0.05 1 2 3 sqrt friedman_mse 1.0 50: Weighted 0.784155 (0.044155)\n",
      "0.05 1 2 3 sqrt friedman_mse 1.0 50: Macro 0.669893 (0.060597)\n",
      "Testing 1330/5184\n",
      "0.05 1 2 3 sqrt friedman_mse 1.0 100: Weighted 0.790751 (0.062641)\n",
      "0.05 1 2 3 sqrt friedman_mse 1.0 100: Macro 0.684705 (0.094014)\n",
      "Testing 1331/5184\n",
      "0.05 1 2 3 sqrt friedman_mse 1.0 200: Weighted 0.792607 (0.044462)\n",
      "0.05 1 2 3 sqrt friedman_mse 1.0 200: Macro 0.690484 (0.071719)\n",
      "Testing 1332/5184\n",
      "0.05 1 2 3 sqrt friedman_mse 1.0 500: Weighted 0.796535 (0.048999)\n",
      "0.05 1 2 3 sqrt friedman_mse 1.0 500: Macro 0.690626 (0.081635)\n",
      "Testing 1333/5184\n",
      "0.05 1 2 3 sqrt mae 0.5 50: Weighted 0.804663 (0.065426)\n",
      "0.05 1 2 3 sqrt mae 0.5 50: Macro 0.689152 (0.091029)\n",
      "Testing 1334/5184\n",
      "0.05 1 2 3 sqrt mae 0.5 100: Weighted 0.799518 (0.052177)\n",
      "0.05 1 2 3 sqrt mae 0.5 100: Macro 0.687772 (0.071897)\n",
      "Testing 1335/5184\n",
      "0.05 1 2 3 sqrt mae 0.5 200: Weighted 0.772744 (0.047631)\n",
      "0.05 1 2 3 sqrt mae 0.5 200: Macro 0.654971 (0.070614)\n",
      "Testing 1336/5184\n",
      "0.05 1 2 3 sqrt mae 0.5 500: Weighted 0.779727 (0.070801)\n",
      "0.05 1 2 3 sqrt mae 0.5 500: Macro 0.658830 (0.106333)\n",
      "Testing 1337/5184\n",
      "0.05 1 2 3 sqrt mae 0.75 50: Weighted 0.785673 (0.065198)\n",
      "0.05 1 2 3 sqrt mae 0.75 50: Macro 0.666151 (0.092202)\n",
      "Testing 1338/5184\n",
      "0.05 1 2 3 sqrt mae 0.75 100: Weighted 0.784594 (0.062446)\n",
      "0.05 1 2 3 sqrt mae 0.75 100: Macro 0.672746 (0.088228)\n",
      "Testing 1339/5184\n",
      "0.05 1 2 3 sqrt mae 0.75 200: Weighted 0.765723 (0.065651)\n",
      "0.05 1 2 3 sqrt mae 0.75 200: Macro 0.644454 (0.100023)\n",
      "Testing 1340/5184\n",
      "0.05 1 2 3 sqrt mae 0.75 500: Weighted 0.754013 (0.059827)\n",
      "0.05 1 2 3 sqrt mae 0.75 500: Macro 0.618179 (0.083189)\n",
      "Testing 1341/5184\n",
      "0.05 1 2 3 sqrt mae 1.0 50: Weighted 0.778898 (0.063476)\n",
      "0.05 1 2 3 sqrt mae 1.0 50: Macro 0.665144 (0.078812)\n",
      "Testing 1342/5184\n",
      "0.05 1 2 3 sqrt mae 1.0 100: Weighted 0.771010 (0.070779)\n",
      "0.05 1 2 3 sqrt mae 1.0 100: Macro 0.657523 (0.101627)\n",
      "Testing 1343/5184\n",
      "0.05 1 2 3 sqrt mae 1.0 200: Weighted 0.752542 (0.060316)\n",
      "0.05 1 2 3 sqrt mae 1.0 200: Macro 0.612860 (0.088429)\n",
      "Testing 1344/5184\n",
      "0.05 1 2 3 sqrt mae 1.0 500: Weighted 0.762242 (0.071580)\n",
      "0.05 1 2 3 sqrt mae 1.0 500: Macro 0.621856 (0.102410)\n",
      "Testing 1345/5184\n",
      "0.05 1 2 5 log2 friedman_mse 0.5 50: Weighted 0.813994 (0.058399)\n",
      "0.05 1 2 5 log2 friedman_mse 0.5 50: Macro 0.709852 (0.084103)\n",
      "Testing 1346/5184\n",
      "0.05 1 2 5 log2 friedman_mse 0.5 100: Weighted 0.821434 (0.075282)\n",
      "0.05 1 2 5 log2 friedman_mse 0.5 100: Macro 0.720724 (0.106512)\n",
      "Testing 1347/5184\n",
      "0.05 1 2 5 log2 friedman_mse 0.5 200: Weighted 0.806067 (0.065680)\n",
      "0.05 1 2 5 log2 friedman_mse 0.5 200: Macro 0.706112 (0.091292)\n",
      "Testing 1348/5184\n",
      "0.05 1 2 5 log2 friedman_mse 0.5 500: Weighted 0.816178 (0.078595)\n",
      "0.05 1 2 5 log2 friedman_mse 0.5 500: Macro 0.716976 (0.119339)\n",
      "Testing 1349/5184\n",
      "0.05 1 2 5 log2 friedman_mse 0.75 50: Weighted 0.791046 (0.055841)\n",
      "0.05 1 2 5 log2 friedman_mse 0.75 50: Macro 0.680712 (0.080433)\n",
      "Testing 1350/5184\n",
      "0.05 1 2 5 log2 friedman_mse 0.75 100: Weighted 0.798304 (0.073145)\n",
      "0.05 1 2 5 log2 friedman_mse 0.75 100: Macro 0.687575 (0.099954)\n",
      "Testing 1351/5184\n",
      "0.05 1 2 5 log2 friedman_mse 0.75 200: Weighted 0.802716 (0.074489)\n",
      "0.05 1 2 5 log2 friedman_mse 0.75 200: Macro 0.703586 (0.114521)\n",
      "Testing 1352/5184\n",
      "0.05 1 2 5 log2 friedman_mse 0.75 500: Weighted 0.810102 (0.067559)\n",
      "0.05 1 2 5 log2 friedman_mse 0.75 500: Macro 0.704583 (0.098398)\n",
      "Testing 1353/5184\n",
      "0.05 1 2 5 log2 friedman_mse 1.0 50: Weighted 0.788870 (0.037413)\n",
      "0.05 1 2 5 log2 friedman_mse 1.0 50: Macro 0.682579 (0.062040)\n",
      "Testing 1354/5184\n",
      "0.05 1 2 5 log2 friedman_mse 1.0 100: Weighted 0.796750 (0.058690)\n",
      "0.05 1 2 5 log2 friedman_mse 1.0 100: Macro 0.695035 (0.095429)\n",
      "Testing 1355/5184\n",
      "0.05 1 2 5 log2 friedman_mse 1.0 200: Weighted 0.792223 (0.074868)\n",
      "0.05 1 2 5 log2 friedman_mse 1.0 200: Macro 0.688336 (0.120058)\n",
      "Testing 1356/5184\n",
      "0.05 1 2 5 log2 friedman_mse 1.0 500: Weighted 0.797418 (0.066673)\n",
      "0.05 1 2 5 log2 friedman_mse 1.0 500: Macro 0.699735 (0.105001)\n",
      "Testing 1357/5184\n",
      "0.05 1 2 5 log2 mae 0.5 50: Weighted 0.794203 (0.047031)\n",
      "0.05 1 2 5 log2 mae 0.5 50: Macro 0.678085 (0.065715)\n",
      "Testing 1358/5184\n",
      "0.05 1 2 5 log2 mae 0.5 100: Weighted 0.810675 (0.048035)\n",
      "0.05 1 2 5 log2 mae 0.5 100: Macro 0.700119 (0.059455)\n",
      "Testing 1359/5184\n",
      "0.05 1 2 5 log2 mae 0.5 200: Weighted 0.787736 (0.053690)\n",
      "0.05 1 2 5 log2 mae 0.5 200: Macro 0.661180 (0.084201)\n",
      "Testing 1360/5184\n",
      "0.05 1 2 5 log2 mae 0.5 500: Weighted 0.790888 (0.067774)\n",
      "0.05 1 2 5 log2 mae 0.5 500: Macro 0.670476 (0.103565)\n",
      "Testing 1361/5184\n",
      "0.05 1 2 5 log2 mae 0.75 50: Weighted 0.770479 (0.051724)\n",
      "0.05 1 2 5 log2 mae 0.75 50: Macro 0.651137 (0.074361)\n",
      "Testing 1362/5184\n",
      "0.05 1 2 5 log2 mae 0.75 100: Weighted 0.779203 (0.070307)\n",
      "0.05 1 2 5 log2 mae 0.75 100: Macro 0.660136 (0.103772)\n",
      "Testing 1363/5184\n",
      "0.05 1 2 5 log2 mae 0.75 200: Weighted 0.777906 (0.072116)\n",
      "0.05 1 2 5 log2 mae 0.75 200: Macro 0.644824 (0.106284)\n",
      "Testing 1364/5184\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05 1 2 5 log2 mae 0.75 500: Weighted 0.783897 (0.075705)\n",
      "0.05 1 2 5 log2 mae 0.75 500: Macro 0.659039 (0.111032)\n",
      "Testing 1365/5184\n",
      "0.05 1 2 5 log2 mae 1.0 50: Weighted 0.754803 (0.056551)\n",
      "0.05 1 2 5 log2 mae 1.0 50: Macro 0.622473 (0.090132)\n",
      "Testing 1366/5184\n",
      "0.05 1 2 5 log2 mae 1.0 100: Weighted 0.776304 (0.072737)\n",
      "0.05 1 2 5 log2 mae 1.0 100: Macro 0.648059 (0.108749)\n",
      "Testing 1367/5184\n",
      "0.05 1 2 5 log2 mae 1.0 200: Weighted 0.772538 (0.083666)\n",
      "0.05 1 2 5 log2 mae 1.0 200: Macro 0.642712 (0.122010)\n",
      "Testing 1368/5184\n",
      "0.05 1 2 5 log2 mae 1.0 500: Weighted 0.774454 (0.091676)\n",
      "0.05 1 2 5 log2 mae 1.0 500: Macro 0.634983 (0.127850)\n",
      "Testing 1369/5184\n",
      "0.05 1 2 5 sqrt friedman_mse 0.5 50: Weighted 0.810944 (0.063129)\n",
      "0.05 1 2 5 sqrt friedman_mse 0.5 50: Macro 0.693766 (0.091890)\n",
      "Testing 1370/5184\n",
      "0.05 1 2 5 sqrt friedman_mse 0.5 100: Weighted 0.816052 (0.072944)\n",
      "0.05 1 2 5 sqrt friedman_mse 0.5 100: Macro 0.722020 (0.105778)\n",
      "Testing 1371/5184\n",
      "0.05 1 2 5 sqrt friedman_mse 0.5 200: Weighted 0.821798 (0.079146)\n",
      "0.05 1 2 5 sqrt friedman_mse 0.5 200: Macro 0.724874 (0.110911)\n",
      "Testing 1372/5184\n",
      "0.05 1 2 5 sqrt friedman_mse 0.5 500: Weighted 0.812518 (0.073395)\n",
      "0.05 1 2 5 sqrt friedman_mse 0.5 500: Macro 0.716916 (0.104209)\n",
      "Testing 1373/5184\n",
      "0.05 1 2 5 sqrt friedman_mse 0.75 50: Weighted 0.806621 (0.070294)\n",
      "0.05 1 2 5 sqrt friedman_mse 0.75 50: Macro 0.697655 (0.095549)\n",
      "Testing 1374/5184\n",
      "0.05 1 2 5 sqrt friedman_mse 0.75 100: Weighted 0.808451 (0.080619)\n",
      "0.05 1 2 5 sqrt friedman_mse 0.75 100: Macro 0.702346 (0.113832)\n",
      "Testing 1375/5184\n",
      "0.05 1 2 5 sqrt friedman_mse 0.75 200: Weighted 0.809029 (0.087165)\n",
      "0.05 1 2 5 sqrt friedman_mse 0.75 200: Macro 0.708445 (0.122433)\n",
      "Testing 1376/5184\n",
      "0.05 1 2 5 sqrt friedman_mse 0.75 500: Weighted 0.809525 (0.077677)\n",
      "0.05 1 2 5 sqrt friedman_mse 0.75 500: Macro 0.697860 (0.114193)\n",
      "Testing 1377/5184\n",
      "0.05 1 2 5 sqrt friedman_mse 1.0 50: Weighted 0.789390 (0.059581)\n",
      "0.05 1 2 5 sqrt friedman_mse 1.0 50: Macro 0.683150 (0.087898)\n",
      "Testing 1378/5184\n",
      "0.05 1 2 5 sqrt friedman_mse 1.0 100: Weighted 0.802057 (0.065479)\n",
      "0.05 1 2 5 sqrt friedman_mse 1.0 100: Macro 0.699591 (0.101191)\n",
      "Testing 1379/5184\n",
      "0.05 1 2 5 sqrt friedman_mse 1.0 200: Weighted 0.790466 (0.085467)\n",
      "0.05 1 2 5 sqrt friedman_mse 1.0 200: Macro 0.683379 (0.131852)\n",
      "Testing 1380/5184\n",
      "0.05 1 2 5 sqrt friedman_mse 1.0 500: Weighted 0.788743 (0.077000)\n",
      "0.05 1 2 5 sqrt friedman_mse 1.0 500: Macro 0.683574 (0.123257)\n",
      "Testing 1381/5184\n",
      "0.05 1 2 5 sqrt mae 0.5 50: Weighted 0.797555 (0.055678)\n",
      "0.05 1 2 5 sqrt mae 0.5 50: Macro 0.685012 (0.077638)\n",
      "Testing 1382/5184\n",
      "0.05 1 2 5 sqrt mae 0.5 100: Weighted 0.794871 (0.055480)\n",
      "0.05 1 2 5 sqrt mae 0.5 100: Macro 0.682978 (0.081116)\n",
      "Testing 1383/5184\n",
      "0.05 1 2 5 sqrt mae 0.5 200: Weighted 0.786568 (0.053795)\n",
      "0.05 1 2 5 sqrt mae 0.5 200: Macro 0.668320 (0.075576)\n",
      "Testing 1384/5184\n",
      "0.05 1 2 5 sqrt mae 0.5 500: Weighted 0.790565 (0.060167)\n",
      "0.05 1 2 5 sqrt mae 0.5 500: Macro 0.671480 (0.094680)\n",
      "Testing 1385/5184\n",
      "0.05 1 2 5 sqrt mae 0.75 50: Weighted 0.779149 (0.053960)\n",
      "0.05 1 2 5 sqrt mae 0.75 50: Macro 0.662084 (0.075480)\n",
      "Testing 1386/5184\n",
      "0.05 1 2 5 sqrt mae 0.75 100: Weighted 0.779002 (0.052216)\n",
      "0.05 1 2 5 sqrt mae 0.75 100: Macro 0.660254 (0.075479)\n",
      "Testing 1387/5184\n",
      "0.05 1 2 5 sqrt mae 0.75 200: Weighted 0.767652 (0.074522)\n",
      "0.05 1 2 5 sqrt mae 0.75 200: Macro 0.634942 (0.106842)\n",
      "Testing 1388/5184\n",
      "0.05 1 2 5 sqrt mae 0.75 500: Weighted 0.786896 (0.078168)\n",
      "0.05 1 2 5 sqrt mae 0.75 500: Macro 0.663556 (0.118395)\n",
      "Testing 1389/5184\n",
      "0.05 1 2 5 sqrt mae 1.0 50: Weighted 0.768508 (0.045358)\n",
      "0.05 1 2 5 sqrt mae 1.0 50: Macro 0.638033 (0.069881)\n",
      "Testing 1390/5184\n",
      "0.05 1 2 5 sqrt mae 1.0 100: Weighted 0.784143 (0.074643)\n",
      "0.05 1 2 5 sqrt mae 1.0 100: Macro 0.666283 (0.112019)\n",
      "Testing 1391/5184\n",
      "0.05 1 2 5 sqrt mae 1.0 200: Weighted 0.774698 (0.081698)\n",
      "0.05 1 2 5 sqrt mae 1.0 200: Macro 0.647109 (0.110292)\n",
      "Testing 1392/5184\n",
      "0.05 1 2 5 sqrt mae 1.0 500: Weighted 0.756842 (0.054167)\n",
      "0.05 1 2 5 sqrt mae 1.0 500: Macro 0.620081 (0.071636)\n",
      "Testing 1393/5184\n",
      "0.05 1 2 8 log2 friedman_mse 0.5 50: Weighted 0.823904 (0.072916)\n",
      "0.05 1 2 8 log2 friedman_mse 0.5 50: Macro 0.725907 (0.101886)\n",
      "Testing 1394/5184\n",
      "0.05 1 2 8 log2 friedman_mse 0.5 100: Weighted 0.814331 (0.080808)\n",
      "0.05 1 2 8 log2 friedman_mse 0.5 100: Macro 0.705881 (0.119036)\n",
      "Testing 1395/5184\n",
      "0.05 1 2 8 log2 friedman_mse 0.5 200: Weighted 0.816683 (0.070807)\n",
      "0.05 1 2 8 log2 friedman_mse 0.5 200: Macro 0.708340 (0.099516)\n",
      "Testing 1396/5184\n",
      "0.05 1 2 8 log2 friedman_mse 0.5 500: Weighted 0.819723 (0.080791)\n",
      "0.05 1 2 8 log2 friedman_mse 0.5 500: Macro 0.719180 (0.117509)\n",
      "Testing 1397/5184\n",
      "0.05 1 2 8 log2 friedman_mse 0.75 50: Weighted 0.802724 (0.069045)\n",
      "0.05 1 2 8 log2 friedman_mse 0.75 50: Macro 0.693247 (0.095808)\n",
      "Testing 1398/5184\n",
      "0.05 1 2 8 log2 friedman_mse 0.75 100: Weighted 0.802683 (0.079830)\n",
      "0.05 1 2 8 log2 friedman_mse 0.75 100: Macro 0.694800 (0.110571)\n",
      "Testing 1399/5184\n",
      "0.05 1 2 8 log2 friedman_mse 0.75 200: Weighted 0.815270 (0.084964)\n",
      "0.05 1 2 8 log2 friedman_mse 0.75 200: Macro 0.715817 (0.120973)\n",
      "Testing 1400/5184\n",
      "0.05 1 2 8 log2 friedman_mse 0.75 500: Weighted 0.819492 (0.087542)\n",
      "0.05 1 2 8 log2 friedman_mse 0.75 500: Macro 0.724171 (0.124575)\n",
      "Testing 1401/5184\n",
      "0.05 1 2 8 log2 friedman_mse 1.0 50: Weighted 0.772748 (0.054967)\n",
      "0.05 1 2 8 log2 friedman_mse 1.0 50: Macro 0.653896 (0.085416)\n",
      "Testing 1402/5184\n",
      "0.05 1 2 8 log2 friedman_mse 1.0 100: Weighted 0.777892 (0.063891)\n",
      "0.05 1 2 8 log2 friedman_mse 1.0 100: Macro 0.664680 (0.096027)\n",
      "Testing 1403/5184\n",
      "0.05 1 2 8 log2 friedman_mse 1.0 200: Weighted 0.781342 (0.063934)\n",
      "0.05 1 2 8 log2 friedman_mse 1.0 200: Macro 0.667789 (0.098666)\n",
      "Testing 1404/5184\n",
      "0.05 1 2 8 log2 friedman_mse 1.0 500: Weighted 0.791888 (0.078188)\n",
      "0.05 1 2 8 log2 friedman_mse 1.0 500: Macro 0.679618 (0.109999)\n",
      "Testing 1405/5184\n",
      "0.05 1 2 8 log2 mae 0.5 50: Weighted 0.792780 (0.072826)\n",
      "0.05 1 2 8 log2 mae 0.5 50: Macro 0.676855 (0.102272)\n",
      "Testing 1406/5184\n",
      "0.05 1 2 8 log2 mae 0.5 100: Weighted 0.805453 (0.046236)\n",
      "0.05 1 2 8 log2 mae 0.5 100: Macro 0.696315 (0.071958)\n",
      "Testing 1407/5184\n",
      "0.05 1 2 8 log2 mae 0.5 200: Weighted 0.798747 (0.050819)\n",
      "0.05 1 2 8 log2 mae 0.5 200: Macro 0.686931 (0.076604)\n",
      "Testing 1408/5184\n",
      "0.05 1 2 8 log2 mae 0.5 500: Weighted 0.808041 (0.069222)\n",
      "0.05 1 2 8 log2 mae 0.5 500: Macro 0.697046 (0.112036)\n",
      "Testing 1409/5184\n",
      "0.05 1 2 8 log2 mae 0.75 50: Weighted 0.774341 (0.058552)\n",
      "0.05 1 2 8 log2 mae 0.75 50: Macro 0.646959 (0.086922)\n",
      "Testing 1410/5184\n",
      "0.05 1 2 8 log2 mae 0.75 100: Weighted 0.780918 (0.061327)\n",
      "0.05 1 2 8 log2 mae 0.75 100: Macro 0.660676 (0.092053)\n",
      "Testing 1411/5184\n",
      "0.05 1 2 8 log2 mae 0.75 200: Weighted 0.783480 (0.067108)\n",
      "0.05 1 2 8 log2 mae 0.75 200: Macro 0.660421 (0.100182)\n",
      "Testing 1412/5184\n",
      "0.05 1 2 8 log2 mae 0.75 500: Weighted 0.776902 (0.081693)\n",
      "0.05 1 2 8 log2 mae 0.75 500: Macro 0.658416 (0.113910)\n",
      "Testing 1413/5184\n",
      "0.05 1 2 8 log2 mae 1.0 50: Weighted 0.781918 (0.064888)\n",
      "0.05 1 2 8 log2 mae 1.0 50: Macro 0.657556 (0.096713)\n",
      "Testing 1414/5184\n",
      "0.05 1 2 8 log2 mae 1.0 100: Weighted 0.773694 (0.057985)\n",
      "0.05 1 2 8 log2 mae 1.0 100: Macro 0.648486 (0.083140)\n",
      "Testing 1415/5184\n",
      "0.05 1 2 8 log2 mae 1.0 200: Weighted 0.778591 (0.077538)\n",
      "0.05 1 2 8 log2 mae 1.0 200: Macro 0.656621 (0.097504)\n",
      "Testing 1416/5184\n",
      "0.05 1 2 8 log2 mae 1.0 500: Weighted 0.770684 (0.076960)\n",
      "0.05 1 2 8 log2 mae 1.0 500: Macro 0.646918 (0.096704)\n",
      "Testing 1417/5184\n",
      "0.05 1 2 8 sqrt friedman_mse 0.5 50: Weighted 0.806154 (0.072109)\n",
      "0.05 1 2 8 sqrt friedman_mse 0.5 50: Macro 0.702927 (0.096590)\n",
      "Testing 1418/5184\n",
      "0.05 1 2 8 sqrt friedman_mse 0.5 100: Weighted 0.813040 (0.064296)\n",
      "0.05 1 2 8 sqrt friedman_mse 0.5 100: Macro 0.714600 (0.096394)\n",
      "Testing 1419/5184\n",
      "0.05 1 2 8 sqrt friedman_mse 0.5 200: Weighted 0.816914 (0.079825)\n",
      "0.05 1 2 8 sqrt friedman_mse 0.5 200: Macro 0.713648 (0.115665)\n",
      "Testing 1420/5184\n",
      "0.05 1 2 8 sqrt friedman_mse 0.5 500: Weighted 0.820265 (0.076228)\n",
      "0.05 1 2 8 sqrt friedman_mse 0.5 500: Macro 0.719576 (0.111393)\n",
      "Testing 1421/5184\n",
      "0.05 1 2 8 sqrt friedman_mse 0.75 50: Weighted 0.801887 (0.070896)\n",
      "0.05 1 2 8 sqrt friedman_mse 0.75 50: Macro 0.700771 (0.095267)\n",
      "Testing 1422/5184\n",
      "0.05 1 2 8 sqrt friedman_mse 0.75 100: Weighted 0.811257 (0.072278)\n",
      "0.05 1 2 8 sqrt friedman_mse 0.75 100: Macro 0.713252 (0.105456)\n",
      "Testing 1423/5184\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05 1 2 8 sqrt friedman_mse 0.75 200: Weighted 0.815270 (0.084964)\n",
      "0.05 1 2 8 sqrt friedman_mse 0.75 200: Macro 0.715817 (0.120973)\n",
      "Testing 1424/5184\n",
      "0.05 1 2 8 sqrt friedman_mse 0.75 500: Weighted 0.800549 (0.078200)\n",
      "0.05 1 2 8 sqrt friedman_mse 0.75 500: Macro 0.693380 (0.118279)\n",
      "Testing 1425/5184\n",
      "0.05 1 2 8 sqrt friedman_mse 1.0 50: Weighted 0.787302 (0.060579)\n",
      "0.05 1 2 8 sqrt friedman_mse 1.0 50: Macro 0.673662 (0.097313)\n",
      "Testing 1426/5184\n",
      "0.05 1 2 8 sqrt friedman_mse 1.0 100: Weighted 0.787332 (0.065678)\n",
      "0.05 1 2 8 sqrt friedman_mse 1.0 100: Macro 0.675667 (0.100748)\n",
      "Testing 1427/5184\n",
      "0.05 1 2 8 sqrt friedman_mse 1.0 200: Weighted 0.773706 (0.051320)\n",
      "0.05 1 2 8 sqrt friedman_mse 1.0 200: Macro 0.668404 (0.081311)\n",
      "Testing 1428/5184\n",
      "0.05 1 2 8 sqrt friedman_mse 1.0 500: Weighted 0.794682 (0.068147)\n",
      "0.05 1 2 8 sqrt friedman_mse 1.0 500: Macro 0.680185 (0.097930)\n",
      "Testing 1429/5184\n",
      "0.05 1 2 8 sqrt mae 0.5 50: Weighted 0.792014 (0.068671)\n",
      "0.05 1 2 8 sqrt mae 0.5 50: Macro 0.676905 (0.095061)\n",
      "Testing 1430/5184\n",
      "0.05 1 2 8 sqrt mae 0.5 100: Weighted 0.794937 (0.046240)\n",
      "0.05 1 2 8 sqrt mae 0.5 100: Macro 0.679827 (0.071407)\n",
      "Testing 1431/5184\n",
      "0.05 1 2 8 sqrt mae 0.5 200: Weighted 0.800786 (0.058214)\n",
      "0.05 1 2 8 sqrt mae 0.5 200: Macro 0.686906 (0.092930)\n",
      "Testing 1432/5184\n",
      "0.05 1 2 8 sqrt mae 0.5 500: Weighted 0.804233 (0.063544)\n",
      "0.05 1 2 8 sqrt mae 0.5 500: Macro 0.696222 (0.095437)\n",
      "Testing 1433/5184\n",
      "0.05 1 2 8 sqrt mae 0.75 50: Weighted 0.782873 (0.076484)\n",
      "0.05 1 2 8 sqrt mae 0.75 50: Macro 0.665928 (0.112169)\n",
      "Testing 1434/5184\n",
      "0.05 1 2 8 sqrt mae 0.75 100: Weighted 0.784000 (0.049669)\n",
      "0.05 1 2 8 sqrt mae 0.75 100: Macro 0.660353 (0.074885)\n",
      "Testing 1435/5184\n",
      "0.05 1 2 8 sqrt mae 0.75 200: Weighted 0.780293 (0.071517)\n",
      "0.05 1 2 8 sqrt mae 0.75 200: Macro 0.663459 (0.103035)\n",
      "Testing 1436/5184\n",
      "0.05 1 2 8 sqrt mae 0.75 500: Weighted 0.777159 (0.071280)\n",
      "0.05 1 2 8 sqrt mae 0.75 500: Macro 0.655837 (0.102519)\n",
      "Testing 1437/5184\n",
      "0.05 1 2 8 sqrt mae 1.0 50: Weighted 0.768003 (0.051492)\n",
      "0.05 1 2 8 sqrt mae 1.0 50: Macro 0.638893 (0.088219)\n",
      "Testing 1438/5184\n",
      "0.05 1 2 8 sqrt mae 1.0 100: Weighted 0.767083 (0.071996)\n",
      "0.05 1 2 8 sqrt mae 1.0 100: Macro 0.640289 (0.108009)\n",
      "Testing 1439/5184\n",
      "0.05 1 2 8 sqrt mae 1.0 200: Weighted 0.793785 (0.082997)\n",
      "0.05 1 2 8 sqrt mae 1.0 200: Macro 0.671591 (0.123154)\n",
      "Testing 1440/5184\n",
      "0.05 1 2 8 sqrt mae 1.0 500: Weighted 0.792044 (0.085856)\n",
      "0.05 1 2 8 sqrt mae 1.0 500: Macro 0.677062 (0.110159)\n",
      "Testing 1441/5184\n",
      "0.05 1 4 3 log2 friedman_mse 0.5 50: Weighted 0.826871 (0.048163)\n",
      "0.05 1 4 3 log2 friedman_mse 0.5 50: Macro 0.720285 (0.062123)\n",
      "Testing 1442/5184\n",
      "0.05 1 4 3 log2 friedman_mse 0.5 100: Weighted 0.823369 (0.068552)\n",
      "0.05 1 4 3 log2 friedman_mse 0.5 100: Macro 0.723609 (0.091888)\n",
      "Testing 1443/5184\n",
      "0.05 1 4 3 log2 friedman_mse 0.5 200: Weighted 0.799807 (0.071561)\n",
      "0.05 1 4 3 log2 friedman_mse 0.5 200: Macro 0.692483 (0.110354)\n",
      "Testing 1444/5184\n",
      "0.05 1 4 3 log2 friedman_mse 0.5 500: Weighted 0.820403 (0.062614)\n",
      "0.05 1 4 3 log2 friedman_mse 0.5 500: Macro 0.724529 (0.098657)\n",
      "Testing 1445/5184\n",
      "0.05 1 4 3 log2 friedman_mse 0.75 50: Weighted 0.802658 (0.067796)\n",
      "0.05 1 4 3 log2 friedman_mse 0.75 50: Macro 0.696461 (0.085373)\n",
      "Testing 1446/5184\n",
      "0.05 1 4 3 log2 friedman_mse 0.75 100: Weighted 0.812588 (0.064423)\n",
      "0.05 1 4 3 log2 friedman_mse 0.75 100: Macro 0.713524 (0.086195)\n",
      "Testing 1447/5184\n",
      "0.05 1 4 3 log2 friedman_mse 0.75 200: Weighted 0.797515 (0.049761)\n",
      "0.05 1 4 3 log2 friedman_mse 0.75 200: Macro 0.693003 (0.074857)\n",
      "Testing 1448/5184\n",
      "0.05 1 4 3 log2 friedman_mse 0.75 500: Weighted 0.811176 (0.054628)\n",
      "0.05 1 4 3 log2 friedman_mse 0.75 500: Macro 0.719280 (0.078344)\n",
      "Testing 1449/5184\n",
      "0.05 1 4 3 log2 friedman_mse 1.0 50: Weighted 0.799986 (0.058547)\n",
      "0.05 1 4 3 log2 friedman_mse 1.0 50: Macro 0.693398 (0.066907)\n",
      "Testing 1450/5184\n",
      "0.05 1 4 3 log2 friedman_mse 1.0 100: Weighted 0.781373 (0.059273)\n",
      "0.05 1 4 3 log2 friedman_mse 1.0 100: Macro 0.676230 (0.089495)\n",
      "Testing 1451/5184\n",
      "0.05 1 4 3 log2 friedman_mse 1.0 200: Weighted 0.789599 (0.047169)\n",
      "0.05 1 4 3 log2 friedman_mse 1.0 200: Macro 0.686010 (0.074483)\n",
      "Testing 1452/5184\n",
      "0.05 1 4 3 log2 friedman_mse 1.0 500: Weighted 0.789797 (0.065214)\n",
      "0.05 1 4 3 log2 friedman_mse 1.0 500: Macro 0.684558 (0.103801)\n",
      "Testing 1453/5184\n",
      "0.05 1 4 3 log2 mae 0.5 50: Weighted 0.809429 (0.054379)\n",
      "0.05 1 4 3 log2 mae 0.5 50: Macro 0.704269 (0.066436)\n",
      "Testing 1454/5184\n",
      "0.05 1 4 3 log2 mae 0.5 100: Weighted 0.798259 (0.033440)\n",
      "0.05 1 4 3 log2 mae 0.5 100: Macro 0.688278 (0.049918)\n",
      "Testing 1455/5184\n",
      "0.05 1 4 3 log2 mae 0.5 200: Weighted 0.795870 (0.054279)\n",
      "0.05 1 4 3 log2 mae 0.5 200: Macro 0.679978 (0.077399)\n",
      "Testing 1456/5184\n",
      "0.05 1 4 3 log2 mae 0.5 500: Weighted 0.766385 (0.072149)\n",
      "0.05 1 4 3 log2 mae 0.5 500: Macro 0.638103 (0.104601)\n",
      "Testing 1457/5184\n",
      "0.05 1 4 3 log2 mae 0.75 50: Weighted 0.798196 (0.064964)\n",
      "0.05 1 4 3 log2 mae 0.75 50: Macro 0.678650 (0.090847)\n",
      "Testing 1458/5184\n",
      "0.05 1 4 3 log2 mae 0.75 100: Weighted 0.775773 (0.052912)\n",
      "0.05 1 4 3 log2 mae 0.75 100: Macro 0.658883 (0.075489)\n",
      "Testing 1459/5184\n",
      "0.05 1 4 3 log2 mae 0.75 200: Weighted 0.780374 (0.068984)\n",
      "0.05 1 4 3 log2 mae 0.75 200: Macro 0.654910 (0.103169)\n",
      "Testing 1460/5184\n",
      "0.05 1 4 3 log2 mae 0.75 500: Weighted 0.761518 (0.051184)\n",
      "0.05 1 4 3 log2 mae 0.75 500: Macro 0.629733 (0.077611)\n",
      "Testing 1461/5184\n",
      "0.05 1 4 3 log2 mae 1.0 50: Weighted 0.783696 (0.071367)\n",
      "0.05 1 4 3 log2 mae 1.0 50: Macro 0.669274 (0.089479)\n",
      "Testing 1462/5184\n",
      "0.05 1 4 3 log2 mae 1.0 100: Weighted 0.784990 (0.077310)\n",
      "0.05 1 4 3 log2 mae 1.0 100: Macro 0.669776 (0.105938)\n",
      "Testing 1463/5184\n",
      "0.05 1 4 3 log2 mae 1.0 200: Weighted 0.775949 (0.075076)\n",
      "0.05 1 4 3 log2 mae 1.0 200: Macro 0.645787 (0.113516)\n",
      "Testing 1464/5184\n",
      "0.05 1 4 3 log2 mae 1.0 500: Weighted 0.746650 (0.057022)\n",
      "0.05 1 4 3 log2 mae 1.0 500: Macro 0.597686 (0.079918)\n",
      "Testing 1465/5184\n",
      "0.05 1 4 3 sqrt friedman_mse 0.5 50: Weighted 0.814410 (0.059062)\n",
      "0.05 1 4 3 sqrt friedman_mse 0.5 50: Macro 0.717302 (0.074182)\n",
      "Testing 1466/5184\n",
      "0.05 1 4 3 sqrt friedman_mse 0.5 100: Weighted 0.806990 (0.044778)\n",
      "0.05 1 4 3 sqrt friedman_mse 0.5 100: Macro 0.707242 (0.063140)\n",
      "Testing 1467/5184\n",
      "0.05 1 4 3 sqrt friedman_mse 0.5 200: Weighted 0.808432 (0.053664)\n",
      "0.05 1 4 3 sqrt friedman_mse 0.5 200: Macro 0.711716 (0.068959)\n",
      "Testing 1468/5184\n",
      "0.05 1 4 3 sqrt friedman_mse 0.5 500: Weighted 0.808137 (0.053895)\n",
      "0.05 1 4 3 sqrt friedman_mse 0.5 500: Macro 0.700735 (0.078797)\n",
      "Testing 1469/5184\n",
      "0.05 1 4 3 sqrt friedman_mse 0.75 50: Weighted 0.794336 (0.060389)\n",
      "0.05 1 4 3 sqrt friedman_mse 0.75 50: Macro 0.686449 (0.079625)\n",
      "Testing 1470/5184\n",
      "0.05 1 4 3 sqrt friedman_mse 0.75 100: Weighted 0.789001 (0.062163)\n",
      "0.05 1 4 3 sqrt friedman_mse 0.75 100: Macro 0.680047 (0.085791)\n",
      "Testing 1471/5184\n",
      "0.05 1 4 3 sqrt friedman_mse 0.75 200: Weighted 0.811992 (0.060621)\n",
      "0.05 1 4 3 sqrt friedman_mse 0.75 200: Macro 0.709932 (0.088788)\n",
      "Testing 1472/5184\n",
      "0.05 1 4 3 sqrt friedman_mse 0.75 500: Weighted 0.806882 (0.060531)\n",
      "0.05 1 4 3 sqrt friedman_mse 0.75 500: Macro 0.708997 (0.090400)\n",
      "Testing 1473/5184\n",
      "0.05 1 4 3 sqrt friedman_mse 1.0 50: Weighted 0.797275 (0.044954)\n",
      "0.05 1 4 3 sqrt friedman_mse 1.0 50: Macro 0.697232 (0.046202)\n",
      "Testing 1474/5184\n",
      "0.05 1 4 3 sqrt friedman_mse 1.0 100: Weighted 0.793741 (0.069385)\n",
      "0.05 1 4 3 sqrt friedman_mse 1.0 100: Macro 0.687736 (0.098116)\n",
      "Testing 1475/5184\n",
      "0.05 1 4 3 sqrt friedman_mse 1.0 200: Weighted 0.798600 (0.051411)\n",
      "0.05 1 4 3 sqrt friedman_mse 1.0 200: Macro 0.695760 (0.078698)\n",
      "Testing 1476/5184\n",
      "0.05 1 4 3 sqrt friedman_mse 1.0 500: Weighted 0.787268 (0.049218)\n",
      "0.05 1 4 3 sqrt friedman_mse 1.0 500: Macro 0.679770 (0.079291)\n",
      "Testing 1477/5184\n",
      "0.05 1 4 3 sqrt mae 0.5 50: Weighted 0.804902 (0.054115)\n",
      "0.05 1 4 3 sqrt mae 0.5 50: Macro 0.699143 (0.073906)\n",
      "Testing 1478/5184\n",
      "0.05 1 4 3 sqrt mae 0.5 100: Weighted 0.804181 (0.055194)\n",
      "0.05 1 4 3 sqrt mae 0.5 100: Macro 0.687397 (0.077060)\n",
      "Testing 1479/5184\n",
      "0.05 1 4 3 sqrt mae 0.5 200: Weighted 0.787366 (0.058856)\n",
      "0.05 1 4 3 sqrt mae 0.5 200: Macro 0.668060 (0.084883)\n",
      "Testing 1480/5184\n",
      "0.05 1 4 3 sqrt mae 0.5 500: Weighted 0.777564 (0.044676)\n",
      "0.05 1 4 3 sqrt mae 0.5 500: Macro 0.647664 (0.072300)\n",
      "Testing 1481/5184\n",
      "0.05 1 4 3 sqrt mae 0.75 50: Weighted 0.786857 (0.060484)\n",
      "0.05 1 4 3 sqrt mae 0.75 50: Macro 0.666533 (0.082470)\n",
      "Testing 1482/5184\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05 1 4 3 sqrt mae 0.75 100: Weighted 0.787555 (0.065065)\n",
      "0.05 1 4 3 sqrt mae 0.75 100: Macro 0.671797 (0.087732)\n",
      "Testing 1483/5184\n",
      "0.05 1 4 3 sqrt mae 0.75 200: Weighted 0.779959 (0.060174)\n",
      "0.05 1 4 3 sqrt mae 0.75 200: Macro 0.658114 (0.081411)\n",
      "Testing 1484/5184\n",
      "0.05 1 4 3 sqrt mae 0.75 500: Weighted 0.767110 (0.056427)\n",
      "0.05 1 4 3 sqrt mae 0.75 500: Macro 0.638106 (0.085602)\n",
      "Testing 1485/5184\n",
      "0.05 1 4 3 sqrt mae 1.0 50: Weighted 0.789418 (0.064091)\n",
      "0.05 1 4 3 sqrt mae 1.0 50: Macro 0.686046 (0.076899)\n",
      "Testing 1486/5184\n",
      "0.05 1 4 3 sqrt mae 1.0 100: Weighted 0.762590 (0.069932)\n",
      "0.05 1 4 3 sqrt mae 1.0 100: Macro 0.624577 (0.103328)\n",
      "Testing 1487/5184\n",
      "0.05 1 4 3 sqrt mae 1.0 200: Weighted 0.745246 (0.060926)\n",
      "0.05 1 4 3 sqrt mae 1.0 200: Macro 0.598566 (0.086657)\n",
      "Testing 1488/5184\n",
      "0.05 1 4 3 sqrt mae 1.0 500: Weighted 0.750847 (0.059921)\n",
      "0.05 1 4 3 sqrt mae 1.0 500: Macro 0.600997 (0.081748)\n",
      "Testing 1489/5184\n",
      "0.05 1 4 5 log2 friedman_mse 0.5 50: Weighted 0.808831 (0.053244)\n",
      "0.05 1 4 5 log2 friedman_mse 0.5 50: Macro 0.692836 (0.068321)\n",
      "Testing 1490/5184\n",
      "0.05 1 4 5 log2 friedman_mse 0.5 100: Weighted 0.818411 (0.072133)\n",
      "0.05 1 4 5 log2 friedman_mse 0.5 100: Macro 0.719223 (0.102626)\n",
      "Testing 1491/5184\n",
      "0.05 1 4 5 log2 friedman_mse 0.5 200: Weighted 0.811278 (0.074590)\n",
      "0.05 1 4 5 log2 friedman_mse 0.5 200: Macro 0.711453 (0.109692)\n",
      "Testing 1492/5184\n",
      "0.05 1 4 5 log2 friedman_mse 0.5 500: Weighted 0.810500 (0.073591)\n",
      "0.05 1 4 5 log2 friedman_mse 0.5 500: Macro 0.714666 (0.113684)\n",
      "Testing 1493/5184\n",
      "0.05 1 4 5 log2 friedman_mse 0.75 50: Weighted 0.807325 (0.050651)\n",
      "0.05 1 4 5 log2 friedman_mse 0.75 50: Macro 0.706579 (0.066193)\n",
      "Testing 1494/5184\n",
      "0.05 1 4 5 log2 friedman_mse 0.75 100: Weighted 0.811065 (0.083369)\n",
      "0.05 1 4 5 log2 friedman_mse 0.75 100: Macro 0.707827 (0.118801)\n",
      "Testing 1495/5184\n",
      "0.05 1 4 5 log2 friedman_mse 0.75 200: Weighted 0.807429 (0.070994)\n",
      "0.05 1 4 5 log2 friedman_mse 0.75 200: Macro 0.701938 (0.105811)\n",
      "Testing 1496/5184\n",
      "0.05 1 4 5 log2 friedman_mse 0.75 500: Weighted 0.787023 (0.059615)\n",
      "0.05 1 4 5 log2 friedman_mse 0.75 500: Macro 0.673374 (0.097872)\n",
      "Testing 1497/5184\n",
      "0.05 1 4 5 log2 friedman_mse 1.0 50: Weighted 0.793850 (0.055446)\n",
      "0.05 1 4 5 log2 friedman_mse 1.0 50: Macro 0.693205 (0.079575)\n",
      "Testing 1498/5184\n",
      "0.05 1 4 5 log2 friedman_mse 1.0 100: Weighted 0.797858 (0.074033)\n",
      "0.05 1 4 5 log2 friedman_mse 1.0 100: Macro 0.691878 (0.106241)\n",
      "Testing 1499/5184\n",
      "0.05 1 4 5 log2 friedman_mse 1.0 200: Weighted 0.797545 (0.078535)\n",
      "0.05 1 4 5 log2 friedman_mse 1.0 200: Macro 0.692340 (0.123105)\n",
      "Testing 1500/5184\n",
      "0.05 1 4 5 log2 friedman_mse 1.0 500: Weighted 0.798967 (0.076867)\n",
      "0.05 1 4 5 log2 friedman_mse 1.0 500: Macro 0.699430 (0.115101)\n",
      "Testing 1501/5184\n",
      "0.05 1 4 5 log2 mae 0.5 50: Weighted 0.799578 (0.042714)\n",
      "0.05 1 4 5 log2 mae 0.5 50: Macro 0.688443 (0.058790)\n",
      "Testing 1502/5184\n",
      "0.05 1 4 5 log2 mae 0.5 100: Weighted 0.801681 (0.060752)\n",
      "0.05 1 4 5 log2 mae 0.5 100: Macro 0.685523 (0.091224)\n",
      "Testing 1503/5184\n",
      "0.05 1 4 5 log2 mae 0.5 200: Weighted 0.786828 (0.053963)\n",
      "0.05 1 4 5 log2 mae 0.5 200: Macro 0.661415 (0.083881)\n",
      "Testing 1504/5184\n",
      "0.05 1 4 5 log2 mae 0.5 500: Weighted 0.799538 (0.069211)\n",
      "0.05 1 4 5 log2 mae 0.5 500: Macro 0.685664 (0.109328)\n",
      "Testing 1505/5184\n",
      "0.05 1 4 5 log2 mae 0.75 50: Weighted 0.774624 (0.056919)\n",
      "0.05 1 4 5 log2 mae 0.75 50: Macro 0.657021 (0.078744)\n",
      "Testing 1506/5184\n",
      "0.05 1 4 5 log2 mae 0.75 100: Weighted 0.792004 (0.067126)\n",
      "0.05 1 4 5 log2 mae 0.75 100: Macro 0.679385 (0.091691)\n",
      "Testing 1507/5184\n",
      "0.05 1 4 5 log2 mae 0.75 200: Weighted 0.768290 (0.073197)\n",
      "0.05 1 4 5 log2 mae 0.75 200: Macro 0.641381 (0.104095)\n",
      "Testing 1508/5184\n",
      "0.05 1 4 5 log2 mae 0.75 500: Weighted 0.787024 (0.074050)\n",
      "0.05 1 4 5 log2 mae 0.75 500: Macro 0.667451 (0.110661)\n",
      "Testing 1509/5184\n",
      "0.05 1 4 5 log2 mae 1.0 50: Weighted 0.761192 (0.061301)\n",
      "0.05 1 4 5 log2 mae 1.0 50: Macro 0.628127 (0.094937)\n",
      "Testing 1510/5184\n",
      "0.05 1 4 5 log2 mae 1.0 100: Weighted 0.758849 (0.060871)\n",
      "0.05 1 4 5 log2 mae 1.0 100: Macro 0.626424 (0.094199)\n",
      "Testing 1511/5184\n",
      "0.05 1 4 5 log2 mae 1.0 200: Weighted 0.767913 (0.070277)\n",
      "0.05 1 4 5 log2 mae 1.0 200: Macro 0.630786 (0.102562)\n",
      "Testing 1512/5184\n",
      "0.05 1 4 5 log2 mae 1.0 500: Weighted 0.792750 (0.073950)\n",
      "0.05 1 4 5 log2 mae 1.0 500: Macro 0.674064 (0.109173)\n",
      "Testing 1513/5184\n",
      "0.05 1 4 5 sqrt friedman_mse 0.5 50: Weighted 0.806176 (0.053736)\n",
      "0.05 1 4 5 sqrt friedman_mse 0.5 50: Macro 0.701220 (0.075984)\n",
      "Testing 1514/5184\n",
      "0.05 1 4 5 sqrt friedman_mse 0.5 100: Weighted 0.818064 (0.077341)\n",
      "0.05 1 4 5 sqrt friedman_mse 0.5 100: Macro 0.716429 (0.111603)\n",
      "Testing 1515/5184\n",
      "0.05 1 4 5 sqrt friedman_mse 0.5 200: Weighted 0.806389 (0.071840)\n",
      "0.05 1 4 5 sqrt friedman_mse 0.5 200: Macro 0.703484 (0.104549)\n",
      "Testing 1516/5184\n",
      "0.05 1 4 5 sqrt friedman_mse 0.5 500: Weighted 0.802285 (0.075874)\n",
      "0.05 1 4 5 sqrt friedman_mse 0.5 500: Macro 0.702495 (0.115503)\n",
      "Testing 1517/5184\n",
      "0.05 1 4 5 sqrt friedman_mse 0.75 50: Weighted 0.806000 (0.057980)\n",
      "0.05 1 4 5 sqrt friedman_mse 0.75 50: Macro 0.705675 (0.082756)\n",
      "Testing 1518/5184\n",
      "0.05 1 4 5 sqrt friedman_mse 0.75 100: Weighted 0.794594 (0.076764)\n",
      "0.05 1 4 5 sqrt friedman_mse 0.75 100: Macro 0.683633 (0.105040)\n",
      "Testing 1519/5184\n",
      "0.05 1 4 5 sqrt friedman_mse 0.75 200: Weighted 0.817494 (0.094526)\n",
      "0.05 1 4 5 sqrt friedman_mse 0.75 200: Macro 0.718531 (0.137028)\n",
      "Testing 1520/5184\n",
      "0.05 1 4 5 sqrt friedman_mse 0.75 500: Weighted 0.804995 (0.075473)\n",
      "0.05 1 4 5 sqrt friedman_mse 0.75 500: Macro 0.696668 (0.116359)\n",
      "Testing 1521/5184\n",
      "0.05 1 4 5 sqrt friedman_mse 1.0 50: Weighted 0.793328 (0.056189)\n",
      "0.05 1 4 5 sqrt friedman_mse 1.0 50: Macro 0.690293 (0.074848)\n",
      "Testing 1522/5184\n",
      "0.05 1 4 5 sqrt friedman_mse 1.0 100: Weighted 0.812446 (0.082045)\n",
      "0.05 1 4 5 sqrt friedman_mse 1.0 100: Macro 0.712068 (0.115213)\n",
      "Testing 1523/5184\n",
      "0.05 1 4 5 sqrt friedman_mse 1.0 200: Weighted 0.798967 (0.076867)\n",
      "0.05 1 4 5 sqrt friedman_mse 1.0 200: Macro 0.699430 (0.115101)\n",
      "Testing 1524/5184\n",
      "0.05 1 4 5 sqrt friedman_mse 1.0 500: Weighted 0.806205 (0.069714)\n",
      "0.05 1 4 5 sqrt friedman_mse 1.0 500: Macro 0.709053 (0.105545)\n",
      "Testing 1525/5184\n",
      "0.05 1 4 5 sqrt mae 0.5 50: Weighted 0.803984 (0.067234)\n",
      "0.05 1 4 5 sqrt mae 0.5 50: Macro 0.690190 (0.090240)\n",
      "Testing 1526/5184\n",
      "0.05 1 4 5 sqrt mae 0.5 100: Weighted 0.791808 (0.057190)\n",
      "0.05 1 4 5 sqrt mae 0.5 100: Macro 0.673837 (0.083261)\n",
      "Testing 1527/5184\n",
      "0.05 1 4 5 sqrt mae 0.5 200: Weighted 0.788001 (0.061243)\n",
      "0.05 1 4 5 sqrt mae 0.5 200: Macro 0.674899 (0.090129)\n",
      "Testing 1528/5184\n",
      "0.05 1 4 5 sqrt mae 0.5 500: Weighted 0.791175 (0.067215)\n",
      "0.05 1 4 5 sqrt mae 0.5 500: Macro 0.670152 (0.101921)\n",
      "Testing 1529/5184\n",
      "0.05 1 4 5 sqrt mae 0.75 50: Weighted 0.772963 (0.037086)\n",
      "0.05 1 4 5 sqrt mae 0.75 50: Macro 0.651931 (0.060144)\n",
      "Testing 1530/5184\n",
      "0.05 1 4 5 sqrt mae 0.75 100: Weighted 0.781821 (0.069113)\n",
      "0.05 1 4 5 sqrt mae 0.75 100: Macro 0.658107 (0.100464)\n",
      "Testing 1531/5184\n",
      "0.05 1 4 5 sqrt mae 0.75 200: Weighted 0.765984 (0.075583)\n",
      "0.05 1 4 5 sqrt mae 0.75 200: Macro 0.642810 (0.109036)\n",
      "Testing 1532/5184\n",
      "0.05 1 4 5 sqrt mae 0.75 500: Weighted 0.790191 (0.066889)\n",
      "0.05 1 4 5 sqrt mae 0.75 500: Macro 0.661737 (0.096466)\n",
      "Testing 1533/5184\n",
      "0.05 1 4 5 sqrt mae 1.0 50: Weighted 0.773988 (0.057599)\n",
      "0.05 1 4 5 sqrt mae 1.0 50: Macro 0.642621 (0.093034)\n",
      "Testing 1534/5184\n",
      "0.05 1 4 5 sqrt mae 1.0 100: Weighted 0.767036 (0.073841)\n",
      "0.05 1 4 5 sqrt mae 1.0 100: Macro 0.636079 (0.110069)\n",
      "Testing 1535/5184\n",
      "0.05 1 4 5 sqrt mae 1.0 200: Weighted 0.787168 (0.088656)\n",
      "0.05 1 4 5 sqrt mae 1.0 200: Macro 0.663330 (0.131019)\n",
      "Testing 1536/5184\n",
      "0.05 1 4 5 sqrt mae 1.0 500: Weighted 0.795318 (0.082042)\n",
      "0.05 1 4 5 sqrt mae 1.0 500: Macro 0.678619 (0.116492)\n",
      "Testing 1537/5184\n",
      "0.05 1 4 8 log2 friedman_mse 0.5 50: Weighted 0.820854 (0.058711)\n",
      "0.05 1 4 8 log2 friedman_mse 0.5 50: Macro 0.725159 (0.075450)\n",
      "Testing 1538/5184\n",
      "0.05 1 4 8 log2 friedman_mse 0.5 100: Weighted 0.819430 (0.081962)\n",
      "0.05 1 4 8 log2 friedman_mse 0.5 100: Macro 0.719238 (0.117339)\n",
      "Testing 1539/5184\n",
      "0.05 1 4 8 log2 friedman_mse 0.5 200: Weighted 0.824320 (0.087763)\n",
      "0.05 1 4 8 log2 friedman_mse 0.5 200: Macro 0.726414 (0.129443)\n",
      "Testing 1540/5184\n",
      "0.05 1 4 8 log2 friedman_mse 0.5 500: Weighted 0.829486 (0.074813)\n",
      "0.05 1 4 8 log2 friedman_mse 0.5 500: Macro 0.734206 (0.118766)\n",
      "Testing 1541/5184\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05 1 4 8 log2 friedman_mse 0.75 50: Weighted 0.794693 (0.076314)\n",
      "0.05 1 4 8 log2 friedman_mse 0.75 50: Macro 0.683757 (0.104706)\n",
      "Testing 1542/5184\n",
      "0.05 1 4 8 log2 friedman_mse 0.75 100: Weighted 0.809214 (0.074654)\n",
      "0.05 1 4 8 log2 friedman_mse 0.75 100: Macro 0.705440 (0.103569)\n",
      "Testing 1543/5184\n",
      "0.05 1 4 8 log2 friedman_mse 0.75 200: Weighted 0.800001 (0.073644)\n",
      "0.05 1 4 8 log2 friedman_mse 0.75 200: Macro 0.688969 (0.112570)\n",
      "Testing 1544/5184\n",
      "0.05 1 4 8 log2 friedman_mse 0.75 500: Weighted 0.819693 (0.086069)\n",
      "0.05 1 4 8 log2 friedman_mse 0.75 500: Macro 0.727814 (0.130324)\n",
      "Testing 1545/5184\n",
      "0.05 1 4 8 log2 friedman_mse 1.0 50: Weighted 0.791949 (0.072349)\n",
      "0.05 1 4 8 log2 friedman_mse 1.0 50: Macro 0.682683 (0.093982)\n",
      "Testing 1546/5184\n",
      "0.05 1 4 8 log2 friedman_mse 1.0 100: Weighted 0.789832 (0.059850)\n",
      "0.05 1 4 8 log2 friedman_mse 1.0 100: Macro 0.677346 (0.096652)\n",
      "Testing 1547/5184\n",
      "0.05 1 4 8 log2 friedman_mse 1.0 200: Weighted 0.806149 (0.069898)\n",
      "0.05 1 4 8 log2 friedman_mse 1.0 200: Macro 0.705610 (0.101814)\n",
      "Testing 1548/5184\n",
      "0.05 1 4 8 log2 friedman_mse 1.0 500: Weighted 0.803906 (0.074889)\n",
      "0.05 1 4 8 log2 friedman_mse 1.0 500: Macro 0.692368 (0.110740)\n",
      "Testing 1549/5184\n",
      "0.05 1 4 8 log2 mae 0.5 50: Weighted 0.784195 (0.061349)\n",
      "0.05 1 4 8 log2 mae 0.5 50: Macro 0.661217 (0.095844)\n",
      "Testing 1550/5184\n",
      "0.05 1 4 8 log2 mae 0.5 100: Weighted 0.803796 (0.058600)\n",
      "0.05 1 4 8 log2 mae 0.5 100: Macro 0.690316 (0.086125)\n",
      "Testing 1551/5184\n",
      "0.05 1 4 8 log2 mae 0.5 200: Weighted 0.804044 (0.055024)\n",
      "0.05 1 4 8 log2 mae 0.5 200: Macro 0.693848 (0.084913)\n",
      "Testing 1552/5184\n",
      "0.05 1 4 8 log2 mae 0.5 500: Weighted 0.808522 (0.061159)\n",
      "0.05 1 4 8 log2 mae 0.5 500: Macro 0.700856 (0.094680)\n",
      "Testing 1553/5184\n",
      "0.05 1 4 8 log2 mae 0.75 50: Weighted 0.777066 (0.063380)\n",
      "0.05 1 4 8 log2 mae 0.75 50: Macro 0.649816 (0.102680)\n",
      "Testing 1554/5184\n",
      "0.05 1 4 8 log2 mae 0.75 100: Weighted 0.784877 (0.047562)\n",
      "0.05 1 4 8 log2 mae 0.75 100: Macro 0.669363 (0.067317)\n",
      "Testing 1555/5184\n",
      "0.05 1 4 8 log2 mae 0.75 200: Weighted 0.795276 (0.063641)\n",
      "0.05 1 4 8 log2 mae 0.75 200: Macro 0.685706 (0.092036)\n",
      "Testing 1556/5184\n",
      "0.05 1 4 8 log2 mae 0.75 500: Weighted 0.796271 (0.062587)\n",
      "0.05 1 4 8 log2 mae 0.75 500: Macro 0.685895 (0.091834)\n",
      "Testing 1557/5184\n",
      "0.05 1 4 8 log2 mae 1.0 50: Weighted 0.766028 (0.042657)\n",
      "0.05 1 4 8 log2 mae 1.0 50: Macro 0.635766 (0.072297)\n",
      "Testing 1558/5184\n",
      "0.05 1 4 8 log2 mae 1.0 100: Weighted 0.783054 (0.049678)\n",
      "0.05 1 4 8 log2 mae 1.0 100: Macro 0.658741 (0.073607)\n",
      "Testing 1559/5184\n",
      "0.05 1 4 8 log2 mae 1.0 200: Weighted 0.775854 (0.054463)\n",
      "0.05 1 4 8 log2 mae 1.0 200: Macro 0.646833 (0.077491)\n",
      "Testing 1560/5184\n",
      "0.05 1 4 8 log2 mae 1.0 500: Weighted 0.763315 (0.078670)\n",
      "0.05 1 4 8 log2 mae 1.0 500: Macro 0.634013 (0.110884)\n",
      "Testing 1561/5184\n",
      "0.05 1 4 8 sqrt friedman_mse 0.5 50: Weighted 0.811761 (0.062245)\n",
      "0.05 1 4 8 sqrt friedman_mse 0.5 50: Macro 0.706075 (0.083187)\n",
      "Testing 1562/5184\n",
      "0.05 1 4 8 sqrt friedman_mse 0.5 100: Weighted 0.830671 (0.076909)\n",
      "0.05 1 4 8 sqrt friedman_mse 0.5 100: Macro 0.731765 (0.117473)\n",
      "Testing 1563/5184\n",
      "0.05 1 4 8 sqrt friedman_mse 0.5 200: Weighted 0.818425 (0.082488)\n",
      "0.05 1 4 8 sqrt friedman_mse 0.5 200: Macro 0.713598 (0.121225)\n",
      "Testing 1564/5184\n",
      "0.05 1 4 8 sqrt friedman_mse 0.5 500: Weighted 0.823168 (0.075631)\n",
      "0.05 1 4 8 sqrt friedman_mse 0.5 500: Macro 0.718960 (0.124585)\n",
      "Testing 1565/5184\n",
      "0.05 1 4 8 sqrt friedman_mse 0.75 50: Weighted 0.785987 (0.061484)\n",
      "0.05 1 4 8 sqrt friedman_mse 0.75 50: Macro 0.678105 (0.083681)\n",
      "Testing 1566/5184\n",
      "0.05 1 4 8 sqrt friedman_mse 0.75 100: Weighted 0.805465 (0.061131)\n",
      "0.05 1 4 8 sqrt friedman_mse 0.75 100: Macro 0.698434 (0.091165)\n",
      "Testing 1567/5184\n",
      "0.05 1 4 8 sqrt friedman_mse 0.75 200: Weighted 0.801185 (0.060031)\n",
      "0.05 1 4 8 sqrt friedman_mse 0.75 200: Macro 0.696393 (0.093829)\n",
      "Testing 1568/5184\n",
      "0.05 1 4 8 sqrt friedman_mse 0.75 500: Weighted 0.809293 (0.077888)\n",
      "0.05 1 4 8 sqrt friedman_mse 0.75 500: Macro 0.709501 (0.111175)\n",
      "Testing 1569/5184\n",
      "0.05 1 4 8 sqrt friedman_mse 1.0 50: Weighted 0.784362 (0.077021)\n",
      "0.05 1 4 8 sqrt friedman_mse 1.0 50: Macro 0.667038 (0.107465)\n",
      "Testing 1570/5184\n",
      "0.05 1 4 8 sqrt friedman_mse 1.0 100: Weighted 0.786082 (0.075221)\n",
      "0.05 1 4 8 sqrt friedman_mse 1.0 100: Macro 0.674380 (0.106266)\n",
      "Testing 1571/5184\n",
      "0.05 1 4 8 sqrt friedman_mse 1.0 200: Weighted 0.801663 (0.075977)\n",
      "0.05 1 4 8 sqrt friedman_mse 1.0 200: Macro 0.700481 (0.108353)\n",
      "Testing 1572/5184\n",
      "0.05 1 4 8 sqrt friedman_mse 1.0 500: Weighted 0.793376 (0.067579)\n",
      "0.05 1 4 8 sqrt friedman_mse 1.0 500: Macro 0.697817 (0.097081)\n",
      "Testing 1573/5184\n",
      "0.05 1 4 8 sqrt mae 0.5 50: Weighted 0.793348 (0.048254)\n",
      "0.05 1 4 8 sqrt mae 0.5 50: Macro 0.679910 (0.071519)\n",
      "Testing 1574/5184\n",
      "0.05 1 4 8 sqrt mae 0.5 100: Weighted 0.802197 (0.038773)\n",
      "0.05 1 4 8 sqrt mae 0.5 100: Macro 0.695127 (0.057842)\n",
      "Testing 1575/5184\n",
      "0.05 1 4 8 sqrt mae 0.5 200: Weighted 0.797152 (0.044193)\n",
      "0.05 1 4 8 sqrt mae 0.5 200: Macro 0.684588 (0.067966)\n",
      "Testing 1576/5184\n",
      "0.05 1 4 8 sqrt mae 0.5 500: Weighted 0.791034 (0.058564)\n",
      "0.05 1 4 8 sqrt mae 0.5 500: Macro 0.670499 (0.094089)\n",
      "Testing 1577/5184\n",
      "0.05 1 4 8 sqrt mae 0.75 50: Weighted 0.795204 (0.045510)\n",
      "0.05 1 4 8 sqrt mae 0.75 50: Macro 0.681325 (0.068284)\n",
      "Testing 1578/5184\n",
      "0.05 1 4 8 sqrt mae 0.75 100: Weighted 0.775045 (0.057754)\n",
      "0.05 1 4 8 sqrt mae 0.75 100: Macro 0.646677 (0.092297)\n",
      "Testing 1579/5184\n",
      "0.05 1 4 8 sqrt mae 0.75 200: Weighted 0.783892 (0.059060)\n",
      "0.05 1 4 8 sqrt mae 0.75 200: Macro 0.672709 (0.079617)\n",
      "Testing 1580/5184\n",
      "0.05 1 4 8 sqrt mae 0.75 500: Weighted 0.800616 (0.066950)\n",
      "0.05 1 4 8 sqrt mae 0.75 500: Macro 0.692773 (0.098973)\n",
      "Testing 1581/5184\n",
      "0.05 1 4 8 sqrt mae 1.0 50: Weighted 0.766076 (0.056393)\n",
      "0.05 1 4 8 sqrt mae 1.0 50: Macro 0.633693 (0.082981)\n",
      "Testing 1582/5184\n",
      "0.05 1 4 8 sqrt mae 1.0 100: Weighted 0.775096 (0.063129)\n",
      "0.05 1 4 8 sqrt mae 1.0 100: Macro 0.655232 (0.092009)\n",
      "Testing 1583/5184\n",
      "0.05 1 4 8 sqrt mae 1.0 200: Weighted 0.766759 (0.065970)\n",
      "0.05 1 4 8 sqrt mae 1.0 200: Macro 0.639517 (0.093430)\n",
      "Testing 1584/5184\n",
      "0.05 1 4 8 sqrt mae 1.0 500: Weighted 0.778738 (0.069149)\n",
      "0.05 1 4 8 sqrt mae 1.0 500: Macro 0.659180 (0.091416)\n",
      "Testing 1585/5184\n",
      "0.05 1 6 3 log2 friedman_mse 0.5 50: Weighted 0.811862 (0.056933)\n",
      "0.05 1 6 3 log2 friedman_mse 0.5 50: Macro 0.701614 (0.070925)\n",
      "Testing 1586/5184\n",
      "0.05 1 6 3 log2 friedman_mse 0.5 100: Weighted 0.821499 (0.076378)\n",
      "0.05 1 6 3 log2 friedman_mse 0.5 100: Macro 0.718078 (0.109387)\n",
      "Testing 1587/5184\n",
      "0.05 1 6 3 log2 friedman_mse 0.5 200: Weighted 0.810718 (0.071552)\n",
      "0.05 1 6 3 log2 friedman_mse 0.5 200: Macro 0.707316 (0.101980)\n",
      "Testing 1588/5184\n",
      "0.05 1 6 3 log2 friedman_mse 0.5 500: Weighted 0.799250 (0.064492)\n",
      "0.05 1 6 3 log2 friedman_mse 0.5 500: Macro 0.686791 (0.104463)\n",
      "Testing 1589/5184\n",
      "0.05 1 6 3 log2 friedman_mse 0.75 50: Weighted 0.816456 (0.048246)\n",
      "0.05 1 6 3 log2 friedman_mse 0.75 50: Macro 0.711484 (0.059133)\n",
      "Testing 1590/5184\n",
      "0.05 1 6 3 log2 friedman_mse 0.75 100: Weighted 0.793004 (0.081372)\n",
      "0.05 1 6 3 log2 friedman_mse 0.75 100: Macro 0.683143 (0.104144)\n",
      "Testing 1591/5184\n",
      "0.05 1 6 3 log2 friedman_mse 0.75 200: Weighted 0.813078 (0.070928)\n",
      "0.05 1 6 3 log2 friedman_mse 0.75 200: Macro 0.709045 (0.097869)\n",
      "Testing 1592/5184\n",
      "0.05 1 6 3 log2 friedman_mse 0.75 500: Weighted 0.805432 (0.056087)\n",
      "0.05 1 6 3 log2 friedman_mse 0.75 500: Macro 0.705190 (0.081622)\n",
      "Testing 1593/5184\n",
      "0.05 1 6 3 log2 friedman_mse 1.0 50: Weighted 0.795323 (0.057175)\n",
      "0.05 1 6 3 log2 friedman_mse 1.0 50: Macro 0.685490 (0.064408)\n",
      "Testing 1594/5184\n",
      "0.05 1 6 3 log2 friedman_mse 1.0 100: Weighted 0.806200 (0.065498)\n",
      "0.05 1 6 3 log2 friedman_mse 1.0 100: Macro 0.705953 (0.092638)\n",
      "Testing 1595/5184\n",
      "0.05 1 6 3 log2 friedman_mse 1.0 200: Weighted 0.799352 (0.058907)\n",
      "0.05 1 6 3 log2 friedman_mse 1.0 200: Macro 0.699206 (0.089379)\n",
      "Testing 1596/5184\n",
      "0.05 1 6 3 log2 friedman_mse 1.0 500: Weighted 0.790721 (0.057268)\n",
      "0.05 1 6 3 log2 friedman_mse 1.0 500: Macro 0.680803 (0.087834)\n",
      "Testing 1597/5184\n",
      "0.05 1 6 3 log2 mae 0.5 50: Weighted 0.805006 (0.064571)\n",
      "0.05 1 6 3 log2 mae 0.5 50: Macro 0.690020 (0.090395)\n",
      "Testing 1598/5184\n",
      "0.05 1 6 3 log2 mae 0.5 100: Weighted 0.789805 (0.048936)\n",
      "0.05 1 6 3 log2 mae 0.5 100: Macro 0.674533 (0.073743)\n",
      "Testing 1599/5184\n",
      "0.05 1 6 3 log2 mae 0.5 200: Weighted 0.795483 (0.054367)\n",
      "0.05 1 6 3 log2 mae 0.5 200: Macro 0.679648 (0.079766)\n",
      "Testing 1600/5184\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05 1 6 3 log2 mae 0.5 500: Weighted 0.781515 (0.038343)\n",
      "0.05 1 6 3 log2 mae 0.5 500: Macro 0.660838 (0.058689)\n",
      "Testing 1601/5184\n",
      "0.05 1 6 3 log2 mae 0.75 50: Weighted 0.779985 (0.048263)\n",
      "0.05 1 6 3 log2 mae 0.75 50: Macro 0.663112 (0.068889)\n",
      "Testing 1602/5184\n",
      "0.05 1 6 3 log2 mae 0.75 100: Weighted 0.782981 (0.054970)\n",
      "0.05 1 6 3 log2 mae 0.75 100: Macro 0.664607 (0.076248)\n",
      "Testing 1603/5184\n",
      "0.05 1 6 3 log2 mae 0.75 200: Weighted 0.752502 (0.066329)\n",
      "0.05 1 6 3 log2 mae 0.75 200: Macro 0.622128 (0.093041)\n",
      "Testing 1604/5184\n",
      "0.05 1 6 3 log2 mae 0.75 500: Weighted 0.759195 (0.070280)\n",
      "0.05 1 6 3 log2 mae 0.75 500: Macro 0.626765 (0.101091)\n",
      "Testing 1605/5184\n",
      "0.05 1 6 3 log2 mae 1.0 50: Weighted 0.773726 (0.061137)\n",
      "0.05 1 6 3 log2 mae 1.0 50: Macro 0.654434 (0.085416)\n",
      "Testing 1606/5184\n",
      "0.05 1 6 3 log2 mae 1.0 100: Weighted 0.766700 (0.081044)\n",
      "0.05 1 6 3 log2 mae 1.0 100: Macro 0.645028 (0.116441)\n",
      "Testing 1607/5184\n",
      "0.05 1 6 3 log2 mae 1.0 200: Weighted 0.765157 (0.068915)\n",
      "0.05 1 6 3 log2 mae 1.0 200: Macro 0.626187 (0.097643)\n",
      "Testing 1608/5184\n",
      "0.05 1 6 3 log2 mae 1.0 500: Weighted 0.752513 (0.062776)\n",
      "0.05 1 6 3 log2 mae 1.0 500: Macro 0.606413 (0.088594)\n",
      "Testing 1609/5184\n",
      "0.05 1 6 3 sqrt friedman_mse 0.5 50: Weighted 0.814744 (0.045142)\n",
      "0.05 1 6 3 sqrt friedman_mse 0.5 50: Macro 0.712708 (0.064500)\n",
      "Testing 1610/5184\n",
      "0.05 1 6 3 sqrt friedman_mse 0.5 100: Weighted 0.815261 (0.065116)\n",
      "0.05 1 6 3 sqrt friedman_mse 0.5 100: Macro 0.709163 (0.087076)\n",
      "Testing 1611/5184\n",
      "0.05 1 6 3 sqrt friedman_mse 0.5 200: Weighted 0.799764 (0.063666)\n",
      "0.05 1 6 3 sqrt friedman_mse 0.5 200: Macro 0.694525 (0.094639)\n",
      "Testing 1612/5184\n",
      "0.05 1 6 3 sqrt friedman_mse 0.5 500: Weighted 0.815675 (0.067133)\n",
      "0.05 1 6 3 sqrt friedman_mse 0.5 500: Macro 0.719434 (0.099147)\n",
      "Testing 1613/5184\n",
      "0.05 1 6 3 sqrt friedman_mse 0.75 50: Weighted 0.800704 (0.063930)\n",
      "0.05 1 6 3 sqrt friedman_mse 0.75 50: Macro 0.696883 (0.077170)\n",
      "Testing 1614/5184\n",
      "0.05 1 6 3 sqrt friedman_mse 0.75 100: Weighted 0.788735 (0.051145)\n",
      "0.05 1 6 3 sqrt friedman_mse 0.75 100: Macro 0.685399 (0.074723)\n",
      "Testing 1615/5184\n",
      "0.05 1 6 3 sqrt friedman_mse 0.75 200: Weighted 0.809415 (0.069480)\n",
      "0.05 1 6 3 sqrt friedman_mse 0.75 200: Macro 0.702230 (0.105569)\n",
      "Testing 1616/5184\n",
      "0.05 1 6 3 sqrt friedman_mse 0.75 500: Weighted 0.808521 (0.058600)\n",
      "0.05 1 6 3 sqrt friedman_mse 0.75 500: Macro 0.707589 (0.089470)\n",
      "Testing 1617/5184\n",
      "0.05 1 6 3 sqrt friedman_mse 1.0 50: Weighted 0.796081 (0.072835)\n",
      "0.05 1 6 3 sqrt friedman_mse 1.0 50: Macro 0.690776 (0.088472)\n",
      "Testing 1618/5184\n",
      "0.05 1 6 3 sqrt friedman_mse 1.0 100: Weighted 0.808079 (0.057546)\n",
      "0.05 1 6 3 sqrt friedman_mse 1.0 100: Macro 0.707962 (0.076006)\n",
      "Testing 1619/5184\n",
      "0.05 1 6 3 sqrt friedman_mse 1.0 200: Weighted 0.800992 (0.044368)\n",
      "0.05 1 6 3 sqrt friedman_mse 1.0 200: Macro 0.702725 (0.070991)\n",
      "Testing 1620/5184\n",
      "0.05 1 6 3 sqrt friedman_mse 1.0 500: Weighted 0.789277 (0.056271)\n",
      "0.05 1 6 3 sqrt friedman_mse 1.0 500: Macro 0.682580 (0.089648)\n",
      "Testing 1621/5184\n",
      "0.05 1 6 3 sqrt mae 0.5 50: Weighted 0.822157 (0.048628)\n",
      "0.05 1 6 3 sqrt mae 0.5 50: Macro 0.719881 (0.061949)\n",
      "Testing 1622/5184\n",
      "0.05 1 6 3 sqrt mae 0.5 100: Weighted 0.789519 (0.052414)\n",
      "0.05 1 6 3 sqrt mae 0.5 100: Macro 0.677141 (0.070596)\n",
      "Testing 1623/5184\n",
      "0.05 1 6 3 sqrt mae 0.5 200: Weighted 0.789962 (0.048907)\n",
      "0.05 1 6 3 sqrt mae 0.5 200: Macro 0.683402 (0.069576)\n",
      "Testing 1624/5184\n",
      "0.05 1 6 3 sqrt mae 0.5 500: Weighted 0.791008 (0.061448)\n",
      "0.05 1 6 3 sqrt mae 0.5 500: Macro 0.668745 (0.095256)\n",
      "Testing 1625/5184\n",
      "0.05 1 6 3 sqrt mae 0.75 50: Weighted 0.792246 (0.070760)\n",
      "0.05 1 6 3 sqrt mae 0.75 50: Macro 0.684289 (0.095998)\n",
      "Testing 1626/5184\n",
      "0.05 1 6 3 sqrt mae 0.75 100: Weighted 0.786856 (0.059356)\n",
      "0.05 1 6 3 sqrt mae 0.75 100: Macro 0.669648 (0.083322)\n",
      "Testing 1627/5184\n",
      "0.05 1 6 3 sqrt mae 0.75 200: Weighted 0.761375 (0.059343)\n",
      "0.05 1 6 3 sqrt mae 0.75 200: Macro 0.630833 (0.088506)\n",
      "Testing 1628/5184\n",
      "0.05 1 6 3 sqrt mae 0.75 500: Weighted 0.758775 (0.065750)\n",
      "0.05 1 6 3 sqrt mae 0.75 500: Macro 0.625322 (0.092547)\n",
      "Testing 1629/5184\n",
      "0.05 1 6 3 sqrt mae 1.0 50: Weighted 0.768370 (0.070640)\n",
      "0.05 1 6 3 sqrt mae 1.0 50: Macro 0.648848 (0.091993)\n",
      "Testing 1630/5184\n",
      "0.05 1 6 3 sqrt mae 1.0 100: Weighted 0.771968 (0.076406)\n",
      "0.05 1 6 3 sqrt mae 1.0 100: Macro 0.655483 (0.106548)\n",
      "Testing 1631/5184\n",
      "0.05 1 6 3 sqrt mae 1.0 200: Weighted 0.757945 (0.072378)\n",
      "0.05 1 6 3 sqrt mae 1.0 200: Macro 0.623350 (0.109413)\n",
      "Testing 1632/5184\n",
      "0.05 1 6 3 sqrt mae 1.0 500: Weighted 0.749688 (0.062094)\n",
      "0.05 1 6 3 sqrt mae 1.0 500: Macro 0.605418 (0.094424)\n",
      "Testing 1633/5184\n",
      "0.05 1 6 5 log2 friedman_mse 0.5 50: Weighted 0.829418 (0.058271)\n",
      "0.05 1 6 5 log2 friedman_mse 0.5 50: Macro 0.736300 (0.077794)\n",
      "Testing 1634/5184\n",
      "0.05 1 6 5 log2 friedman_mse 0.5 100: Weighted 0.827905 (0.061388)\n",
      "0.05 1 6 5 log2 friedman_mse 0.5 100: Macro 0.734893 (0.077255)\n",
      "Testing 1635/5184\n",
      "0.05 1 6 5 log2 friedman_mse 0.5 200: Weighted 0.815887 (0.069906)\n",
      "0.05 1 6 5 log2 friedman_mse 0.5 200: Macro 0.721711 (0.099068)\n",
      "Testing 1636/5184\n",
      "0.05 1 6 5 log2 friedman_mse 0.5 500: Weighted 0.810724 (0.068436)\n",
      "0.05 1 6 5 log2 friedman_mse 0.5 500: Macro 0.707737 (0.102568)\n",
      "Testing 1637/5184\n",
      "0.05 1 6 5 log2 friedman_mse 0.75 50: Weighted 0.808160 (0.073014)\n",
      "0.05 1 6 5 log2 friedman_mse 0.75 50: Macro 0.709281 (0.106749)\n",
      "Testing 1638/5184\n",
      "0.05 1 6 5 log2 friedman_mse 0.75 100: Weighted 0.804381 (0.078219)\n",
      "0.05 1 6 5 log2 friedman_mse 0.75 100: Macro 0.694335 (0.112053)\n",
      "Testing 1639/5184\n",
      "0.05 1 6 5 log2 friedman_mse 0.75 200: Weighted 0.801886 (0.087170)\n",
      "0.05 1 6 5 log2 friedman_mse 0.75 200: Macro 0.691363 (0.125865)\n",
      "Testing 1640/5184\n",
      "0.05 1 6 5 log2 friedman_mse 0.75 500: Weighted 0.811534 (0.074273)\n",
      "0.05 1 6 5 log2 friedman_mse 0.75 500: Macro 0.714981 (0.114598)\n",
      "Testing 1641/5184\n",
      "0.05 1 6 5 log2 friedman_mse 1.0 50: Weighted 0.795914 (0.064799)\n",
      "0.05 1 6 5 log2 friedman_mse 1.0 50: Macro 0.689307 (0.091353)\n",
      "Testing 1642/5184\n",
      "0.05 1 6 5 log2 friedman_mse 1.0 100: Weighted 0.810292 (0.091122)\n",
      "0.05 1 6 5 log2 friedman_mse 1.0 100: Macro 0.702416 (0.135478)\n",
      "Testing 1643/5184\n",
      "0.05 1 6 5 log2 friedman_mse 1.0 200: Weighted 0.801983 (0.074833)\n",
      "0.05 1 6 5 log2 friedman_mse 1.0 200: Macro 0.696210 (0.120676)\n",
      "Testing 1644/5184\n",
      "0.05 1 6 5 log2 friedman_mse 1.0 500: Weighted 0.795959 (0.059623)\n",
      "0.05 1 6 5 log2 friedman_mse 1.0 500: Macro 0.696476 (0.093851)\n",
      "Testing 1645/5184\n",
      "0.05 1 6 5 log2 mae 0.5 50: Weighted 0.810577 (0.059192)\n",
      "0.05 1 6 5 log2 mae 0.5 50: Macro 0.694336 (0.085240)\n",
      "Testing 1646/5184\n",
      "0.05 1 6 5 log2 mae 0.5 100: Weighted 0.785288 (0.047036)\n",
      "0.05 1 6 5 log2 mae 0.5 100: Macro 0.667568 (0.069518)\n",
      "Testing 1647/5184\n",
      "0.05 1 6 5 log2 mae 0.5 200: Weighted 0.789593 (0.051926)\n",
      "0.05 1 6 5 log2 mae 0.5 200: Macro 0.667947 (0.085668)\n",
      "Testing 1648/5184\n",
      "0.05 1 6 5 log2 mae 0.5 500: Weighted 0.791438 (0.067461)\n",
      "0.05 1 6 5 log2 mae 0.5 500: Macro 0.673227 (0.104801)\n",
      "Testing 1649/5184\n",
      "0.05 1 6 5 log2 mae 0.75 50: Weighted 0.785504 (0.036664)\n",
      "0.05 1 6 5 log2 mae 0.75 50: Macro 0.665770 (0.056564)\n",
      "Testing 1650/5184\n",
      "0.05 1 6 5 log2 mae 0.75 100: Weighted 0.751272 (0.049307)\n",
      "0.05 1 6 5 log2 mae 0.75 100: Macro 0.628180 (0.071642)\n",
      "Testing 1651/5184\n",
      "0.05 1 6 5 log2 mae 0.75 200: Weighted 0.774564 (0.068524)\n",
      "0.05 1 6 5 log2 mae 0.75 200: Macro 0.648692 (0.100525)\n",
      "Testing 1652/5184\n",
      "0.05 1 6 5 log2 mae 0.75 500: Weighted 0.777683 (0.054925)\n",
      "0.05 1 6 5 log2 mae 0.75 500: Macro 0.649179 (0.083654)\n",
      "Testing 1653/5184\n",
      "0.05 1 6 5 log2 mae 1.0 50: Weighted 0.768158 (0.073062)\n",
      "0.05 1 6 5 log2 mae 1.0 50: Macro 0.634142 (0.109477)\n",
      "Testing 1654/5184\n",
      "0.05 1 6 5 log2 mae 1.0 100: Weighted 0.788307 (0.053353)\n",
      "0.05 1 6 5 log2 mae 1.0 100: Macro 0.657272 (0.087101)\n",
      "Testing 1655/5184\n",
      "0.05 1 6 5 log2 mae 1.0 200: Weighted 0.779402 (0.076387)\n",
      "0.05 1 6 5 log2 mae 1.0 200: Macro 0.647435 (0.108484)\n",
      "Testing 1656/5184\n",
      "0.05 1 6 5 log2 mae 1.0 500: Weighted 0.792827 (0.072897)\n",
      "0.05 1 6 5 log2 mae 1.0 500: Macro 0.679631 (0.112235)\n",
      "Testing 1657/5184\n",
      "0.05 1 6 5 sqrt friedman_mse 0.5 50: Weighted 0.808384 (0.074778)\n",
      "0.05 1 6 5 sqrt friedman_mse 0.5 50: Macro 0.699211 (0.108271)\n",
      "Testing 1658/5184\n",
      "0.05 1 6 5 sqrt friedman_mse 0.5 100: Weighted 0.806493 (0.054742)\n",
      "0.05 1 6 5 sqrt friedman_mse 0.5 100: Macro 0.697777 (0.082754)\n",
      "Testing 1659/5184\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05 1 6 5 sqrt friedman_mse 0.5 200: Weighted 0.818413 (0.069234)\n",
      "0.05 1 6 5 sqrt friedman_mse 0.5 200: Macro 0.711919 (0.104793)\n",
      "Testing 1660/5184\n",
      "0.05 1 6 5 sqrt friedman_mse 0.5 500: Weighted 0.802618 (0.073333)\n",
      "0.05 1 6 5 sqrt friedman_mse 0.5 500: Macro 0.703147 (0.110601)\n",
      "Testing 1661/5184\n",
      "0.05 1 6 5 sqrt friedman_mse 0.75 50: Weighted 0.789296 (0.060883)\n",
      "0.05 1 6 5 sqrt friedman_mse 0.75 50: Macro 0.680732 (0.092238)\n",
      "Testing 1662/5184\n",
      "0.05 1 6 5 sqrt friedman_mse 0.75 100: Weighted 0.815470 (0.075334)\n",
      "0.05 1 6 5 sqrt friedman_mse 0.75 100: Macro 0.711608 (0.107436)\n",
      "Testing 1663/5184\n",
      "0.05 1 6 5 sqrt friedman_mse 0.75 200: Weighted 0.812038 (0.066324)\n",
      "0.05 1 6 5 sqrt friedman_mse 0.75 200: Macro 0.712197 (0.095777)\n",
      "Testing 1664/5184\n",
      "0.05 1 6 5 sqrt friedman_mse 0.75 500: Weighted 0.801004 (0.078659)\n",
      "0.05 1 6 5 sqrt friedman_mse 0.75 500: Macro 0.697447 (0.123710)\n",
      "Testing 1665/5184\n",
      "0.05 1 6 5 sqrt friedman_mse 1.0 50: Weighted 0.798035 (0.072717)\n",
      "0.05 1 6 5 sqrt friedman_mse 1.0 50: Macro 0.692202 (0.105111)\n",
      "Testing 1666/5184\n",
      "0.05 1 6 5 sqrt friedman_mse 1.0 100: Weighted 0.802245 (0.069560)\n",
      "0.05 1 6 5 sqrt friedman_mse 1.0 100: Macro 0.695014 (0.102867)\n",
      "Testing 1667/5184\n",
      "0.05 1 6 5 sqrt friedman_mse 1.0 200: Weighted 0.802725 (0.072672)\n",
      "0.05 1 6 5 sqrt friedman_mse 1.0 200: Macro 0.704291 (0.110070)\n",
      "Testing 1668/5184\n",
      "0.05 1 6 5 sqrt friedman_mse 1.0 500: Weighted 0.790466 (0.085467)\n",
      "0.05 1 6 5 sqrt friedman_mse 1.0 500: Macro 0.683379 (0.131852)\n",
      "Testing 1669/5184\n",
      "0.05 1 6 5 sqrt mae 0.5 50: Weighted 0.798945 (0.042398)\n",
      "0.05 1 6 5 sqrt mae 0.5 50: Macro 0.676390 (0.061267)\n",
      "Testing 1670/5184\n",
      "0.05 1 6 5 sqrt mae 0.5 100: Weighted 0.786478 (0.045541)\n",
      "0.05 1 6 5 sqrt mae 0.5 100: Macro 0.668067 (0.068900)\n",
      "Testing 1671/5184\n",
      "0.05 1 6 5 sqrt mae 0.5 200: Weighted 0.790770 (0.058278)\n",
      "0.05 1 6 5 sqrt mae 0.5 200: Macro 0.667424 (0.090778)\n",
      "Testing 1672/5184\n",
      "0.05 1 6 5 sqrt mae 0.5 500: Weighted 0.786473 (0.063423)\n",
      "0.05 1 6 5 sqrt mae 0.5 500: Macro 0.666194 (0.099531)\n",
      "Testing 1673/5184\n",
      "0.05 1 6 5 sqrt mae 0.75 50: Weighted 0.767514 (0.063809)\n",
      "0.05 1 6 5 sqrt mae 0.75 50: Macro 0.648246 (0.087986)\n",
      "Testing 1674/5184\n",
      "0.05 1 6 5 sqrt mae 0.75 100: Weighted 0.771592 (0.069428)\n",
      "0.05 1 6 5 sqrt mae 0.75 100: Macro 0.648108 (0.102932)\n",
      "Testing 1675/5184\n",
      "0.05 1 6 5 sqrt mae 0.75 200: Weighted 0.755086 (0.068576)\n",
      "0.05 1 6 5 sqrt mae 0.75 200: Macro 0.620717 (0.095814)\n",
      "Testing 1676/5184\n",
      "0.05 1 6 5 sqrt mae 0.75 500: Weighted 0.788639 (0.071083)\n",
      "0.05 1 6 5 sqrt mae 0.75 500: Macro 0.665468 (0.105254)\n",
      "Testing 1677/5184\n",
      "0.05 1 6 5 sqrt mae 1.0 50: Weighted 0.770425 (0.043961)\n",
      "0.05 1 6 5 sqrt mae 1.0 50: Macro 0.637781 (0.068750)\n",
      "Testing 1678/5184\n",
      "0.05 1 6 5 sqrt mae 1.0 100: Weighted 0.783130 (0.076306)\n",
      "0.05 1 6 5 sqrt mae 1.0 100: Macro 0.660251 (0.117731)\n",
      "Testing 1679/5184\n",
      "0.05 1 6 5 sqrt mae 1.0 200: Weighted 0.775271 (0.071819)\n",
      "0.05 1 6 5 sqrt mae 1.0 200: Macro 0.643118 (0.104200)\n",
      "Testing 1680/5184\n",
      "0.05 1 6 5 sqrt mae 1.0 500: Weighted 0.789404 (0.073234)\n",
      "0.05 1 6 5 sqrt mae 1.0 500: Macro 0.667730 (0.108016)\n",
      "Testing 1681/5184\n",
      "0.05 1 6 8 log2 friedman_mse 0.5 50: Weighted 0.808613 (0.053317)\n",
      "0.05 1 6 8 log2 friedman_mse 0.5 50: Macro 0.699645 (0.072123)\n",
      "Testing 1682/5184\n",
      "0.05 1 6 8 log2 friedman_mse 0.5 100: Weighted 0.814499 (0.081151)\n",
      "0.05 1 6 8 log2 friedman_mse 0.5 100: Macro 0.711607 (0.115372)\n",
      "Testing 1683/5184\n",
      "0.05 1 6 8 log2 friedman_mse 0.5 200: Weighted 0.809715 (0.079904)\n",
      "0.05 1 6 8 log2 friedman_mse 0.5 200: Macro 0.707554 (0.121828)\n",
      "Testing 1684/5184\n",
      "0.05 1 6 8 log2 friedman_mse 0.5 500: Weighted 0.809020 (0.084987)\n",
      "0.05 1 6 8 log2 friedman_mse 0.5 500: Macro 0.703928 (0.133362)\n",
      "Testing 1685/5184\n",
      "0.05 1 6 8 log2 friedman_mse 0.75 50: Weighted 0.799739 (0.050227)\n",
      "0.05 1 6 8 log2 friedman_mse 0.75 50: Macro 0.698398 (0.071964)\n",
      "Testing 1686/5184\n",
      "0.05 1 6 8 log2 friedman_mse 0.75 100: Weighted 0.821875 (0.074141)\n",
      "0.05 1 6 8 log2 friedman_mse 0.75 100: Macro 0.721346 (0.106756)\n",
      "Testing 1687/5184\n",
      "0.05 1 6 8 log2 friedman_mse 0.75 200: Weighted 0.820039 (0.076852)\n",
      "0.05 1 6 8 log2 friedman_mse 0.75 200: Macro 0.723361 (0.117339)\n",
      "Testing 1688/5184\n",
      "0.05 1 6 8 log2 friedman_mse 0.75 500: Weighted 0.813843 (0.088018)\n",
      "0.05 1 6 8 log2 friedman_mse 0.75 500: Macro 0.712454 (0.137772)\n",
      "Testing 1689/5184\n",
      "0.05 1 6 8 log2 friedman_mse 1.0 50: Weighted 0.790515 (0.075519)\n",
      "0.05 1 6 8 log2 friedman_mse 1.0 50: Macro 0.677493 (0.111671)\n",
      "Testing 1690/5184\n",
      "0.05 1 6 8 log2 friedman_mse 1.0 100: Weighted 0.794109 (0.076628)\n",
      "0.05 1 6 8 log2 friedman_mse 1.0 100: Macro 0.688523 (0.114965)\n",
      "Testing 1691/5184\n",
      "0.05 1 6 8 log2 friedman_mse 1.0 200: Weighted 0.800048 (0.057120)\n",
      "0.05 1 6 8 log2 friedman_mse 1.0 200: Macro 0.697043 (0.087549)\n",
      "Testing 1692/5184\n",
      "0.05 1 6 8 log2 friedman_mse 1.0 500: Weighted 0.782351 (0.065697)\n",
      "0.05 1 6 8 log2 friedman_mse 1.0 500: Macro 0.680913 (0.094613)\n",
      "Testing 1693/5184\n",
      "0.05 1 6 8 log2 mae 0.5 50: Weighted 0.784338 (0.047004)\n",
      "0.05 1 6 8 log2 mae 0.5 50: Macro 0.669754 (0.066075)\n",
      "Testing 1694/5184\n",
      "0.05 1 6 8 log2 mae 0.5 100: Weighted 0.801291 (0.050915)\n",
      "0.05 1 6 8 log2 mae 0.5 100: Macro 0.690767 (0.077915)\n",
      "Testing 1695/5184\n",
      "0.05 1 6 8 log2 mae 0.5 200: Weighted 0.805567 (0.064210)\n",
      "0.05 1 6 8 log2 mae 0.5 200: Macro 0.694366 (0.104896)\n",
      "Testing 1696/5184\n",
      "0.05 1 6 8 log2 mae 0.5 500: Weighted 0.810316 (0.057442)\n",
      "0.05 1 6 8 log2 mae 0.5 500: Macro 0.706405 (0.086264)\n",
      "Testing 1697/5184\n",
      "0.05 1 6 8 log2 mae 0.75 50: Weighted 0.789828 (0.053454)\n",
      "0.05 1 6 8 log2 mae 0.75 50: Macro 0.669308 (0.084686)\n",
      "Testing 1698/5184\n",
      "0.05 1 6 8 log2 mae 0.75 100: Weighted 0.788837 (0.063301)\n",
      "0.05 1 6 8 log2 mae 0.75 100: Macro 0.670690 (0.096883)\n",
      "Testing 1699/5184\n",
      "0.05 1 6 8 log2 mae 0.75 200: Weighted 0.780232 (0.061436)\n",
      "0.05 1 6 8 log2 mae 0.75 200: Macro 0.658010 (0.088082)\n",
      "Testing 1700/5184\n",
      "0.05 1 6 8 log2 mae 0.75 500: Weighted 0.779423 (0.090069)\n",
      "0.05 1 6 8 log2 mae 0.75 500: Macro 0.653986 (0.142033)\n",
      "Testing 1701/5184\n",
      "0.05 1 6 8 log2 mae 1.0 50: Weighted 0.765250 (0.069308)\n",
      "0.05 1 6 8 log2 mae 1.0 50: Macro 0.627774 (0.106822)\n",
      "Testing 1702/5184\n",
      "0.05 1 6 8 log2 mae 1.0 100: Weighted 0.784064 (0.065054)\n",
      "0.05 1 6 8 log2 mae 1.0 100: Macro 0.664399 (0.092437)\n",
      "Testing 1703/5184\n",
      "0.05 1 6 8 log2 mae 1.0 200: Weighted 0.759333 (0.077471)\n",
      "0.05 1 6 8 log2 mae 1.0 200: Macro 0.626117 (0.114214)\n",
      "Testing 1704/5184\n",
      "0.05 1 6 8 log2 mae 1.0 500: Weighted 0.789426 (0.071573)\n",
      "0.05 1 6 8 log2 mae 1.0 500: Macro 0.679898 (0.104954)\n",
      "Testing 1705/5184\n",
      "0.05 1 6 8 sqrt friedman_mse 0.5 50: Weighted 0.806827 (0.054518)\n",
      "0.05 1 6 8 sqrt friedman_mse 0.5 50: Macro 0.709439 (0.073715)\n",
      "Testing 1706/5184\n",
      "0.05 1 6 8 sqrt friedman_mse 0.5 100: Weighted 0.815518 (0.079349)\n",
      "0.05 1 6 8 sqrt friedman_mse 0.5 100: Macro 0.711191 (0.115504)\n",
      "Testing 1707/5184\n",
      "0.05 1 6 8 sqrt friedman_mse 0.5 200: Weighted 0.814759 (0.079790)\n",
      "0.05 1 6 8 sqrt friedman_mse 0.5 200: Macro 0.715003 (0.122071)\n",
      "Testing 1708/5184\n",
      "0.05 1 6 8 sqrt friedman_mse 0.5 500: Weighted 0.818258 (0.085850)\n",
      "0.05 1 6 8 sqrt friedman_mse 0.5 500: Macro 0.715764 (0.135973)\n",
      "Testing 1709/5184\n",
      "0.05 1 6 8 sqrt friedman_mse 0.75 50: Weighted 0.809971 (0.070132)\n",
      "0.05 1 6 8 sqrt friedman_mse 0.75 50: Macro 0.709120 (0.086969)\n",
      "Testing 1710/5184\n",
      "0.05 1 6 8 sqrt friedman_mse 0.75 100: Weighted 0.812972 (0.070903)\n",
      "0.05 1 6 8 sqrt friedman_mse 0.75 100: Macro 0.710301 (0.098261)\n",
      "Testing 1711/5184\n",
      "0.05 1 6 8 sqrt friedman_mse 0.75 200: Weighted 0.818926 (0.090070)\n",
      "0.05 1 6 8 sqrt friedman_mse 0.75 200: Macro 0.716057 (0.135672)\n",
      "Testing 1712/5184\n",
      "0.05 1 6 8 sqrt friedman_mse 0.75 500: Weighted 0.804655 (0.071847)\n",
      "0.05 1 6 8 sqrt friedman_mse 0.75 500: Macro 0.699080 (0.115757)\n",
      "Testing 1713/5184\n",
      "0.05 1 6 8 sqrt friedman_mse 1.0 50: Weighted 0.800703 (0.078433)\n",
      "0.05 1 6 8 sqrt friedman_mse 1.0 50: Macro 0.693471 (0.117980)\n",
      "Testing 1714/5184\n",
      "0.05 1 6 8 sqrt friedman_mse 1.0 100: Weighted 0.786470 (0.062814)\n",
      "0.05 1 6 8 sqrt friedman_mse 1.0 100: Macro 0.682010 (0.087160)\n",
      "Testing 1715/5184\n",
      "0.05 1 6 8 sqrt friedman_mse 1.0 200: Weighted 0.794798 (0.073623)\n",
      "0.05 1 6 8 sqrt friedman_mse 1.0 200: Macro 0.688950 (0.114686)\n",
      "Testing 1716/5184\n",
      "0.05 1 6 8 sqrt friedman_mse 1.0 500: Weighted 0.791895 (0.068343)\n",
      "0.05 1 6 8 sqrt friedman_mse 1.0 500: Macro 0.687384 (0.097162)\n",
      "Testing 1717/5184\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05 1 6 8 sqrt mae 0.5 50: Weighted 0.797600 (0.044006)\n",
      "0.05 1 6 8 sqrt mae 0.5 50: Macro 0.684553 (0.066637)\n",
      "Testing 1718/5184\n",
      "0.05 1 6 8 sqrt mae 0.5 100: Weighted 0.792320 (0.066572)\n",
      "0.05 1 6 8 sqrt mae 0.5 100: Macro 0.679598 (0.098701)\n",
      "Testing 1719/5184\n",
      "0.05 1 6 8 sqrt mae 0.5 200: Weighted 0.787786 (0.061738)\n",
      "0.05 1 6 8 sqrt mae 0.5 200: Macro 0.671404 (0.093261)\n",
      "Testing 1720/5184\n",
      "0.05 1 6 8 sqrt mae 0.5 500: Weighted 0.788776 (0.042483)\n",
      "0.05 1 6 8 sqrt mae 0.5 500: Macro 0.673375 (0.062737)\n",
      "Testing 1721/5184\n",
      "0.05 1 6 8 sqrt mae 0.75 50: Weighted 0.800735 (0.041422)\n",
      "0.05 1 6 8 sqrt mae 0.75 50: Macro 0.682004 (0.070393)\n",
      "Testing 1722/5184\n",
      "0.05 1 6 8 sqrt mae 0.75 100: Weighted 0.783713 (0.066749)\n",
      "0.05 1 6 8 sqrt mae 0.75 100: Macro 0.657901 (0.101698)\n",
      "Testing 1723/5184\n",
      "0.05 1 6 8 sqrt mae 0.75 200: Weighted 0.785593 (0.073516)\n",
      "0.05 1 6 8 sqrt mae 0.75 200: Macro 0.668998 (0.110127)\n",
      "Testing 1724/5184\n",
      "0.05 1 6 8 sqrt mae 0.75 500: Weighted 0.794888 (0.073342)\n",
      "0.05 1 6 8 sqrt mae 0.75 500: Macro 0.681704 (0.111730)\n",
      "Testing 1725/5184\n",
      "0.05 1 6 8 sqrt mae 1.0 50: Weighted 0.773644 (0.055434)\n",
      "0.05 1 6 8 sqrt mae 1.0 50: Macro 0.648986 (0.090779)\n",
      "Testing 1726/5184\n",
      "0.05 1 6 8 sqrt mae 1.0 100: Weighted 0.756468 (0.066649)\n",
      "0.05 1 6 8 sqrt mae 1.0 100: Macro 0.623889 (0.102926)\n",
      "Testing 1727/5184\n",
      "0.05 1 6 8 sqrt mae 1.0 200: Weighted 0.786928 (0.064108)\n",
      "0.05 1 6 8 sqrt mae 1.0 200: Macro 0.670999 (0.096817)\n",
      "Testing 1728/5184\n",
      "0.05 1 6 8 sqrt mae 1.0 500: Weighted 0.794922 (0.075343)\n",
      "0.05 1 6 8 sqrt mae 1.0 500: Macro 0.681812 (0.115366)\n",
      "Testing 1729/5184\n",
      "0.05 3 2 3 log2 friedman_mse 0.5 50: Weighted 0.815664 (0.061957)\n",
      "0.05 3 2 3 log2 friedman_mse 0.5 50: Macro 0.703549 (0.089096)\n",
      "Testing 1730/5184\n",
      "0.05 3 2 3 log2 friedman_mse 0.5 100: Weighted 0.812099 (0.066572)\n",
      "0.05 3 2 3 log2 friedman_mse 0.5 100: Macro 0.706600 (0.085068)\n",
      "Testing 1731/5184\n",
      "0.05 3 2 3 log2 friedman_mse 0.5 200: Weighted 0.804864 (0.050249)\n",
      "0.05 3 2 3 log2 friedman_mse 0.5 200: Macro 0.699953 (0.080262)\n",
      "Testing 1732/5184\n",
      "0.05 3 2 3 log2 friedman_mse 0.5 500: Weighted 0.810693 (0.053234)\n",
      "0.05 3 2 3 log2 friedman_mse 0.5 500: Macro 0.713604 (0.071842)\n",
      "Testing 1733/5184\n",
      "0.05 3 2 3 log2 friedman_mse 0.75 50: Weighted 0.800940 (0.062267)\n",
      "0.05 3 2 3 log2 friedman_mse 0.75 50: Macro 0.692961 (0.074819)\n",
      "Testing 1734/5184\n",
      "0.05 3 2 3 log2 friedman_mse 0.75 100: Weighted 0.800061 (0.061984)\n",
      "0.05 3 2 3 log2 friedman_mse 0.75 100: Macro 0.698658 (0.080843)\n",
      "Testing 1735/5184\n",
      "0.05 3 2 3 log2 friedman_mse 0.75 200: Weighted 0.807625 (0.065991)\n",
      "0.05 3 2 3 log2 friedman_mse 0.75 200: Macro 0.704307 (0.093238)\n",
      "Testing 1736/5184\n",
      "0.05 3 2 3 log2 friedman_mse 0.75 500: Weighted 0.814144 (0.045052)\n",
      "0.05 3 2 3 log2 friedman_mse 0.75 500: Macro 0.717596 (0.060361)\n",
      "Testing 1737/5184\n",
      "0.05 3 2 3 log2 friedman_mse 1.0 50: Weighted 0.796689 (0.064054)\n",
      "0.05 3 2 3 log2 friedman_mse 1.0 50: Macro 0.682586 (0.081616)\n",
      "Testing 1738/5184\n",
      "0.05 3 2 3 log2 friedman_mse 1.0 100: Weighted 0.803804 (0.074834)\n",
      "0.05 3 2 3 log2 friedman_mse 1.0 100: Macro 0.701442 (0.097551)\n",
      "Testing 1739/5184\n",
      "0.05 3 2 3 log2 friedman_mse 1.0 200: Weighted 0.808113 (0.068203)\n",
      "0.05 3 2 3 log2 friedman_mse 1.0 200: Macro 0.707151 (0.099175)\n",
      "Testing 1740/5184\n",
      "0.05 3 2 3 log2 friedman_mse 1.0 500: Weighted 0.811576 (0.054947)\n",
      "0.05 3 2 3 log2 friedman_mse 1.0 500: Macro 0.717175 (0.080458)\n",
      "Testing 1741/5184\n",
      "0.05 3 2 3 log2 mae 0.5 50: Weighted 0.825270 (0.045645)\n",
      "0.05 3 2 3 log2 mae 0.5 50: Macro 0.718224 (0.063144)\n",
      "Testing 1742/5184\n",
      "0.05 3 2 3 log2 mae 0.5 100: Weighted 0.811731 (0.058107)\n",
      "0.05 3 2 3 log2 mae 0.5 100: Macro 0.698616 (0.080900)\n",
      "Testing 1743/5184\n",
      "0.05 3 2 3 log2 mae 0.5 200: Weighted 0.789951 (0.069146)\n",
      "0.05 3 2 3 log2 mae 0.5 200: Macro 0.671135 (0.095092)\n",
      "Testing 1744/5184\n",
      "0.05 3 2 3 log2 mae 0.5 500: Weighted 0.788802 (0.072209)\n",
      "0.05 3 2 3 log2 mae 0.5 500: Macro 0.664029 (0.109415)\n",
      "Testing 1745/5184\n",
      "0.05 3 2 3 log2 mae 0.75 50: Weighted 0.792872 (0.066257)\n",
      "0.05 3 2 3 log2 mae 0.75 50: Macro 0.677003 (0.094907)\n",
      "Testing 1746/5184\n",
      "0.05 3 2 3 log2 mae 0.75 100: Weighted 0.787467 (0.061662)\n",
      "0.05 3 2 3 log2 mae 0.75 100: Macro 0.675750 (0.081792)\n",
      "Testing 1747/5184\n",
      "0.05 3 2 3 log2 mae 0.75 200: Weighted 0.774677 (0.073485)\n",
      "0.05 3 2 3 log2 mae 0.75 200: Macro 0.650522 (0.105421)\n",
      "Testing 1748/5184\n",
      "0.05 3 2 3 log2 mae 0.75 500: Weighted 0.759272 (0.071552)\n",
      "0.05 3 2 3 log2 mae 0.75 500: Macro 0.616926 (0.103701)\n",
      "Testing 1749/5184\n",
      "0.05 3 2 3 log2 mae 1.0 50: Weighted 0.789853 (0.064311)\n",
      "0.05 3 2 3 log2 mae 1.0 50: Macro 0.674832 (0.088769)\n",
      "Testing 1750/5184\n",
      "0.05 3 2 3 log2 mae 1.0 100: Weighted 0.790579 (0.075003)\n",
      "0.05 3 2 3 log2 mae 1.0 100: Macro 0.675811 (0.108269)\n",
      "Testing 1751/5184\n",
      "0.05 3 2 3 log2 mae 1.0 200: Weighted 0.755962 (0.071356)\n",
      "0.05 3 2 3 log2 mae 1.0 200: Macro 0.617241 (0.100708)\n",
      "Testing 1752/5184\n",
      "0.05 3 2 3 log2 mae 1.0 500: Weighted 0.757009 (0.073990)\n",
      "0.05 3 2 3 log2 mae 1.0 500: Macro 0.614579 (0.097707)\n",
      "Testing 1753/5184\n",
      "0.05 3 2 3 sqrt friedman_mse 0.5 50: Weighted 0.824503 (0.061009)\n",
      "0.05 3 2 3 sqrt friedman_mse 0.5 50: Macro 0.721504 (0.081658)\n",
      "Testing 1754/5184\n",
      "0.05 3 2 3 sqrt friedman_mse 0.5 100: Weighted 0.805913 (0.067930)\n",
      "0.05 3 2 3 sqrt friedman_mse 0.5 100: Macro 0.693732 (0.091367)\n",
      "Testing 1755/5184\n",
      "0.05 3 2 3 sqrt friedman_mse 0.5 200: Weighted 0.805365 (0.056937)\n",
      "0.05 3 2 3 sqrt friedman_mse 0.5 200: Macro 0.703335 (0.082261)\n",
      "Testing 1756/5184\n",
      "0.05 3 2 3 sqrt friedman_mse 0.5 500: Weighted 0.805683 (0.056438)\n",
      "0.05 3 2 3 sqrt friedman_mse 0.5 500: Macro 0.693039 (0.085202)\n",
      "Testing 1757/5184\n",
      "0.05 3 2 3 sqrt friedman_mse 0.75 50: Weighted 0.816244 (0.044292)\n",
      "0.05 3 2 3 sqrt friedman_mse 0.75 50: Macro 0.709713 (0.055162)\n",
      "Testing 1758/5184\n",
      "0.05 3 2 3 sqrt friedman_mse 0.75 100: Weighted 0.813958 (0.059677)\n",
      "0.05 3 2 3 sqrt friedman_mse 0.75 100: Macro 0.713210 (0.078055)\n",
      "Testing 1759/5184\n",
      "0.05 3 2 3 sqrt friedman_mse 0.75 200: Weighted 0.810133 (0.059968)\n",
      "0.05 3 2 3 sqrt friedman_mse 0.75 200: Macro 0.712727 (0.079639)\n",
      "Testing 1760/5184\n",
      "0.05 3 2 3 sqrt friedman_mse 0.75 500: Weighted 0.815598 (0.050475)\n",
      "0.05 3 2 3 sqrt friedman_mse 0.75 500: Macro 0.722597 (0.074998)\n",
      "Testing 1761/5184\n",
      "0.05 3 2 3 sqrt friedman_mse 1.0 50: Weighted 0.794319 (0.061939)\n",
      "0.05 3 2 3 sqrt friedman_mse 1.0 50: Macro 0.685424 (0.081356)\n",
      "Testing 1762/5184\n",
      "0.05 3 2 3 sqrt friedman_mse 1.0 100: Weighted 0.804539 (0.069809)\n",
      "0.05 3 2 3 sqrt friedman_mse 1.0 100: Macro 0.699680 (0.086915)\n",
      "Testing 1763/5184\n",
      "0.05 3 2 3 sqrt friedman_mse 1.0 200: Weighted 0.798991 (0.056057)\n",
      "0.05 3 2 3 sqrt friedman_mse 1.0 200: Macro 0.696024 (0.084912)\n",
      "Testing 1764/5184\n",
      "0.05 3 2 3 sqrt friedman_mse 1.0 500: Weighted 0.806738 (0.048649)\n",
      "0.05 3 2 3 sqrt friedman_mse 1.0 500: Macro 0.706782 (0.067195)\n",
      "Testing 1765/5184\n",
      "0.05 3 2 3 sqrt mae 0.5 50: Weighted 0.811508 (0.063551)\n",
      "0.05 3 2 3 sqrt mae 0.5 50: Macro 0.700323 (0.087626)\n",
      "Testing 1766/5184\n",
      "0.05 3 2 3 sqrt mae 0.5 100: Weighted 0.804871 (0.058416)\n",
      "0.05 3 2 3 sqrt mae 0.5 100: Macro 0.686361 (0.084070)\n",
      "Testing 1767/5184\n",
      "0.05 3 2 3 sqrt mae 0.5 200: Weighted 0.789199 (0.066919)\n",
      "0.05 3 2 3 sqrt mae 0.5 200: Macro 0.670541 (0.097703)\n",
      "Testing 1768/5184\n",
      "0.05 3 2 3 sqrt mae 0.5 500: Weighted 0.785393 (0.068482)\n",
      "0.05 3 2 3 sqrt mae 0.5 500: Macro 0.658653 (0.097510)\n",
      "Testing 1769/5184\n",
      "0.05 3 2 3 sqrt mae 0.75 50: Weighted 0.795162 (0.061721)\n",
      "0.05 3 2 3 sqrt mae 0.75 50: Macro 0.677930 (0.082004)\n",
      "Testing 1770/5184\n",
      "0.05 3 2 3 sqrt mae 0.75 100: Weighted 0.800803 (0.069062)\n",
      "0.05 3 2 3 sqrt mae 0.75 100: Macro 0.680296 (0.099295)\n",
      "Testing 1771/5184\n",
      "0.05 3 2 3 sqrt mae 0.75 200: Weighted 0.775693 (0.080617)\n",
      "0.05 3 2 3 sqrt mae 0.75 200: Macro 0.654351 (0.117219)\n",
      "Testing 1772/5184\n",
      "0.05 3 2 3 sqrt mae 0.75 500: Weighted 0.771665 (0.074838)\n",
      "0.05 3 2 3 sqrt mae 0.75 500: Macro 0.634422 (0.101273)\n",
      "Testing 1773/5184\n",
      "0.05 3 2 3 sqrt mae 1.0 50: Weighted 0.792544 (0.058598)\n",
      "0.05 3 2 3 sqrt mae 1.0 50: Macro 0.673780 (0.083641)\n",
      "Testing 1774/5184\n",
      "0.05 3 2 3 sqrt mae 1.0 100: Weighted 0.782044 (0.076592)\n",
      "0.05 3 2 3 sqrt mae 1.0 100: Macro 0.665614 (0.108339)\n",
      "Testing 1775/5184\n",
      "0.05 3 2 3 sqrt mae 1.0 200: Weighted 0.769782 (0.063090)\n",
      "0.05 3 2 3 sqrt mae 1.0 200: Macro 0.642605 (0.094249)\n",
      "Testing 1776/5184\n",
      "0.05 3 2 3 sqrt mae 1.0 500: Weighted 0.763478 (0.072004)\n",
      "0.05 3 2 3 sqrt mae 1.0 500: Macro 0.627778 (0.101411)\n",
      "Testing 1777/5184\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05 3 2 5 log2 friedman_mse 0.5 50: Weighted 0.798125 (0.067846)\n",
      "0.05 3 2 5 log2 friedman_mse 0.5 50: Macro 0.691205 (0.088853)\n",
      "Testing 1778/5184\n",
      "0.05 3 2 5 log2 friedman_mse 0.5 100: Weighted 0.829736 (0.075199)\n",
      "0.05 3 2 5 log2 friedman_mse 0.5 100: Macro 0.729691 (0.108171)\n",
      "Testing 1779/5184\n",
      "0.05 3 2 5 log2 friedman_mse 0.5 200: Weighted 0.815433 (0.062583)\n",
      "0.05 3 2 5 log2 friedman_mse 0.5 200: Macro 0.718786 (0.095056)\n",
      "Testing 1780/5184\n",
      "0.05 3 2 5 log2 friedman_mse 0.5 500: Weighted 0.797864 (0.088913)\n",
      "0.05 3 2 5 log2 friedman_mse 0.5 500: Macro 0.696854 (0.135608)\n",
      "Testing 1781/5184\n",
      "0.05 3 2 5 log2 friedman_mse 0.75 50: Weighted 0.791022 (0.064818)\n",
      "0.05 3 2 5 log2 friedman_mse 0.75 50: Macro 0.677906 (0.086910)\n",
      "Testing 1782/5184\n",
      "0.05 3 2 5 log2 friedman_mse 0.75 100: Weighted 0.811501 (0.077783)\n",
      "0.05 3 2 5 log2 friedman_mse 0.75 100: Macro 0.714100 (0.104537)\n",
      "Testing 1783/5184\n",
      "0.05 3 2 5 log2 friedman_mse 0.75 200: Weighted 0.821311 (0.085962)\n",
      "0.05 3 2 5 log2 friedman_mse 0.75 200: Macro 0.721274 (0.125657)\n",
      "Testing 1784/5184\n",
      "0.05 3 2 5 log2 friedman_mse 0.75 500: Weighted 0.812463 (0.075215)\n",
      "0.05 3 2 5 log2 friedman_mse 0.75 500: Macro 0.706273 (0.118279)\n",
      "Testing 1785/5184\n",
      "0.05 3 2 5 log2 friedman_mse 1.0 50: Weighted 0.797778 (0.068768)\n",
      "0.05 3 2 5 log2 friedman_mse 1.0 50: Macro 0.698640 (0.082894)\n",
      "Testing 1786/5184\n",
      "0.05 3 2 5 log2 friedman_mse 1.0 100: Weighted 0.802313 (0.073558)\n",
      "0.05 3 2 5 log2 friedman_mse 1.0 100: Macro 0.705860 (0.101250)\n",
      "Testing 1787/5184\n",
      "0.05 3 2 5 log2 friedman_mse 1.0 200: Weighted 0.807910 (0.079240)\n",
      "0.05 3 2 5 log2 friedman_mse 1.0 200: Macro 0.705282 (0.115747)\n",
      "Testing 1788/5184\n",
      "0.05 3 2 5 log2 friedman_mse 1.0 500: Weighted 0.803432 (0.080770)\n",
      "0.05 3 2 5 log2 friedman_mse 1.0 500: Macro 0.702133 (0.116494)\n",
      "Testing 1789/5184\n",
      "0.05 3 2 5 log2 mae 0.5 50: Weighted 0.800068 (0.062029)\n",
      "0.05 3 2 5 log2 mae 0.5 50: Macro 0.683420 (0.085942)\n",
      "Testing 1790/5184\n",
      "0.05 3 2 5 log2 mae 0.5 100: Weighted 0.797710 (0.074314)\n",
      "0.05 3 2 5 log2 mae 0.5 100: Macro 0.682913 (0.097921)\n",
      "Testing 1791/5184\n",
      "0.05 3 2 5 log2 mae 0.5 200: Weighted 0.788741 (0.080394)\n",
      "0.05 3 2 5 log2 mae 0.5 200: Macro 0.665326 (0.113802)\n",
      "Testing 1792/5184\n",
      "0.05 3 2 5 log2 mae 0.5 500: Weighted 0.791501 (0.083972)\n",
      "0.05 3 2 5 log2 mae 0.5 500: Macro 0.668849 (0.116892)\n",
      "Testing 1793/5184\n",
      "0.05 3 2 5 log2 mae 0.75 50: Weighted 0.781575 (0.079962)\n",
      "0.05 3 2 5 log2 mae 0.75 50: Macro 0.661699 (0.105405)\n",
      "Testing 1794/5184\n",
      "0.05 3 2 5 log2 mae 0.75 100: Weighted 0.789763 (0.078780)\n",
      "0.05 3 2 5 log2 mae 0.75 100: Macro 0.666449 (0.113874)\n",
      "Testing 1795/5184\n",
      "0.05 3 2 5 log2 mae 0.75 200: Weighted 0.780572 (0.063775)\n",
      "0.05 3 2 5 log2 mae 0.75 200: Macro 0.642904 (0.083431)\n",
      "Testing 1796/5184\n",
      "0.05 3 2 5 log2 mae 0.75 500: Weighted 0.785770 (0.069650)\n",
      "0.05 3 2 5 log2 mae 0.75 500: Macro 0.651416 (0.089766)\n",
      "Testing 1797/5184\n",
      "0.05 3 2 5 log2 mae 1.0 50: Weighted 0.773674 (0.072723)\n",
      "0.05 3 2 5 log2 mae 1.0 50: Macro 0.644050 (0.108957)\n",
      "Testing 1798/5184\n",
      "0.05 3 2 5 log2 mae 1.0 100: Weighted 0.776022 (0.083585)\n",
      "0.05 3 2 5 log2 mae 1.0 100: Macro 0.640723 (0.117331)\n",
      "Testing 1799/5184\n",
      "0.05 3 2 5 log2 mae 1.0 200: Weighted 0.779896 (0.084465)\n",
      "0.05 3 2 5 log2 mae 1.0 200: Macro 0.643995 (0.110917)\n",
      "Testing 1800/5184\n",
      "0.05 3 2 5 log2 mae 1.0 500: Weighted 0.784319 (0.097615)\n",
      "0.05 3 2 5 log2 mae 1.0 500: Macro 0.651943 (0.133832)\n",
      "Testing 1801/5184\n",
      "0.05 3 2 5 sqrt friedman_mse 0.5 50: Weighted 0.817416 (0.057527)\n",
      "0.05 3 2 5 sqrt friedman_mse 0.5 50: Macro 0.718010 (0.075136)\n",
      "Testing 1802/5184\n",
      "0.05 3 2 5 sqrt friedman_mse 0.5 100: Weighted 0.813144 (0.071336)\n",
      "0.05 3 2 5 sqrt friedman_mse 0.5 100: Macro 0.703747 (0.104606)\n",
      "Testing 1803/5184\n",
      "0.05 3 2 5 sqrt friedman_mse 0.5 200: Weighted 0.809597 (0.065364)\n",
      "0.05 3 2 5 sqrt friedman_mse 0.5 200: Macro 0.705890 (0.094641)\n",
      "Testing 1804/5184\n",
      "0.05 3 2 5 sqrt friedman_mse 0.5 500: Weighted 0.802740 (0.074325)\n",
      "0.05 3 2 5 sqrt friedman_mse 0.5 500: Macro 0.700230 (0.115650)\n",
      "Testing 1805/5184\n",
      "0.05 3 2 5 sqrt friedman_mse 0.75 50: Weighted 0.804624 (0.067387)\n",
      "0.05 3 2 5 sqrt friedman_mse 0.75 50: Macro 0.697520 (0.090004)\n",
      "Testing 1806/5184\n",
      "0.05 3 2 5 sqrt friedman_mse 0.75 100: Weighted 0.807642 (0.086745)\n",
      "0.05 3 2 5 sqrt friedman_mse 0.75 100: Macro 0.708414 (0.118086)\n",
      "Testing 1807/5184\n",
      "0.05 3 2 5 sqrt friedman_mse 0.75 200: Weighted 0.802565 (0.074015)\n",
      "0.05 3 2 5 sqrt friedman_mse 0.75 200: Macro 0.697955 (0.107589)\n",
      "Testing 1808/5184\n",
      "0.05 3 2 5 sqrt friedman_mse 0.75 500: Weighted 0.816134 (0.078764)\n",
      "0.05 3 2 5 sqrt friedman_mse 0.75 500: Macro 0.716861 (0.119799)\n",
      "Testing 1809/5184\n",
      "0.05 3 2 5 sqrt friedman_mse 1.0 50: Weighted 0.799296 (0.063927)\n",
      "0.05 3 2 5 sqrt friedman_mse 1.0 50: Macro 0.688469 (0.082857)\n",
      "Testing 1810/5184\n",
      "0.05 3 2 5 sqrt friedman_mse 1.0 100: Weighted 0.808013 (0.088467)\n",
      "0.05 3 2 5 sqrt friedman_mse 1.0 100: Macro 0.708245 (0.122631)\n",
      "Testing 1811/5184\n",
      "0.05 3 2 5 sqrt friedman_mse 1.0 200: Weighted 0.806872 (0.092251)\n",
      "0.05 3 2 5 sqrt friedman_mse 1.0 200: Macro 0.698011 (0.133379)\n",
      "Testing 1812/5184\n",
      "0.05 3 2 5 sqrt friedman_mse 1.0 500: Weighted 0.820326 (0.076303)\n",
      "0.05 3 2 5 sqrt friedman_mse 1.0 500: Macro 0.718928 (0.111842)\n",
      "Testing 1813/5184\n",
      "0.05 3 2 5 sqrt mae 0.5 50: Weighted 0.800103 (0.062716)\n",
      "0.05 3 2 5 sqrt mae 0.5 50: Macro 0.687579 (0.081513)\n",
      "Testing 1814/5184\n",
      "0.05 3 2 5 sqrt mae 0.5 100: Weighted 0.799911 (0.059390)\n",
      "0.05 3 2 5 sqrt mae 0.5 100: Macro 0.677107 (0.087208)\n",
      "Testing 1815/5184\n",
      "0.05 3 2 5 sqrt mae 0.5 200: Weighted 0.796908 (0.080895)\n",
      "0.05 3 2 5 sqrt mae 0.5 200: Macro 0.675770 (0.116619)\n",
      "Testing 1816/5184\n",
      "0.05 3 2 5 sqrt mae 0.5 500: Weighted 0.800390 (0.077463)\n",
      "0.05 3 2 5 sqrt mae 0.5 500: Macro 0.677861 (0.111195)\n",
      "Testing 1817/5184\n",
      "0.05 3 2 5 sqrt mae 0.75 50: Weighted 0.782019 (0.062763)\n",
      "0.05 3 2 5 sqrt mae 0.75 50: Macro 0.661547 (0.079857)\n",
      "Testing 1818/5184\n",
      "0.05 3 2 5 sqrt mae 0.75 100: Weighted 0.762250 (0.078018)\n",
      "0.05 3 2 5 sqrt mae 0.75 100: Macro 0.624732 (0.107525)\n",
      "Testing 1819/5184\n",
      "0.05 3 2 5 sqrt mae 0.75 200: Weighted 0.787722 (0.089599)\n",
      "0.05 3 2 5 sqrt mae 0.75 200: Macro 0.659433 (0.133657)\n",
      "Testing 1820/5184\n",
      "0.05 3 2 5 sqrt mae 0.75 500: Weighted 0.767441 (0.071031)\n",
      "0.05 3 2 5 sqrt mae 0.75 500: Macro 0.621696 (0.096711)\n",
      "Testing 1821/5184\n",
      "0.05 3 2 5 sqrt mae 1.0 50: Weighted 0.788638 (0.068126)\n",
      "0.05 3 2 5 sqrt mae 1.0 50: Macro 0.665474 (0.107534)\n",
      "Testing 1822/5184\n",
      "0.05 3 2 5 sqrt mae 1.0 100: Weighted 0.783387 (0.076373)\n",
      "0.05 3 2 5 sqrt mae 1.0 100: Macro 0.653027 (0.111419)\n",
      "Testing 1823/5184\n",
      "0.05 3 2 5 sqrt mae 1.0 200: Weighted 0.754380 (0.075398)\n",
      "0.05 3 2 5 sqrt mae 1.0 200: Macro 0.609670 (0.094588)\n",
      "Testing 1824/5184\n",
      "0.05 3 2 5 sqrt mae 1.0 500: Weighted 0.773716 (0.083433)\n",
      "0.05 3 2 5 sqrt mae 1.0 500: Macro 0.637572 (0.114016)\n",
      "Testing 1825/5184\n",
      "0.05 3 2 8 log2 friedman_mse 0.5 50: Weighted 0.817261 (0.058154)\n",
      "0.05 3 2 8 log2 friedman_mse 0.5 50: Macro 0.716886 (0.074207)\n",
      "Testing 1826/5184\n",
      "0.05 3 2 8 log2 friedman_mse 0.5 100: Weighted 0.812164 (0.058508)\n",
      "0.05 3 2 8 log2 friedman_mse 0.5 100: Macro 0.707090 (0.083709)\n",
      "Testing 1827/5184\n",
      "0.05 3 2 8 log2 friedman_mse 0.5 200: Weighted 0.834392 (0.085416)\n",
      "0.05 3 2 8 log2 friedman_mse 0.5 200: Macro 0.734676 (0.128336)\n",
      "Testing 1828/5184\n",
      "0.05 3 2 8 log2 friedman_mse 0.5 500: Weighted 0.821269 (0.068500)\n",
      "0.05 3 2 8 log2 friedman_mse 0.5 500: Macro 0.714612 (0.113966)\n",
      "Testing 1829/5184\n",
      "0.05 3 2 8 log2 friedman_mse 0.75 50: Weighted 0.804936 (0.068124)\n",
      "0.05 3 2 8 log2 friedman_mse 0.75 50: Macro 0.712341 (0.080312)\n",
      "Testing 1830/5184\n",
      "0.05 3 2 8 log2 friedman_mse 0.75 100: Weighted 0.812980 (0.076755)\n",
      "0.05 3 2 8 log2 friedman_mse 0.75 100: Macro 0.712451 (0.106970)\n",
      "Testing 1831/5184\n",
      "0.05 3 2 8 log2 friedman_mse 0.75 200: Weighted 0.809875 (0.094732)\n",
      "0.05 3 2 8 log2 friedman_mse 0.75 200: Macro 0.711761 (0.142877)\n",
      "Testing 1832/5184\n",
      "0.05 3 2 8 log2 friedman_mse 0.75 500: Weighted 0.831968 (0.080561)\n",
      "0.05 3 2 8 log2 friedman_mse 0.75 500: Macro 0.738527 (0.123160)\n",
      "Testing 1833/5184\n",
      "0.05 3 2 8 log2 friedman_mse 1.0 50: Weighted 0.797165 (0.068951)\n",
      "0.05 3 2 8 log2 friedman_mse 1.0 50: Macro 0.685443 (0.094320)\n",
      "Testing 1834/5184\n",
      "0.05 3 2 8 log2 friedman_mse 1.0 100: Weighted 0.784517 (0.090177)\n",
      "0.05 3 2 8 log2 friedman_mse 1.0 100: Macro 0.672122 (0.123885)\n",
      "Testing 1835/5184\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05 3 2 8 log2 friedman_mse 1.0 200: Weighted 0.795809 (0.085450)\n",
      "0.05 3 2 8 log2 friedman_mse 1.0 200: Macro 0.688332 (0.120809)\n",
      "Testing 1836/5184\n",
      "0.05 3 2 8 log2 friedman_mse 1.0 500: Weighted 0.797042 (0.071471)\n",
      "0.05 3 2 8 log2 friedman_mse 1.0 500: Macro 0.691030 (0.108047)\n",
      "Testing 1837/5184\n",
      "0.05 3 2 8 log2 mae 0.5 50: Weighted 0.788787 (0.066354)\n",
      "0.05 3 2 8 log2 mae 0.5 50: Macro 0.666312 (0.092612)\n",
      "Testing 1838/5184\n",
      "0.05 3 2 8 log2 mae 0.5 100: Weighted 0.832036 (0.083823)\n",
      "0.05 3 2 8 log2 mae 0.5 100: Macro 0.737634 (0.120828)\n",
      "Testing 1839/5184\n",
      "0.05 3 2 8 log2 mae 0.5 200: Weighted 0.796322 (0.073099)\n",
      "0.05 3 2 8 log2 mae 0.5 200: Macro 0.681147 (0.098007)\n",
      "Testing 1840/5184\n",
      "0.05 3 2 8 log2 mae 0.5 500: Weighted 0.798704 (0.098313)\n",
      "0.05 3 2 8 log2 mae 0.5 500: Macro 0.686976 (0.136595)\n",
      "Testing 1841/5184\n",
      "0.05 3 2 8 log2 mae 0.75 50: Weighted 0.786352 (0.075379)\n",
      "0.05 3 2 8 log2 mae 0.75 50: Macro 0.655026 (0.111804)\n",
      "Testing 1842/5184\n",
      "0.05 3 2 8 log2 mae 0.75 100: Weighted 0.777442 (0.084355)\n",
      "0.05 3 2 8 log2 mae 0.75 100: Macro 0.653038 (0.114975)\n",
      "Testing 1843/5184\n",
      "0.05 3 2 8 log2 mae 0.75 200: Weighted 0.782042 (0.078625)\n",
      "0.05 3 2 8 log2 mae 0.75 200: Macro 0.650483 (0.114293)\n",
      "Testing 1844/5184\n",
      "0.05 3 2 8 log2 mae 0.75 500: Weighted 0.780558 (0.077484)\n",
      "0.05 3 2 8 log2 mae 0.75 500: Macro 0.649174 (0.111124)\n",
      "Testing 1845/5184\n",
      "0.05 3 2 8 log2 mae 1.0 50: Weighted 0.768944 (0.078743)\n",
      "0.05 3 2 8 log2 mae 1.0 50: Macro 0.638184 (0.107374)\n",
      "Testing 1846/5184\n",
      "0.05 3 2 8 log2 mae 1.0 100: Weighted 0.787310 (0.082549)\n",
      "0.05 3 2 8 log2 mae 1.0 100: Macro 0.664537 (0.124447)\n",
      "Testing 1847/5184\n",
      "0.05 3 2 8 log2 mae 1.0 200: Weighted 0.775131 (0.095435)\n",
      "0.05 3 2 8 log2 mae 1.0 200: Macro 0.639186 (0.138461)\n",
      "Testing 1848/5184\n",
      "0.05 3 2 8 log2 mae 1.0 500: Weighted 0.799140 (0.088137)\n",
      "0.05 3 2 8 log2 mae 1.0 500: Macro 0.676024 (0.131854)\n",
      "Testing 1849/5184\n",
      "0.05 3 2 8 sqrt friedman_mse 0.5 50: Weighted 0.814865 (0.064062)\n",
      "0.05 3 2 8 sqrt friedman_mse 0.5 50: Macro 0.709442 (0.091780)\n",
      "Testing 1850/5184\n",
      "0.05 3 2 8 sqrt friedman_mse 0.5 100: Weighted 0.840174 (0.064560)\n",
      "0.05 3 2 8 sqrt friedman_mse 0.5 100: Macro 0.747510 (0.091875)\n",
      "Testing 1851/5184\n",
      "0.05 3 2 8 sqrt friedman_mse 0.5 200: Weighted 0.820039 (0.070198)\n",
      "0.05 3 2 8 sqrt friedman_mse 0.5 200: Macro 0.720773 (0.096405)\n",
      "Testing 1852/5184\n",
      "0.05 3 2 8 sqrt friedman_mse 0.5 500: Weighted 0.826516 (0.080045)\n",
      "0.05 3 2 8 sqrt friedman_mse 0.5 500: Macro 0.726694 (0.131054)\n",
      "Testing 1853/5184\n",
      "0.05 3 2 8 sqrt friedman_mse 0.75 50: Weighted 0.806568 (0.065565)\n",
      "0.05 3 2 8 sqrt friedman_mse 0.75 50: Macro 0.710004 (0.080595)\n",
      "Testing 1854/5184\n",
      "0.05 3 2 8 sqrt friedman_mse 0.75 100: Weighted 0.806608 (0.075406)\n",
      "0.05 3 2 8 sqrt friedman_mse 0.75 100: Macro 0.701428 (0.116847)\n",
      "Testing 1855/5184\n",
      "0.05 3 2 8 sqrt friedman_mse 0.75 200: Weighted 0.814241 (0.086440)\n",
      "0.05 3 2 8 sqrt friedman_mse 0.75 200: Macro 0.706502 (0.129184)\n",
      "Testing 1856/5184\n",
      "0.05 3 2 8 sqrt friedman_mse 0.75 500: Weighted 0.824304 (0.084916)\n",
      "0.05 3 2 8 sqrt friedman_mse 0.75 500: Macro 0.720778 (0.129260)\n",
      "Testing 1857/5184\n",
      "0.05 3 2 8 sqrt friedman_mse 1.0 50: Weighted 0.787205 (0.089064)\n",
      "0.05 3 2 8 sqrt friedman_mse 1.0 50: Macro 0.673777 (0.124068)\n",
      "Testing 1858/5184\n",
      "0.05 3 2 8 sqrt friedman_mse 1.0 100: Weighted 0.792225 (0.086969)\n",
      "0.05 3 2 8 sqrt friedman_mse 1.0 100: Macro 0.682072 (0.120798)\n",
      "Testing 1859/5184\n",
      "0.05 3 2 8 sqrt friedman_mse 1.0 200: Weighted 0.797514 (0.089997)\n",
      "0.05 3 2 8 sqrt friedman_mse 1.0 200: Macro 0.691859 (0.128911)\n",
      "Testing 1860/5184\n",
      "0.05 3 2 8 sqrt friedman_mse 1.0 500: Weighted 0.787127 (0.086870)\n",
      "0.05 3 2 8 sqrt friedman_mse 1.0 500: Macro 0.678483 (0.119912)\n",
      "Testing 1861/5184\n",
      "0.05 3 2 8 sqrt mae 0.5 50: Weighted 0.803049 (0.058839)\n",
      "0.05 3 2 8 sqrt mae 0.5 50: Macro 0.682448 (0.084783)\n",
      "Testing 1862/5184\n",
      "0.05 3 2 8 sqrt mae 0.5 100: Weighted 0.789409 (0.061792)\n",
      "0.05 3 2 8 sqrt mae 0.5 100: Macro 0.663882 (0.087920)\n",
      "Testing 1863/5184\n",
      "0.05 3 2 8 sqrt mae 0.5 200: Weighted 0.805049 (0.064660)\n",
      "0.05 3 2 8 sqrt mae 0.5 200: Macro 0.689140 (0.090148)\n",
      "Testing 1864/5184\n",
      "0.05 3 2 8 sqrt mae 0.5 500: Weighted 0.808258 (0.095524)\n",
      "0.05 3 2 8 sqrt mae 0.5 500: Macro 0.695432 (0.136220)\n",
      "Testing 1865/5184\n",
      "0.05 3 2 8 sqrt mae 0.75 50: Weighted 0.780586 (0.071076)\n",
      "0.05 3 2 8 sqrt mae 0.75 50: Macro 0.659393 (0.092581)\n",
      "Testing 1866/5184\n",
      "0.05 3 2 8 sqrt mae 0.75 100: Weighted 0.788511 (0.073226)\n",
      "0.05 3 2 8 sqrt mae 0.75 100: Macro 0.669148 (0.098318)\n",
      "Testing 1867/5184\n",
      "0.05 3 2 8 sqrt mae 0.75 200: Weighted 0.774875 (0.104152)\n",
      "0.05 3 2 8 sqrt mae 0.75 200: Macro 0.650126 (0.144369)\n",
      "Testing 1868/5184\n",
      "0.05 3 2 8 sqrt mae 0.75 500: Weighted 0.803192 (0.096080)\n",
      "0.05 3 2 8 sqrt mae 0.75 500: Macro 0.681071 (0.144937)\n",
      "Testing 1869/5184\n",
      "0.05 3 2 8 sqrt mae 1.0 50: Weighted 0.787326 (0.074266)\n",
      "0.05 3 2 8 sqrt mae 1.0 50: Macro 0.664864 (0.104441)\n",
      "Testing 1870/5184\n",
      "0.05 3 2 8 sqrt mae 1.0 100: Weighted 0.779036 (0.090827)\n",
      "0.05 3 2 8 sqrt mae 1.0 100: Macro 0.658136 (0.121936)\n",
      "Testing 1871/5184\n",
      "0.05 3 2 8 sqrt mae 1.0 200: Weighted 0.782471 (0.098128)\n",
      "0.05 3 2 8 sqrt mae 1.0 200: Macro 0.650299 (0.142501)\n",
      "Testing 1872/5184\n",
      "0.05 3 2 8 sqrt mae 1.0 500: Weighted 0.785650 (0.085522)\n",
      "0.05 3 2 8 sqrt mae 1.0 500: Macro 0.649555 (0.128489)\n",
      "Testing 1873/5184\n",
      "0.05 3 4 3 log2 friedman_mse 0.5 50: Weighted 0.807674 (0.056758)\n",
      "0.05 3 4 3 log2 friedman_mse 0.5 50: Macro 0.694221 (0.081078)\n",
      "Testing 1874/5184\n",
      "0.05 3 4 3 log2 friedman_mse 0.5 100: Weighted 0.805302 (0.048901)\n",
      "0.05 3 4 3 log2 friedman_mse 0.5 100: Macro 0.701823 (0.067033)\n",
      "Testing 1875/5184\n",
      "0.05 3 4 3 log2 friedman_mse 0.5 200: Weighted 0.809535 (0.061876)\n",
      "0.05 3 4 3 log2 friedman_mse 0.5 200: Macro 0.715436 (0.091913)\n",
      "Testing 1876/5184\n",
      "0.05 3 4 3 log2 friedman_mse 0.5 500: Weighted 0.820223 (0.054941)\n",
      "0.05 3 4 3 log2 friedman_mse 0.5 500: Macro 0.719373 (0.086182)\n",
      "Testing 1877/5184\n",
      "0.05 3 4 3 log2 friedman_mse 0.75 50: Weighted 0.811354 (0.056085)\n",
      "0.05 3 4 3 log2 friedman_mse 0.75 50: Macro 0.704995 (0.069155)\n",
      "Testing 1878/5184\n",
      "0.05 3 4 3 log2 friedman_mse 0.75 100: Weighted 0.802796 (0.065927)\n",
      "0.05 3 4 3 log2 friedman_mse 0.75 100: Macro 0.693376 (0.086468)\n",
      "Testing 1879/5184\n",
      "0.05 3 4 3 log2 friedman_mse 0.75 200: Weighted 0.813700 (0.066830)\n",
      "0.05 3 4 3 log2 friedman_mse 0.75 200: Macro 0.716198 (0.092966)\n",
      "Testing 1880/5184\n",
      "0.05 3 4 3 log2 friedman_mse 0.75 500: Weighted 0.813004 (0.054575)\n",
      "0.05 3 4 3 log2 friedman_mse 0.75 500: Macro 0.710742 (0.087340)\n",
      "Testing 1881/5184\n",
      "0.05 3 4 3 log2 friedman_mse 1.0 50: Weighted 0.799021 (0.065333)\n",
      "0.05 3 4 3 log2 friedman_mse 1.0 50: Macro 0.688640 (0.081786)\n",
      "Testing 1882/5184\n",
      "0.05 3 4 3 log2 friedman_mse 1.0 100: Weighted 0.807796 (0.062390)\n",
      "0.05 3 4 3 log2 friedman_mse 1.0 100: Macro 0.713424 (0.082679)\n",
      "Testing 1883/5184\n",
      "0.05 3 4 3 log2 friedman_mse 1.0 200: Weighted 0.799575 (0.048083)\n",
      "0.05 3 4 3 log2 friedman_mse 1.0 200: Macro 0.698707 (0.069261)\n",
      "Testing 1884/5184\n",
      "0.05 3 4 3 log2 friedman_mse 1.0 500: Weighted 0.801776 (0.055798)\n",
      "0.05 3 4 3 log2 friedman_mse 1.0 500: Macro 0.699881 (0.082841)\n",
      "Testing 1885/5184\n",
      "0.05 3 4 3 log2 mae 0.5 50: Weighted 0.812627 (0.051061)\n",
      "0.05 3 4 3 log2 mae 0.5 50: Macro 0.701687 (0.069943)\n",
      "Testing 1886/5184\n",
      "0.05 3 4 3 log2 mae 0.5 100: Weighted 0.817791 (0.050508)\n",
      "0.05 3 4 3 log2 mae 0.5 100: Macro 0.708519 (0.071072)\n",
      "Testing 1887/5184\n",
      "0.05 3 4 3 log2 mae 0.5 200: Weighted 0.807649 (0.059785)\n",
      "0.05 3 4 3 log2 mae 0.5 200: Macro 0.690639 (0.082297)\n",
      "Testing 1888/5184\n",
      "0.05 3 4 3 log2 mae 0.5 500: Weighted 0.791248 (0.084270)\n",
      "0.05 3 4 3 log2 mae 0.5 500: Macro 0.675217 (0.123184)\n",
      "Testing 1889/5184\n",
      "0.05 3 4 3 log2 mae 0.75 50: Weighted 0.794778 (0.054898)\n",
      "0.05 3 4 3 log2 mae 0.75 50: Macro 0.677662 (0.080425)\n",
      "Testing 1890/5184\n",
      "0.05 3 4 3 log2 mae 0.75 100: Weighted 0.784419 (0.053332)\n",
      "0.05 3 4 3 log2 mae 0.75 100: Macro 0.659293 (0.076713)\n",
      "Testing 1891/5184\n",
      "0.05 3 4 3 log2 mae 0.75 200: Weighted 0.778277 (0.068939)\n",
      "0.05 3 4 3 log2 mae 0.75 200: Macro 0.654781 (0.099973)\n",
      "Testing 1892/5184\n",
      "0.05 3 4 3 log2 mae 0.75 500: Weighted 0.761928 (0.057483)\n",
      "0.05 3 4 3 log2 mae 0.75 500: Macro 0.618559 (0.074694)\n",
      "Testing 1893/5184\n",
      "0.05 3 4 3 log2 mae 1.0 50: Weighted 0.795428 (0.063775)\n",
      "0.05 3 4 3 log2 mae 1.0 50: Macro 0.674462 (0.085450)\n",
      "Testing 1894/5184\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05 3 4 3 log2 mae 1.0 100: Weighted 0.778940 (0.082184)\n",
      "0.05 3 4 3 log2 mae 1.0 100: Macro 0.655003 (0.115313)\n",
      "Testing 1895/5184\n",
      "0.05 3 4 3 log2 mae 1.0 200: Weighted 0.761278 (0.076674)\n",
      "0.05 3 4 3 log2 mae 1.0 200: Macro 0.627639 (0.111638)\n",
      "Testing 1896/5184\n",
      "0.05 3 4 3 log2 mae 1.0 500: Weighted 0.756834 (0.069215)\n",
      "0.05 3 4 3 log2 mae 1.0 500: Macro 0.616861 (0.093101)\n",
      "Testing 1897/5184\n",
      "0.05 3 4 3 sqrt friedman_mse 0.5 50: Weighted 0.805688 (0.048683)\n",
      "0.05 3 4 3 sqrt friedman_mse 0.5 50: Macro 0.695811 (0.065421)\n",
      "Testing 1898/5184\n",
      "0.05 3 4 3 sqrt friedman_mse 0.5 100: Weighted 0.802953 (0.063941)\n",
      "0.05 3 4 3 sqrt friedman_mse 0.5 100: Macro 0.698561 (0.085901)\n",
      "Testing 1899/5184\n",
      "0.05 3 4 3 sqrt friedman_mse 0.5 200: Weighted 0.808188 (0.051240)\n",
      "0.05 3 4 3 sqrt friedman_mse 0.5 200: Macro 0.704894 (0.081250)\n",
      "Testing 1900/5184\n",
      "0.05 3 4 3 sqrt friedman_mse 0.5 500: Weighted 0.818470 (0.059814)\n",
      "0.05 3 4 3 sqrt friedman_mse 0.5 500: Macro 0.724000 (0.092301)\n",
      "Testing 1901/5184\n",
      "0.05 3 4 3 sqrt friedman_mse 0.75 50: Weighted 0.809581 (0.054326)\n",
      "0.05 3 4 3 sqrt friedman_mse 0.75 50: Macro 0.703148 (0.065698)\n",
      "Testing 1902/5184\n",
      "0.05 3 4 3 sqrt friedman_mse 0.75 100: Weighted 0.813755 (0.072444)\n",
      "0.05 3 4 3 sqrt friedman_mse 0.75 100: Macro 0.713296 (0.094580)\n",
      "Testing 1903/5184\n",
      "0.05 3 4 3 sqrt friedman_mse 0.75 200: Weighted 0.812393 (0.066417)\n",
      "0.05 3 4 3 sqrt friedman_mse 0.75 200: Macro 0.710413 (0.097640)\n",
      "Testing 1904/5184\n",
      "0.05 3 4 3 sqrt friedman_mse 0.75 500: Weighted 0.810672 (0.056022)\n",
      "0.05 3 4 3 sqrt friedman_mse 0.75 500: Macro 0.711721 (0.086632)\n",
      "Testing 1905/5184\n",
      "0.05 3 4 3 sqrt friedman_mse 1.0 50: Weighted 0.793202 (0.064113)\n",
      "0.05 3 4 3 sqrt friedman_mse 1.0 50: Macro 0.679181 (0.081898)\n",
      "Testing 1906/5184\n",
      "0.05 3 4 3 sqrt friedman_mse 1.0 100: Weighted 0.803804 (0.074834)\n",
      "0.05 3 4 3 sqrt friedman_mse 1.0 100: Macro 0.701442 (0.097551)\n",
      "Testing 1907/5184\n",
      "0.05 3 4 3 sqrt friedman_mse 1.0 200: Weighted 0.812535 (0.064146)\n",
      "0.05 3 4 3 sqrt friedman_mse 1.0 200: Macro 0.710469 (0.095534)\n",
      "Testing 1908/5184\n",
      "0.05 3 4 3 sqrt friedman_mse 1.0 500: Weighted 0.811162 (0.055982)\n",
      "0.05 3 4 3 sqrt friedman_mse 1.0 500: Macro 0.712169 (0.086057)\n",
      "Testing 1909/5184\n",
      "0.05 3 4 3 sqrt mae 0.5 50: Weighted 0.821525 (0.056419)\n",
      "0.05 3 4 3 sqrt mae 0.5 50: Macro 0.716753 (0.078488)\n",
      "Testing 1910/5184\n",
      "0.05 3 4 3 sqrt mae 0.5 100: Weighted 0.811768 (0.054395)\n",
      "0.05 3 4 3 sqrt mae 0.5 100: Macro 0.697123 (0.080144)\n",
      "Testing 1911/5184\n",
      "0.05 3 4 3 sqrt mae 0.5 200: Weighted 0.780053 (0.060695)\n",
      "0.05 3 4 3 sqrt mae 0.5 200: Macro 0.652490 (0.088873)\n",
      "Testing 1912/5184\n",
      "0.05 3 4 3 sqrt mae 0.5 500: Weighted 0.785213 (0.073788)\n",
      "0.05 3 4 3 sqrt mae 0.5 500: Macro 0.662835 (0.105398)\n",
      "Testing 1913/5184\n",
      "0.05 3 4 3 sqrt mae 0.75 50: Weighted 0.788587 (0.066330)\n",
      "0.05 3 4 3 sqrt mae 0.75 50: Macro 0.668898 (0.093010)\n",
      "Testing 1914/5184\n",
      "0.05 3 4 3 sqrt mae 0.75 100: Weighted 0.784819 (0.063285)\n",
      "0.05 3 4 3 sqrt mae 0.75 100: Macro 0.664873 (0.090659)\n",
      "Testing 1915/5184\n",
      "0.05 3 4 3 sqrt mae 0.75 200: Weighted 0.765365 (0.072565)\n",
      "0.05 3 4 3 sqrt mae 0.75 200: Macro 0.637422 (0.100492)\n",
      "Testing 1916/5184\n",
      "0.05 3 4 3 sqrt mae 0.75 500: Weighted 0.777179 (0.067064)\n",
      "0.05 3 4 3 sqrt mae 0.75 500: Macro 0.649032 (0.093416)\n",
      "Testing 1917/5184\n",
      "0.05 3 4 3 sqrt mae 1.0 50: Weighted 0.773608 (0.068169)\n",
      "0.05 3 4 3 sqrt mae 1.0 50: Macro 0.647815 (0.091391)\n",
      "Testing 1918/5184\n",
      "0.05 3 4 3 sqrt mae 1.0 100: Weighted 0.784169 (0.074473)\n",
      "0.05 3 4 3 sqrt mae 1.0 100: Macro 0.666035 (0.103033)\n",
      "Testing 1919/5184\n",
      "0.05 3 4 3 sqrt mae 1.0 200: Weighted 0.769497 (0.069634)\n",
      "0.05 3 4 3 sqrt mae 1.0 200: Macro 0.633917 (0.105218)\n",
      "Testing 1920/5184\n",
      "0.05 3 4 3 sqrt mae 1.0 500: Weighted 0.763826 (0.078455)\n",
      "0.05 3 4 3 sqrt mae 1.0 500: Macro 0.626907 (0.108570)\n",
      "Testing 1921/5184\n",
      "0.05 3 4 5 log2 friedman_mse 0.5 50: Weighted 0.813711 (0.052642)\n",
      "0.05 3 4 5 log2 friedman_mse 0.5 50: Macro 0.700808 (0.075979)\n",
      "Testing 1922/5184\n",
      "0.05 3 4 5 log2 friedman_mse 0.5 100: Weighted 0.821668 (0.083204)\n",
      "0.05 3 4 5 log2 friedman_mse 0.5 100: Macro 0.724257 (0.117908)\n",
      "Testing 1923/5184\n",
      "0.05 3 4 5 log2 friedman_mse 0.5 200: Weighted 0.830062 (0.078679)\n",
      "0.05 3 4 5 log2 friedman_mse 0.5 200: Macro 0.733373 (0.109508)\n",
      "Testing 1924/5184\n",
      "0.05 3 4 5 log2 friedman_mse 0.5 500: Weighted 0.807967 (0.068265)\n",
      "0.05 3 4 5 log2 friedman_mse 0.5 500: Macro 0.702712 (0.102612)\n",
      "Testing 1925/5184\n",
      "0.05 3 4 5 log2 friedman_mse 0.75 50: Weighted 0.794852 (0.062741)\n",
      "0.05 3 4 5 log2 friedman_mse 0.75 50: Macro 0.693948 (0.083805)\n",
      "Testing 1926/5184\n",
      "0.05 3 4 5 log2 friedman_mse 0.75 100: Weighted 0.818497 (0.077236)\n",
      "0.05 3 4 5 log2 friedman_mse 0.75 100: Macro 0.722311 (0.104917)\n",
      "Testing 1927/5184\n",
      "0.05 3 4 5 log2 friedman_mse 0.75 200: Weighted 0.811543 (0.072710)\n",
      "0.05 3 4 5 log2 friedman_mse 0.75 200: Macro 0.709025 (0.109938)\n",
      "Testing 1928/5184\n",
      "0.05 3 4 5 log2 friedman_mse 0.75 500: Weighted 0.813319 (0.074526)\n",
      "0.05 3 4 5 log2 friedman_mse 0.75 500: Macro 0.704736 (0.119506)\n",
      "Testing 1929/5184\n",
      "0.05 3 4 5 log2 friedman_mse 1.0 50: Weighted 0.802128 (0.077463)\n",
      "0.05 3 4 5 log2 friedman_mse 1.0 50: Macro 0.696625 (0.103652)\n",
      "Testing 1930/5184\n",
      "0.05 3 4 5 log2 friedman_mse 1.0 100: Weighted 0.813318 (0.083004)\n",
      "0.05 3 4 5 log2 friedman_mse 1.0 100: Macro 0.709866 (0.120758)\n",
      "Testing 1931/5184\n",
      "0.05 3 4 5 log2 friedman_mse 1.0 200: Weighted 0.802837 (0.083769)\n",
      "0.05 3 4 5 log2 friedman_mse 1.0 200: Macro 0.694374 (0.126638)\n",
      "Testing 1932/5184\n",
      "0.05 3 4 5 log2 friedman_mse 1.0 500: Weighted 0.808208 (0.090532)\n",
      "0.05 3 4 5 log2 friedman_mse 1.0 500: Macro 0.698997 (0.132154)\n",
      "Testing 1933/5184\n",
      "0.05 3 4 5 log2 mae 0.5 50: Weighted 0.799482 (0.064117)\n",
      "0.05 3 4 5 log2 mae 0.5 50: Macro 0.677646 (0.091520)\n",
      "Testing 1934/5184\n",
      "0.05 3 4 5 log2 mae 0.5 100: Weighted 0.802958 (0.067405)\n",
      "0.05 3 4 5 log2 mae 0.5 100: Macro 0.685793 (0.095046)\n",
      "Testing 1935/5184\n",
      "0.05 3 4 5 log2 mae 0.5 200: Weighted 0.791406 (0.077839)\n",
      "0.05 3 4 5 log2 mae 0.5 200: Macro 0.669846 (0.109975)\n",
      "Testing 1936/5184\n",
      "0.05 3 4 5 log2 mae 0.5 500: Weighted 0.789527 (0.078945)\n",
      "0.05 3 4 5 log2 mae 0.5 500: Macro 0.664924 (0.107992)\n",
      "Testing 1937/5184\n",
      "0.05 3 4 5 log2 mae 0.75 50: Weighted 0.780124 (0.079512)\n",
      "0.05 3 4 5 log2 mae 0.75 50: Macro 0.650851 (0.114307)\n",
      "Testing 1938/5184\n",
      "0.05 3 4 5 log2 mae 0.75 100: Weighted 0.772848 (0.086307)\n",
      "0.05 3 4 5 log2 mae 0.75 100: Macro 0.641218 (0.122914)\n",
      "Testing 1939/5184\n",
      "0.05 3 4 5 log2 mae 0.75 200: Weighted 0.786243 (0.069890)\n",
      "0.05 3 4 5 log2 mae 0.75 200: Macro 0.661448 (0.100001)\n",
      "Testing 1940/5184\n",
      "0.05 3 4 5 log2 mae 0.75 500: Weighted 0.793276 (0.083710)\n",
      "0.05 3 4 5 log2 mae 0.75 500: Macro 0.669499 (0.111760)\n",
      "Testing 1941/5184\n",
      "0.05 3 4 5 log2 mae 1.0 50: Weighted 0.769098 (0.068542)\n",
      "0.05 3 4 5 log2 mae 1.0 50: Macro 0.643279 (0.096838)\n",
      "Testing 1942/5184\n",
      "0.05 3 4 5 log2 mae 1.0 100: Weighted 0.764796 (0.077969)\n",
      "0.05 3 4 5 log2 mae 1.0 100: Macro 0.630823 (0.108472)\n",
      "Testing 1943/5184\n",
      "0.05 3 4 5 log2 mae 1.0 200: Weighted 0.786927 (0.084870)\n",
      "0.05 3 4 5 log2 mae 1.0 200: Macro 0.663204 (0.117032)\n",
      "Testing 1944/5184\n",
      "0.05 3 4 5 log2 mae 1.0 500: Weighted 0.775172 (0.078339)\n",
      "0.05 3 4 5 log2 mae 1.0 500: Macro 0.639381 (0.105362)\n",
      "Testing 1945/5184\n",
      "0.05 3 4 5 sqrt friedman_mse 0.5 50: Weighted 0.820703 (0.051053)\n",
      "0.05 3 4 5 sqrt friedman_mse 0.5 50: Macro 0.714743 (0.067486)\n",
      "Testing 1946/5184\n",
      "0.05 3 4 5 sqrt friedman_mse 0.5 100: Weighted 0.813551 (0.070914)\n",
      "0.05 3 4 5 sqrt friedman_mse 0.5 100: Macro 0.708372 (0.099709)\n",
      "Testing 1947/5184\n",
      "0.05 3 4 5 sqrt friedman_mse 0.5 200: Weighted 0.822727 (0.079847)\n",
      "0.05 3 4 5 sqrt friedman_mse 0.5 200: Macro 0.715929 (0.117141)\n",
      "Testing 1948/5184\n",
      "0.05 3 4 5 sqrt friedman_mse 0.5 500: Weighted 0.815432 (0.077296)\n",
      "0.05 3 4 5 sqrt friedman_mse 0.5 500: Macro 0.723165 (0.120269)\n",
      "Testing 1949/5184\n",
      "0.05 3 4 5 sqrt friedman_mse 0.75 50: Weighted 0.796467 (0.064143)\n",
      "0.05 3 4 5 sqrt friedman_mse 0.75 50: Macro 0.686980 (0.086204)\n",
      "Testing 1950/5184\n",
      "0.05 3 4 5 sqrt friedman_mse 0.75 100: Weighted 0.802754 (0.090321)\n",
      "0.05 3 4 5 sqrt friedman_mse 0.75 100: Macro 0.698940 (0.126243)\n",
      "Testing 1951/5184\n",
      "0.05 3 4 5 sqrt friedman_mse 0.75 200: Weighted 0.813631 (0.083015)\n",
      "0.05 3 4 5 sqrt friedman_mse 0.75 200: Macro 0.709409 (0.122967)\n",
      "Testing 1952/5184\n",
      "0.05 3 4 5 sqrt friedman_mse 0.75 500: Weighted 0.815624 (0.073333)\n",
      "0.05 3 4 5 sqrt friedman_mse 0.75 500: Macro 0.712164 (0.112897)\n",
      "Testing 1953/5184\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05 3 4 5 sqrt friedman_mse 1.0 50: Weighted 0.792958 (0.083395)\n",
      "0.05 3 4 5 sqrt friedman_mse 1.0 50: Macro 0.684991 (0.112028)\n",
      "Testing 1954/5184\n",
      "0.05 3 4 5 sqrt friedman_mse 1.0 100: Weighted 0.797576 (0.073807)\n",
      "0.05 3 4 5 sqrt friedman_mse 1.0 100: Macro 0.688924 (0.100250)\n",
      "Testing 1955/5184\n",
      "0.05 3 4 5 sqrt friedman_mse 1.0 200: Weighted 0.816053 (0.080350)\n",
      "0.05 3 4 5 sqrt friedman_mse 1.0 200: Macro 0.714686 (0.114438)\n",
      "Testing 1956/5184\n",
      "0.05 3 4 5 sqrt friedman_mse 1.0 500: Weighted 0.816463 (0.080478)\n",
      "0.05 3 4 5 sqrt friedman_mse 1.0 500: Macro 0.713955 (0.116853)\n",
      "Testing 1957/5184\n",
      "0.05 3 4 5 sqrt mae 0.5 50: Weighted 0.807613 (0.060405)\n",
      "0.05 3 4 5 sqrt mae 0.5 50: Macro 0.692965 (0.084607)\n",
      "Testing 1958/5184\n",
      "0.05 3 4 5 sqrt mae 0.5 100: Weighted 0.808491 (0.071563)\n",
      "0.05 3 4 5 sqrt mae 0.5 100: Macro 0.690035 (0.105310)\n",
      "Testing 1959/5184\n",
      "0.05 3 4 5 sqrt mae 0.5 200: Weighted 0.791150 (0.078243)\n",
      "0.05 3 4 5 sqrt mae 0.5 200: Macro 0.669221 (0.110726)\n",
      "Testing 1960/5184\n",
      "0.05 3 4 5 sqrt mae 0.5 500: Weighted 0.777311 (0.069128)\n",
      "0.05 3 4 5 sqrt mae 0.5 500: Macro 0.640879 (0.088423)\n",
      "Testing 1961/5184\n",
      "0.05 3 4 5 sqrt mae 0.75 50: Weighted 0.793382 (0.059838)\n",
      "0.05 3 4 5 sqrt mae 0.75 50: Macro 0.672028 (0.081007)\n",
      "Testing 1962/5184\n",
      "0.05 3 4 5 sqrt mae 0.75 100: Weighted 0.781824 (0.077403)\n",
      "0.05 3 4 5 sqrt mae 0.75 100: Macro 0.655062 (0.109220)\n",
      "Testing 1963/5184\n",
      "0.05 3 4 5 sqrt mae 0.75 200: Weighted 0.778910 (0.079927)\n",
      "0.05 3 4 5 sqrt mae 0.75 200: Macro 0.646645 (0.114034)\n",
      "Testing 1964/5184\n",
      "0.05 3 4 5 sqrt mae 0.75 500: Weighted 0.780427 (0.085919)\n",
      "0.05 3 4 5 sqrt mae 0.75 500: Macro 0.647312 (0.116596)\n",
      "Testing 1965/5184\n",
      "0.05 3 4 5 sqrt mae 1.0 50: Weighted 0.768672 (0.061823)\n",
      "0.05 3 4 5 sqrt mae 1.0 50: Macro 0.639553 (0.089277)\n",
      "Testing 1966/5184\n",
      "0.05 3 4 5 sqrt mae 1.0 100: Weighted 0.773323 (0.086759)\n",
      "0.05 3 4 5 sqrt mae 1.0 100: Macro 0.642079 (0.119546)\n",
      "Testing 1967/5184\n",
      "0.05 3 4 5 sqrt mae 1.0 200: Weighted 0.784461 (0.102704)\n",
      "0.05 3 4 5 sqrt mae 1.0 200: Macro 0.661704 (0.145676)\n",
      "Testing 1968/5184\n",
      "0.05 3 4 5 sqrt mae 1.0 500: Weighted 0.784453 (0.090078)\n",
      "0.05 3 4 5 sqrt mae 1.0 500: Macro 0.652177 (0.126057)\n",
      "Testing 1969/5184\n",
      "0.05 3 4 8 log2 friedman_mse 0.5 50: Weighted 0.826959 (0.076127)\n",
      "0.05 3 4 8 log2 friedman_mse 0.5 50: Macro 0.732335 (0.101885)\n",
      "Testing 1970/5184\n",
      "0.05 3 4 8 log2 friedman_mse 0.5 100: Weighted 0.827386 (0.075797)\n",
      "0.05 3 4 8 log2 friedman_mse 0.5 100: Macro 0.733769 (0.117799)\n",
      "Testing 1971/5184\n",
      "0.05 3 4 8 log2 friedman_mse 0.5 200: Weighted 0.831578 (0.071406)\n",
      "0.05 3 4 8 log2 friedman_mse 0.5 200: Macro 0.730185 (0.104426)\n",
      "Testing 1972/5184\n",
      "0.05 3 4 8 log2 friedman_mse 0.5 500: Weighted 0.816737 (0.082746)\n",
      "0.05 3 4 8 log2 friedman_mse 0.5 500: Macro 0.712574 (0.131419)\n",
      "Testing 1973/5184\n",
      "0.05 3 4 8 log2 friedman_mse 0.75 50: Weighted 0.815062 (0.052288)\n",
      "0.05 3 4 8 log2 friedman_mse 0.75 50: Macro 0.720393 (0.070724)\n",
      "Testing 1974/5184\n",
      "0.05 3 4 8 log2 friedman_mse 0.75 100: Weighted 0.806650 (0.076809)\n",
      "0.05 3 4 8 log2 friedman_mse 0.75 100: Macro 0.706159 (0.102170)\n",
      "Testing 1975/5184\n",
      "0.05 3 4 8 log2 friedman_mse 0.75 200: Weighted 0.822529 (0.084698)\n",
      "0.05 3 4 8 log2 friedman_mse 0.75 200: Macro 0.718654 (0.128486)\n",
      "Testing 1976/5184\n",
      "0.05 3 4 8 log2 friedman_mse 0.75 500: Weighted 0.811777 (0.077146)\n",
      "0.05 3 4 8 log2 friedman_mse 0.75 500: Macro 0.708326 (0.119643)\n",
      "Testing 1977/5184\n",
      "0.05 3 4 8 log2 friedman_mse 1.0 50: Weighted 0.784384 (0.066242)\n",
      "0.05 3 4 8 log2 friedman_mse 1.0 50: Macro 0.670956 (0.093954)\n",
      "Testing 1978/5184\n",
      "0.05 3 4 8 log2 friedman_mse 1.0 100: Weighted 0.796110 (0.081819)\n",
      "0.05 3 4 8 log2 friedman_mse 1.0 100: Macro 0.691746 (0.108849)\n",
      "Testing 1979/5184\n",
      "0.05 3 4 8 log2 friedman_mse 1.0 200: Weighted 0.803664 (0.094910)\n",
      "0.05 3 4 8 log2 friedman_mse 1.0 200: Macro 0.704692 (0.134975)\n",
      "Testing 1980/5184\n",
      "0.05 3 4 8 log2 friedman_mse 1.0 500: Weighted 0.795105 (0.069121)\n",
      "0.05 3 4 8 log2 friedman_mse 1.0 500: Macro 0.686508 (0.109213)\n",
      "Testing 1981/5184\n",
      "0.05 3 4 8 log2 mae 0.5 50: Weighted 0.792782 (0.059470)\n",
      "0.05 3 4 8 log2 mae 0.5 50: Macro 0.671615 (0.082947)\n",
      "Testing 1982/5184\n",
      "0.05 3 4 8 log2 mae 0.5 100: Weighted 0.812683 (0.074706)\n",
      "0.05 3 4 8 log2 mae 0.5 100: Macro 0.698992 (0.108533)\n",
      "Testing 1983/5184\n",
      "0.05 3 4 8 log2 mae 0.5 200: Weighted 0.805771 (0.074093)\n",
      "0.05 3 4 8 log2 mae 0.5 200: Macro 0.685494 (0.110539)\n",
      "Testing 1984/5184\n",
      "0.05 3 4 8 log2 mae 0.5 500: Weighted 0.796109 (0.082194)\n",
      "0.05 3 4 8 log2 mae 0.5 500: Macro 0.682233 (0.110331)\n",
      "Testing 1985/5184\n",
      "0.05 3 4 8 log2 mae 0.75 50: Weighted 0.793420 (0.077960)\n",
      "0.05 3 4 8 log2 mae 0.75 50: Macro 0.670376 (0.111142)\n",
      "Testing 1986/5184\n",
      "0.05 3 4 8 log2 mae 0.75 100: Weighted 0.789899 (0.079476)\n",
      "0.05 3 4 8 log2 mae 0.75 100: Macro 0.660761 (0.118419)\n",
      "Testing 1987/5184\n",
      "0.05 3 4 8 log2 mae 0.75 200: Weighted 0.789483 (0.089823)\n",
      "0.05 3 4 8 log2 mae 0.75 200: Macro 0.663581 (0.132302)\n",
      "Testing 1988/5184\n",
      "0.05 3 4 8 log2 mae 0.75 500: Weighted 0.795747 (0.093932)\n",
      "0.05 3 4 8 log2 mae 0.75 500: Macro 0.673886 (0.139541)\n",
      "Testing 1989/5184\n",
      "0.05 3 4 8 log2 mae 1.0 50: Weighted 0.767872 (0.063894)\n",
      "0.05 3 4 8 log2 mae 1.0 50: Macro 0.632927 (0.080058)\n",
      "Testing 1990/5184\n",
      "0.05 3 4 8 log2 mae 1.0 100: Weighted 0.774081 (0.092588)\n",
      "0.05 3 4 8 log2 mae 1.0 100: Macro 0.644121 (0.133235)\n",
      "Testing 1991/5184\n",
      "0.05 3 4 8 log2 mae 1.0 200: Weighted 0.776505 (0.076207)\n",
      "0.05 3 4 8 log2 mae 1.0 200: Macro 0.642930 (0.101071)\n",
      "Testing 1992/5184\n",
      "0.05 3 4 8 log2 mae 1.0 500: Weighted 0.784926 (0.092769)\n",
      "0.05 3 4 8 log2 mae 1.0 500: Macro 0.656808 (0.130476)\n",
      "Testing 1993/5184\n",
      "0.05 3 4 8 sqrt friedman_mse 0.5 50: Weighted 0.816894 (0.060689)\n",
      "0.05 3 4 8 sqrt friedman_mse 0.5 50: Macro 0.702677 (0.090195)\n",
      "Testing 1994/5184\n",
      "0.05 3 4 8 sqrt friedman_mse 0.5 100: Weighted 0.834702 (0.080751)\n",
      "0.05 3 4 8 sqrt friedman_mse 0.5 100: Macro 0.739019 (0.119008)\n",
      "Testing 1995/5184\n",
      "0.05 3 4 8 sqrt friedman_mse 0.5 200: Weighted 0.816378 (0.075449)\n",
      "0.05 3 4 8 sqrt friedman_mse 0.5 200: Macro 0.708132 (0.106163)\n",
      "Testing 1996/5184\n",
      "0.05 3 4 8 sqrt friedman_mse 0.5 500: Weighted 0.819162 (0.074514)\n",
      "0.05 3 4 8 sqrt friedman_mse 0.5 500: Macro 0.726786 (0.117159)\n",
      "Testing 1997/5184\n",
      "0.05 3 4 8 sqrt friedman_mse 0.75 50: Weighted 0.807642 (0.055406)\n",
      "0.05 3 4 8 sqrt friedman_mse 0.75 50: Macro 0.706244 (0.065988)\n",
      "Testing 1998/5184\n",
      "0.05 3 4 8 sqrt friedman_mse 0.75 100: Weighted 0.797107 (0.095378)\n",
      "0.05 3 4 8 sqrt friedman_mse 0.75 100: Macro 0.687919 (0.136815)\n",
      "Testing 1999/5184\n",
      "0.05 3 4 8 sqrt friedman_mse 0.75 200: Weighted 0.817360 (0.078708)\n",
      "0.05 3 4 8 sqrt friedman_mse 0.75 200: Macro 0.714892 (0.124030)\n",
      "Testing 2000/5184\n",
      "0.05 3 4 8 sqrt friedman_mse 0.75 500: Weighted 0.825935 (0.081980)\n",
      "0.05 3 4 8 sqrt friedman_mse 0.75 500: Macro 0.723489 (0.124758)\n",
      "Testing 2001/5184\n",
      "0.05 3 4 8 sqrt friedman_mse 1.0 50: Weighted 0.801413 (0.081630)\n",
      "0.05 3 4 8 sqrt friedman_mse 1.0 50: Macro 0.697167 (0.110598)\n",
      "Testing 2002/5184\n",
      "0.05 3 4 8 sqrt friedman_mse 1.0 100: Weighted 0.788699 (0.081086)\n",
      "0.05 3 4 8 sqrt friedman_mse 1.0 100: Macro 0.679572 (0.114442)\n",
      "Testing 2003/5184\n",
      "0.05 3 4 8 sqrt friedman_mse 1.0 200: Weighted 0.797925 (0.072938)\n",
      "0.05 3 4 8 sqrt friedman_mse 1.0 200: Macro 0.689362 (0.104921)\n",
      "Testing 2004/5184\n",
      "0.05 3 4 8 sqrt friedman_mse 1.0 500: Weighted 0.807121 (0.078962)\n",
      "0.05 3 4 8 sqrt friedman_mse 1.0 500: Macro 0.701531 (0.111612)\n",
      "Testing 2005/5184\n",
      "0.05 3 4 8 sqrt mae 0.5 50: Weighted 0.806130 (0.063668)\n",
      "0.05 3 4 8 sqrt mae 0.5 50: Macro 0.694214 (0.087311)\n",
      "Testing 2006/5184\n",
      "0.05 3 4 8 sqrt mae 0.5 100: Weighted 0.792501 (0.087409)\n",
      "0.05 3 4 8 sqrt mae 0.5 100: Macro 0.674320 (0.120665)\n",
      "Testing 2007/5184\n",
      "0.05 3 4 8 sqrt mae 0.5 200: Weighted 0.791181 (0.079073)\n",
      "0.05 3 4 8 sqrt mae 0.5 200: Macro 0.670237 (0.111928)\n",
      "Testing 2008/5184\n",
      "0.05 3 4 8 sqrt mae 0.5 500: Weighted 0.807690 (0.088239)\n",
      "0.05 3 4 8 sqrt mae 0.5 500: Macro 0.693727 (0.125571)\n",
      "Testing 2009/5184\n",
      "0.05 3 4 8 sqrt mae 0.75 50: Weighted 0.782543 (0.067022)\n",
      "0.05 3 4 8 sqrt mae 0.75 50: Macro 0.664900 (0.090288)\n",
      "Testing 2010/5184\n",
      "0.05 3 4 8 sqrt mae 0.75 100: Weighted 0.805581 (0.084907)\n",
      "0.05 3 4 8 sqrt mae 0.75 100: Macro 0.693614 (0.118946)\n",
      "Testing 2011/5184\n",
      "0.05 3 4 8 sqrt mae 0.75 200: Weighted 0.788286 (0.093453)\n",
      "0.05 3 4 8 sqrt mae 0.75 200: Macro 0.659858 (0.137374)\n",
      "Testing 2012/5184\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05 3 4 8 sqrt mae 0.75 500: Weighted 0.804514 (0.092615)\n",
      "0.05 3 4 8 sqrt mae 0.75 500: Macro 0.685908 (0.139259)\n",
      "Testing 2013/5184\n",
      "0.05 3 4 8 sqrt mae 1.0 50: Weighted 0.786414 (0.075496)\n",
      "0.05 3 4 8 sqrt mae 1.0 50: Macro 0.665629 (0.103330)\n",
      "Testing 2014/5184\n",
      "0.05 3 4 8 sqrt mae 1.0 100: Weighted 0.781790 (0.083635)\n",
      "0.05 3 4 8 sqrt mae 1.0 100: Macro 0.659593 (0.114838)\n",
      "Testing 2015/5184\n",
      "0.05 3 4 8 sqrt mae 1.0 200: Weighted 0.771083 (0.088680)\n",
      "0.05 3 4 8 sqrt mae 1.0 200: Macro 0.639990 (0.130685)\n",
      "Testing 2016/5184\n",
      "0.05 3 4 8 sqrt mae 1.0 500: Weighted 0.796613 (0.089076)\n",
      "0.05 3 4 8 sqrt mae 1.0 500: Macro 0.670860 (0.130011)\n",
      "Testing 2017/5184\n",
      "0.05 3 6 3 log2 friedman_mse 0.5 50: Weighted 0.824946 (0.062791)\n",
      "0.05 3 6 3 log2 friedman_mse 0.5 50: Macro 0.720831 (0.088715)\n",
      "Testing 2018/5184\n",
      "0.05 3 6 3 log2 friedman_mse 0.5 100: Weighted 0.805653 (0.055852)\n",
      "0.05 3 6 3 log2 friedman_mse 0.5 100: Macro 0.700554 (0.074438)\n",
      "Testing 2019/5184\n",
      "0.05 3 6 3 log2 friedman_mse 0.5 200: Weighted 0.809406 (0.055618)\n",
      "0.05 3 6 3 log2 friedman_mse 0.5 200: Macro 0.716217 (0.080087)\n",
      "Testing 2020/5184\n",
      "0.05 3 6 3 log2 friedman_mse 0.5 500: Weighted 0.827792 (0.055467)\n",
      "0.05 3 6 3 log2 friedman_mse 0.5 500: Macro 0.741005 (0.082593)\n",
      "Testing 2021/5184\n",
      "0.05 3 6 3 log2 friedman_mse 0.75 50: Weighted 0.814869 (0.074978)\n",
      "0.05 3 6 3 log2 friedman_mse 0.75 50: Macro 0.708949 (0.100062)\n",
      "Testing 2022/5184\n",
      "0.05 3 6 3 log2 friedman_mse 0.75 100: Weighted 0.806622 (0.067957)\n",
      "0.05 3 6 3 log2 friedman_mse 0.75 100: Macro 0.699872 (0.086746)\n",
      "Testing 2023/5184\n",
      "0.05 3 6 3 log2 friedman_mse 0.75 200: Weighted 0.808435 (0.063726)\n",
      "0.05 3 6 3 log2 friedman_mse 0.75 200: Macro 0.710613 (0.087252)\n",
      "Testing 2024/5184\n",
      "0.05 3 6 3 log2 friedman_mse 0.75 500: Weighted 0.803398 (0.062493)\n",
      "0.05 3 6 3 log2 friedman_mse 0.75 500: Macro 0.703139 (0.093737)\n",
      "Testing 2025/5184\n",
      "0.05 3 6 3 log2 friedman_mse 1.0 50: Weighted 0.783462 (0.050630)\n",
      "0.05 3 6 3 log2 friedman_mse 1.0 50: Macro 0.669810 (0.068431)\n",
      "Testing 2026/5184\n",
      "0.05 3 6 3 log2 friedman_mse 1.0 100: Weighted 0.803804 (0.074834)\n",
      "0.05 3 6 3 log2 friedman_mse 1.0 100: Macro 0.701442 (0.097551)\n",
      "Testing 2027/5184\n",
      "0.05 3 6 3 log2 friedman_mse 1.0 200: Weighted 0.803469 (0.051779)\n",
      "0.05 3 6 3 log2 friedman_mse 1.0 200: Macro 0.706236 (0.073933)\n",
      "Testing 2028/5184\n",
      "0.05 3 6 3 log2 friedman_mse 1.0 500: Weighted 0.815598 (0.050475)\n",
      "0.05 3 6 3 log2 friedman_mse 1.0 500: Macro 0.722597 (0.074998)\n",
      "Testing 2029/5184\n",
      "0.05 3 6 3 log2 mae 0.5 50: Weighted 0.803852 (0.065767)\n",
      "0.05 3 6 3 log2 mae 0.5 50: Macro 0.688947 (0.090547)\n",
      "Testing 2030/5184\n",
      "0.05 3 6 3 log2 mae 0.5 100: Weighted 0.800714 (0.060189)\n",
      "0.05 3 6 3 log2 mae 0.5 100: Macro 0.683390 (0.084246)\n",
      "Testing 2031/5184\n",
      "0.05 3 6 3 log2 mae 0.5 200: Weighted 0.794141 (0.065060)\n",
      "0.05 3 6 3 log2 mae 0.5 200: Macro 0.673091 (0.091086)\n",
      "Testing 2032/5184\n",
      "0.05 3 6 3 log2 mae 0.5 500: Weighted 0.796784 (0.071061)\n",
      "0.05 3 6 3 log2 mae 0.5 500: Macro 0.673720 (0.105158)\n",
      "Testing 2033/5184\n",
      "0.05 3 6 3 log2 mae 0.75 50: Weighted 0.794653 (0.070801)\n",
      "0.05 3 6 3 log2 mae 0.75 50: Macro 0.674343 (0.096000)\n",
      "Testing 2034/5184\n",
      "0.05 3 6 3 log2 mae 0.75 100: Weighted 0.782680 (0.067051)\n",
      "0.05 3 6 3 log2 mae 0.75 100: Macro 0.665537 (0.091354)\n",
      "Testing 2035/5184\n",
      "0.05 3 6 3 log2 mae 0.75 200: Weighted 0.764839 (0.063957)\n",
      "0.05 3 6 3 log2 mae 0.75 200: Macro 0.635561 (0.090972)\n",
      "Testing 2036/5184\n",
      "0.05 3 6 3 log2 mae 0.75 500: Weighted 0.760918 (0.070033)\n",
      "0.05 3 6 3 log2 mae 0.75 500: Macro 0.622375 (0.099213)\n",
      "Testing 2037/5184\n",
      "0.05 3 6 3 log2 mae 1.0 50: Weighted 0.779453 (0.063345)\n",
      "0.05 3 6 3 log2 mae 1.0 50: Macro 0.657371 (0.086540)\n",
      "Testing 2038/5184\n",
      "0.05 3 6 3 log2 mae 1.0 100: Weighted 0.768218 (0.052029)\n",
      "0.05 3 6 3 log2 mae 1.0 100: Macro 0.642916 (0.069046)\n",
      "Testing 2039/5184\n",
      "0.05 3 6 3 log2 mae 1.0 200: Weighted 0.771868 (0.060337)\n",
      "0.05 3 6 3 log2 mae 1.0 200: Macro 0.632210 (0.088011)\n",
      "Testing 2040/5184\n",
      "0.05 3 6 3 log2 mae 1.0 500: Weighted 0.768102 (0.051590)\n",
      "0.05 3 6 3 log2 mae 1.0 500: Macro 0.627342 (0.074402)\n",
      "Testing 2041/5184\n",
      "0.05 3 6 3 sqrt friedman_mse 0.5 50: Weighted 0.803704 (0.041274)\n",
      "0.05 3 6 3 sqrt friedman_mse 0.5 50: Macro 0.696369 (0.054799)\n",
      "Testing 2042/5184\n",
      "0.05 3 6 3 sqrt friedman_mse 0.5 100: Weighted 0.824916 (0.057566)\n",
      "0.05 3 6 3 sqrt friedman_mse 0.5 100: Macro 0.720337 (0.078729)\n",
      "Testing 2043/5184\n",
      "0.05 3 6 3 sqrt friedman_mse 0.5 200: Weighted 0.814028 (0.075033)\n",
      "0.05 3 6 3 sqrt friedman_mse 0.5 200: Macro 0.716749 (0.109331)\n",
      "Testing 2044/5184\n",
      "0.05 3 6 3 sqrt friedman_mse 0.5 500: Weighted 0.819770 (0.069447)\n",
      "0.05 3 6 3 sqrt friedman_mse 0.5 500: Macro 0.721847 (0.103061)\n",
      "Testing 2045/5184\n",
      "0.05 3 6 3 sqrt friedman_mse 0.75 50: Weighted 0.808427 (0.060706)\n",
      "0.05 3 6 3 sqrt friedman_mse 0.75 50: Macro 0.704709 (0.069605)\n",
      "Testing 2046/5184\n",
      "0.05 3 6 3 sqrt friedman_mse 0.75 100: Weighted 0.811573 (0.072956)\n",
      "0.05 3 6 3 sqrt friedman_mse 0.75 100: Macro 0.706774 (0.096034)\n",
      "Testing 2047/5184\n",
      "0.05 3 6 3 sqrt friedman_mse 0.75 200: Weighted 0.807124 (0.056132)\n",
      "0.05 3 6 3 sqrt friedman_mse 0.75 200: Macro 0.709129 (0.080421)\n",
      "Testing 2048/5184\n",
      "0.05 3 6 3 sqrt friedman_mse 0.75 500: Weighted 0.816564 (0.049678)\n",
      "0.05 3 6 3 sqrt friedman_mse 0.75 500: Macro 0.722495 (0.075097)\n",
      "Testing 2049/5184\n",
      "0.05 3 6 3 sqrt friedman_mse 1.0 50: Weighted 0.804778 (0.060755)\n",
      "0.05 3 6 3 sqrt friedman_mse 1.0 50: Macro 0.697769 (0.073285)\n",
      "Testing 2050/5184\n",
      "0.05 3 6 3 sqrt friedman_mse 1.0 100: Weighted 0.798971 (0.072048)\n",
      "0.05 3 6 3 sqrt friedman_mse 1.0 100: Macro 0.694373 (0.102524)\n",
      "Testing 2051/5184\n",
      "0.05 3 6 3 sqrt friedman_mse 1.0 200: Weighted 0.807996 (0.057682)\n",
      "0.05 3 6 3 sqrt friedman_mse 1.0 200: Macro 0.709906 (0.078580)\n",
      "Testing 2052/5184\n",
      "0.05 3 6 3 sqrt friedman_mse 1.0 500: Weighted 0.811576 (0.054947)\n",
      "0.05 3 6 3 sqrt friedman_mse 1.0 500: Macro 0.717175 (0.080458)\n",
      "Testing 2053/5184\n",
      "0.05 3 6 3 sqrt mae 0.5 50: Weighted 0.811716 (0.052371)\n",
      "0.05 3 6 3 sqrt mae 0.5 50: Macro 0.696551 (0.074783)\n",
      "Testing 2054/5184\n",
      "0.05 3 6 3 sqrt mae 0.5 100: Weighted 0.808462 (0.061278)\n",
      "0.05 3 6 3 sqrt mae 0.5 100: Macro 0.689015 (0.092529)\n",
      "Testing 2055/5184\n",
      "0.05 3 6 3 sqrt mae 0.5 200: Weighted 0.804890 (0.070142)\n",
      "0.05 3 6 3 sqrt mae 0.5 200: Macro 0.694185 (0.102910)\n",
      "Testing 2056/5184\n",
      "0.05 3 6 3 sqrt mae 0.5 500: Weighted 0.799280 (0.075396)\n",
      "0.05 3 6 3 sqrt mae 0.5 500: Macro 0.683074 (0.115029)\n",
      "Testing 2057/5184\n",
      "0.05 3 6 3 sqrt mae 0.75 50: Weighted 0.789785 (0.061884)\n",
      "0.05 3 6 3 sqrt mae 0.75 50: Macro 0.672146 (0.082323)\n",
      "Testing 2058/5184\n",
      "0.05 3 6 3 sqrt mae 0.75 100: Weighted 0.779282 (0.069402)\n",
      "0.05 3 6 3 sqrt mae 0.75 100: Macro 0.661090 (0.094746)\n",
      "Testing 2059/5184\n",
      "0.05 3 6 3 sqrt mae 0.75 200: Weighted 0.774677 (0.073485)\n",
      "0.05 3 6 3 sqrt mae 0.75 200: Macro 0.650522 (0.105421)\n",
      "Testing 2060/5184\n",
      "0.05 3 6 3 sqrt mae 0.75 500: Weighted 0.762935 (0.067763)\n",
      "0.05 3 6 3 sqrt mae 0.75 500: Macro 0.625764 (0.091604)\n",
      "Testing 2061/5184\n",
      "0.05 3 6 3 sqrt mae 1.0 50: Weighted 0.791646 (0.079208)\n",
      "0.05 3 6 3 sqrt mae 1.0 50: Macro 0.675563 (0.110626)\n",
      "Testing 2062/5184\n",
      "0.05 3 6 3 sqrt mae 1.0 100: Weighted 0.775300 (0.072569)\n",
      "0.05 3 6 3 sqrt mae 1.0 100: Macro 0.648405 (0.105302)\n",
      "Testing 2063/5184\n",
      "0.05 3 6 3 sqrt mae 1.0 200: Weighted 0.760408 (0.068771)\n",
      "0.05 3 6 3 sqrt mae 1.0 200: Macro 0.620529 (0.098335)\n",
      "Testing 2064/5184\n",
      "0.05 3 6 3 sqrt mae 1.0 500: Weighted 0.761207 (0.075939)\n",
      "0.05 3 6 3 sqrt mae 1.0 500: Macro 0.618569 (0.100563)\n",
      "Testing 2065/5184\n",
      "0.05 3 6 5 log2 friedman_mse 0.5 50: Weighted 0.836899 (0.068641)\n",
      "0.05 3 6 5 log2 friedman_mse 0.5 50: Macro 0.740296 (0.098499)\n",
      "Testing 2066/5184\n",
      "0.05 3 6 5 log2 friedman_mse 0.5 100: Weighted 0.818122 (0.077952)\n",
      "0.05 3 6 5 log2 friedman_mse 0.5 100: Macro 0.715101 (0.111374)\n",
      "Testing 2067/5184\n",
      "0.05 3 6 5 log2 friedman_mse 0.5 200: Weighted 0.815701 (0.059722)\n",
      "0.05 3 6 5 log2 friedman_mse 0.5 200: Macro 0.715303 (0.097929)\n",
      "Testing 2068/5184\n",
      "0.05 3 6 5 log2 friedman_mse 0.5 500: Weighted 0.814343 (0.089364)\n",
      "0.05 3 6 5 log2 friedman_mse 0.5 500: Macro 0.720462 (0.143108)\n",
      "Testing 2069/5184\n",
      "0.05 3 6 5 log2 friedman_mse 0.75 50: Weighted 0.799429 (0.094204)\n",
      "0.05 3 6 5 log2 friedman_mse 0.75 50: Macro 0.695056 (0.130695)\n",
      "Testing 2070/5184\n",
      "0.05 3 6 5 log2 friedman_mse 0.75 100: Weighted 0.803616 (0.089535)\n",
      "0.05 3 6 5 log2 friedman_mse 0.75 100: Macro 0.699006 (0.126181)\n",
      "Testing 2071/5184\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05 3 6 5 log2 friedman_mse 0.75 200: Weighted 0.811481 (0.072669)\n",
      "0.05 3 6 5 log2 friedman_mse 0.75 200: Macro 0.710043 (0.110723)\n",
      "Testing 2072/5184\n",
      "0.05 3 6 5 log2 friedman_mse 0.75 500: Weighted 0.809892 (0.084666)\n",
      "0.05 3 6 5 log2 friedman_mse 0.75 500: Macro 0.705733 (0.130781)\n",
      "Testing 2073/5184\n",
      "0.05 3 6 5 log2 friedman_mse 1.0 50: Weighted 0.801006 (0.077008)\n",
      "0.05 3 6 5 log2 friedman_mse 1.0 50: Macro 0.698735 (0.101840)\n",
      "Testing 2074/5184\n",
      "0.05 3 6 5 log2 friedman_mse 1.0 100: Weighted 0.816570 (0.084124)\n",
      "0.05 3 6 5 log2 friedman_mse 1.0 100: Macro 0.721442 (0.115242)\n",
      "Testing 2075/5184\n",
      "0.05 3 6 5 log2 friedman_mse 1.0 200: Weighted 0.809976 (0.086350)\n",
      "0.05 3 6 5 log2 friedman_mse 1.0 200: Macro 0.702383 (0.128745)\n",
      "Testing 2076/5184\n",
      "0.05 3 6 5 log2 friedman_mse 1.0 500: Weighted 0.811930 (0.074426)\n",
      "0.05 3 6 5 log2 friedman_mse 1.0 500: Macro 0.709195 (0.111483)\n",
      "Testing 2077/5184\n",
      "0.05 3 6 5 log2 mae 0.5 50: Weighted 0.791053 (0.070452)\n",
      "0.05 3 6 5 log2 mae 0.5 50: Macro 0.675865 (0.092962)\n",
      "Testing 2078/5184\n",
      "0.05 3 6 5 log2 mae 0.5 100: Weighted 0.790400 (0.071086)\n",
      "0.05 3 6 5 log2 mae 0.5 100: Macro 0.670844 (0.097975)\n",
      "Testing 2079/5184\n",
      "0.05 3 6 5 log2 mae 0.5 200: Weighted 0.797547 (0.082556)\n",
      "0.05 3 6 5 log2 mae 0.5 200: Macro 0.680448 (0.109036)\n",
      "Testing 2080/5184\n",
      "0.05 3 6 5 log2 mae 0.5 500: Weighted 0.798172 (0.079847)\n",
      "0.05 3 6 5 log2 mae 0.5 500: Macro 0.676811 (0.108827)\n",
      "Testing 2081/5184\n",
      "0.05 3 6 5 log2 mae 0.75 50: Weighted 0.787523 (0.075938)\n",
      "0.05 3 6 5 log2 mae 0.75 50: Macro 0.664299 (0.105895)\n",
      "Testing 2082/5184\n",
      "0.05 3 6 5 log2 mae 0.75 100: Weighted 0.785142 (0.051880)\n",
      "0.05 3 6 5 log2 mae 0.75 100: Macro 0.664897 (0.071711)\n",
      "Testing 2083/5184\n",
      "0.05 3 6 5 log2 mae 0.75 200: Weighted 0.765702 (0.082032)\n",
      "0.05 3 6 5 log2 mae 0.75 200: Macro 0.634985 (0.119830)\n",
      "Testing 2084/5184\n",
      "0.05 3 6 5 log2 mae 0.75 500: Weighted 0.793181 (0.071911)\n",
      "0.05 3 6 5 log2 mae 0.75 500: Macro 0.661950 (0.092844)\n",
      "Testing 2085/5184\n",
      "0.05 3 6 5 log2 mae 1.0 50: Weighted 0.773428 (0.063805)\n",
      "0.05 3 6 5 log2 mae 1.0 50: Macro 0.647288 (0.092308)\n",
      "Testing 2086/5184\n",
      "0.05 3 6 5 log2 mae 1.0 100: Weighted 0.775025 (0.086543)\n",
      "0.05 3 6 5 log2 mae 1.0 100: Macro 0.645062 (0.121856)\n",
      "Testing 2087/5184\n",
      "0.05 3 6 5 log2 mae 1.0 200: Weighted 0.767876 (0.079279)\n",
      "0.05 3 6 5 log2 mae 1.0 200: Macro 0.626543 (0.101614)\n",
      "Testing 2088/5184\n",
      "0.05 3 6 5 log2 mae 1.0 500: Weighted 0.783151 (0.073798)\n",
      "0.05 3 6 5 log2 mae 1.0 500: Macro 0.651283 (0.091456)\n",
      "Testing 2089/5184\n",
      "0.05 3 6 5 sqrt friedman_mse 0.5 50: Weighted 0.821883 (0.064149)\n",
      "0.05 3 6 5 sqrt friedman_mse 0.5 50: Macro 0.718227 (0.090980)\n",
      "Testing 2090/5184\n",
      "0.05 3 6 5 sqrt friedman_mse 0.5 100: Weighted 0.811630 (0.066367)\n",
      "0.05 3 6 5 sqrt friedman_mse 0.5 100: Macro 0.708040 (0.090916)\n",
      "Testing 2091/5184\n",
      "0.05 3 6 5 sqrt friedman_mse 0.5 200: Weighted 0.816901 (0.089825)\n",
      "0.05 3 6 5 sqrt friedman_mse 0.5 200: Macro 0.718025 (0.128529)\n",
      "Testing 2092/5184\n",
      "0.05 3 6 5 sqrt friedman_mse 0.5 500: Weighted 0.821112 (0.081957)\n",
      "0.05 3 6 5 sqrt friedman_mse 0.5 500: Macro 0.729984 (0.131477)\n",
      "Testing 2093/5184\n",
      "0.05 3 6 5 sqrt friedman_mse 0.75 50: Weighted 0.812987 (0.064505)\n",
      "0.05 3 6 5 sqrt friedman_mse 0.75 50: Macro 0.704802 (0.087690)\n",
      "Testing 2094/5184\n",
      "0.05 3 6 5 sqrt friedman_mse 0.75 100: Weighted 0.807161 (0.065897)\n",
      "0.05 3 6 5 sqrt friedman_mse 0.75 100: Macro 0.703616 (0.087039)\n",
      "Testing 2095/5184\n",
      "0.05 3 6 5 sqrt friedman_mse 0.75 200: Weighted 0.814665 (0.085714)\n",
      "0.05 3 6 5 sqrt friedman_mse 0.75 200: Macro 0.715185 (0.120246)\n",
      "Testing 2096/5184\n",
      "0.05 3 6 5 sqrt friedman_mse 0.75 500: Weighted 0.809227 (0.078815)\n",
      "0.05 3 6 5 sqrt friedman_mse 0.75 500: Macro 0.701954 (0.124077)\n",
      "Testing 2097/5184\n",
      "0.05 3 6 5 sqrt friedman_mse 1.0 50: Weighted 0.802280 (0.069414)\n",
      "0.05 3 6 5 sqrt friedman_mse 1.0 50: Macro 0.700925 (0.089654)\n",
      "Testing 2098/5184\n",
      "0.05 3 6 5 sqrt friedman_mse 1.0 100: Weighted 0.810600 (0.083884)\n",
      "0.05 3 6 5 sqrt friedman_mse 1.0 100: Macro 0.706904 (0.119429)\n",
      "Testing 2099/5184\n",
      "0.05 3 6 5 sqrt friedman_mse 1.0 200: Weighted 0.806256 (0.077676)\n",
      "0.05 3 6 5 sqrt friedman_mse 1.0 200: Macro 0.704306 (0.114245)\n",
      "Testing 2100/5184\n",
      "0.05 3 6 5 sqrt friedman_mse 1.0 500: Weighted 0.805825 (0.081859)\n",
      "0.05 3 6 5 sqrt friedman_mse 1.0 500: Macro 0.698535 (0.123627)\n",
      "Testing 2101/5184\n",
      "0.05 3 6 5 sqrt mae 0.5 50: Weighted 0.801620 (0.067932)\n",
      "0.05 3 6 5 sqrt mae 0.5 50: Macro 0.679036 (0.100067)\n",
      "Testing 2102/5184\n",
      "0.05 3 6 5 sqrt mae 0.5 100: Weighted 0.794181 (0.065281)\n",
      "0.05 3 6 5 sqrt mae 0.5 100: Macro 0.668026 (0.096817)\n",
      "Testing 2103/5184\n",
      "0.05 3 6 5 sqrt mae 0.5 200: Weighted 0.793454 (0.059372)\n",
      "0.05 3 6 5 sqrt mae 0.5 200: Macro 0.670733 (0.081296)\n",
      "Testing 2104/5184\n",
      "0.05 3 6 5 sqrt mae 0.5 500: Weighted 0.783253 (0.087974)\n",
      "0.05 3 6 5 sqrt mae 0.5 500: Macro 0.656948 (0.121387)\n",
      "Testing 2105/5184\n",
      "0.05 3 6 5 sqrt mae 0.75 50: Weighted 0.789288 (0.066896)\n",
      "0.05 3 6 5 sqrt mae 0.75 50: Macro 0.660934 (0.097625)\n",
      "Testing 2106/5184\n",
      "0.05 3 6 5 sqrt mae 0.75 100: Weighted 0.778994 (0.075404)\n",
      "0.05 3 6 5 sqrt mae 0.75 100: Macro 0.645302 (0.110630)\n",
      "Testing 2107/5184\n",
      "0.05 3 6 5 sqrt mae 0.75 200: Weighted 0.778694 (0.091979)\n",
      "0.05 3 6 5 sqrt mae 0.75 200: Macro 0.653356 (0.124909)\n",
      "Testing 2108/5184\n",
      "0.05 3 6 5 sqrt mae 0.75 500: Weighted 0.798774 (0.076501)\n",
      "0.05 3 6 5 sqrt mae 0.75 500: Macro 0.674097 (0.104565)\n",
      "Testing 2109/5184\n",
      "0.05 3 6 5 sqrt mae 1.0 50: Weighted 0.781219 (0.067772)\n",
      "0.05 3 6 5 sqrt mae 1.0 50: Macro 0.652820 (0.100570)\n",
      "Testing 2110/5184\n",
      "0.05 3 6 5 sqrt mae 1.0 100: Weighted 0.760635 (0.081630)\n",
      "0.05 3 6 5 sqrt mae 1.0 100: Macro 0.624317 (0.111680)\n",
      "Testing 2111/5184\n",
      "0.05 3 6 5 sqrt mae 1.0 200: Weighted 0.773588 (0.084199)\n",
      "0.05 3 6 5 sqrt mae 1.0 200: Macro 0.637982 (0.114947)\n",
      "Testing 2112/5184\n",
      "0.05 3 6 5 sqrt mae 1.0 500: Weighted 0.780240 (0.092883)\n",
      "0.05 3 6 5 sqrt mae 1.0 500: Macro 0.645156 (0.126755)\n",
      "Testing 2113/5184\n",
      "0.05 3 6 8 log2 friedman_mse 0.5 50: Weighted 0.820774 (0.070491)\n",
      "0.05 3 6 8 log2 friedman_mse 0.5 50: Macro 0.712588 (0.102691)\n",
      "Testing 2114/5184\n",
      "0.05 3 6 8 log2 friedman_mse 0.5 100: Weighted 0.823534 (0.078637)\n",
      "0.05 3 6 8 log2 friedman_mse 0.5 100: Macro 0.722201 (0.110488)\n",
      "Testing 2115/5184\n",
      "0.05 3 6 8 log2 friedman_mse 0.5 200: Weighted 0.824492 (0.071918)\n",
      "0.05 3 6 8 log2 friedman_mse 0.5 200: Macro 0.726725 (0.113541)\n",
      "Testing 2116/5184\n",
      "0.05 3 6 8 log2 friedman_mse 0.5 500: Weighted 0.826786 (0.076468)\n",
      "0.05 3 6 8 log2 friedman_mse 0.5 500: Macro 0.726805 (0.125876)\n",
      "Testing 2117/5184\n",
      "0.05 3 6 8 log2 friedman_mse 0.75 50: Weighted 0.815248 (0.085095)\n",
      "0.05 3 6 8 log2 friedman_mse 0.75 50: Macro 0.728955 (0.107836)\n",
      "Testing 2118/5184\n",
      "0.05 3 6 8 log2 friedman_mse 0.75 100: Weighted 0.802980 (0.080800)\n",
      "0.05 3 6 8 log2 friedman_mse 0.75 100: Macro 0.701395 (0.117128)\n",
      "Testing 2119/5184\n",
      "0.05 3 6 8 log2 friedman_mse 0.75 200: Weighted 0.830349 (0.087978)\n",
      "0.05 3 6 8 log2 friedman_mse 0.75 200: Macro 0.733813 (0.134048)\n",
      "Testing 2120/5184\n",
      "0.05 3 6 8 log2 friedman_mse 0.75 500: Weighted 0.827570 (0.078641)\n",
      "0.05 3 6 8 log2 friedman_mse 0.75 500: Macro 0.735402 (0.121272)\n",
      "Testing 2121/5184\n",
      "0.05 3 6 8 log2 friedman_mse 1.0 50: Weighted 0.790460 (0.072862)\n",
      "0.05 3 6 8 log2 friedman_mse 1.0 50: Macro 0.672797 (0.099903)\n",
      "Testing 2122/5184\n",
      "0.05 3 6 8 log2 friedman_mse 1.0 100: Weighted 0.794400 (0.070420)\n",
      "0.05 3 6 8 log2 friedman_mse 1.0 100: Macro 0.687517 (0.094752)\n",
      "Testing 2123/5184\n",
      "0.05 3 6 8 log2 friedman_mse 1.0 200: Weighted 0.801442 (0.079973)\n",
      "0.05 3 6 8 log2 friedman_mse 1.0 200: Macro 0.699345 (0.109383)\n",
      "Testing 2124/5184\n",
      "0.05 3 6 8 log2 friedman_mse 1.0 500: Weighted 0.806833 (0.073381)\n",
      "0.05 3 6 8 log2 friedman_mse 1.0 500: Macro 0.709420 (0.107953)\n",
      "Testing 2125/5184\n",
      "0.05 3 6 8 log2 mae 0.5 50: Weighted 0.791593 (0.070367)\n",
      "0.05 3 6 8 log2 mae 0.5 50: Macro 0.668807 (0.098567)\n",
      "Testing 2126/5184\n",
      "0.05 3 6 8 log2 mae 0.5 100: Weighted 0.797076 (0.065114)\n",
      "0.05 3 6 8 log2 mae 0.5 100: Macro 0.677661 (0.090104)\n",
      "Testing 2127/5184\n",
      "0.05 3 6 8 log2 mae 0.5 200: Weighted 0.796322 (0.073099)\n",
      "0.05 3 6 8 log2 mae 0.5 200: Macro 0.681147 (0.098007)\n",
      "Testing 2128/5184\n",
      "0.05 3 6 8 log2 mae 0.5 500: Weighted 0.826777 (0.071742)\n",
      "0.05 3 6 8 log2 mae 0.5 500: Macro 0.720496 (0.103854)\n",
      "Testing 2129/5184\n",
      "0.05 3 6 8 log2 mae 0.75 50: Weighted 0.789179 (0.062387)\n",
      "0.05 3 6 8 log2 mae 0.75 50: Macro 0.659647 (0.091795)\n",
      "Testing 2130/5184\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05 3 6 8 log2 mae 0.75 100: Weighted 0.778563 (0.082948)\n",
      "0.05 3 6 8 log2 mae 0.75 100: Macro 0.654343 (0.113175)\n",
      "Testing 2131/5184\n",
      "0.05 3 6 8 log2 mae 0.75 200: Weighted 0.785051 (0.094159)\n",
      "0.05 3 6 8 log2 mae 0.75 200: Macro 0.659715 (0.136879)\n",
      "Testing 2132/5184\n",
      "0.05 3 6 8 log2 mae 0.75 500: Weighted 0.792133 (0.094872)\n",
      "0.05 3 6 8 log2 mae 0.75 500: Macro 0.670478 (0.138172)\n",
      "Testing 2133/5184\n",
      "0.05 3 6 8 log2 mae 1.0 50: Weighted 0.779926 (0.089672)\n",
      "0.05 3 6 8 log2 mae 1.0 50: Macro 0.652416 (0.127024)\n",
      "Testing 2134/5184\n",
      "0.05 3 6 8 log2 mae 1.0 100: Weighted 0.759811 (0.090838)\n",
      "0.05 3 6 8 log2 mae 1.0 100: Macro 0.618507 (0.127177)\n",
      "Testing 2135/5184\n",
      "0.05 3 6 8 log2 mae 1.0 200: Weighted 0.771395 (0.075996)\n",
      "0.05 3 6 8 log2 mae 1.0 200: Macro 0.634473 (0.114287)\n",
      "Testing 2136/5184\n",
      "0.05 3 6 8 log2 mae 1.0 500: Weighted 0.790657 (0.086734)\n",
      "0.05 3 6 8 log2 mae 1.0 500: Macro 0.660770 (0.131694)\n",
      "Testing 2137/5184\n",
      "0.05 3 6 8 sqrt friedman_mse 0.5 50: Weighted 0.830903 (0.066947)\n",
      "0.05 3 6 8 sqrt friedman_mse 0.5 50: Macro 0.731058 (0.097040)\n",
      "Testing 2138/5184\n",
      "0.05 3 6 8 sqrt friedman_mse 0.5 100: Weighted 0.820601 (0.081023)\n",
      "0.05 3 6 8 sqrt friedman_mse 0.5 100: Macro 0.716757 (0.116646)\n",
      "Testing 2139/5184\n",
      "0.05 3 6 8 sqrt friedman_mse 0.5 200: Weighted 0.825509 (0.072621)\n",
      "0.05 3 6 8 sqrt friedman_mse 0.5 200: Macro 0.718853 (0.106029)\n",
      "Testing 2140/5184\n",
      "0.05 3 6 8 sqrt friedman_mse 0.5 500: Weighted 0.823652 (0.084402)\n",
      "0.05 3 6 8 sqrt friedman_mse 0.5 500: Macro 0.719379 (0.134738)\n",
      "Testing 2141/5184\n",
      "0.05 3 6 8 sqrt friedman_mse 0.75 50: Weighted 0.806444 (0.052198)\n",
      "0.05 3 6 8 sqrt friedman_mse 0.75 50: Macro 0.703217 (0.077625)\n",
      "Testing 2142/5184\n",
      "0.05 3 6 8 sqrt friedman_mse 0.75 100: Weighted 0.815270 (0.084964)\n",
      "0.05 3 6 8 sqrt friedman_mse 0.75 100: Macro 0.715817 (0.120973)\n",
      "Testing 2143/5184\n",
      "0.05 3 6 8 sqrt friedman_mse 0.75 200: Weighted 0.817297 (0.078675)\n",
      "0.05 3 6 8 sqrt friedman_mse 0.75 200: Macro 0.715910 (0.124678)\n",
      "Testing 2144/5184\n",
      "0.05 3 6 8 sqrt friedman_mse 0.75 500: Weighted 0.826889 (0.083128)\n",
      "0.05 3 6 8 sqrt friedman_mse 0.75 500: Macro 0.723633 (0.128243)\n",
      "Testing 2145/5184\n",
      "0.05 3 6 8 sqrt friedman_mse 1.0 50: Weighted 0.787874 (0.068245)\n",
      "0.05 3 6 8 sqrt friedman_mse 1.0 50: Macro 0.674148 (0.086517)\n",
      "Testing 2146/5184\n",
      "0.05 3 6 8 sqrt friedman_mse 1.0 100: Weighted 0.785663 (0.078028)\n",
      "0.05 3 6 8 sqrt friedman_mse 1.0 100: Macro 0.672224 (0.109686)\n",
      "Testing 2147/5184\n",
      "0.05 3 6 8 sqrt friedman_mse 1.0 200: Weighted 0.812619 (0.087828)\n",
      "0.05 3 6 8 sqrt friedman_mse 1.0 200: Macro 0.708486 (0.127595)\n",
      "Testing 2148/5184\n",
      "0.05 3 6 8 sqrt friedman_mse 1.0 500: Weighted 0.797643 (0.079628)\n",
      "0.05 3 6 8 sqrt friedman_mse 1.0 500: Macro 0.689781 (0.114956)\n",
      "Testing 2149/5184\n",
      "0.05 3 6 8 sqrt mae 0.5 50: Weighted 0.811742 (0.075625)\n",
      "0.05 3 6 8 sqrt mae 0.5 50: Macro 0.698840 (0.108678)\n",
      "Testing 2150/5184\n",
      "0.05 3 6 8 sqrt mae 0.5 100: Weighted 0.807939 (0.082536)\n",
      "0.05 3 6 8 sqrt mae 0.5 100: Macro 0.695572 (0.116751)\n",
      "Testing 2151/5184\n",
      "0.05 3 6 8 sqrt mae 0.5 200: Weighted 0.795069 (0.074583)\n",
      "0.05 3 6 8 sqrt mae 0.5 200: Macro 0.681207 (0.098553)\n",
      "Testing 2152/5184\n",
      "0.05 3 6 8 sqrt mae 0.5 500: Weighted 0.807449 (0.079822)\n",
      "0.05 3 6 8 sqrt mae 0.5 500: Macro 0.690870 (0.117374)\n",
      "Testing 2153/5184\n",
      "0.05 3 6 8 sqrt mae 0.75 50: Weighted 0.774929 (0.075885)\n",
      "0.05 3 6 8 sqrt mae 0.75 50: Macro 0.646872 (0.105172)\n",
      "Testing 2154/5184\n",
      "0.05 3 6 8 sqrt mae 0.75 100: Weighted 0.773573 (0.080855)\n",
      "0.05 3 6 8 sqrt mae 0.75 100: Macro 0.640601 (0.115285)\n",
      "Testing 2155/5184\n",
      "0.05 3 6 8 sqrt mae 0.75 200: Weighted 0.788302 (0.083381)\n",
      "0.05 3 6 8 sqrt mae 0.75 200: Macro 0.657395 (0.123884)\n",
      "Testing 2156/5184\n",
      "0.05 3 6 8 sqrt mae 0.75 500: Weighted 0.801172 (0.097055)\n",
      "0.05 3 6 8 sqrt mae 0.75 500: Macro 0.683810 (0.144693)\n",
      "Testing 2157/5184\n",
      "0.05 3 6 8 sqrt mae 1.0 50: Weighted 0.786066 (0.060150)\n",
      "0.05 3 6 8 sqrt mae 1.0 50: Macro 0.671089 (0.081958)\n",
      "Testing 2158/5184\n",
      "0.05 3 6 8 sqrt mae 1.0 100: Weighted 0.769279 (0.078851)\n",
      "0.05 3 6 8 sqrt mae 1.0 100: Macro 0.642376 (0.103600)\n",
      "Testing 2159/5184\n",
      "0.05 3 6 8 sqrt mae 1.0 200: Weighted 0.779349 (0.087140)\n",
      "0.05 3 6 8 sqrt mae 1.0 200: Macro 0.649351 (0.117713)\n",
      "Testing 2160/5184\n",
      "0.05 3 6 8 sqrt mae 1.0 500: Weighted 0.789008 (0.086234)\n",
      "0.05 3 6 8 sqrt mae 1.0 500: Macro 0.662834 (0.129026)\n",
      "Testing 2161/5184\n",
      "0.05 5 2 3 log2 friedman_mse 0.5 50: Weighted 0.815471 (0.065854)\n",
      "0.05 5 2 3 log2 friedman_mse 0.5 50: Macro 0.704951 (0.093172)\n",
      "Testing 2162/5184\n",
      "0.05 5 2 3 log2 friedman_mse 0.5 100: Weighted 0.813350 (0.060976)\n",
      "0.05 5 2 3 log2 friedman_mse 0.5 100: Macro 0.713385 (0.085106)\n",
      "Testing 2163/5184\n",
      "0.05 5 2 3 log2 friedman_mse 0.5 200: Weighted 0.823969 (0.073082)\n",
      "0.05 5 2 3 log2 friedman_mse 0.5 200: Macro 0.719421 (0.108739)\n",
      "Testing 2164/5184\n",
      "0.05 5 2 3 log2 friedman_mse 0.5 500: Weighted 0.822818 (0.048862)\n",
      "0.05 5 2 3 log2 friedman_mse 0.5 500: Macro 0.730274 (0.068204)\n",
      "Testing 2165/5184\n",
      "0.05 5 2 3 log2 friedman_mse 0.75 50: Weighted 0.820013 (0.059843)\n",
      "0.05 5 2 3 log2 friedman_mse 0.75 50: Macro 0.716632 (0.076772)\n",
      "Testing 2166/5184\n",
      "0.05 5 2 3 log2 friedman_mse 0.75 100: Weighted 0.814143 (0.061528)\n",
      "0.05 5 2 3 log2 friedman_mse 0.75 100: Macro 0.717351 (0.074688)\n",
      "Testing 2167/5184\n",
      "0.05 5 2 3 log2 friedman_mse 0.75 200: Weighted 0.811028 (0.075699)\n",
      "0.05 5 2 3 log2 friedman_mse 0.75 200: Macro 0.712091 (0.105936)\n",
      "Testing 2168/5184\n",
      "0.05 5 2 3 log2 friedman_mse 0.75 500: Weighted 0.807529 (0.050556)\n",
      "0.05 5 2 3 log2 friedman_mse 0.75 500: Macro 0.708307 (0.068283)\n",
      "Testing 2169/5184\n",
      "0.05 5 2 3 log2 friedman_mse 1.0 50: Weighted 0.791862 (0.060917)\n",
      "0.05 5 2 3 log2 friedman_mse 1.0 50: Macro 0.676220 (0.078393)\n",
      "Testing 2170/5184\n",
      "0.05 5 2 3 log2 friedman_mse 1.0 100: Weighted 0.799214 (0.079618)\n",
      "0.05 5 2 3 log2 friedman_mse 1.0 100: Macro 0.697978 (0.100961)\n",
      "Testing 2171/5184\n",
      "0.05 5 2 3 log2 friedman_mse 1.0 200: Weighted 0.817859 (0.073319)\n",
      "0.05 5 2 3 log2 friedman_mse 1.0 200: Macro 0.716375 (0.100563)\n",
      "Testing 2172/5184\n",
      "0.05 5 2 3 log2 friedman_mse 1.0 500: Weighted 0.797236 (0.067637)\n",
      "0.05 5 2 3 log2 friedman_mse 1.0 500: Macro 0.689882 (0.097336)\n",
      "Testing 2173/5184\n",
      "0.05 5 2 3 log2 mae 0.5 50: Weighted 0.816593 (0.056095)\n",
      "0.05 5 2 3 log2 mae 0.5 50: Macro 0.704334 (0.083640)\n",
      "Testing 2174/5184\n",
      "0.05 5 2 3 log2 mae 0.5 100: Weighted 0.808859 (0.063772)\n",
      "0.05 5 2 3 log2 mae 0.5 100: Macro 0.695150 (0.089695)\n",
      "Testing 2175/5184\n",
      "0.05 5 2 3 log2 mae 0.5 200: Weighted 0.802927 (0.076668)\n",
      "0.05 5 2 3 log2 mae 0.5 200: Macro 0.689049 (0.108101)\n",
      "Testing 2176/5184\n",
      "0.05 5 2 3 log2 mae 0.5 500: Weighted 0.787888 (0.069739)\n",
      "0.05 5 2 3 log2 mae 0.5 500: Macro 0.665942 (0.091912)\n",
      "Testing 2177/5184\n",
      "0.05 5 2 3 log2 mae 0.75 50: Weighted 0.800213 (0.074535)\n",
      "0.05 5 2 3 log2 mae 0.75 50: Macro 0.681711 (0.102884)\n",
      "Testing 2178/5184\n",
      "0.05 5 2 3 log2 mae 0.75 100: Weighted 0.790785 (0.072619)\n",
      "0.05 5 2 3 log2 mae 0.75 100: Macro 0.663930 (0.105675)\n",
      "Testing 2179/5184\n",
      "0.05 5 2 3 log2 mae 0.75 200: Weighted 0.776895 (0.061050)\n",
      "0.05 5 2 3 log2 mae 0.75 200: Macro 0.648663 (0.090623)\n",
      "Testing 2180/5184\n",
      "0.05 5 2 3 log2 mae 0.75 500: Weighted 0.754482 (0.066110)\n",
      "0.05 5 2 3 log2 mae 0.75 500: Macro 0.610449 (0.082494)\n",
      "Testing 2181/5184\n",
      "0.05 5 2 3 log2 mae 1.0 50: Weighted 0.791723 (0.068595)\n",
      "0.05 5 2 3 log2 mae 1.0 50: Macro 0.672851 (0.097351)\n",
      "Testing 2182/5184\n",
      "0.05 5 2 3 log2 mae 1.0 100: Weighted 0.795255 (0.075304)\n",
      "0.05 5 2 3 log2 mae 1.0 100: Macro 0.677623 (0.104094)\n",
      "Testing 2183/5184\n",
      "0.05 5 2 3 log2 mae 1.0 200: Weighted 0.758267 (0.050781)\n",
      "0.05 5 2 3 log2 mae 1.0 200: Macro 0.612362 (0.074274)\n",
      "Testing 2184/5184\n",
      "0.05 5 2 3 log2 mae 1.0 500: Weighted 0.755281 (0.055645)\n",
      "0.05 5 2 3 log2 mae 1.0 500: Macro 0.605065 (0.077784)\n",
      "Testing 2185/5184\n",
      "0.05 5 2 3 sqrt friedman_mse 0.5 50: Weighted 0.815630 (0.061345)\n",
      "0.05 5 2 3 sqrt friedman_mse 0.5 50: Macro 0.706057 (0.087508)\n",
      "Testing 2186/5184\n",
      "0.05 5 2 3 sqrt friedman_mse 0.5 100: Weighted 0.812028 (0.063752)\n",
      "0.05 5 2 3 sqrt friedman_mse 0.5 100: Macro 0.704705 (0.083630)\n",
      "Testing 2187/5184\n",
      "0.05 5 2 3 sqrt friedman_mse 0.5 200: Weighted 0.813675 (0.060034)\n",
      "0.05 5 2 3 sqrt friedman_mse 0.5 200: Macro 0.719113 (0.084333)\n",
      "Testing 2188/5184\n",
      "0.05 5 2 3 sqrt friedman_mse 0.5 500: Weighted 0.810028 (0.056502)\n",
      "0.05 5 2 3 sqrt friedman_mse 0.5 500: Macro 0.707576 (0.078968)\n",
      "Testing 2189/5184\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05 5 2 3 sqrt friedman_mse 0.75 50: Weighted 0.809130 (0.057895)\n",
      "0.05 5 2 3 sqrt friedman_mse 0.75 50: Macro 0.706040 (0.070367)\n",
      "Testing 2190/5184\n",
      "0.05 5 2 3 sqrt friedman_mse 0.75 100: Weighted 0.807400 (0.089412)\n",
      "0.05 5 2 3 sqrt friedman_mse 0.75 100: Macro 0.701468 (0.118792)\n",
      "Testing 2191/5184\n",
      "0.05 5 2 3 sqrt friedman_mse 0.75 200: Weighted 0.818956 (0.073612)\n",
      "0.05 5 2 3 sqrt friedman_mse 0.75 200: Macro 0.717184 (0.095160)\n",
      "Testing 2192/5184\n",
      "0.05 5 2 3 sqrt friedman_mse 0.75 500: Weighted 0.815909 (0.056801)\n",
      "0.05 5 2 3 sqrt friedman_mse 0.75 500: Macro 0.718780 (0.070531)\n",
      "Testing 2193/5184\n",
      "0.05 5 2 3 sqrt friedman_mse 1.0 50: Weighted 0.793422 (0.054519)\n",
      "0.05 5 2 3 sqrt friedman_mse 1.0 50: Macro 0.680244 (0.066113)\n",
      "Testing 2194/5184\n",
      "0.05 5 2 3 sqrt friedman_mse 1.0 100: Weighted 0.813424 (0.085161)\n",
      "0.05 5 2 3 sqrt friedman_mse 1.0 100: Macro 0.716263 (0.110409)\n",
      "Testing 2195/5184\n",
      "0.05 5 2 3 sqrt friedman_mse 1.0 200: Weighted 0.825373 (0.069732)\n",
      "0.05 5 2 3 sqrt friedman_mse 1.0 200: Macro 0.732948 (0.089339)\n",
      "Testing 2196/5184\n",
      "0.05 5 2 3 sqrt friedman_mse 1.0 500: Weighted 0.801426 (0.066031)\n",
      "0.05 5 2 3 sqrt friedman_mse 1.0 500: Macro 0.691657 (0.091137)\n",
      "Testing 2197/5184\n",
      "0.05 5 2 3 sqrt mae 0.5 50: Weighted 0.817184 (0.053385)\n",
      "0.05 5 2 3 sqrt mae 0.5 50: Macro 0.703305 (0.078713)\n",
      "Testing 2198/5184\n",
      "0.05 5 2 3 sqrt mae 0.5 100: Weighted 0.807832 (0.073511)\n",
      "0.05 5 2 3 sqrt mae 0.5 100: Macro 0.693351 (0.102673)\n",
      "Testing 2199/5184\n",
      "0.05 5 2 3 sqrt mae 0.5 200: Weighted 0.798264 (0.061192)\n",
      "0.05 5 2 3 sqrt mae 0.5 200: Macro 0.675525 (0.085399)\n",
      "Testing 2200/5184\n",
      "0.05 5 2 3 sqrt mae 0.5 500: Weighted 0.794151 (0.074637)\n",
      "0.05 5 2 3 sqrt mae 0.5 500: Macro 0.673434 (0.106651)\n",
      "Testing 2201/5184\n",
      "0.05 5 2 3 sqrt mae 0.75 50: Weighted 0.810201 (0.071393)\n",
      "0.05 5 2 3 sqrt mae 0.75 50: Macro 0.699779 (0.098893)\n",
      "Testing 2202/5184\n",
      "0.05 5 2 3 sqrt mae 0.75 100: Weighted 0.796208 (0.074131)\n",
      "0.05 5 2 3 sqrt mae 0.75 100: Macro 0.677954 (0.103705)\n",
      "Testing 2203/5184\n",
      "0.05 5 2 3 sqrt mae 0.75 200: Weighted 0.788813 (0.066988)\n",
      "0.05 5 2 3 sqrt mae 0.75 200: Macro 0.666564 (0.092510)\n",
      "Testing 2204/5184\n",
      "0.05 5 2 3 sqrt mae 0.75 500: Weighted 0.776064 (0.071963)\n",
      "0.05 5 2 3 sqrt mae 0.75 500: Macro 0.642027 (0.098992)\n",
      "Testing 2205/5184\n",
      "0.05 5 2 3 sqrt mae 1.0 50: Weighted 0.795461 (0.073694)\n",
      "0.05 5 2 3 sqrt mae 1.0 50: Macro 0.677852 (0.102824)\n",
      "Testing 2206/5184\n",
      "0.05 5 2 3 sqrt mae 1.0 100: Weighted 0.785857 (0.087703)\n",
      "0.05 5 2 3 sqrt mae 1.0 100: Macro 0.662640 (0.123206)\n",
      "Testing 2207/5184\n",
      "0.05 5 2 3 sqrt mae 1.0 200: Weighted 0.771583 (0.074932)\n",
      "0.05 5 2 3 sqrt mae 1.0 200: Macro 0.630424 (0.109605)\n",
      "Testing 2208/5184\n",
      "0.05 5 2 3 sqrt mae 1.0 500: Weighted 0.750612 (0.065838)\n",
      "0.05 5 2 3 sqrt mae 1.0 500: Macro 0.597511 (0.089993)\n",
      "Testing 2209/5184\n",
      "0.05 5 2 5 log2 friedman_mse 0.5 50: Weighted 0.812736 (0.054182)\n",
      "0.05 5 2 5 log2 friedman_mse 0.5 50: Macro 0.706095 (0.077650)\n",
      "Testing 2210/5184\n",
      "0.05 5 2 5 log2 friedman_mse 0.5 100: Weighted 0.819924 (0.066315)\n",
      "0.05 5 2 5 log2 friedman_mse 0.5 100: Macro 0.724288 (0.098921)\n",
      "Testing 2211/5184\n",
      "0.05 5 2 5 log2 friedman_mse 0.5 200: Weighted 0.812623 (0.067508)\n",
      "0.05 5 2 5 log2 friedman_mse 0.5 200: Macro 0.706222 (0.099522)\n",
      "Testing 2212/5184\n",
      "0.05 5 2 5 log2 friedman_mse 0.5 500: Weighted 0.814113 (0.070790)\n",
      "0.05 5 2 5 log2 friedman_mse 0.5 500: Macro 0.713939 (0.104462)\n",
      "Testing 2213/5184\n",
      "0.05 5 2 5 log2 friedman_mse 0.75 50: Weighted 0.812092 (0.070104)\n",
      "0.05 5 2 5 log2 friedman_mse 0.75 50: Macro 0.703092 (0.098936)\n",
      "Testing 2214/5184\n",
      "0.05 5 2 5 log2 friedman_mse 0.75 100: Weighted 0.825257 (0.072813)\n",
      "0.05 5 2 5 log2 friedman_mse 0.75 100: Macro 0.731806 (0.098532)\n",
      "Testing 2215/5184\n",
      "0.05 5 2 5 log2 friedman_mse 0.75 200: Weighted 0.815381 (0.084996)\n",
      "0.05 5 2 5 log2 friedman_mse 0.75 200: Macro 0.714852 (0.120596)\n",
      "Testing 2216/5184\n",
      "0.05 5 2 5 log2 friedman_mse 0.75 500: Weighted 0.805715 (0.082131)\n",
      "0.05 5 2 5 log2 friedman_mse 0.75 500: Macro 0.692366 (0.120189)\n",
      "Testing 2217/5184\n",
      "0.05 5 2 5 log2 friedman_mse 1.0 50: Weighted 0.807415 (0.066764)\n",
      "0.05 5 2 5 log2 friedman_mse 1.0 50: Macro 0.702762 (0.090164)\n",
      "Testing 2218/5184\n",
      "0.05 5 2 5 log2 friedman_mse 1.0 100: Weighted 0.806954 (0.086624)\n",
      "0.05 5 2 5 log2 friedman_mse 1.0 100: Macro 0.710154 (0.116364)\n",
      "Testing 2219/5184\n",
      "0.05 5 2 5 log2 friedman_mse 1.0 200: Weighted 0.795321 (0.089433)\n",
      "0.05 5 2 5 log2 friedman_mse 1.0 200: Macro 0.691422 (0.130778)\n",
      "Testing 2220/5184\n",
      "0.05 5 2 5 log2 friedman_mse 1.0 500: Weighted 0.804764 (0.060361)\n",
      "0.05 5 2 5 log2 friedman_mse 1.0 500: Macro 0.705604 (0.086243)\n",
      "Testing 2221/5184\n",
      "0.05 5 2 5 log2 mae 0.5 50: Weighted 0.812525 (0.057328)\n",
      "0.05 5 2 5 log2 mae 0.5 50: Macro 0.704735 (0.075009)\n",
      "Testing 2222/5184\n",
      "0.05 5 2 5 log2 mae 0.5 100: Weighted 0.803815 (0.073836)\n",
      "0.05 5 2 5 log2 mae 0.5 100: Macro 0.688743 (0.103679)\n",
      "Testing 2223/5184\n",
      "0.05 5 2 5 log2 mae 0.5 200: Weighted 0.801711 (0.067777)\n",
      "0.05 5 2 5 log2 mae 0.5 200: Macro 0.686034 (0.093287)\n",
      "Testing 2224/5184\n",
      "0.05 5 2 5 log2 mae 0.5 500: Weighted 0.780817 (0.079877)\n",
      "0.05 5 2 5 log2 mae 0.5 500: Macro 0.663138 (0.103144)\n",
      "Testing 2225/5184\n",
      "0.05 5 2 5 log2 mae 0.75 50: Weighted 0.796597 (0.079472)\n",
      "0.05 5 2 5 log2 mae 0.75 50: Macro 0.680845 (0.105751)\n",
      "Testing 2226/5184\n",
      "0.05 5 2 5 log2 mae 0.75 100: Weighted 0.778632 (0.072249)\n",
      "0.05 5 2 5 log2 mae 0.75 100: Macro 0.646345 (0.105354)\n",
      "Testing 2227/5184\n",
      "0.05 5 2 5 log2 mae 0.75 200: Weighted 0.768372 (0.079261)\n",
      "0.05 5 2 5 log2 mae 0.75 200: Macro 0.630309 (0.110453)\n",
      "Testing 2228/5184\n",
      "0.05 5 2 5 log2 mae 0.75 500: Weighted 0.794085 (0.101269)\n",
      "0.05 5 2 5 log2 mae 0.75 500: Macro 0.670577 (0.148495)\n",
      "Testing 2229/5184\n",
      "0.05 5 2 5 log2 mae 1.0 50: Weighted 0.790060 (0.072013)\n",
      "0.05 5 2 5 log2 mae 1.0 50: Macro 0.664242 (0.104769)\n",
      "Testing 2230/5184\n",
      "0.05 5 2 5 log2 mae 1.0 100: Weighted 0.779764 (0.079432)\n",
      "0.05 5 2 5 log2 mae 1.0 100: Macro 0.649452 (0.114695)\n",
      "Testing 2231/5184\n",
      "0.05 5 2 5 log2 mae 1.0 200: Weighted 0.783095 (0.093276)\n",
      "0.05 5 2 5 log2 mae 1.0 200: Macro 0.655646 (0.129962)\n",
      "Testing 2232/5184\n",
      "0.05 5 2 5 log2 mae 1.0 500: Weighted 0.774048 (0.092637)\n",
      "0.05 5 2 5 log2 mae 1.0 500: Macro 0.640573 (0.124917)\n",
      "Testing 2233/5184\n",
      "0.05 5 2 5 sqrt friedman_mse 0.5 50: Weighted 0.835707 (0.072789)\n",
      "0.05 5 2 5 sqrt friedman_mse 0.5 50: Macro 0.743308 (0.101188)\n",
      "Testing 2234/5184\n",
      "0.05 5 2 5 sqrt friedman_mse 0.5 100: Weighted 0.831808 (0.074503)\n",
      "0.05 5 2 5 sqrt friedman_mse 0.5 100: Macro 0.733183 (0.108877)\n",
      "Testing 2235/5184\n",
      "0.05 5 2 5 sqrt friedman_mse 0.5 200: Weighted 0.823169 (0.077959)\n",
      "0.05 5 2 5 sqrt friedman_mse 0.5 200: Macro 0.723164 (0.113246)\n",
      "Testing 2236/5184\n",
      "0.05 5 2 5 sqrt friedman_mse 0.5 500: Weighted 0.815929 (0.069298)\n",
      "0.05 5 2 5 sqrt friedman_mse 0.5 500: Macro 0.725568 (0.098111)\n",
      "Testing 2237/5184\n",
      "0.05 5 2 5 sqrt friedman_mse 0.75 50: Weighted 0.805660 (0.056953)\n",
      "0.05 5 2 5 sqrt friedman_mse 0.75 50: Macro 0.695640 (0.080735)\n",
      "Testing 2238/5184\n",
      "0.05 5 2 5 sqrt friedman_mse 0.75 100: Weighted 0.816309 (0.069326)\n",
      "0.05 5 2 5 sqrt friedman_mse 0.75 100: Macro 0.714884 (0.090814)\n",
      "Testing 2239/5184\n",
      "0.05 5 2 5 sqrt friedman_mse 0.75 200: Weighted 0.822140 (0.063527)\n",
      "0.05 5 2 5 sqrt friedman_mse 0.75 200: Macro 0.724679 (0.093047)\n",
      "Testing 2240/5184\n",
      "0.05 5 2 5 sqrt friedman_mse 0.75 500: Weighted 0.823202 (0.080617)\n",
      "0.05 5 2 5 sqrt friedman_mse 0.75 500: Macro 0.732080 (0.121732)\n",
      "Testing 2241/5184\n",
      "0.05 5 2 5 sqrt friedman_mse 1.0 50: Weighted 0.794694 (0.075566)\n",
      "0.05 5 2 5 sqrt friedman_mse 1.0 50: Macro 0.686715 (0.099269)\n",
      "Testing 2242/5184\n",
      "0.05 5 2 5 sqrt friedman_mse 1.0 100: Weighted 0.808480 (0.080446)\n",
      "0.05 5 2 5 sqrt friedman_mse 1.0 100: Macro 0.708714 (0.109346)\n",
      "Testing 2243/5184\n",
      "0.05 5 2 5 sqrt friedman_mse 1.0 200: Weighted 0.801819 (0.084319)\n",
      "0.05 5 2 5 sqrt friedman_mse 1.0 200: Macro 0.696911 (0.131332)\n",
      "Testing 2244/5184\n",
      "0.05 5 2 5 sqrt friedman_mse 1.0 500: Weighted 0.798059 (0.059142)\n",
      "0.05 5 2 5 sqrt friedman_mse 1.0 500: Macro 0.692928 (0.078278)\n",
      "Testing 2245/5184\n",
      "0.05 5 2 5 sqrt mae 0.5 50: Weighted 0.808010 (0.059806)\n",
      "0.05 5 2 5 sqrt mae 0.5 50: Macro 0.692346 (0.081894)\n",
      "Testing 2246/5184\n",
      "0.05 5 2 5 sqrt mae 0.5 100: Weighted 0.806979 (0.052389)\n",
      "0.05 5 2 5 sqrt mae 0.5 100: Macro 0.685840 (0.078513)\n",
      "Testing 2247/5184\n",
      "0.05 5 2 5 sqrt mae 0.5 200: Weighted 0.800958 (0.067441)\n",
      "0.05 5 2 5 sqrt mae 0.5 200: Macro 0.692929 (0.089098)\n",
      "Testing 2248/5184\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05 5 2 5 sqrt mae 0.5 500: Weighted 0.792786 (0.080602)\n",
      "0.05 5 2 5 sqrt mae 0.5 500: Macro 0.675083 (0.109456)\n",
      "Testing 2249/5184\n",
      "0.05 5 2 5 sqrt mae 0.75 50: Weighted 0.778101 (0.072837)\n",
      "0.05 5 2 5 sqrt mae 0.75 50: Macro 0.648342 (0.103109)\n",
      "Testing 2250/5184\n",
      "0.05 5 2 5 sqrt mae 0.75 100: Weighted 0.780460 (0.070442)\n",
      "0.05 5 2 5 sqrt mae 0.75 100: Macro 0.644800 (0.106380)\n",
      "Testing 2251/5184\n",
      "0.05 5 2 5 sqrt mae 0.75 200: Weighted 0.773074 (0.066381)\n",
      "0.05 5 2 5 sqrt mae 0.75 200: Macro 0.631929 (0.092398)\n",
      "Testing 2252/5184\n",
      "0.05 5 2 5 sqrt mae 0.75 500: Weighted 0.767673 (0.088414)\n",
      "0.05 5 2 5 sqrt mae 0.75 500: Macro 0.633982 (0.110477)\n",
      "Testing 2253/5184\n",
      "0.05 5 2 5 sqrt mae 1.0 50: Weighted 0.789784 (0.080000)\n",
      "0.05 5 2 5 sqrt mae 1.0 50: Macro 0.659541 (0.119567)\n",
      "Testing 2254/5184\n",
      "0.05 5 2 5 sqrt mae 1.0 100: Weighted 0.784116 (0.086817)\n",
      "0.05 5 2 5 sqrt mae 1.0 100: Macro 0.654649 (0.125050)\n",
      "Testing 2255/5184\n",
      "0.05 5 2 5 sqrt mae 1.0 200: Weighted 0.784461 (0.102704)\n",
      "0.05 5 2 5 sqrt mae 1.0 200: Macro 0.661704 (0.145676)\n",
      "Testing 2256/5184\n",
      "0.05 5 2 5 sqrt mae 1.0 500: Weighted 0.777443 (0.094874)\n",
      "0.05 5 2 5 sqrt mae 1.0 500: Macro 0.642899 (0.125810)\n",
      "Testing 2257/5184\n",
      "0.05 5 2 8 log2 friedman_mse 0.5 50: Weighted 0.828733 (0.052896)\n",
      "0.05 5 2 8 log2 friedman_mse 0.5 50: Macro 0.725448 (0.072769)\n",
      "Testing 2258/5184\n",
      "0.05 5 2 8 log2 friedman_mse 0.5 100: Weighted 0.811052 (0.049153)\n",
      "0.05 5 2 8 log2 friedman_mse 0.5 100: Macro 0.700829 (0.066752)\n",
      "Testing 2259/5184\n",
      "0.05 5 2 8 log2 friedman_mse 0.5 200: Weighted 0.837986 (0.071270)\n",
      "0.05 5 2 8 log2 friedman_mse 0.5 200: Macro 0.741831 (0.101703)\n",
      "Testing 2260/5184\n",
      "0.05 5 2 8 log2 friedman_mse 0.5 500: Weighted 0.811611 (0.071741)\n",
      "0.05 5 2 8 log2 friedman_mse 0.5 500: Macro 0.710579 (0.113885)\n",
      "Testing 2261/5184\n",
      "0.05 5 2 8 log2 friedman_mse 0.75 50: Weighted 0.821798 (0.055172)\n",
      "0.05 5 2 8 log2 friedman_mse 0.75 50: Macro 0.722010 (0.073180)\n",
      "Testing 2262/5184\n",
      "0.05 5 2 8 log2 friedman_mse 0.75 100: Weighted 0.829761 (0.074284)\n",
      "0.05 5 2 8 log2 friedman_mse 0.75 100: Macro 0.738161 (0.097979)\n",
      "Testing 2263/5184\n",
      "0.05 5 2 8 log2 friedman_mse 0.75 200: Weighted 0.827971 (0.082186)\n",
      "0.05 5 2 8 log2 friedman_mse 0.75 200: Macro 0.729407 (0.116784)\n",
      "Testing 2264/5184\n",
      "0.05 5 2 8 log2 friedman_mse 0.75 500: Weighted 0.814404 (0.069732)\n",
      "0.05 5 2 8 log2 friedman_mse 0.75 500: Macro 0.711807 (0.099231)\n",
      "Testing 2265/5184\n",
      "0.05 5 2 8 log2 friedman_mse 1.0 50: Weighted 0.802253 (0.057602)\n",
      "0.05 5 2 8 log2 friedman_mse 1.0 50: Macro 0.700184 (0.067365)\n",
      "Testing 2266/5184\n",
      "0.05 5 2 8 log2 friedman_mse 1.0 100: Weighted 0.809574 (0.102714)\n",
      "0.05 5 2 8 log2 friedman_mse 1.0 100: Macro 0.709628 (0.149135)\n",
      "Testing 2267/5184\n",
      "0.05 5 2 8 log2 friedman_mse 1.0 200: Weighted 0.787554 (0.099754)\n",
      "0.05 5 2 8 log2 friedman_mse 1.0 200: Macro 0.676346 (0.147597)\n",
      "Testing 2268/5184\n",
      "0.05 5 2 8 log2 friedman_mse 1.0 500: Weighted 0.786043 (0.088530)\n",
      "0.05 5 2 8 log2 friedman_mse 1.0 500: Macro 0.683805 (0.147466)\n",
      "Testing 2269/5184\n",
      "0.05 5 2 8 log2 mae 0.5 50: Weighted 0.819406 (0.058127)\n",
      "0.05 5 2 8 log2 mae 0.5 50: Macro 0.712098 (0.082225)\n",
      "Testing 2270/5184\n",
      "0.05 5 2 8 log2 mae 0.5 100: Weighted 0.801794 (0.068310)\n",
      "0.05 5 2 8 log2 mae 0.5 100: Macro 0.691471 (0.089413)\n",
      "Testing 2271/5184\n",
      "0.05 5 2 8 log2 mae 0.5 200: Weighted 0.799136 (0.070470)\n",
      "0.05 5 2 8 log2 mae 0.5 200: Macro 0.681385 (0.097777)\n",
      "Testing 2272/5184\n",
      "0.05 5 2 8 log2 mae 0.5 500: Weighted 0.793978 (0.074670)\n",
      "0.05 5 2 8 log2 mae 0.5 500: Macro 0.679588 (0.095339)\n",
      "Testing 2273/5184\n",
      "0.05 5 2 8 log2 mae 0.75 50: Weighted 0.798308 (0.068192)\n",
      "0.05 5 2 8 log2 mae 0.75 50: Macro 0.671890 (0.102431)\n",
      "Testing 2274/5184\n",
      "0.05 5 2 8 log2 mae 0.75 100: Weighted 0.788677 (0.072436)\n",
      "0.05 5 2 8 log2 mae 0.75 100: Macro 0.654882 (0.107179)\n",
      "Testing 2275/5184\n",
      "0.05 5 2 8 log2 mae 0.75 200: Weighted 0.789043 (0.090878)\n",
      "0.05 5 2 8 log2 mae 0.75 200: Macro 0.675132 (0.115118)\n",
      "Testing 2276/5184\n",
      "0.05 5 2 8 log2 mae 0.75 500: Weighted 0.789038 (0.087239)\n",
      "0.05 5 2 8 log2 mae 0.75 500: Macro 0.665221 (0.126154)\n",
      "Testing 2277/5184\n",
      "0.05 5 2 8 log2 mae 1.0 50: Weighted 0.769410 (0.073655)\n",
      "0.05 5 2 8 log2 mae 1.0 50: Macro 0.631806 (0.108992)\n",
      "Testing 2278/5184\n",
      "0.05 5 2 8 log2 mae 1.0 100: Weighted 0.772167 (0.074332)\n",
      "0.05 5 2 8 log2 mae 1.0 100: Macro 0.626647 (0.112682)\n",
      "Testing 2279/5184\n",
      "0.05 5 2 8 log2 mae 1.0 200: Weighted 0.779291 (0.091375)\n",
      "0.05 5 2 8 log2 mae 1.0 200: Macro 0.643881 (0.136013)\n",
      "Testing 2280/5184\n",
      "0.05 5 2 8 log2 mae 1.0 500: Weighted 0.785992 (0.106191)\n",
      "0.05 5 2 8 log2 mae 1.0 500: Macro 0.654823 (0.159856)\n",
      "Testing 2281/5184\n",
      "0.05 5 2 8 sqrt friedman_mse 0.5 50: Weighted 0.806653 (0.060685)\n",
      "0.05 5 2 8 sqrt friedman_mse 0.5 50: Macro 0.693228 (0.084556)\n",
      "Testing 2282/5184\n",
      "0.05 5 2 8 sqrt friedman_mse 0.5 100: Weighted 0.821994 (0.067096)\n",
      "0.05 5 2 8 sqrt friedman_mse 0.5 100: Macro 0.713418 (0.097017)\n",
      "Testing 2283/5184\n",
      "0.05 5 2 8 sqrt friedman_mse 0.5 200: Weighted 0.822200 (0.073471)\n",
      "0.05 5 2 8 sqrt friedman_mse 0.5 200: Macro 0.722830 (0.115633)\n",
      "Testing 2284/5184\n",
      "0.05 5 2 8 sqrt friedman_mse 0.5 500: Weighted 0.817946 (0.084963)\n",
      "0.05 5 2 8 sqrt friedman_mse 0.5 500: Macro 0.719185 (0.137106)\n",
      "Testing 2285/5184\n",
      "0.05 5 2 8 sqrt friedman_mse 0.75 50: Weighted 0.829881 (0.060619)\n",
      "0.05 5 2 8 sqrt friedman_mse 0.75 50: Macro 0.735848 (0.076927)\n",
      "Testing 2286/5184\n",
      "0.05 5 2 8 sqrt friedman_mse 0.75 100: Weighted 0.825606 (0.081571)\n",
      "0.05 5 2 8 sqrt friedman_mse 0.75 100: Macro 0.733806 (0.114908)\n",
      "Testing 2287/5184\n",
      "0.05 5 2 8 sqrt friedman_mse 0.75 200: Weighted 0.836360 (0.073845)\n",
      "0.05 5 2 8 sqrt friedman_mse 0.75 200: Macro 0.738236 (0.111395)\n",
      "Testing 2288/5184\n",
      "0.05 5 2 8 sqrt friedman_mse 0.75 500: Weighted 0.809756 (0.086104)\n",
      "0.05 5 2 8 sqrt friedman_mse 0.75 500: Macro 0.711816 (0.138665)\n",
      "Testing 2289/5184\n",
      "0.05 5 2 8 sqrt friedman_mse 1.0 50: Weighted 0.808958 (0.060227)\n",
      "0.05 5 2 8 sqrt friedman_mse 1.0 50: Macro 0.701746 (0.082541)\n",
      "Testing 2290/5184\n",
      "0.05 5 2 8 sqrt friedman_mse 1.0 100: Weighted 0.809379 (0.084775)\n",
      "0.05 5 2 8 sqrt friedman_mse 1.0 100: Macro 0.715723 (0.113374)\n",
      "Testing 2291/5184\n",
      "0.05 5 2 8 sqrt friedman_mse 1.0 200: Weighted 0.807541 (0.106306)\n",
      "0.05 5 2 8 sqrt friedman_mse 1.0 200: Macro 0.712971 (0.158191)\n",
      "Testing 2292/5184\n",
      "0.05 5 2 8 sqrt friedman_mse 1.0 500: Weighted 0.795434 (0.088189)\n",
      "0.05 5 2 8 sqrt friedman_mse 1.0 500: Macro 0.695058 (0.132779)\n",
      "Testing 2293/5184\n",
      "0.05 5 2 8 sqrt mae 0.5 50: Weighted 0.796091 (0.071303)\n",
      "0.05 5 2 8 sqrt mae 0.5 50: Macro 0.672706 (0.099783)\n",
      "Testing 2294/5184\n",
      "0.05 5 2 8 sqrt mae 0.5 100: Weighted 0.810088 (0.072028)\n",
      "0.05 5 2 8 sqrt mae 0.5 100: Macro 0.690105 (0.109464)\n",
      "Testing 2295/5184\n",
      "0.05 5 2 8 sqrt mae 0.5 200: Weighted 0.779537 (0.072413)\n",
      "0.05 5 2 8 sqrt mae 0.5 200: Macro 0.644306 (0.109040)\n",
      "Testing 2296/5184\n",
      "0.05 5 2 8 sqrt mae 0.5 500: Weighted 0.790123 (0.071571)\n",
      "0.05 5 2 8 sqrt mae 0.5 500: Macro 0.669664 (0.093078)\n",
      "Testing 2297/5184\n",
      "0.05 5 2 8 sqrt mae 0.75 50: Weighted 0.804327 (0.069075)\n",
      "0.05 5 2 8 sqrt mae 0.75 50: Macro 0.684900 (0.099858)\n",
      "Testing 2298/5184\n",
      "0.05 5 2 8 sqrt mae 0.75 100: Weighted 0.780722 (0.073434)\n",
      "0.05 5 2 8 sqrt mae 0.75 100: Macro 0.645504 (0.106587)\n",
      "Testing 2299/5184\n",
      "0.05 5 2 8 sqrt mae 0.75 200: Weighted 0.788763 (0.082531)\n",
      "0.05 5 2 8 sqrt mae 0.75 200: Macro 0.658674 (0.119810)\n",
      "Testing 2300/5184\n",
      "0.05 5 2 8 sqrt mae 0.75 500: Weighted 0.792247 (0.102914)\n",
      "0.05 5 2 8 sqrt mae 0.75 500: Macro 0.670627 (0.148459)\n",
      "Testing 2301/5184\n",
      "0.05 5 2 8 sqrt mae 1.0 50: Weighted 0.791518 (0.060619)\n",
      "0.05 5 2 8 sqrt mae 1.0 50: Macro 0.657657 (0.094834)\n",
      "Testing 2302/5184\n",
      "0.05 5 2 8 sqrt mae 1.0 100: Weighted 0.778910 (0.079714)\n",
      "0.05 5 2 8 sqrt mae 1.0 100: Macro 0.637727 (0.120723)\n",
      "Testing 2303/5184\n",
      "0.05 5 2 8 sqrt mae 1.0 200: Weighted 0.787195 (0.090623)\n",
      "0.05 5 2 8 sqrt mae 1.0 200: Macro 0.651048 (0.137977)\n",
      "Testing 2304/5184\n",
      "0.05 5 2 8 sqrt mae 1.0 500: Weighted 0.785070 (0.096628)\n",
      "0.05 5 2 8 sqrt mae 1.0 500: Macro 0.656442 (0.141258)\n",
      "Testing 2305/5184\n",
      "0.05 5 4 3 log2 friedman_mse 0.5 50: Weighted 0.820887 (0.062309)\n",
      "0.05 5 4 3 log2 friedman_mse 0.5 50: Macro 0.717404 (0.084046)\n",
      "Testing 2306/5184\n",
      "0.05 5 4 3 log2 friedman_mse 0.5 100: Weighted 0.816986 (0.072059)\n",
      "0.05 5 4 3 log2 friedman_mse 0.5 100: Macro 0.714349 (0.096401)\n",
      "Testing 2307/5184\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05 5 4 3 log2 friedman_mse 0.5 200: Weighted 0.826586 (0.056242)\n",
      "0.05 5 4 3 log2 friedman_mse 0.5 200: Macro 0.730369 (0.080705)\n",
      "Testing 2308/5184\n",
      "0.05 5 4 3 log2 friedman_mse 0.5 500: Weighted 0.814004 (0.053293)\n",
      "0.05 5 4 3 log2 friedman_mse 0.5 500: Macro 0.712112 (0.075112)\n",
      "Testing 2309/5184\n",
      "0.05 5 4 3 log2 friedman_mse 0.75 50: Weighted 0.802338 (0.060525)\n",
      "0.05 5 4 3 log2 friedman_mse 0.75 50: Macro 0.688671 (0.079970)\n",
      "Testing 2310/5184\n",
      "0.05 5 4 3 log2 friedman_mse 0.75 100: Weighted 0.811476 (0.065672)\n",
      "0.05 5 4 3 log2 friedman_mse 0.75 100: Macro 0.703254 (0.080217)\n",
      "Testing 2311/5184\n",
      "0.05 5 4 3 log2 friedman_mse 0.75 200: Weighted 0.813226 (0.063610)\n",
      "0.05 5 4 3 log2 friedman_mse 0.75 200: Macro 0.715616 (0.083696)\n",
      "Testing 2312/5184\n",
      "0.05 5 4 3 log2 friedman_mse 0.75 500: Weighted 0.802681 (0.053080)\n",
      "0.05 5 4 3 log2 friedman_mse 0.75 500: Macro 0.697103 (0.076554)\n",
      "Testing 2313/5184\n",
      "0.05 5 4 3 log2 friedman_mse 1.0 50: Weighted 0.796693 (0.053270)\n",
      "0.05 5 4 3 log2 friedman_mse 1.0 50: Macro 0.686643 (0.065157)\n",
      "Testing 2314/5184\n",
      "0.05 5 4 3 log2 friedman_mse 1.0 100: Weighted 0.809017 (0.076972)\n",
      "0.05 5 4 3 log2 friedman_mse 1.0 100: Macro 0.710794 (0.098517)\n",
      "Testing 2315/5184\n",
      "0.05 5 4 3 log2 friedman_mse 1.0 200: Weighted 0.824586 (0.077131)\n",
      "0.05 5 4 3 log2 friedman_mse 1.0 200: Macro 0.732224 (0.100239)\n",
      "Testing 2316/5184\n",
      "0.05 5 4 3 log2 friedman_mse 1.0 500: Weighted 0.801426 (0.066031)\n",
      "0.05 5 4 3 log2 friedman_mse 1.0 500: Macro 0.691657 (0.091137)\n",
      "Testing 2317/5184\n",
      "0.05 5 4 3 log2 mae 0.5 50: Weighted 0.809912 (0.069018)\n",
      "0.05 5 4 3 log2 mae 0.5 50: Macro 0.697559 (0.097785)\n",
      "Testing 2318/5184\n",
      "0.05 5 4 3 log2 mae 0.5 100: Weighted 0.809904 (0.077801)\n",
      "0.05 5 4 3 log2 mae 0.5 100: Macro 0.694615 (0.113242)\n",
      "Testing 2319/5184\n",
      "0.05 5 4 3 log2 mae 0.5 200: Weighted 0.798161 (0.060415)\n",
      "0.05 5 4 3 log2 mae 0.5 200: Macro 0.676875 (0.086057)\n",
      "Testing 2320/5184\n",
      "0.05 5 4 3 log2 mae 0.5 500: Weighted 0.788556 (0.079371)\n",
      "0.05 5 4 3 log2 mae 0.5 500: Macro 0.663049 (0.111214)\n",
      "Testing 2321/5184\n",
      "0.05 5 4 3 log2 mae 0.75 50: Weighted 0.798149 (0.067984)\n",
      "0.05 5 4 3 log2 mae 0.75 50: Macro 0.679707 (0.093380)\n",
      "Testing 2322/5184\n",
      "0.05 5 4 3 log2 mae 0.75 100: Weighted 0.799829 (0.072077)\n",
      "0.05 5 4 3 log2 mae 0.75 100: Macro 0.681523 (0.099779)\n",
      "Testing 2323/5184\n",
      "0.05 5 4 3 log2 mae 0.75 200: Weighted 0.786044 (0.073413)\n",
      "0.05 5 4 3 log2 mae 0.75 200: Macro 0.658509 (0.108643)\n",
      "Testing 2324/5184\n",
      "0.05 5 4 3 log2 mae 0.75 500: Weighted 0.768159 (0.058749)\n",
      "0.05 5 4 3 log2 mae 0.75 500: Macro 0.623427 (0.085639)\n",
      "Testing 2325/5184\n",
      "0.05 5 4 3 log2 mae 1.0 50: Weighted 0.791906 (0.067009)\n",
      "0.05 5 4 3 log2 mae 1.0 50: Macro 0.671301 (0.094600)\n",
      "Testing 2326/5184\n",
      "0.05 5 4 3 log2 mae 1.0 100: Weighted 0.790319 (0.080607)\n",
      "0.05 5 4 3 log2 mae 1.0 100: Macro 0.660910 (0.121030)\n",
      "Testing 2327/5184\n",
      "0.05 5 4 3 log2 mae 1.0 200: Weighted 0.766856 (0.069461)\n",
      "0.05 5 4 3 log2 mae 1.0 200: Macro 0.623013 (0.099471)\n",
      "Testing 2328/5184\n",
      "0.05 5 4 3 log2 mae 1.0 500: Weighted 0.774398 (0.058768)\n",
      "0.05 5 4 3 log2 mae 1.0 500: Macro 0.633146 (0.086834)\n",
      "Testing 2329/5184\n",
      "0.05 5 4 3 sqrt friedman_mse 0.5 50: Weighted 0.828759 (0.078398)\n",
      "0.05 5 4 3 sqrt friedman_mse 0.5 50: Macro 0.734738 (0.106827)\n",
      "Testing 2330/5184\n",
      "0.05 5 4 3 sqrt friedman_mse 0.5 100: Weighted 0.813143 (0.066272)\n",
      "0.05 5 4 3 sqrt friedman_mse 0.5 100: Macro 0.706449 (0.082307)\n",
      "Testing 2331/5184\n",
      "0.05 5 4 3 sqrt friedman_mse 0.5 200: Weighted 0.805032 (0.069112)\n",
      "0.05 5 4 3 sqrt friedman_mse 0.5 200: Macro 0.694671 (0.103973)\n",
      "Testing 2332/5184\n",
      "0.05 5 4 3 sqrt friedman_mse 0.5 500: Weighted 0.813329 (0.053086)\n",
      "0.05 5 4 3 sqrt friedman_mse 0.5 500: Macro 0.706368 (0.085241)\n",
      "Testing 2333/5184\n",
      "0.05 5 4 3 sqrt friedman_mse 0.75 50: Weighted 0.810869 (0.059622)\n",
      "0.05 5 4 3 sqrt friedman_mse 0.75 50: Macro 0.705520 (0.074278)\n",
      "Testing 2334/5184\n",
      "0.05 5 4 3 sqrt friedman_mse 0.75 100: Weighted 0.809197 (0.073152)\n",
      "0.05 5 4 3 sqrt friedman_mse 0.75 100: Macro 0.702739 (0.093857)\n",
      "Testing 2335/5184\n",
      "0.05 5 4 3 sqrt friedman_mse 0.75 200: Weighted 0.807480 (0.077282)\n",
      "0.05 5 4 3 sqrt friedman_mse 0.75 200: Macro 0.708576 (0.108267)\n",
      "Testing 2336/5184\n",
      "0.05 5 4 3 sqrt friedman_mse 0.75 500: Weighted 0.805751 (0.061438)\n",
      "0.05 5 4 3 sqrt friedman_mse 0.75 500: Macro 0.700951 (0.096710)\n",
      "Testing 2337/5184\n",
      "0.05 5 4 3 sqrt friedman_mse 1.0 50: Weighted 0.802610 (0.054643)\n",
      "0.05 5 4 3 sqrt friedman_mse 1.0 50: Macro 0.693054 (0.067414)\n",
      "Testing 2338/5184\n",
      "0.05 5 4 3 sqrt friedman_mse 1.0 100: Weighted 0.802052 (0.070144)\n",
      "0.05 5 4 3 sqrt friedman_mse 1.0 100: Macro 0.701024 (0.084847)\n",
      "Testing 2339/5184\n",
      "0.05 5 4 3 sqrt friedman_mse 1.0 200: Weighted 0.829771 (0.076194)\n",
      "0.05 5 4 3 sqrt friedman_mse 1.0 200: Macro 0.740573 (0.100491)\n",
      "Testing 2340/5184\n",
      "0.05 5 4 3 sqrt friedman_mse 1.0 500: Weighted 0.801846 (0.058955)\n",
      "0.05 5 4 3 sqrt friedman_mse 1.0 500: Macro 0.699299 (0.081108)\n",
      "Testing 2341/5184\n",
      "0.05 5 4 3 sqrt mae 0.5 50: Weighted 0.828706 (0.043428)\n",
      "0.05 5 4 3 sqrt mae 0.5 50: Macro 0.723249 (0.060337)\n",
      "Testing 2342/5184\n",
      "0.05 5 4 3 sqrt mae 0.5 100: Weighted 0.807493 (0.045217)\n",
      "0.05 5 4 3 sqrt mae 0.5 100: Macro 0.687965 (0.067458)\n",
      "Testing 2343/5184\n",
      "0.05 5 4 3 sqrt mae 0.5 200: Weighted 0.802402 (0.067210)\n",
      "0.05 5 4 3 sqrt mae 0.5 200: Macro 0.685027 (0.094883)\n",
      "Testing 2344/5184\n",
      "0.05 5 4 3 sqrt mae 0.5 500: Weighted 0.786753 (0.078757)\n",
      "0.05 5 4 3 sqrt mae 0.5 500: Macro 0.665392 (0.099590)\n",
      "Testing 2345/5184\n",
      "0.05 5 4 3 sqrt mae 0.75 50: Weighted 0.799542 (0.076952)\n",
      "0.05 5 4 3 sqrt mae 0.75 50: Macro 0.686676 (0.101932)\n",
      "Testing 2346/5184\n",
      "0.05 5 4 3 sqrt mae 0.75 100: Weighted 0.796208 (0.074131)\n",
      "0.05 5 4 3 sqrt mae 0.75 100: Macro 0.677954 (0.103705)\n",
      "Testing 2347/5184\n",
      "0.05 5 4 3 sqrt mae 0.75 200: Weighted 0.772578 (0.066904)\n",
      "0.05 5 4 3 sqrt mae 0.75 200: Macro 0.645496 (0.094990)\n",
      "Testing 2348/5184\n",
      "0.05 5 4 3 sqrt mae 0.75 500: Weighted 0.777201 (0.070260)\n",
      "0.05 5 4 3 sqrt mae 0.75 500: Macro 0.634672 (0.095283)\n",
      "Testing 2349/5184\n",
      "0.05 5 4 3 sqrt mae 1.0 50: Weighted 0.791688 (0.068568)\n",
      "0.05 5 4 3 sqrt mae 1.0 50: Macro 0.671143 (0.095826)\n",
      "Testing 2350/5184\n",
      "0.05 5 4 3 sqrt mae 1.0 100: Weighted 0.796654 (0.083214)\n",
      "0.05 5 4 3 sqrt mae 1.0 100: Macro 0.674252 (0.121531)\n",
      "Testing 2351/5184\n",
      "0.05 5 4 3 sqrt mae 1.0 200: Weighted 0.762849 (0.068469)\n",
      "0.05 5 4 3 sqrt mae 1.0 200: Macro 0.620067 (0.099390)\n",
      "Testing 2352/5184\n",
      "0.05 5 4 3 sqrt mae 1.0 500: Weighted 0.764120 (0.066932)\n",
      "0.05 5 4 3 sqrt mae 1.0 500: Macro 0.621380 (0.093054)\n",
      "Testing 2353/5184\n",
      "0.05 5 4 5 log2 friedman_mse 0.5 50: Weighted 0.825447 (0.068658)\n",
      "0.05 5 4 5 log2 friedman_mse 0.5 50: Macro 0.723704 (0.093886)\n",
      "Testing 2354/5184\n",
      "0.05 5 4 5 log2 friedman_mse 0.5 100: Weighted 0.815881 (0.080396)\n",
      "0.05 5 4 5 log2 friedman_mse 0.5 100: Macro 0.708577 (0.114768)\n",
      "Testing 2355/5184\n",
      "0.05 5 4 5 log2 friedman_mse 0.5 200: Weighted 0.820009 (0.081985)\n",
      "0.05 5 4 5 log2 friedman_mse 0.5 200: Macro 0.726697 (0.117728)\n",
      "Testing 2356/5184\n",
      "0.05 5 4 5 log2 friedman_mse 0.5 500: Weighted 0.807621 (0.060833)\n",
      "0.05 5 4 5 log2 friedman_mse 0.5 500: Macro 0.708367 (0.087235)\n",
      "Testing 2357/5184\n",
      "0.05 5 4 5 log2 friedman_mse 0.75 50: Weighted 0.801940 (0.062378)\n",
      "0.05 5 4 5 log2 friedman_mse 0.75 50: Macro 0.691014 (0.086963)\n",
      "Testing 2358/5184\n",
      "0.05 5 4 5 log2 friedman_mse 0.75 100: Weighted 0.799389 (0.077697)\n",
      "0.05 5 4 5 log2 friedman_mse 0.75 100: Macro 0.696873 (0.106451)\n",
      "Testing 2359/5184\n",
      "0.05 5 4 5 log2 friedman_mse 0.75 200: Weighted 0.823242 (0.070929)\n",
      "0.05 5 4 5 log2 friedman_mse 0.75 200: Macro 0.718839 (0.102037)\n",
      "Testing 2360/5184\n",
      "0.05 5 4 5 log2 friedman_mse 0.75 500: Weighted 0.807057 (0.070277)\n",
      "0.05 5 4 5 log2 friedman_mse 0.75 500: Macro 0.690351 (0.103535)\n",
      "Testing 2361/5184\n",
      "0.05 5 4 5 log2 friedman_mse 1.0 50: Weighted 0.803709 (0.059298)\n",
      "0.05 5 4 5 log2 friedman_mse 1.0 50: Macro 0.695468 (0.080963)\n",
      "Testing 2362/5184\n",
      "0.05 5 4 5 log2 friedman_mse 1.0 100: Weighted 0.798044 (0.084059)\n",
      "0.05 5 4 5 log2 friedman_mse 1.0 100: Macro 0.692372 (0.114199)\n",
      "Testing 2363/5184\n",
      "0.05 5 4 5 log2 friedman_mse 1.0 200: Weighted 0.802155 (0.084545)\n",
      "0.05 5 4 5 log2 friedman_mse 1.0 200: Macro 0.694118 (0.129043)\n",
      "Testing 2364/5184\n",
      "0.05 5 4 5 log2 friedman_mse 1.0 500: Weighted 0.805408 (0.069342)\n",
      "0.05 5 4 5 log2 friedman_mse 1.0 500: Macro 0.710019 (0.097312)\n",
      "Testing 2365/5184\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05 5 4 5 log2 mae 0.5 50: Weighted 0.805531 (0.067996)\n",
      "0.05 5 4 5 log2 mae 0.5 50: Macro 0.688332 (0.097397)\n",
      "Testing 2366/5184\n",
      "0.05 5 4 5 log2 mae 0.5 100: Weighted 0.804397 (0.073309)\n",
      "0.05 5 4 5 log2 mae 0.5 100: Macro 0.687245 (0.105542)\n",
      "Testing 2367/5184\n",
      "0.05 5 4 5 log2 mae 0.5 200: Weighted 0.801211 (0.068831)\n",
      "0.05 5 4 5 log2 mae 0.5 200: Macro 0.679438 (0.104079)\n",
      "Testing 2368/5184\n",
      "0.05 5 4 5 log2 mae 0.5 500: Weighted 0.788665 (0.079620)\n",
      "0.05 5 4 5 log2 mae 0.5 500: Macro 0.665872 (0.107042)\n",
      "Testing 2369/5184\n",
      "0.05 5 4 5 log2 mae 0.75 50: Weighted 0.787696 (0.063118)\n",
      "0.05 5 4 5 log2 mae 0.75 50: Macro 0.662636 (0.090358)\n",
      "Testing 2370/5184\n",
      "0.05 5 4 5 log2 mae 0.75 100: Weighted 0.788241 (0.080923)\n",
      "0.05 5 4 5 log2 mae 0.75 100: Macro 0.662182 (0.117384)\n",
      "Testing 2371/5184\n",
      "0.05 5 4 5 log2 mae 0.75 200: Weighted 0.784417 (0.093871)\n",
      "0.05 5 4 5 log2 mae 0.75 200: Macro 0.657975 (0.135010)\n",
      "Testing 2372/5184\n",
      "0.05 5 4 5 log2 mae 0.75 500: Weighted 0.778009 (0.089496)\n",
      "0.05 5 4 5 log2 mae 0.75 500: Macro 0.649314 (0.125758)\n",
      "Testing 2373/5184\n",
      "0.05 5 4 5 log2 mae 1.0 50: Weighted 0.779720 (0.064877)\n",
      "0.05 5 4 5 log2 mae 1.0 50: Macro 0.640309 (0.093413)\n",
      "Testing 2374/5184\n",
      "0.05 5 4 5 log2 mae 1.0 100: Weighted 0.784203 (0.093131)\n",
      "0.05 5 4 5 log2 mae 1.0 100: Macro 0.656165 (0.136189)\n",
      "Testing 2375/5184\n",
      "0.05 5 4 5 log2 mae 1.0 200: Weighted 0.785201 (0.091151)\n",
      "0.05 5 4 5 log2 mae 1.0 200: Macro 0.656373 (0.129217)\n",
      "Testing 2376/5184\n",
      "0.05 5 4 5 log2 mae 1.0 500: Weighted 0.783877 (0.090543)\n",
      "0.05 5 4 5 log2 mae 1.0 500: Macro 0.657863 (0.120782)\n",
      "Testing 2377/5184\n",
      "0.05 5 4 5 sqrt friedman_mse 0.5 50: Weighted 0.825724 (0.075928)\n",
      "0.05 5 4 5 sqrt friedman_mse 0.5 50: Macro 0.722630 (0.109985)\n",
      "Testing 2378/5184\n",
      "0.05 5 4 5 sqrt friedman_mse 0.5 100: Weighted 0.817577 (0.076321)\n",
      "0.05 5 4 5 sqrt friedman_mse 0.5 100: Macro 0.709163 (0.109051)\n",
      "Testing 2379/5184\n",
      "0.05 5 4 5 sqrt friedman_mse 0.5 200: Weighted 0.827254 (0.070293)\n",
      "0.05 5 4 5 sqrt friedman_mse 0.5 200: Macro 0.729372 (0.104388)\n",
      "Testing 2380/5184\n",
      "0.05 5 4 5 sqrt friedman_mse 0.5 500: Weighted 0.827577 (0.057049)\n",
      "0.05 5 4 5 sqrt friedman_mse 0.5 500: Macro 0.736936 (0.080783)\n",
      "Testing 2381/5184\n",
      "0.05 5 4 5 sqrt friedman_mse 0.75 50: Weighted 0.810680 (0.054943)\n",
      "0.05 5 4 5 sqrt friedman_mse 0.75 50: Macro 0.703494 (0.071577)\n",
      "Testing 2382/5184\n",
      "0.05 5 4 5 sqrt friedman_mse 0.75 100: Weighted 0.809486 (0.079712)\n",
      "0.05 5 4 5 sqrt friedman_mse 0.75 100: Macro 0.701070 (0.114990)\n",
      "Testing 2383/5184\n",
      "0.05 5 4 5 sqrt friedman_mse 0.75 200: Weighted 0.821311 (0.085962)\n",
      "0.05 5 4 5 sqrt friedman_mse 0.75 200: Macro 0.721274 (0.125657)\n",
      "Testing 2384/5184\n",
      "0.05 5 4 5 sqrt friedman_mse 0.75 500: Weighted 0.822845 (0.061477)\n",
      "0.05 5 4 5 sqrt friedman_mse 0.75 500: Macro 0.724833 (0.087441)\n",
      "Testing 2385/5184\n",
      "0.05 5 4 5 sqrt friedman_mse 1.0 50: Weighted 0.804127 (0.064334)\n",
      "0.05 5 4 5 sqrt friedman_mse 1.0 50: Macro 0.699739 (0.087618)\n",
      "Testing 2386/5184\n",
      "0.05 5 4 5 sqrt friedman_mse 1.0 100: Weighted 0.805437 (0.073225)\n",
      "0.05 5 4 5 sqrt friedman_mse 1.0 100: Macro 0.707367 (0.094170)\n",
      "Testing 2387/5184\n",
      "0.05 5 4 5 sqrt friedman_mse 1.0 200: Weighted 0.807347 (0.076531)\n",
      "0.05 5 4 5 sqrt friedman_mse 1.0 200: Macro 0.704597 (0.113950)\n",
      "Testing 2388/5184\n",
      "0.05 5 4 5 sqrt friedman_mse 1.0 500: Weighted 0.809497 (0.074025)\n",
      "0.05 5 4 5 sqrt friedman_mse 1.0 500: Macro 0.712922 (0.114690)\n",
      "Testing 2389/5184\n",
      "0.05 5 4 5 sqrt mae 0.5 50: Weighted 0.817139 (0.053224)\n",
      "0.05 5 4 5 sqrt mae 0.5 50: Macro 0.702906 (0.077322)\n",
      "Testing 2390/5184\n",
      "0.05 5 4 5 sqrt mae 0.5 100: Weighted 0.803346 (0.055926)\n",
      "0.05 5 4 5 sqrt mae 0.5 100: Macro 0.688636 (0.078187)\n",
      "Testing 2391/5184\n",
      "0.05 5 4 5 sqrt mae 0.5 200: Weighted 0.798216 (0.060696)\n",
      "0.05 5 4 5 sqrt mae 0.5 200: Macro 0.680886 (0.078732)\n",
      "Testing 2392/5184\n",
      "0.05 5 4 5 sqrt mae 0.5 500: Weighted 0.786373 (0.083006)\n",
      "0.05 5 4 5 sqrt mae 0.5 500: Macro 0.668072 (0.106047)\n",
      "Testing 2393/5184\n",
      "0.05 5 4 5 sqrt mae 0.75 50: Weighted 0.791854 (0.078021)\n",
      "0.05 5 4 5 sqrt mae 0.75 50: Macro 0.672137 (0.107169)\n",
      "Testing 2394/5184\n",
      "0.05 5 4 5 sqrt mae 0.75 100: Weighted 0.777018 (0.063645)\n",
      "0.05 5 4 5 sqrt mae 0.75 100: Macro 0.642517 (0.088228)\n",
      "Testing 2395/5184\n",
      "0.05 5 4 5 sqrt mae 0.75 200: Weighted 0.776547 (0.073168)\n",
      "0.05 5 4 5 sqrt mae 0.75 200: Macro 0.641868 (0.105347)\n",
      "Testing 2396/5184\n",
      "0.05 5 4 5 sqrt mae 0.75 500: Weighted 0.785389 (0.070127)\n",
      "0.05 5 4 5 sqrt mae 0.75 500: Macro 0.653108 (0.092599)\n",
      "Testing 2397/5184\n",
      "0.05 5 4 5 sqrt mae 1.0 50: Weighted 0.786095 (0.075948)\n",
      "0.05 5 4 5 sqrt mae 1.0 50: Macro 0.653105 (0.113881)\n",
      "Testing 2398/5184\n",
      "0.05 5 4 5 sqrt mae 1.0 100: Weighted 0.771482 (0.078812)\n",
      "0.05 5 4 5 sqrt mae 1.0 100: Macro 0.632606 (0.110482)\n",
      "Testing 2399/5184\n",
      "0.05 5 4 5 sqrt mae 1.0 200: Weighted 0.766057 (0.076054)\n",
      "0.05 5 4 5 sqrt mae 1.0 200: Macro 0.625090 (0.108458)\n",
      "Testing 2400/5184\n",
      "0.05 5 4 5 sqrt mae 1.0 500: Weighted 0.772077 (0.092276)\n",
      "0.05 5 4 5 sqrt mae 1.0 500: Macro 0.633266 (0.123413)\n",
      "Testing 2401/5184\n",
      "0.05 5 4 8 log2 friedman_mse 0.5 50: Weighted 0.815167 (0.054737)\n",
      "0.05 5 4 8 log2 friedman_mse 0.5 50: Macro 0.711169 (0.070994)\n",
      "Testing 2402/5184\n",
      "0.05 5 4 8 log2 friedman_mse 0.5 100: Weighted 0.840334 (0.070476)\n",
      "0.05 5 4 8 log2 friedman_mse 0.5 100: Macro 0.751440 (0.097659)\n",
      "Testing 2403/5184\n",
      "0.05 5 4 8 log2 friedman_mse 0.5 200: Weighted 0.824365 (0.066301)\n",
      "0.05 5 4 8 log2 friedman_mse 0.5 200: Macro 0.726107 (0.096577)\n",
      "Testing 2404/5184\n",
      "0.05 5 4 8 log2 friedman_mse 0.5 500: Weighted 0.812412 (0.082275)\n",
      "0.05 5 4 8 log2 friedman_mse 0.5 500: Macro 0.710973 (0.123778)\n",
      "Testing 2405/5184\n",
      "0.05 5 4 8 log2 friedman_mse 0.75 50: Weighted 0.820795 (0.069494)\n",
      "0.05 5 4 8 log2 friedman_mse 0.75 50: Macro 0.721533 (0.097006)\n",
      "Testing 2406/5184\n",
      "0.05 5 4 8 log2 friedman_mse 0.75 100: Weighted 0.816084 (0.087313)\n",
      "0.05 5 4 8 log2 friedman_mse 0.75 100: Macro 0.711102 (0.122560)\n",
      "Testing 2407/5184\n",
      "0.05 5 4 8 log2 friedman_mse 0.75 200: Weighted 0.818717 (0.095864)\n",
      "0.05 5 4 8 log2 friedman_mse 0.75 200: Macro 0.714192 (0.141986)\n",
      "Testing 2408/5184\n",
      "0.05 5 4 8 log2 friedman_mse 0.75 500: Weighted 0.811469 (0.072447)\n",
      "0.05 5 4 8 log2 friedman_mse 0.75 500: Macro 0.713285 (0.122346)\n",
      "Testing 2409/5184\n",
      "0.05 5 4 8 log2 friedman_mse 1.0 50: Weighted 0.802836 (0.071744)\n",
      "0.05 5 4 8 log2 friedman_mse 1.0 50: Macro 0.699506 (0.094691)\n",
      "Testing 2410/5184\n",
      "0.05 5 4 8 log2 friedman_mse 1.0 100: Weighted 0.814173 (0.069972)\n",
      "0.05 5 4 8 log2 friedman_mse 1.0 100: Macro 0.721795 (0.088248)\n",
      "Testing 2411/5184\n",
      "0.05 5 4 8 log2 friedman_mse 1.0 200: Weighted 0.791793 (0.088861)\n",
      "0.05 5 4 8 log2 friedman_mse 1.0 200: Macro 0.686308 (0.132464)\n",
      "Testing 2412/5184\n",
      "0.05 5 4 8 log2 friedman_mse 1.0 500: Weighted 0.804306 (0.095414)\n",
      "0.05 5 4 8 log2 friedman_mse 1.0 500: Macro 0.709131 (0.144224)\n",
      "Testing 2413/5184\n",
      "0.05 5 4 8 log2 mae 0.5 50: Weighted 0.808938 (0.069331)\n",
      "0.05 5 4 8 log2 mae 0.5 50: Macro 0.695870 (0.097900)\n",
      "Testing 2414/5184\n",
      "0.05 5 4 8 log2 mae 0.5 100: Weighted 0.799765 (0.080562)\n",
      "0.05 5 4 8 log2 mae 0.5 100: Macro 0.681942 (0.113534)\n",
      "Testing 2415/5184\n",
      "0.05 5 4 8 log2 mae 0.5 200: Weighted 0.797353 (0.065346)\n",
      "0.05 5 4 8 log2 mae 0.5 200: Macro 0.680731 (0.084342)\n",
      "Testing 2416/5184\n",
      "0.05 5 4 8 log2 mae 0.5 500: Weighted 0.799039 (0.068607)\n",
      "0.05 5 4 8 log2 mae 0.5 500: Macro 0.673248 (0.096111)\n",
      "Testing 2417/5184\n",
      "0.05 5 4 8 log2 mae 0.75 50: Weighted 0.795178 (0.076610)\n",
      "0.05 5 4 8 log2 mae 0.75 50: Macro 0.671769 (0.107692)\n",
      "Testing 2418/5184\n",
      "0.05 5 4 8 log2 mae 0.75 100: Weighted 0.786719 (0.069568)\n",
      "0.05 5 4 8 log2 mae 0.75 100: Macro 0.658664 (0.099979)\n",
      "Testing 2419/5184\n",
      "0.05 5 4 8 log2 mae 0.75 200: Weighted 0.794478 (0.084629)\n",
      "0.05 5 4 8 log2 mae 0.75 200: Macro 0.666874 (0.127254)\n",
      "Testing 2420/5184\n",
      "0.05 5 4 8 log2 mae 0.75 500: Weighted 0.796644 (0.108746)\n",
      "0.05 5 4 8 log2 mae 0.75 500: Macro 0.678252 (0.158453)\n",
      "Testing 2421/5184\n",
      "0.05 5 4 8 log2 mae 1.0 50: Weighted 0.781584 (0.078362)\n",
      "0.05 5 4 8 log2 mae 1.0 50: Macro 0.648412 (0.116306)\n",
      "Testing 2422/5184\n",
      "0.05 5 4 8 log2 mae 1.0 100: Weighted 0.782057 (0.085498)\n",
      "0.05 5 4 8 log2 mae 1.0 100: Macro 0.650988 (0.121677)\n",
      "Testing 2423/5184\n",
      "0.05 5 4 8 log2 mae 1.0 200: Weighted 0.785012 (0.096449)\n",
      "0.05 5 4 8 log2 mae 1.0 200: Macro 0.650827 (0.144853)\n",
      "Testing 2424/5184\n",
      "0.05 5 4 8 log2 mae 1.0 500: Weighted 0.790431 (0.112865)\n",
      "0.05 5 4 8 log2 mae 1.0 500: Macro 0.672611 (0.164566)\n",
      "Testing 2425/5184\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05 5 4 8 sqrt friedman_mse 0.5 50: Weighted 0.820522 (0.050971)\n",
      "0.05 5 4 8 sqrt friedman_mse 0.5 50: Macro 0.715668 (0.068001)\n",
      "Testing 2426/5184\n",
      "0.05 5 4 8 sqrt friedman_mse 0.5 100: Weighted 0.807715 (0.076640)\n",
      "0.05 5 4 8 sqrt friedman_mse 0.5 100: Macro 0.698267 (0.106671)\n",
      "Testing 2427/5184\n",
      "0.05 5 4 8 sqrt friedman_mse 0.5 200: Weighted 0.833365 (0.075133)\n",
      "0.05 5 4 8 sqrt friedman_mse 0.5 200: Macro 0.742927 (0.111225)\n",
      "Testing 2428/5184\n",
      "0.05 5 4 8 sqrt friedman_mse 0.5 500: Weighted 0.821526 (0.065973)\n",
      "0.05 5 4 8 sqrt friedman_mse 0.5 500: Macro 0.719477 (0.096496)\n",
      "Testing 2429/5184\n",
      "0.05 5 4 8 sqrt friedman_mse 0.75 50: Weighted 0.809373 (0.075280)\n",
      "0.05 5 4 8 sqrt friedman_mse 0.75 50: Macro 0.701872 (0.102926)\n",
      "Testing 2430/5184\n",
      "0.05 5 4 8 sqrt friedman_mse 0.75 100: Weighted 0.809443 (0.065916)\n",
      "0.05 5 4 8 sqrt friedman_mse 0.75 100: Macro 0.709910 (0.086846)\n",
      "Testing 2431/5184\n",
      "0.05 5 4 8 sqrt friedman_mse 0.75 200: Weighted 0.823410 (0.070064)\n",
      "0.05 5 4 8 sqrt friedman_mse 0.75 200: Macro 0.719669 (0.105757)\n",
      "Testing 2432/5184\n",
      "0.05 5 4 8 sqrt friedman_mse 0.75 500: Weighted 0.812750 (0.079635)\n",
      "0.05 5 4 8 sqrt friedman_mse 0.75 500: Macro 0.710975 (0.129205)\n",
      "Testing 2433/5184\n",
      "0.05 5 4 8 sqrt friedman_mse 1.0 50: Weighted 0.807192 (0.076054)\n",
      "0.05 5 4 8 sqrt friedman_mse 1.0 50: Macro 0.706722 (0.102776)\n",
      "Testing 2434/5184\n",
      "0.05 5 4 8 sqrt friedman_mse 1.0 100: Weighted 0.809379 (0.084775)\n",
      "0.05 5 4 8 sqrt friedman_mse 1.0 100: Macro 0.715723 (0.113374)\n",
      "Testing 2435/5184\n",
      "0.05 5 4 8 sqrt friedman_mse 1.0 200: Weighted 0.791275 (0.094172)\n",
      "0.05 5 4 8 sqrt friedman_mse 1.0 200: Macro 0.686082 (0.152138)\n",
      "Testing 2436/5184\n",
      "0.05 5 4 8 sqrt friedman_mse 1.0 500: Weighted 0.793881 (0.080679)\n",
      "0.05 5 4 8 sqrt friedman_mse 1.0 500: Macro 0.710924 (0.116887)\n",
      "Testing 2437/5184\n",
      "0.05 5 4 8 sqrt mae 0.5 50: Weighted 0.815539 (0.069791)\n",
      "0.05 5 4 8 sqrt mae 0.5 50: Macro 0.699695 (0.103957)\n",
      "Testing 2438/5184\n",
      "0.05 5 4 8 sqrt mae 0.5 100: Weighted 0.798853 (0.070912)\n",
      "0.05 5 4 8 sqrt mae 0.5 100: Macro 0.673903 (0.106566)\n",
      "Testing 2439/5184\n",
      "0.05 5 4 8 sqrt mae 0.5 200: Weighted 0.805478 (0.072514)\n",
      "0.05 5 4 8 sqrt mae 0.5 200: Macro 0.699741 (0.095988)\n",
      "Testing 2440/5184\n",
      "0.05 5 4 8 sqrt mae 0.5 500: Weighted 0.794958 (0.079594)\n",
      "0.05 5 4 8 sqrt mae 0.5 500: Macro 0.671222 (0.108148)\n",
      "Testing 2441/5184\n",
      "0.05 5 4 8 sqrt mae 0.75 50: Weighted 0.795641 (0.073812)\n",
      "0.05 5 4 8 sqrt mae 0.75 50: Macro 0.676928 (0.102142)\n",
      "Testing 2442/5184\n",
      "0.05 5 4 8 sqrt mae 0.75 100: Weighted 0.785601 (0.085567)\n",
      "0.05 5 4 8 sqrt mae 0.75 100: Macro 0.654676 (0.123541)\n",
      "Testing 2443/5184\n",
      "0.05 5 4 8 sqrt mae 0.75 200: Weighted 0.778246 (0.093624)\n",
      "0.05 5 4 8 sqrt mae 0.75 200: Macro 0.650744 (0.132376)\n",
      "Testing 2444/5184\n",
      "0.05 5 4 8 sqrt mae 0.75 500: Weighted 0.782723 (0.094636)\n",
      "0.05 5 4 8 sqrt mae 0.75 500: Macro 0.659978 (0.137756)\n",
      "Testing 2445/5184\n",
      "0.05 5 4 8 sqrt mae 1.0 50: Weighted 0.770032 (0.083256)\n",
      "0.05 5 4 8 sqrt mae 1.0 50: Macro 0.639012 (0.117657)\n",
      "Testing 2446/5184\n",
      "0.05 5 4 8 sqrt mae 1.0 100: Weighted 0.800827 (0.078896)\n",
      "0.05 5 4 8 sqrt mae 1.0 100: Macro 0.673811 (0.121093)\n",
      "Testing 2447/5184\n",
      "0.05 5 4 8 sqrt mae 1.0 200: Weighted 0.782762 (0.096129)\n",
      "0.05 5 4 8 sqrt mae 1.0 200: Macro 0.650560 (0.140202)\n",
      "Testing 2448/5184\n",
      "0.05 5 4 8 sqrt mae 1.0 500: Weighted 0.782652 (0.105275)\n",
      "0.05 5 4 8 sqrt mae 1.0 500: Macro 0.660057 (0.148451)\n",
      "Testing 2449/5184\n",
      "0.05 5 6 3 log2 friedman_mse 0.5 50: Weighted 0.816464 (0.056270)\n",
      "0.05 5 6 3 log2 friedman_mse 0.5 50: Macro 0.710442 (0.074978)\n",
      "Testing 2450/5184\n",
      "0.05 5 6 3 log2 friedman_mse 0.5 100: Weighted 0.810470 (0.070794)\n",
      "0.05 5 6 3 log2 friedman_mse 0.5 100: Macro 0.703504 (0.093425)\n",
      "Testing 2451/5184\n",
      "0.05 5 6 3 log2 friedman_mse 0.5 200: Weighted 0.816329 (0.032311)\n",
      "0.05 5 6 3 log2 friedman_mse 0.5 200: Macro 0.712013 (0.046765)\n",
      "Testing 2452/5184\n",
      "0.05 5 6 3 log2 friedman_mse 0.5 500: Weighted 0.815056 (0.072541)\n",
      "0.05 5 6 3 log2 friedman_mse 0.5 500: Macro 0.713596 (0.103695)\n",
      "Testing 2453/5184\n",
      "0.05 5 6 3 log2 friedman_mse 0.75 50: Weighted 0.812382 (0.074287)\n",
      "0.05 5 6 3 log2 friedman_mse 0.75 50: Macro 0.703803 (0.101247)\n",
      "Testing 2454/5184\n",
      "0.05 5 6 3 log2 friedman_mse 0.75 100: Weighted 0.824820 (0.084937)\n",
      "0.05 5 6 3 log2 friedman_mse 0.75 100: Macro 0.724438 (0.118741)\n",
      "Testing 2455/5184\n",
      "0.05 5 6 3 log2 friedman_mse 0.75 200: Weighted 0.809272 (0.080975)\n",
      "0.05 5 6 3 log2 friedman_mse 0.75 200: Macro 0.707717 (0.108831)\n",
      "Testing 2456/5184\n",
      "0.05 5 6 3 log2 friedman_mse 0.75 500: Weighted 0.805525 (0.051993)\n",
      "0.05 5 6 3 log2 friedman_mse 0.75 500: Macro 0.702429 (0.071897)\n",
      "Testing 2457/5184\n",
      "0.05 5 6 3 log2 friedman_mse 1.0 50: Weighted 0.793576 (0.055319)\n",
      "0.05 5 6 3 log2 friedman_mse 1.0 50: Macro 0.680410 (0.065843)\n",
      "Testing 2458/5184\n",
      "0.05 5 6 3 log2 friedman_mse 1.0 100: Weighted 0.800251 (0.079109)\n",
      "0.05 5 6 3 log2 friedman_mse 1.0 100: Macro 0.698080 (0.100898)\n",
      "Testing 2459/5184\n",
      "0.05 5 6 3 log2 friedman_mse 1.0 200: Weighted 0.813319 (0.063394)\n",
      "0.05 5 6 3 log2 friedman_mse 1.0 200: Macro 0.712329 (0.079509)\n",
      "Testing 2460/5184\n",
      "0.05 5 6 3 log2 friedman_mse 1.0 500: Weighted 0.800172 (0.067736)\n",
      "0.05 5 6 3 log2 friedman_mse 1.0 500: Macro 0.691091 (0.091837)\n",
      "Testing 2461/5184\n",
      "0.05 5 6 3 log2 mae 0.5 50: Weighted 0.824136 (0.049403)\n",
      "0.05 5 6 3 log2 mae 0.5 50: Macro 0.713287 (0.074549)\n",
      "Testing 2462/5184\n",
      "0.05 5 6 3 log2 mae 0.5 100: Weighted 0.808678 (0.063673)\n",
      "0.05 5 6 3 log2 mae 0.5 100: Macro 0.696075 (0.090285)\n",
      "Testing 2463/5184\n",
      "0.05 5 6 3 log2 mae 0.5 200: Weighted 0.812116 (0.067429)\n",
      "0.05 5 6 3 log2 mae 0.5 200: Macro 0.697595 (0.099230)\n",
      "Testing 2464/5184\n",
      "0.05 5 6 3 log2 mae 0.5 500: Weighted 0.791394 (0.074067)\n",
      "0.05 5 6 3 log2 mae 0.5 500: Macro 0.670359 (0.094717)\n",
      "Testing 2465/5184\n",
      "0.05 5 6 3 log2 mae 0.75 50: Weighted 0.803154 (0.070397)\n",
      "0.05 5 6 3 log2 mae 0.75 50: Macro 0.685993 (0.097059)\n",
      "Testing 2466/5184\n",
      "0.05 5 6 3 log2 mae 0.75 100: Weighted 0.795427 (0.067204)\n",
      "0.05 5 6 3 log2 mae 0.75 100: Macro 0.674606 (0.093302)\n",
      "Testing 2467/5184\n",
      "0.05 5 6 3 log2 mae 0.75 200: Weighted 0.778365 (0.070805)\n",
      "0.05 5 6 3 log2 mae 0.75 200: Macro 0.643444 (0.098675)\n",
      "Testing 2468/5184\n",
      "0.05 5 6 3 log2 mae 0.75 500: Weighted 0.776090 (0.072014)\n",
      "0.05 5 6 3 log2 mae 0.75 500: Macro 0.642307 (0.099711)\n",
      "Testing 2469/5184\n",
      "0.05 5 6 3 log2 mae 1.0 50: Weighted 0.791323 (0.060759)\n",
      "0.05 5 6 3 log2 mae 1.0 50: Macro 0.671472 (0.081911)\n",
      "Testing 2470/5184\n",
      "0.05 5 6 3 log2 mae 1.0 100: Weighted 0.790773 (0.077270)\n",
      "0.05 5 6 3 log2 mae 1.0 100: Macro 0.667397 (0.113050)\n",
      "Testing 2471/5184\n",
      "0.05 5 6 3 log2 mae 1.0 200: Weighted 0.778612 (0.062325)\n",
      "0.05 5 6 3 log2 mae 1.0 200: Macro 0.637560 (0.090711)\n",
      "Testing 2472/5184\n",
      "0.05 5 6 3 log2 mae 1.0 500: Weighted 0.768213 (0.065491)\n",
      "0.05 5 6 3 log2 mae 1.0 500: Macro 0.624592 (0.095651)\n",
      "Testing 2473/5184\n",
      "0.05 5 6 3 sqrt friedman_mse 0.5 50: Weighted 0.821016 (0.062143)\n",
      "0.05 5 6 3 sqrt friedman_mse 0.5 50: Macro 0.711296 (0.092318)\n",
      "Testing 2474/5184\n",
      "0.05 5 6 3 sqrt friedman_mse 0.5 100: Weighted 0.832474 (0.060339)\n",
      "0.05 5 6 3 sqrt friedman_mse 0.5 100: Macro 0.729793 (0.082793)\n",
      "Testing 2475/5184\n",
      "0.05 5 6 3 sqrt friedman_mse 0.5 200: Weighted 0.818767 (0.073020)\n",
      "0.05 5 6 3 sqrt friedman_mse 0.5 200: Macro 0.716252 (0.108585)\n",
      "Testing 2476/5184\n",
      "0.05 5 6 3 sqrt friedman_mse 0.5 500: Weighted 0.817503 (0.050335)\n",
      "0.05 5 6 3 sqrt friedman_mse 0.5 500: Macro 0.717838 (0.073942)\n",
      "Testing 2477/5184\n",
      "0.05 5 6 3 sqrt friedman_mse 0.75 50: Weighted 0.810870 (0.056456)\n",
      "0.05 5 6 3 sqrt friedman_mse 0.75 50: Macro 0.705289 (0.070780)\n",
      "Testing 2478/5184\n",
      "0.05 5 6 3 sqrt friedman_mse 0.75 100: Weighted 0.815363 (0.072928)\n",
      "0.05 5 6 3 sqrt friedman_mse 0.75 100: Macro 0.715720 (0.096129)\n",
      "Testing 2479/5184\n",
      "0.05 5 6 3 sqrt friedman_mse 0.75 200: Weighted 0.815297 (0.064825)\n",
      "0.05 5 6 3 sqrt friedman_mse 0.75 200: Macro 0.712473 (0.087247)\n",
      "Testing 2480/5184\n",
      "0.05 5 6 3 sqrt friedman_mse 0.75 500: Weighted 0.810363 (0.058030)\n",
      "0.05 5 6 3 sqrt friedman_mse 0.75 500: Macro 0.712822 (0.084958)\n",
      "Testing 2481/5184\n",
      "0.05 5 6 3 sqrt friedman_mse 1.0 50: Weighted 0.793725 (0.054124)\n",
      "0.05 5 6 3 sqrt friedman_mse 1.0 50: Macro 0.680874 (0.065291)\n",
      "Testing 2482/5184\n",
      "0.05 5 6 3 sqrt friedman_mse 1.0 100: Weighted 0.805294 (0.079595)\n",
      "0.05 5 6 3 sqrt friedman_mse 1.0 100: Macro 0.705528 (0.101887)\n",
      "Testing 2483/5184\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05 5 6 3 sqrt friedman_mse 1.0 200: Weighted 0.817259 (0.063141)\n",
      "0.05 5 6 3 sqrt friedman_mse 1.0 200: Macro 0.722562 (0.085843)\n",
      "Testing 2484/5184\n",
      "0.05 5 6 3 sqrt friedman_mse 1.0 500: Weighted 0.806274 (0.064115)\n",
      "0.05 5 6 3 sqrt friedman_mse 1.0 500: Macro 0.702862 (0.085030)\n",
      "Testing 2485/5184\n",
      "0.05 5 6 3 sqrt mae 0.5 50: Weighted 0.825381 (0.053762)\n",
      "0.05 5 6 3 sqrt mae 0.5 50: Macro 0.722101 (0.072474)\n",
      "Testing 2486/5184\n",
      "0.05 5 6 3 sqrt mae 0.5 100: Weighted 0.813345 (0.075117)\n",
      "0.05 5 6 3 sqrt mae 0.5 100: Macro 0.699108 (0.109575)\n",
      "Testing 2487/5184\n",
      "0.05 5 6 3 sqrt mae 0.5 200: Weighted 0.791237 (0.066705)\n",
      "0.05 5 6 3 sqrt mae 0.5 200: Macro 0.671523 (0.088792)\n",
      "Testing 2488/5184\n",
      "0.05 5 6 3 sqrt mae 0.5 500: Weighted 0.786999 (0.081371)\n",
      "0.05 5 6 3 sqrt mae 0.5 500: Macro 0.666720 (0.115994)\n",
      "Testing 2489/5184\n",
      "0.05 5 6 3 sqrt mae 0.75 50: Weighted 0.802955 (0.066643)\n",
      "0.05 5 6 3 sqrt mae 0.75 50: Macro 0.690556 (0.089751)\n",
      "Testing 2490/5184\n",
      "0.05 5 6 3 sqrt mae 0.75 100: Weighted 0.791868 (0.068705)\n",
      "0.05 5 6 3 sqrt mae 0.75 100: Macro 0.670218 (0.095028)\n",
      "Testing 2491/5184\n",
      "0.05 5 6 3 sqrt mae 0.75 200: Weighted 0.783281 (0.067905)\n",
      "0.05 5 6 3 sqrt mae 0.75 200: Macro 0.659371 (0.093834)\n",
      "Testing 2492/5184\n",
      "0.05 5 6 3 sqrt mae 0.75 500: Weighted 0.767191 (0.071298)\n",
      "0.05 5 6 3 sqrt mae 0.75 500: Macro 0.631558 (0.093752)\n",
      "Testing 2493/5184\n",
      "0.05 5 6 3 sqrt mae 1.0 50: Weighted 0.791719 (0.061055)\n",
      "0.05 5 6 3 sqrt mae 1.0 50: Macro 0.670567 (0.079425)\n",
      "Testing 2494/5184\n",
      "0.05 5 6 3 sqrt mae 1.0 100: Weighted 0.793020 (0.079014)\n",
      "0.05 5 6 3 sqrt mae 1.0 100: Macro 0.668466 (0.115911)\n",
      "Testing 2495/5184\n",
      "0.05 5 6 3 sqrt mae 1.0 200: Weighted 0.785589 (0.087828)\n",
      "0.05 5 6 3 sqrt mae 1.0 200: Macro 0.655133 (0.127809)\n",
      "Testing 2496/5184\n",
      "0.05 5 6 3 sqrt mae 1.0 500: Weighted 0.756200 (0.048492)\n",
      "0.05 5 6 3 sqrt mae 1.0 500: Macro 0.600601 (0.071184)\n",
      "Testing 2497/5184\n",
      "0.05 5 6 5 log2 friedman_mse 0.5 50: Weighted 0.815023 (0.063511)\n",
      "0.05 5 6 5 log2 friedman_mse 0.5 50: Macro 0.718123 (0.079678)\n",
      "Testing 2498/5184\n",
      "0.05 5 6 5 log2 friedman_mse 0.5 100: Weighted 0.823014 (0.069320)\n",
      "0.05 5 6 5 log2 friedman_mse 0.5 100: Macro 0.725436 (0.103333)\n",
      "Testing 2499/5184\n",
      "0.05 5 6 5 log2 friedman_mse 0.5 200: Weighted 0.801040 (0.060730)\n",
      "0.05 5 6 5 log2 friedman_mse 0.5 200: Macro 0.688481 (0.082015)\n",
      "Testing 2500/5184\n",
      "0.05 5 6 5 log2 friedman_mse 0.5 500: Weighted 0.812702 (0.046732)\n",
      "0.05 5 6 5 log2 friedman_mse 0.5 500: Macro 0.716559 (0.065368)\n",
      "Testing 2501/5184\n",
      "0.05 5 6 5 log2 friedman_mse 0.75 50: Weighted 0.798573 (0.058422)\n",
      "0.05 5 6 5 log2 friedman_mse 0.75 50: Macro 0.689222 (0.074416)\n",
      "Testing 2502/5184\n",
      "0.05 5 6 5 log2 friedman_mse 0.75 100: Weighted 0.823492 (0.076818)\n",
      "0.05 5 6 5 log2 friedman_mse 0.75 100: Macro 0.727834 (0.108144)\n",
      "Testing 2503/5184\n",
      "0.05 5 6 5 log2 friedman_mse 0.75 200: Weighted 0.811292 (0.076544)\n",
      "0.05 5 6 5 log2 friedman_mse 0.75 200: Macro 0.702406 (0.106447)\n",
      "Testing 2504/5184\n",
      "0.05 5 6 5 log2 friedman_mse 0.75 500: Weighted 0.818068 (0.067504)\n",
      "0.05 5 6 5 log2 friedman_mse 0.75 500: Macro 0.715480 (0.100406)\n",
      "Testing 2505/5184\n",
      "0.05 5 6 5 log2 friedman_mse 1.0 50: Weighted 0.798543 (0.070766)\n",
      "0.05 5 6 5 log2 friedman_mse 1.0 50: Macro 0.691570 (0.092997)\n",
      "Testing 2506/5184\n",
      "0.05 5 6 5 log2 friedman_mse 1.0 100: Weighted 0.806759 (0.083435)\n",
      "0.05 5 6 5 log2 friedman_mse 1.0 100: Macro 0.702594 (0.114309)\n",
      "Testing 2507/5184\n",
      "0.05 5 6 5 log2 friedman_mse 1.0 200: Weighted 0.811105 (0.084919)\n",
      "0.05 5 6 5 log2 friedman_mse 1.0 200: Macro 0.712626 (0.124035)\n",
      "Testing 2508/5184\n",
      "0.05 5 6 5 log2 friedman_mse 1.0 500: Weighted 0.811228 (0.073160)\n",
      "0.05 5 6 5 log2 friedman_mse 1.0 500: Macro 0.715265 (0.104068)\n",
      "Testing 2509/5184\n",
      "0.05 5 6 5 log2 mae 0.5 50: Weighted 0.813258 (0.058069)\n",
      "0.05 5 6 5 log2 mae 0.5 50: Macro 0.698452 (0.085137)\n",
      "Testing 2510/5184\n",
      "0.05 5 6 5 log2 mae 0.5 100: Weighted 0.792275 (0.076460)\n",
      "0.05 5 6 5 log2 mae 0.5 100: Macro 0.662234 (0.110891)\n",
      "Testing 2511/5184\n",
      "0.05 5 6 5 log2 mae 0.5 200: Weighted 0.785593 (0.065192)\n",
      "0.05 5 6 5 log2 mae 0.5 200: Macro 0.660514 (0.087620)\n",
      "Testing 2512/5184\n",
      "0.05 5 6 5 log2 mae 0.5 500: Weighted 0.777642 (0.082914)\n",
      "0.05 5 6 5 log2 mae 0.5 500: Macro 0.656146 (0.108782)\n",
      "Testing 2513/5184\n",
      "0.05 5 6 5 log2 mae 0.75 50: Weighted 0.789583 (0.077509)\n",
      "0.05 5 6 5 log2 mae 0.75 50: Macro 0.655927 (0.118310)\n",
      "Testing 2514/5184\n",
      "0.05 5 6 5 log2 mae 0.75 100: Weighted 0.784934 (0.066464)\n",
      "0.05 5 6 5 log2 mae 0.75 100: Macro 0.655093 (0.097090)\n",
      "Testing 2515/5184\n",
      "0.05 5 6 5 log2 mae 0.75 200: Weighted 0.783236 (0.084573)\n",
      "0.05 5 6 5 log2 mae 0.75 200: Macro 0.651566 (0.121153)\n",
      "Testing 2516/5184\n",
      "0.05 5 6 5 log2 mae 0.75 500: Weighted 0.777065 (0.078738)\n",
      "0.05 5 6 5 log2 mae 0.75 500: Macro 0.643385 (0.101182)\n",
      "Testing 2517/5184\n",
      "0.05 5 6 5 log2 mae 1.0 50: Weighted 0.791881 (0.077358)\n",
      "0.05 5 6 5 log2 mae 1.0 50: Macro 0.659457 (0.119386)\n",
      "Testing 2518/5184\n",
      "0.05 5 6 5 log2 mae 1.0 100: Weighted 0.780763 (0.087634)\n",
      "0.05 5 6 5 log2 mae 1.0 100: Macro 0.650936 (0.127748)\n",
      "Testing 2519/5184\n",
      "0.05 5 6 5 log2 mae 1.0 200: Weighted 0.771500 (0.078886)\n",
      "0.05 5 6 5 log2 mae 1.0 200: Macro 0.635219 (0.109118)\n",
      "Testing 2520/5184\n",
      "0.05 5 6 5 log2 mae 1.0 500: Weighted 0.785784 (0.097228)\n",
      "0.05 5 6 5 log2 mae 1.0 500: Macro 0.652121 (0.134977)\n",
      "Testing 2521/5184\n",
      "0.05 5 6 5 sqrt friedman_mse 0.5 50: Weighted 0.829333 (0.067921)\n",
      "0.05 5 6 5 sqrt friedman_mse 0.5 50: Macro 0.732799 (0.097013)\n",
      "Testing 2522/5184\n",
      "0.05 5 6 5 sqrt friedman_mse 0.5 100: Weighted 0.814696 (0.062027)\n",
      "0.05 5 6 5 sqrt friedman_mse 0.5 100: Macro 0.705831 (0.087646)\n",
      "Testing 2523/5184\n",
      "0.05 5 6 5 sqrt friedman_mse 0.5 200: Weighted 0.827470 (0.070600)\n",
      "0.05 5 6 5 sqrt friedman_mse 0.5 200: Macro 0.719030 (0.105832)\n",
      "Testing 2524/5184\n",
      "0.05 5 6 5 sqrt friedman_mse 0.5 500: Weighted 0.813429 (0.060940)\n",
      "0.05 5 6 5 sqrt friedman_mse 0.5 500: Macro 0.709693 (0.090019)\n",
      "Testing 2525/5184\n",
      "0.05 5 6 5 sqrt friedman_mse 0.75 50: Weighted 0.815943 (0.072852)\n",
      "0.05 5 6 5 sqrt friedman_mse 0.75 50: Macro 0.709356 (0.101783)\n",
      "Testing 2526/5184\n",
      "0.05 5 6 5 sqrt friedman_mse 0.75 100: Weighted 0.811193 (0.073421)\n",
      "0.05 5 6 5 sqrt friedman_mse 0.75 100: Macro 0.703575 (0.104795)\n",
      "Testing 2527/5184\n",
      "0.05 5 6 5 sqrt friedman_mse 0.75 200: Weighted 0.821311 (0.085962)\n",
      "0.05 5 6 5 sqrt friedman_mse 0.75 200: Macro 0.721274 (0.125657)\n",
      "Testing 2528/5184\n",
      "0.05 5 6 5 sqrt friedman_mse 0.75 500: Weighted 0.833741 (0.075036)\n",
      "0.05 5 6 5 sqrt friedman_mse 0.75 500: Macro 0.739677 (0.107938)\n",
      "Testing 2529/5184\n",
      "0.05 5 6 5 sqrt friedman_mse 1.0 50: Weighted 0.802093 (0.077973)\n",
      "0.05 5 6 5 sqrt friedman_mse 1.0 50: Macro 0.699198 (0.103886)\n",
      "Testing 2530/5184\n",
      "0.05 5 6 5 sqrt friedman_mse 1.0 100: Weighted 0.811368 (0.078308)\n",
      "0.05 5 6 5 sqrt friedman_mse 1.0 100: Macro 0.712852 (0.103813)\n",
      "Testing 2531/5184\n",
      "0.05 5 6 5 sqrt friedman_mse 1.0 200: Weighted 0.801290 (0.063916)\n",
      "0.05 5 6 5 sqrt friedman_mse 1.0 200: Macro 0.689806 (0.091595)\n",
      "Testing 2532/5184\n",
      "0.05 5 6 5 sqrt friedman_mse 1.0 500: Weighted 0.798493 (0.059273)\n",
      "0.05 5 6 5 sqrt friedman_mse 1.0 500: Macro 0.695990 (0.079799)\n",
      "Testing 2533/5184\n",
      "0.05 5 6 5 sqrt mae 0.5 50: Weighted 0.809645 (0.059812)\n",
      "0.05 5 6 5 sqrt mae 0.5 50: Macro 0.706105 (0.075195)\n",
      "Testing 2534/5184\n",
      "0.05 5 6 5 sqrt mae 0.5 100: Weighted 0.808005 (0.071960)\n",
      "0.05 5 6 5 sqrt mae 0.5 100: Macro 0.691634 (0.103639)\n",
      "Testing 2535/5184\n",
      "0.05 5 6 5 sqrt mae 0.5 200: Weighted 0.799085 (0.078322)\n",
      "0.05 5 6 5 sqrt mae 0.5 200: Macro 0.677973 (0.115122)\n",
      "Testing 2536/5184\n",
      "0.05 5 6 5 sqrt mae 0.5 500: Weighted 0.794580 (0.081728)\n",
      "0.05 5 6 5 sqrt mae 0.5 500: Macro 0.680199 (0.105762)\n",
      "Testing 2537/5184\n",
      "0.05 5 6 5 sqrt mae 0.75 50: Weighted 0.790674 (0.072755)\n",
      "0.05 5 6 5 sqrt mae 0.75 50: Macro 0.669556 (0.098917)\n",
      "Testing 2538/5184\n",
      "0.05 5 6 5 sqrt mae 0.75 100: Weighted 0.784263 (0.066754)\n",
      "0.05 5 6 5 sqrt mae 0.75 100: Macro 0.656595 (0.095648)\n",
      "Testing 2539/5184\n",
      "0.05 5 6 5 sqrt mae 0.75 200: Weighted 0.776069 (0.071731)\n",
      "0.05 5 6 5 sqrt mae 0.75 200: Macro 0.645293 (0.092541)\n",
      "Testing 2540/5184\n",
      "0.05 5 6 5 sqrt mae 0.75 500: Weighted 0.778615 (0.066407)\n",
      "0.05 5 6 5 sqrt mae 0.75 500: Macro 0.644130 (0.090486)\n",
      "Testing 2541/5184\n",
      "0.05 5 6 5 sqrt mae 1.0 50: Weighted 0.782730 (0.078768)\n",
      "0.05 5 6 5 sqrt mae 1.0 50: Macro 0.649075 (0.117555)\n",
      "Testing 2542/5184\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05 5 6 5 sqrt mae 1.0 100: Weighted 0.794898 (0.084243)\n",
      "0.05 5 6 5 sqrt mae 1.0 100: Macro 0.662747 (0.124302)\n",
      "Testing 2543/5184\n",
      "0.05 5 6 5 sqrt mae 1.0 200: Weighted 0.773496 (0.076984)\n",
      "0.05 5 6 5 sqrt mae 1.0 200: Macro 0.639596 (0.109863)\n",
      "Testing 2544/5184\n",
      "0.05 5 6 5 sqrt mae 1.0 500: Weighted 0.775694 (0.088291)\n",
      "0.05 5 6 5 sqrt mae 1.0 500: Macro 0.632090 (0.122679)\n",
      "Testing 2545/5184\n",
      "0.05 5 6 8 log2 friedman_mse 0.5 50: Weighted 0.827496 (0.055917)\n",
      "0.05 5 6 8 log2 friedman_mse 0.5 50: Macro 0.728183 (0.074634)\n",
      "Testing 2546/5184\n",
      "0.05 5 6 8 log2 friedman_mse 0.5 100: Weighted 0.826127 (0.071424)\n",
      "0.05 5 6 8 log2 friedman_mse 0.5 100: Macro 0.733128 (0.098415)\n",
      "Testing 2547/5184\n",
      "0.05 5 6 8 log2 friedman_mse 0.5 200: Weighted 0.827788 (0.069016)\n",
      "0.05 5 6 8 log2 friedman_mse 0.5 200: Macro 0.732163 (0.105759)\n",
      "Testing 2548/5184\n",
      "0.05 5 6 8 log2 friedman_mse 0.5 500: Weighted 0.809117 (0.066210)\n",
      "0.05 5 6 8 log2 friedman_mse 0.5 500: Macro 0.706479 (0.094128)\n",
      "Testing 2549/5184\n",
      "0.05 5 6 8 log2 friedman_mse 0.75 50: Weighted 0.813146 (0.059902)\n",
      "0.05 5 6 8 log2 friedman_mse 0.75 50: Macro 0.705908 (0.081648)\n",
      "Testing 2550/5184\n",
      "0.05 5 6 8 log2 friedman_mse 0.75 100: Weighted 0.832568 (0.087580)\n",
      "0.05 5 6 8 log2 friedman_mse 0.75 100: Macro 0.739288 (0.129570)\n",
      "Testing 2551/5184\n",
      "0.05 5 6 8 log2 friedman_mse 0.75 200: Weighted 0.828486 (0.090630)\n",
      "0.05 5 6 8 log2 friedman_mse 0.75 200: Macro 0.734640 (0.132760)\n",
      "Testing 2552/5184\n",
      "0.05 5 6 8 log2 friedman_mse 0.75 500: Weighted 0.808658 (0.078186)\n",
      "0.05 5 6 8 log2 friedman_mse 0.75 500: Macro 0.711963 (0.130149)\n",
      "Testing 2553/5184\n",
      "0.05 5 6 8 log2 friedman_mse 1.0 50: Weighted 0.802812 (0.069289)\n",
      "0.05 5 6 8 log2 friedman_mse 1.0 50: Macro 0.699497 (0.092196)\n",
      "Testing 2554/5184\n",
      "0.05 5 6 8 log2 friedman_mse 1.0 100: Weighted 0.806069 (0.093458)\n",
      "0.05 5 6 8 log2 friedman_mse 1.0 100: Macro 0.714446 (0.123056)\n",
      "Testing 2555/5184\n",
      "0.05 5 6 8 log2 friedman_mse 1.0 200: Weighted 0.801656 (0.102123)\n",
      "0.05 5 6 8 log2 friedman_mse 1.0 200: Macro 0.695929 (0.156242)\n",
      "Testing 2556/5184\n",
      "0.05 5 6 8 log2 friedman_mse 1.0 500: Weighted 0.805456 (0.088984)\n",
      "0.05 5 6 8 log2 friedman_mse 1.0 500: Macro 0.716599 (0.130572)\n",
      "Testing 2557/5184\n",
      "0.05 5 6 8 log2 mae 0.5 50: Weighted 0.799719 (0.069957)\n",
      "0.05 5 6 8 log2 mae 0.5 50: Macro 0.679887 (0.099639)\n",
      "Testing 2558/5184\n",
      "0.05 5 6 8 log2 mae 0.5 100: Weighted 0.794175 (0.071232)\n",
      "0.05 5 6 8 log2 mae 0.5 100: Macro 0.663063 (0.102499)\n",
      "Testing 2559/5184\n",
      "0.05 5 6 8 log2 mae 0.5 200: Weighted 0.798028 (0.061195)\n",
      "0.05 5 6 8 log2 mae 0.5 200: Macro 0.679137 (0.085170)\n",
      "Testing 2560/5184\n",
      "0.05 5 6 8 log2 mae 0.5 500: Weighted 0.799412 (0.060451)\n",
      "0.05 5 6 8 log2 mae 0.5 500: Macro 0.672999 (0.090280)\n",
      "Testing 2561/5184\n",
      "0.05 5 6 8 log2 mae 0.75 50: Weighted 0.798411 (0.064818)\n",
      "0.05 5 6 8 log2 mae 0.75 50: Macro 0.677354 (0.091722)\n",
      "Testing 2562/5184\n",
      "0.05 5 6 8 log2 mae 0.75 100: Weighted 0.792667 (0.068399)\n",
      "0.05 5 6 8 log2 mae 0.75 100: Macro 0.669421 (0.093299)\n",
      "Testing 2563/5184\n",
      "0.05 5 6 8 log2 mae 0.75 200: Weighted 0.783238 (0.079032)\n",
      "0.05 5 6 8 log2 mae 0.75 200: Macro 0.651666 (0.116401)\n",
      "Testing 2564/5184\n",
      "0.05 5 6 8 log2 mae 0.75 500: Weighted 0.786188 (0.100590)\n",
      "0.05 5 6 8 log2 mae 0.75 500: Macro 0.666218 (0.145312)\n",
      "Testing 2565/5184\n",
      "0.05 5 6 8 log2 mae 1.0 50: Weighted 0.783915 (0.067624)\n",
      "0.05 5 6 8 log2 mae 1.0 50: Macro 0.650528 (0.101327)\n",
      "Testing 2566/5184\n",
      "0.05 5 6 8 log2 mae 1.0 100: Weighted 0.783454 (0.085782)\n",
      "0.05 5 6 8 log2 mae 1.0 100: Macro 0.654965 (0.124041)\n",
      "Testing 2567/5184\n",
      "0.05 5 6 8 log2 mae 1.0 200: Weighted 0.786504 (0.101483)\n",
      "0.05 5 6 8 log2 mae 1.0 200: Macro 0.656660 (0.149255)\n",
      "Testing 2568/5184\n",
      "0.05 5 6 8 log2 mae 1.0 500: Weighted 0.767662 (0.103108)\n",
      "0.05 5 6 8 log2 mae 1.0 500: Macro 0.632912 (0.144117)\n",
      "Testing 2569/5184\n",
      "0.05 5 6 8 sqrt friedman_mse 0.5 50: Weighted 0.839356 (0.075430)\n",
      "0.05 5 6 8 sqrt friedman_mse 0.5 50: Macro 0.745399 (0.108658)\n",
      "Testing 2570/5184\n",
      "0.05 5 6 8 sqrt friedman_mse 0.5 100: Weighted 0.822907 (0.075799)\n",
      "0.05 5 6 8 sqrt friedman_mse 0.5 100: Macro 0.724816 (0.108441)\n",
      "Testing 2571/5184\n",
      "0.05 5 6 8 sqrt friedman_mse 0.5 200: Weighted 0.819183 (0.066230)\n",
      "0.05 5 6 8 sqrt friedman_mse 0.5 200: Macro 0.722785 (0.091111)\n",
      "Testing 2572/5184\n",
      "0.05 5 6 8 sqrt friedman_mse 0.5 500: Weighted 0.810385 (0.066733)\n",
      "0.05 5 6 8 sqrt friedman_mse 0.5 500: Macro 0.701688 (0.107278)\n",
      "Testing 2573/5184\n",
      "0.05 5 6 8 sqrt friedman_mse 0.75 50: Weighted 0.822178 (0.059991)\n",
      "0.05 5 6 8 sqrt friedman_mse 0.75 50: Macro 0.723128 (0.076972)\n",
      "Testing 2574/5184\n",
      "0.05 5 6 8 sqrt friedman_mse 0.75 100: Weighted 0.834252 (0.074626)\n",
      "0.05 5 6 8 sqrt friedman_mse 0.75 100: Macro 0.749084 (0.101928)\n",
      "Testing 2575/5184\n",
      "0.05 5 6 8 sqrt friedman_mse 0.75 200: Weighted 0.826851 (0.087252)\n",
      "0.05 5 6 8 sqrt friedman_mse 0.75 200: Macro 0.732618 (0.126860)\n",
      "Testing 2576/5184\n",
      "0.05 5 6 8 sqrt friedman_mse 0.75 500: Weighted 0.815434 (0.078332)\n",
      "0.05 5 6 8 sqrt friedman_mse 0.75 500: Macro 0.720025 (0.128572)\n",
      "Testing 2577/5184\n",
      "0.05 5 6 8 sqrt friedman_mse 1.0 50: Weighted 0.812209 (0.079566)\n",
      "0.05 5 6 8 sqrt friedman_mse 1.0 50: Macro 0.714431 (0.107809)\n",
      "Testing 2578/5184\n",
      "0.05 5 6 8 sqrt friedman_mse 1.0 100: Weighted 0.814537 (0.076203)\n",
      "0.05 5 6 8 sqrt friedman_mse 1.0 100: Macro 0.720632 (0.101385)\n",
      "Testing 2579/5184\n",
      "0.05 5 6 8 sqrt friedman_mse 1.0 200: Weighted 0.802087 (0.086103)\n",
      "0.05 5 6 8 sqrt friedman_mse 1.0 200: Macro 0.711638 (0.116627)\n",
      "Testing 2580/5184\n",
      "0.05 5 6 8 sqrt friedman_mse 1.0 500: Weighted 0.805973 (0.088742)\n",
      "0.05 5 6 8 sqrt friedman_mse 1.0 500: Macro 0.720425 (0.134134)\n",
      "Testing 2581/5184\n",
      "0.05 5 6 8 sqrt mae 0.5 50: Weighted 0.811713 (0.059371)\n",
      "0.05 5 6 8 sqrt mae 0.5 50: Macro 0.699991 (0.083106)\n",
      "Testing 2582/5184\n",
      "0.05 5 6 8 sqrt mae 0.5 100: Weighted 0.804142 (0.075883)\n",
      "0.05 5 6 8 sqrt mae 0.5 100: Macro 0.686849 (0.108607)\n",
      "Testing 2583/5184\n",
      "0.05 5 6 8 sqrt mae 0.5 200: Weighted 0.792433 (0.065476)\n",
      "0.05 5 6 8 sqrt mae 0.5 200: Macro 0.664830 (0.094882)\n",
      "Testing 2584/5184\n",
      "0.05 5 6 8 sqrt mae 0.5 500: Weighted 0.796763 (0.070165)\n",
      "0.05 5 6 8 sqrt mae 0.5 500: Macro 0.679543 (0.086450)\n",
      "Testing 2585/5184\n",
      "0.05 5 6 8 sqrt mae 0.75 50: Weighted 0.791225 (0.070329)\n",
      "0.05 5 6 8 sqrt mae 0.75 50: Macro 0.659789 (0.103853)\n",
      "Testing 2586/5184\n",
      "0.05 5 6 8 sqrt mae 0.75 100: Weighted 0.803117 (0.076859)\n",
      "0.05 5 6 8 sqrt mae 0.75 100: Macro 0.684699 (0.110550)\n",
      "Testing 2587/5184\n",
      "0.05 5 6 8 sqrt mae 0.75 200: Weighted 0.793046 (0.087854)\n",
      "0.05 5 6 8 sqrt mae 0.75 200: Macro 0.669065 (0.131135)\n",
      "Testing 2588/5184\n",
      "0.05 5 6 8 sqrt mae 0.75 500: Weighted 0.778202 (0.096526)\n",
      "0.05 5 6 8 sqrt mae 0.75 500: Macro 0.650477 (0.135683)\n",
      "Testing 2589/5184\n",
      "0.05 5 6 8 sqrt mae 1.0 50: Weighted 0.790905 (0.080212)\n",
      "0.05 5 6 8 sqrt mae 1.0 50: Macro 0.662860 (0.116935)\n",
      "Testing 2590/5184\n",
      "0.05 5 6 8 sqrt mae 1.0 100: Weighted 0.783454 (0.085782)\n",
      "0.05 5 6 8 sqrt mae 1.0 100: Macro 0.654965 (0.124041)\n",
      "Testing 2591/5184\n",
      "0.05 5 6 8 sqrt mae 1.0 200: Weighted 0.785064 (0.083871)\n",
      "0.05 5 6 8 sqrt mae 1.0 200: Macro 0.651022 (0.124455)\n",
      "Testing 2592/5184\n",
      "0.05 5 6 8 sqrt mae 1.0 500: Weighted 0.772282 (0.088799)\n",
      "0.05 5 6 8 sqrt mae 1.0 500: Macro 0.634672 (0.127768)\n",
      "Testing 2593/5184\n",
      "0.1 1 2 3 log2 friedman_mse 0.5 50: Weighted 0.782853 (0.047261)\n",
      "0.1 1 2 3 log2 friedman_mse 0.5 50: Macro 0.674605 (0.078571)\n",
      "Testing 2594/5184\n",
      "0.1 1 2 3 log2 friedman_mse 0.5 100: Weighted 0.804787 (0.054813)\n",
      "0.1 1 2 3 log2 friedman_mse 0.5 100: Macro 0.694800 (0.078082)\n",
      "Testing 2595/5184\n",
      "0.1 1 2 3 log2 friedman_mse 0.5 200: Weighted 0.808187 (0.053055)\n",
      "0.1 1 2 3 log2 friedman_mse 0.5 200: Macro 0.709650 (0.081787)\n",
      "Testing 2596/5184\n",
      "0.1 1 2 3 log2 friedman_mse 0.5 500: Weighted 0.820320 (0.071008)\n",
      "0.1 1 2 3 log2 friedman_mse 0.5 500: Macro 0.730425 (0.106014)\n",
      "Testing 2597/5184\n",
      "0.1 1 2 3 log2 friedman_mse 0.75 50: Weighted 0.798722 (0.080406)\n",
      "0.1 1 2 3 log2 friedman_mse 0.75 50: Macro 0.694009 (0.109524)\n",
      "Testing 2598/5184\n",
      "0.1 1 2 3 log2 friedman_mse 0.75 100: Weighted 0.784335 (0.051606)\n",
      "0.1 1 2 3 log2 friedman_mse 0.75 100: Macro 0.668921 (0.075465)\n",
      "Testing 2599/5184\n",
      "0.1 1 2 3 log2 friedman_mse 0.75 200: Weighted 0.801766 (0.056617)\n",
      "0.1 1 2 3 log2 friedman_mse 0.75 200: Macro 0.699974 (0.085898)\n",
      "Testing 2600/5184\n",
      "0.1 1 2 3 log2 friedman_mse 0.75 500: Weighted 0.790815 (0.068704)\n",
      "0.1 1 2 3 log2 friedman_mse 0.75 500: Macro 0.683189 (0.113804)\n",
      "Testing 2601/5184\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1 1 2 3 log2 friedman_mse 1.0 50: Weighted 0.790995 (0.073078)\n",
      "0.1 1 2 3 log2 friedman_mse 1.0 50: Macro 0.687176 (0.109958)\n",
      "Testing 2602/5184\n",
      "0.1 1 2 3 log2 friedman_mse 1.0 100: Weighted 0.809628 (0.048888)\n",
      "0.1 1 2 3 log2 friedman_mse 1.0 100: Macro 0.710413 (0.072862)\n",
      "Testing 2603/5184\n",
      "0.1 1 2 3 log2 friedman_mse 1.0 200: Weighted 0.792671 (0.053588)\n",
      "0.1 1 2 3 log2 friedman_mse 1.0 200: Macro 0.685652 (0.086769)\n",
      "Testing 2604/5184\n",
      "0.1 1 2 3 log2 friedman_mse 1.0 500: Weighted 0.797757 (0.055942)\n",
      "0.1 1 2 3 log2 friedman_mse 1.0 500: Macro 0.697949 (0.085709)\n",
      "Testing 2605/5184\n",
      "0.1 1 2 3 log2 mae 0.5 50: Weighted 0.794385 (0.033899)\n",
      "0.1 1 2 3 log2 mae 0.5 50: Macro 0.684927 (0.049006)\n",
      "Testing 2606/5184\n",
      "0.1 1 2 3 log2 mae 0.5 100: Weighted 0.793408 (0.052295)\n",
      "0.1 1 2 3 log2 mae 0.5 100: Macro 0.680136 (0.077564)\n",
      "Testing 2607/5184\n",
      "0.1 1 2 3 log2 mae 0.5 200: Weighted 0.774924 (0.056576)\n",
      "0.1 1 2 3 log2 mae 0.5 200: Macro 0.648274 (0.088757)\n",
      "Testing 2608/5184\n",
      "0.1 1 2 3 log2 mae 0.5 500: Weighted 0.786514 (0.079113)\n",
      "0.1 1 2 3 log2 mae 0.5 500: Macro 0.673684 (0.123717)\n",
      "Testing 2609/5184\n",
      "0.1 1 2 3 log2 mae 0.75 50: Weighted 0.784266 (0.066996)\n",
      "0.1 1 2 3 log2 mae 0.75 50: Macro 0.667365 (0.090688)\n",
      "Testing 2610/5184\n",
      "0.1 1 2 3 log2 mae 0.75 100: Weighted 0.771120 (0.060452)\n",
      "0.1 1 2 3 log2 mae 0.75 100: Macro 0.645180 (0.085911)\n",
      "Testing 2611/5184\n",
      "0.1 1 2 3 log2 mae 0.75 200: Weighted 0.763019 (0.059212)\n",
      "0.1 1 2 3 log2 mae 0.75 200: Macro 0.631806 (0.090866)\n",
      "Testing 2612/5184\n",
      "0.1 1 2 3 log2 mae 0.75 500: Weighted 0.775458 (0.079201)\n",
      "0.1 1 2 3 log2 mae 0.75 500: Macro 0.645802 (0.113415)\n",
      "Testing 2613/5184\n",
      "0.1 1 2 3 log2 mae 1.0 50: Weighted 0.774303 (0.055174)\n",
      "0.1 1 2 3 log2 mae 1.0 50: Macro 0.654204 (0.074579)\n",
      "Testing 2614/5184\n",
      "0.1 1 2 3 log2 mae 1.0 100: Weighted 0.758592 (0.072947)\n",
      "0.1 1 2 3 log2 mae 1.0 100: Macro 0.634623 (0.107586)\n",
      "Testing 2615/5184\n",
      "0.1 1 2 3 log2 mae 1.0 200: Weighted 0.757282 (0.057380)\n",
      "0.1 1 2 3 log2 mae 1.0 200: Macro 0.609821 (0.080227)\n",
      "Testing 2616/5184\n",
      "0.1 1 2 3 log2 mae 1.0 500: Weighted 0.768345 (0.072679)\n",
      "0.1 1 2 3 log2 mae 1.0 500: Macro 0.623611 (0.110455)\n",
      "Testing 2617/5184\n",
      "0.1 1 2 3 sqrt friedman_mse 0.5 50: Weighted 0.805774 (0.066189)\n",
      "0.1 1 2 3 sqrt friedman_mse 0.5 50: Macro 0.705877 (0.077666)\n",
      "Testing 2618/5184\n",
      "0.1 1 2 3 sqrt friedman_mse 0.5 100: Weighted 0.791754 (0.062795)\n",
      "0.1 1 2 3 sqrt friedman_mse 0.5 100: Macro 0.682648 (0.086651)\n",
      "Testing 2619/5184\n",
      "0.1 1 2 3 sqrt friedman_mse 0.5 200: Weighted 0.799134 (0.080556)\n",
      "0.1 1 2 3 sqrt friedman_mse 0.5 200: Macro 0.695709 (0.113456)\n",
      "Testing 2620/5184\n",
      "0.1 1 2 3 sqrt friedman_mse 0.5 500: Weighted 0.806178 (0.064527)\n",
      "0.1 1 2 3 sqrt friedman_mse 0.5 500: Macro 0.709232 (0.096459)\n",
      "Testing 2621/5184\n",
      "0.1 1 2 3 sqrt friedman_mse 0.75 50: Weighted 0.808841 (0.075114)\n",
      "0.1 1 2 3 sqrt friedman_mse 0.75 50: Macro 0.710411 (0.097223)\n",
      "Testing 2622/5184\n",
      "0.1 1 2 3 sqrt friedman_mse 0.75 100: Weighted 0.807737 (0.054432)\n",
      "0.1 1 2 3 sqrt friedman_mse 0.75 100: Macro 0.708525 (0.072257)\n",
      "Testing 2623/5184\n",
      "0.1 1 2 3 sqrt friedman_mse 0.75 200: Weighted 0.798706 (0.056566)\n",
      "0.1 1 2 3 sqrt friedman_mse 0.75 200: Macro 0.699233 (0.090103)\n",
      "Testing 2624/5184\n",
      "0.1 1 2 3 sqrt friedman_mse 0.75 500: Weighted 0.797913 (0.067454)\n",
      "0.1 1 2 3 sqrt friedman_mse 0.75 500: Macro 0.697079 (0.109109)\n",
      "Testing 2625/5184\n",
      "0.1 1 2 3 sqrt friedman_mse 1.0 50: Weighted 0.792013 (0.050787)\n",
      "0.1 1 2 3 sqrt friedman_mse 1.0 50: Macro 0.687281 (0.074474)\n",
      "Testing 2626/5184\n",
      "0.1 1 2 3 sqrt friedman_mse 1.0 100: Weighted 0.794106 (0.053060)\n",
      "0.1 1 2 3 sqrt friedman_mse 1.0 100: Macro 0.692199 (0.085268)\n",
      "Testing 2627/5184\n",
      "0.1 1 2 3 sqrt friedman_mse 1.0 200: Weighted 0.793603 (0.055362)\n",
      "0.1 1 2 3 sqrt friedman_mse 1.0 200: Macro 0.692720 (0.088135)\n",
      "Testing 2628/5184\n",
      "0.1 1 2 3 sqrt friedman_mse 1.0 500: Weighted 0.789514 (0.063430)\n",
      "0.1 1 2 3 sqrt friedman_mse 1.0 500: Macro 0.688178 (0.093754)\n",
      "Testing 2629/5184\n",
      "0.1 1 2 3 sqrt mae 0.5 50: Weighted 0.798948 (0.060553)\n",
      "0.1 1 2 3 sqrt mae 0.5 50: Macro 0.677746 (0.084514)\n",
      "Testing 2630/5184\n",
      "0.1 1 2 3 sqrt mae 0.5 100: Weighted 0.794259 (0.052575)\n",
      "0.1 1 2 3 sqrt mae 0.5 100: Macro 0.678192 (0.075551)\n",
      "Testing 2631/5184\n",
      "0.1 1 2 3 sqrt mae 0.5 200: Weighted 0.777330 (0.056813)\n",
      "0.1 1 2 3 sqrt mae 0.5 200: Macro 0.660195 (0.078462)\n",
      "Testing 2632/5184\n",
      "0.1 1 2 3 sqrt mae 0.5 500: Weighted 0.763145 (0.054881)\n",
      "0.1 1 2 3 sqrt mae 0.5 500: Macro 0.632959 (0.081256)\n",
      "Testing 2633/5184\n",
      "0.1 1 2 3 sqrt mae 0.75 50: Weighted 0.779472 (0.071927)\n",
      "0.1 1 2 3 sqrt mae 0.75 50: Macro 0.663564 (0.096970)\n",
      "Testing 2634/5184\n",
      "0.1 1 2 3 sqrt mae 0.75 100: Weighted 0.761882 (0.059578)\n",
      "0.1 1 2 3 sqrt mae 0.75 100: Macro 0.640809 (0.085941)\n",
      "Testing 2635/5184\n",
      "0.1 1 2 3 sqrt mae 0.75 200: Weighted 0.764427 (0.071183)\n",
      "0.1 1 2 3 sqrt mae 0.75 200: Macro 0.627839 (0.110393)\n",
      "Testing 2636/5184\n",
      "0.1 1 2 3 sqrt mae 0.75 500: Weighted 0.789880 (0.088780)\n",
      "0.1 1 2 3 sqrt mae 0.75 500: Macro 0.674043 (0.133322)\n",
      "Testing 2637/5184\n",
      "0.1 1 2 3 sqrt mae 1.0 50: Weighted 0.782397 (0.055166)\n",
      "0.1 1 2 3 sqrt mae 1.0 50: Macro 0.667246 (0.078768)\n",
      "Testing 2638/5184\n",
      "0.1 1 2 3 sqrt mae 1.0 100: Weighted 0.768960 (0.064251)\n",
      "0.1 1 2 3 sqrt mae 1.0 100: Macro 0.640001 (0.101314)\n",
      "Testing 2639/5184\n",
      "0.1 1 2 3 sqrt mae 1.0 200: Weighted 0.749838 (0.065860)\n",
      "0.1 1 2 3 sqrt mae 1.0 200: Macro 0.608715 (0.094089)\n",
      "Testing 2640/5184\n",
      "0.1 1 2 3 sqrt mae 1.0 500: Weighted 0.759494 (0.074511)\n",
      "0.1 1 2 3 sqrt mae 1.0 500: Macro 0.616137 (0.114984)\n",
      "Testing 2641/5184\n",
      "0.1 1 2 5 log2 friedman_mse 0.5 50: Weighted 0.829280 (0.072625)\n",
      "0.1 1 2 5 log2 friedman_mse 0.5 50: Macro 0.728065 (0.109581)\n",
      "Testing 2642/5184\n",
      "0.1 1 2 5 log2 friedman_mse 0.5 100: Weighted 0.822867 (0.083964)\n",
      "0.1 1 2 5 log2 friedman_mse 0.5 100: Macro 0.727120 (0.130469)\n",
      "Testing 2643/5184\n",
      "0.1 1 2 5 log2 friedman_mse 0.5 200: Weighted 0.820783 (0.097370)\n",
      "0.1 1 2 5 log2 friedman_mse 0.5 200: Macro 0.727114 (0.141561)\n",
      "Testing 2644/5184\n",
      "0.1 1 2 5 log2 friedman_mse 0.5 500: Weighted 0.819990 (0.080682)\n",
      "0.1 1 2 5 log2 friedman_mse 0.5 500: Macro 0.725111 (0.110705)\n",
      "Testing 2645/5184\n",
      "0.1 1 2 5 log2 friedman_mse 0.75 50: Weighted 0.811927 (0.066277)\n",
      "0.1 1 2 5 log2 friedman_mse 0.75 50: Macro 0.713161 (0.096279)\n",
      "Testing 2646/5184\n",
      "0.1 1 2 5 log2 friedman_mse 0.75 100: Weighted 0.821020 (0.076347)\n",
      "0.1 1 2 5 log2 friedman_mse 0.75 100: Macro 0.727042 (0.105375)\n",
      "Testing 2647/5184\n",
      "0.1 1 2 5 log2 friedman_mse 0.75 200: Weighted 0.805490 (0.059019)\n",
      "0.1 1 2 5 log2 friedman_mse 0.75 200: Macro 0.704729 (0.095556)\n",
      "Testing 2648/5184\n",
      "0.1 1 2 5 log2 friedman_mse 0.75 500: Weighted 0.804219 (0.074423)\n",
      "0.1 1 2 5 log2 friedman_mse 0.75 500: Macro 0.695787 (0.115238)\n",
      "Testing 2649/5184\n",
      "0.1 1 2 5 log2 friedman_mse 1.0 50: Weighted 0.802452 (0.061904)\n",
      "0.1 1 2 5 log2 friedman_mse 1.0 50: Macro 0.709554 (0.095199)\n",
      "Testing 2650/5184\n",
      "0.1 1 2 5 log2 friedman_mse 1.0 100: Weighted 0.784744 (0.082436)\n",
      "0.1 1 2 5 log2 friedman_mse 1.0 100: Macro 0.676906 (0.124337)\n",
      "Testing 2651/5184\n",
      "0.1 1 2 5 log2 friedman_mse 1.0 200: Weighted 0.805637 (0.070380)\n",
      "0.1 1 2 5 log2 friedman_mse 1.0 200: Macro 0.709499 (0.105066)\n",
      "Testing 2652/5184\n",
      "0.1 1 2 5 log2 friedman_mse 1.0 500: Weighted 0.792223 (0.074868)\n",
      "0.1 1 2 5 log2 friedman_mse 1.0 500: Macro 0.688336 (0.120058)\n",
      "Testing 2653/5184\n",
      "0.1 1 2 5 log2 mae 0.5 50: Weighted 0.778962 (0.048958)\n",
      "0.1 1 2 5 log2 mae 0.5 50: Macro 0.655329 (0.079901)\n",
      "Testing 2654/5184\n",
      "0.1 1 2 5 log2 mae 0.5 100: Weighted 0.782663 (0.063605)\n",
      "0.1 1 2 5 log2 mae 0.5 100: Macro 0.664077 (0.089001)\n",
      "Testing 2655/5184\n",
      "0.1 1 2 5 log2 mae 0.5 200: Weighted 0.791951 (0.087214)\n",
      "0.1 1 2 5 log2 mae 0.5 200: Macro 0.675966 (0.128299)\n",
      "Testing 2656/5184\n",
      "0.1 1 2 5 log2 mae 0.5 500: Weighted 0.802117 (0.058071)\n",
      "0.1 1 2 5 log2 mae 0.5 500: Macro 0.688174 (0.083634)\n",
      "Testing 2657/5184\n",
      "0.1 1 2 5 log2 mae 0.75 50: Weighted 0.784471 (0.067195)\n",
      "0.1 1 2 5 log2 mae 0.75 50: Macro 0.655657 (0.103377)\n",
      "Testing 2658/5184\n",
      "0.1 1 2 5 log2 mae 0.75 100: Weighted 0.782535 (0.058022)\n",
      "0.1 1 2 5 log2 mae 0.75 100: Macro 0.657876 (0.086324)\n",
      "Testing 2659/5184\n",
      "0.1 1 2 5 log2 mae 0.75 200: Weighted 0.777427 (0.069717)\n",
      "0.1 1 2 5 log2 mae 0.75 200: Macro 0.649504 (0.098291)\n",
      "Testing 2660/5184\n",
      "0.1 1 2 5 log2 mae 0.75 500: Weighted 0.782890 (0.073843)\n",
      "0.1 1 2 5 log2 mae 0.75 500: Macro 0.657358 (0.108248)\n",
      "Testing 2661/5184\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1 1 2 5 log2 mae 1.0 50: Weighted 0.775770 (0.057702)\n",
      "0.1 1 2 5 log2 mae 1.0 50: Macro 0.648547 (0.081181)\n",
      "Testing 2662/5184\n",
      "0.1 1 2 5 log2 mae 1.0 100: Weighted 0.765041 (0.065344)\n",
      "0.1 1 2 5 log2 mae 1.0 100: Macro 0.633355 (0.097965)\n",
      "Testing 2663/5184\n",
      "0.1 1 2 5 log2 mae 1.0 200: Weighted 0.786481 (0.093995)\n",
      "0.1 1 2 5 log2 mae 1.0 200: Macro 0.661942 (0.125723)\n",
      "Testing 2664/5184\n",
      "0.1 1 2 5 log2 mae 1.0 500: Weighted 0.758229 (0.080734)\n",
      "0.1 1 2 5 log2 mae 1.0 500: Macro 0.623181 (0.114286)\n",
      "Testing 2665/5184\n",
      "0.1 1 2 5 sqrt friedman_mse 0.5 50: Weighted 0.823301 (0.071729)\n",
      "0.1 1 2 5 sqrt friedman_mse 0.5 50: Macro 0.728159 (0.095985)\n",
      "Testing 2666/5184\n",
      "0.1 1 2 5 sqrt friedman_mse 0.5 100: Weighted 0.811118 (0.071721)\n",
      "0.1 1 2 5 sqrt friedman_mse 0.5 100: Macro 0.705261 (0.094316)\n",
      "Testing 2667/5184\n",
      "0.1 1 2 5 sqrt friedman_mse 0.5 200: Weighted 0.825862 (0.081893)\n",
      "0.1 1 2 5 sqrt friedman_mse 0.5 200: Macro 0.737195 (0.122862)\n",
      "Testing 2668/5184\n",
      "0.1 1 2 5 sqrt friedman_mse 0.5 500: Weighted 0.810871 (0.063288)\n",
      "0.1 1 2 5 sqrt friedman_mse 0.5 500: Macro 0.711200 (0.087652)\n",
      "Testing 2669/5184\n",
      "0.1 1 2 5 sqrt friedman_mse 0.75 50: Weighted 0.805448 (0.078253)\n",
      "0.1 1 2 5 sqrt friedman_mse 0.75 50: Macro 0.699229 (0.116614)\n",
      "Testing 2670/5184\n",
      "0.1 1 2 5 sqrt friedman_mse 0.75 100: Weighted 0.807943 (0.079871)\n",
      "0.1 1 2 5 sqrt friedman_mse 0.75 100: Macro 0.705665 (0.105712)\n",
      "Testing 2671/5184\n",
      "0.1 1 2 5 sqrt friedman_mse 0.75 200: Weighted 0.797524 (0.068332)\n",
      "0.1 1 2 5 sqrt friedman_mse 0.75 200: Macro 0.696885 (0.102493)\n",
      "Testing 2672/5184\n",
      "0.1 1 2 5 sqrt friedman_mse 0.75 500: Weighted 0.799650 (0.076353)\n",
      "0.1 1 2 5 sqrt friedman_mse 0.75 500: Macro 0.694287 (0.112465)\n",
      "Testing 2673/5184\n",
      "0.1 1 2 5 sqrt friedman_mse 1.0 50: Weighted 0.802509 (0.067263)\n",
      "0.1 1 2 5 sqrt friedman_mse 1.0 50: Macro 0.705248 (0.100835)\n",
      "Testing 2674/5184\n",
      "0.1 1 2 5 sqrt friedman_mse 1.0 100: Weighted 0.802606 (0.064500)\n",
      "0.1 1 2 5 sqrt friedman_mse 1.0 100: Macro 0.707034 (0.094847)\n",
      "Testing 2675/5184\n",
      "0.1 1 2 5 sqrt friedman_mse 1.0 200: Weighted 0.788655 (0.075573)\n",
      "0.1 1 2 5 sqrt friedman_mse 1.0 200: Macro 0.683034 (0.122097)\n",
      "Testing 2676/5184\n",
      "0.1 1 2 5 sqrt friedman_mse 1.0 500: Weighted 0.794309 (0.070862)\n",
      "0.1 1 2 5 sqrt friedman_mse 1.0 500: Macro 0.688168 (0.108341)\n",
      "Testing 2677/5184\n",
      "0.1 1 2 5 sqrt mae 0.5 50: Weighted 0.794919 (0.037762)\n",
      "0.1 1 2 5 sqrt mae 0.5 50: Macro 0.678408 (0.059980)\n",
      "Testing 2678/5184\n",
      "0.1 1 2 5 sqrt mae 0.5 100: Weighted 0.797179 (0.064209)\n",
      "0.1 1 2 5 sqrt mae 0.5 100: Macro 0.689157 (0.097643)\n",
      "Testing 2679/5184\n",
      "0.1 1 2 5 sqrt mae 0.5 200: Weighted 0.787046 (0.062452)\n",
      "0.1 1 2 5 sqrt mae 0.5 200: Macro 0.663033 (0.096325)\n",
      "Testing 2680/5184\n",
      "0.1 1 2 5 sqrt mae 0.5 500: Weighted 0.799508 (0.087290)\n",
      "0.1 1 2 5 sqrt mae 0.5 500: Macro 0.697941 (0.126517)\n",
      "Testing 2681/5184\n",
      "0.1 1 2 5 sqrt mae 0.75 50: Weighted 0.781375 (0.042155)\n",
      "0.1 1 2 5 sqrt mae 0.75 50: Macro 0.659863 (0.058040)\n",
      "Testing 2682/5184\n",
      "0.1 1 2 5 sqrt mae 0.75 100: Weighted 0.768908 (0.061577)\n",
      "0.1 1 2 5 sqrt mae 0.75 100: Macro 0.639133 (0.090654)\n",
      "Testing 2683/5184\n",
      "0.1 1 2 5 sqrt mae 0.75 200: Weighted 0.789300 (0.095851)\n",
      "0.1 1 2 5 sqrt mae 0.75 200: Macro 0.669449 (0.146204)\n",
      "Testing 2684/5184\n",
      "0.1 1 2 5 sqrt mae 0.75 500: Weighted 0.791375 (0.078292)\n",
      "0.1 1 2 5 sqrt mae 0.75 500: Macro 0.676009 (0.114978)\n",
      "Testing 2685/5184\n",
      "0.1 1 2 5 sqrt mae 1.0 50: Weighted 0.778381 (0.079615)\n",
      "0.1 1 2 5 sqrt mae 1.0 50: Macro 0.653096 (0.118301)\n",
      "Testing 2686/5184\n",
      "0.1 1 2 5 sqrt mae 1.0 100: Weighted 0.767702 (0.069447)\n",
      "0.1 1 2 5 sqrt mae 1.0 100: Macro 0.629497 (0.097790)\n",
      "Testing 2687/5184\n",
      "0.1 1 2 5 sqrt mae 1.0 200: Weighted 0.777810 (0.067793)\n",
      "0.1 1 2 5 sqrt mae 1.0 200: Macro 0.649778 (0.102674)\n",
      "Testing 2688/5184\n",
      "0.1 1 2 5 sqrt mae 1.0 500: Weighted 0.787566 (0.062176)\n",
      "0.1 1 2 5 sqrt mae 1.0 500: Macro 0.667438 (0.083865)\n",
      "Testing 2689/5184\n",
      "0.1 1 2 8 log2 friedman_mse 0.5 50: Weighted 0.821501 (0.085575)\n",
      "0.1 1 2 8 log2 friedman_mse 0.5 50: Macro 0.724131 (0.123553)\n",
      "Testing 2690/5184\n",
      "0.1 1 2 8 log2 friedman_mse 0.5 100: Weighted 0.815261 (0.078916)\n",
      "0.1 1 2 8 log2 friedman_mse 0.5 100: Macro 0.705682 (0.110084)\n",
      "Testing 2691/5184\n",
      "0.1 1 2 8 log2 friedman_mse 0.5 200: Weighted 0.819656 (0.068682)\n",
      "0.1 1 2 8 log2 friedman_mse 0.5 200: Macro 0.724446 (0.101099)\n",
      "Testing 2692/5184\n",
      "0.1 1 2 8 log2 friedman_mse 0.5 500: Weighted 0.815670 (0.095291)\n",
      "0.1 1 2 8 log2 friedman_mse 0.5 500: Macro 0.719553 (0.136695)\n",
      "Testing 2693/5184\n",
      "0.1 1 2 8 log2 friedman_mse 0.75 50: Weighted 0.810842 (0.048817)\n",
      "0.1 1 2 8 log2 friedman_mse 0.75 50: Macro 0.708527 (0.068841)\n",
      "Testing 2694/5184\n",
      "0.1 1 2 8 log2 friedman_mse 0.75 100: Weighted 0.810156 (0.079147)\n",
      "0.1 1 2 8 log2 friedman_mse 0.75 100: Macro 0.708524 (0.109819)\n",
      "Testing 2695/5184\n",
      "0.1 1 2 8 log2 friedman_mse 0.75 200: Weighted 0.814233 (0.082052)\n",
      "0.1 1 2 8 log2 friedman_mse 0.75 200: Macro 0.717010 (0.114392)\n",
      "Testing 2696/5184\n",
      "0.1 1 2 8 log2 friedman_mse 0.75 500: Weighted 0.805561 (0.072546)\n",
      "0.1 1 2 8 log2 friedman_mse 0.75 500: Macro 0.704782 (0.104720)\n",
      "Testing 2697/5184\n",
      "0.1 1 2 8 log2 friedman_mse 1.0 50: Weighted 0.781044 (0.059528)\n",
      "0.1 1 2 8 log2 friedman_mse 1.0 50: Macro 0.677929 (0.090292)\n",
      "Testing 2698/5184\n",
      "0.1 1 2 8 log2 friedman_mse 1.0 100: Weighted 0.804099 (0.076384)\n",
      "0.1 1 2 8 log2 friedman_mse 1.0 100: Macro 0.694845 (0.111126)\n",
      "Testing 2699/5184\n",
      "0.1 1 2 8 log2 friedman_mse 1.0 200: Weighted 0.797394 (0.080991)\n",
      "0.1 1 2 8 log2 friedman_mse 1.0 200: Macro 0.685102 (0.117079)\n",
      "Testing 2700/5184\n",
      "0.1 1 2 8 log2 friedman_mse 1.0 500: Weighted 0.784380 (0.054608)\n",
      "0.1 1 2 8 log2 friedman_mse 1.0 500: Macro 0.671455 (0.087547)\n",
      "Testing 2701/5184\n",
      "0.1 1 2 8 log2 mae 0.5 50: Weighted 0.801002 (0.058770)\n",
      "0.1 1 2 8 log2 mae 0.5 50: Macro 0.683467 (0.081917)\n",
      "Testing 2702/5184\n",
      "0.1 1 2 8 log2 mae 0.5 100: Weighted 0.804046 (0.054791)\n",
      "0.1 1 2 8 log2 mae 0.5 100: Macro 0.693849 (0.084002)\n",
      "Testing 2703/5184\n",
      "0.1 1 2 8 log2 mae 0.5 200: Weighted 0.795097 (0.063828)\n",
      "0.1 1 2 8 log2 mae 0.5 200: Macro 0.681263 (0.090650)\n",
      "Testing 2704/5184\n",
      "0.1 1 2 8 log2 mae 0.5 500: Weighted 0.801928 (0.065979)\n",
      "0.1 1 2 8 log2 mae 0.5 500: Macro 0.697153 (0.094508)\n",
      "Testing 2705/5184\n",
      "0.1 1 2 8 log2 mae 0.75 50: Weighted 0.796259 (0.055664)\n",
      "0.1 1 2 8 log2 mae 0.75 50: Macro 0.677457 (0.082899)\n",
      "Testing 2706/5184\n",
      "0.1 1 2 8 log2 mae 0.75 100: Weighted 0.775906 (0.076046)\n",
      "0.1 1 2 8 log2 mae 0.75 100: Macro 0.649384 (0.120198)\n",
      "Testing 2707/5184\n",
      "0.1 1 2 8 log2 mae 0.75 200: Weighted 0.780676 (0.058545)\n",
      "0.1 1 2 8 log2 mae 0.75 200: Macro 0.660206 (0.077954)\n",
      "Testing 2708/5184\n",
      "0.1 1 2 8 log2 mae 0.75 500: Weighted 0.788344 (0.079226)\n",
      "0.1 1 2 8 log2 mae 0.75 500: Macro 0.680122 (0.111567)\n",
      "Testing 2709/5184\n",
      "0.1 1 2 8 log2 mae 1.0 50: Weighted 0.763378 (0.087020)\n",
      "0.1 1 2 8 log2 mae 1.0 50: Macro 0.629289 (0.130033)\n",
      "Testing 2710/5184\n",
      "0.1 1 2 8 log2 mae 1.0 100: Weighted 0.775974 (0.054530)\n",
      "0.1 1 2 8 log2 mae 1.0 100: Macro 0.647437 (0.078724)\n",
      "Testing 2711/5184\n",
      "0.1 1 2 8 log2 mae 1.0 200: Weighted 0.761702 (0.085591)\n",
      "0.1 1 2 8 log2 mae 1.0 200: Macro 0.637202 (0.111524)\n",
      "Testing 2712/5184\n",
      "0.1 1 2 8 log2 mae 1.0 500: Weighted 0.790420 (0.092199)\n",
      "0.1 1 2 8 log2 mae 1.0 500: Macro 0.670575 (0.127447)\n",
      "Testing 2713/5184\n",
      "0.1 1 2 8 sqrt friedman_mse 0.5 50: Weighted 0.807032 (0.054766)\n",
      "0.1 1 2 8 sqrt friedman_mse 0.5 50: Macro 0.699749 (0.073693)\n",
      "Testing 2714/5184\n",
      "0.1 1 2 8 sqrt friedman_mse 0.5 100: Weighted 0.832304 (0.083869)\n",
      "0.1 1 2 8 sqrt friedman_mse 0.5 100: Macro 0.736402 (0.119073)\n",
      "Testing 2715/5184\n",
      "0.1 1 2 8 sqrt friedman_mse 0.5 200: Weighted 0.819000 (0.082447)\n",
      "0.1 1 2 8 sqrt friedman_mse 0.5 200: Macro 0.719438 (0.118108)\n",
      "Testing 2716/5184\n",
      "0.1 1 2 8 sqrt friedman_mse 0.5 500: Weighted 0.815273 (0.081460)\n",
      "0.1 1 2 8 sqrt friedman_mse 0.5 500: Macro 0.714255 (0.114712)\n",
      "Testing 2717/5184\n",
      "0.1 1 2 8 sqrt friedman_mse 0.75 50: Weighted 0.801926 (0.065790)\n",
      "0.1 1 2 8 sqrt friedman_mse 0.75 50: Macro 0.697255 (0.095768)\n",
      "Testing 2718/5184\n",
      "0.1 1 2 8 sqrt friedman_mse 0.75 100: Weighted 0.801793 (0.080441)\n",
      "0.1 1 2 8 sqrt friedman_mse 0.75 100: Macro 0.696030 (0.110545)\n",
      "Testing 2719/5184\n",
      "0.1 1 2 8 sqrt friedman_mse 0.75 200: Weighted 0.802523 (0.068858)\n",
      "0.1 1 2 8 sqrt friedman_mse 0.75 200: Macro 0.702213 (0.096352)\n",
      "Testing 2720/5184\n",
      "0.1 1 2 8 sqrt friedman_mse 0.75 500: Weighted 0.802773 (0.064677)\n",
      "0.1 1 2 8 sqrt friedman_mse 0.75 500: Macro 0.699257 (0.101555)\n",
      "Testing 2721/5184\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1 1 2 8 sqrt friedman_mse 1.0 50: Weighted 0.777646 (0.068682)\n",
      "0.1 1 2 8 sqrt friedman_mse 1.0 50: Macro 0.663378 (0.105614)\n",
      "Testing 2722/5184\n",
      "0.1 1 2 8 sqrt friedman_mse 1.0 100: Weighted 0.780233 (0.055825)\n",
      "0.1 1 2 8 sqrt friedman_mse 1.0 100: Macro 0.668967 (0.091657)\n",
      "Testing 2723/5184\n",
      "0.1 1 2 8 sqrt friedman_mse 1.0 200: Weighted 0.777212 (0.051845)\n",
      "0.1 1 2 8 sqrt friedman_mse 1.0 200: Macro 0.669899 (0.086542)\n",
      "Testing 2724/5184\n",
      "0.1 1 2 8 sqrt friedman_mse 1.0 500: Weighted 0.794313 (0.063103)\n",
      "0.1 1 2 8 sqrt friedman_mse 1.0 500: Macro 0.687175 (0.101805)\n",
      "Testing 2725/5184\n",
      "0.1 1 2 8 sqrt mae 0.5 50: Weighted 0.791657 (0.069175)\n",
      "0.1 1 2 8 sqrt mae 0.5 50: Macro 0.660195 (0.099337)\n",
      "Testing 2726/5184\n",
      "0.1 1 2 8 sqrt mae 0.5 100: Weighted 0.787024 (0.067216)\n",
      "0.1 1 2 8 sqrt mae 0.5 100: Macro 0.664258 (0.103709)\n",
      "Testing 2727/5184\n",
      "0.1 1 2 8 sqrt mae 0.5 200: Weighted 0.796177 (0.054760)\n",
      "0.1 1 2 8 sqrt mae 0.5 200: Macro 0.679572 (0.087056)\n",
      "Testing 2728/5184\n",
      "0.1 1 2 8 sqrt mae 0.5 500: Weighted 0.799595 (0.064616)\n",
      "0.1 1 2 8 sqrt mae 0.5 500: Macro 0.693359 (0.087368)\n",
      "Testing 2729/5184\n",
      "0.1 1 2 8 sqrt mae 0.75 50: Weighted 0.791729 (0.040138)\n",
      "0.1 1 2 8 sqrt mae 0.75 50: Macro 0.675866 (0.054783)\n",
      "Testing 2730/5184\n",
      "0.1 1 2 8 sqrt mae 0.75 100: Weighted 0.795185 (0.073904)\n",
      "0.1 1 2 8 sqrt mae 0.75 100: Macro 0.680406 (0.116110)\n",
      "Testing 2731/5184\n",
      "0.1 1 2 8 sqrt mae 0.75 200: Weighted 0.784736 (0.083777)\n",
      "0.1 1 2 8 sqrt mae 0.75 200: Macro 0.667470 (0.126660)\n",
      "Testing 2732/5184\n",
      "0.1 1 2 8 sqrt mae 0.75 500: Weighted 0.788100 (0.088744)\n",
      "0.1 1 2 8 sqrt mae 0.75 500: Macro 0.682459 (0.124940)\n",
      "Testing 2733/5184\n",
      "0.1 1 2 8 sqrt mae 1.0 50: Weighted 0.776379 (0.074305)\n",
      "0.1 1 2 8 sqrt mae 1.0 50: Macro 0.650059 (0.104414)\n",
      "Testing 2734/5184\n",
      "0.1 1 2 8 sqrt mae 1.0 100: Weighted 0.780895 (0.059920)\n",
      "0.1 1 2 8 sqrt mae 1.0 100: Macro 0.665850 (0.078565)\n",
      "Testing 2735/5184\n",
      "0.1 1 2 8 sqrt mae 1.0 200: Weighted 0.774787 (0.094767)\n",
      "0.1 1 2 8 sqrt mae 1.0 200: Macro 0.644222 (0.137711)\n",
      "Testing 2736/5184\n",
      "0.1 1 2 8 sqrt mae 1.0 500: Weighted 0.779999 (0.095951)\n",
      "0.1 1 2 8 sqrt mae 1.0 500: Macro 0.658488 (0.133931)\n",
      "Testing 2737/5184\n",
      "0.1 1 4 3 log2 friedman_mse 0.5 50: Weighted 0.807740 (0.063836)\n",
      "0.1 1 4 3 log2 friedman_mse 0.5 50: Macro 0.708170 (0.090075)\n",
      "Testing 2738/5184\n",
      "0.1 1 4 3 log2 friedman_mse 0.5 100: Weighted 0.819179 (0.061265)\n",
      "0.1 1 4 3 log2 friedman_mse 0.5 100: Macro 0.720493 (0.086247)\n",
      "Testing 2739/5184\n",
      "0.1 1 4 3 log2 friedman_mse 0.5 200: Weighted 0.815751 (0.060216)\n",
      "0.1 1 4 3 log2 friedman_mse 0.5 200: Macro 0.703517 (0.092823)\n",
      "Testing 2740/5184\n",
      "0.1 1 4 3 log2 friedman_mse 0.5 500: Weighted 0.800519 (0.052423)\n",
      "0.1 1 4 3 log2 friedman_mse 0.5 500: Macro 0.685504 (0.072482)\n",
      "Testing 2741/5184\n",
      "0.1 1 4 3 log2 friedman_mse 0.75 50: Weighted 0.807348 (0.082263)\n",
      "0.1 1 4 3 log2 friedman_mse 0.75 50: Macro 0.707663 (0.111359)\n",
      "Testing 2742/5184\n",
      "0.1 1 4 3 log2 friedman_mse 0.75 100: Weighted 0.808889 (0.069304)\n",
      "0.1 1 4 3 log2 friedman_mse 0.75 100: Macro 0.708032 (0.100376)\n",
      "Testing 2743/5184\n",
      "0.1 1 4 3 log2 friedman_mse 0.75 200: Weighted 0.797936 (0.071271)\n",
      "0.1 1 4 3 log2 friedman_mse 0.75 200: Macro 0.693737 (0.110184)\n",
      "Testing 2744/5184\n",
      "0.1 1 4 3 log2 friedman_mse 0.75 500: Weighted 0.790968 (0.066680)\n",
      "0.1 1 4 3 log2 friedman_mse 0.75 500: Macro 0.683739 (0.098948)\n",
      "Testing 2745/5184\n",
      "0.1 1 4 3 log2 friedman_mse 1.0 50: Weighted 0.793711 (0.061586)\n",
      "0.1 1 4 3 log2 friedman_mse 1.0 50: Macro 0.681297 (0.079567)\n",
      "Testing 2746/5184\n",
      "0.1 1 4 3 log2 friedman_mse 1.0 100: Weighted 0.807349 (0.042916)\n",
      "0.1 1 4 3 log2 friedman_mse 1.0 100: Macro 0.704785 (0.067908)\n",
      "Testing 2747/5184\n",
      "0.1 1 4 3 log2 friedman_mse 1.0 200: Weighted 0.793087 (0.062191)\n",
      "0.1 1 4 3 log2 friedman_mse 1.0 200: Macro 0.686218 (0.094517)\n",
      "Testing 2748/5184\n",
      "0.1 1 4 3 log2 friedman_mse 1.0 500: Weighted 0.793132 (0.062245)\n",
      "0.1 1 4 3 log2 friedman_mse 1.0 500: Macro 0.690025 (0.099110)\n",
      "Testing 2749/5184\n",
      "0.1 1 4 3 log2 mae 0.5 50: Weighted 0.797580 (0.052766)\n",
      "0.1 1 4 3 log2 mae 0.5 50: Macro 0.684180 (0.075545)\n",
      "Testing 2750/5184\n",
      "0.1 1 4 3 log2 mae 0.5 100: Weighted 0.795231 (0.052766)\n",
      "0.1 1 4 3 log2 mae 0.5 100: Macro 0.688274 (0.074391)\n",
      "Testing 2751/5184\n",
      "0.1 1 4 3 log2 mae 0.5 200: Weighted 0.794799 (0.054909)\n",
      "0.1 1 4 3 log2 mae 0.5 200: Macro 0.676950 (0.074382)\n",
      "Testing 2752/5184\n",
      "0.1 1 4 3 log2 mae 0.5 500: Weighted 0.783577 (0.077253)\n",
      "0.1 1 4 3 log2 mae 0.5 500: Macro 0.662718 (0.113763)\n",
      "Testing 2753/5184\n",
      "0.1 1 4 3 log2 mae 0.75 50: Weighted 0.776658 (0.043356)\n",
      "0.1 1 4 3 log2 mae 0.75 50: Macro 0.653947 (0.071395)\n",
      "Testing 2754/5184\n",
      "0.1 1 4 3 log2 mae 0.75 100: Weighted 0.770587 (0.061829)\n",
      "0.1 1 4 3 log2 mae 0.75 100: Macro 0.647954 (0.080822)\n",
      "Testing 2755/5184\n",
      "0.1 1 4 3 log2 mae 0.75 200: Weighted 0.762223 (0.056924)\n",
      "0.1 1 4 3 log2 mae 0.75 200: Macro 0.625174 (0.085284)\n",
      "Testing 2756/5184\n",
      "0.1 1 4 3 log2 mae 0.75 500: Weighted 0.772655 (0.086089)\n",
      "0.1 1 4 3 log2 mae 0.75 500: Macro 0.647120 (0.119173)\n",
      "Testing 2757/5184\n",
      "0.1 1 4 3 log2 mae 1.0 50: Weighted 0.762222 (0.066908)\n",
      "0.1 1 4 3 log2 mae 1.0 50: Macro 0.642053 (0.093456)\n",
      "Testing 2758/5184\n",
      "0.1 1 4 3 log2 mae 1.0 100: Weighted 0.766752 (0.080136)\n",
      "0.1 1 4 3 log2 mae 1.0 100: Macro 0.635611 (0.120581)\n",
      "Testing 2759/5184\n",
      "0.1 1 4 3 log2 mae 1.0 200: Weighted 0.747023 (0.047970)\n",
      "0.1 1 4 3 log2 mae 1.0 200: Macro 0.594811 (0.066662)\n",
      "Testing 2760/5184\n",
      "0.1 1 4 3 log2 mae 1.0 500: Weighted 0.769585 (0.051129)\n",
      "0.1 1 4 3 log2 mae 1.0 500: Macro 0.630292 (0.069139)\n",
      "Testing 2761/5184\n",
      "0.1 1 4 3 sqrt friedman_mse 0.5 50: Weighted 0.806423 (0.045166)\n",
      "0.1 1 4 3 sqrt friedman_mse 0.5 50: Macro 0.696269 (0.051556)\n",
      "Testing 2762/5184\n",
      "0.1 1 4 3 sqrt friedman_mse 0.5 100: Weighted 0.809975 (0.047215)\n",
      "0.1 1 4 3 sqrt friedman_mse 0.5 100: Macro 0.703874 (0.067014)\n",
      "Testing 2763/5184\n",
      "0.1 1 4 3 sqrt friedman_mse 0.5 200: Weighted 0.807629 (0.071075)\n",
      "0.1 1 4 3 sqrt friedman_mse 0.5 200: Macro 0.702271 (0.105453)\n",
      "Testing 2764/5184\n",
      "0.1 1 4 3 sqrt friedman_mse 0.5 500: Weighted 0.797775 (0.045274)\n",
      "0.1 1 4 3 sqrt friedman_mse 0.5 500: Macro 0.679726 (0.067877)\n",
      "Testing 2765/5184\n",
      "0.1 1 4 3 sqrt friedman_mse 0.75 50: Weighted 0.816826 (0.083793)\n",
      "0.1 1 4 3 sqrt friedman_mse 0.75 50: Macro 0.720804 (0.115881)\n",
      "Testing 2766/5184\n",
      "0.1 1 4 3 sqrt friedman_mse 0.75 100: Weighted 0.797833 (0.047617)\n",
      "0.1 1 4 3 sqrt friedman_mse 0.75 100: Macro 0.693088 (0.075178)\n",
      "Testing 2767/5184\n",
      "0.1 1 4 3 sqrt friedman_mse 0.75 200: Weighted 0.793977 (0.071688)\n",
      "0.1 1 4 3 sqrt friedman_mse 0.75 200: Macro 0.690455 (0.106141)\n",
      "Testing 2768/5184\n",
      "0.1 1 4 3 sqrt friedman_mse 0.75 500: Weighted 0.797237 (0.063194)\n",
      "0.1 1 4 3 sqrt friedman_mse 0.75 500: Macro 0.690995 (0.096668)\n",
      "Testing 2769/5184\n",
      "0.1 1 4 3 sqrt friedman_mse 1.0 50: Weighted 0.796984 (0.055604)\n",
      "0.1 1 4 3 sqrt friedman_mse 1.0 50: Macro 0.694873 (0.072937)\n",
      "Testing 2770/5184\n",
      "0.1 1 4 3 sqrt friedman_mse 1.0 100: Weighted 0.802988 (0.063473)\n",
      "0.1 1 4 3 sqrt friedman_mse 1.0 100: Macro 0.704456 (0.096294)\n",
      "Testing 2771/5184\n",
      "0.1 1 4 3 sqrt friedman_mse 1.0 200: Weighted 0.792199 (0.053134)\n",
      "0.1 1 4 3 sqrt friedman_mse 1.0 200: Macro 0.687401 (0.085034)\n",
      "Testing 2772/5184\n",
      "0.1 1 4 3 sqrt friedman_mse 1.0 500: Weighted 0.793272 (0.061842)\n",
      "0.1 1 4 3 sqrt friedman_mse 1.0 500: Macro 0.691654 (0.096724)\n",
      "Testing 2773/5184\n",
      "0.1 1 4 3 sqrt mae 0.5 50: Weighted 0.803490 (0.035696)\n",
      "0.1 1 4 3 sqrt mae 0.5 50: Macro 0.695239 (0.059507)\n",
      "Testing 2774/5184\n",
      "0.1 1 4 3 sqrt mae 0.5 100: Weighted 0.781101 (0.049892)\n",
      "0.1 1 4 3 sqrt mae 0.5 100: Macro 0.661049 (0.071596)\n",
      "Testing 2775/5184\n",
      "0.1 1 4 3 sqrt mae 0.5 200: Weighted 0.783496 (0.057084)\n",
      "0.1 1 4 3 sqrt mae 0.5 200: Macro 0.665831 (0.080589)\n",
      "Testing 2776/5184\n",
      "0.1 1 4 3 sqrt mae 0.5 500: Weighted 0.788173 (0.060714)\n",
      "0.1 1 4 3 sqrt mae 0.5 500: Macro 0.666426 (0.090661)\n",
      "Testing 2777/5184\n",
      "0.1 1 4 3 sqrt mae 0.75 50: Weighted 0.790208 (0.056239)\n",
      "0.1 1 4 3 sqrt mae 0.75 50: Macro 0.672714 (0.080486)\n",
      "Testing 2778/5184\n",
      "0.1 1 4 3 sqrt mae 0.75 100: Weighted 0.783611 (0.066624)\n",
      "0.1 1 4 3 sqrt mae 0.75 100: Macro 0.663952 (0.089010)\n",
      "Testing 2779/5184\n",
      "0.1 1 4 3 sqrt mae 0.75 200: Weighted 0.753612 (0.053796)\n",
      "0.1 1 4 3 sqrt mae 0.75 200: Macro 0.612295 (0.073746)\n",
      "Testing 2780/5184\n",
      "0.1 1 4 3 sqrt mae 0.75 500: Weighted 0.764473 (0.058302)\n",
      "0.1 1 4 3 sqrt mae 0.75 500: Macro 0.628079 (0.084351)\n",
      "Testing 2781/5184\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1 1 4 3 sqrt mae 1.0 50: Weighted 0.759964 (0.054277)\n",
      "0.1 1 4 3 sqrt mae 1.0 50: Macro 0.636152 (0.067504)\n",
      "Testing 2782/5184\n",
      "0.1 1 4 3 sqrt mae 1.0 100: Weighted 0.757102 (0.064189)\n",
      "0.1 1 4 3 sqrt mae 1.0 100: Macro 0.623246 (0.091248)\n",
      "Testing 2783/5184\n",
      "0.1 1 4 3 sqrt mae 1.0 200: Weighted 0.748153 (0.056636)\n",
      "0.1 1 4 3 sqrt mae 1.0 200: Macro 0.603198 (0.081410)\n",
      "Testing 2784/5184\n",
      "0.1 1 4 3 sqrt mae 1.0 500: Weighted 0.760360 (0.069548)\n",
      "0.1 1 4 3 sqrt mae 1.0 500: Macro 0.621424 (0.098842)\n",
      "Testing 2785/5184\n",
      "0.1 1 4 5 log2 friedman_mse 0.5 50: Weighted 0.821633 (0.074889)\n",
      "0.1 1 4 5 log2 friedman_mse 0.5 50: Macro 0.720946 (0.106414)\n",
      "Testing 2786/5184\n",
      "0.1 1 4 5 log2 friedman_mse 0.5 100: Weighted 0.817182 (0.072137)\n",
      "0.1 1 4 5 log2 friedman_mse 0.5 100: Macro 0.721110 (0.105330)\n",
      "Testing 2787/5184\n",
      "0.1 1 4 5 log2 friedman_mse 0.5 200: Weighted 0.806484 (0.062486)\n",
      "0.1 1 4 5 log2 friedman_mse 0.5 200: Macro 0.699578 (0.092601)\n",
      "Testing 2788/5184\n",
      "0.1 1 4 5 log2 friedman_mse 0.5 500: Weighted 0.810724 (0.068436)\n",
      "0.1 1 4 5 log2 friedman_mse 0.5 500: Macro 0.707737 (0.102568)\n",
      "Testing 2789/5184\n",
      "0.1 1 4 5 log2 friedman_mse 0.75 50: Weighted 0.795444 (0.061812)\n",
      "0.1 1 4 5 log2 friedman_mse 0.75 50: Macro 0.695128 (0.087715)\n",
      "Testing 2790/5184\n",
      "0.1 1 4 5 log2 friedman_mse 0.75 100: Weighted 0.816839 (0.089796)\n",
      "0.1 1 4 5 log2 friedman_mse 0.75 100: Macro 0.719043 (0.129130)\n",
      "Testing 2791/5184\n",
      "0.1 1 4 5 log2 friedman_mse 0.75 200: Weighted 0.797669 (0.088931)\n",
      "0.1 1 4 5 log2 friedman_mse 0.75 200: Macro 0.689860 (0.133828)\n",
      "Testing 2792/5184\n",
      "0.1 1 4 5 log2 friedman_mse 0.75 500: Weighted 0.798967 (0.087458)\n",
      "0.1 1 4 5 log2 friedman_mse 0.75 500: Macro 0.693154 (0.129350)\n",
      "Testing 2793/5184\n",
      "0.1 1 4 5 log2 friedman_mse 1.0 50: Weighted 0.807447 (0.082469)\n",
      "0.1 1 4 5 log2 friedman_mse 1.0 50: Macro 0.703319 (0.115077)\n",
      "Testing 2794/5184\n",
      "0.1 1 4 5 log2 friedman_mse 1.0 100: Weighted 0.802725 (0.072672)\n",
      "0.1 1 4 5 log2 friedman_mse 1.0 100: Macro 0.704291 (0.110070)\n",
      "Testing 2795/5184\n",
      "0.1 1 4 5 log2 friedman_mse 1.0 200: Weighted 0.792714 (0.061229)\n",
      "0.1 1 4 5 log2 friedman_mse 1.0 200: Macro 0.692342 (0.101335)\n",
      "Testing 2796/5184\n",
      "0.1 1 4 5 log2 friedman_mse 1.0 500: Weighted 0.799736 (0.085246)\n",
      "0.1 1 4 5 log2 friedman_mse 1.0 500: Macro 0.702257 (0.128629)\n",
      "Testing 2797/5184\n",
      "0.1 1 4 5 log2 mae 0.5 50: Weighted 0.807842 (0.033371)\n",
      "0.1 1 4 5 log2 mae 0.5 50: Macro 0.700086 (0.050373)\n",
      "Testing 2798/5184\n",
      "0.1 1 4 5 log2 mae 0.5 100: Weighted 0.777291 (0.052802)\n",
      "0.1 1 4 5 log2 mae 0.5 100: Macro 0.642225 (0.082494)\n",
      "Testing 2799/5184\n",
      "0.1 1 4 5 log2 mae 0.5 200: Weighted 0.793887 (0.057401)\n",
      "0.1 1 4 5 log2 mae 0.5 200: Macro 0.676071 (0.091515)\n",
      "Testing 2800/5184\n",
      "0.1 1 4 5 log2 mae 0.5 500: Weighted 0.802943 (0.084033)\n",
      "0.1 1 4 5 log2 mae 0.5 500: Macro 0.694606 (0.126741)\n",
      "Testing 2801/5184\n",
      "0.1 1 4 5 log2 mae 0.75 50: Weighted 0.776768 (0.047871)\n",
      "0.1 1 4 5 log2 mae 0.75 50: Macro 0.659276 (0.064630)\n",
      "Testing 2802/5184\n",
      "0.1 1 4 5 log2 mae 0.75 100: Weighted 0.791767 (0.066599)\n",
      "0.1 1 4 5 log2 mae 0.75 100: Macro 0.672555 (0.091574)\n",
      "Testing 2803/5184\n",
      "0.1 1 4 5 log2 mae 0.75 200: Weighted 0.764042 (0.056344)\n",
      "0.1 1 4 5 log2 mae 0.75 200: Macro 0.626680 (0.075772)\n",
      "Testing 2804/5184\n",
      "0.1 1 4 5 log2 mae 0.75 500: Weighted 0.789355 (0.075620)\n",
      "0.1 1 4 5 log2 mae 0.75 500: Macro 0.667682 (0.115209)\n",
      "Testing 2805/5184\n",
      "0.1 1 4 5 log2 mae 1.0 50: Weighted 0.772796 (0.077050)\n",
      "0.1 1 4 5 log2 mae 1.0 50: Macro 0.650346 (0.118713)\n",
      "Testing 2806/5184\n",
      "0.1 1 4 5 log2 mae 1.0 100: Weighted 0.781246 (0.066947)\n",
      "0.1 1 4 5 log2 mae 1.0 100: Macro 0.651041 (0.091976)\n",
      "Testing 2807/5184\n",
      "0.1 1 4 5 log2 mae 1.0 200: Weighted 0.758891 (0.053443)\n",
      "0.1 1 4 5 log2 mae 1.0 200: Macro 0.617003 (0.065312)\n",
      "Testing 2808/5184\n",
      "0.1 1 4 5 log2 mae 1.0 500: Weighted 0.775627 (0.075274)\n",
      "0.1 1 4 5 log2 mae 1.0 500: Macro 0.635142 (0.105651)\n",
      "Testing 2809/5184\n",
      "0.1 1 4 5 sqrt friedman_mse 0.5 50: Weighted 0.810015 (0.080026)\n",
      "0.1 1 4 5 sqrt friedman_mse 0.5 50: Macro 0.710031 (0.108927)\n",
      "Testing 2810/5184\n",
      "0.1 1 4 5 sqrt friedman_mse 0.5 100: Weighted 0.817113 (0.079525)\n",
      "0.1 1 4 5 sqrt friedman_mse 0.5 100: Macro 0.720658 (0.108916)\n",
      "Testing 2811/5184\n",
      "0.1 1 4 5 sqrt friedman_mse 0.5 200: Weighted 0.803800 (0.072584)\n",
      "0.1 1 4 5 sqrt friedman_mse 0.5 200: Macro 0.702357 (0.113141)\n",
      "Testing 2812/5184\n",
      "0.1 1 4 5 sqrt friedman_mse 0.5 500: Weighted 0.796512 (0.079696)\n",
      "0.1 1 4 5 sqrt friedman_mse 0.5 500: Macro 0.690834 (0.125156)\n",
      "Testing 2813/5184\n",
      "0.1 1 4 5 sqrt friedman_mse 0.75 50: Weighted 0.811381 (0.061386)\n",
      "0.1 1 4 5 sqrt friedman_mse 0.75 50: Macro 0.709195 (0.088495)\n",
      "Testing 2814/5184\n",
      "0.1 1 4 5 sqrt friedman_mse 0.75 100: Weighted 0.798925 (0.065066)\n",
      "0.1 1 4 5 sqrt friedman_mse 0.75 100: Macro 0.697961 (0.106800)\n",
      "Testing 2815/5184\n",
      "0.1 1 4 5 sqrt friedman_mse 0.75 200: Weighted 0.801078 (0.076711)\n",
      "0.1 1 4 5 sqrt friedman_mse 0.75 200: Macro 0.687715 (0.114640)\n",
      "Testing 2816/5184\n",
      "0.1 1 4 5 sqrt friedman_mse 0.75 500: Weighted 0.802815 (0.086450)\n",
      "0.1 1 4 5 sqrt friedman_mse 0.75 500: Macro 0.689849 (0.126976)\n",
      "Testing 2817/5184\n",
      "0.1 1 4 5 sqrt friedman_mse 1.0 50: Weighted 0.801596 (0.067935)\n",
      "0.1 1 4 5 sqrt friedman_mse 1.0 50: Macro 0.701154 (0.094686)\n",
      "Testing 2818/5184\n",
      "0.1 1 4 5 sqrt friedman_mse 1.0 100: Weighted 0.788743 (0.077000)\n",
      "0.1 1 4 5 sqrt friedman_mse 1.0 100: Macro 0.683574 (0.123257)\n",
      "Testing 2819/5184\n",
      "0.1 1 4 5 sqrt friedman_mse 1.0 200: Weighted 0.797786 (0.069233)\n",
      "0.1 1 4 5 sqrt friedman_mse 1.0 200: Macro 0.696270 (0.104053)\n",
      "Testing 2820/5184\n",
      "0.1 1 4 5 sqrt friedman_mse 1.0 500: Weighted 0.806850 (0.068485)\n",
      "0.1 1 4 5 sqrt friedman_mse 1.0 500: Macro 0.708316 (0.106229)\n",
      "Testing 2821/5184\n",
      "0.1 1 4 5 sqrt mae 0.5 50: Weighted 0.776260 (0.035631)\n",
      "0.1 1 4 5 sqrt mae 0.5 50: Macro 0.655386 (0.054653)\n",
      "Testing 2822/5184\n",
      "0.1 1 4 5 sqrt mae 0.5 100: Weighted 0.786266 (0.076393)\n",
      "0.1 1 4 5 sqrt mae 0.5 100: Macro 0.656913 (0.104215)\n",
      "Testing 2823/5184\n",
      "0.1 1 4 5 sqrt mae 0.5 200: Weighted 0.791526 (0.069559)\n",
      "0.1 1 4 5 sqrt mae 0.5 200: Macro 0.672830 (0.111056)\n",
      "Testing 2824/5184\n",
      "0.1 1 4 5 sqrt mae 0.5 500: Weighted 0.777589 (0.059384)\n",
      "0.1 1 4 5 sqrt mae 0.5 500: Macro 0.657634 (0.082594)\n",
      "Testing 2825/5184\n",
      "0.1 1 4 5 sqrt mae 0.75 50: Weighted 0.787441 (0.053364)\n",
      "0.1 1 4 5 sqrt mae 0.75 50: Macro 0.672366 (0.077235)\n",
      "Testing 2826/5184\n",
      "0.1 1 4 5 sqrt mae 0.75 100: Weighted 0.769116 (0.075127)\n",
      "0.1 1 4 5 sqrt mae 0.75 100: Macro 0.633755 (0.113979)\n",
      "Testing 2827/5184\n",
      "0.1 1 4 5 sqrt mae 0.75 200: Weighted 0.787460 (0.089256)\n",
      "0.1 1 4 5 sqrt mae 0.75 200: Macro 0.674257 (0.133384)\n",
      "Testing 2828/5184\n",
      "0.1 1 4 5 sqrt mae 0.75 500: Weighted 0.786923 (0.062067)\n",
      "0.1 1 4 5 sqrt mae 0.75 500: Macro 0.670710 (0.086133)\n",
      "Testing 2829/5184\n",
      "0.1 1 4 5 sqrt mae 1.0 50: Weighted 0.778684 (0.061858)\n",
      "0.1 1 4 5 sqrt mae 1.0 50: Macro 0.655226 (0.091467)\n",
      "Testing 2830/5184\n",
      "0.1 1 4 5 sqrt mae 1.0 100: Weighted 0.770007 (0.060038)\n",
      "0.1 1 4 5 sqrt mae 1.0 100: Macro 0.633928 (0.086697)\n",
      "Testing 2831/5184\n",
      "0.1 1 4 5 sqrt mae 1.0 200: Weighted 0.787887 (0.066702)\n",
      "0.1 1 4 5 sqrt mae 1.0 200: Macro 0.658311 (0.089398)\n",
      "Testing 2832/5184\n",
      "0.1 1 4 5 sqrt mae 1.0 500: Weighted 0.776947 (0.071988)\n",
      "0.1 1 4 5 sqrt mae 1.0 500: Macro 0.645821 (0.108074)\n",
      "Testing 2833/5184\n",
      "0.1 1 4 8 log2 friedman_mse 0.5 50: Weighted 0.812579 (0.071498)\n",
      "0.1 1 4 8 log2 friedman_mse 0.5 50: Macro 0.715950 (0.103225)\n",
      "Testing 2834/5184\n",
      "0.1 1 4 8 log2 friedman_mse 0.5 100: Weighted 0.818787 (0.084510)\n",
      "0.1 1 4 8 log2 friedman_mse 0.5 100: Macro 0.718755 (0.120826)\n",
      "Testing 2835/5184\n",
      "0.1 1 4 8 log2 friedman_mse 0.5 200: Weighted 0.824140 (0.082575)\n",
      "0.1 1 4 8 log2 friedman_mse 0.5 200: Macro 0.731102 (0.127701)\n",
      "Testing 2836/5184\n",
      "0.1 1 4 8 log2 friedman_mse 0.5 500: Weighted 0.813855 (0.081082)\n",
      "0.1 1 4 8 log2 friedman_mse 0.5 500: Macro 0.715321 (0.133406)\n",
      "Testing 2837/5184\n",
      "0.1 1 4 8 log2 friedman_mse 0.75 50: Weighted 0.807429 (0.070994)\n",
      "0.1 1 4 8 log2 friedman_mse 0.75 50: Macro 0.701938 (0.105811)\n",
      "Testing 2838/5184\n",
      "0.1 1 4 8 log2 friedman_mse 0.75 100: Weighted 0.815008 (0.071918)\n",
      "0.1 1 4 8 log2 friedman_mse 0.75 100: Macro 0.715074 (0.106672)\n",
      "Testing 2839/5184\n",
      "0.1 1 4 8 log2 friedman_mse 0.75 200: Weighted 0.804362 (0.088517)\n",
      "0.1 1 4 8 log2 friedman_mse 0.75 200: Macro 0.708566 (0.128482)\n",
      "Testing 2840/5184\n",
      "0.1 1 4 8 log2 friedman_mse 0.75 500: Weighted 0.796401 (0.079635)\n",
      "0.1 1 4 8 log2 friedman_mse 0.75 500: Macro 0.691798 (0.125704)\n",
      "Testing 2841/5184\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1 1 4 8 log2 friedman_mse 1.0 50: Weighted 0.796167 (0.061339)\n",
      "0.1 1 4 8 log2 friedman_mse 1.0 50: Macro 0.694470 (0.090422)\n",
      "Testing 2842/5184\n",
      "0.1 1 4 8 log2 friedman_mse 1.0 100: Weighted 0.788121 (0.051011)\n",
      "0.1 1 4 8 log2 friedman_mse 1.0 100: Macro 0.685898 (0.069814)\n",
      "Testing 2843/5184\n",
      "0.1 1 4 8 log2 friedman_mse 1.0 200: Weighted 0.796603 (0.072491)\n",
      "0.1 1 4 8 log2 friedman_mse 1.0 200: Macro 0.685021 (0.109834)\n",
      "Testing 2844/5184\n",
      "0.1 1 4 8 log2 friedman_mse 1.0 500: Weighted 0.794219 (0.063103)\n",
      "0.1 1 4 8 log2 friedman_mse 1.0 500: Macro 0.692371 (0.084939)\n",
      "Testing 2845/5184\n",
      "0.1 1 4 8 log2 mae 0.5 50: Weighted 0.778678 (0.045742)\n",
      "0.1 1 4 8 log2 mae 0.5 50: Macro 0.653315 (0.066700)\n",
      "Testing 2846/5184\n",
      "0.1 1 4 8 log2 mae 0.5 100: Weighted 0.792760 (0.058543)\n",
      "0.1 1 4 8 log2 mae 0.5 100: Macro 0.666680 (0.100299)\n",
      "Testing 2847/5184\n",
      "0.1 1 4 8 log2 mae 0.5 200: Weighted 0.792361 (0.057741)\n",
      "0.1 1 4 8 log2 mae 0.5 200: Macro 0.674595 (0.091812)\n",
      "Testing 2848/5184\n",
      "0.1 1 4 8 log2 mae 0.5 500: Weighted 0.815682 (0.053731)\n",
      "0.1 1 4 8 log2 mae 0.5 500: Macro 0.715748 (0.077930)\n",
      "Testing 2849/5184\n",
      "0.1 1 4 8 log2 mae 0.75 50: Weighted 0.780142 (0.061054)\n",
      "0.1 1 4 8 log2 mae 0.75 50: Macro 0.652198 (0.098832)\n",
      "Testing 2850/5184\n",
      "0.1 1 4 8 log2 mae 0.75 100: Weighted 0.771228 (0.070965)\n",
      "0.1 1 4 8 log2 mae 0.75 100: Macro 0.642027 (0.112603)\n",
      "Testing 2851/5184\n",
      "0.1 1 4 8 log2 mae 0.75 200: Weighted 0.786896 (0.062634)\n",
      "0.1 1 4 8 log2 mae 0.75 200: Macro 0.666263 (0.097381)\n",
      "Testing 2852/5184\n",
      "0.1 1 4 8 log2 mae 0.75 500: Weighted 0.777046 (0.073606)\n",
      "0.1 1 4 8 log2 mae 0.75 500: Macro 0.650216 (0.117296)\n",
      "Testing 2853/5184\n",
      "0.1 1 4 8 log2 mae 1.0 50: Weighted 0.765516 (0.075133)\n",
      "0.1 1 4 8 log2 mae 1.0 50: Macro 0.643778 (0.106339)\n",
      "Testing 2854/5184\n",
      "0.1 1 4 8 log2 mae 1.0 100: Weighted 0.758833 (0.082154)\n",
      "0.1 1 4 8 log2 mae 1.0 100: Macro 0.629251 (0.114880)\n",
      "Testing 2855/5184\n",
      "0.1 1 4 8 log2 mae 1.0 200: Weighted 0.773430 (0.085489)\n",
      "0.1 1 4 8 log2 mae 1.0 200: Macro 0.656919 (0.126209)\n",
      "Testing 2856/5184\n",
      "0.1 1 4 8 log2 mae 1.0 500: Weighted 0.783530 (0.064455)\n",
      "0.1 1 4 8 log2 mae 1.0 500: Macro 0.668277 (0.080964)\n",
      "Testing 2857/5184\n",
      "0.1 1 4 8 sqrt friedman_mse 0.5 50: Weighted 0.814865 (0.062010)\n",
      "0.1 1 4 8 sqrt friedman_mse 0.5 50: Macro 0.718546 (0.091859)\n",
      "Testing 2858/5184\n",
      "0.1 1 4 8 sqrt friedman_mse 0.5 100: Weighted 0.821000 (0.067285)\n",
      "0.1 1 4 8 sqrt friedman_mse 0.5 100: Macro 0.711746 (0.099176)\n",
      "Testing 2859/5184\n",
      "0.1 1 4 8 sqrt friedman_mse 0.5 200: Weighted 0.809230 (0.087509)\n",
      "0.1 1 4 8 sqrt friedman_mse 0.5 200: Macro 0.709386 (0.132518)\n",
      "Testing 2860/5184\n",
      "0.1 1 4 8 sqrt friedman_mse 0.5 500: Weighted 0.804213 (0.072072)\n",
      "0.1 1 4 8 sqrt friedman_mse 0.5 500: Macro 0.699951 (0.118341)\n",
      "Testing 2861/5184\n",
      "0.1 1 4 8 sqrt friedman_mse 0.75 50: Weighted 0.798210 (0.052831)\n",
      "0.1 1 4 8 sqrt friedman_mse 0.75 50: Macro 0.699928 (0.074663)\n",
      "Testing 2862/5184\n",
      "0.1 1 4 8 sqrt friedman_mse 0.75 100: Weighted 0.802291 (0.079454)\n",
      "0.1 1 4 8 sqrt friedman_mse 0.75 100: Macro 0.699558 (0.116651)\n",
      "Testing 2863/5184\n",
      "0.1 1 4 8 sqrt friedman_mse 0.75 200: Weighted 0.803816 (0.067952)\n",
      "0.1 1 4 8 sqrt friedman_mse 0.75 200: Macro 0.698004 (0.109420)\n",
      "Testing 2864/5184\n",
      "0.1 1 4 8 sqrt friedman_mse 0.75 500: Weighted 0.810140 (0.077338)\n",
      "0.1 1 4 8 sqrt friedman_mse 0.75 500: Macro 0.716028 (0.121280)\n",
      "Testing 2865/5184\n",
      "0.1 1 4 8 sqrt friedman_mse 1.0 50: Weighted 0.788649 (0.067485)\n",
      "0.1 1 4 8 sqrt friedman_mse 1.0 50: Macro 0.679267 (0.098310)\n",
      "Testing 2866/5184\n",
      "0.1 1 4 8 sqrt friedman_mse 1.0 100: Weighted 0.791453 (0.077440)\n",
      "0.1 1 4 8 sqrt friedman_mse 1.0 100: Macro 0.687565 (0.116111)\n",
      "Testing 2867/5184\n",
      "0.1 1 4 8 sqrt friedman_mse 1.0 200: Weighted 0.810961 (0.077730)\n",
      "0.1 1 4 8 sqrt friedman_mse 1.0 200: Macro 0.717674 (0.110236)\n",
      "Testing 2868/5184\n",
      "0.1 1 4 8 sqrt friedman_mse 1.0 500: Weighted 0.798265 (0.067763)\n",
      "0.1 1 4 8 sqrt friedman_mse 1.0 500: Macro 0.697203 (0.102272)\n",
      "Testing 2869/5184\n",
      "0.1 1 4 8 sqrt mae 0.5 50: Weighted 0.790955 (0.039965)\n",
      "0.1 1 4 8 sqrt mae 0.5 50: Macro 0.669507 (0.059815)\n",
      "Testing 2870/5184\n",
      "0.1 1 4 8 sqrt mae 0.5 100: Weighted 0.797495 (0.062099)\n",
      "0.1 1 4 8 sqrt mae 0.5 100: Macro 0.681182 (0.099916)\n",
      "Testing 2871/5184\n",
      "0.1 1 4 8 sqrt mae 0.5 200: Weighted 0.787214 (0.064528)\n",
      "0.1 1 4 8 sqrt mae 0.5 200: Macro 0.672637 (0.091621)\n",
      "Testing 2872/5184\n",
      "0.1 1 4 8 sqrt mae 0.5 500: Weighted 0.793825 (0.057183)\n",
      "0.1 1 4 8 sqrt mae 0.5 500: Macro 0.676034 (0.091763)\n",
      "Testing 2873/5184\n",
      "0.1 1 4 8 sqrt mae 0.75 50: Weighted 0.790109 (0.051749)\n",
      "0.1 1 4 8 sqrt mae 0.75 50: Macro 0.675835 (0.075887)\n",
      "Testing 2874/5184\n",
      "0.1 1 4 8 sqrt mae 0.75 100: Weighted 0.765383 (0.075601)\n",
      "0.1 1 4 8 sqrt mae 0.75 100: Macro 0.637006 (0.108603)\n",
      "Testing 2875/5184\n",
      "0.1 1 4 8 sqrt mae 0.75 200: Weighted 0.778513 (0.060282)\n",
      "0.1 1 4 8 sqrt mae 0.75 200: Macro 0.661064 (0.086352)\n",
      "Testing 2876/5184\n",
      "0.1 1 4 8 sqrt mae 0.75 500: Weighted 0.783271 (0.075484)\n",
      "0.1 1 4 8 sqrt mae 0.75 500: Macro 0.665196 (0.113115)\n",
      "Testing 2877/5184\n",
      "0.1 1 4 8 sqrt mae 1.0 50: Weighted 0.776796 (0.064032)\n",
      "0.1 1 4 8 sqrt mae 1.0 50: Macro 0.655628 (0.095129)\n",
      "Testing 2878/5184\n",
      "0.1 1 4 8 sqrt mae 1.0 100: Weighted 0.773980 (0.066041)\n",
      "0.1 1 4 8 sqrt mae 1.0 100: Macro 0.643396 (0.104811)\n",
      "Testing 2879/5184\n",
      "0.1 1 4 8 sqrt mae 1.0 200: Weighted 0.777680 (0.059083)\n",
      "0.1 1 4 8 sqrt mae 1.0 200: Macro 0.656720 (0.079557)\n",
      "Testing 2880/5184\n",
      "0.1 1 4 8 sqrt mae 1.0 500: Weighted 0.783293 (0.078725)\n",
      "0.1 1 4 8 sqrt mae 1.0 500: Macro 0.666562 (0.106561)\n",
      "Testing 2881/5184\n",
      "0.1 1 6 3 log2 friedman_mse 0.5 50: Weighted 0.820294 (0.062800)\n",
      "0.1 1 6 3 log2 friedman_mse 0.5 50: Macro 0.718315 (0.090631)\n",
      "Testing 2882/5184\n",
      "0.1 1 6 3 log2 friedman_mse 0.5 100: Weighted 0.792743 (0.059530)\n",
      "0.1 1 6 3 log2 friedman_mse 0.5 100: Macro 0.677692 (0.090239)\n",
      "Testing 2883/5184\n",
      "0.1 1 6 3 log2 friedman_mse 0.5 200: Weighted 0.813482 (0.042348)\n",
      "0.1 1 6 3 log2 friedman_mse 0.5 200: Macro 0.711855 (0.068393)\n",
      "Testing 2884/5184\n",
      "0.1 1 6 3 log2 friedman_mse 0.5 500: Weighted 0.800757 (0.077192)\n",
      "0.1 1 6 3 log2 friedman_mse 0.5 500: Macro 0.689338 (0.113488)\n",
      "Testing 2885/5184\n",
      "0.1 1 6 3 log2 friedman_mse 0.75 50: Weighted 0.806245 (0.081789)\n",
      "0.1 1 6 3 log2 friedman_mse 0.75 50: Macro 0.693158 (0.112925)\n",
      "Testing 2886/5184\n",
      "0.1 1 6 3 log2 friedman_mse 0.75 100: Weighted 0.812413 (0.065488)\n",
      "0.1 1 6 3 log2 friedman_mse 0.75 100: Macro 0.710247 (0.097123)\n",
      "Testing 2887/5184\n",
      "0.1 1 6 3 log2 friedman_mse 0.75 200: Weighted 0.806528 (0.052814)\n",
      "0.1 1 6 3 log2 friedman_mse 0.75 200: Macro 0.711085 (0.076373)\n",
      "Testing 2888/5184\n",
      "0.1 1 6 3 log2 friedman_mse 0.75 500: Weighted 0.802019 (0.075178)\n",
      "0.1 1 6 3 log2 friedman_mse 0.75 500: Macro 0.703021 (0.112524)\n",
      "Testing 2889/5184\n",
      "0.1 1 6 3 log2 friedman_mse 1.0 50: Weighted 0.801391 (0.048314)\n",
      "0.1 1 6 3 log2 friedman_mse 1.0 50: Macro 0.700759 (0.072758)\n",
      "Testing 2890/5184\n",
      "0.1 1 6 3 log2 friedman_mse 1.0 100: Weighted 0.810913 (0.054725)\n",
      "0.1 1 6 3 log2 friedman_mse 1.0 100: Macro 0.714438 (0.085373)\n",
      "Testing 2891/5184\n",
      "0.1 1 6 3 log2 friedman_mse 1.0 200: Weighted 0.800023 (0.057342)\n",
      "0.1 1 6 3 log2 friedman_mse 1.0 200: Macro 0.697226 (0.086359)\n",
      "Testing 2892/5184\n",
      "0.1 1 6 3 log2 friedman_mse 1.0 500: Weighted 0.812734 (0.044999)\n",
      "0.1 1 6 3 log2 friedman_mse 1.0 500: Macro 0.717466 (0.065632)\n",
      "Testing 2893/5184\n",
      "0.1 1 6 3 log2 mae 0.5 50: Weighted 0.787675 (0.031764)\n",
      "0.1 1 6 3 log2 mae 0.5 50: Macro 0.680302 (0.044611)\n",
      "Testing 2894/5184\n",
      "0.1 1 6 3 log2 mae 0.5 100: Weighted 0.788582 (0.051732)\n",
      "0.1 1 6 3 log2 mae 0.5 100: Macro 0.675659 (0.075713)\n",
      "Testing 2895/5184\n",
      "0.1 1 6 3 log2 mae 0.5 200: Weighted 0.773413 (0.064326)\n",
      "0.1 1 6 3 log2 mae 0.5 200: Macro 0.651817 (0.103134)\n",
      "Testing 2896/5184\n",
      "0.1 1 6 3 log2 mae 0.5 500: Weighted 0.786954 (0.069370)\n",
      "0.1 1 6 3 log2 mae 0.5 500: Macro 0.671326 (0.114610)\n",
      "Testing 2897/5184\n",
      "0.1 1 6 3 log2 mae 0.75 50: Weighted 0.774366 (0.046134)\n",
      "0.1 1 6 3 log2 mae 0.75 50: Macro 0.666485 (0.059075)\n",
      "Testing 2898/5184\n",
      "0.1 1 6 3 log2 mae 0.75 100: Weighted 0.765512 (0.073501)\n",
      "0.1 1 6 3 log2 mae 0.75 100: Macro 0.652320 (0.102990)\n",
      "Testing 2899/5184\n",
      "0.1 1 6 3 log2 mae 0.75 200: Weighted 0.759306 (0.063132)\n",
      "0.1 1 6 3 log2 mae 0.75 200: Macro 0.624175 (0.089659)\n",
      "Testing 2900/5184\n",
      "0.1 1 6 3 log2 mae 0.75 500: Weighted 0.781154 (0.090305)\n",
      "0.1 1 6 3 log2 mae 0.75 500: Macro 0.662606 (0.133558)\n",
      "Testing 2901/5184\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1 1 6 3 log2 mae 1.0 50: Weighted 0.771254 (0.059179)\n",
      "0.1 1 6 3 log2 mae 1.0 50: Macro 0.653885 (0.087872)\n",
      "Testing 2902/5184\n",
      "0.1 1 6 3 log2 mae 1.0 100: Weighted 0.751313 (0.061123)\n",
      "0.1 1 6 3 log2 mae 1.0 100: Macro 0.609293 (0.088015)\n",
      "Testing 2903/5184\n",
      "0.1 1 6 3 log2 mae 1.0 200: Weighted 0.763865 (0.077261)\n",
      "0.1 1 6 3 log2 mae 1.0 200: Macro 0.627519 (0.117822)\n",
      "Testing 2904/5184\n",
      "0.1 1 6 3 log2 mae 1.0 500: Weighted 0.759620 (0.053385)\n",
      "0.1 1 6 3 log2 mae 1.0 500: Macro 0.611371 (0.075753)\n",
      "Testing 2905/5184\n",
      "0.1 1 6 3 sqrt friedman_mse 0.5 50: Weighted 0.810242 (0.062036)\n",
      "0.1 1 6 3 sqrt friedman_mse 0.5 50: Macro 0.715418 (0.083014)\n",
      "Testing 2906/5184\n",
      "0.1 1 6 3 sqrt friedman_mse 0.5 100: Weighted 0.809662 (0.061927)\n",
      "0.1 1 6 3 sqrt friedman_mse 0.5 100: Macro 0.708379 (0.086140)\n",
      "Testing 2907/5184\n",
      "0.1 1 6 3 sqrt friedman_mse 0.5 200: Weighted 0.803546 (0.067565)\n",
      "0.1 1 6 3 sqrt friedman_mse 0.5 200: Macro 0.694804 (0.107864)\n",
      "Testing 2908/5184\n",
      "0.1 1 6 3 sqrt friedman_mse 0.5 500: Weighted 0.793160 (0.063684)\n",
      "0.1 1 6 3 sqrt friedman_mse 0.5 500: Macro 0.676798 (0.097436)\n",
      "Testing 2909/5184\n",
      "0.1 1 6 3 sqrt friedman_mse 0.75 50: Weighted 0.812716 (0.065755)\n",
      "0.1 1 6 3 sqrt friedman_mse 0.75 50: Macro 0.709688 (0.081138)\n",
      "Testing 2910/5184\n",
      "0.1 1 6 3 sqrt friedman_mse 0.75 100: Weighted 0.792816 (0.059477)\n",
      "0.1 1 6 3 sqrt friedman_mse 0.75 100: Macro 0.683759 (0.082496)\n",
      "Testing 2911/5184\n",
      "0.1 1 6 3 sqrt friedman_mse 0.75 200: Weighted 0.803012 (0.062531)\n",
      "0.1 1 6 3 sqrt friedman_mse 0.75 200: Macro 0.705133 (0.093023)\n",
      "Testing 2912/5184\n",
      "0.1 1 6 3 sqrt friedman_mse 0.75 500: Weighted 0.813805 (0.064535)\n",
      "0.1 1 6 3 sqrt friedman_mse 0.75 500: Macro 0.716329 (0.105707)\n",
      "Testing 2913/5184\n",
      "0.1 1 6 3 sqrt friedman_mse 1.0 50: Weighted 0.804802 (0.066794)\n",
      "0.1 1 6 3 sqrt friedman_mse 1.0 50: Macro 0.704225 (0.094433)\n",
      "Testing 2914/5184\n",
      "0.1 1 6 3 sqrt friedman_mse 1.0 100: Weighted 0.799065 (0.061817)\n",
      "0.1 1 6 3 sqrt friedman_mse 1.0 100: Macro 0.691791 (0.080863)\n",
      "Testing 2915/5184\n",
      "0.1 1 6 3 sqrt friedman_mse 1.0 200: Weighted 0.804046 (0.053940)\n",
      "0.1 1 6 3 sqrt friedman_mse 1.0 200: Macro 0.702648 (0.082617)\n",
      "Testing 2916/5184\n",
      "0.1 1 6 3 sqrt friedman_mse 1.0 500: Weighted 0.786811 (0.069682)\n",
      "0.1 1 6 3 sqrt friedman_mse 1.0 500: Macro 0.686804 (0.103527)\n",
      "Testing 2917/5184\n",
      "0.1 1 6 3 sqrt mae 0.5 50: Weighted 0.805124 (0.036362)\n",
      "0.1 1 6 3 sqrt mae 0.5 50: Macro 0.701008 (0.043514)\n",
      "Testing 2918/5184\n",
      "0.1 1 6 3 sqrt mae 0.5 100: Weighted 0.784691 (0.043569)\n",
      "0.1 1 6 3 sqrt mae 0.5 100: Macro 0.670812 (0.057110)\n",
      "Testing 2919/5184\n",
      "0.1 1 6 3 sqrt mae 0.5 200: Weighted 0.761855 (0.047338)\n",
      "0.1 1 6 3 sqrt mae 0.5 200: Macro 0.629746 (0.070603)\n",
      "Testing 2920/5184\n",
      "0.1 1 6 3 sqrt mae 0.5 500: Weighted 0.789313 (0.065453)\n",
      "0.1 1 6 3 sqrt mae 0.5 500: Macro 0.675712 (0.107014)\n",
      "Testing 2921/5184\n",
      "0.1 1 6 3 sqrt mae 0.75 50: Weighted 0.788266 (0.061354)\n",
      "0.1 1 6 3 sqrt mae 0.75 50: Macro 0.668978 (0.086586)\n",
      "Testing 2922/5184\n",
      "0.1 1 6 3 sqrt mae 0.75 100: Weighted 0.765904 (0.065865)\n",
      "0.1 1 6 3 sqrt mae 0.75 100: Macro 0.643530 (0.099011)\n",
      "Testing 2923/5184\n",
      "0.1 1 6 3 sqrt mae 0.75 200: Weighted 0.761582 (0.050588)\n",
      "0.1 1 6 3 sqrt mae 0.75 200: Macro 0.629703 (0.080595)\n",
      "Testing 2924/5184\n",
      "0.1 1 6 3 sqrt mae 0.75 500: Weighted 0.768072 (0.066101)\n",
      "0.1 1 6 3 sqrt mae 0.75 500: Macro 0.631741 (0.096802)\n",
      "Testing 2925/5184\n",
      "0.1 1 6 3 sqrt mae 1.0 50: Weighted 0.774397 (0.075391)\n",
      "0.1 1 6 3 sqrt mae 1.0 50: Macro 0.645981 (0.110646)\n",
      "Testing 2926/5184\n",
      "0.1 1 6 3 sqrt mae 1.0 100: Weighted 0.759214 (0.076235)\n",
      "0.1 1 6 3 sqrt mae 1.0 100: Macro 0.616965 (0.112181)\n",
      "Testing 2927/5184\n",
      "0.1 1 6 3 sqrt mae 1.0 200: Weighted 0.745246 (0.060926)\n",
      "0.1 1 6 3 sqrt mae 1.0 200: Macro 0.598566 (0.086657)\n",
      "Testing 2928/5184\n",
      "0.1 1 6 3 sqrt mae 1.0 500: Weighted 0.749499 (0.051972)\n",
      "0.1 1 6 3 sqrt mae 1.0 500: Macro 0.601360 (0.084707)\n",
      "Testing 2929/5184\n",
      "0.1 1 6 5 log2 friedman_mse 0.5 50: Weighted 0.809457 (0.056414)\n",
      "0.1 1 6 5 log2 friedman_mse 0.5 50: Macro 0.698824 (0.068705)\n",
      "Testing 2930/5184\n",
      "0.1 1 6 5 log2 friedman_mse 0.5 100: Weighted 0.801090 (0.062297)\n",
      "0.1 1 6 5 log2 friedman_mse 0.5 100: Macro 0.696201 (0.093897)\n",
      "Testing 2931/5184\n",
      "0.1 1 6 5 log2 friedman_mse 0.5 200: Weighted 0.816203 (0.070490)\n",
      "0.1 1 6 5 log2 friedman_mse 0.5 200: Macro 0.713115 (0.109010)\n",
      "Testing 2932/5184\n",
      "0.1 1 6 5 log2 friedman_mse 0.5 500: Weighted 0.805106 (0.075524)\n",
      "0.1 1 6 5 log2 friedman_mse 0.5 500: Macro 0.695704 (0.115807)\n",
      "Testing 2933/5184\n",
      "0.1 1 6 5 log2 friedman_mse 0.75 50: Weighted 0.799719 (0.081730)\n",
      "0.1 1 6 5 log2 friedman_mse 0.75 50: Macro 0.695034 (0.120669)\n",
      "Testing 2934/5184\n",
      "0.1 1 6 5 log2 friedman_mse 0.75 100: Weighted 0.792970 (0.080074)\n",
      "0.1 1 6 5 log2 friedman_mse 0.75 100: Macro 0.685637 (0.119955)\n",
      "Testing 2935/5184\n",
      "0.1 1 6 5 log2 friedman_mse 0.75 200: Weighted 0.789533 (0.078458)\n",
      "0.1 1 6 5 log2 friedman_mse 0.75 200: Macro 0.681541 (0.119206)\n",
      "Testing 2936/5184\n",
      "0.1 1 6 5 log2 friedman_mse 0.75 500: Weighted 0.798334 (0.067206)\n",
      "0.1 1 6 5 log2 friedman_mse 0.75 500: Macro 0.695958 (0.105103)\n",
      "Testing 2937/5184\n",
      "0.1 1 6 5 log2 friedman_mse 1.0 50: Weighted 0.786696 (0.062443)\n",
      "0.1 1 6 5 log2 friedman_mse 1.0 50: Macro 0.682435 (0.088270)\n",
      "Testing 2938/5184\n",
      "0.1 1 6 5 log2 friedman_mse 1.0 100: Weighted 0.796882 (0.079329)\n",
      "0.1 1 6 5 log2 friedman_mse 1.0 100: Macro 0.692683 (0.122701)\n",
      "Testing 2939/5184\n",
      "0.1 1 6 5 log2 friedman_mse 1.0 200: Weighted 0.796519 (0.069167)\n",
      "0.1 1 6 5 log2 friedman_mse 1.0 200: Macro 0.700026 (0.105507)\n",
      "Testing 2940/5184\n",
      "0.1 1 6 5 log2 friedman_mse 1.0 500: Weighted 0.797418 (0.066673)\n",
      "0.1 1 6 5 log2 friedman_mse 1.0 500: Macro 0.699735 (0.105001)\n",
      "Testing 2941/5184\n",
      "0.1 1 6 5 log2 mae 0.5 50: Weighted 0.785640 (0.054855)\n",
      "0.1 1 6 5 log2 mae 0.5 50: Macro 0.656494 (0.080108)\n",
      "Testing 2942/5184\n",
      "0.1 1 6 5 log2 mae 0.5 100: Weighted 0.791383 (0.059217)\n",
      "0.1 1 6 5 log2 mae 0.5 100: Macro 0.663956 (0.088986)\n",
      "Testing 2943/5184\n",
      "0.1 1 6 5 log2 mae 0.5 200: Weighted 0.790004 (0.068936)\n",
      "0.1 1 6 5 log2 mae 0.5 200: Macro 0.675125 (0.106695)\n",
      "Testing 2944/5184\n",
      "0.1 1 6 5 log2 mae 0.5 500: Weighted 0.779899 (0.051071)\n",
      "0.1 1 6 5 log2 mae 0.5 500: Macro 0.649719 (0.076320)\n",
      "Testing 2945/5184\n",
      "0.1 1 6 5 log2 mae 0.75 50: Weighted 0.765401 (0.051628)\n",
      "0.1 1 6 5 log2 mae 0.75 50: Macro 0.634806 (0.074887)\n",
      "Testing 2946/5184\n",
      "0.1 1 6 5 log2 mae 0.75 100: Weighted 0.781530 (0.068242)\n",
      "0.1 1 6 5 log2 mae 0.75 100: Macro 0.660606 (0.098589)\n",
      "Testing 2947/5184\n",
      "0.1 1 6 5 log2 mae 0.75 200: Weighted 0.774652 (0.073865)\n",
      "0.1 1 6 5 log2 mae 0.75 200: Macro 0.642550 (0.109358)\n",
      "Testing 2948/5184\n",
      "0.1 1 6 5 log2 mae 0.75 500: Weighted 0.805128 (0.089332)\n",
      "0.1 1 6 5 log2 mae 0.75 500: Macro 0.691340 (0.134594)\n",
      "Testing 2949/5184\n",
      "0.1 1 6 5 log2 mae 1.0 50: Weighted 0.799915 (0.079635)\n",
      "0.1 1 6 5 log2 mae 1.0 50: Macro 0.690030 (0.121166)\n",
      "Testing 2950/5184\n",
      "0.1 1 6 5 log2 mae 1.0 100: Weighted 0.769766 (0.072563)\n",
      "0.1 1 6 5 log2 mae 1.0 100: Macro 0.634906 (0.106940)\n",
      "Testing 2951/5184\n",
      "0.1 1 6 5 log2 mae 1.0 200: Weighted 0.787181 (0.077290)\n",
      "0.1 1 6 5 log2 mae 1.0 200: Macro 0.661173 (0.114442)\n",
      "Testing 2952/5184\n",
      "0.1 1 6 5 log2 mae 1.0 500: Weighted 0.784995 (0.085372)\n",
      "0.1 1 6 5 log2 mae 1.0 500: Macro 0.661233 (0.126119)\n",
      "Testing 2953/5184\n",
      "0.1 1 6 5 sqrt friedman_mse 0.5 50: Weighted 0.820410 (0.059113)\n",
      "0.1 1 6 5 sqrt friedman_mse 0.5 50: Macro 0.723330 (0.077986)\n",
      "Testing 2954/5184\n",
      "0.1 1 6 5 sqrt friedman_mse 0.5 100: Weighted 0.823789 (0.075823)\n",
      "0.1 1 6 5 sqrt friedman_mse 0.5 100: Macro 0.725578 (0.103320)\n",
      "Testing 2955/5184\n",
      "0.1 1 6 5 sqrt friedman_mse 0.5 200: Weighted 0.809812 (0.086645)\n",
      "0.1 1 6 5 sqrt friedman_mse 0.5 200: Macro 0.712480 (0.138130)\n",
      "Testing 2956/5184\n",
      "0.1 1 6 5 sqrt friedman_mse 0.5 500: Weighted 0.805612 (0.079472)\n",
      "0.1 1 6 5 sqrt friedman_mse 0.5 500: Macro 0.698456 (0.119991)\n",
      "Testing 2957/5184\n",
      "0.1 1 6 5 sqrt friedman_mse 0.75 50: Weighted 0.834903 (0.079667)\n",
      "0.1 1 6 5 sqrt friedman_mse 0.75 50: Macro 0.750381 (0.110241)\n",
      "Testing 2958/5184\n",
      "0.1 1 6 5 sqrt friedman_mse 0.75 100: Weighted 0.814418 (0.092432)\n",
      "0.1 1 6 5 sqrt friedman_mse 0.75 100: Macro 0.713539 (0.132937)\n",
      "Testing 2959/5184\n",
      "0.1 1 6 5 sqrt friedman_mse 0.75 200: Weighted 0.798198 (0.084784)\n",
      "0.1 1 6 5 sqrt friedman_mse 0.75 200: Macro 0.688960 (0.124891)\n",
      "Testing 2960/5184\n",
      "0.1 1 6 5 sqrt friedman_mse 0.75 500: Weighted 0.805898 (0.070734)\n",
      "0.1 1 6 5 sqrt friedman_mse 0.75 500: Macro 0.711146 (0.116927)\n",
      "Testing 2961/5184\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1 1 6 5 sqrt friedman_mse 1.0 50: Weighted 0.792941 (0.056189)\n",
      "0.1 1 6 5 sqrt friedman_mse 1.0 50: Macro 0.684889 (0.086617)\n",
      "Testing 2962/5184\n",
      "0.1 1 6 5 sqrt friedman_mse 1.0 100: Weighted 0.802725 (0.072672)\n",
      "0.1 1 6 5 sqrt friedman_mse 1.0 100: Macro 0.704291 (0.110070)\n",
      "Testing 2963/5184\n",
      "0.1 1 6 5 sqrt friedman_mse 1.0 200: Weighted 0.797608 (0.078584)\n",
      "0.1 1 6 5 sqrt friedman_mse 1.0 200: Macro 0.691322 (0.122252)\n",
      "Testing 2964/5184\n",
      "0.1 1 6 5 sqrt friedman_mse 1.0 500: Weighted 0.788315 (0.078266)\n",
      "0.1 1 6 5 sqrt friedman_mse 1.0 500: Macro 0.679163 (0.120829)\n",
      "Testing 2965/5184\n",
      "0.1 1 6 5 sqrt mae 0.5 50: Weighted 0.782836 (0.048578)\n",
      "0.1 1 6 5 sqrt mae 0.5 50: Macro 0.656851 (0.080464)\n",
      "Testing 2966/5184\n",
      "0.1 1 6 5 sqrt mae 0.5 100: Weighted 0.781871 (0.058386)\n",
      "0.1 1 6 5 sqrt mae 0.5 100: Macro 0.656045 (0.087985)\n",
      "Testing 2967/5184\n",
      "0.1 1 6 5 sqrt mae 0.5 200: Weighted 0.788029 (0.073049)\n",
      "0.1 1 6 5 sqrt mae 0.5 200: Macro 0.670181 (0.112770)\n",
      "Testing 2968/5184\n",
      "0.1 1 6 5 sqrt mae 0.5 500: Weighted 0.795111 (0.073140)\n",
      "0.1 1 6 5 sqrt mae 0.5 500: Macro 0.678201 (0.110420)\n",
      "Testing 2969/5184\n",
      "0.1 1 6 5 sqrt mae 0.75 50: Weighted 0.777008 (0.055154)\n",
      "0.1 1 6 5 sqrt mae 0.75 50: Macro 0.653018 (0.085396)\n",
      "Testing 2970/5184\n",
      "0.1 1 6 5 sqrt mae 0.75 100: Weighted 0.768569 (0.062621)\n",
      "0.1 1 6 5 sqrt mae 0.75 100: Macro 0.643374 (0.092612)\n",
      "Testing 2971/5184\n",
      "0.1 1 6 5 sqrt mae 0.75 200: Weighted 0.767094 (0.062587)\n",
      "0.1 1 6 5 sqrt mae 0.75 200: Macro 0.628396 (0.091969)\n",
      "Testing 2972/5184\n",
      "0.1 1 6 5 sqrt mae 0.75 500: Weighted 0.792701 (0.075015)\n",
      "0.1 1 6 5 sqrt mae 0.75 500: Macro 0.675833 (0.111890)\n",
      "Testing 2973/5184\n",
      "0.1 1 6 5 sqrt mae 1.0 50: Weighted 0.764146 (0.060779)\n",
      "0.1 1 6 5 sqrt mae 1.0 50: Macro 0.627968 (0.090218)\n",
      "Testing 2974/5184\n",
      "0.1 1 6 5 sqrt mae 1.0 100: Weighted 0.762642 (0.066547)\n",
      "0.1 1 6 5 sqrt mae 1.0 100: Macro 0.626149 (0.096104)\n",
      "Testing 2975/5184\n",
      "0.1 1 6 5 sqrt mae 1.0 200: Weighted 0.773188 (0.083341)\n",
      "0.1 1 6 5 sqrt mae 1.0 200: Macro 0.642952 (0.119776)\n",
      "Testing 2976/5184\n",
      "0.1 1 6 5 sqrt mae 1.0 500: Weighted 0.783483 (0.071993)\n",
      "0.1 1 6 5 sqrt mae 1.0 500: Macro 0.656638 (0.112812)\n",
      "Testing 2977/5184\n",
      "0.1 1 6 8 log2 friedman_mse 0.5 50: Weighted 0.806585 (0.061552)\n",
      "0.1 1 6 8 log2 friedman_mse 0.5 50: Macro 0.698366 (0.082336)\n",
      "Testing 2978/5184\n",
      "0.1 1 6 8 log2 friedman_mse 0.5 100: Weighted 0.811290 (0.072664)\n",
      "0.1 1 6 8 log2 friedman_mse 0.5 100: Macro 0.709419 (0.115991)\n",
      "Testing 2979/5184\n",
      "0.1 1 6 8 log2 friedman_mse 0.5 200: Weighted 0.825329 (0.063042)\n",
      "0.1 1 6 8 log2 friedman_mse 0.5 200: Macro 0.718421 (0.098566)\n",
      "Testing 2980/5184\n",
      "0.1 1 6 8 log2 friedman_mse 0.5 500: Weighted 0.836899 (0.067188)\n",
      "0.1 1 6 8 log2 friedman_mse 0.5 500: Macro 0.753164 (0.109609)\n",
      "Testing 2981/5184\n",
      "0.1 1 6 8 log2 friedman_mse 0.75 50: Weighted 0.805008 (0.067920)\n",
      "0.1 1 6 8 log2 friedman_mse 0.75 50: Macro 0.697319 (0.092649)\n",
      "Testing 2982/5184\n",
      "0.1 1 6 8 log2 friedman_mse 0.75 100: Weighted 0.814310 (0.083819)\n",
      "0.1 1 6 8 log2 friedman_mse 0.75 100: Macro 0.712292 (0.130895)\n",
      "Testing 2983/5184\n",
      "0.1 1 6 8 log2 friedman_mse 0.75 200: Weighted 0.796401 (0.079635)\n",
      "0.1 1 6 8 log2 friedman_mse 0.75 200: Macro 0.691798 (0.125704)\n",
      "Testing 2984/5184\n",
      "0.1 1 6 8 log2 friedman_mse 0.75 500: Weighted 0.791581 (0.077415)\n",
      "0.1 1 6 8 log2 friedman_mse 0.75 500: Macro 0.683203 (0.121543)\n",
      "Testing 2985/5184\n",
      "0.1 1 6 8 log2 friedman_mse 1.0 50: Weighted 0.797239 (0.073119)\n",
      "0.1 1 6 8 log2 friedman_mse 1.0 50: Macro 0.690988 (0.111932)\n",
      "Testing 2986/5184\n",
      "0.1 1 6 8 log2 friedman_mse 1.0 100: Weighted 0.796096 (0.083658)\n",
      "0.1 1 6 8 log2 friedman_mse 1.0 100: Macro 0.690062 (0.122541)\n",
      "Testing 2987/5184\n",
      "0.1 1 6 8 log2 friedman_mse 1.0 200: Weighted 0.805451 (0.076782)\n",
      "0.1 1 6 8 log2 friedman_mse 1.0 200: Macro 0.708579 (0.102093)\n",
      "Testing 2988/5184\n",
      "0.1 1 6 8 log2 friedman_mse 1.0 500: Weighted 0.791297 (0.089632)\n",
      "0.1 1 6 8 log2 friedman_mse 1.0 500: Macro 0.687632 (0.133029)\n",
      "Testing 2989/5184\n",
      "0.1 1 6 8 log2 mae 0.5 50: Weighted 0.808953 (0.040633)\n",
      "0.1 1 6 8 log2 mae 0.5 50: Macro 0.695242 (0.068230)\n",
      "Testing 2990/5184\n",
      "0.1 1 6 8 log2 mae 0.5 100: Weighted 0.805725 (0.043868)\n",
      "0.1 1 6 8 log2 mae 0.5 100: Macro 0.696648 (0.067079)\n",
      "Testing 2991/5184\n",
      "0.1 1 6 8 log2 mae 0.5 200: Weighted 0.811413 (0.056468)\n",
      "0.1 1 6 8 log2 mae 0.5 200: Macro 0.705934 (0.085760)\n",
      "Testing 2992/5184\n",
      "0.1 1 6 8 log2 mae 0.5 500: Weighted 0.802199 (0.074654)\n",
      "0.1 1 6 8 log2 mae 0.5 500: Macro 0.693034 (0.115015)\n",
      "Testing 2993/5184\n",
      "0.1 1 6 8 log2 mae 0.75 50: Weighted 0.778641 (0.054495)\n",
      "0.1 1 6 8 log2 mae 0.75 50: Macro 0.658757 (0.081311)\n",
      "Testing 2994/5184\n",
      "0.1 1 6 8 log2 mae 0.75 100: Weighted 0.794943 (0.054776)\n",
      "0.1 1 6 8 log2 mae 0.75 100: Macro 0.679946 (0.084915)\n",
      "Testing 2995/5184\n",
      "0.1 1 6 8 log2 mae 0.75 200: Weighted 0.780265 (0.069364)\n",
      "0.1 1 6 8 log2 mae 0.75 200: Macro 0.652182 (0.112062)\n",
      "Testing 2996/5184\n",
      "0.1 1 6 8 log2 mae 0.75 500: Weighted 0.804845 (0.071775)\n",
      "0.1 1 6 8 log2 mae 0.75 500: Macro 0.695954 (0.106790)\n",
      "Testing 2997/5184\n",
      "0.1 1 6 8 log2 mae 1.0 50: Weighted 0.779049 (0.063101)\n",
      "0.1 1 6 8 log2 mae 1.0 50: Macro 0.662032 (0.098285)\n",
      "Testing 2998/5184\n",
      "0.1 1 6 8 log2 mae 1.0 100: Weighted 0.775216 (0.072160)\n",
      "0.1 1 6 8 log2 mae 1.0 100: Macro 0.644546 (0.103119)\n",
      "Testing 2999/5184\n",
      "0.1 1 6 8 log2 mae 1.0 200: Weighted 0.786956 (0.063205)\n",
      "0.1 1 6 8 log2 mae 1.0 200: Macro 0.671279 (0.087696)\n",
      "Testing 3000/5184\n",
      "0.1 1 6 8 log2 mae 1.0 500: Weighted 0.778205 (0.072776)\n",
      "0.1 1 6 8 log2 mae 1.0 500: Macro 0.657390 (0.103915)\n",
      "Testing 3001/5184\n",
      "0.1 1 6 8 sqrt friedman_mse 0.5 50: Weighted 0.820277 (0.064348)\n",
      "0.1 1 6 8 sqrt friedman_mse 0.5 50: Macro 0.721858 (0.096087)\n",
      "Testing 3002/5184\n",
      "0.1 1 6 8 sqrt friedman_mse 0.5 100: Weighted 0.829147 (0.089028)\n",
      "0.1 1 6 8 sqrt friedman_mse 0.5 100: Macro 0.735399 (0.132716)\n",
      "Testing 3003/5184\n",
      "0.1 1 6 8 sqrt friedman_mse 0.5 200: Weighted 0.810089 (0.067126)\n",
      "0.1 1 6 8 sqrt friedman_mse 0.5 200: Macro 0.703475 (0.099288)\n",
      "Testing 3004/5184\n",
      "0.1 1 6 8 sqrt friedman_mse 0.5 500: Weighted 0.801723 (0.076269)\n",
      "0.1 1 6 8 sqrt friedman_mse 0.5 500: Macro 0.695282 (0.111547)\n",
      "Testing 3005/5184\n",
      "0.1 1 6 8 sqrt friedman_mse 0.75 50: Weighted 0.793737 (0.066381)\n",
      "0.1 1 6 8 sqrt friedman_mse 0.75 50: Macro 0.683864 (0.094681)\n",
      "Testing 3006/5184\n",
      "0.1 1 6 8 sqrt friedman_mse 0.75 100: Weighted 0.813989 (0.075533)\n",
      "0.1 1 6 8 sqrt friedman_mse 0.75 100: Macro 0.717000 (0.111899)\n",
      "Testing 3007/5184\n",
      "0.1 1 6 8 sqrt friedman_mse 0.75 200: Weighted 0.812363 (0.087578)\n",
      "0.1 1 6 8 sqrt friedman_mse 0.75 200: Macro 0.713869 (0.134332)\n",
      "Testing 3008/5184\n",
      "0.1 1 6 8 sqrt friedman_mse 0.75 500: Weighted 0.824041 (0.083031)\n",
      "0.1 1 6 8 sqrt friedman_mse 0.75 500: Macro 0.727641 (0.120910)\n",
      "Testing 3009/5184\n",
      "0.1 1 6 8 sqrt friedman_mse 1.0 50: Weighted 0.793794 (0.078469)\n",
      "0.1 1 6 8 sqrt friedman_mse 1.0 50: Macro 0.684279 (0.114593)\n",
      "Testing 3010/5184\n",
      "0.1 1 6 8 sqrt friedman_mse 1.0 100: Weighted 0.788019 (0.068918)\n",
      "0.1 1 6 8 sqrt friedman_mse 1.0 100: Macro 0.675535 (0.109076)\n",
      "Testing 3011/5184\n",
      "0.1 1 6 8 sqrt friedman_mse 1.0 200: Weighted 0.803260 (0.065105)\n",
      "0.1 1 6 8 sqrt friedman_mse 1.0 200: Macro 0.705794 (0.096537)\n",
      "Testing 3012/5184\n",
      "0.1 1 6 8 sqrt friedman_mse 1.0 500: Weighted 0.780438 (0.067614)\n",
      "0.1 1 6 8 sqrt friedman_mse 1.0 500: Macro 0.676623 (0.109028)\n",
      "Testing 3013/5184\n",
      "0.1 1 6 8 sqrt mae 0.5 50: Weighted 0.794094 (0.037421)\n",
      "0.1 1 6 8 sqrt mae 0.5 50: Macro 0.670795 (0.068628)\n",
      "Testing 3014/5184\n",
      "0.1 1 6 8 sqrt mae 0.5 100: Weighted 0.796966 (0.052140)\n",
      "0.1 1 6 8 sqrt mae 0.5 100: Macro 0.676663 (0.081689)\n",
      "Testing 3015/5184\n",
      "0.1 1 6 8 sqrt mae 0.5 200: Weighted 0.782762 (0.047481)\n",
      "0.1 1 6 8 sqrt mae 0.5 200: Macro 0.655059 (0.068702)\n",
      "Testing 3016/5184\n",
      "0.1 1 6 8 sqrt mae 0.5 500: Weighted 0.789843 (0.060811)\n",
      "0.1 1 6 8 sqrt mae 0.5 500: Macro 0.670989 (0.096684)\n",
      "Testing 3017/5184\n",
      "0.1 1 6 8 sqrt mae 0.75 50: Weighted 0.794485 (0.075753)\n",
      "0.1 1 6 8 sqrt mae 0.75 50: Macro 0.681903 (0.114502)\n",
      "Testing 3018/5184\n",
      "0.1 1 6 8 sqrt mae 0.75 100: Weighted 0.778743 (0.089766)\n",
      "0.1 1 6 8 sqrt mae 0.75 100: Macro 0.664185 (0.128799)\n",
      "Testing 3019/5184\n",
      "0.1 1 6 8 sqrt mae 0.75 200: Weighted 0.783308 (0.093518)\n",
      "0.1 1 6 8 sqrt mae 0.75 200: Macro 0.659064 (0.148774)\n",
      "Testing 3020/5184\n",
      "0.1 1 6 8 sqrt mae 0.75 500: Weighted 0.798578 (0.078565)\n",
      "0.1 1 6 8 sqrt mae 0.75 500: Macro 0.683280 (0.126848)\n",
      "Testing 3021/5184\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1 1 6 8 sqrt mae 1.0 50: Weighted 0.780200 (0.079028)\n",
      "0.1 1 6 8 sqrt mae 1.0 50: Macro 0.659852 (0.118057)\n",
      "Testing 3022/5184\n",
      "0.1 1 6 8 sqrt mae 1.0 100: Weighted 0.768504 (0.076028)\n",
      "0.1 1 6 8 sqrt mae 1.0 100: Macro 0.639826 (0.113769)\n",
      "Testing 3023/5184\n",
      "0.1 1 6 8 sqrt mae 1.0 200: Weighted 0.760013 (0.089290)\n",
      "0.1 1 6 8 sqrt mae 1.0 200: Macro 0.628073 (0.130898)\n",
      "Testing 3024/5184\n",
      "0.1 1 6 8 sqrt mae 1.0 500: Weighted 0.781471 (0.047815)\n",
      "0.1 1 6 8 sqrt mae 1.0 500: Macro 0.670715 (0.063310)\n",
      "Testing 3025/5184\n",
      "0.1 3 2 3 log2 friedman_mse 0.5 50: Weighted 0.813811 (0.057013)\n",
      "0.1 3 2 3 log2 friedman_mse 0.5 50: Macro 0.711180 (0.077313)\n",
      "Testing 3026/5184\n",
      "0.1 3 2 3 log2 friedman_mse 0.5 100: Weighted 0.814791 (0.070325)\n",
      "0.1 3 2 3 log2 friedman_mse 0.5 100: Macro 0.713338 (0.108295)\n",
      "Testing 3027/5184\n",
      "0.1 3 2 3 log2 friedman_mse 0.5 200: Weighted 0.818829 (0.057772)\n",
      "0.1 3 2 3 log2 friedman_mse 0.5 200: Macro 0.716719 (0.083421)\n",
      "Testing 3028/5184\n",
      "0.1 3 2 3 log2 friedman_mse 0.5 500: Weighted 0.806959 (0.064105)\n",
      "0.1 3 2 3 log2 friedman_mse 0.5 500: Macro 0.706233 (0.097319)\n",
      "Testing 3029/5184\n",
      "0.1 3 2 3 log2 friedman_mse 0.75 50: Weighted 0.808417 (0.081445)\n",
      "0.1 3 2 3 log2 friedman_mse 0.75 50: Macro 0.701854 (0.119478)\n",
      "Testing 3030/5184\n",
      "0.1 3 2 3 log2 friedman_mse 0.75 100: Weighted 0.808505 (0.059493)\n",
      "0.1 3 2 3 log2 friedman_mse 0.75 100: Macro 0.713238 (0.085596)\n",
      "Testing 3031/5184\n",
      "0.1 3 2 3 log2 friedman_mse 0.75 200: Weighted 0.813436 (0.065999)\n",
      "0.1 3 2 3 log2 friedman_mse 0.75 200: Macro 0.709369 (0.092898)\n",
      "Testing 3032/5184\n",
      "0.1 3 2 3 log2 friedman_mse 0.75 500: Weighted 0.816247 (0.059896)\n",
      "0.1 3 2 3 log2 friedman_mse 0.75 500: Macro 0.724194 (0.082401)\n",
      "Testing 3033/5184\n",
      "0.1 3 2 3 log2 friedman_mse 1.0 50: Weighted 0.796031 (0.069988)\n",
      "0.1 3 2 3 log2 friedman_mse 1.0 50: Macro 0.684413 (0.093827)\n",
      "Testing 3034/5184\n",
      "0.1 3 2 3 log2 friedman_mse 1.0 100: Weighted 0.803357 (0.056546)\n",
      "0.1 3 2 3 log2 friedman_mse 1.0 100: Macro 0.691521 (0.084926)\n",
      "Testing 3035/5184\n",
      "0.1 3 2 3 log2 friedman_mse 1.0 200: Weighted 0.812542 (0.054288)\n",
      "0.1 3 2 3 log2 friedman_mse 1.0 200: Macro 0.717073 (0.080543)\n",
      "Testing 3036/5184\n",
      "0.1 3 2 3 log2 friedman_mse 1.0 500: Weighted 0.802461 (0.054990)\n",
      "0.1 3 2 3 log2 friedman_mse 1.0 500: Macro 0.696803 (0.079491)\n",
      "Testing 3037/5184\n",
      "0.1 3 2 3 log2 mae 0.5 50: Weighted 0.803587 (0.056168)\n",
      "0.1 3 2 3 log2 mae 0.5 50: Macro 0.682763 (0.081991)\n",
      "Testing 3038/5184\n",
      "0.1 3 2 3 log2 mae 0.5 100: Weighted 0.788705 (0.078506)\n",
      "0.1 3 2 3 log2 mae 0.5 100: Macro 0.675453 (0.108737)\n",
      "Testing 3039/5184\n",
      "0.1 3 2 3 log2 mae 0.5 200: Weighted 0.784357 (0.062840)\n",
      "0.1 3 2 3 log2 mae 0.5 200: Macro 0.657954 (0.082406)\n",
      "Testing 3040/5184\n",
      "0.1 3 2 3 log2 mae 0.5 500: Weighted 0.800357 (0.077572)\n",
      "0.1 3 2 3 log2 mae 0.5 500: Macro 0.681834 (0.112407)\n",
      "Testing 3041/5184\n",
      "0.1 3 2 3 log2 mae 0.75 50: Weighted 0.795912 (0.053268)\n",
      "0.1 3 2 3 log2 mae 0.75 50: Macro 0.678185 (0.079715)\n",
      "Testing 3042/5184\n",
      "0.1 3 2 3 log2 mae 0.75 100: Weighted 0.780274 (0.075362)\n",
      "0.1 3 2 3 log2 mae 0.75 100: Macro 0.664963 (0.105232)\n",
      "Testing 3043/5184\n",
      "0.1 3 2 3 log2 mae 0.75 200: Weighted 0.773531 (0.054830)\n",
      "0.1 3 2 3 log2 mae 0.75 200: Macro 0.633721 (0.072165)\n",
      "Testing 3044/5184\n",
      "0.1 3 2 3 log2 mae 0.75 500: Weighted 0.765353 (0.075406)\n",
      "0.1 3 2 3 log2 mae 0.75 500: Macro 0.629751 (0.108317)\n",
      "Testing 3045/5184\n",
      "0.1 3 2 3 log2 mae 1.0 50: Weighted 0.788787 (0.071505)\n",
      "0.1 3 2 3 log2 mae 1.0 50: Macro 0.668728 (0.094439)\n",
      "Testing 3046/5184\n",
      "0.1 3 2 3 log2 mae 1.0 100: Weighted 0.769022 (0.073447)\n",
      "0.1 3 2 3 log2 mae 1.0 100: Macro 0.639069 (0.100983)\n",
      "Testing 3047/5184\n",
      "0.1 3 2 3 log2 mae 1.0 200: Weighted 0.758847 (0.067342)\n",
      "0.1 3 2 3 log2 mae 1.0 200: Macro 0.621843 (0.095359)\n",
      "Testing 3048/5184\n",
      "0.1 3 2 3 log2 mae 1.0 500: Weighted 0.774544 (0.082038)\n",
      "0.1 3 2 3 log2 mae 1.0 500: Macro 0.639683 (0.112839)\n",
      "Testing 3049/5184\n",
      "0.1 3 2 3 sqrt friedman_mse 0.5 50: Weighted 0.821198 (0.067257)\n",
      "0.1 3 2 3 sqrt friedman_mse 0.5 50: Macro 0.717420 (0.091597)\n",
      "Testing 3050/5184\n",
      "0.1 3 2 3 sqrt friedman_mse 0.5 100: Weighted 0.797484 (0.063265)\n",
      "0.1 3 2 3 sqrt friedman_mse 0.5 100: Macro 0.679501 (0.088455)\n",
      "Testing 3051/5184\n",
      "0.1 3 2 3 sqrt friedman_mse 0.5 200: Weighted 0.810934 (0.048643)\n",
      "0.1 3 2 3 sqrt friedman_mse 0.5 200: Macro 0.702205 (0.071109)\n",
      "Testing 3052/5184\n",
      "0.1 3 2 3 sqrt friedman_mse 0.5 500: Weighted 0.805531 (0.077016)\n",
      "0.1 3 2 3 sqrt friedman_mse 0.5 500: Macro 0.699793 (0.121617)\n",
      "Testing 3053/5184\n",
      "0.1 3 2 3 sqrt friedman_mse 0.75 50: Weighted 0.804656 (0.068530)\n",
      "0.1 3 2 3 sqrt friedman_mse 0.75 50: Macro 0.706116 (0.091613)\n",
      "Testing 3054/5184\n",
      "0.1 3 2 3 sqrt friedman_mse 0.75 100: Weighted 0.795666 (0.057502)\n",
      "0.1 3 2 3 sqrt friedman_mse 0.75 100: Macro 0.686347 (0.089359)\n",
      "Testing 3055/5184\n",
      "0.1 3 2 3 sqrt friedman_mse 0.75 200: Weighted 0.815769 (0.060717)\n",
      "0.1 3 2 3 sqrt friedman_mse 0.75 200: Macro 0.724097 (0.096346)\n",
      "Testing 3056/5184\n",
      "0.1 3 2 3 sqrt friedman_mse 0.75 500: Weighted 0.809886 (0.053928)\n",
      "0.1 3 2 3 sqrt friedman_mse 0.75 500: Macro 0.712042 (0.084864)\n",
      "Testing 3057/5184\n",
      "0.1 3 2 3 sqrt friedman_mse 1.0 50: Weighted 0.801794 (0.052657)\n",
      "0.1 3 2 3 sqrt friedman_mse 1.0 50: Macro 0.696092 (0.072554)\n",
      "Testing 3058/5184\n",
      "0.1 3 2 3 sqrt friedman_mse 1.0 100: Weighted 0.813526 (0.065574)\n",
      "0.1 3 2 3 sqrt friedman_mse 1.0 100: Macro 0.707866 (0.091997)\n",
      "Testing 3059/5184\n",
      "0.1 3 2 3 sqrt friedman_mse 1.0 200: Weighted 0.803193 (0.053182)\n",
      "0.1 3 2 3 sqrt friedman_mse 1.0 200: Macro 0.703409 (0.071149)\n",
      "Testing 3060/5184\n",
      "0.1 3 2 3 sqrt friedman_mse 1.0 500: Weighted 0.811576 (0.054947)\n",
      "0.1 3 2 3 sqrt friedman_mse 1.0 500: Macro 0.717175 (0.080458)\n",
      "Testing 3061/5184\n",
      "0.1 3 2 3 sqrt mae 0.5 50: Weighted 0.830311 (0.058581)\n",
      "0.1 3 2 3 sqrt mae 0.5 50: Macro 0.730107 (0.083860)\n",
      "Testing 3062/5184\n",
      "0.1 3 2 3 sqrt mae 0.5 100: Weighted 0.793302 (0.053914)\n",
      "0.1 3 2 3 sqrt mae 0.5 100: Macro 0.671132 (0.082273)\n",
      "Testing 3063/5184\n",
      "0.1 3 2 3 sqrt mae 0.5 200: Weighted 0.775048 (0.083649)\n",
      "0.1 3 2 3 sqrt mae 0.5 200: Macro 0.647085 (0.113448)\n",
      "Testing 3064/5184\n",
      "0.1 3 2 3 sqrt mae 0.5 500: Weighted 0.786325 (0.088638)\n",
      "0.1 3 2 3 sqrt mae 0.5 500: Macro 0.669721 (0.129065)\n",
      "Testing 3065/5184\n",
      "0.1 3 2 3 sqrt mae 0.75 50: Weighted 0.786403 (0.072234)\n",
      "0.1 3 2 3 sqrt mae 0.75 50: Macro 0.668001 (0.103658)\n",
      "Testing 3066/5184\n",
      "0.1 3 2 3 sqrt mae 0.75 100: Weighted 0.770894 (0.066063)\n",
      "0.1 3 2 3 sqrt mae 0.75 100: Macro 0.647953 (0.088393)\n",
      "Testing 3067/5184\n",
      "0.1 3 2 3 sqrt mae 0.75 200: Weighted 0.771820 (0.088017)\n",
      "0.1 3 2 3 sqrt mae 0.75 200: Macro 0.641322 (0.127012)\n",
      "Testing 3068/5184\n",
      "0.1 3 2 3 sqrt mae 0.75 500: Weighted 0.754954 (0.072699)\n",
      "0.1 3 2 3 sqrt mae 0.75 500: Macro 0.606202 (0.094041)\n",
      "Testing 3069/5184\n",
      "0.1 3 2 3 sqrt mae 1.0 50: Weighted 0.785970 (0.058377)\n",
      "0.1 3 2 3 sqrt mae 1.0 50: Macro 0.671791 (0.075641)\n",
      "Testing 3070/5184\n",
      "0.1 3 2 3 sqrt mae 1.0 100: Weighted 0.760140 (0.062231)\n",
      "0.1 3 2 3 sqrt mae 1.0 100: Macro 0.625944 (0.089365)\n",
      "Testing 3071/5184\n",
      "0.1 3 2 3 sqrt mae 1.0 200: Weighted 0.751446 (0.076728)\n",
      "0.1 3 2 3 sqrt mae 1.0 200: Macro 0.603813 (0.100660)\n",
      "Testing 3072/5184\n",
      "0.1 3 2 3 sqrt mae 1.0 500: Weighted 0.780855 (0.084490)\n",
      "0.1 3 2 3 sqrt mae 1.0 500: Macro 0.646893 (0.118098)\n",
      "Testing 3073/5184\n",
      "0.1 3 2 5 log2 friedman_mse 0.5 50: Weighted 0.813336 (0.072876)\n",
      "0.1 3 2 5 log2 friedman_mse 0.5 50: Macro 0.717187 (0.105269)\n",
      "Testing 3074/5184\n",
      "0.1 3 2 5 log2 friedman_mse 0.5 100: Weighted 0.812441 (0.082884)\n",
      "0.1 3 2 5 log2 friedman_mse 0.5 100: Macro 0.702671 (0.120608)\n",
      "Testing 3075/5184\n",
      "0.1 3 2 5 log2 friedman_mse 0.5 200: Weighted 0.805546 (0.059069)\n",
      "0.1 3 2 5 log2 friedman_mse 0.5 200: Macro 0.699757 (0.090679)\n",
      "Testing 3076/5184\n",
      "0.1 3 2 5 log2 friedman_mse 0.5 500: Weighted 0.819153 (0.069683)\n",
      "0.1 3 2 5 log2 friedman_mse 0.5 500: Macro 0.727667 (0.103259)\n",
      "Testing 3077/5184\n",
      "0.1 3 2 5 log2 friedman_mse 0.75 50: Weighted 0.803328 (0.077825)\n",
      "0.1 3 2 5 log2 friedman_mse 0.75 50: Macro 0.704068 (0.111251)\n",
      "Testing 3078/5184\n",
      "0.1 3 2 5 log2 friedman_mse 0.75 100: Weighted 0.819129 (0.073355)\n",
      "0.1 3 2 5 log2 friedman_mse 0.75 100: Macro 0.714158 (0.104544)\n",
      "Testing 3079/5184\n",
      "0.1 3 2 5 log2 friedman_mse 0.75 200: Weighted 0.810881 (0.078867)\n",
      "0.1 3 2 5 log2 friedman_mse 0.75 200: Macro 0.710998 (0.115711)\n",
      "Testing 3080/5184\n",
      "0.1 3 2 5 log2 friedman_mse 0.75 500: Weighted 0.804123 (0.080644)\n",
      "0.1 3 2 5 log2 friedman_mse 0.75 500: Macro 0.693990 (0.119131)\n",
      "Testing 3081/5184\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1 3 2 5 log2 friedman_mse 1.0 50: Weighted 0.806626 (0.082273)\n",
      "0.1 3 2 5 log2 friedman_mse 1.0 50: Macro 0.701925 (0.115600)\n",
      "Testing 3082/5184\n",
      "0.1 3 2 5 log2 friedman_mse 1.0 100: Weighted 0.801807 (0.085816)\n",
      "0.1 3 2 5 log2 friedman_mse 1.0 100: Macro 0.700628 (0.121683)\n",
      "Testing 3083/5184\n",
      "0.1 3 2 5 log2 friedman_mse 1.0 200: Weighted 0.808481 (0.078419)\n",
      "0.1 3 2 5 log2 friedman_mse 1.0 200: Macro 0.707256 (0.115459)\n",
      "Testing 3084/5184\n",
      "0.1 3 2 5 log2 friedman_mse 1.0 500: Weighted 0.807227 (0.079970)\n",
      "0.1 3 2 5 log2 friedman_mse 1.0 500: Macro 0.706689 (0.116089)\n",
      "Testing 3085/5184\n",
      "0.1 3 2 5 log2 mae 0.5 50: Weighted 0.792720 (0.072445)\n",
      "0.1 3 2 5 log2 mae 0.5 50: Macro 0.669795 (0.112940)\n",
      "Testing 3086/5184\n",
      "0.1 3 2 5 log2 mae 0.5 100: Weighted 0.778922 (0.071736)\n",
      "0.1 3 2 5 log2 mae 0.5 100: Macro 0.649962 (0.099725)\n",
      "Testing 3087/5184\n",
      "0.1 3 2 5 log2 mae 0.5 200: Weighted 0.797540 (0.066642)\n",
      "0.1 3 2 5 log2 mae 0.5 200: Macro 0.673593 (0.098061)\n",
      "Testing 3088/5184\n",
      "0.1 3 2 5 log2 mae 0.5 500: Weighted 0.812233 (0.095485)\n",
      "0.1 3 2 5 log2 mae 0.5 500: Macro 0.705374 (0.131383)\n",
      "Testing 3089/5184\n",
      "0.1 3 2 5 log2 mae 0.75 50: Weighted 0.776924 (0.084243)\n",
      "0.1 3 2 5 log2 mae 0.75 50: Macro 0.644054 (0.122418)\n",
      "Testing 3090/5184\n",
      "0.1 3 2 5 log2 mae 0.75 100: Weighted 0.800766 (0.095301)\n",
      "0.1 3 2 5 log2 mae 0.75 100: Macro 0.681272 (0.141035)\n",
      "Testing 3091/5184\n",
      "0.1 3 2 5 log2 mae 0.75 200: Weighted 0.790574 (0.067735)\n",
      "0.1 3 2 5 log2 mae 0.75 200: Macro 0.660296 (0.092868)\n",
      "Testing 3092/5184\n",
      "0.1 3 2 5 log2 mae 0.75 500: Weighted 0.785722 (0.085926)\n",
      "0.1 3 2 5 log2 mae 0.75 500: Macro 0.656323 (0.122852)\n",
      "Testing 3093/5184\n",
      "0.1 3 2 5 log2 mae 1.0 50: Weighted 0.769526 (0.068979)\n",
      "0.1 3 2 5 log2 mae 1.0 50: Macro 0.642375 (0.097806)\n",
      "Testing 3094/5184\n",
      "0.1 3 2 5 log2 mae 1.0 100: Weighted 0.766280 (0.083086)\n",
      "0.1 3 2 5 log2 mae 1.0 100: Macro 0.625618 (0.105799)\n",
      "Testing 3095/5184\n",
      "0.1 3 2 5 log2 mae 1.0 200: Weighted 0.764669 (0.082660)\n",
      "0.1 3 2 5 log2 mae 1.0 200: Macro 0.624104 (0.118106)\n",
      "Testing 3096/5184\n",
      "0.1 3 2 5 log2 mae 1.0 500: Weighted 0.799129 (0.084059)\n",
      "0.1 3 2 5 log2 mae 1.0 500: Macro 0.677730 (0.115023)\n",
      "Testing 3097/5184\n",
      "0.1 3 2 5 sqrt friedman_mse 0.5 50: Weighted 0.824300 (0.076869)\n",
      "0.1 3 2 5 sqrt friedman_mse 0.5 50: Macro 0.728796 (0.107602)\n",
      "Testing 3098/5184\n",
      "0.1 3 2 5 sqrt friedman_mse 0.5 100: Weighted 0.827609 (0.077404)\n",
      "0.1 3 2 5 sqrt friedman_mse 0.5 100: Macro 0.731778 (0.112666)\n",
      "Testing 3099/5184\n",
      "0.1 3 2 5 sqrt friedman_mse 0.5 200: Weighted 0.815729 (0.064476)\n",
      "0.1 3 2 5 sqrt friedman_mse 0.5 200: Macro 0.716699 (0.097947)\n",
      "Testing 3100/5184\n",
      "0.1 3 2 5 sqrt friedman_mse 0.5 500: Weighted 0.815415 (0.065026)\n",
      "0.1 3 2 5 sqrt friedman_mse 0.5 500: Macro 0.711643 (0.086643)\n",
      "Testing 3101/5184\n",
      "0.1 3 2 5 sqrt friedman_mse 0.75 50: Weighted 0.806955 (0.080183)\n",
      "0.1 3 2 5 sqrt friedman_mse 0.75 50: Macro 0.705892 (0.118007)\n",
      "Testing 3102/5184\n",
      "0.1 3 2 5 sqrt friedman_mse 0.75 100: Weighted 0.809698 (0.063611)\n",
      "0.1 3 2 5 sqrt friedman_mse 0.75 100: Macro 0.699298 (0.092139)\n",
      "Testing 3103/5184\n",
      "0.1 3 2 5 sqrt friedman_mse 0.75 200: Weighted 0.822125 (0.089841)\n",
      "0.1 3 2 5 sqrt friedman_mse 0.75 200: Macro 0.718884 (0.136662)\n",
      "Testing 3104/5184\n",
      "0.1 3 2 5 sqrt friedman_mse 0.75 500: Weighted 0.804833 (0.062614)\n",
      "0.1 3 2 5 sqrt friedman_mse 0.75 500: Macro 0.697066 (0.094588)\n",
      "Testing 3105/5184\n",
      "0.1 3 2 5 sqrt friedman_mse 1.0 50: Weighted 0.804927 (0.083998)\n",
      "0.1 3 2 5 sqrt friedman_mse 1.0 50: Macro 0.700338 (0.117411)\n",
      "Testing 3106/5184\n",
      "0.1 3 2 5 sqrt friedman_mse 1.0 100: Weighted 0.803653 (0.093093)\n",
      "0.1 3 2 5 sqrt friedman_mse 1.0 100: Macro 0.699633 (0.139285)\n",
      "Testing 3107/5184\n",
      "0.1 3 2 5 sqrt friedman_mse 1.0 200: Weighted 0.808208 (0.090532)\n",
      "0.1 3 2 5 sqrt friedman_mse 1.0 200: Macro 0.698997 (0.132154)\n",
      "Testing 3108/5184\n",
      "0.1 3 2 5 sqrt friedman_mse 1.0 500: Weighted 0.807588 (0.091326)\n",
      "0.1 3 2 5 sqrt friedman_mse 1.0 500: Macro 0.697724 (0.133738)\n",
      "Testing 3109/5184\n",
      "0.1 3 2 5 sqrt mae 0.5 50: Weighted 0.776087 (0.055873)\n",
      "0.1 3 2 5 sqrt mae 0.5 50: Macro 0.644736 (0.075021)\n",
      "Testing 3110/5184\n",
      "0.1 3 2 5 sqrt mae 0.5 100: Weighted 0.794616 (0.064797)\n",
      "0.1 3 2 5 sqrt mae 0.5 100: Macro 0.674574 (0.089638)\n",
      "Testing 3111/5184\n",
      "0.1 3 2 5 sqrt mae 0.5 200: Weighted 0.789637 (0.079514)\n",
      "0.1 3 2 5 sqrt mae 0.5 200: Macro 0.670094 (0.109778)\n",
      "Testing 3112/5184\n",
      "0.1 3 2 5 sqrt mae 0.5 500: Weighted 0.792735 (0.072717)\n",
      "0.1 3 2 5 sqrt mae 0.5 500: Macro 0.666352 (0.098783)\n",
      "Testing 3113/5184\n",
      "0.1 3 2 5 sqrt mae 0.75 50: Weighted 0.782234 (0.064091)\n",
      "0.1 3 2 5 sqrt mae 0.75 50: Macro 0.664851 (0.088458)\n",
      "Testing 3114/5184\n",
      "0.1 3 2 5 sqrt mae 0.75 100: Weighted 0.792454 (0.077052)\n",
      "0.1 3 2 5 sqrt mae 0.75 100: Macro 0.670459 (0.109403)\n",
      "Testing 3115/5184\n",
      "0.1 3 2 5 sqrt mae 0.75 200: Weighted 0.768665 (0.061337)\n",
      "0.1 3 2 5 sqrt mae 0.75 200: Macro 0.631013 (0.081793)\n",
      "Testing 3116/5184\n",
      "0.1 3 2 5 sqrt mae 0.75 500: Weighted 0.797847 (0.074310)\n",
      "0.1 3 2 5 sqrt mae 0.75 500: Macro 0.669636 (0.099090)\n",
      "Testing 3117/5184\n",
      "0.1 3 2 5 sqrt mae 1.0 50: Weighted 0.773042 (0.074695)\n",
      "0.1 3 2 5 sqrt mae 1.0 50: Macro 0.644902 (0.112574)\n",
      "Testing 3118/5184\n",
      "0.1 3 2 5 sqrt mae 1.0 100: Weighted 0.774513 (0.084693)\n",
      "0.1 3 2 5 sqrt mae 1.0 100: Macro 0.641583 (0.112380)\n",
      "Testing 3119/5184\n",
      "0.1 3 2 5 sqrt mae 1.0 200: Weighted 0.778356 (0.080125)\n",
      "0.1 3 2 5 sqrt mae 1.0 200: Macro 0.644113 (0.101549)\n",
      "Testing 3120/5184\n",
      "0.1 3 2 5 sqrt mae 1.0 500: Weighted 0.773200 (0.081795)\n",
      "0.1 3 2 5 sqrt mae 1.0 500: Macro 0.638354 (0.107441)\n",
      "Testing 3121/5184\n",
      "0.1 3 2 8 log2 friedman_mse 0.5 50: Weighted 0.806516 (0.062619)\n",
      "0.1 3 2 8 log2 friedman_mse 0.5 50: Macro 0.697293 (0.089292)\n",
      "Testing 3122/5184\n",
      "0.1 3 2 8 log2 friedman_mse 0.5 100: Weighted 0.819505 (0.076386)\n",
      "0.1 3 2 8 log2 friedman_mse 0.5 100: Macro 0.720767 (0.106200)\n",
      "Testing 3123/5184\n",
      "0.1 3 2 8 log2 friedman_mse 0.5 200: Weighted 0.819384 (0.068646)\n",
      "0.1 3 2 8 log2 friedman_mse 0.5 200: Macro 0.714510 (0.101120)\n",
      "Testing 3124/5184\n",
      "0.1 3 2 8 log2 friedman_mse 0.5 500: Weighted 0.813343 (0.066680)\n",
      "0.1 3 2 8 log2 friedman_mse 0.5 500: Macro 0.699218 (0.105586)\n",
      "Testing 3125/5184\n",
      "0.1 3 2 8 log2 friedman_mse 0.75 50: Weighted 0.801572 (0.070419)\n",
      "0.1 3 2 8 log2 friedman_mse 0.75 50: Macro 0.693310 (0.096284)\n",
      "Testing 3126/5184\n",
      "0.1 3 2 8 log2 friedman_mse 0.75 100: Weighted 0.812405 (0.086010)\n",
      "0.1 3 2 8 log2 friedman_mse 0.75 100: Macro 0.699907 (0.126045)\n",
      "Testing 3127/5184\n",
      "0.1 3 2 8 log2 friedman_mse 0.75 200: Weighted 0.831324 (0.082988)\n",
      "0.1 3 2 8 log2 friedman_mse 0.75 200: Macro 0.734400 (0.136362)\n",
      "Testing 3128/5184\n",
      "0.1 3 2 8 log2 friedman_mse 0.75 500: Weighted 0.822635 (0.072627)\n",
      "0.1 3 2 8 log2 friedman_mse 0.75 500: Macro 0.726946 (0.110015)\n",
      "Testing 3129/5184\n",
      "0.1 3 2 8 log2 friedman_mse 1.0 50: Weighted 0.792852 (0.068855)\n",
      "0.1 3 2 8 log2 friedman_mse 1.0 50: Macro 0.681673 (0.091421)\n",
      "Testing 3130/5184\n",
      "0.1 3 2 8 log2 friedman_mse 1.0 100: Weighted 0.801988 (0.073004)\n",
      "0.1 3 2 8 log2 friedman_mse 1.0 100: Macro 0.697063 (0.113356)\n",
      "Testing 3131/5184\n",
      "0.1 3 2 8 log2 friedman_mse 1.0 200: Weighted 0.804477 (0.084264)\n",
      "0.1 3 2 8 log2 friedman_mse 1.0 200: Macro 0.694902 (0.122351)\n",
      "Testing 3132/5184\n",
      "0.1 3 2 8 log2 friedman_mse 1.0 500: Weighted 0.809243 (0.089679)\n",
      "0.1 3 2 8 log2 friedman_mse 1.0 500: Macro 0.711424 (0.138508)\n",
      "Testing 3133/5184\n",
      "0.1 3 2 8 log2 mae 0.5 50: Weighted 0.798292 (0.068043)\n",
      "0.1 3 2 8 log2 mae 0.5 50: Macro 0.678231 (0.088277)\n",
      "Testing 3134/5184\n",
      "0.1 3 2 8 log2 mae 0.5 100: Weighted 0.806651 (0.094301)\n",
      "0.1 3 2 8 log2 mae 0.5 100: Macro 0.697184 (0.133457)\n",
      "Testing 3135/5184\n",
      "0.1 3 2 8 log2 mae 0.5 200: Weighted 0.804231 (0.073221)\n",
      "0.1 3 2 8 log2 mae 0.5 200: Macro 0.691966 (0.100638)\n",
      "Testing 3136/5184\n",
      "0.1 3 2 8 log2 mae 0.5 500: Weighted 0.781274 (0.078136)\n",
      "0.1 3 2 8 log2 mae 0.5 500: Macro 0.660511 (0.111714)\n",
      "Testing 3137/5184\n",
      "0.1 3 2 8 log2 mae 0.75 50: Weighted 0.793748 (0.077684)\n",
      "0.1 3 2 8 log2 mae 0.75 50: Macro 0.676833 (0.104562)\n",
      "Testing 3138/5184\n",
      "0.1 3 2 8 log2 mae 0.75 100: Weighted 0.780628 (0.088502)\n",
      "0.1 3 2 8 log2 mae 0.75 100: Macro 0.652754 (0.128416)\n",
      "Testing 3139/5184\n",
      "0.1 3 2 8 log2 mae 0.75 200: Weighted 0.790710 (0.079342)\n",
      "0.1 3 2 8 log2 mae 0.75 200: Macro 0.657270 (0.115313)\n",
      "Testing 3140/5184\n",
      "0.1 3 2 8 log2 mae 0.75 500: Weighted 0.786507 (0.091110)\n",
      "0.1 3 2 8 log2 mae 0.75 500: Macro 0.665503 (0.134426)\n",
      "Testing 3141/5184\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1 3 2 8 log2 mae 1.0 50: Weighted 0.769167 (0.105520)\n",
      "0.1 3 2 8 log2 mae 1.0 50: Macro 0.643420 (0.146248)\n",
      "Testing 3142/5184\n",
      "0.1 3 2 8 log2 mae 1.0 100: Weighted 0.771912 (0.075616)\n",
      "0.1 3 2 8 log2 mae 1.0 100: Macro 0.633981 (0.104511)\n",
      "Testing 3143/5184\n",
      "0.1 3 2 8 log2 mae 1.0 200: Weighted 0.795589 (0.094135)\n",
      "0.1 3 2 8 log2 mae 1.0 200: Macro 0.667964 (0.144044)\n",
      "Testing 3144/5184\n",
      "0.1 3 2 8 log2 mae 1.0 500: Weighted 0.789546 (0.093105)\n",
      "0.1 3 2 8 log2 mae 1.0 500: Macro 0.668304 (0.132523)\n",
      "Testing 3145/5184\n",
      "0.1 3 2 8 sqrt friedman_mse 0.5 50: Weighted 0.825064 (0.070351)\n",
      "0.1 3 2 8 sqrt friedman_mse 0.5 50: Macro 0.725263 (0.096587)\n",
      "Testing 3146/5184\n",
      "0.1 3 2 8 sqrt friedman_mse 0.5 100: Weighted 0.817425 (0.073549)\n",
      "0.1 3 2 8 sqrt friedman_mse 0.5 100: Macro 0.706661 (0.106416)\n",
      "Testing 3147/5184\n",
      "0.1 3 2 8 sqrt friedman_mse 0.5 200: Weighted 0.810536 (0.076509)\n",
      "0.1 3 2 8 sqrt friedman_mse 0.5 200: Macro 0.707338 (0.125345)\n",
      "Testing 3148/5184\n",
      "0.1 3 2 8 sqrt friedman_mse 0.5 500: Weighted 0.817714 (0.078281)\n",
      "0.1 3 2 8 sqrt friedman_mse 0.5 500: Macro 0.714471 (0.124555)\n",
      "Testing 3149/5184\n",
      "0.1 3 2 8 sqrt friedman_mse 0.75 50: Weighted 0.803337 (0.074919)\n",
      "0.1 3 2 8 sqrt friedman_mse 0.75 50: Macro 0.694991 (0.105685)\n",
      "Testing 3150/5184\n",
      "0.1 3 2 8 sqrt friedman_mse 0.75 100: Weighted 0.813138 (0.077587)\n",
      "0.1 3 2 8 sqrt friedman_mse 0.75 100: Macro 0.704676 (0.115809)\n",
      "Testing 3151/5184\n",
      "0.1 3 2 8 sqrt friedman_mse 0.75 200: Weighted 0.803629 (0.088377)\n",
      "0.1 3 2 8 sqrt friedman_mse 0.75 200: Macro 0.700932 (0.134744)\n",
      "Testing 3152/5184\n",
      "0.1 3 2 8 sqrt friedman_mse 0.75 500: Weighted 0.815220 (0.073173)\n",
      "0.1 3 2 8 sqrt friedman_mse 0.75 500: Macro 0.712556 (0.114606)\n",
      "Testing 3153/5184\n",
      "0.1 3 2 8 sqrt friedman_mse 1.0 50: Weighted 0.792853 (0.071162)\n",
      "0.1 3 2 8 sqrt friedman_mse 1.0 50: Macro 0.684891 (0.111155)\n",
      "Testing 3154/5184\n",
      "0.1 3 2 8 sqrt friedman_mse 1.0 100: Weighted 0.799468 (0.093302)\n",
      "0.1 3 2 8 sqrt friedman_mse 1.0 100: Macro 0.691761 (0.135908)\n",
      "Testing 3155/5184\n",
      "0.1 3 2 8 sqrt friedman_mse 1.0 200: Weighted 0.803130 (0.074802)\n",
      "0.1 3 2 8 sqrt friedman_mse 1.0 200: Macro 0.697672 (0.110076)\n",
      "Testing 3156/5184\n",
      "0.1 3 2 8 sqrt friedman_mse 1.0 500: Weighted 0.788839 (0.091209)\n",
      "0.1 3 2 8 sqrt friedman_mse 1.0 500: Macro 0.678921 (0.128487)\n",
      "Testing 3157/5184\n",
      "0.1 3 2 8 sqrt mae 0.5 50: Weighted 0.807906 (0.071025)\n",
      "0.1 3 2 8 sqrt mae 0.5 50: Macro 0.699233 (0.106919)\n",
      "Testing 3158/5184\n",
      "0.1 3 2 8 sqrt mae 0.5 100: Weighted 0.799615 (0.072447)\n",
      "0.1 3 2 8 sqrt mae 0.5 100: Macro 0.681837 (0.099706)\n",
      "Testing 3159/5184\n",
      "0.1 3 2 8 sqrt mae 0.5 200: Weighted 0.814326 (0.081339)\n",
      "0.1 3 2 8 sqrt mae 0.5 200: Macro 0.707084 (0.114796)\n",
      "Testing 3160/5184\n",
      "0.1 3 2 8 sqrt mae 0.5 500: Weighted 0.800023 (0.068862)\n",
      "0.1 3 2 8 sqrt mae 0.5 500: Macro 0.690445 (0.090003)\n",
      "Testing 3161/5184\n",
      "0.1 3 2 8 sqrt mae 0.75 50: Weighted 0.783246 (0.086007)\n",
      "0.1 3 2 8 sqrt mae 0.75 50: Macro 0.653211 (0.125952)\n",
      "Testing 3162/5184\n",
      "0.1 3 2 8 sqrt mae 0.75 100: Weighted 0.790653 (0.101401)\n",
      "0.1 3 2 8 sqrt mae 0.75 100: Macro 0.672220 (0.149743)\n",
      "Testing 3163/5184\n",
      "0.1 3 2 8 sqrt mae 0.75 200: Weighted 0.787240 (0.083826)\n",
      "0.1 3 2 8 sqrt mae 0.75 200: Macro 0.666829 (0.123604)\n",
      "Testing 3164/5184\n",
      "0.1 3 2 8 sqrt mae 0.75 500: Weighted 0.790892 (0.087197)\n",
      "0.1 3 2 8 sqrt mae 0.75 500: Macro 0.662722 (0.128348)\n",
      "Testing 3165/5184\n",
      "0.1 3 2 8 sqrt mae 1.0 50: Weighted 0.773258 (0.094103)\n",
      "0.1 3 2 8 sqrt mae 1.0 50: Macro 0.645101 (0.135926)\n",
      "Testing 3166/5184\n",
      "0.1 3 2 8 sqrt mae 1.0 100: Weighted 0.759644 (0.090875)\n",
      "0.1 3 2 8 sqrt mae 1.0 100: Macro 0.622208 (0.128759)\n",
      "Testing 3167/5184\n",
      "0.1 3 2 8 sqrt mae 1.0 200: Weighted 0.785551 (0.095969)\n",
      "0.1 3 2 8 sqrt mae 1.0 200: Macro 0.656860 (0.139155)\n",
      "Testing 3168/5184\n",
      "0.1 3 2 8 sqrt mae 1.0 500: Weighted 0.783309 (0.080726)\n",
      "0.1 3 2 8 sqrt mae 1.0 500: Macro 0.651964 (0.115286)\n",
      "Testing 3169/5184\n",
      "0.1 3 4 3 log2 friedman_mse 0.5 50: Weighted 0.805809 (0.057156)\n",
      "0.1 3 4 3 log2 friedman_mse 0.5 50: Macro 0.691023 (0.077587)\n",
      "Testing 3170/5184\n",
      "0.1 3 4 3 log2 friedman_mse 0.5 100: Weighted 0.809659 (0.057462)\n",
      "0.1 3 4 3 log2 friedman_mse 0.5 100: Macro 0.698894 (0.094143)\n",
      "Testing 3171/5184\n",
      "0.1 3 4 3 log2 friedman_mse 0.5 200: Weighted 0.812749 (0.071755)\n",
      "0.1 3 4 3 log2 friedman_mse 0.5 200: Macro 0.713630 (0.100031)\n",
      "Testing 3172/5184\n",
      "0.1 3 4 3 log2 friedman_mse 0.5 500: Weighted 0.824865 (0.053184)\n",
      "0.1 3 4 3 log2 friedman_mse 0.5 500: Macro 0.739303 (0.078176)\n",
      "Testing 3173/5184\n",
      "0.1 3 4 3 log2 friedman_mse 0.75 50: Weighted 0.788893 (0.056507)\n",
      "0.1 3 4 3 log2 friedman_mse 0.75 50: Macro 0.682417 (0.080014)\n",
      "Testing 3174/5184\n",
      "0.1 3 4 3 log2 friedman_mse 0.75 100: Weighted 0.799206 (0.073960)\n",
      "0.1 3 4 3 log2 friedman_mse 0.75 100: Macro 0.700873 (0.109716)\n",
      "Testing 3175/5184\n",
      "0.1 3 4 3 log2 friedman_mse 0.75 200: Weighted 0.809070 (0.047171)\n",
      "0.1 3 4 3 log2 friedman_mse 0.75 200: Macro 0.705803 (0.068035)\n",
      "Testing 3176/5184\n",
      "0.1 3 4 3 log2 friedman_mse 0.75 500: Weighted 0.805211 (0.047840)\n",
      "0.1 3 4 3 log2 friedman_mse 0.75 500: Macro 0.704591 (0.066968)\n",
      "Testing 3177/5184\n",
      "0.1 3 4 3 log2 friedman_mse 1.0 50: Weighted 0.805081 (0.064978)\n",
      "0.1 3 4 3 log2 friedman_mse 1.0 50: Macro 0.697850 (0.083634)\n",
      "Testing 3178/5184\n",
      "0.1 3 4 3 log2 friedman_mse 1.0 100: Weighted 0.803667 (0.072869)\n",
      "0.1 3 4 3 log2 friedman_mse 1.0 100: Macro 0.703863 (0.102973)\n",
      "Testing 3179/5184\n",
      "0.1 3 4 3 log2 friedman_mse 1.0 200: Weighted 0.812542 (0.054288)\n",
      "0.1 3 4 3 log2 friedman_mse 1.0 200: Macro 0.717073 (0.080543)\n",
      "Testing 3180/5184\n",
      "0.1 3 4 3 log2 friedman_mse 1.0 500: Weighted 0.803414 (0.071851)\n",
      "0.1 3 4 3 log2 friedman_mse 1.0 500: Macro 0.708991 (0.103530)\n",
      "Testing 3181/5184\n",
      "0.1 3 4 3 log2 mae 0.5 50: Weighted 0.804056 (0.057553)\n",
      "0.1 3 4 3 log2 mae 0.5 50: Macro 0.688732 (0.078512)\n",
      "Testing 3182/5184\n",
      "0.1 3 4 3 log2 mae 0.5 100: Weighted 0.794899 (0.053387)\n",
      "0.1 3 4 3 log2 mae 0.5 100: Macro 0.674435 (0.078712)\n",
      "Testing 3183/5184\n",
      "0.1 3 4 3 log2 mae 0.5 200: Weighted 0.787499 (0.058594)\n",
      "0.1 3 4 3 log2 mae 0.5 200: Macro 0.667495 (0.081911)\n",
      "Testing 3184/5184\n",
      "0.1 3 4 3 log2 mae 0.5 500: Weighted 0.785911 (0.057113)\n",
      "0.1 3 4 3 log2 mae 0.5 500: Macro 0.661219 (0.072727)\n",
      "Testing 3185/5184\n",
      "0.1 3 4 3 log2 mae 0.75 50: Weighted 0.786399 (0.071435)\n",
      "0.1 3 4 3 log2 mae 0.75 50: Macro 0.673777 (0.097058)\n",
      "Testing 3186/5184\n",
      "0.1 3 4 3 log2 mae 0.75 100: Weighted 0.774865 (0.071646)\n",
      "0.1 3 4 3 log2 mae 0.75 100: Macro 0.656800 (0.096201)\n",
      "Testing 3187/5184\n",
      "0.1 3 4 3 log2 mae 0.75 200: Weighted 0.774814 (0.082077)\n",
      "0.1 3 4 3 log2 mae 0.75 200: Macro 0.650223 (0.112715)\n",
      "Testing 3188/5184\n",
      "0.1 3 4 3 log2 mae 0.75 500: Weighted 0.785659 (0.079594)\n",
      "0.1 3 4 3 log2 mae 0.75 500: Macro 0.661984 (0.108115)\n",
      "Testing 3189/5184\n",
      "0.1 3 4 3 log2 mae 1.0 50: Weighted 0.770043 (0.077893)\n",
      "0.1 3 4 3 log2 mae 1.0 50: Macro 0.644780 (0.109246)\n",
      "Testing 3190/5184\n",
      "0.1 3 4 3 log2 mae 1.0 100: Weighted 0.760593 (0.075947)\n",
      "0.1 3 4 3 log2 mae 1.0 100: Macro 0.623177 (0.106712)\n",
      "Testing 3191/5184\n",
      "0.1 3 4 3 log2 mae 1.0 200: Weighted 0.771377 (0.075522)\n",
      "0.1 3 4 3 log2 mae 1.0 200: Macro 0.642360 (0.112669)\n",
      "Testing 3192/5184\n",
      "0.1 3 4 3 log2 mae 1.0 500: Weighted 0.766723 (0.090236)\n",
      "0.1 3 4 3 log2 mae 1.0 500: Macro 0.624861 (0.126059)\n",
      "Testing 3193/5184\n",
      "0.1 3 4 3 sqrt friedman_mse 0.5 50: Weighted 0.807938 (0.059469)\n",
      "0.1 3 4 3 sqrt friedman_mse 0.5 50: Macro 0.705797 (0.080480)\n",
      "Testing 3194/5184\n",
      "0.1 3 4 3 sqrt friedman_mse 0.5 100: Weighted 0.825742 (0.066032)\n",
      "0.1 3 4 3 sqrt friedman_mse 0.5 100: Macro 0.724912 (0.100183)\n",
      "Testing 3195/5184\n",
      "0.1 3 4 3 sqrt friedman_mse 0.5 200: Weighted 0.810103 (0.055841)\n",
      "0.1 3 4 3 sqrt friedman_mse 0.5 200: Macro 0.712440 (0.084715)\n",
      "Testing 3196/5184\n",
      "0.1 3 4 3 sqrt friedman_mse 0.5 500: Weighted 0.809621 (0.067386)\n",
      "0.1 3 4 3 sqrt friedman_mse 0.5 500: Macro 0.717249 (0.100611)\n",
      "Testing 3197/5184\n",
      "0.1 3 4 3 sqrt friedman_mse 0.75 50: Weighted 0.802460 (0.058833)\n",
      "0.1 3 4 3 sqrt friedman_mse 0.75 50: Macro 0.692412 (0.078903)\n",
      "Testing 3198/5184\n",
      "0.1 3 4 3 sqrt friedman_mse 0.75 100: Weighted 0.806565 (0.052403)\n",
      "0.1 3 4 3 sqrt friedman_mse 0.75 100: Macro 0.709960 (0.079120)\n",
      "Testing 3199/5184\n",
      "0.1 3 4 3 sqrt friedman_mse 0.75 200: Weighted 0.811467 (0.055024)\n",
      "0.1 3 4 3 sqrt friedman_mse 0.75 200: Macro 0.711415 (0.085697)\n",
      "Testing 3200/5184\n",
      "0.1 3 4 3 sqrt friedman_mse 0.75 500: Weighted 0.799879 (0.059286)\n",
      "0.1 3 4 3 sqrt friedman_mse 0.75 500: Macro 0.690887 (0.088092)\n",
      "Testing 3201/5184\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1 3 4 3 sqrt friedman_mse 1.0 50: Weighted 0.802499 (0.058748)\n",
      "0.1 3 4 3 sqrt friedman_mse 1.0 50: Macro 0.701770 (0.076984)\n",
      "Testing 3202/5184\n",
      "0.1 3 4 3 sqrt friedman_mse 1.0 100: Weighted 0.809033 (0.056817)\n",
      "0.1 3 4 3 sqrt friedman_mse 1.0 100: Macro 0.710008 (0.078485)\n",
      "Testing 3203/5184\n",
      "0.1 3 4 3 sqrt friedman_mse 1.0 200: Weighted 0.817432 (0.057356)\n",
      "0.1 3 4 3 sqrt friedman_mse 1.0 200: Macro 0.725041 (0.085864)\n",
      "Testing 3204/5184\n",
      "0.1 3 4 3 sqrt friedman_mse 1.0 500: Weighted 0.807299 (0.060973)\n",
      "0.1 3 4 3 sqrt friedman_mse 1.0 500: Macro 0.707195 (0.092112)\n",
      "Testing 3205/5184\n",
      "0.1 3 4 3 sqrt mae 0.5 50: Weighted 0.811793 (0.047701)\n",
      "0.1 3 4 3 sqrt mae 0.5 50: Macro 0.701738 (0.062676)\n",
      "Testing 3206/5184\n",
      "0.1 3 4 3 sqrt mae 0.5 100: Weighted 0.802696 (0.060389)\n",
      "0.1 3 4 3 sqrt mae 0.5 100: Macro 0.686843 (0.081751)\n",
      "Testing 3207/5184\n",
      "0.1 3 4 3 sqrt mae 0.5 200: Weighted 0.786897 (0.069114)\n",
      "0.1 3 4 3 sqrt mae 0.5 200: Macro 0.664594 (0.106009)\n",
      "Testing 3208/5184\n",
      "0.1 3 4 3 sqrt mae 0.5 500: Weighted 0.777304 (0.091090)\n",
      "0.1 3 4 3 sqrt mae 0.5 500: Macro 0.654214 (0.125876)\n",
      "Testing 3209/5184\n",
      "0.1 3 4 3 sqrt mae 0.75 50: Weighted 0.791868 (0.068705)\n",
      "0.1 3 4 3 sqrt mae 0.75 50: Macro 0.670218 (0.095028)\n",
      "Testing 3210/5184\n",
      "0.1 3 4 3 sqrt mae 0.75 100: Weighted 0.769809 (0.066878)\n",
      "0.1 3 4 3 sqrt mae 0.75 100: Macro 0.648682 (0.089685)\n",
      "Testing 3211/5184\n",
      "0.1 3 4 3 sqrt mae 0.75 200: Weighted 0.770373 (0.064136)\n",
      "0.1 3 4 3 sqrt mae 0.75 200: Macro 0.638948 (0.082519)\n",
      "Testing 3212/5184\n",
      "0.1 3 4 3 sqrt mae 0.75 500: Weighted 0.789990 (0.067603)\n",
      "0.1 3 4 3 sqrt mae 0.75 500: Macro 0.659091 (0.089238)\n",
      "Testing 3213/5184\n",
      "0.1 3 4 3 sqrt mae 1.0 50: Weighted 0.781536 (0.059784)\n",
      "0.1 3 4 3 sqrt mae 1.0 50: Macro 0.660506 (0.078696)\n",
      "Testing 3214/5184\n",
      "0.1 3 4 3 sqrt mae 1.0 100: Weighted 0.766241 (0.082262)\n",
      "0.1 3 4 3 sqrt mae 1.0 100: Macro 0.636856 (0.122731)\n",
      "Testing 3215/5184\n",
      "0.1 3 4 3 sqrt mae 1.0 200: Weighted 0.740485 (0.067253)\n",
      "0.1 3 4 3 sqrt mae 1.0 200: Macro 0.595102 (0.088297)\n",
      "Testing 3216/5184\n",
      "0.1 3 4 3 sqrt mae 1.0 500: Weighted 0.791136 (0.076137)\n",
      "0.1 3 4 3 sqrt mae 1.0 500: Macro 0.671356 (0.107801)\n",
      "Testing 3217/5184\n",
      "0.1 3 4 5 log2 friedman_mse 0.5 50: Weighted 0.820806 (0.070431)\n",
      "0.1 3 4 5 log2 friedman_mse 0.5 50: Macro 0.719315 (0.095833)\n",
      "Testing 3218/5184\n",
      "0.1 3 4 5 log2 friedman_mse 0.5 100: Weighted 0.816222 (0.079718)\n",
      "0.1 3 4 5 log2 friedman_mse 0.5 100: Macro 0.725982 (0.114202)\n",
      "Testing 3219/5184\n",
      "0.1 3 4 5 log2 friedman_mse 0.5 200: Weighted 0.820048 (0.082845)\n",
      "0.1 3 4 5 log2 friedman_mse 0.5 200: Macro 0.721478 (0.118211)\n",
      "Testing 3220/5184\n",
      "0.1 3 4 5 log2 friedman_mse 0.5 500: Weighted 0.811079 (0.067935)\n",
      "0.1 3 4 5 log2 friedman_mse 0.5 500: Macro 0.712300 (0.112211)\n",
      "Testing 3221/5184\n",
      "0.1 3 4 5 log2 friedman_mse 0.75 50: Weighted 0.800237 (0.066331)\n",
      "0.1 3 4 5 log2 friedman_mse 0.75 50: Macro 0.689005 (0.096669)\n",
      "Testing 3222/5184\n",
      "0.1 3 4 5 log2 friedman_mse 0.75 100: Weighted 0.812024 (0.077617)\n",
      "0.1 3 4 5 log2 friedman_mse 0.75 100: Macro 0.705680 (0.110956)\n",
      "Testing 3223/5184\n",
      "0.1 3 4 5 log2 friedman_mse 0.75 200: Weighted 0.827845 (0.067272)\n",
      "0.1 3 4 5 log2 friedman_mse 0.75 200: Macro 0.730866 (0.107494)\n",
      "Testing 3224/5184\n",
      "0.1 3 4 5 log2 friedman_mse 0.75 500: Weighted 0.807358 (0.073837)\n",
      "0.1 3 4 5 log2 friedman_mse 0.75 500: Macro 0.699539 (0.115729)\n",
      "Testing 3225/5184\n",
      "0.1 3 4 5 log2 friedman_mse 1.0 50: Weighted 0.809780 (0.089827)\n",
      "0.1 3 4 5 log2 friedman_mse 1.0 50: Macro 0.713702 (0.123038)\n",
      "Testing 3226/5184\n",
      "0.1 3 4 5 log2 friedman_mse 1.0 100: Weighted 0.801315 (0.089525)\n",
      "0.1 3 4 5 log2 friedman_mse 1.0 100: Macro 0.693077 (0.130115)\n",
      "Testing 3227/5184\n",
      "0.1 3 4 5 log2 friedman_mse 1.0 200: Weighted 0.807582 (0.081878)\n",
      "0.1 3 4 5 log2 friedman_mse 1.0 200: Macro 0.705045 (0.116161)\n",
      "Testing 3228/5184\n",
      "0.1 3 4 5 log2 friedman_mse 1.0 500: Weighted 0.808146 (0.090497)\n",
      "0.1 3 4 5 log2 friedman_mse 1.0 500: Macro 0.700015 (0.132884)\n",
      "Testing 3229/5184\n",
      "0.1 3 4 5 log2 mae 0.5 50: Weighted 0.792957 (0.069560)\n",
      "0.1 3 4 5 log2 mae 0.5 50: Macro 0.672436 (0.095535)\n",
      "Testing 3230/5184\n",
      "0.1 3 4 5 log2 mae 0.5 100: Weighted 0.788288 (0.071292)\n",
      "0.1 3 4 5 log2 mae 0.5 100: Macro 0.659490 (0.101462)\n",
      "Testing 3231/5184\n",
      "0.1 3 4 5 log2 mae 0.5 200: Weighted 0.793717 (0.064015)\n",
      "0.1 3 4 5 log2 mae 0.5 200: Macro 0.663939 (0.087136)\n",
      "Testing 3232/5184\n",
      "0.1 3 4 5 log2 mae 0.5 500: Weighted 0.778672 (0.077168)\n",
      "0.1 3 4 5 log2 mae 0.5 500: Macro 0.655048 (0.102695)\n",
      "Testing 3233/5184\n",
      "0.1 3 4 5 log2 mae 0.75 50: Weighted 0.778302 (0.070158)\n",
      "0.1 3 4 5 log2 mae 0.75 50: Macro 0.653933 (0.101204)\n",
      "Testing 3234/5184\n",
      "0.1 3 4 5 log2 mae 0.75 100: Weighted 0.790050 (0.075527)\n",
      "0.1 3 4 5 log2 mae 0.75 100: Macro 0.663022 (0.103030)\n",
      "Testing 3235/5184\n",
      "0.1 3 4 5 log2 mae 0.75 200: Weighted 0.771505 (0.064779)\n",
      "0.1 3 4 5 log2 mae 0.75 200: Macro 0.635427 (0.083953)\n",
      "Testing 3236/5184\n",
      "0.1 3 4 5 log2 mae 0.75 500: Weighted 0.777470 (0.069438)\n",
      "0.1 3 4 5 log2 mae 0.75 500: Macro 0.646525 (0.088523)\n",
      "Testing 3237/5184\n",
      "0.1 3 4 5 log2 mae 1.0 50: Weighted 0.769266 (0.076649)\n",
      "0.1 3 4 5 log2 mae 1.0 50: Macro 0.638360 (0.110872)\n",
      "Testing 3238/5184\n",
      "0.1 3 4 5 log2 mae 1.0 100: Weighted 0.776035 (0.071648)\n",
      "0.1 3 4 5 log2 mae 1.0 100: Macro 0.642298 (0.103146)\n",
      "Testing 3239/5184\n",
      "0.1 3 4 5 log2 mae 1.0 200: Weighted 0.797948 (0.099300)\n",
      "0.1 3 4 5 log2 mae 1.0 200: Macro 0.686421 (0.142196)\n",
      "Testing 3240/5184\n",
      "0.1 3 4 5 log2 mae 1.0 500: Weighted 0.774111 (0.075165)\n",
      "0.1 3 4 5 log2 mae 1.0 500: Macro 0.642243 (0.094179)\n",
      "Testing 3241/5184\n",
      "0.1 3 4 5 sqrt friedman_mse 0.5 50: Weighted 0.820602 (0.066997)\n",
      "0.1 3 4 5 sqrt friedman_mse 0.5 50: Macro 0.713452 (0.094412)\n",
      "Testing 3242/5184\n",
      "0.1 3 4 5 sqrt friedman_mse 0.5 100: Weighted 0.805092 (0.059452)\n",
      "0.1 3 4 5 sqrt friedman_mse 0.5 100: Macro 0.695427 (0.086110)\n",
      "Testing 3243/5184\n",
      "0.1 3 4 5 sqrt friedman_mse 0.5 200: Weighted 0.819990 (0.080682)\n",
      "0.1 3 4 5 sqrt friedman_mse 0.5 200: Macro 0.725111 (0.110705)\n",
      "Testing 3244/5184\n",
      "0.1 3 4 5 sqrt friedman_mse 0.5 500: Weighted 0.830533 (0.056292)\n",
      "0.1 3 4 5 sqrt friedman_mse 0.5 500: Macro 0.744057 (0.077206)\n",
      "Testing 3245/5184\n",
      "0.1 3 4 5 sqrt friedman_mse 0.75 50: Weighted 0.802729 (0.084241)\n",
      "0.1 3 4 5 sqrt friedman_mse 0.75 50: Macro 0.694776 (0.113414)\n",
      "Testing 3246/5184\n",
      "0.1 3 4 5 sqrt friedman_mse 0.75 100: Weighted 0.807858 (0.091707)\n",
      "0.1 3 4 5 sqrt friedman_mse 0.75 100: Macro 0.705675 (0.128616)\n",
      "Testing 3247/5184\n",
      "0.1 3 4 5 sqrt friedman_mse 0.75 200: Weighted 0.816152 (0.067878)\n",
      "0.1 3 4 5 sqrt friedman_mse 0.75 200: Macro 0.719284 (0.099591)\n",
      "Testing 3248/5184\n",
      "0.1 3 4 5 sqrt friedman_mse 0.75 500: Weighted 0.810412 (0.066029)\n",
      "0.1 3 4 5 sqrt friedman_mse 0.75 500: Macro 0.705918 (0.099585)\n",
      "Testing 3249/5184\n",
      "0.1 3 4 5 sqrt friedman_mse 1.0 50: Weighted 0.810935 (0.085200)\n",
      "0.1 3 4 5 sqrt friedman_mse 1.0 50: Macro 0.713192 (0.117476)\n",
      "Testing 3250/5184\n",
      "0.1 3 4 5 sqrt friedman_mse 1.0 100: Weighted 0.808208 (0.090532)\n",
      "0.1 3 4 5 sqrt friedman_mse 1.0 100: Macro 0.698997 (0.132154)\n",
      "Testing 3251/5184\n",
      "0.1 3 4 5 sqrt friedman_mse 1.0 200: Weighted 0.803828 (0.084981)\n",
      "0.1 3 4 5 sqrt friedman_mse 1.0 200: Macro 0.691772 (0.123653)\n",
      "Testing 3252/5184\n",
      "0.1 3 4 5 sqrt friedman_mse 1.0 500: Weighted 0.802277 (0.086479)\n",
      "0.1 3 4 5 sqrt friedman_mse 1.0 500: Macro 0.694269 (0.128907)\n",
      "Testing 3253/5184\n",
      "0.1 3 4 5 sqrt mae 0.5 50: Weighted 0.815180 (0.073233)\n",
      "0.1 3 4 5 sqrt mae 0.5 50: Macro 0.694248 (0.110290)\n",
      "Testing 3254/5184\n",
      "0.1 3 4 5 sqrt mae 0.5 100: Weighted 0.813438 (0.102343)\n",
      "0.1 3 4 5 sqrt mae 0.5 100: Macro 0.712986 (0.142166)\n",
      "Testing 3255/5184\n",
      "0.1 3 4 5 sqrt mae 0.5 200: Weighted 0.789524 (0.076850)\n",
      "0.1 3 4 5 sqrt mae 0.5 200: Macro 0.671621 (0.112964)\n",
      "Testing 3256/5184\n",
      "0.1 3 4 5 sqrt mae 0.5 500: Weighted 0.785470 (0.089432)\n",
      "0.1 3 4 5 sqrt mae 0.5 500: Macro 0.662185 (0.108599)\n",
      "Testing 3257/5184\n",
      "0.1 3 4 5 sqrt mae 0.75 50: Weighted 0.787725 (0.079652)\n",
      "0.1 3 4 5 sqrt mae 0.75 50: Macro 0.669101 (0.116069)\n",
      "Testing 3258/5184\n",
      "0.1 3 4 5 sqrt mae 0.75 100: Weighted 0.762704 (0.075471)\n",
      "0.1 3 4 5 sqrt mae 0.75 100: Macro 0.629641 (0.104861)\n",
      "Testing 3259/5184\n",
      "0.1 3 4 5 sqrt mae 0.75 200: Weighted 0.769679 (0.085621)\n",
      "0.1 3 4 5 sqrt mae 0.75 200: Macro 0.635141 (0.106627)\n",
      "Testing 3260/5184\n",
      "0.1 3 4 5 sqrt mae 0.75 500: Weighted 0.792426 (0.080136)\n",
      "0.1 3 4 5 sqrt mae 0.75 500: Macro 0.664936 (0.103477)\n",
      "Testing 3261/5184\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1 3 4 5 sqrt mae 1.0 50: Weighted 0.772924 (0.077811)\n",
      "0.1 3 4 5 sqrt mae 1.0 50: Macro 0.641664 (0.109488)\n",
      "Testing 3262/5184\n",
      "0.1 3 4 5 sqrt mae 1.0 100: Weighted 0.775761 (0.103374)\n",
      "0.1 3 4 5 sqrt mae 1.0 100: Macro 0.644673 (0.150265)\n",
      "Testing 3263/5184\n",
      "0.1 3 4 5 sqrt mae 1.0 200: Weighted 0.778763 (0.091052)\n",
      "0.1 3 4 5 sqrt mae 1.0 200: Macro 0.656323 (0.126026)\n",
      "Testing 3264/5184\n",
      "0.1 3 4 5 sqrt mae 1.0 500: Weighted 0.774537 (0.064357)\n",
      "0.1 3 4 5 sqrt mae 1.0 500: Macro 0.640607 (0.079891)\n",
      "Testing 3265/5184\n",
      "0.1 3 4 8 log2 friedman_mse 0.5 50: Weighted 0.817967 (0.066186)\n",
      "0.1 3 4 8 log2 friedman_mse 0.5 50: Macro 0.724908 (0.093947)\n",
      "Testing 3266/5184\n",
      "0.1 3 4 8 log2 friedman_mse 0.5 100: Weighted 0.815423 (0.061920)\n",
      "0.1 3 4 8 log2 friedman_mse 0.5 100: Macro 0.707742 (0.094670)\n",
      "Testing 3267/5184\n",
      "0.1 3 4 8 log2 friedman_mse 0.5 200: Weighted 0.822889 (0.077430)\n",
      "0.1 3 4 8 log2 friedman_mse 0.5 200: Macro 0.723179 (0.118618)\n",
      "Testing 3268/5184\n",
      "0.1 3 4 8 log2 friedman_mse 0.5 500: Weighted 0.818617 (0.058276)\n",
      "0.1 3 4 8 log2 friedman_mse 0.5 500: Macro 0.714069 (0.093220)\n",
      "Testing 3269/5184\n",
      "0.1 3 4 8 log2 friedman_mse 0.75 50: Weighted 0.804795 (0.083895)\n",
      "0.1 3 4 8 log2 friedman_mse 0.75 50: Macro 0.703964 (0.113753)\n",
      "Testing 3270/5184\n",
      "0.1 3 4 8 log2 friedman_mse 0.75 100: Weighted 0.808781 (0.075861)\n",
      "0.1 3 4 8 log2 friedman_mse 0.75 100: Macro 0.702660 (0.117257)\n",
      "Testing 3271/5184\n",
      "0.1 3 4 8 log2 friedman_mse 0.75 200: Weighted 0.826934 (0.068176)\n",
      "0.1 3 4 8 log2 friedman_mse 0.75 200: Macro 0.731412 (0.105401)\n",
      "Testing 3272/5184\n",
      "0.1 3 4 8 log2 friedman_mse 0.75 500: Weighted 0.824229 (0.094442)\n",
      "0.1 3 4 8 log2 friedman_mse 0.75 500: Macro 0.733273 (0.135670)\n",
      "Testing 3273/5184\n",
      "0.1 3 4 8 log2 friedman_mse 1.0 50: Weighted 0.791427 (0.077589)\n",
      "0.1 3 4 8 log2 friedman_mse 1.0 50: Macro 0.687481 (0.106456)\n",
      "Testing 3274/5184\n",
      "0.1 3 4 8 log2 friedman_mse 1.0 100: Weighted 0.796357 (0.064484)\n",
      "0.1 3 4 8 log2 friedman_mse 1.0 100: Macro 0.686479 (0.093362)\n",
      "Testing 3275/5184\n",
      "0.1 3 4 8 log2 friedman_mse 1.0 200: Weighted 0.813168 (0.076705)\n",
      "0.1 3 4 8 log2 friedman_mse 1.0 200: Macro 0.710639 (0.107679)\n",
      "Testing 3276/5184\n",
      "0.1 3 4 8 log2 friedman_mse 1.0 500: Weighted 0.798033 (0.072966)\n",
      "0.1 3 4 8 log2 friedman_mse 1.0 500: Macro 0.688428 (0.104449)\n",
      "Testing 3277/5184\n",
      "0.1 3 4 8 log2 mae 0.5 50: Weighted 0.797212 (0.082760)\n",
      "0.1 3 4 8 log2 mae 0.5 50: Macro 0.683413 (0.111888)\n",
      "Testing 3278/5184\n",
      "0.1 3 4 8 log2 mae 0.5 100: Weighted 0.812047 (0.083899)\n",
      "0.1 3 4 8 log2 mae 0.5 100: Macro 0.695741 (0.127552)\n",
      "Testing 3279/5184\n",
      "0.1 3 4 8 log2 mae 0.5 200: Weighted 0.818673 (0.083011)\n",
      "0.1 3 4 8 log2 mae 0.5 200: Macro 0.712909 (0.114895)\n",
      "Testing 3280/5184\n",
      "0.1 3 4 8 log2 mae 0.5 500: Weighted 0.790452 (0.073168)\n",
      "0.1 3 4 8 log2 mae 0.5 500: Macro 0.671610 (0.109663)\n",
      "Testing 3281/5184\n",
      "0.1 3 4 8 log2 mae 0.75 50: Weighted 0.779580 (0.089442)\n",
      "0.1 3 4 8 log2 mae 0.75 50: Macro 0.650471 (0.128244)\n",
      "Testing 3282/5184\n",
      "0.1 3 4 8 log2 mae 0.75 100: Weighted 0.779761 (0.091099)\n",
      "0.1 3 4 8 log2 mae 0.75 100: Macro 0.642492 (0.135090)\n",
      "Testing 3283/5184\n",
      "0.1 3 4 8 log2 mae 0.75 200: Weighted 0.792125 (0.090875)\n",
      "0.1 3 4 8 log2 mae 0.75 200: Macro 0.672507 (0.124416)\n",
      "Testing 3284/5184\n",
      "0.1 3 4 8 log2 mae 0.75 500: Weighted 0.799829 (0.077082)\n",
      "0.1 3 4 8 log2 mae 0.75 500: Macro 0.681292 (0.104297)\n",
      "Testing 3285/5184\n",
      "0.1 3 4 8 log2 mae 1.0 50: Weighted 0.777092 (0.077169)\n",
      "0.1 3 4 8 log2 mae 1.0 50: Macro 0.651515 (0.105054)\n",
      "Testing 3286/5184\n",
      "0.1 3 4 8 log2 mae 1.0 100: Weighted 0.773621 (0.074829)\n",
      "0.1 3 4 8 log2 mae 1.0 100: Macro 0.648189 (0.107935)\n",
      "Testing 3287/5184\n",
      "0.1 3 4 8 log2 mae 1.0 200: Weighted 0.769804 (0.082923)\n",
      "0.1 3 4 8 log2 mae 1.0 200: Macro 0.633397 (0.122046)\n",
      "Testing 3288/5184\n",
      "0.1 3 4 8 log2 mae 1.0 500: Weighted 0.775694 (0.078784)\n",
      "0.1 3 4 8 log2 mae 1.0 500: Macro 0.643652 (0.122357)\n",
      "Testing 3289/5184\n",
      "0.1 3 4 8 sqrt friedman_mse 0.5 50: Weighted 0.831595 (0.077726)\n",
      "0.1 3 4 8 sqrt friedman_mse 0.5 50: Macro 0.738998 (0.114529)\n",
      "Testing 3290/5184\n",
      "0.1 3 4 8 sqrt friedman_mse 0.5 100: Weighted 0.814896 (0.080901)\n",
      "0.1 3 4 8 sqrt friedman_mse 0.5 100: Macro 0.710509 (0.116091)\n",
      "Testing 3291/5184\n",
      "0.1 3 4 8 sqrt friedman_mse 0.5 200: Weighted 0.803724 (0.067781)\n",
      "0.1 3 4 8 sqrt friedman_mse 0.5 200: Macro 0.697710 (0.097690)\n",
      "Testing 3292/5184\n",
      "0.1 3 4 8 sqrt friedman_mse 0.5 500: Weighted 0.817741 (0.075108)\n",
      "0.1 3 4 8 sqrt friedman_mse 0.5 500: Macro 0.724755 (0.130793)\n",
      "Testing 3293/5184\n",
      "0.1 3 4 8 sqrt friedman_mse 0.75 50: Weighted 0.823014 (0.085579)\n",
      "0.1 3 4 8 sqrt friedman_mse 0.75 50: Macro 0.725216 (0.119715)\n",
      "Testing 3294/5184\n",
      "0.1 3 4 8 sqrt friedman_mse 0.75 100: Weighted 0.821652 (0.090357)\n",
      "0.1 3 4 8 sqrt friedman_mse 0.75 100: Macro 0.720930 (0.135558)\n",
      "Testing 3295/5184\n",
      "0.1 3 4 8 sqrt friedman_mse 0.75 200: Weighted 0.840392 (0.079407)\n",
      "0.1 3 4 8 sqrt friedman_mse 0.75 200: Macro 0.747768 (0.119816)\n",
      "Testing 3296/5184\n",
      "0.1 3 4 8 sqrt friedman_mse 0.75 500: Weighted 0.810538 (0.096354)\n",
      "0.1 3 4 8 sqrt friedman_mse 0.75 500: Macro 0.707337 (0.140152)\n",
      "Testing 3297/5184\n",
      "0.1 3 4 8 sqrt friedman_mse 1.0 50: Weighted 0.790653 (0.077148)\n",
      "0.1 3 4 8 sqrt friedman_mse 1.0 50: Macro 0.679014 (0.107879)\n",
      "Testing 3298/5184\n",
      "0.1 3 4 8 sqrt friedman_mse 1.0 100: Weighted 0.798033 (0.072966)\n",
      "0.1 3 4 8 sqrt friedman_mse 1.0 100: Macro 0.688428 (0.104449)\n",
      "Testing 3299/5184\n",
      "0.1 3 4 8 sqrt friedman_mse 1.0 200: Weighted 0.797732 (0.083492)\n",
      "0.1 3 4 8 sqrt friedman_mse 1.0 200: Macro 0.690037 (0.118912)\n",
      "Testing 3300/5184\n",
      "0.1 3 4 8 sqrt friedman_mse 1.0 500: Weighted 0.825309 (0.081943)\n",
      "0.1 3 4 8 sqrt friedman_mse 1.0 500: Macro 0.731977 (0.115236)\n",
      "Testing 3301/5184\n",
      "0.1 3 4 8 sqrt mae 0.5 50: Weighted 0.813112 (0.064498)\n",
      "0.1 3 4 8 sqrt mae 0.5 50: Macro 0.702683 (0.090503)\n",
      "Testing 3302/5184\n",
      "0.1 3 4 8 sqrt mae 0.5 100: Weighted 0.800876 (0.057933)\n",
      "0.1 3 4 8 sqrt mae 0.5 100: Macro 0.685596 (0.076227)\n",
      "Testing 3303/5184\n",
      "0.1 3 4 8 sqrt mae 0.5 200: Weighted 0.802590 (0.075085)\n",
      "0.1 3 4 8 sqrt mae 0.5 200: Macro 0.681109 (0.112613)\n",
      "Testing 3304/5184\n",
      "0.1 3 4 8 sqrt mae 0.5 500: Weighted 0.797568 (0.082717)\n",
      "0.1 3 4 8 sqrt mae 0.5 500: Macro 0.675960 (0.130468)\n",
      "Testing 3305/5184\n",
      "0.1 3 4 8 sqrt mae 0.75 50: Weighted 0.774782 (0.086497)\n",
      "0.1 3 4 8 sqrt mae 0.75 50: Macro 0.637908 (0.129080)\n",
      "Testing 3306/5184\n",
      "0.1 3 4 8 sqrt mae 0.75 100: Weighted 0.781688 (0.094763)\n",
      "0.1 3 4 8 sqrt mae 0.75 100: Macro 0.650812 (0.136326)\n",
      "Testing 3307/5184\n",
      "0.1 3 4 8 sqrt mae 0.75 200: Weighted 0.806540 (0.089187)\n",
      "0.1 3 4 8 sqrt mae 0.75 200: Macro 0.685517 (0.133082)\n",
      "Testing 3308/5184\n",
      "0.1 3 4 8 sqrt mae 0.75 500: Weighted 0.798477 (0.086438)\n",
      "0.1 3 4 8 sqrt mae 0.75 500: Macro 0.679441 (0.135011)\n",
      "Testing 3309/5184\n",
      "0.1 3 4 8 sqrt mae 1.0 50: Weighted 0.776227 (0.095753)\n",
      "0.1 3 4 8 sqrt mae 1.0 50: Macro 0.650533 (0.132553)\n",
      "Testing 3310/5184\n",
      "0.1 3 4 8 sqrt mae 1.0 100: Weighted 0.779428 (0.097660)\n",
      "0.1 3 4 8 sqrt mae 1.0 100: Macro 0.647446 (0.139595)\n",
      "Testing 3311/5184\n",
      "0.1 3 4 8 sqrt mae 1.0 200: Weighted 0.799621 (0.101316)\n",
      "0.1 3 4 8 sqrt mae 1.0 200: Macro 0.681076 (0.151174)\n",
      "Testing 3312/5184\n",
      "0.1 3 4 8 sqrt mae 1.0 500: Weighted 0.767181 (0.084873)\n",
      "0.1 3 4 8 sqrt mae 1.0 500: Macro 0.624138 (0.116560)\n",
      "Testing 3313/5184\n",
      "0.1 3 6 3 log2 friedman_mse 0.5 50: Weighted 0.815617 (0.044934)\n",
      "0.1 3 6 3 log2 friedman_mse 0.5 50: Macro 0.706538 (0.060861)\n",
      "Testing 3314/5184\n",
      "0.1 3 6 3 log2 friedman_mse 0.5 100: Weighted 0.782414 (0.069591)\n",
      "0.1 3 6 3 log2 friedman_mse 0.5 100: Macro 0.670109 (0.100346)\n",
      "Testing 3315/5184\n",
      "0.1 3 6 3 log2 friedman_mse 0.5 200: Weighted 0.831637 (0.070972)\n",
      "0.1 3 6 3 log2 friedman_mse 0.5 200: Macro 0.741223 (0.096833)\n",
      "Testing 3316/5184\n",
      "0.1 3 6 3 log2 friedman_mse 0.5 500: Weighted 0.810655 (0.051085)\n",
      "0.1 3 6 3 log2 friedman_mse 0.5 500: Macro 0.704164 (0.075864)\n",
      "Testing 3317/5184\n",
      "0.1 3 6 3 log2 friedman_mse 0.75 50: Weighted 0.789259 (0.054104)\n",
      "0.1 3 6 3 log2 friedman_mse 0.75 50: Macro 0.671597 (0.072238)\n",
      "Testing 3318/5184\n",
      "0.1 3 6 3 log2 friedman_mse 0.75 100: Weighted 0.803810 (0.055605)\n",
      "0.1 3 6 3 log2 friedman_mse 0.75 100: Macro 0.693990 (0.077250)\n",
      "Testing 3319/5184\n",
      "0.1 3 6 3 log2 friedman_mse 0.75 200: Weighted 0.815072 (0.061168)\n",
      "0.1 3 6 3 log2 friedman_mse 0.75 200: Macro 0.720694 (0.080925)\n",
      "Testing 3320/5184\n",
      "0.1 3 6 3 log2 friedman_mse 0.75 500: Weighted 0.815162 (0.065086)\n",
      "0.1 3 6 3 log2 friedman_mse 0.75 500: Macro 0.719960 (0.100219)\n",
      "Testing 3321/5184\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1 3 6 3 log2 friedman_mse 1.0 50: Weighted 0.797015 (0.066067)\n",
      "0.1 3 6 3 log2 friedman_mse 1.0 50: Macro 0.691437 (0.088854)\n",
      "Testing 3322/5184\n",
      "0.1 3 6 3 log2 friedman_mse 1.0 100: Weighted 0.804452 (0.061626)\n",
      "0.1 3 6 3 log2 friedman_mse 1.0 100: Macro 0.706532 (0.082115)\n",
      "Testing 3323/5184\n",
      "0.1 3 6 3 log2 friedman_mse 1.0 200: Weighted 0.816564 (0.049678)\n",
      "0.1 3 6 3 log2 friedman_mse 1.0 200: Macro 0.722495 (0.075097)\n",
      "Testing 3324/5184\n",
      "0.1 3 6 3 log2 friedman_mse 1.0 500: Weighted 0.810070 (0.059761)\n",
      "0.1 3 6 3 log2 friedman_mse 1.0 500: Macro 0.712649 (0.089153)\n",
      "Testing 3325/5184\n",
      "0.1 3 6 3 log2 mae 0.5 50: Weighted 0.815894 (0.054386)\n",
      "0.1 3 6 3 log2 mae 0.5 50: Macro 0.697414 (0.082782)\n",
      "Testing 3326/5184\n",
      "0.1 3 6 3 log2 mae 0.5 100: Weighted 0.780523 (0.056814)\n",
      "0.1 3 6 3 log2 mae 0.5 100: Macro 0.660324 (0.077562)\n",
      "Testing 3327/5184\n",
      "0.1 3 6 3 log2 mae 0.5 200: Weighted 0.775049 (0.063405)\n",
      "0.1 3 6 3 log2 mae 0.5 200: Macro 0.639709 (0.090020)\n",
      "Testing 3328/5184\n",
      "0.1 3 6 3 log2 mae 0.5 500: Weighted 0.795147 (0.083350)\n",
      "0.1 3 6 3 log2 mae 0.5 500: Macro 0.677704 (0.115376)\n",
      "Testing 3329/5184\n",
      "0.1 3 6 3 log2 mae 0.75 50: Weighted 0.779980 (0.063369)\n",
      "0.1 3 6 3 log2 mae 0.75 50: Macro 0.654556 (0.087290)\n",
      "Testing 3330/5184\n",
      "0.1 3 6 3 log2 mae 0.75 100: Weighted 0.788591 (0.076990)\n",
      "0.1 3 6 3 log2 mae 0.75 100: Macro 0.676569 (0.107699)\n",
      "Testing 3331/5184\n",
      "0.1 3 6 3 log2 mae 0.75 200: Weighted 0.794453 (0.091761)\n",
      "0.1 3 6 3 log2 mae 0.75 200: Macro 0.677119 (0.130432)\n",
      "Testing 3332/5184\n",
      "0.1 3 6 3 log2 mae 0.75 500: Weighted 0.777584 (0.070903)\n",
      "0.1 3 6 3 log2 mae 0.75 500: Macro 0.651718 (0.098303)\n",
      "Testing 3333/5184\n",
      "0.1 3 6 3 log2 mae 1.0 50: Weighted 0.792218 (0.070519)\n",
      "0.1 3 6 3 log2 mae 1.0 50: Macro 0.676341 (0.097785)\n",
      "Testing 3334/5184\n",
      "0.1 3 6 3 log2 mae 1.0 100: Weighted 0.759192 (0.063471)\n",
      "0.1 3 6 3 log2 mae 1.0 100: Macro 0.626026 (0.089262)\n",
      "Testing 3335/5184\n",
      "0.1 3 6 3 log2 mae 1.0 200: Weighted 0.752849 (0.054796)\n",
      "0.1 3 6 3 log2 mae 1.0 200: Macro 0.616112 (0.078343)\n",
      "Testing 3336/5184\n",
      "0.1 3 6 3 log2 mae 1.0 500: Weighted 0.770510 (0.067170)\n",
      "0.1 3 6 3 log2 mae 1.0 500: Macro 0.635425 (0.083710)\n",
      "Testing 3337/5184\n",
      "0.1 3 6 3 sqrt friedman_mse 0.5 50: Weighted 0.794221 (0.055852)\n",
      "0.1 3 6 3 sqrt friedman_mse 0.5 50: Macro 0.688520 (0.067327)\n",
      "Testing 3338/5184\n",
      "0.1 3 6 3 sqrt friedman_mse 0.5 100: Weighted 0.808327 (0.043304)\n",
      "0.1 3 6 3 sqrt friedman_mse 0.5 100: Macro 0.700846 (0.058468)\n",
      "Testing 3339/5184\n",
      "0.1 3 6 3 sqrt friedman_mse 0.5 200: Weighted 0.812039 (0.069124)\n",
      "0.1 3 6 3 sqrt friedman_mse 0.5 200: Macro 0.703159 (0.101625)\n",
      "Testing 3340/5184\n",
      "0.1 3 6 3 sqrt friedman_mse 0.5 500: Weighted 0.799420 (0.055293)\n",
      "0.1 3 6 3 sqrt friedman_mse 0.5 500: Macro 0.689851 (0.077370)\n",
      "Testing 3341/5184\n",
      "0.1 3 6 3 sqrt friedman_mse 0.75 50: Weighted 0.799940 (0.071756)\n",
      "0.1 3 6 3 sqrt friedman_mse 0.75 50: Macro 0.692927 (0.094914)\n",
      "Testing 3342/5184\n",
      "0.1 3 6 3 sqrt friedman_mse 0.75 100: Weighted 0.818330 (0.077492)\n",
      "0.1 3 6 3 sqrt friedman_mse 0.75 100: Macro 0.719961 (0.112514)\n",
      "Testing 3343/5184\n",
      "0.1 3 6 3 sqrt friedman_mse 0.75 200: Weighted 0.813230 (0.066414)\n",
      "0.1 3 6 3 sqrt friedman_mse 0.75 200: Macro 0.710029 (0.097592)\n",
      "Testing 3344/5184\n",
      "0.1 3 6 3 sqrt friedman_mse 0.75 500: Weighted 0.815434 (0.061711)\n",
      "0.1 3 6 3 sqrt friedman_mse 0.75 500: Macro 0.720971 (0.095037)\n",
      "Testing 3345/5184\n",
      "0.1 3 6 3 sqrt friedman_mse 1.0 50: Weighted 0.799470 (0.065534)\n",
      "0.1 3 6 3 sqrt friedman_mse 1.0 50: Macro 0.696921 (0.089994)\n",
      "Testing 3346/5184\n",
      "0.1 3 6 3 sqrt friedman_mse 1.0 100: Weighted 0.812575 (0.071664)\n",
      "0.1 3 6 3 sqrt friedman_mse 1.0 100: Macro 0.709565 (0.099327)\n",
      "Testing 3347/5184\n",
      "0.1 3 6 3 sqrt friedman_mse 1.0 200: Weighted 0.806942 (0.058671)\n",
      "0.1 3 6 3 sqrt friedman_mse 1.0 200: Macro 0.706513 (0.090783)\n",
      "Testing 3348/5184\n",
      "0.1 3 6 3 sqrt friedman_mse 1.0 500: Weighted 0.806333 (0.061478)\n",
      "0.1 3 6 3 sqrt friedman_mse 1.0 500: Macro 0.707298 (0.092048)\n",
      "Testing 3349/5184\n",
      "0.1 3 6 3 sqrt mae 0.5 50: Weighted 0.807872 (0.062240)\n",
      "0.1 3 6 3 sqrt mae 0.5 50: Macro 0.688412 (0.091515)\n",
      "Testing 3350/5184\n",
      "0.1 3 6 3 sqrt mae 0.5 100: Weighted 0.794288 (0.052809)\n",
      "0.1 3 6 3 sqrt mae 0.5 100: Macro 0.675663 (0.074739)\n",
      "Testing 3351/5184\n",
      "0.1 3 6 3 sqrt mae 0.5 200: Weighted 0.779542 (0.070952)\n",
      "0.1 3 6 3 sqrt mae 0.5 200: Macro 0.651135 (0.102580)\n",
      "Testing 3352/5184\n",
      "0.1 3 6 3 sqrt mae 0.5 500: Weighted 0.797730 (0.072032)\n",
      "0.1 3 6 3 sqrt mae 0.5 500: Macro 0.679139 (0.100071)\n",
      "Testing 3353/5184\n",
      "0.1 3 6 3 sqrt mae 0.75 50: Weighted 0.778420 (0.070424)\n",
      "0.1 3 6 3 sqrt mae 0.75 50: Macro 0.661263 (0.094554)\n",
      "Testing 3354/5184\n",
      "0.1 3 6 3 sqrt mae 0.75 100: Weighted 0.761132 (0.066165)\n",
      "0.1 3 6 3 sqrt mae 0.75 100: Macro 0.627053 (0.089909)\n",
      "Testing 3355/5184\n",
      "0.1 3 6 3 sqrt mae 0.75 200: Weighted 0.758501 (0.048388)\n",
      "0.1 3 6 3 sqrt mae 0.75 200: Macro 0.618132 (0.062585)\n",
      "Testing 3356/5184\n",
      "0.1 3 6 3 sqrt mae 0.75 500: Weighted 0.774465 (0.081458)\n",
      "0.1 3 6 3 sqrt mae 0.75 500: Macro 0.652778 (0.116329)\n",
      "Testing 3357/5184\n",
      "0.1 3 6 3 sqrt mae 1.0 50: Weighted 0.769417 (0.059668)\n",
      "0.1 3 6 3 sqrt mae 1.0 50: Macro 0.645198 (0.082070)\n",
      "Testing 3358/5184\n",
      "0.1 3 6 3 sqrt mae 1.0 100: Weighted 0.763681 (0.062104)\n",
      "0.1 3 6 3 sqrt mae 1.0 100: Macro 0.625378 (0.083013)\n",
      "Testing 3359/5184\n",
      "0.1 3 6 3 sqrt mae 1.0 200: Weighted 0.755473 (0.074422)\n",
      "0.1 3 6 3 sqrt mae 1.0 200: Macro 0.610749 (0.098822)\n",
      "Testing 3360/5184\n",
      "0.1 3 6 3 sqrt mae 1.0 500: Weighted 0.759214 (0.062202)\n",
      "0.1 3 6 3 sqrt mae 1.0 500: Macro 0.620616 (0.094037)\n",
      "Testing 3361/5184\n",
      "0.1 3 6 5 log2 friedman_mse 0.5 50: Weighted 0.822468 (0.054920)\n",
      "0.1 3 6 5 log2 friedman_mse 0.5 50: Macro 0.720124 (0.068159)\n",
      "Testing 3362/5184\n",
      "0.1 3 6 5 log2 friedman_mse 0.5 100: Weighted 0.807565 (0.063738)\n",
      "0.1 3 6 5 log2 friedman_mse 0.5 100: Macro 0.702672 (0.091316)\n",
      "Testing 3363/5184\n",
      "0.1 3 6 5 log2 friedman_mse 0.5 200: Weighted 0.800536 (0.084721)\n",
      "0.1 3 6 5 log2 friedman_mse 0.5 200: Macro 0.687248 (0.127619)\n",
      "Testing 3364/5184\n",
      "0.1 3 6 5 log2 friedman_mse 0.5 500: Weighted 0.828560 (0.075353)\n",
      "0.1 3 6 5 log2 friedman_mse 0.5 500: Macro 0.743887 (0.111944)\n",
      "Testing 3365/5184\n",
      "0.1 3 6 5 log2 friedman_mse 0.75 50: Weighted 0.813041 (0.076832)\n",
      "0.1 3 6 5 log2 friedman_mse 0.75 50: Macro 0.712961 (0.105507)\n",
      "Testing 3366/5184\n",
      "0.1 3 6 5 log2 friedman_mse 0.75 100: Weighted 0.797803 (0.071207)\n",
      "0.1 3 6 5 log2 friedman_mse 0.75 100: Macro 0.695039 (0.099181)\n",
      "Testing 3367/5184\n",
      "0.1 3 6 5 log2 friedman_mse 0.75 200: Weighted 0.802981 (0.083310)\n",
      "0.1 3 6 5 log2 friedman_mse 0.75 200: Macro 0.704533 (0.123810)\n",
      "Testing 3368/5184\n",
      "0.1 3 6 5 log2 friedman_mse 0.75 500: Weighted 0.809064 (0.078823)\n",
      "0.1 3 6 5 log2 friedman_mse 0.75 500: Macro 0.702090 (0.122964)\n",
      "Testing 3369/5184\n",
      "0.1 3 6 5 log2 friedman_mse 1.0 50: Weighted 0.798999 (0.065096)\n",
      "0.1 3 6 5 log2 friedman_mse 1.0 50: Macro 0.692329 (0.098066)\n",
      "Testing 3370/5184\n",
      "0.1 3 6 5 log2 friedman_mse 1.0 100: Weighted 0.815007 (0.064541)\n",
      "0.1 3 6 5 log2 friedman_mse 1.0 100: Macro 0.707941 (0.093306)\n",
      "Testing 3371/5184\n",
      "0.1 3 6 5 log2 friedman_mse 1.0 200: Weighted 0.803613 (0.084716)\n",
      "0.1 3 6 5 log2 friedman_mse 1.0 200: Macro 0.695255 (0.127669)\n",
      "Testing 3372/5184\n",
      "0.1 3 6 5 log2 friedman_mse 1.0 500: Weighted 0.808208 (0.090532)\n",
      "0.1 3 6 5 log2 friedman_mse 1.0 500: Macro 0.698997 (0.132154)\n",
      "Testing 3373/5184\n",
      "0.1 3 6 5 log2 mae 0.5 50: Weighted 0.789398 (0.062270)\n",
      "0.1 3 6 5 log2 mae 0.5 50: Macro 0.665510 (0.086614)\n",
      "Testing 3374/5184\n",
      "0.1 3 6 5 log2 mae 0.5 100: Weighted 0.801172 (0.076035)\n",
      "0.1 3 6 5 log2 mae 0.5 100: Macro 0.681510 (0.113109)\n",
      "Testing 3375/5184\n",
      "0.1 3 6 5 log2 mae 0.5 200: Weighted 0.787830 (0.079087)\n",
      "0.1 3 6 5 log2 mae 0.5 200: Macro 0.668420 (0.108811)\n",
      "Testing 3376/5184\n",
      "0.1 3 6 5 log2 mae 0.5 500: Weighted 0.797515 (0.072966)\n",
      "0.1 3 6 5 log2 mae 0.5 500: Macro 0.683791 (0.095934)\n",
      "Testing 3377/5184\n",
      "0.1 3 6 5 log2 mae 0.75 50: Weighted 0.793149 (0.066609)\n",
      "0.1 3 6 5 log2 mae 0.75 50: Macro 0.674242 (0.090689)\n",
      "Testing 3378/5184\n",
      "0.1 3 6 5 log2 mae 0.75 100: Weighted 0.799067 (0.080488)\n",
      "0.1 3 6 5 log2 mae 0.75 100: Macro 0.681887 (0.113226)\n",
      "Testing 3379/5184\n",
      "0.1 3 6 5 log2 mae 0.75 200: Weighted 0.770641 (0.077361)\n",
      "0.1 3 6 5 log2 mae 0.75 200: Macro 0.634778 (0.109930)\n",
      "Testing 3380/5184\n",
      "0.1 3 6 5 log2 mae 0.75 500: Weighted 0.792563 (0.074835)\n",
      "0.1 3 6 5 log2 mae 0.75 500: Macro 0.677098 (0.094301)\n",
      "Testing 3381/5184\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1 3 6 5 log2 mae 1.0 50: Weighted 0.765302 (0.074556)\n",
      "0.1 3 6 5 log2 mae 1.0 50: Macro 0.625398 (0.099384)\n",
      "Testing 3382/5184\n",
      "0.1 3 6 5 log2 mae 1.0 100: Weighted 0.750794 (0.078862)\n",
      "0.1 3 6 5 log2 mae 1.0 100: Macro 0.601525 (0.103519)\n",
      "Testing 3383/5184\n",
      "0.1 3 6 5 log2 mae 1.0 200: Weighted 0.789166 (0.090748)\n",
      "0.1 3 6 5 log2 mae 1.0 200: Macro 0.658958 (0.131509)\n",
      "Testing 3384/5184\n",
      "0.1 3 6 5 log2 mae 1.0 500: Weighted 0.775082 (0.090653)\n",
      "0.1 3 6 5 log2 mae 1.0 500: Macro 0.641490 (0.124800)\n",
      "Testing 3385/5184\n",
      "0.1 3 6 5 sqrt friedman_mse 0.5 50: Weighted 0.818271 (0.058983)\n",
      "0.1 3 6 5 sqrt friedman_mse 0.5 50: Macro 0.725848 (0.091490)\n",
      "Testing 3386/5184\n",
      "0.1 3 6 5 sqrt friedman_mse 0.5 100: Weighted 0.807285 (0.081011)\n",
      "0.1 3 6 5 sqrt friedman_mse 0.5 100: Macro 0.707257 (0.119632)\n",
      "Testing 3387/5184\n",
      "0.1 3 6 5 sqrt friedman_mse 0.5 200: Weighted 0.826144 (0.070556)\n",
      "0.1 3 6 5 sqrt friedman_mse 0.5 200: Macro 0.730598 (0.102196)\n",
      "Testing 3388/5184\n",
      "0.1 3 6 5 sqrt friedman_mse 0.5 500: Weighted 0.818945 (0.065454)\n",
      "0.1 3 6 5 sqrt friedman_mse 0.5 500: Macro 0.728658 (0.099470)\n",
      "Testing 3389/5184\n",
      "0.1 3 6 5 sqrt friedman_mse 0.75 50: Weighted 0.800030 (0.082234)\n",
      "0.1 3 6 5 sqrt friedman_mse 0.75 50: Macro 0.688537 (0.116282)\n",
      "Testing 3390/5184\n",
      "0.1 3 6 5 sqrt friedman_mse 0.75 100: Weighted 0.819734 (0.072440)\n",
      "0.1 3 6 5 sqrt friedman_mse 0.75 100: Macro 0.714789 (0.105386)\n",
      "Testing 3391/5184\n",
      "0.1 3 6 5 sqrt friedman_mse 0.75 200: Weighted 0.812768 (0.072727)\n",
      "0.1 3 6 5 sqrt friedman_mse 0.75 200: Macro 0.707057 (0.114399)\n",
      "Testing 3392/5184\n",
      "0.1 3 6 5 sqrt friedman_mse 0.75 500: Weighted 0.818445 (0.084810)\n",
      "0.1 3 6 5 sqrt friedman_mse 0.75 500: Macro 0.721636 (0.132158)\n",
      "Testing 3393/5184\n",
      "0.1 3 6 5 sqrt friedman_mse 1.0 50: Weighted 0.803410 (0.085190)\n",
      "0.1 3 6 5 sqrt friedman_mse 1.0 50: Macro 0.705853 (0.112500)\n",
      "Testing 3394/5184\n",
      "0.1 3 6 5 sqrt friedman_mse 1.0 100: Weighted 0.808653 (0.081489)\n",
      "0.1 3 6 5 sqrt friedman_mse 1.0 100: Macro 0.702475 (0.115544)\n",
      "Testing 3395/5184\n",
      "0.1 3 6 5 sqrt friedman_mse 1.0 200: Weighted 0.797875 (0.077395)\n",
      "0.1 3 6 5 sqrt friedman_mse 1.0 200: Macro 0.697199 (0.112923)\n",
      "Testing 3396/5184\n",
      "0.1 3 6 5 sqrt friedman_mse 1.0 500: Weighted 0.805001 (0.072323)\n",
      "0.1 3 6 5 sqrt friedman_mse 1.0 500: Macro 0.706347 (0.105945)\n",
      "Testing 3397/5184\n",
      "0.1 3 6 5 sqrt mae 0.5 50: Weighted 0.790664 (0.059376)\n",
      "0.1 3 6 5 sqrt mae 0.5 50: Macro 0.663504 (0.081901)\n",
      "Testing 3398/5184\n",
      "0.1 3 6 5 sqrt mae 0.5 100: Weighted 0.787890 (0.080610)\n",
      "0.1 3 6 5 sqrt mae 0.5 100: Macro 0.666299 (0.113901)\n",
      "Testing 3399/5184\n",
      "0.1 3 6 5 sqrt mae 0.5 200: Weighted 0.782177 (0.092521)\n",
      "0.1 3 6 5 sqrt mae 0.5 200: Macro 0.665951 (0.131883)\n",
      "Testing 3400/5184\n",
      "0.1 3 6 5 sqrt mae 0.5 500: Weighted 0.798228 (0.087288)\n",
      "0.1 3 6 5 sqrt mae 0.5 500: Macro 0.682604 (0.126232)\n",
      "Testing 3401/5184\n",
      "0.1 3 6 5 sqrt mae 0.75 50: Weighted 0.787196 (0.092071)\n",
      "0.1 3 6 5 sqrt mae 0.75 50: Macro 0.658156 (0.136144)\n",
      "Testing 3402/5184\n",
      "0.1 3 6 5 sqrt mae 0.75 100: Weighted 0.779310 (0.071107)\n",
      "0.1 3 6 5 sqrt mae 0.75 100: Macro 0.649605 (0.095051)\n",
      "Testing 3403/5184\n",
      "0.1 3 6 5 sqrt mae 0.75 200: Weighted 0.777772 (0.091272)\n",
      "0.1 3 6 5 sqrt mae 0.75 200: Macro 0.648139 (0.134107)\n",
      "Testing 3404/5184\n",
      "0.1 3 6 5 sqrt mae 0.75 500: Weighted 0.793076 (0.089994)\n",
      "0.1 3 6 5 sqrt mae 0.75 500: Macro 0.676641 (0.117174)\n",
      "Testing 3405/5184\n",
      "0.1 3 6 5 sqrt mae 1.0 50: Weighted 0.778510 (0.086841)\n",
      "0.1 3 6 5 sqrt mae 1.0 50: Macro 0.655426 (0.128774)\n",
      "Testing 3406/5184\n",
      "0.1 3 6 5 sqrt mae 1.0 100: Weighted 0.776015 (0.083591)\n",
      "0.1 3 6 5 sqrt mae 1.0 100: Macro 0.647691 (0.111688)\n",
      "Testing 3407/5184\n",
      "0.1 3 6 5 sqrt mae 1.0 200: Weighted 0.787928 (0.084219)\n",
      "0.1 3 6 5 sqrt mae 1.0 200: Macro 0.661338 (0.107277)\n",
      "Testing 3408/5184\n",
      "0.1 3 6 5 sqrt mae 1.0 500: Weighted 0.764507 (0.086046)\n",
      "0.1 3 6 5 sqrt mae 1.0 500: Macro 0.632197 (0.112819)\n",
      "Testing 3409/5184\n",
      "0.1 3 6 8 log2 friedman_mse 0.5 50: Weighted 0.807901 (0.069367)\n",
      "0.1 3 6 8 log2 friedman_mse 0.5 50: Macro 0.695138 (0.096377)\n",
      "Testing 3410/5184\n",
      "0.1 3 6 8 log2 friedman_mse 0.5 100: Weighted 0.819965 (0.070379)\n",
      "0.1 3 6 8 log2 friedman_mse 0.5 100: Macro 0.707958 (0.101257)\n",
      "Testing 3411/5184\n",
      "0.1 3 6 8 log2 friedman_mse 0.5 200: Weighted 0.810984 (0.078452)\n",
      "0.1 3 6 8 log2 friedman_mse 0.5 200: Macro 0.707227 (0.109701)\n",
      "Testing 3412/5184\n",
      "0.1 3 6 8 log2 friedman_mse 0.5 500: Weighted 0.817083 (0.077567)\n",
      "0.1 3 6 8 log2 friedman_mse 0.5 500: Macro 0.712319 (0.121177)\n",
      "Testing 3413/5184\n",
      "0.1 3 6 8 log2 friedman_mse 0.75 50: Weighted 0.808992 (0.077025)\n",
      "0.1 3 6 8 log2 friedman_mse 0.75 50: Macro 0.702679 (0.112046)\n",
      "Testing 3414/5184\n",
      "0.1 3 6 8 log2 friedman_mse 0.75 100: Weighted 0.823252 (0.087951)\n",
      "0.1 3 6 8 log2 friedman_mse 0.75 100: Macro 0.724437 (0.128435)\n",
      "Testing 3415/5184\n",
      "0.1 3 6 8 log2 friedman_mse 0.75 200: Weighted 0.814291 (0.072476)\n",
      "0.1 3 6 8 log2 friedman_mse 0.75 200: Macro 0.717790 (0.112511)\n",
      "Testing 3416/5184\n",
      "0.1 3 6 8 log2 friedman_mse 0.75 500: Weighted 0.824628 (0.081361)\n",
      "0.1 3 6 8 log2 friedman_mse 0.75 500: Macro 0.729052 (0.127218)\n",
      "Testing 3417/5184\n",
      "0.1 3 6 8 log2 friedman_mse 1.0 50: Weighted 0.800004 (0.082205)\n",
      "0.1 3 6 8 log2 friedman_mse 1.0 50: Macro 0.695103 (0.110339)\n",
      "Testing 3418/5184\n",
      "0.1 3 6 8 log2 friedman_mse 1.0 100: Weighted 0.795809 (0.085450)\n",
      "0.1 3 6 8 log2 friedman_mse 1.0 100: Macro 0.688332 (0.120809)\n",
      "Testing 3419/5184\n",
      "0.1 3 6 8 log2 friedman_mse 1.0 200: Weighted 0.823998 (0.087366)\n",
      "0.1 3 6 8 log2 friedman_mse 1.0 200: Macro 0.729398 (0.130248)\n",
      "Testing 3420/5184\n",
      "0.1 3 6 8 log2 friedman_mse 1.0 500: Weighted 0.808150 (0.101605)\n",
      "0.1 3 6 8 log2 friedman_mse 1.0 500: Macro 0.712890 (0.146532)\n",
      "Testing 3421/5184\n",
      "0.1 3 6 8 log2 mae 0.5 50: Weighted 0.796543 (0.072840)\n",
      "0.1 3 6 8 log2 mae 0.5 50: Macro 0.673411 (0.106019)\n",
      "Testing 3422/5184\n",
      "0.1 3 6 8 log2 mae 0.5 100: Weighted 0.798203 (0.072826)\n",
      "0.1 3 6 8 log2 mae 0.5 100: Macro 0.679580 (0.102056)\n",
      "Testing 3423/5184\n",
      "0.1 3 6 8 log2 mae 0.5 200: Weighted 0.802331 (0.075192)\n",
      "0.1 3 6 8 log2 mae 0.5 200: Macro 0.681581 (0.112765)\n",
      "Testing 3424/5184\n",
      "0.1 3 6 8 log2 mae 0.5 500: Weighted 0.797657 (0.059095)\n",
      "0.1 3 6 8 log2 mae 0.5 500: Macro 0.677986 (0.075537)\n",
      "Testing 3425/5184\n",
      "0.1 3 6 8 log2 mae 0.75 50: Weighted 0.780079 (0.068813)\n",
      "0.1 3 6 8 log2 mae 0.75 50: Macro 0.656183 (0.099053)\n",
      "Testing 3426/5184\n",
      "0.1 3 6 8 log2 mae 0.75 100: Weighted 0.784655 (0.086855)\n",
      "0.1 3 6 8 log2 mae 0.75 100: Macro 0.661918 (0.120547)\n",
      "Testing 3427/5184\n",
      "0.1 3 6 8 log2 mae 0.75 200: Weighted 0.773913 (0.073091)\n",
      "0.1 3 6 8 log2 mae 0.75 200: Macro 0.643938 (0.106741)\n",
      "Testing 3428/5184\n",
      "0.1 3 6 8 log2 mae 0.75 500: Weighted 0.795735 (0.091443)\n",
      "0.1 3 6 8 log2 mae 0.75 500: Macro 0.675372 (0.134590)\n",
      "Testing 3429/5184\n",
      "0.1 3 6 8 log2 mae 1.0 50: Weighted 0.754923 (0.073546)\n",
      "0.1 3 6 8 log2 mae 1.0 50: Macro 0.610160 (0.101574)\n",
      "Testing 3430/5184\n",
      "0.1 3 6 8 log2 mae 1.0 100: Weighted 0.772948 (0.088181)\n",
      "0.1 3 6 8 log2 mae 1.0 100: Macro 0.639226 (0.123344)\n",
      "Testing 3431/5184\n",
      "0.1 3 6 8 log2 mae 1.0 200: Weighted 0.785024 (0.080924)\n",
      "0.1 3 6 8 log2 mae 1.0 200: Macro 0.655809 (0.111651)\n",
      "Testing 3432/5184\n",
      "0.1 3 6 8 log2 mae 1.0 500: Weighted 0.792747 (0.086607)\n",
      "0.1 3 6 8 log2 mae 1.0 500: Macro 0.662373 (0.132779)\n",
      "Testing 3433/5184\n",
      "0.1 3 6 8 sqrt friedman_mse 0.5 50: Weighted 0.825468 (0.078316)\n",
      "0.1 3 6 8 sqrt friedman_mse 0.5 50: Macro 0.730143 (0.111818)\n",
      "Testing 3434/5184\n",
      "0.1 3 6 8 sqrt friedman_mse 0.5 100: Weighted 0.827725 (0.079709)\n",
      "0.1 3 6 8 sqrt friedman_mse 0.5 100: Macro 0.724815 (0.121996)\n",
      "Testing 3435/5184\n",
      "0.1 3 6 8 sqrt friedman_mse 0.5 200: Weighted 0.823419 (0.073567)\n",
      "0.1 3 6 8 sqrt friedman_mse 0.5 200: Macro 0.723431 (0.107444)\n",
      "Testing 3436/5184\n",
      "0.1 3 6 8 sqrt friedman_mse 0.5 500: Weighted 0.809660 (0.083864)\n",
      "0.1 3 6 8 sqrt friedman_mse 0.5 500: Macro 0.706202 (0.135441)\n",
      "Testing 3437/5184\n",
      "0.1 3 6 8 sqrt friedman_mse 0.75 50: Weighted 0.805574 (0.070829)\n",
      "0.1 3 6 8 sqrt friedman_mse 0.75 50: Macro 0.703611 (0.103779)\n",
      "Testing 3438/5184\n",
      "0.1 3 6 8 sqrt friedman_mse 0.75 100: Weighted 0.809433 (0.089961)\n",
      "0.1 3 6 8 sqrt friedman_mse 0.75 100: Macro 0.702207 (0.134101)\n",
      "Testing 3439/5184\n",
      "0.1 3 6 8 sqrt friedman_mse 0.75 200: Weighted 0.808352 (0.075489)\n",
      "0.1 3 6 8 sqrt friedman_mse 0.75 200: Macro 0.703158 (0.115650)\n",
      "Testing 3440/5184\n",
      "0.1 3 6 8 sqrt friedman_mse 0.75 500: Weighted 0.819239 (0.079993)\n",
      "0.1 3 6 8 sqrt friedman_mse 0.75 500: Macro 0.716607 (0.125373)\n",
      "Testing 3441/5184\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1 3 6 8 sqrt friedman_mse 1.0 50: Weighted 0.794336 (0.077723)\n",
      "0.1 3 6 8 sqrt friedman_mse 1.0 50: Macro 0.690384 (0.108294)\n",
      "Testing 3442/5184\n",
      "0.1 3 6 8 sqrt friedman_mse 1.0 100: Weighted 0.813023 (0.097062)\n",
      "0.1 3 6 8 sqrt friedman_mse 1.0 100: Macro 0.715925 (0.144607)\n",
      "Testing 3443/5184\n",
      "0.1 3 6 8 sqrt friedman_mse 1.0 200: Weighted 0.790603 (0.089632)\n",
      "0.1 3 6 8 sqrt friedman_mse 1.0 200: Macro 0.683865 (0.124246)\n",
      "Testing 3444/5184\n",
      "0.1 3 6 8 sqrt friedman_mse 1.0 500: Weighted 0.819625 (0.078276)\n",
      "0.1 3 6 8 sqrt friedman_mse 1.0 500: Macro 0.716899 (0.109118)\n",
      "Testing 3445/5184\n",
      "0.1 3 6 8 sqrt mae 0.5 50: Weighted 0.816804 (0.074134)\n",
      "0.1 3 6 8 sqrt mae 0.5 50: Macro 0.707100 (0.105983)\n",
      "Testing 3446/5184\n",
      "0.1 3 6 8 sqrt mae 0.5 100: Weighted 0.808013 (0.079071)\n",
      "0.1 3 6 8 sqrt mae 0.5 100: Macro 0.701492 (0.107824)\n",
      "Testing 3447/5184\n",
      "0.1 3 6 8 sqrt mae 0.5 200: Weighted 0.797409 (0.093126)\n",
      "0.1 3 6 8 sqrt mae 0.5 200: Macro 0.684790 (0.131002)\n",
      "Testing 3448/5184\n",
      "0.1 3 6 8 sqrt mae 0.5 500: Weighted 0.806029 (0.072734)\n",
      "0.1 3 6 8 sqrt mae 0.5 500: Macro 0.693019 (0.097602)\n",
      "Testing 3449/5184\n",
      "0.1 3 6 8 sqrt mae 0.75 50: Weighted 0.791271 (0.069706)\n",
      "0.1 3 6 8 sqrt mae 0.75 50: Macro 0.671718 (0.091087)\n",
      "Testing 3450/5184\n",
      "0.1 3 6 8 sqrt mae 0.75 100: Weighted 0.789652 (0.070533)\n",
      "0.1 3 6 8 sqrt mae 0.75 100: Macro 0.665392 (0.104764)\n",
      "Testing 3451/5184\n",
      "0.1 3 6 8 sqrt mae 0.75 200: Weighted 0.802652 (0.093009)\n",
      "0.1 3 6 8 sqrt mae 0.75 200: Macro 0.683060 (0.141041)\n",
      "Testing 3452/5184\n",
      "0.1 3 6 8 sqrt mae 0.75 500: Weighted 0.794457 (0.082350)\n",
      "0.1 3 6 8 sqrt mae 0.75 500: Macro 0.668582 (0.125910)\n",
      "Testing 3453/5184\n",
      "0.1 3 6 8 sqrt mae 1.0 50: Weighted 0.786487 (0.085169)\n",
      "0.1 3 6 8 sqrt mae 1.0 50: Macro 0.662208 (0.116651)\n",
      "Testing 3454/5184\n",
      "0.1 3 6 8 sqrt mae 1.0 100: Weighted 0.778362 (0.089612)\n",
      "0.1 3 6 8 sqrt mae 1.0 100: Macro 0.642374 (0.129307)\n",
      "Testing 3455/5184\n",
      "0.1 3 6 8 sqrt mae 1.0 200: Weighted 0.790408 (0.089031)\n",
      "0.1 3 6 8 sqrt mae 1.0 200: Macro 0.669893 (0.125015)\n",
      "Testing 3456/5184\n",
      "0.1 3 6 8 sqrt mae 1.0 500: Weighted 0.775759 (0.070305)\n",
      "0.1 3 6 8 sqrt mae 1.0 500: Macro 0.638152 (0.101142)\n",
      "Testing 3457/5184\n",
      "0.1 5 2 3 log2 friedman_mse 0.5 50: Weighted 0.821146 (0.076774)\n",
      "0.1 5 2 3 log2 friedman_mse 0.5 50: Macro 0.716244 (0.110384)\n",
      "Testing 3458/5184\n",
      "0.1 5 2 3 log2 friedman_mse 0.5 100: Weighted 0.811577 (0.070015)\n",
      "0.1 5 2 3 log2 friedman_mse 0.5 100: Macro 0.704402 (0.099332)\n",
      "Testing 3459/5184\n",
      "0.1 5 2 3 log2 friedman_mse 0.5 200: Weighted 0.816306 (0.060176)\n",
      "0.1 5 2 3 log2 friedman_mse 0.5 200: Macro 0.713288 (0.096389)\n",
      "Testing 3460/5184\n",
      "0.1 5 2 3 log2 friedman_mse 0.5 500: Weighted 0.815964 (0.048599)\n",
      "0.1 5 2 3 log2 friedman_mse 0.5 500: Macro 0.730426 (0.067188)\n",
      "Testing 3461/5184\n",
      "0.1 5 2 3 log2 friedman_mse 0.75 50: Weighted 0.820272 (0.071613)\n",
      "0.1 5 2 3 log2 friedman_mse 0.75 50: Macro 0.717065 (0.096653)\n",
      "Testing 3462/5184\n",
      "0.1 5 2 3 log2 friedman_mse 0.75 100: Weighted 0.816583 (0.064009)\n",
      "0.1 5 2 3 log2 friedman_mse 0.75 100: Macro 0.726000 (0.093366)\n",
      "Testing 3463/5184\n",
      "0.1 5 2 3 log2 friedman_mse 0.75 200: Weighted 0.810363 (0.058030)\n",
      "0.1 5 2 3 log2 friedman_mse 0.75 200: Macro 0.712822 (0.084958)\n",
      "Testing 3464/5184\n",
      "0.1 5 2 3 log2 friedman_mse 0.75 500: Weighted 0.808403 (0.046743)\n",
      "0.1 5 2 3 log2 friedman_mse 0.75 500: Macro 0.708836 (0.070635)\n",
      "Testing 3465/5184\n",
      "0.1 5 2 3 log2 friedman_mse 1.0 50: Weighted 0.809333 (0.072739)\n",
      "0.1 5 2 3 log2 friedman_mse 1.0 50: Macro 0.710565 (0.089337)\n",
      "Testing 3466/5184\n",
      "0.1 5 2 3 log2 friedman_mse 1.0 100: Weighted 0.820595 (0.072608)\n",
      "0.1 5 2 3 log2 friedman_mse 1.0 100: Macro 0.727328 (0.092395)\n",
      "Testing 3467/5184\n",
      "0.1 5 2 3 log2 friedman_mse 1.0 200: Weighted 0.797903 (0.068043)\n",
      "0.1 5 2 3 log2 friedman_mse 1.0 200: Macro 0.686849 (0.094861)\n",
      "Testing 3468/5184\n",
      "0.1 5 2 3 log2 friedman_mse 1.0 500: Weighted 0.804847 (0.058036)\n",
      "0.1 5 2 3 log2 friedman_mse 1.0 500: Macro 0.707795 (0.082054)\n",
      "Testing 3469/5184\n",
      "0.1 5 2 3 log2 mae 0.5 50: Weighted 0.820652 (0.048859)\n",
      "0.1 5 2 3 log2 mae 0.5 50: Macro 0.713921 (0.067276)\n",
      "Testing 3470/5184\n",
      "0.1 5 2 3 log2 mae 0.5 100: Weighted 0.791634 (0.056711)\n",
      "0.1 5 2 3 log2 mae 0.5 100: Macro 0.672267 (0.082346)\n",
      "Testing 3471/5184\n",
      "0.1 5 2 3 log2 mae 0.5 200: Weighted 0.772623 (0.064385)\n",
      "0.1 5 2 3 log2 mae 0.5 200: Macro 0.644382 (0.093030)\n",
      "Testing 3472/5184\n",
      "0.1 5 2 3 log2 mae 0.5 500: Weighted 0.777721 (0.076371)\n",
      "0.1 5 2 3 log2 mae 0.5 500: Macro 0.660991 (0.104186)\n",
      "Testing 3473/5184\n",
      "0.1 5 2 3 log2 mae 0.75 50: Weighted 0.787801 (0.074033)\n",
      "0.1 5 2 3 log2 mae 0.75 50: Macro 0.666182 (0.102652)\n",
      "Testing 3474/5184\n",
      "0.1 5 2 3 log2 mae 0.75 100: Weighted 0.772474 (0.079108)\n",
      "0.1 5 2 3 log2 mae 0.75 100: Macro 0.644275 (0.108487)\n",
      "Testing 3475/5184\n",
      "0.1 5 2 3 log2 mae 0.75 200: Weighted 0.766492 (0.071983)\n",
      "0.1 5 2 3 log2 mae 0.75 200: Macro 0.625963 (0.099145)\n",
      "Testing 3476/5184\n",
      "0.1 5 2 3 log2 mae 0.75 500: Weighted 0.766735 (0.080963)\n",
      "0.1 5 2 3 log2 mae 0.75 500: Macro 0.631715 (0.106624)\n",
      "Testing 3477/5184\n",
      "0.1 5 2 3 log2 mae 1.0 50: Weighted 0.783873 (0.076693)\n",
      "0.1 5 2 3 log2 mae 1.0 50: Macro 0.655522 (0.110829)\n",
      "Testing 3478/5184\n",
      "0.1 5 2 3 log2 mae 1.0 100: Weighted 0.794494 (0.079081)\n",
      "0.1 5 2 3 log2 mae 1.0 100: Macro 0.670082 (0.113768)\n",
      "Testing 3479/5184\n",
      "0.1 5 2 3 log2 mae 1.0 200: Weighted 0.760468 (0.069637)\n",
      "0.1 5 2 3 log2 mae 1.0 200: Macro 0.617750 (0.096038)\n",
      "Testing 3480/5184\n",
      "0.1 5 2 3 log2 mae 1.0 500: Weighted 0.774044 (0.075685)\n",
      "0.1 5 2 3 log2 mae 1.0 500: Macro 0.635390 (0.107382)\n",
      "Testing 3481/5184\n",
      "0.1 5 2 3 sqrt friedman_mse 0.5 50: Weighted 0.826341 (0.043705)\n",
      "0.1 5 2 3 sqrt friedman_mse 0.5 50: Macro 0.717679 (0.056591)\n",
      "Testing 3482/5184\n",
      "0.1 5 2 3 sqrt friedman_mse 0.5 100: Weighted 0.824623 (0.056765)\n",
      "0.1 5 2 3 sqrt friedman_mse 0.5 100: Macro 0.725139 (0.072452)\n",
      "Testing 3483/5184\n",
      "0.1 5 2 3 sqrt friedman_mse 0.5 200: Weighted 0.808903 (0.036686)\n",
      "0.1 5 2 3 sqrt friedman_mse 0.5 200: Macro 0.693805 (0.051751)\n",
      "Testing 3484/5184\n",
      "0.1 5 2 3 sqrt friedman_mse 0.5 500: Weighted 0.799223 (0.047569)\n",
      "0.1 5 2 3 sqrt friedman_mse 0.5 500: Macro 0.696077 (0.064840)\n",
      "Testing 3485/5184\n",
      "0.1 5 2 3 sqrt friedman_mse 0.75 50: Weighted 0.822856 (0.068233)\n",
      "0.1 5 2 3 sqrt friedman_mse 0.75 50: Macro 0.727183 (0.084016)\n",
      "Testing 3486/5184\n",
      "0.1 5 2 3 sqrt friedman_mse 0.75 100: Weighted 0.805926 (0.054468)\n",
      "0.1 5 2 3 sqrt friedman_mse 0.75 100: Macro 0.700681 (0.085187)\n",
      "Testing 3487/5184\n",
      "0.1 5 2 3 sqrt friedman_mse 0.75 200: Weighted 0.823914 (0.057855)\n",
      "0.1 5 2 3 sqrt friedman_mse 0.75 200: Macro 0.725750 (0.070348)\n",
      "Testing 3488/5184\n",
      "0.1 5 2 3 sqrt friedman_mse 0.75 500: Weighted 0.816964 (0.057880)\n",
      "0.1 5 2 3 sqrt friedman_mse 0.75 500: Macro 0.720842 (0.082639)\n",
      "Testing 3489/5184\n",
      "0.1 5 2 3 sqrt friedman_mse 1.0 50: Weighted 0.800003 (0.064102)\n",
      "0.1 5 2 3 sqrt friedman_mse 1.0 50: Macro 0.689263 (0.082563)\n",
      "Testing 3490/5184\n",
      "0.1 5 2 3 sqrt friedman_mse 1.0 100: Weighted 0.821403 (0.069355)\n",
      "0.1 5 2 3 sqrt friedman_mse 1.0 100: Macro 0.719748 (0.097357)\n",
      "Testing 3491/5184\n",
      "0.1 5 2 3 sqrt friedman_mse 1.0 200: Weighted 0.809943 (0.063370)\n",
      "0.1 5 2 3 sqrt friedman_mse 1.0 200: Macro 0.708324 (0.083539)\n",
      "Testing 3492/5184\n",
      "0.1 5 2 3 sqrt friedman_mse 1.0 500: Weighted 0.794623 (0.061072)\n",
      "0.1 5 2 3 sqrt friedman_mse 1.0 500: Macro 0.691607 (0.089340)\n",
      "Testing 3493/5184\n",
      "0.1 5 2 3 sqrt mae 0.5 50: Weighted 0.806733 (0.053194)\n",
      "0.1 5 2 3 sqrt mae 0.5 50: Macro 0.698583 (0.076932)\n",
      "Testing 3494/5184\n",
      "0.1 5 2 3 sqrt mae 0.5 100: Weighted 0.805079 (0.053859)\n",
      "0.1 5 2 3 sqrt mae 0.5 100: Macro 0.685470 (0.079881)\n",
      "Testing 3495/5184\n",
      "0.1 5 2 3 sqrt mae 0.5 200: Weighted 0.783878 (0.054956)\n",
      "0.1 5 2 3 sqrt mae 0.5 200: Macro 0.658156 (0.072620)\n",
      "Testing 3496/5184\n",
      "0.1 5 2 3 sqrt mae 0.5 500: Weighted 0.781435 (0.072443)\n",
      "0.1 5 2 3 sqrt mae 0.5 500: Macro 0.662257 (0.095235)\n",
      "Testing 3497/5184\n",
      "0.1 5 2 3 sqrt mae 0.75 50: Weighted 0.789431 (0.062257)\n",
      "0.1 5 2 3 sqrt mae 0.75 50: Macro 0.662031 (0.092471)\n",
      "Testing 3498/5184\n",
      "0.1 5 2 3 sqrt mae 0.75 100: Weighted 0.790521 (0.068505)\n",
      "0.1 5 2 3 sqrt mae 0.75 100: Macro 0.669539 (0.096419)\n",
      "Testing 3499/5184\n",
      "0.1 5 2 3 sqrt mae 0.75 200: Weighted 0.792257 (0.073786)\n",
      "0.1 5 2 3 sqrt mae 0.75 200: Macro 0.668126 (0.107348)\n",
      "Testing 3500/5184\n",
      "0.1 5 2 3 sqrt mae 0.75 500: Weighted 0.778391 (0.059802)\n",
      "0.1 5 2 3 sqrt mae 0.75 500: Macro 0.638265 (0.080702)\n",
      "Testing 3501/5184\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1 5 2 3 sqrt mae 1.0 50: Weighted 0.790906 (0.068968)\n",
      "0.1 5 2 3 sqrt mae 1.0 50: Macro 0.665837 (0.104327)\n",
      "Testing 3502/5184\n",
      "0.1 5 2 3 sqrt mae 1.0 100: Weighted 0.778427 (0.071542)\n",
      "0.1 5 2 3 sqrt mae 1.0 100: Macro 0.641765 (0.109705)\n",
      "Testing 3503/5184\n",
      "0.1 5 2 3 sqrt mae 1.0 200: Weighted 0.768367 (0.061902)\n",
      "0.1 5 2 3 sqrt mae 1.0 200: Macro 0.626283 (0.089870)\n",
      "Testing 3504/5184\n",
      "0.1 5 2 3 sqrt mae 1.0 500: Weighted 0.746922 (0.073432)\n",
      "0.1 5 2 3 sqrt mae 1.0 500: Macro 0.603419 (0.095418)\n",
      "Testing 3505/5184\n",
      "0.1 5 2 5 log2 friedman_mse 0.5 50: Weighted 0.822681 (0.064527)\n",
      "0.1 5 2 5 log2 friedman_mse 0.5 50: Macro 0.714107 (0.081812)\n",
      "Testing 3506/5184\n",
      "0.1 5 2 5 log2 friedman_mse 0.5 100: Weighted 0.815350 (0.072353)\n",
      "0.1 5 2 5 log2 friedman_mse 0.5 100: Macro 0.713407 (0.103784)\n",
      "Testing 3507/5184\n",
      "0.1 5 2 5 log2 friedman_mse 0.5 200: Weighted 0.814302 (0.075310)\n",
      "0.1 5 2 5 log2 friedman_mse 0.5 200: Macro 0.718243 (0.103924)\n",
      "Testing 3508/5184\n",
      "0.1 5 2 5 log2 friedman_mse 0.5 500: Weighted 0.817421 (0.066842)\n",
      "0.1 5 2 5 log2 friedman_mse 0.5 500: Macro 0.730935 (0.097281)\n",
      "Testing 3509/5184\n",
      "0.1 5 2 5 log2 friedman_mse 0.75 50: Weighted 0.812557 (0.061784)\n",
      "0.1 5 2 5 log2 friedman_mse 0.75 50: Macro 0.705279 (0.081439)\n",
      "Testing 3510/5184\n",
      "0.1 5 2 5 log2 friedman_mse 0.75 100: Weighted 0.807632 (0.077222)\n",
      "0.1 5 2 5 log2 friedman_mse 0.75 100: Macro 0.704104 (0.115545)\n",
      "Testing 3511/5184\n",
      "0.1 5 2 5 log2 friedman_mse 0.75 200: Weighted 0.819898 (0.065214)\n",
      "0.1 5 2 5 log2 friedman_mse 0.75 200: Macro 0.721006 (0.091704)\n",
      "Testing 3512/5184\n",
      "0.1 5 2 5 log2 friedman_mse 0.75 500: Weighted 0.820207 (0.069331)\n",
      "0.1 5 2 5 log2 friedman_mse 0.75 500: Macro 0.721603 (0.100318)\n",
      "Testing 3513/5184\n",
      "0.1 5 2 5 log2 friedman_mse 1.0 50: Weighted 0.811663 (0.074092)\n",
      "0.1 5 2 5 log2 friedman_mse 1.0 50: Macro 0.707820 (0.096978)\n",
      "Testing 3514/5184\n",
      "0.1 5 2 5 log2 friedman_mse 1.0 100: Weighted 0.808189 (0.086508)\n",
      "0.1 5 2 5 log2 friedman_mse 1.0 100: Macro 0.708774 (0.127516)\n",
      "Testing 3515/5184\n",
      "0.1 5 2 5 log2 friedman_mse 1.0 200: Weighted 0.809130 (0.065164)\n",
      "0.1 5 2 5 log2 friedman_mse 1.0 200: Macro 0.710184 (0.090650)\n",
      "Testing 3516/5184\n",
      "0.1 5 2 5 log2 friedman_mse 1.0 500: Weighted 0.806260 (0.082500)\n",
      "0.1 5 2 5 log2 friedman_mse 1.0 500: Macro 0.705781 (0.117108)\n",
      "Testing 3517/5184\n",
      "0.1 5 2 5 log2 mae 0.5 50: Weighted 0.812829 (0.073162)\n",
      "0.1 5 2 5 log2 mae 0.5 50: Macro 0.700771 (0.108895)\n",
      "Testing 3518/5184\n",
      "0.1 5 2 5 log2 mae 0.5 100: Weighted 0.795869 (0.073216)\n",
      "0.1 5 2 5 log2 mae 0.5 100: Macro 0.676352 (0.106144)\n",
      "Testing 3519/5184\n",
      "0.1 5 2 5 log2 mae 0.5 200: Weighted 0.795210 (0.066038)\n",
      "0.1 5 2 5 log2 mae 0.5 200: Macro 0.675339 (0.087823)\n",
      "Testing 3520/5184\n",
      "0.1 5 2 5 log2 mae 0.5 500: Weighted 0.799267 (0.069239)\n",
      "0.1 5 2 5 log2 mae 0.5 500: Macro 0.683946 (0.093830)\n",
      "Testing 3521/5184\n",
      "0.1 5 2 5 log2 mae 0.75 50: Weighted 0.781060 (0.080305)\n",
      "0.1 5 2 5 log2 mae 0.75 50: Macro 0.652761 (0.111428)\n",
      "Testing 3522/5184\n",
      "0.1 5 2 5 log2 mae 0.75 100: Weighted 0.782253 (0.085423)\n",
      "0.1 5 2 5 log2 mae 0.75 100: Macro 0.656562 (0.117016)\n",
      "Testing 3523/5184\n",
      "0.1 5 2 5 log2 mae 0.75 200: Weighted 0.770275 (0.100400)\n",
      "0.1 5 2 5 log2 mae 0.75 200: Macro 0.640801 (0.133472)\n",
      "Testing 3524/5184\n",
      "0.1 5 2 5 log2 mae 0.75 500: Weighted 0.785528 (0.080995)\n",
      "0.1 5 2 5 log2 mae 0.75 500: Macro 0.658433 (0.106673)\n",
      "Testing 3525/5184\n",
      "0.1 5 2 5 log2 mae 1.0 50: Weighted 0.789893 (0.070538)\n",
      "0.1 5 2 5 log2 mae 1.0 50: Macro 0.665327 (0.101746)\n",
      "Testing 3526/5184\n",
      "0.1 5 2 5 log2 mae 1.0 100: Weighted 0.780896 (0.076173)\n",
      "0.1 5 2 5 log2 mae 1.0 100: Macro 0.649355 (0.102184)\n",
      "Testing 3527/5184\n",
      "0.1 5 2 5 log2 mae 1.0 200: Weighted 0.776374 (0.082817)\n",
      "0.1 5 2 5 log2 mae 1.0 200: Macro 0.641907 (0.111807)\n",
      "Testing 3528/5184\n",
      "0.1 5 2 5 log2 mae 1.0 500: Weighted 0.770590 (0.102490)\n",
      "0.1 5 2 5 log2 mae 1.0 500: Macro 0.634634 (0.143750)\n",
      "Testing 3529/5184\n",
      "0.1 5 2 5 sqrt friedman_mse 0.5 50: Weighted 0.814037 (0.043160)\n",
      "0.1 5 2 5 sqrt friedman_mse 0.5 50: Macro 0.709579 (0.064667)\n",
      "Testing 3530/5184\n",
      "0.1 5 2 5 sqrt friedman_mse 0.5 100: Weighted 0.809388 (0.056668)\n",
      "0.1 5 2 5 sqrt friedman_mse 0.5 100: Macro 0.708238 (0.080796)\n",
      "Testing 3531/5184\n",
      "0.1 5 2 5 sqrt friedman_mse 0.5 200: Weighted 0.805241 (0.056126)\n",
      "0.1 5 2 5 sqrt friedman_mse 0.5 200: Macro 0.693509 (0.075380)\n",
      "Testing 3532/5184\n",
      "0.1 5 2 5 sqrt friedman_mse 0.5 500: Weighted 0.808735 (0.054047)\n",
      "0.1 5 2 5 sqrt friedman_mse 0.5 500: Macro 0.723077 (0.081482)\n",
      "Testing 3533/5184\n",
      "0.1 5 2 5 sqrt friedman_mse 0.75 50: Weighted 0.820646 (0.068966)\n",
      "0.1 5 2 5 sqrt friedman_mse 0.75 50: Macro 0.724733 (0.090398)\n",
      "Testing 3534/5184\n",
      "0.1 5 2 5 sqrt friedman_mse 0.75 100: Weighted 0.807999 (0.077684)\n",
      "0.1 5 2 5 sqrt friedman_mse 0.75 100: Macro 0.698155 (0.108712)\n",
      "Testing 3535/5184\n",
      "0.1 5 2 5 sqrt friedman_mse 0.75 200: Weighted 0.809220 (0.077263)\n",
      "0.1 5 2 5 sqrt friedman_mse 0.75 200: Macro 0.702791 (0.119959)\n",
      "Testing 3536/5184\n",
      "0.1 5 2 5 sqrt friedman_mse 0.75 500: Weighted 0.827118 (0.064044)\n",
      "0.1 5 2 5 sqrt friedman_mse 0.75 500: Macro 0.725824 (0.084941)\n",
      "Testing 3537/5184\n",
      "0.1 5 2 5 sqrt friedman_mse 1.0 50: Weighted 0.797787 (0.066464)\n",
      "0.1 5 2 5 sqrt friedman_mse 1.0 50: Macro 0.691887 (0.084545)\n",
      "Testing 3538/5184\n",
      "0.1 5 2 5 sqrt friedman_mse 1.0 100: Weighted 0.814805 (0.091814)\n",
      "0.1 5 2 5 sqrt friedman_mse 1.0 100: Macro 0.717579 (0.128889)\n",
      "Testing 3539/5184\n",
      "0.1 5 2 5 sqrt friedman_mse 1.0 200: Weighted 0.800934 (0.074899)\n",
      "0.1 5 2 5 sqrt friedman_mse 1.0 200: Macro 0.700156 (0.110457)\n",
      "Testing 3540/5184\n",
      "0.1 5 2 5 sqrt friedman_mse 1.0 500: Weighted 0.806285 (0.069693)\n",
      "0.1 5 2 5 sqrt friedman_mse 1.0 500: Macro 0.712204 (0.100663)\n",
      "Testing 3541/5184\n",
      "0.1 5 2 5 sqrt mae 0.5 50: Weighted 0.799272 (0.069377)\n",
      "0.1 5 2 5 sqrt mae 0.5 50: Macro 0.676613 (0.095657)\n",
      "Testing 3542/5184\n",
      "0.1 5 2 5 sqrt mae 0.5 100: Weighted 0.794781 (0.057771)\n",
      "0.1 5 2 5 sqrt mae 0.5 100: Macro 0.667063 (0.086582)\n",
      "Testing 3543/5184\n",
      "0.1 5 2 5 sqrt mae 0.5 200: Weighted 0.786687 (0.074438)\n",
      "0.1 5 2 5 sqrt mae 0.5 200: Macro 0.666347 (0.096537)\n",
      "Testing 3544/5184\n",
      "0.1 5 2 5 sqrt mae 0.5 500: Weighted 0.787191 (0.084920)\n",
      "0.1 5 2 5 sqrt mae 0.5 500: Macro 0.670271 (0.112744)\n",
      "Testing 3545/5184\n",
      "0.1 5 2 5 sqrt mae 0.75 50: Weighted 0.800189 (0.069756)\n",
      "0.1 5 2 5 sqrt mae 0.75 50: Macro 0.681749 (0.097692)\n",
      "Testing 3546/5184\n",
      "0.1 5 2 5 sqrt mae 0.75 100: Weighted 0.782321 (0.094212)\n",
      "0.1 5 2 5 sqrt mae 0.75 100: Macro 0.654650 (0.133528)\n",
      "Testing 3547/5184\n",
      "0.1 5 2 5 sqrt mae 0.75 200: Weighted 0.787773 (0.090307)\n",
      "0.1 5 2 5 sqrt mae 0.75 200: Macro 0.663847 (0.124906)\n",
      "Testing 3548/5184\n",
      "0.1 5 2 5 sqrt mae 0.75 500: Weighted 0.784276 (0.071543)\n",
      "0.1 5 2 5 sqrt mae 0.75 500: Macro 0.652386 (0.092314)\n",
      "Testing 3549/5184\n",
      "0.1 5 2 5 sqrt mae 1.0 50: Weighted 0.780519 (0.076138)\n",
      "0.1 5 2 5 sqrt mae 1.0 50: Macro 0.654311 (0.113687)\n",
      "Testing 3550/5184\n",
      "0.1 5 2 5 sqrt mae 1.0 100: Weighted 0.772827 (0.073681)\n",
      "0.1 5 2 5 sqrt mae 1.0 100: Macro 0.632193 (0.096883)\n",
      "Testing 3551/5184\n",
      "0.1 5 2 5 sqrt mae 1.0 200: Weighted 0.781334 (0.090741)\n",
      "0.1 5 2 5 sqrt mae 1.0 200: Macro 0.649471 (0.119381)\n",
      "Testing 3552/5184\n",
      "0.1 5 2 5 sqrt mae 1.0 500: Weighted 0.774340 (0.088409)\n",
      "0.1 5 2 5 sqrt mae 1.0 500: Macro 0.640700 (0.118628)\n",
      "Testing 3553/5184\n",
      "0.1 5 2 8 log2 friedman_mse 0.5 50: Weighted 0.821624 (0.055177)\n",
      "0.1 5 2 8 log2 friedman_mse 0.5 50: Macro 0.722907 (0.073297)\n",
      "Testing 3554/5184\n",
      "0.1 5 2 8 log2 friedman_mse 0.5 100: Weighted 0.819011 (0.072274)\n",
      "0.1 5 2 8 log2 friedman_mse 0.5 100: Macro 0.709840 (0.098314)\n",
      "Testing 3555/5184\n",
      "0.1 5 2 8 log2 friedman_mse 0.5 200: Weighted 0.808800 (0.058514)\n",
      "0.1 5 2 8 log2 friedman_mse 0.5 200: Macro 0.703056 (0.084941)\n",
      "Testing 3556/5184\n",
      "0.1 5 2 8 log2 friedman_mse 0.5 500: Weighted 0.822040 (0.061140)\n",
      "0.1 5 2 8 log2 friedman_mse 0.5 500: Macro 0.731229 (0.090905)\n",
      "Testing 3557/5184\n",
      "0.1 5 2 8 log2 friedman_mse 0.75 50: Weighted 0.815270 (0.084964)\n",
      "0.1 5 2 8 log2 friedman_mse 0.75 50: Macro 0.715817 (0.120973)\n",
      "Testing 3558/5184\n",
      "0.1 5 2 8 log2 friedman_mse 0.75 100: Weighted 0.818878 (0.073061)\n",
      "0.1 5 2 8 log2 friedman_mse 0.75 100: Macro 0.709576 (0.101813)\n",
      "Testing 3559/5184\n",
      "0.1 5 2 8 log2 friedman_mse 0.75 200: Weighted 0.820357 (0.079665)\n",
      "0.1 5 2 8 log2 friedman_mse 0.75 200: Macro 0.717548 (0.121886)\n",
      "Testing 3560/5184\n",
      "0.1 5 2 8 log2 friedman_mse 0.75 500: Weighted 0.817472 (0.078892)\n",
      "0.1 5 2 8 log2 friedman_mse 0.75 500: Macro 0.716393 (0.126024)\n",
      "Testing 3561/5184\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1 5 2 8 log2 friedman_mse 1.0 50: Weighted 0.786046 (0.075065)\n",
      "0.1 5 2 8 log2 friedman_mse 1.0 50: Macro 0.676695 (0.109742)\n",
      "Testing 3562/5184\n",
      "0.1 5 2 8 log2 friedman_mse 1.0 100: Weighted 0.803098 (0.093109)\n",
      "0.1 5 2 8 log2 friedman_mse 1.0 100: Macro 0.713721 (0.126224)\n",
      "Testing 3563/5184\n",
      "0.1 5 2 8 log2 friedman_mse 1.0 200: Weighted 0.804139 (0.088697)\n",
      "0.1 5 2 8 log2 friedman_mse 1.0 200: Macro 0.710870 (0.128672)\n",
      "Testing 3564/5184\n",
      "0.1 5 2 8 log2 friedman_mse 1.0 500: Weighted 0.801913 (0.086389)\n",
      "0.1 5 2 8 log2 friedman_mse 1.0 500: Macro 0.702889 (0.122433)\n",
      "Testing 3565/5184\n",
      "0.1 5 2 8 log2 mae 0.5 50: Weighted 0.799912 (0.078241)\n",
      "0.1 5 2 8 log2 mae 0.5 50: Macro 0.688754 (0.105636)\n",
      "Testing 3566/5184\n",
      "0.1 5 2 8 log2 mae 0.5 100: Weighted 0.818613 (0.067254)\n",
      "0.1 5 2 8 log2 mae 0.5 100: Macro 0.710852 (0.092654)\n",
      "Testing 3567/5184\n",
      "0.1 5 2 8 log2 mae 0.5 200: Weighted 0.779701 (0.071019)\n",
      "0.1 5 2 8 log2 mae 0.5 200: Macro 0.653516 (0.091242)\n",
      "Testing 3568/5184\n",
      "0.1 5 2 8 log2 mae 0.5 500: Weighted 0.800560 (0.083534)\n",
      "0.1 5 2 8 log2 mae 0.5 500: Macro 0.681618 (0.112199)\n",
      "Testing 3569/5184\n",
      "0.1 5 2 8 log2 mae 0.75 50: Weighted 0.791117 (0.081349)\n",
      "0.1 5 2 8 log2 mae 0.75 50: Macro 0.669963 (0.114554)\n",
      "Testing 3570/5184\n",
      "0.1 5 2 8 log2 mae 0.75 100: Weighted 0.783144 (0.080752)\n",
      "0.1 5 2 8 log2 mae 0.75 100: Macro 0.653898 (0.117513)\n",
      "Testing 3571/5184\n",
      "0.1 5 2 8 log2 mae 0.75 200: Weighted 0.788085 (0.088257)\n",
      "0.1 5 2 8 log2 mae 0.75 200: Macro 0.661366 (0.127935)\n",
      "Testing 3572/5184\n",
      "0.1 5 2 8 log2 mae 0.75 500: Weighted 0.783911 (0.082746)\n",
      "0.1 5 2 8 log2 mae 0.75 500: Macro 0.658620 (0.107030)\n",
      "Testing 3573/5184\n",
      "0.1 5 2 8 log2 mae 1.0 50: Weighted 0.786425 (0.086111)\n",
      "0.1 5 2 8 log2 mae 1.0 50: Macro 0.658876 (0.124280)\n",
      "Testing 3574/5184\n",
      "0.1 5 2 8 log2 mae 1.0 100: Weighted 0.790966 (0.080521)\n",
      "0.1 5 2 8 log2 mae 1.0 100: Macro 0.660046 (0.118531)\n",
      "Testing 3575/5184\n",
      "0.1 5 2 8 log2 mae 1.0 200: Weighted 0.782283 (0.098990)\n",
      "0.1 5 2 8 log2 mae 1.0 200: Macro 0.650684 (0.144911)\n",
      "Testing 3576/5184\n",
      "0.1 5 2 8 log2 mae 1.0 500: Weighted 0.803942 (0.106837)\n",
      "0.1 5 2 8 log2 mae 1.0 500: Macro 0.692750 (0.156156)\n",
      "Testing 3577/5184\n",
      "0.1 5 2 8 sqrt friedman_mse 0.5 50: Weighted 0.833461 (0.074385)\n",
      "0.1 5 2 8 sqrt friedman_mse 0.5 50: Macro 0.734870 (0.101275)\n",
      "Testing 3578/5184\n",
      "0.1 5 2 8 sqrt friedman_mse 0.5 100: Weighted 0.820987 (0.070489)\n",
      "0.1 5 2 8 sqrt friedman_mse 0.5 100: Macro 0.718390 (0.095503)\n",
      "Testing 3579/5184\n",
      "0.1 5 2 8 sqrt friedman_mse 0.5 200: Weighted 0.806057 (0.068631)\n",
      "0.1 5 2 8 sqrt friedman_mse 0.5 200: Macro 0.700222 (0.098796)\n",
      "Testing 3580/5184\n",
      "0.1 5 2 8 sqrt friedman_mse 0.5 500: Weighted 0.823371 (0.061054)\n",
      "0.1 5 2 8 sqrt friedman_mse 0.5 500: Macro 0.726582 (0.086925)\n",
      "Testing 3581/5184\n",
      "0.1 5 2 8 sqrt friedman_mse 0.75 50: Weighted 0.818895 (0.076952)\n",
      "0.1 5 2 8 sqrt friedman_mse 0.75 50: Macro 0.721213 (0.105818)\n",
      "Testing 3582/5184\n",
      "0.1 5 2 8 sqrt friedman_mse 0.75 100: Weighted 0.826603 (0.091163)\n",
      "0.1 5 2 8 sqrt friedman_mse 0.75 100: Macro 0.729106 (0.139586)\n",
      "Testing 3583/5184\n",
      "0.1 5 2 8 sqrt friedman_mse 0.75 200: Weighted 0.797554 (0.062163)\n",
      "0.1 5 2 8 sqrt friedman_mse 0.75 200: Macro 0.691002 (0.100319)\n",
      "Testing 3584/5184\n",
      "0.1 5 2 8 sqrt friedman_mse 0.75 500: Weighted 0.812190 (0.084304)\n",
      "0.1 5 2 8 sqrt friedman_mse 0.75 500: Macro 0.695144 (0.130458)\n",
      "Testing 3585/5184\n",
      "0.1 5 2 8 sqrt friedman_mse 1.0 50: Weighted 0.799456 (0.089148)\n",
      "0.1 5 2 8 sqrt friedman_mse 1.0 50: Macro 0.693201 (0.125601)\n",
      "Testing 3586/5184\n",
      "0.1 5 2 8 sqrt friedman_mse 1.0 100: Weighted 0.805760 (0.099990)\n",
      "0.1 5 2 8 sqrt friedman_mse 1.0 100: Macro 0.707924 (0.150584)\n",
      "Testing 3587/5184\n",
      "0.1 5 2 8 sqrt friedman_mse 1.0 200: Weighted 0.789576 (0.076751)\n",
      "0.1 5 2 8 sqrt friedman_mse 1.0 200: Macro 0.684207 (0.124956)\n",
      "Testing 3588/5184\n",
      "0.1 5 2 8 sqrt friedman_mse 1.0 500: Weighted 0.805659 (0.077834)\n",
      "0.1 5 2 8 sqrt friedman_mse 1.0 500: Macro 0.715137 (0.105624)\n",
      "Testing 3589/5184\n",
      "0.1 5 2 8 sqrt mae 0.5 50: Weighted 0.801613 (0.068199)\n",
      "0.1 5 2 8 sqrt mae 0.5 50: Macro 0.692396 (0.090043)\n",
      "Testing 3590/5184\n",
      "0.1 5 2 8 sqrt mae 0.5 100: Weighted 0.806312 (0.062993)\n",
      "0.1 5 2 8 sqrt mae 0.5 100: Macro 0.691505 (0.084065)\n",
      "Testing 3591/5184\n",
      "0.1 5 2 8 sqrt mae 0.5 200: Weighted 0.798182 (0.077608)\n",
      "0.1 5 2 8 sqrt mae 0.5 200: Macro 0.685093 (0.100565)\n",
      "Testing 3592/5184\n",
      "0.1 5 2 8 sqrt mae 0.5 500: Weighted 0.815029 (0.050360)\n",
      "0.1 5 2 8 sqrt mae 0.5 500: Macro 0.704431 (0.062990)\n",
      "Testing 3593/5184\n",
      "0.1 5 2 8 sqrt mae 0.75 50: Weighted 0.784335 (0.081008)\n",
      "0.1 5 2 8 sqrt mae 0.75 50: Macro 0.656115 (0.115322)\n",
      "Testing 3594/5184\n",
      "0.1 5 2 8 sqrt mae 0.75 100: Weighted 0.782462 (0.087959)\n",
      "0.1 5 2 8 sqrt mae 0.75 100: Macro 0.659502 (0.121725)\n",
      "Testing 3595/5184\n",
      "0.1 5 2 8 sqrt mae 0.75 200: Weighted 0.790728 (0.100580)\n",
      "0.1 5 2 8 sqrt mae 0.75 200: Macro 0.667379 (0.151547)\n",
      "Testing 3596/5184\n",
      "0.1 5 2 8 sqrt mae 0.75 500: Weighted 0.773394 (0.085220)\n",
      "0.1 5 2 8 sqrt mae 0.75 500: Macro 0.644270 (0.122640)\n",
      "Testing 3597/5184\n",
      "0.1 5 2 8 sqrt mae 1.0 50: Weighted 0.791962 (0.087406)\n",
      "0.1 5 2 8 sqrt mae 1.0 50: Macro 0.667245 (0.127465)\n",
      "Testing 3598/5184\n",
      "0.1 5 2 8 sqrt mae 1.0 100: Weighted 0.789453 (0.105552)\n",
      "0.1 5 2 8 sqrt mae 1.0 100: Macro 0.660222 (0.156837)\n",
      "Testing 3599/5184\n",
      "0.1 5 2 8 sqrt mae 1.0 200: Weighted 0.795862 (0.093265)\n",
      "0.1 5 2 8 sqrt mae 1.0 200: Macro 0.668714 (0.135926)\n",
      "Testing 3600/5184\n",
      "0.1 5 2 8 sqrt mae 1.0 500: Weighted 0.795978 (0.071255)\n",
      "0.1 5 2 8 sqrt mae 1.0 500: Macro 0.673335 (0.101385)\n",
      "Testing 3601/5184\n",
      "0.1 5 4 3 log2 friedman_mse 0.5 50: Weighted 0.815127 (0.068368)\n",
      "0.1 5 4 3 log2 friedman_mse 0.5 50: Macro 0.704863 (0.092487)\n",
      "Testing 3602/5184\n",
      "0.1 5 4 3 log2 friedman_mse 0.5 100: Weighted 0.811847 (0.055328)\n",
      "0.1 5 4 3 log2 friedman_mse 0.5 100: Macro 0.708753 (0.090658)\n",
      "Testing 3603/5184\n",
      "0.1 5 4 3 log2 friedman_mse 0.5 200: Weighted 0.814211 (0.057344)\n",
      "0.1 5 4 3 log2 friedman_mse 0.5 200: Macro 0.717753 (0.089213)\n",
      "Testing 3604/5184\n",
      "0.1 5 4 3 log2 friedman_mse 0.5 500: Weighted 0.812897 (0.041145)\n",
      "0.1 5 4 3 log2 friedman_mse 0.5 500: Macro 0.718377 (0.061424)\n",
      "Testing 3605/5184\n",
      "0.1 5 4 3 log2 friedman_mse 0.75 50: Weighted 0.815544 (0.062108)\n",
      "0.1 5 4 3 log2 friedman_mse 0.75 50: Macro 0.709663 (0.081169)\n",
      "Testing 3606/5184\n",
      "0.1 5 4 3 log2 friedman_mse 0.75 100: Weighted 0.824068 (0.081099)\n",
      "0.1 5 4 3 log2 friedman_mse 0.75 100: Macro 0.722242 (0.112076)\n",
      "Testing 3607/5184\n",
      "0.1 5 4 3 log2 friedman_mse 0.75 200: Weighted 0.820003 (0.062194)\n",
      "0.1 5 4 3 log2 friedman_mse 0.75 200: Macro 0.728325 (0.082873)\n",
      "Testing 3608/5184\n",
      "0.1 5 4 3 log2 friedman_mse 0.75 500: Weighted 0.815915 (0.068236)\n",
      "0.1 5 4 3 log2 friedman_mse 0.75 500: Macro 0.721039 (0.100920)\n",
      "Testing 3609/5184\n",
      "0.1 5 4 3 log2 friedman_mse 1.0 50: Weighted 0.821529 (0.082254)\n",
      "0.1 5 4 3 log2 friedman_mse 1.0 50: Macro 0.726674 (0.106741)\n",
      "Testing 3610/5184\n",
      "0.1 5 4 3 log2 friedman_mse 1.0 100: Weighted 0.821921 (0.061741)\n",
      "0.1 5 4 3 log2 friedman_mse 1.0 100: Macro 0.727613 (0.083181)\n",
      "Testing 3611/5184\n",
      "0.1 5 4 3 log2 friedman_mse 1.0 200: Weighted 0.815028 (0.055690)\n",
      "0.1 5 4 3 log2 friedman_mse 1.0 200: Macro 0.717784 (0.069344)\n",
      "Testing 3612/5184\n",
      "0.1 5 4 3 log2 friedman_mse 1.0 500: Weighted 0.805865 (0.051572)\n",
      "0.1 5 4 3 log2 friedman_mse 1.0 500: Macro 0.712419 (0.069316)\n",
      "Testing 3613/5184\n",
      "0.1 5 4 3 log2 mae 0.5 50: Weighted 0.811249 (0.060621)\n",
      "0.1 5 4 3 log2 mae 0.5 50: Macro 0.698138 (0.085564)\n",
      "Testing 3614/5184\n",
      "0.1 5 4 3 log2 mae 0.5 100: Weighted 0.809577 (0.077876)\n",
      "0.1 5 4 3 log2 mae 0.5 100: Macro 0.702015 (0.108864)\n",
      "Testing 3615/5184\n",
      "0.1 5 4 3 log2 mae 0.5 200: Weighted 0.763107 (0.058663)\n",
      "0.1 5 4 3 log2 mae 0.5 200: Macro 0.627941 (0.088013)\n",
      "Testing 3616/5184\n",
      "0.1 5 4 3 log2 mae 0.5 500: Weighted 0.782503 (0.084458)\n",
      "0.1 5 4 3 log2 mae 0.5 500: Macro 0.663951 (0.110055)\n",
      "Testing 3617/5184\n",
      "0.1 5 4 3 log2 mae 0.75 50: Weighted 0.803544 (0.058937)\n",
      "0.1 5 4 3 log2 mae 0.75 50: Macro 0.690717 (0.080525)\n",
      "Testing 3618/5184\n",
      "0.1 5 4 3 log2 mae 0.75 100: Weighted 0.793608 (0.065571)\n",
      "0.1 5 4 3 log2 mae 0.75 100: Macro 0.676348 (0.091733)\n",
      "Testing 3619/5184\n",
      "0.1 5 4 3 log2 mae 0.75 200: Weighted 0.766684 (0.062366)\n",
      "0.1 5 4 3 log2 mae 0.75 200: Macro 0.628942 (0.084722)\n",
      "Testing 3620/5184\n",
      "0.1 5 4 3 log2 mae 0.75 500: Weighted 0.778678 (0.079633)\n",
      "0.1 5 4 3 log2 mae 0.75 500: Macro 0.650984 (0.113141)\n",
      "Testing 3621/5184\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1 5 4 3 log2 mae 1.0 50: Weighted 0.785663 (0.067483)\n",
      "0.1 5 4 3 log2 mae 1.0 50: Macro 0.658914 (0.103333)\n",
      "Testing 3622/5184\n",
      "0.1 5 4 3 log2 mae 1.0 100: Weighted 0.761528 (0.065722)\n",
      "0.1 5 4 3 log2 mae 1.0 100: Macro 0.613456 (0.091953)\n",
      "Testing 3623/5184\n",
      "0.1 5 4 3 log2 mae 1.0 200: Weighted 0.770909 (0.060015)\n",
      "0.1 5 4 3 log2 mae 1.0 200: Macro 0.634656 (0.087371)\n",
      "Testing 3624/5184\n",
      "0.1 5 4 3 log2 mae 1.0 500: Weighted 0.764842 (0.068416)\n",
      "0.1 5 4 3 log2 mae 1.0 500: Macro 0.628102 (0.097326)\n",
      "Testing 3625/5184\n",
      "0.1 5 4 3 sqrt friedman_mse 0.5 50: Weighted 0.818790 (0.067426)\n",
      "0.1 5 4 3 sqrt friedman_mse 0.5 50: Macro 0.713063 (0.084705)\n",
      "Testing 3626/5184\n",
      "0.1 5 4 3 sqrt friedman_mse 0.5 100: Weighted 0.821458 (0.063577)\n",
      "0.1 5 4 3 sqrt friedman_mse 0.5 100: Macro 0.712242 (0.085369)\n",
      "Testing 3627/5184\n",
      "0.1 5 4 3 sqrt friedman_mse 0.5 200: Weighted 0.809942 (0.065363)\n",
      "0.1 5 4 3 sqrt friedman_mse 0.5 200: Macro 0.701490 (0.103649)\n",
      "Testing 3628/5184\n",
      "0.1 5 4 3 sqrt friedman_mse 0.5 500: Weighted 0.814786 (0.044470)\n",
      "0.1 5 4 3 sqrt friedman_mse 0.5 500: Macro 0.713335 (0.069279)\n",
      "Testing 3629/5184\n",
      "0.1 5 4 3 sqrt friedman_mse 0.75 50: Weighted 0.809816 (0.083024)\n",
      "0.1 5 4 3 sqrt friedman_mse 0.75 50: Macro 0.705767 (0.109347)\n",
      "Testing 3630/5184\n",
      "0.1 5 4 3 sqrt friedman_mse 0.75 100: Weighted 0.804673 (0.074841)\n",
      "0.1 5 4 3 sqrt friedman_mse 0.75 100: Macro 0.696433 (0.099953)\n",
      "Testing 3631/5184\n",
      "0.1 5 4 3 sqrt friedman_mse 0.75 200: Weighted 0.818982 (0.051093)\n",
      "0.1 5 4 3 sqrt friedman_mse 0.75 200: Macro 0.727988 (0.073328)\n",
      "Testing 3632/5184\n",
      "0.1 5 4 3 sqrt friedman_mse 0.75 500: Weighted 0.826515 (0.056191)\n",
      "0.1 5 4 3 sqrt friedman_mse 0.75 500: Macro 0.744483 (0.082866)\n",
      "Testing 3633/5184\n",
      "0.1 5 4 3 sqrt friedman_mse 1.0 50: Weighted 0.800385 (0.080952)\n",
      "0.1 5 4 3 sqrt friedman_mse 1.0 50: Macro 0.697623 (0.104448)\n",
      "Testing 3634/5184\n",
      "0.1 5 4 3 sqrt friedman_mse 1.0 100: Weighted 0.807889 (0.065358)\n",
      "0.1 5 4 3 sqrt friedman_mse 1.0 100: Macro 0.703671 (0.077862)\n",
      "Testing 3635/5184\n",
      "0.1 5 4 3 sqrt friedman_mse 1.0 200: Weighted 0.809175 (0.057208)\n",
      "0.1 5 4 3 sqrt friedman_mse 1.0 200: Macro 0.716384 (0.073469)\n",
      "Testing 3636/5184\n",
      "0.1 5 4 3 sqrt friedman_mse 1.0 500: Weighted 0.797441 (0.059729)\n",
      "0.1 5 4 3 sqrt friedman_mse 1.0 500: Macro 0.696982 (0.085981)\n",
      "Testing 3637/5184\n",
      "0.1 5 4 3 sqrt mae 0.5 50: Weighted 0.811711 (0.061025)\n",
      "0.1 5 4 3 sqrt mae 0.5 50: Macro 0.699022 (0.081692)\n",
      "Testing 3638/5184\n",
      "0.1 5 4 3 sqrt mae 0.5 100: Weighted 0.797163 (0.050352)\n",
      "0.1 5 4 3 sqrt mae 0.5 100: Macro 0.682332 (0.075439)\n",
      "Testing 3639/5184\n",
      "0.1 5 4 3 sqrt mae 0.5 200: Weighted 0.790335 (0.079085)\n",
      "0.1 5 4 3 sqrt mae 0.5 200: Macro 0.669331 (0.109412)\n",
      "Testing 3640/5184\n",
      "0.1 5 4 3 sqrt mae 0.5 500: Weighted 0.780865 (0.075712)\n",
      "0.1 5 4 3 sqrt mae 0.5 500: Macro 0.653935 (0.088681)\n",
      "Testing 3641/5184\n",
      "0.1 5 4 3 sqrt mae 0.75 50: Weighted 0.792625 (0.076812)\n",
      "0.1 5 4 3 sqrt mae 0.75 50: Macro 0.673393 (0.107499)\n",
      "Testing 3642/5184\n",
      "0.1 5 4 3 sqrt mae 0.75 100: Weighted 0.770729 (0.060126)\n",
      "0.1 5 4 3 sqrt mae 0.75 100: Macro 0.633553 (0.081147)\n",
      "Testing 3643/5184\n",
      "0.1 5 4 3 sqrt mae 0.75 200: Weighted 0.779116 (0.071878)\n",
      "0.1 5 4 3 sqrt mae 0.75 200: Macro 0.648548 (0.097932)\n",
      "Testing 3644/5184\n",
      "0.1 5 4 3 sqrt mae 0.75 500: Weighted 0.761814 (0.061090)\n",
      "0.1 5 4 3 sqrt mae 0.75 500: Macro 0.621071 (0.082525)\n",
      "Testing 3645/5184\n",
      "0.1 5 4 3 sqrt mae 1.0 50: Weighted 0.799022 (0.082076)\n",
      "0.1 5 4 3 sqrt mae 1.0 50: Macro 0.676612 (0.118790)\n",
      "Testing 3646/5184\n",
      "0.1 5 4 3 sqrt mae 1.0 100: Weighted 0.779535 (0.073801)\n",
      "0.1 5 4 3 sqrt mae 1.0 100: Macro 0.642324 (0.106598)\n",
      "Testing 3647/5184\n",
      "0.1 5 4 3 sqrt mae 1.0 200: Weighted 0.759886 (0.061206)\n",
      "0.1 5 4 3 sqrt mae 1.0 200: Macro 0.611226 (0.082843)\n",
      "Testing 3648/5184\n",
      "0.1 5 4 3 sqrt mae 1.0 500: Weighted 0.772784 (0.077257)\n",
      "0.1 5 4 3 sqrt mae 1.0 500: Macro 0.641623 (0.107976)\n",
      "Testing 3649/5184\n",
      "0.1 5 4 5 log2 friedman_mse 0.5 50: Weighted 0.818047 (0.065204)\n",
      "0.1 5 4 5 log2 friedman_mse 0.5 50: Macro 0.711245 (0.092658)\n",
      "Testing 3650/5184\n",
      "0.1 5 4 5 log2 friedman_mse 0.5 100: Weighted 0.808990 (0.046065)\n",
      "0.1 5 4 5 log2 friedman_mse 0.5 100: Macro 0.697970 (0.062222)\n",
      "Testing 3651/5184\n",
      "0.1 5 4 5 log2 friedman_mse 0.5 200: Weighted 0.814504 (0.063522)\n",
      "0.1 5 4 5 log2 friedman_mse 0.5 200: Macro 0.715475 (0.094772)\n",
      "Testing 3652/5184\n",
      "0.1 5 4 5 log2 friedman_mse 0.5 500: Weighted 0.817440 (0.066338)\n",
      "0.1 5 4 5 log2 friedman_mse 0.5 500: Macro 0.725862 (0.105127)\n",
      "Testing 3653/5184\n",
      "0.1 5 4 5 log2 friedman_mse 0.75 50: Weighted 0.810450 (0.083977)\n",
      "0.1 5 4 5 log2 friedman_mse 0.75 50: Macro 0.707221 (0.118400)\n",
      "Testing 3654/5184\n",
      "0.1 5 4 5 log2 friedman_mse 0.75 100: Weighted 0.816073 (0.074119)\n",
      "0.1 5 4 5 log2 friedman_mse 0.75 100: Macro 0.713776 (0.114240)\n",
      "Testing 3655/5184\n",
      "0.1 5 4 5 log2 friedman_mse 0.75 200: Weighted 0.808808 (0.077183)\n",
      "0.1 5 4 5 log2 friedman_mse 0.75 200: Macro 0.708935 (0.110388)\n",
      "Testing 3656/5184\n",
      "0.1 5 4 5 log2 friedman_mse 0.75 500: Weighted 0.801669 (0.064936)\n",
      "0.1 5 4 5 log2 friedman_mse 0.75 500: Macro 0.696282 (0.095852)\n",
      "Testing 3657/5184\n",
      "0.1 5 4 5 log2 friedman_mse 1.0 50: Weighted 0.797915 (0.094814)\n",
      "0.1 5 4 5 log2 friedman_mse 1.0 50: Macro 0.686641 (0.136920)\n",
      "Testing 3658/5184\n",
      "0.1 5 4 5 log2 friedman_mse 1.0 100: Weighted 0.810524 (0.097984)\n",
      "0.1 5 4 5 log2 friedman_mse 1.0 100: Macro 0.714447 (0.138998)\n",
      "Testing 3659/5184\n",
      "0.1 5 4 5 log2 friedman_mse 1.0 200: Weighted 0.797088 (0.067314)\n",
      "0.1 5 4 5 log2 friedman_mse 1.0 200: Macro 0.690988 (0.098646)\n",
      "Testing 3660/5184\n",
      "0.1 5 4 5 log2 friedman_mse 1.0 500: Weighted 0.789808 (0.058467)\n",
      "0.1 5 4 5 log2 friedman_mse 1.0 500: Macro 0.690148 (0.091482)\n",
      "Testing 3661/5184\n",
      "0.1 5 4 5 log2 mae 0.5 50: Weighted 0.799029 (0.059345)\n",
      "0.1 5 4 5 log2 mae 0.5 50: Macro 0.676639 (0.086262)\n",
      "Testing 3662/5184\n",
      "0.1 5 4 5 log2 mae 0.5 100: Weighted 0.802550 (0.084120)\n",
      "0.1 5 4 5 log2 mae 0.5 100: Macro 0.688249 (0.127061)\n",
      "Testing 3663/5184\n",
      "0.1 5 4 5 log2 mae 0.5 200: Weighted 0.785239 (0.086092)\n",
      "0.1 5 4 5 log2 mae 0.5 200: Macro 0.670099 (0.112869)\n",
      "Testing 3664/5184\n",
      "0.1 5 4 5 log2 mae 0.5 500: Weighted 0.796399 (0.079990)\n",
      "0.1 5 4 5 log2 mae 0.5 500: Macro 0.683750 (0.108140)\n",
      "Testing 3665/5184\n",
      "0.1 5 4 5 log2 mae 0.75 50: Weighted 0.783185 (0.064702)\n",
      "0.1 5 4 5 log2 mae 0.75 50: Macro 0.654743 (0.082875)\n",
      "Testing 3666/5184\n",
      "0.1 5 4 5 log2 mae 0.75 100: Weighted 0.788800 (0.072859)\n",
      "0.1 5 4 5 log2 mae 0.75 100: Macro 0.660499 (0.104723)\n",
      "Testing 3667/5184\n",
      "0.1 5 4 5 log2 mae 0.75 200: Weighted 0.764876 (0.081867)\n",
      "0.1 5 4 5 log2 mae 0.75 200: Macro 0.620311 (0.111197)\n",
      "Testing 3668/5184\n",
      "0.1 5 4 5 log2 mae 0.75 500: Weighted 0.776059 (0.089255)\n",
      "0.1 5 4 5 log2 mae 0.75 500: Macro 0.643648 (0.111114)\n",
      "Testing 3669/5184\n",
      "0.1 5 4 5 log2 mae 1.0 50: Weighted 0.776721 (0.091741)\n",
      "0.1 5 4 5 log2 mae 1.0 50: Macro 0.646042 (0.129397)\n",
      "Testing 3670/5184\n",
      "0.1 5 4 5 log2 mae 1.0 100: Weighted 0.774538 (0.093597)\n",
      "0.1 5 4 5 log2 mae 1.0 100: Macro 0.642293 (0.129420)\n",
      "Testing 3671/5184\n",
      "0.1 5 4 5 log2 mae 1.0 200: Weighted 0.772859 (0.083383)\n",
      "0.1 5 4 5 log2 mae 1.0 200: Macro 0.633813 (0.111486)\n",
      "Testing 3672/5184\n",
      "0.1 5 4 5 log2 mae 1.0 500: Weighted 0.788599 (0.094214)\n",
      "0.1 5 4 5 log2 mae 1.0 500: Macro 0.657189 (0.132997)\n",
      "Testing 3673/5184\n",
      "0.1 5 4 5 sqrt friedman_mse 0.5 50: Weighted 0.809297 (0.064595)\n",
      "0.1 5 4 5 sqrt friedman_mse 0.5 50: Macro 0.700602 (0.085627)\n",
      "Testing 3674/5184\n",
      "0.1 5 4 5 sqrt friedman_mse 0.5 100: Weighted 0.820638 (0.057747)\n",
      "0.1 5 4 5 sqrt friedman_mse 0.5 100: Macro 0.725569 (0.078271)\n",
      "Testing 3675/5184\n",
      "0.1 5 4 5 sqrt friedman_mse 0.5 200: Weighted 0.804437 (0.053699)\n",
      "0.1 5 4 5 sqrt friedman_mse 0.5 200: Macro 0.689512 (0.076420)\n",
      "Testing 3676/5184\n",
      "0.1 5 4 5 sqrt friedman_mse 0.5 500: Weighted 0.823890 (0.058212)\n",
      "0.1 5 4 5 sqrt friedman_mse 0.5 500: Macro 0.735398 (0.086429)\n",
      "Testing 3677/5184\n",
      "0.1 5 4 5 sqrt friedman_mse 0.75 50: Weighted 0.813657 (0.066684)\n",
      "0.1 5 4 5 sqrt friedman_mse 0.75 50: Macro 0.712583 (0.083691)\n",
      "Testing 3678/5184\n",
      "0.1 5 4 5 sqrt friedman_mse 0.75 100: Weighted 0.821395 (0.069158)\n",
      "0.1 5 4 5 sqrt friedman_mse 0.75 100: Macro 0.727050 (0.091167)\n",
      "Testing 3679/5184\n",
      "0.1 5 4 5 sqrt friedman_mse 0.75 200: Weighted 0.823181 (0.090823)\n",
      "0.1 5 4 5 sqrt friedman_mse 0.75 200: Macro 0.729757 (0.126020)\n",
      "Testing 3680/5184\n",
      "0.1 5 4 5 sqrt friedman_mse 0.75 500: Weighted 0.826466 (0.082651)\n",
      "0.1 5 4 5 sqrt friedman_mse 0.75 500: Macro 0.724824 (0.120288)\n",
      "Testing 3681/5184\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1 5 4 5 sqrt friedman_mse 1.0 50: Weighted 0.807971 (0.075219)\n",
      "0.1 5 4 5 sqrt friedman_mse 1.0 50: Macro 0.705823 (0.101597)\n",
      "Testing 3682/5184\n",
      "0.1 5 4 5 sqrt friedman_mse 1.0 100: Weighted 0.799647 (0.086535)\n",
      "0.1 5 4 5 sqrt friedman_mse 1.0 100: Macro 0.694641 (0.128521)\n",
      "Testing 3683/5184\n",
      "0.1 5 4 5 sqrt friedman_mse 1.0 200: Weighted 0.810383 (0.075305)\n",
      "0.1 5 4 5 sqrt friedman_mse 1.0 200: Macro 0.720560 (0.108133)\n",
      "Testing 3684/5184\n",
      "0.1 5 4 5 sqrt friedman_mse 1.0 500: Weighted 0.800869 (0.078165)\n",
      "0.1 5 4 5 sqrt friedman_mse 1.0 500: Macro 0.701445 (0.118082)\n",
      "Testing 3685/5184\n",
      "0.1 5 4 5 sqrt mae 0.5 50: Weighted 0.783725 (0.054160)\n",
      "0.1 5 4 5 sqrt mae 0.5 50: Macro 0.652200 (0.084505)\n",
      "Testing 3686/5184\n",
      "0.1 5 4 5 sqrt mae 0.5 100: Weighted 0.795112 (0.081388)\n",
      "0.1 5 4 5 sqrt mae 0.5 100: Macro 0.670113 (0.115650)\n",
      "Testing 3687/5184\n",
      "0.1 5 4 5 sqrt mae 0.5 200: Weighted 0.793242 (0.073858)\n",
      "0.1 5 4 5 sqrt mae 0.5 200: Macro 0.674583 (0.091156)\n",
      "Testing 3688/5184\n",
      "0.1 5 4 5 sqrt mae 0.5 500: Weighted 0.787383 (0.078507)\n",
      "0.1 5 4 5 sqrt mae 0.5 500: Macro 0.665146 (0.104819)\n",
      "Testing 3689/5184\n",
      "0.1 5 4 5 sqrt mae 0.75 50: Weighted 0.781443 (0.072332)\n",
      "0.1 5 4 5 sqrt mae 0.75 50: Macro 0.649131 (0.099798)\n",
      "Testing 3690/5184\n",
      "0.1 5 4 5 sqrt mae 0.75 100: Weighted 0.778701 (0.071760)\n",
      "0.1 5 4 5 sqrt mae 0.75 100: Macro 0.648339 (0.099482)\n",
      "Testing 3691/5184\n",
      "0.1 5 4 5 sqrt mae 0.75 200: Weighted 0.771313 (0.085934)\n",
      "0.1 5 4 5 sqrt mae 0.75 200: Macro 0.642649 (0.108466)\n",
      "Testing 3692/5184\n",
      "0.1 5 4 5 sqrt mae 0.75 500: Weighted 0.776570 (0.086097)\n",
      "0.1 5 4 5 sqrt mae 0.75 500: Macro 0.643568 (0.118392)\n",
      "Testing 3693/5184\n",
      "0.1 5 4 5 sqrt mae 1.0 50: Weighted 0.782513 (0.074301)\n",
      "0.1 5 4 5 sqrt mae 1.0 50: Macro 0.647975 (0.106380)\n",
      "Testing 3694/5184\n",
      "0.1 5 4 5 sqrt mae 1.0 100: Weighted 0.761904 (0.065220)\n",
      "0.1 5 4 5 sqrt mae 1.0 100: Macro 0.620391 (0.086872)\n",
      "Testing 3695/5184\n",
      "0.1 5 4 5 sqrt mae 1.0 200: Weighted 0.769218 (0.102862)\n",
      "0.1 5 4 5 sqrt mae 1.0 200: Macro 0.628303 (0.140597)\n",
      "Testing 3696/5184\n",
      "0.1 5 4 5 sqrt mae 1.0 500: Weighted 0.783678 (0.072431)\n",
      "0.1 5 4 5 sqrt mae 1.0 500: Macro 0.659044 (0.103366)\n",
      "Testing 3697/5184\n",
      "0.1 5 4 8 log2 friedman_mse 0.5 50: Weighted 0.819353 (0.084247)\n",
      "0.1 5 4 8 log2 friedman_mse 0.5 50: Macro 0.717636 (0.118675)\n",
      "Testing 3698/5184\n",
      "0.1 5 4 8 log2 friedman_mse 0.5 100: Weighted 0.809153 (0.067508)\n",
      "0.1 5 4 8 log2 friedman_mse 0.5 100: Macro 0.703422 (0.092403)\n",
      "Testing 3699/5184\n",
      "0.1 5 4 8 log2 friedman_mse 0.5 200: Weighted 0.812156 (0.069742)\n",
      "0.1 5 4 8 log2 friedman_mse 0.5 200: Macro 0.701867 (0.105897)\n",
      "Testing 3700/5184\n",
      "0.1 5 4 8 log2 friedman_mse 0.5 500: Weighted 0.820098 (0.057237)\n",
      "0.1 5 4 8 log2 friedman_mse 0.5 500: Macro 0.721065 (0.073917)\n",
      "Testing 3701/5184\n",
      "0.1 5 4 8 log2 friedman_mse 0.75 50: Weighted 0.802369 (0.078710)\n",
      "0.1 5 4 8 log2 friedman_mse 0.75 50: Macro 0.692820 (0.107028)\n",
      "Testing 3702/5184\n",
      "0.1 5 4 8 log2 friedman_mse 0.75 100: Weighted 0.810109 (0.063579)\n",
      "0.1 5 4 8 log2 friedman_mse 0.75 100: Macro 0.705173 (0.108096)\n",
      "Testing 3703/5184\n",
      "0.1 5 4 8 log2 friedman_mse 0.75 200: Weighted 0.805914 (0.080719)\n",
      "0.1 5 4 8 log2 friedman_mse 0.75 200: Macro 0.699438 (0.125417)\n",
      "Testing 3704/5184\n",
      "0.1 5 4 8 log2 friedman_mse 0.75 500: Weighted 0.809915 (0.072587)\n",
      "0.1 5 4 8 log2 friedman_mse 0.75 500: Macro 0.711184 (0.110175)\n",
      "Testing 3705/5184\n",
      "0.1 5 4 8 log2 friedman_mse 1.0 50: Weighted 0.818995 (0.079031)\n",
      "0.1 5 4 8 log2 friedman_mse 1.0 50: Macro 0.723439 (0.109559)\n",
      "Testing 3706/5184\n",
      "0.1 5 4 8 log2 friedman_mse 1.0 100: Weighted 0.799477 (0.101255)\n",
      "0.1 5 4 8 log2 friedman_mse 1.0 100: Macro 0.695472 (0.151061)\n",
      "Testing 3707/5184\n",
      "0.1 5 4 8 log2 friedman_mse 1.0 200: Weighted 0.785651 (0.080584)\n",
      "0.1 5 4 8 log2 friedman_mse 1.0 200: Macro 0.668888 (0.124685)\n",
      "Testing 3708/5184\n",
      "0.1 5 4 8 log2 friedman_mse 1.0 500: Weighted 0.805404 (0.078571)\n",
      "0.1 5 4 8 log2 friedman_mse 1.0 500: Macro 0.719480 (0.126053)\n",
      "Testing 3709/5184\n",
      "0.1 5 4 8 log2 mae 0.5 50: Weighted 0.814732 (0.055823)\n",
      "0.1 5 4 8 log2 mae 0.5 50: Macro 0.704967 (0.079401)\n",
      "Testing 3710/5184\n",
      "0.1 5 4 8 log2 mae 0.5 100: Weighted 0.808409 (0.072237)\n",
      "0.1 5 4 8 log2 mae 0.5 100: Macro 0.695993 (0.090326)\n",
      "Testing 3711/5184\n",
      "0.1 5 4 8 log2 mae 0.5 200: Weighted 0.788611 (0.071281)\n",
      "0.1 5 4 8 log2 mae 0.5 200: Macro 0.668648 (0.087602)\n",
      "Testing 3712/5184\n",
      "0.1 5 4 8 log2 mae 0.5 500: Weighted 0.811753 (0.064028)\n",
      "0.1 5 4 8 log2 mae 0.5 500: Macro 0.698164 (0.087659)\n",
      "Testing 3713/5184\n",
      "0.1 5 4 8 log2 mae 0.75 50: Weighted 0.788450 (0.075519)\n",
      "0.1 5 4 8 log2 mae 0.75 50: Macro 0.663533 (0.103349)\n",
      "Testing 3714/5184\n",
      "0.1 5 4 8 log2 mae 0.75 100: Weighted 0.776996 (0.082210)\n",
      "0.1 5 4 8 log2 mae 0.75 100: Macro 0.649164 (0.119666)\n",
      "Testing 3715/5184\n",
      "0.1 5 4 8 log2 mae 0.75 200: Weighted 0.785881 (0.094425)\n",
      "0.1 5 4 8 log2 mae 0.75 200: Macro 0.672190 (0.128793)\n",
      "Testing 3716/5184\n",
      "0.1 5 4 8 log2 mae 0.75 500: Weighted 0.787804 (0.107159)\n",
      "0.1 5 4 8 log2 mae 0.75 500: Macro 0.666016 (0.151872)\n",
      "Testing 3717/5184\n",
      "0.1 5 4 8 log2 mae 1.0 50: Weighted 0.785256 (0.076562)\n",
      "0.1 5 4 8 log2 mae 1.0 50: Macro 0.653200 (0.110701)\n",
      "Testing 3718/5184\n",
      "0.1 5 4 8 log2 mae 1.0 100: Weighted 0.775723 (0.115446)\n",
      "0.1 5 4 8 log2 mae 1.0 100: Macro 0.644924 (0.169507)\n",
      "Testing 3719/5184\n",
      "0.1 5 4 8 log2 mae 1.0 200: Weighted 0.784535 (0.095184)\n",
      "0.1 5 4 8 log2 mae 1.0 200: Macro 0.648446 (0.139379)\n",
      "Testing 3720/5184\n",
      "0.1 5 4 8 log2 mae 1.0 500: Weighted 0.793426 (0.086384)\n",
      "0.1 5 4 8 log2 mae 1.0 500: Macro 0.672922 (0.114423)\n",
      "Testing 3721/5184\n",
      "0.1 5 4 8 sqrt friedman_mse 0.5 50: Weighted 0.818850 (0.062223)\n",
      "0.1 5 4 8 sqrt friedman_mse 0.5 50: Macro 0.707948 (0.087257)\n",
      "Testing 3722/5184\n",
      "0.1 5 4 8 sqrt friedman_mse 0.5 100: Weighted 0.820254 (0.069401)\n",
      "0.1 5 4 8 sqrt friedman_mse 0.5 100: Macro 0.715117 (0.090684)\n",
      "Testing 3723/5184\n",
      "0.1 5 4 8 sqrt friedman_mse 0.5 200: Weighted 0.807830 (0.061495)\n",
      "0.1 5 4 8 sqrt friedman_mse 0.5 200: Macro 0.701056 (0.089682)\n",
      "Testing 3724/5184\n",
      "0.1 5 4 8 sqrt friedman_mse 0.5 500: Weighted 0.804928 (0.061644)\n",
      "0.1 5 4 8 sqrt friedman_mse 0.5 500: Macro 0.697472 (0.086193)\n",
      "Testing 3725/5184\n",
      "0.1 5 4 8 sqrt friedman_mse 0.75 50: Weighted 0.823079 (0.071948)\n",
      "0.1 5 4 8 sqrt friedman_mse 0.75 50: Macro 0.734515 (0.103993)\n",
      "Testing 3726/5184\n",
      "0.1 5 4 8 sqrt friedman_mse 0.75 100: Weighted 0.813081 (0.079138)\n",
      "0.1 5 4 8 sqrt friedman_mse 0.75 100: Macro 0.701165 (0.117984)\n",
      "Testing 3727/5184\n",
      "0.1 5 4 8 sqrt friedman_mse 0.75 200: Weighted 0.812949 (0.088276)\n",
      "0.1 5 4 8 sqrt friedman_mse 0.75 200: Macro 0.711428 (0.136317)\n",
      "Testing 3728/5184\n",
      "0.1 5 4 8 sqrt friedman_mse 0.75 500: Weighted 0.802860 (0.080066)\n",
      "0.1 5 4 8 sqrt friedman_mse 0.75 500: Macro 0.696809 (0.127895)\n",
      "Testing 3729/5184\n",
      "0.1 5 4 8 sqrt friedman_mse 1.0 50: Weighted 0.803542 (0.089588)\n",
      "0.1 5 4 8 sqrt friedman_mse 1.0 50: Macro 0.711365 (0.128487)\n",
      "Testing 3730/5184\n",
      "0.1 5 4 8 sqrt friedman_mse 1.0 100: Weighted 0.796103 (0.084375)\n",
      "0.1 5 4 8 sqrt friedman_mse 1.0 100: Macro 0.697681 (0.120288)\n",
      "Testing 3731/5184\n",
      "0.1 5 4 8 sqrt friedman_mse 1.0 200: Weighted 0.801474 (0.085949)\n",
      "0.1 5 4 8 sqrt friedman_mse 1.0 200: Macro 0.706629 (0.122416)\n",
      "Testing 3732/5184\n",
      "0.1 5 4 8 sqrt friedman_mse 1.0 500: Weighted 0.800621 (0.067100)\n",
      "0.1 5 4 8 sqrt friedman_mse 1.0 500: Macro 0.712487 (0.100154)\n",
      "Testing 3733/5184\n",
      "0.1 5 4 8 sqrt mae 0.5 50: Weighted 0.797883 (0.078391)\n",
      "0.1 5 4 8 sqrt mae 0.5 50: Macro 0.674266 (0.115614)\n",
      "Testing 3734/5184\n",
      "0.1 5 4 8 sqrt mae 0.5 100: Weighted 0.779933 (0.079575)\n",
      "0.1 5 4 8 sqrt mae 0.5 100: Macro 0.652654 (0.112001)\n",
      "Testing 3735/5184\n",
      "0.1 5 4 8 sqrt mae 0.5 200: Weighted 0.783597 (0.076046)\n",
      "0.1 5 4 8 sqrt mae 0.5 200: Macro 0.658348 (0.093987)\n",
      "Testing 3736/5184\n",
      "0.1 5 4 8 sqrt mae 0.5 500: Weighted 0.798832 (0.069579)\n",
      "0.1 5 4 8 sqrt mae 0.5 500: Macro 0.680471 (0.087505)\n",
      "Testing 3737/5184\n",
      "0.1 5 4 8 sqrt mae 0.75 50: Weighted 0.789887 (0.069241)\n",
      "0.1 5 4 8 sqrt mae 0.75 50: Macro 0.663804 (0.101161)\n",
      "Testing 3738/5184\n",
      "0.1 5 4 8 sqrt mae 0.75 100: Weighted 0.784814 (0.075910)\n",
      "0.1 5 4 8 sqrt mae 0.75 100: Macro 0.660417 (0.107327)\n",
      "Testing 3739/5184\n",
      "0.1 5 4 8 sqrt mae 0.75 200: Weighted 0.787603 (0.092809)\n",
      "0.1 5 4 8 sqrt mae 0.75 200: Macro 0.671145 (0.128244)\n",
      "Testing 3740/5184\n",
      "0.1 5 4 8 sqrt mae 0.75 500: Weighted 0.799972 (0.084429)\n",
      "0.1 5 4 8 sqrt mae 0.75 500: Macro 0.681215 (0.113702)\n",
      "Testing 3741/5184\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1 5 4 8 sqrt mae 1.0 50: Weighted 0.783252 (0.071547)\n",
      "0.1 5 4 8 sqrt mae 1.0 50: Macro 0.650527 (0.102445)\n",
      "Testing 3742/5184\n",
      "0.1 5 4 8 sqrt mae 1.0 100: Weighted 0.768026 (0.091090)\n",
      "0.1 5 4 8 sqrt mae 1.0 100: Macro 0.633570 (0.136297)\n",
      "Testing 3743/5184\n",
      "0.1 5 4 8 sqrt mae 1.0 200: Weighted 0.777876 (0.101878)\n",
      "0.1 5 4 8 sqrt mae 1.0 200: Macro 0.648426 (0.149328)\n",
      "Testing 3744/5184\n",
      "0.1 5 4 8 sqrt mae 1.0 500: Weighted 0.789162 (0.081840)\n",
      "0.1 5 4 8 sqrt mae 1.0 500: Macro 0.664345 (0.121676)\n",
      "Testing 3745/5184\n",
      "0.1 5 6 3 log2 friedman_mse 0.5 50: Weighted 0.819924 (0.068769)\n",
      "0.1 5 6 3 log2 friedman_mse 0.5 50: Macro 0.716888 (0.092219)\n",
      "Testing 3746/5184\n",
      "0.1 5 6 3 log2 friedman_mse 0.5 100: Weighted 0.818947 (0.053679)\n",
      "0.1 5 6 3 log2 friedman_mse 0.5 100: Macro 0.720396 (0.080175)\n",
      "Testing 3747/5184\n",
      "0.1 5 6 3 log2 friedman_mse 0.5 200: Weighted 0.819112 (0.058509)\n",
      "0.1 5 6 3 log2 friedman_mse 0.5 200: Macro 0.708898 (0.085526)\n",
      "Testing 3748/5184\n",
      "0.1 5 6 3 log2 friedman_mse 0.5 500: Weighted 0.806827 (0.052894)\n",
      "0.1 5 6 3 log2 friedman_mse 0.5 500: Macro 0.708942 (0.076966)\n",
      "Testing 3749/5184\n",
      "0.1 5 6 3 log2 friedman_mse 0.75 50: Weighted 0.818454 (0.068005)\n",
      "0.1 5 6 3 log2 friedman_mse 0.75 50: Macro 0.714861 (0.091165)\n",
      "Testing 3750/5184\n",
      "0.1 5 6 3 log2 friedman_mse 0.75 100: Weighted 0.812257 (0.068565)\n",
      "0.1 5 6 3 log2 friedman_mse 0.75 100: Macro 0.703741 (0.086245)\n",
      "Testing 3751/5184\n",
      "0.1 5 6 3 log2 friedman_mse 0.75 200: Weighted 0.825249 (0.066917)\n",
      "0.1 5 6 3 log2 friedman_mse 0.75 200: Macro 0.730859 (0.088275)\n",
      "Testing 3752/5184\n",
      "0.1 5 6 3 log2 friedman_mse 0.75 500: Weighted 0.811399 (0.062718)\n",
      "0.1 5 6 3 log2 friedman_mse 0.75 500: Macro 0.712989 (0.091344)\n",
      "Testing 3753/5184\n",
      "0.1 5 6 3 log2 friedman_mse 1.0 50: Weighted 0.807392 (0.076659)\n",
      "0.1 5 6 3 log2 friedman_mse 1.0 50: Macro 0.707986 (0.096210)\n",
      "Testing 3754/5184\n",
      "0.1 5 6 3 log2 friedman_mse 1.0 100: Weighted 0.812204 (0.076102)\n",
      "0.1 5 6 3 log2 friedman_mse 1.0 100: Macro 0.709892 (0.102524)\n",
      "Testing 3755/5184\n",
      "0.1 5 6 3 log2 friedman_mse 1.0 200: Weighted 0.809788 (0.068265)\n",
      "0.1 5 6 3 log2 friedman_mse 1.0 200: Macro 0.705155 (0.101076)\n",
      "Testing 3756/5184\n",
      "0.1 5 6 3 log2 friedman_mse 1.0 500: Weighted 0.801179 (0.058530)\n",
      "0.1 5 6 3 log2 friedman_mse 1.0 500: Macro 0.702333 (0.083537)\n",
      "Testing 3757/5184\n",
      "0.1 5 6 3 log2 mae 0.5 50: Weighted 0.798823 (0.082442)\n",
      "0.1 5 6 3 log2 mae 0.5 50: Macro 0.683690 (0.112247)\n",
      "Testing 3758/5184\n",
      "0.1 5 6 3 log2 mae 0.5 100: Weighted 0.804690 (0.065831)\n",
      "0.1 5 6 3 log2 mae 0.5 100: Macro 0.689365 (0.091930)\n",
      "Testing 3759/5184\n",
      "0.1 5 6 3 log2 mae 0.5 200: Weighted 0.793872 (0.092138)\n",
      "0.1 5 6 3 log2 mae 0.5 200: Macro 0.684719 (0.124934)\n",
      "Testing 3760/5184\n",
      "0.1 5 6 3 log2 mae 0.5 500: Weighted 0.795861 (0.071000)\n",
      "0.1 5 6 3 log2 mae 0.5 500: Macro 0.678763 (0.093813)\n",
      "Testing 3761/5184\n",
      "0.1 5 6 3 log2 mae 0.75 50: Weighted 0.795326 (0.053636)\n",
      "0.1 5 6 3 log2 mae 0.75 50: Macro 0.678002 (0.079749)\n",
      "Testing 3762/5184\n",
      "0.1 5 6 3 log2 mae 0.75 100: Weighted 0.782753 (0.076114)\n",
      "0.1 5 6 3 log2 mae 0.75 100: Macro 0.662326 (0.110245)\n",
      "Testing 3763/5184\n",
      "0.1 5 6 3 log2 mae 0.75 200: Weighted 0.770262 (0.054339)\n",
      "0.1 5 6 3 log2 mae 0.75 200: Macro 0.630230 (0.078202)\n",
      "Testing 3764/5184\n",
      "0.1 5 6 3 log2 mae 0.75 500: Weighted 0.773011 (0.057357)\n",
      "0.1 5 6 3 log2 mae 0.75 500: Macro 0.634097 (0.078371)\n",
      "Testing 3765/5184\n",
      "0.1 5 6 3 log2 mae 1.0 50: Weighted 0.787104 (0.081159)\n",
      "0.1 5 6 3 log2 mae 1.0 50: Macro 0.654508 (0.120690)\n",
      "Testing 3766/5184\n",
      "0.1 5 6 3 log2 mae 1.0 100: Weighted 0.786612 (0.064007)\n",
      "0.1 5 6 3 log2 mae 1.0 100: Macro 0.657491 (0.098384)\n",
      "Testing 3767/5184\n",
      "0.1 5 6 3 log2 mae 1.0 200: Weighted 0.773777 (0.053443)\n",
      "0.1 5 6 3 log2 mae 1.0 200: Macro 0.638025 (0.077693)\n",
      "Testing 3768/5184\n",
      "0.1 5 6 3 log2 mae 1.0 500: Weighted 0.759144 (0.074246)\n",
      "0.1 5 6 3 log2 mae 1.0 500: Macro 0.624129 (0.105760)\n",
      "Testing 3769/5184\n",
      "0.1 5 6 3 sqrt friedman_mse 0.5 50: Weighted 0.819513 (0.071512)\n",
      "0.1 5 6 3 sqrt friedman_mse 0.5 50: Macro 0.721394 (0.091707)\n",
      "Testing 3770/5184\n",
      "0.1 5 6 3 sqrt friedman_mse 0.5 100: Weighted 0.817281 (0.055238)\n",
      "0.1 5 6 3 sqrt friedman_mse 0.5 100: Macro 0.712385 (0.079909)\n",
      "Testing 3771/5184\n",
      "0.1 5 6 3 sqrt friedman_mse 0.5 200: Weighted 0.801873 (0.069975)\n",
      "0.1 5 6 3 sqrt friedman_mse 0.5 200: Macro 0.692857 (0.104740)\n",
      "Testing 3772/5184\n",
      "0.1 5 6 3 sqrt friedman_mse 0.5 500: Weighted 0.803349 (0.046147)\n",
      "0.1 5 6 3 sqrt friedman_mse 0.5 500: Macro 0.699257 (0.067634)\n",
      "Testing 3773/5184\n",
      "0.1 5 6 3 sqrt friedman_mse 0.75 50: Weighted 0.812462 (0.070709)\n",
      "0.1 5 6 3 sqrt friedman_mse 0.75 50: Macro 0.706427 (0.092798)\n",
      "Testing 3774/5184\n",
      "0.1 5 6 3 sqrt friedman_mse 0.75 100: Weighted 0.812806 (0.062924)\n",
      "0.1 5 6 3 sqrt friedman_mse 0.75 100: Macro 0.710945 (0.085607)\n",
      "Testing 3775/5184\n",
      "0.1 5 6 3 sqrt friedman_mse 0.75 200: Weighted 0.824135 (0.055232)\n",
      "0.1 5 6 3 sqrt friedman_mse 0.75 200: Macro 0.725112 (0.072297)\n",
      "Testing 3776/5184\n",
      "0.1 5 6 3 sqrt friedman_mse 0.75 500: Weighted 0.809940 (0.063367)\n",
      "0.1 5 6 3 sqrt friedman_mse 0.75 500: Macro 0.712227 (0.087963)\n",
      "Testing 3777/5184\n",
      "0.1 5 6 3 sqrt friedman_mse 1.0 50: Weighted 0.799872 (0.055684)\n",
      "0.1 5 6 3 sqrt friedman_mse 1.0 50: Macro 0.690865 (0.063977)\n",
      "Testing 3778/5184\n",
      "0.1 5 6 3 sqrt friedman_mse 1.0 100: Weighted 0.824840 (0.075995)\n",
      "0.1 5 6 3 sqrt friedman_mse 1.0 100: Macro 0.732942 (0.099831)\n",
      "Testing 3779/5184\n",
      "0.1 5 6 3 sqrt friedman_mse 1.0 200: Weighted 0.805020 (0.065961)\n",
      "0.1 5 6 3 sqrt friedman_mse 1.0 200: Macro 0.702295 (0.085854)\n",
      "Testing 3780/5184\n",
      "0.1 5 6 3 sqrt friedman_mse 1.0 500: Weighted 0.809444 (0.058086)\n",
      "0.1 5 6 3 sqrt friedman_mse 1.0 500: Macro 0.713975 (0.070455)\n",
      "Testing 3781/5184\n",
      "0.1 5 6 3 sqrt mae 0.5 50: Weighted 0.805021 (0.064279)\n",
      "0.1 5 6 3 sqrt mae 0.5 50: Macro 0.684522 (0.096374)\n",
      "Testing 3782/5184\n",
      "0.1 5 6 3 sqrt mae 0.5 100: Weighted 0.795521 (0.052868)\n",
      "0.1 5 6 3 sqrt mae 0.5 100: Macro 0.671481 (0.070310)\n",
      "Testing 3783/5184\n",
      "0.1 5 6 3 sqrt mae 0.5 200: Weighted 0.783894 (0.066280)\n",
      "0.1 5 6 3 sqrt mae 0.5 200: Macro 0.658439 (0.091564)\n",
      "Testing 3784/5184\n",
      "0.1 5 6 3 sqrt mae 0.5 500: Weighted 0.768374 (0.078849)\n",
      "0.1 5 6 3 sqrt mae 0.5 500: Macro 0.630216 (0.108334)\n",
      "Testing 3785/5184\n",
      "0.1 5 6 3 sqrt mae 0.75 50: Weighted 0.803483 (0.062452)\n",
      "0.1 5 6 3 sqrt mae 0.75 50: Macro 0.689461 (0.084025)\n",
      "Testing 3786/5184\n",
      "0.1 5 6 3 sqrt mae 0.75 100: Weighted 0.779586 (0.059683)\n",
      "0.1 5 6 3 sqrt mae 0.75 100: Macro 0.653562 (0.078930)\n",
      "Testing 3787/5184\n",
      "0.1 5 6 3 sqrt mae 0.75 200: Weighted 0.773412 (0.065877)\n",
      "0.1 5 6 3 sqrt mae 0.75 200: Macro 0.640354 (0.086797)\n",
      "Testing 3788/5184\n",
      "0.1 5 6 3 sqrt mae 0.75 500: Weighted 0.764251 (0.074561)\n",
      "0.1 5 6 3 sqrt mae 0.75 500: Macro 0.629350 (0.107377)\n",
      "Testing 3789/5184\n",
      "0.1 5 6 3 sqrt mae 1.0 50: Weighted 0.783687 (0.086208)\n",
      "0.1 5 6 3 sqrt mae 1.0 50: Macro 0.652283 (0.127673)\n",
      "Testing 3790/5184\n",
      "0.1 5 6 3 sqrt mae 1.0 100: Weighted 0.776905 (0.083760)\n",
      "0.1 5 6 3 sqrt mae 1.0 100: Macro 0.640792 (0.120170)\n",
      "Testing 3791/5184\n",
      "0.1 5 6 3 sqrt mae 1.0 200: Weighted 0.764116 (0.054431)\n",
      "0.1 5 6 3 sqrt mae 1.0 200: Macro 0.624440 (0.085090)\n",
      "Testing 3792/5184\n",
      "0.1 5 6 3 sqrt mae 1.0 500: Weighted 0.772270 (0.074139)\n",
      "0.1 5 6 3 sqrt mae 1.0 500: Macro 0.628633 (0.100374)\n",
      "Testing 3793/5184\n",
      "0.1 5 6 5 log2 friedman_mse 0.5 50: Weighted 0.811312 (0.061761)\n",
      "0.1 5 6 5 log2 friedman_mse 0.5 50: Macro 0.694015 (0.084053)\n",
      "Testing 3794/5184\n",
      "0.1 5 6 5 log2 friedman_mse 0.5 100: Weighted 0.825943 (0.083103)\n",
      "0.1 5 6 5 log2 friedman_mse 0.5 100: Macro 0.727976 (0.114918)\n",
      "Testing 3795/5184\n",
      "0.1 5 6 5 log2 friedman_mse 0.5 200: Weighted 0.814333 (0.068684)\n",
      "0.1 5 6 5 log2 friedman_mse 0.5 200: Macro 0.713076 (0.100434)\n",
      "Testing 3796/5184\n",
      "0.1 5 6 5 log2 friedman_mse 0.5 500: Weighted 0.810393 (0.060324)\n",
      "0.1 5 6 5 log2 friedman_mse 0.5 500: Macro 0.708037 (0.088767)\n",
      "Testing 3797/5184\n",
      "0.1 5 6 5 log2 friedman_mse 0.75 50: Weighted 0.833698 (0.071173)\n",
      "0.1 5 6 5 log2 friedman_mse 0.75 50: Macro 0.744728 (0.096353)\n",
      "Testing 3798/5184\n",
      "0.1 5 6 5 log2 friedman_mse 0.75 100: Weighted 0.806961 (0.064890)\n",
      "0.1 5 6 5 log2 friedman_mse 0.75 100: Macro 0.697143 (0.081861)\n",
      "Testing 3799/5184\n",
      "0.1 5 6 5 log2 friedman_mse 0.75 200: Weighted 0.822015 (0.068115)\n",
      "0.1 5 6 5 log2 friedman_mse 0.75 200: Macro 0.722793 (0.092191)\n",
      "Testing 3800/5184\n",
      "0.1 5 6 5 log2 friedman_mse 0.75 500: Weighted 0.819836 (0.065176)\n",
      "0.1 5 6 5 log2 friedman_mse 0.75 500: Macro 0.722024 (0.092511)\n",
      "Testing 3801/5184\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1 5 6 5 log2 friedman_mse 1.0 50: Weighted 0.813139 (0.076744)\n",
      "0.1 5 6 5 log2 friedman_mse 1.0 50: Macro 0.718318 (0.098981)\n",
      "Testing 3802/5184\n",
      "0.1 5 6 5 log2 friedman_mse 1.0 100: Weighted 0.793168 (0.095448)\n",
      "0.1 5 6 5 log2 friedman_mse 1.0 100: Macro 0.684581 (0.133448)\n",
      "Testing 3803/5184\n",
      "0.1 5 6 5 log2 friedman_mse 1.0 200: Weighted 0.805744 (0.069600)\n",
      "0.1 5 6 5 log2 friedman_mse 1.0 200: Macro 0.707227 (0.094588)\n",
      "Testing 3804/5184\n",
      "0.1 5 6 5 log2 friedman_mse 1.0 500: Weighted 0.805218 (0.063143)\n",
      "0.1 5 6 5 log2 friedman_mse 1.0 500: Macro 0.708296 (0.087619)\n",
      "Testing 3805/5184\n",
      "0.1 5 6 5 log2 mae 0.5 50: Weighted 0.802607 (0.058839)\n",
      "0.1 5 6 5 log2 mae 0.5 50: Macro 0.678817 (0.088248)\n",
      "Testing 3806/5184\n",
      "0.1 5 6 5 log2 mae 0.5 100: Weighted 0.794375 (0.083667)\n",
      "0.1 5 6 5 log2 mae 0.5 100: Macro 0.670470 (0.120273)\n",
      "Testing 3807/5184\n",
      "0.1 5 6 5 log2 mae 0.5 200: Weighted 0.787127 (0.098531)\n",
      "0.1 5 6 5 log2 mae 0.5 200: Macro 0.667528 (0.133294)\n",
      "Testing 3808/5184\n",
      "0.1 5 6 5 log2 mae 0.5 500: Weighted 0.780817 (0.079877)\n",
      "0.1 5 6 5 log2 mae 0.5 500: Macro 0.663138 (0.103144)\n",
      "Testing 3809/5184\n",
      "0.1 5 6 5 log2 mae 0.75 50: Weighted 0.776338 (0.074966)\n",
      "0.1 5 6 5 log2 mae 0.75 50: Macro 0.638096 (0.108363)\n",
      "Testing 3810/5184\n",
      "0.1 5 6 5 log2 mae 0.75 100: Weighted 0.776233 (0.091348)\n",
      "0.1 5 6 5 log2 mae 0.75 100: Macro 0.643775 (0.130632)\n",
      "Testing 3811/5184\n",
      "0.1 5 6 5 log2 mae 0.75 200: Weighted 0.788969 (0.087459)\n",
      "0.1 5 6 5 log2 mae 0.75 200: Macro 0.665520 (0.115811)\n",
      "Testing 3812/5184\n",
      "0.1 5 6 5 log2 mae 0.75 500: Weighted 0.782092 (0.083276)\n",
      "0.1 5 6 5 log2 mae 0.75 500: Macro 0.653735 (0.102269)\n",
      "Testing 3813/5184\n",
      "0.1 5 6 5 log2 mae 1.0 50: Weighted 0.772399 (0.068855)\n",
      "0.1 5 6 5 log2 mae 1.0 50: Macro 0.633863 (0.099885)\n",
      "Testing 3814/5184\n",
      "0.1 5 6 5 log2 mae 1.0 100: Weighted 0.779466 (0.086185)\n",
      "0.1 5 6 5 log2 mae 1.0 100: Macro 0.639598 (0.115835)\n",
      "Testing 3815/5184\n",
      "0.1 5 6 5 log2 mae 1.0 200: Weighted 0.777906 (0.103445)\n",
      "0.1 5 6 5 log2 mae 1.0 200: Macro 0.648737 (0.148011)\n",
      "Testing 3816/5184\n",
      "0.1 5 6 5 log2 mae 1.0 500: Weighted 0.773914 (0.089890)\n",
      "0.1 5 6 5 log2 mae 1.0 500: Macro 0.635590 (0.122038)\n",
      "Testing 3817/5184\n",
      "0.1 5 6 5 sqrt friedman_mse 0.5 50: Weighted 0.819358 (0.057308)\n",
      "0.1 5 6 5 sqrt friedman_mse 0.5 50: Macro 0.713986 (0.071654)\n",
      "Testing 3818/5184\n",
      "0.1 5 6 5 sqrt friedman_mse 0.5 100: Weighted 0.809332 (0.059780)\n",
      "0.1 5 6 5 sqrt friedman_mse 0.5 100: Macro 0.701328 (0.085406)\n",
      "Testing 3819/5184\n",
      "0.1 5 6 5 sqrt friedman_mse 0.5 200: Weighted 0.809893 (0.068615)\n",
      "0.1 5 6 5 sqrt friedman_mse 0.5 200: Macro 0.709263 (0.104266)\n",
      "Testing 3820/5184\n",
      "0.1 5 6 5 sqrt friedman_mse 0.5 500: Weighted 0.795598 (0.058642)\n",
      "0.1 5 6 5 sqrt friedman_mse 0.5 500: Macro 0.697137 (0.094029)\n",
      "Testing 3821/5184\n",
      "0.1 5 6 5 sqrt friedman_mse 0.75 50: Weighted 0.815760 (0.081476)\n",
      "0.1 5 6 5 sqrt friedman_mse 0.75 50: Macro 0.717274 (0.110807)\n",
      "Testing 3822/5184\n",
      "0.1 5 6 5 sqrt friedman_mse 0.75 100: Weighted 0.805826 (0.070633)\n",
      "0.1 5 6 5 sqrt friedman_mse 0.75 100: Macro 0.702355 (0.104823)\n",
      "Testing 3823/5184\n",
      "0.1 5 6 5 sqrt friedman_mse 0.75 200: Weighted 0.813247 (0.075354)\n",
      "0.1 5 6 5 sqrt friedman_mse 0.75 200: Macro 0.706489 (0.103102)\n",
      "Testing 3824/5184\n",
      "0.1 5 6 5 sqrt friedman_mse 0.75 500: Weighted 0.806729 (0.084516)\n",
      "0.1 5 6 5 sqrt friedman_mse 0.75 500: Macro 0.692174 (0.120454)\n",
      "Testing 3825/5184\n",
      "0.1 5 6 5 sqrt friedman_mse 1.0 50: Weighted 0.812619 (0.082061)\n",
      "0.1 5 6 5 sqrt friedman_mse 1.0 50: Macro 0.711171 (0.115054)\n",
      "Testing 3826/5184\n",
      "0.1 5 6 5 sqrt friedman_mse 1.0 100: Weighted 0.800955 (0.082928)\n",
      "0.1 5 6 5 sqrt friedman_mse 1.0 100: Macro 0.702435 (0.118092)\n",
      "Testing 3827/5184\n",
      "0.1 5 6 5 sqrt friedman_mse 1.0 200: Weighted 0.814084 (0.080094)\n",
      "0.1 5 6 5 sqrt friedman_mse 1.0 200: Macro 0.719701 (0.123161)\n",
      "Testing 3828/5184\n",
      "0.1 5 6 5 sqrt friedman_mse 1.0 500: Weighted 0.809494 (0.066924)\n",
      "0.1 5 6 5 sqrt friedman_mse 1.0 500: Macro 0.704371 (0.102532)\n",
      "Testing 3829/5184\n",
      "0.1 5 6 5 sqrt mae 0.5 50: Weighted 0.802564 (0.062156)\n",
      "0.1 5 6 5 sqrt mae 0.5 50: Macro 0.682973 (0.089144)\n",
      "Testing 3830/5184\n",
      "0.1 5 6 5 sqrt mae 0.5 100: Weighted 0.787246 (0.052457)\n",
      "0.1 5 6 5 sqrt mae 0.5 100: Macro 0.657908 (0.066661)\n",
      "Testing 3831/5184\n",
      "0.1 5 6 5 sqrt mae 0.5 200: Weighted 0.798052 (0.089589)\n",
      "0.1 5 6 5 sqrt mae 0.5 200: Macro 0.680988 (0.129121)\n",
      "Testing 3832/5184\n",
      "0.1 5 6 5 sqrt mae 0.5 500: Weighted 0.796312 (0.075225)\n",
      "0.1 5 6 5 sqrt mae 0.5 500: Macro 0.684745 (0.098647)\n",
      "Testing 3833/5184\n",
      "0.1 5 6 5 sqrt mae 0.75 50: Weighted 0.795848 (0.077412)\n",
      "0.1 5 6 5 sqrt mae 0.75 50: Macro 0.676684 (0.106003)\n",
      "Testing 3834/5184\n",
      "0.1 5 6 5 sqrt mae 0.75 100: Weighted 0.763307 (0.065947)\n",
      "0.1 5 6 5 sqrt mae 0.75 100: Macro 0.620020 (0.083296)\n",
      "Testing 3835/5184\n",
      "0.1 5 6 5 sqrt mae 0.75 200: Weighted 0.772190 (0.076323)\n",
      "0.1 5 6 5 sqrt mae 0.75 200: Macro 0.645137 (0.103780)\n",
      "Testing 3836/5184\n",
      "0.1 5 6 5 sqrt mae 0.75 500: Weighted 0.774430 (0.089814)\n",
      "0.1 5 6 5 sqrt mae 0.75 500: Macro 0.644959 (0.127998)\n",
      "Testing 3837/5184\n",
      "0.1 5 6 5 sqrt mae 1.0 50: Weighted 0.776870 (0.066437)\n",
      "0.1 5 6 5 sqrt mae 1.0 50: Macro 0.635580 (0.092024)\n",
      "Testing 3838/5184\n",
      "0.1 5 6 5 sqrt mae 1.0 100: Weighted 0.758678 (0.088284)\n",
      "0.1 5 6 5 sqrt mae 1.0 100: Macro 0.612293 (0.120415)\n",
      "Testing 3839/5184\n",
      "0.1 5 6 5 sqrt mae 1.0 200: Weighted 0.787263 (0.107727)\n",
      "0.1 5 6 5 sqrt mae 1.0 200: Macro 0.663962 (0.154263)\n",
      "Testing 3840/5184\n",
      "0.1 5 6 5 sqrt mae 1.0 500: Weighted 0.780204 (0.096983)\n",
      "0.1 5 6 5 sqrt mae 1.0 500: Macro 0.655835 (0.138205)\n",
      "Testing 3841/5184\n",
      "0.1 5 6 8 log2 friedman_mse 0.5 50: Weighted 0.813759 (0.059532)\n",
      "0.1 5 6 8 log2 friedman_mse 0.5 50: Macro 0.716370 (0.074892)\n",
      "Testing 3842/5184\n",
      "0.1 5 6 8 log2 friedman_mse 0.5 100: Weighted 0.813915 (0.058653)\n",
      "0.1 5 6 8 log2 friedman_mse 0.5 100: Macro 0.711633 (0.089128)\n",
      "Testing 3843/5184\n",
      "0.1 5 6 8 log2 friedman_mse 0.5 200: Weighted 0.822749 (0.063433)\n",
      "0.1 5 6 8 log2 friedman_mse 0.5 200: Macro 0.724723 (0.101617)\n",
      "Testing 3844/5184\n",
      "0.1 5 6 8 log2 friedman_mse 0.5 500: Weighted 0.807487 (0.068123)\n",
      "0.1 5 6 8 log2 friedman_mse 0.5 500: Macro 0.703597 (0.108671)\n",
      "Testing 3845/5184\n",
      "0.1 5 6 8 log2 friedman_mse 0.75 50: Weighted 0.814319 (0.075893)\n",
      "0.1 5 6 8 log2 friedman_mse 0.75 50: Macro 0.712175 (0.106037)\n",
      "Testing 3846/5184\n",
      "0.1 5 6 8 log2 friedman_mse 0.75 100: Weighted 0.815284 (0.071071)\n",
      "0.1 5 6 8 log2 friedman_mse 0.75 100: Macro 0.716349 (0.101641)\n",
      "Testing 3847/5184\n",
      "0.1 5 6 8 log2 friedman_mse 0.75 200: Weighted 0.811429 (0.075802)\n",
      "0.1 5 6 8 log2 friedman_mse 0.75 200: Macro 0.710584 (0.119168)\n",
      "Testing 3848/5184\n",
      "0.1 5 6 8 log2 friedman_mse 0.75 500: Weighted 0.813796 (0.083141)\n",
      "0.1 5 6 8 log2 friedman_mse 0.75 500: Macro 0.716269 (0.135945)\n",
      "Testing 3849/5184\n",
      "0.1 5 6 8 log2 friedman_mse 1.0 50: Weighted 0.800527 (0.097256)\n",
      "0.1 5 6 8 log2 friedman_mse 1.0 50: Macro 0.694777 (0.132819)\n",
      "Testing 3850/5184\n",
      "0.1 5 6 8 log2 friedman_mse 1.0 100: Weighted 0.800259 (0.093779)\n",
      "0.1 5 6 8 log2 friedman_mse 1.0 100: Macro 0.696696 (0.137242)\n",
      "Testing 3851/5184\n",
      "0.1 5 6 8 log2 friedman_mse 1.0 200: Weighted 0.793944 (0.063810)\n",
      "0.1 5 6 8 log2 friedman_mse 1.0 200: Macro 0.691151 (0.099300)\n",
      "Testing 3852/5184\n",
      "0.1 5 6 8 log2 friedman_mse 1.0 500: Weighted 0.810355 (0.094328)\n",
      "0.1 5 6 8 log2 friedman_mse 1.0 500: Macro 0.711522 (0.145148)\n",
      "Testing 3853/5184\n",
      "0.1 5 6 8 log2 mae 0.5 50: Weighted 0.809538 (0.060225)\n",
      "0.1 5 6 8 log2 mae 0.5 50: Macro 0.692474 (0.086996)\n",
      "Testing 3854/5184\n",
      "0.1 5 6 8 log2 mae 0.5 100: Weighted 0.788203 (0.082979)\n",
      "0.1 5 6 8 log2 mae 0.5 100: Macro 0.669007 (0.112296)\n",
      "Testing 3855/5184\n",
      "0.1 5 6 8 log2 mae 0.5 200: Weighted 0.796019 (0.075980)\n",
      "0.1 5 6 8 log2 mae 0.5 200: Macro 0.671789 (0.109397)\n",
      "Testing 3856/5184\n",
      "0.1 5 6 8 log2 mae 0.5 500: Weighted 0.798660 (0.066725)\n",
      "0.1 5 6 8 log2 mae 0.5 500: Macro 0.679664 (0.085424)\n",
      "Testing 3857/5184\n",
      "0.1 5 6 8 log2 mae 0.75 50: Weighted 0.781329 (0.062324)\n",
      "0.1 5 6 8 log2 mae 0.75 50: Macro 0.656976 (0.080507)\n",
      "Testing 3858/5184\n",
      "0.1 5 6 8 log2 mae 0.75 100: Weighted 0.788504 (0.108239)\n",
      "0.1 5 6 8 log2 mae 0.75 100: Macro 0.662646 (0.160523)\n",
      "Testing 3859/5184\n",
      "0.1 5 6 8 log2 mae 0.75 200: Weighted 0.788846 (0.097488)\n",
      "0.1 5 6 8 log2 mae 0.75 200: Macro 0.664534 (0.141004)\n",
      "Testing 3860/5184\n",
      "0.1 5 6 8 log2 mae 0.75 500: Weighted 0.799288 (0.087445)\n",
      "0.1 5 6 8 log2 mae 0.75 500: Macro 0.679549 (0.123759)\n",
      "Testing 3861/5184\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1 5 6 8 log2 mae 1.0 50: Weighted 0.783277 (0.074246)\n",
      "0.1 5 6 8 log2 mae 1.0 50: Macro 0.649146 (0.108415)\n",
      "Testing 3862/5184\n",
      "0.1 5 6 8 log2 mae 1.0 100: Weighted 0.769643 (0.090337)\n",
      "0.1 5 6 8 log2 mae 1.0 100: Macro 0.629782 (0.131666)\n",
      "Testing 3863/5184\n",
      "0.1 5 6 8 log2 mae 1.0 200: Weighted 0.788692 (0.106317)\n",
      "0.1 5 6 8 log2 mae 1.0 200: Macro 0.660958 (0.156787)\n",
      "Testing 3864/5184\n",
      "0.1 5 6 8 log2 mae 1.0 500: Weighted 0.775819 (0.082406)\n",
      "0.1 5 6 8 log2 mae 1.0 500: Macro 0.646170 (0.115134)\n",
      "Testing 3865/5184\n",
      "0.1 5 6 8 sqrt friedman_mse 0.5 50: Weighted 0.807145 (0.065687)\n",
      "0.1 5 6 8 sqrt friedman_mse 0.5 50: Macro 0.702776 (0.087560)\n",
      "Testing 3866/5184\n",
      "0.1 5 6 8 sqrt friedman_mse 0.5 100: Weighted 0.818114 (0.073089)\n",
      "0.1 5 6 8 sqrt friedman_mse 0.5 100: Macro 0.722209 (0.114274)\n",
      "Testing 3867/5184\n",
      "0.1 5 6 8 sqrt friedman_mse 0.5 200: Weighted 0.813935 (0.072255)\n",
      "0.1 5 6 8 sqrt friedman_mse 0.5 200: Macro 0.717019 (0.093718)\n",
      "Testing 3868/5184\n",
      "0.1 5 6 8 sqrt friedman_mse 0.5 500: Weighted 0.803383 (0.070151)\n",
      "0.1 5 6 8 sqrt friedman_mse 0.5 500: Macro 0.709085 (0.121086)\n",
      "Testing 3869/5184\n",
      "0.1 5 6 8 sqrt friedman_mse 0.75 50: Weighted 0.812930 (0.079769)\n",
      "0.1 5 6 8 sqrt friedman_mse 0.75 50: Macro 0.711536 (0.107548)\n",
      "Testing 3870/5184\n",
      "0.1 5 6 8 sqrt friedman_mse 0.75 100: Weighted 0.814542 (0.093065)\n",
      "0.1 5 6 8 sqrt friedman_mse 0.75 100: Macro 0.711751 (0.137176)\n",
      "Testing 3871/5184\n",
      "0.1 5 6 8 sqrt friedman_mse 0.75 200: Weighted 0.804626 (0.070734)\n",
      "0.1 5 6 8 sqrt friedman_mse 0.75 200: Macro 0.704010 (0.104484)\n",
      "Testing 3872/5184\n",
      "0.1 5 6 8 sqrt friedman_mse 0.75 500: Weighted 0.821185 (0.069407)\n",
      "0.1 5 6 8 sqrt friedman_mse 0.75 500: Macro 0.720879 (0.103832)\n",
      "Testing 3873/5184\n",
      "0.1 5 6 8 sqrt friedman_mse 1.0 50: Weighted 0.811613 (0.077823)\n",
      "0.1 5 6 8 sqrt friedman_mse 1.0 50: Macro 0.713136 (0.104084)\n",
      "Testing 3874/5184\n",
      "0.1 5 6 8 sqrt friedman_mse 1.0 100: Weighted 0.811363 (0.095309)\n",
      "0.1 5 6 8 sqrt friedman_mse 1.0 100: Macro 0.718541 (0.142470)\n",
      "Testing 3875/5184\n",
      "0.1 5 6 8 sqrt friedman_mse 1.0 200: Weighted 0.800566 (0.086362)\n",
      "0.1 5 6 8 sqrt friedman_mse 1.0 200: Macro 0.708631 (0.126606)\n",
      "Testing 3876/5184\n",
      "0.1 5 6 8 sqrt friedman_mse 1.0 500: Weighted 0.807505 (0.091763)\n",
      "0.1 5 6 8 sqrt friedman_mse 1.0 500: Macro 0.711557 (0.141336)\n",
      "Testing 3877/5184\n",
      "0.1 5 6 8 sqrt mae 0.5 50: Weighted 0.817161 (0.070690)\n",
      "0.1 5 6 8 sqrt mae 0.5 50: Macro 0.709204 (0.099873)\n",
      "Testing 3878/5184\n",
      "0.1 5 6 8 sqrt mae 0.5 100: Weighted 0.787331 (0.073240)\n",
      "0.1 5 6 8 sqrt mae 0.5 100: Macro 0.655126 (0.114182)\n",
      "Testing 3879/5184\n",
      "0.1 5 6 8 sqrt mae 0.5 200: Weighted 0.799627 (0.069490)\n",
      "0.1 5 6 8 sqrt mae 0.5 200: Macro 0.675156 (0.100859)\n",
      "Testing 3880/5184\n",
      "0.1 5 6 8 sqrt mae 0.5 500: Weighted 0.793418 (0.081769)\n",
      "0.1 5 6 8 sqrt mae 0.5 500: Macro 0.677258 (0.101740)\n",
      "Testing 3881/5184\n",
      "0.1 5 6 8 sqrt mae 0.75 50: Weighted 0.797037 (0.059247)\n",
      "0.1 5 6 8 sqrt mae 0.75 50: Macro 0.672130 (0.083309)\n",
      "Testing 3882/5184\n",
      "0.1 5 6 8 sqrt mae 0.75 100: Weighted 0.805732 (0.083252)\n",
      "0.1 5 6 8 sqrt mae 0.75 100: Macro 0.688687 (0.118480)\n",
      "Testing 3883/5184\n",
      "0.1 5 6 8 sqrt mae 0.75 200: Weighted 0.787046 (0.088841)\n",
      "0.1 5 6 8 sqrt mae 0.75 200: Macro 0.661335 (0.128149)\n",
      "Testing 3884/5184\n",
      "0.1 5 6 8 sqrt mae 0.75 500: Weighted 0.787492 (0.096323)\n",
      "0.1 5 6 8 sqrt mae 0.75 500: Macro 0.661732 (0.133464)\n",
      "Testing 3885/5184\n",
      "0.1 5 6 8 sqrt mae 1.0 50: Weighted 0.800602 (0.087215)\n",
      "0.1 5 6 8 sqrt mae 1.0 50: Macro 0.684470 (0.124119)\n",
      "Testing 3886/5184\n",
      "0.1 5 6 8 sqrt mae 1.0 100: Weighted 0.780155 (0.081670)\n",
      "0.1 5 6 8 sqrt mae 1.0 100: Macro 0.641559 (0.123427)\n",
      "Testing 3887/5184\n",
      "0.1 5 6 8 sqrt mae 1.0 200: Weighted 0.783732 (0.087920)\n",
      "0.1 5 6 8 sqrt mae 1.0 200: Macro 0.650132 (0.130420)\n",
      "Testing 3888/5184\n",
      "0.1 5 6 8 sqrt mae 1.0 500: Weighted 0.779260 (0.095345)\n",
      "0.1 5 6 8 sqrt mae 1.0 500: Macro 0.652108 (0.138545)\n",
      "Testing 3889/5184\n",
      "0.2 1 2 3 log2 friedman_mse 0.5 50: Weighted 0.810189 (0.060421)\n",
      "0.2 1 2 3 log2 friedman_mse 0.5 50: Macro 0.702321 (0.083241)\n",
      "Testing 3890/5184\n",
      "0.2 1 2 3 log2 friedman_mse 0.5 100: Weighted 0.811076 (0.073673)\n",
      "0.2 1 2 3 log2 friedman_mse 0.5 100: Macro 0.707662 (0.112396)\n",
      "Testing 3891/5184\n",
      "0.2 1 2 3 log2 friedman_mse 0.5 200: Weighted 0.818186 (0.058763)\n",
      "0.2 1 2 3 log2 friedman_mse 0.5 200: Macro 0.723766 (0.092421)\n",
      "Testing 3892/5184\n",
      "0.2 1 2 3 log2 friedman_mse 0.5 500: Weighted 0.799127 (0.069899)\n",
      "0.2 1 2 3 log2 friedman_mse 0.5 500: Macro 0.695413 (0.112079)\n",
      "Testing 3893/5184\n",
      "0.2 1 2 3 log2 friedman_mse 0.75 50: Weighted 0.798193 (0.060060)\n",
      "0.2 1 2 3 log2 friedman_mse 0.75 50: Macro 0.696640 (0.089369)\n",
      "Testing 3894/5184\n",
      "0.2 1 2 3 log2 friedman_mse 0.75 100: Weighted 0.813312 (0.056222)\n",
      "0.2 1 2 3 log2 friedman_mse 0.75 100: Macro 0.722560 (0.087025)\n",
      "Testing 3895/5184\n",
      "0.2 1 2 3 log2 friedman_mse 0.75 200: Weighted 0.791086 (0.078022)\n",
      "0.2 1 2 3 log2 friedman_mse 0.75 200: Macro 0.670864 (0.110252)\n",
      "Testing 3896/5184\n",
      "0.2 1 2 3 log2 friedman_mse 0.75 500: Weighted 0.810929 (0.070036)\n",
      "0.2 1 2 3 log2 friedman_mse 0.75 500: Macro 0.719054 (0.103301)\n",
      "Testing 3897/5184\n",
      "0.2 1 2 3 log2 friedman_mse 1.0 50: Weighted 0.792157 (0.044645)\n",
      "0.2 1 2 3 log2 friedman_mse 1.0 50: Macro 0.695289 (0.064140)\n",
      "Testing 3898/5184\n",
      "0.2 1 2 3 log2 friedman_mse 1.0 100: Weighted 0.795325 (0.062211)\n",
      "0.2 1 2 3 log2 friedman_mse 1.0 100: Macro 0.688440 (0.095369)\n",
      "Testing 3899/5184\n",
      "0.2 1 2 3 log2 friedman_mse 1.0 200: Weighted 0.801263 (0.054101)\n",
      "0.2 1 2 3 log2 friedman_mse 1.0 200: Macro 0.705343 (0.083812)\n",
      "Testing 3900/5184\n",
      "0.2 1 2 3 log2 friedman_mse 1.0 500: Weighted 0.789616 (0.067876)\n",
      "0.2 1 2 3 log2 friedman_mse 1.0 500: Macro 0.687081 (0.111706)\n",
      "Testing 3901/5184\n",
      "0.2 1 2 3 log2 mae 0.5 50: Weighted 0.782218 (0.040639)\n",
      "0.2 1 2 3 log2 mae 0.5 50: Macro 0.660970 (0.058942)\n",
      "Testing 3902/5184\n",
      "0.2 1 2 3 log2 mae 0.5 100: Weighted 0.777148 (0.052241)\n",
      "0.2 1 2 3 log2 mae 0.5 100: Macro 0.645073 (0.081515)\n",
      "Testing 3903/5184\n",
      "0.2 1 2 3 log2 mae 0.5 200: Weighted 0.625010 (0.267414)\n",
      "0.2 1 2 3 log2 mae 0.5 200: Macro 0.528875 (0.224117)\n",
      "Testing 3904/5184\n",
      "0.2 1 2 3 log2 mae 0.5 500: Weighted 0.793196 (0.078681)\n",
      "0.2 1 2 3 log2 mae 0.5 500: Macro 0.681183 (0.115983)\n",
      "Testing 3905/5184\n",
      "0.2 1 2 3 log2 mae 0.75 50: Weighted 0.766687 (0.055410)\n",
      "0.2 1 2 3 log2 mae 0.75 50: Macro 0.640638 (0.072390)\n",
      "Testing 3906/5184\n",
      "0.2 1 2 3 log2 mae 0.75 100: Weighted 0.771923 (0.071382)\n",
      "0.2 1 2 3 log2 mae 0.75 100: Macro 0.644818 (0.104917)\n",
      "Testing 3907/5184\n",
      "0.2 1 2 3 log2 mae 0.75 200: Weighted 0.757814 (0.058673)\n",
      "0.2 1 2 3 log2 mae 0.75 200: Macro 0.615290 (0.086536)\n",
      "Testing 3908/5184\n",
      "0.2 1 2 3 log2 mae 0.75 500: Weighted 0.776392 (0.082032)\n",
      "0.2 1 2 3 log2 mae 0.75 500: Macro 0.652474 (0.117955)\n",
      "Testing 3909/5184\n",
      "0.2 1 2 3 log2 mae 1.0 50: Weighted 0.747949 (0.053242)\n",
      "0.2 1 2 3 log2 mae 1.0 50: Macro 0.613567 (0.076769)\n",
      "Testing 3910/5184\n",
      "0.2 1 2 3 log2 mae 1.0 100: Weighted 0.744776 (0.063700)\n",
      "0.2 1 2 3 log2 mae 1.0 100: Macro 0.600744 (0.091909)\n",
      "Testing 3911/5184\n",
      "0.2 1 2 3 log2 mae 1.0 200: Weighted 0.760088 (0.061444)\n",
      "0.2 1 2 3 log2 mae 1.0 200: Macro 0.614642 (0.088781)\n",
      "Testing 3912/5184\n",
      "0.2 1 2 3 log2 mae 1.0 500: Weighted 0.765849 (0.063913)\n",
      "0.2 1 2 3 log2 mae 1.0 500: Macro 0.615539 (0.094838)\n",
      "Testing 3913/5184\n",
      "0.2 1 2 3 sqrt friedman_mse 0.5 50: Weighted 0.811492 (0.058264)\n",
      "0.2 1 2 3 sqrt friedman_mse 0.5 50: Macro 0.708946 (0.081036)\n",
      "Testing 3914/5184\n",
      "0.2 1 2 3 sqrt friedman_mse 0.5 100: Weighted 0.817135 (0.067805)\n",
      "0.2 1 2 3 sqrt friedman_mse 0.5 100: Macro 0.723519 (0.105545)\n",
      "Testing 3915/5184\n",
      "0.2 1 2 3 sqrt friedman_mse 0.5 200: Weighted 0.811623 (0.060940)\n",
      "0.2 1 2 3 sqrt friedman_mse 0.5 200: Macro 0.709558 (0.088174)\n",
      "Testing 3916/5184\n",
      "0.2 1 2 3 sqrt friedman_mse 0.5 500: Weighted 0.793334 (0.068750)\n",
      "0.2 1 2 3 sqrt friedman_mse 0.5 500: Macro 0.676044 (0.104970)\n",
      "Testing 3917/5184\n",
      "0.2 1 2 3 sqrt friedman_mse 0.75 50: Weighted 0.804069 (0.069052)\n",
      "0.2 1 2 3 sqrt friedman_mse 0.75 50: Macro 0.699742 (0.094757)\n",
      "Testing 3918/5184\n",
      "0.2 1 2 3 sqrt friedman_mse 0.75 100: Weighted 0.797431 (0.063477)\n",
      "0.2 1 2 3 sqrt friedman_mse 0.75 100: Macro 0.687446 (0.091599)\n",
      "Testing 3919/5184\n",
      "0.2 1 2 3 sqrt friedman_mse 0.75 200: Weighted 0.788042 (0.066996)\n",
      "0.2 1 2 3 sqrt friedman_mse 0.75 200: Macro 0.671124 (0.103878)\n",
      "Testing 3920/5184\n",
      "0.2 1 2 3 sqrt friedman_mse 0.75 500: Weighted 0.807129 (0.069645)\n",
      "0.2 1 2 3 sqrt friedman_mse 0.75 500: Macro 0.718457 (0.105017)\n",
      "Testing 3921/5184\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2 1 2 3 sqrt friedman_mse 1.0 50: Weighted 0.794512 (0.052702)\n",
      "0.2 1 2 3 sqrt friedman_mse 1.0 50: Macro 0.694044 (0.083990)\n",
      "Testing 3922/5184\n",
      "0.2 1 2 3 sqrt friedman_mse 1.0 100: Weighted 0.797915 (0.047482)\n",
      "0.2 1 2 3 sqrt friedman_mse 1.0 100: Macro 0.695530 (0.077182)\n",
      "Testing 3923/5184\n",
      "0.2 1 2 3 sqrt friedman_mse 1.0 200: Weighted 0.793903 (0.069714)\n",
      "0.2 1 2 3 sqrt friedman_mse 1.0 200: Macro 0.685111 (0.106651)\n",
      "Testing 3924/5184\n",
      "0.2 1 2 3 sqrt friedman_mse 1.0 500: Weighted 0.794004 (0.056991)\n",
      "0.2 1 2 3 sqrt friedman_mse 1.0 500: Macro 0.697823 (0.081190)\n",
      "Testing 3925/5184\n",
      "0.2 1 2 3 sqrt mae 0.5 50: Weighted 0.801423 (0.067308)\n",
      "0.2 1 2 3 sqrt mae 0.5 50: Macro 0.693370 (0.092399)\n",
      "Testing 3926/5184\n",
      "0.2 1 2 3 sqrt mae 0.5 100: Weighted 0.794575 (0.043246)\n",
      "0.2 1 2 3 sqrt mae 0.5 100: Macro 0.689347 (0.065476)\n",
      "Testing 3927/5184\n",
      "0.2 1 2 3 sqrt mae 0.5 200: Weighted 0.769897 (0.050463)\n",
      "0.2 1 2 3 sqrt mae 0.5 200: Macro 0.636711 (0.074188)\n",
      "Testing 3928/5184\n",
      "0.2 1 2 3 sqrt mae 0.5 500: Weighted 0.781853 (0.073060)\n",
      "0.2 1 2 3 sqrt mae 0.5 500: Macro 0.662268 (0.108430)\n",
      "Testing 3929/5184\n",
      "0.2 1 2 3 sqrt mae 0.75 50: Weighted 0.768872 (0.057280)\n",
      "0.2 1 2 3 sqrt mae 0.75 50: Macro 0.645118 (0.088922)\n",
      "Testing 3930/5184\n",
      "0.2 1 2 3 sqrt mae 0.75 100: Weighted 0.755961 (0.057122)\n",
      "0.2 1 2 3 sqrt mae 0.75 100: Macro 0.622608 (0.079759)\n",
      "Testing 3931/5184\n",
      "0.2 1 2 3 sqrt mae 0.75 200: Weighted 0.757995 (0.071924)\n",
      "0.2 1 2 3 sqrt mae 0.75 200: Macro 0.620380 (0.105111)\n",
      "Testing 3932/5184\n",
      "0.2 1 2 3 sqrt mae 0.75 500: Weighted 0.788114 (0.087571)\n",
      "0.2 1 2 3 sqrt mae 0.75 500: Macro 0.669493 (0.125044)\n",
      "Testing 3933/5184\n",
      "0.2 1 2 3 sqrt mae 1.0 50: Weighted 0.755376 (0.057620)\n",
      "0.2 1 2 3 sqrt mae 1.0 50: Macro 0.613492 (0.081881)\n",
      "Testing 3934/5184\n",
      "0.2 1 2 3 sqrt mae 1.0 100: Weighted 0.770463 (0.053613)\n",
      "0.2 1 2 3 sqrt mae 1.0 100: Macro 0.621416 (0.076674)\n",
      "Testing 3935/5184\n",
      "0.2 1 2 3 sqrt mae 1.0 200: Weighted 0.758774 (0.071545)\n",
      "0.2 1 2 3 sqrt mae 1.0 200: Macro 0.613889 (0.094159)\n",
      "Testing 3936/5184\n",
      "0.2 1 2 3 sqrt mae 1.0 500: Weighted 0.766332 (0.072797)\n",
      "0.2 1 2 3 sqrt mae 1.0 500: Macro 0.621140 (0.109673)\n",
      "Testing 3937/5184\n",
      "0.2 1 2 5 log2 friedman_mse 0.5 50: Weighted 0.808348 (0.070438)\n",
      "0.2 1 2 5 log2 friedman_mse 0.5 50: Macro 0.707157 (0.094494)\n",
      "Testing 3938/5184\n",
      "0.2 1 2 5 log2 friedman_mse 0.5 100: Weighted 0.806713 (0.089660)\n",
      "0.2 1 2 5 log2 friedman_mse 0.5 100: Macro 0.700348 (0.131643)\n",
      "Testing 3939/5184\n",
      "0.2 1 2 5 log2 friedman_mse 0.5 200: Weighted 0.826500 (0.081828)\n",
      "0.2 1 2 5 log2 friedman_mse 0.5 200: Macro 0.721644 (0.120611)\n",
      "Testing 3940/5184\n",
      "0.2 1 2 5 log2 friedman_mse 0.5 500: Weighted 0.810539 (0.067119)\n",
      "0.2 1 2 5 log2 friedman_mse 0.5 500: Macro 0.711745 (0.106873)\n",
      "Testing 3941/5184\n",
      "0.2 1 2 5 log2 friedman_mse 0.75 50: Weighted 0.829725 (0.081296)\n",
      "0.2 1 2 5 log2 friedman_mse 0.75 50: Macro 0.735148 (0.112498)\n",
      "Testing 3942/5184\n",
      "0.2 1 2 5 log2 friedman_mse 0.75 100: Weighted 0.803327 (0.073090)\n",
      "0.2 1 2 5 log2 friedman_mse 0.75 100: Macro 0.694022 (0.105826)\n",
      "Testing 3943/5184\n",
      "0.2 1 2 5 log2 friedman_mse 0.75 200: Weighted 0.803552 (0.073188)\n",
      "0.2 1 2 5 log2 friedman_mse 0.75 200: Macro 0.699702 (0.093661)\n",
      "Testing 3944/5184\n",
      "0.2 1 2 5 log2 friedman_mse 0.75 500: Weighted 0.835446 (0.083583)\n",
      "0.2 1 2 5 log2 friedman_mse 0.75 500: Macro 0.753640 (0.115820)\n",
      "Testing 3945/5184\n",
      "0.2 1 2 5 log2 friedman_mse 1.0 50: Weighted 0.794347 (0.065151)\n",
      "0.2 1 2 5 log2 friedman_mse 1.0 50: Macro 0.693628 (0.095314)\n",
      "Testing 3946/5184\n",
      "0.2 1 2 5 log2 friedman_mse 1.0 100: Weighted 0.792733 (0.072190)\n",
      "0.2 1 2 5 log2 friedman_mse 1.0 100: Macro 0.681996 (0.116010)\n",
      "Testing 3947/5184\n",
      "0.2 1 2 5 log2 friedman_mse 1.0 200: Weighted 0.790318 (0.069032)\n",
      "0.2 1 2 5 log2 friedman_mse 1.0 200: Macro 0.684596 (0.113564)\n",
      "Testing 3948/5184\n",
      "0.2 1 2 5 log2 friedman_mse 1.0 500: Weighted 0.803576 (0.071770)\n",
      "0.2 1 2 5 log2 friedman_mse 1.0 500: Macro 0.709689 (0.104994)\n",
      "Testing 3949/5184\n",
      "0.2 1 2 5 log2 mae 0.5 50: Weighted 0.769858 (0.051314)\n",
      "0.2 1 2 5 log2 mae 0.5 50: Macro 0.643556 (0.078335)\n",
      "Testing 3950/5184\n",
      "0.2 1 2 5 log2 mae 0.5 100: Weighted 0.781815 (0.075330)\n",
      "0.2 1 2 5 log2 mae 0.5 100: Macro 0.662901 (0.112794)\n",
      "Testing 3951/5184\n",
      "0.2 1 2 5 log2 mae 0.5 200: Weighted 0.789424 (0.062372)\n",
      "0.2 1 2 5 log2 mae 0.5 200: Macro 0.669865 (0.093946)\n",
      "Testing 3952/5184\n",
      "0.2 1 2 5 log2 mae 0.5 500: Weighted 0.786843 (0.072517)\n",
      "0.2 1 2 5 log2 mae 0.5 500: Macro 0.671919 (0.099946)\n",
      "Testing 3953/5184\n",
      "0.2 1 2 5 log2 mae 0.75 50: Weighted 0.783208 (0.086026)\n",
      "0.2 1 2 5 log2 mae 0.75 50: Macro 0.665194 (0.121636)\n",
      "Testing 3954/5184\n",
      "0.2 1 2 5 log2 mae 0.75 100: Weighted 0.777553 (0.080971)\n",
      "0.2 1 2 5 log2 mae 0.75 100: Macro 0.656600 (0.116018)\n",
      "Testing 3955/5184\n",
      "0.2 1 2 5 log2 mae 0.75 200: Weighted 0.792920 (0.073624)\n",
      "0.2 1 2 5 log2 mae 0.75 200: Macro 0.673470 (0.107077)\n",
      "Testing 3956/5184\n",
      "0.2 1 2 5 log2 mae 0.75 500: Weighted 0.763570 (0.073995)\n",
      "0.2 1 2 5 log2 mae 0.75 500: Macro 0.623115 (0.097707)\n",
      "Testing 3957/5184\n",
      "0.2 1 2 5 log2 mae 1.0 50: Weighted 0.774292 (0.076743)\n",
      "0.2 1 2 5 log2 mae 1.0 50: Macro 0.649988 (0.115122)\n",
      "Testing 3958/5184\n",
      "0.2 1 2 5 log2 mae 1.0 100: Weighted 0.784570 (0.073866)\n",
      "0.2 1 2 5 log2 mae 1.0 100: Macro 0.663681 (0.106467)\n",
      "Testing 3959/5184\n",
      "0.2 1 2 5 log2 mae 1.0 200: Weighted 0.778579 (0.077294)\n",
      "0.2 1 2 5 log2 mae 1.0 200: Macro 0.633230 (0.109451)\n",
      "Testing 3960/5184\n",
      "0.2 1 2 5 log2 mae 1.0 500: Weighted 0.795259 (0.081401)\n",
      "0.2 1 2 5 log2 mae 1.0 500: Macro 0.672838 (0.116631)\n",
      "Testing 3961/5184\n",
      "0.2 1 2 5 sqrt friedman_mse 0.5 50: Weighted 0.814658 (0.073012)\n",
      "0.2 1 2 5 sqrt friedman_mse 0.5 50: Macro 0.713803 (0.110720)\n",
      "Testing 3962/5184\n",
      "0.2 1 2 5 sqrt friedman_mse 0.5 100: Weighted 0.793411 (0.059948)\n",
      "0.2 1 2 5 sqrt friedman_mse 0.5 100: Macro 0.680885 (0.092550)\n",
      "Testing 3963/5184\n",
      "0.2 1 2 5 sqrt friedman_mse 0.5 200: Weighted 0.811454 (0.101267)\n",
      "0.2 1 2 5 sqrt friedman_mse 0.5 200: Macro 0.706044 (0.151004)\n",
      "Testing 3964/5184\n",
      "0.2 1 2 5 sqrt friedman_mse 0.5 500: Weighted 0.824418 (0.079560)\n",
      "0.2 1 2 5 sqrt friedman_mse 0.5 500: Macro 0.731357 (0.121201)\n",
      "Testing 3965/5184\n",
      "0.2 1 2 5 sqrt friedman_mse 0.75 50: Weighted 0.811524 (0.072202)\n",
      "0.2 1 2 5 sqrt friedman_mse 0.75 50: Macro 0.710928 (0.106828)\n",
      "Testing 3966/5184\n",
      "0.2 1 2 5 sqrt friedman_mse 0.75 100: Weighted 0.808435 (0.077050)\n",
      "0.2 1 2 5 sqrt friedman_mse 0.75 100: Macro 0.701122 (0.107307)\n",
      "Testing 3967/5184\n",
      "0.2 1 2 5 sqrt friedman_mse 0.75 200: Weighted 0.796921 (0.067334)\n",
      "0.2 1 2 5 sqrt friedman_mse 0.75 200: Macro 0.694855 (0.097414)\n",
      "Testing 3968/5184\n",
      "0.2 1 2 5 sqrt friedman_mse 0.75 500: Weighted 0.813511 (0.069814)\n",
      "0.2 1 2 5 sqrt friedman_mse 0.75 500: Macro 0.716945 (0.094500)\n",
      "Testing 3969/5184\n",
      "0.2 1 2 5 sqrt friedman_mse 1.0 50: Weighted 0.803903 (0.092086)\n",
      "0.2 1 2 5 sqrt friedman_mse 1.0 50: Macro 0.702457 (0.128012)\n",
      "Testing 3970/5184\n",
      "0.2 1 2 5 sqrt friedman_mse 1.0 100: Weighted 0.789097 (0.088114)\n",
      "0.2 1 2 5 sqrt friedman_mse 1.0 100: Macro 0.684484 (0.134029)\n",
      "Testing 3971/5184\n",
      "0.2 1 2 5 sqrt friedman_mse 1.0 200: Weighted 0.797530 (0.080600)\n",
      "0.2 1 2 5 sqrt friedman_mse 1.0 200: Macro 0.692892 (0.124932)\n",
      "Testing 3972/5184\n",
      "0.2 1 2 5 sqrt friedman_mse 1.0 500: Weighted 0.783804 (0.072821)\n",
      "0.2 1 2 5 sqrt friedman_mse 1.0 500: Macro 0.675552 (0.116497)\n",
      "Testing 3973/5184\n",
      "0.2 1 2 5 sqrt mae 0.5 50: Weighted 0.813350 (0.066172)\n",
      "0.2 1 2 5 sqrt mae 0.5 50: Macro 0.705139 (0.100398)\n",
      "Testing 3974/5184\n",
      "0.2 1 2 5 sqrt mae 0.5 100: Weighted 0.788931 (0.072537)\n",
      "0.2 1 2 5 sqrt mae 0.5 100: Macro 0.674449 (0.110996)\n",
      "Testing 3975/5184\n",
      "0.2 1 2 5 sqrt mae 0.5 200: Weighted 0.804719 (0.072186)\n",
      "0.2 1 2 5 sqrt mae 0.5 200: Macro 0.692456 (0.115472)\n",
      "Testing 3976/5184\n",
      "0.2 1 2 5 sqrt mae 0.5 500: Weighted 0.813195 (0.073153)\n",
      "0.2 1 2 5 sqrt mae 0.5 500: Macro 0.709087 (0.109733)\n",
      "Testing 3977/5184\n",
      "0.2 1 2 5 sqrt mae 0.75 50: Weighted 0.774517 (0.058111)\n",
      "0.2 1 2 5 sqrt mae 0.75 50: Macro 0.650864 (0.081401)\n",
      "Testing 3978/5184\n",
      "0.2 1 2 5 sqrt mae 0.75 100: Weighted 0.780389 (0.080368)\n",
      "0.2 1 2 5 sqrt mae 0.75 100: Macro 0.652601 (0.126124)\n",
      "Testing 3979/5184\n",
      "0.2 1 2 5 sqrt mae 0.75 200: Weighted 0.775070 (0.081809)\n",
      "0.2 1 2 5 sqrt mae 0.75 200: Macro 0.643832 (0.118989)\n",
      "Testing 3980/5184\n",
      "0.2 1 2 5 sqrt mae 0.75 500: Weighted 0.783844 (0.072476)\n",
      "0.2 1 2 5 sqrt mae 0.75 500: Macro 0.659361 (0.106572)\n",
      "Testing 3981/5184\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2 1 2 5 sqrt mae 1.0 50: Weighted 0.771653 (0.075895)\n",
      "0.2 1 2 5 sqrt mae 1.0 50: Macro 0.643046 (0.107042)\n",
      "Testing 3982/5184\n",
      "0.2 1 2 5 sqrt mae 1.0 100: Weighted 0.786068 (0.090181)\n",
      "0.2 1 2 5 sqrt mae 1.0 100: Macro 0.664593 (0.136248)\n",
      "Testing 3983/5184\n",
      "0.2 1 2 5 sqrt mae 1.0 200: Weighted 0.776365 (0.097936)\n",
      "0.2 1 2 5 sqrt mae 1.0 200: Macro 0.644341 (0.143893)\n",
      "Testing 3984/5184\n",
      "0.2 1 2 5 sqrt mae 1.0 500: Weighted 0.774925 (0.091717)\n",
      "0.2 1 2 5 sqrt mae 1.0 500: Macro 0.651268 (0.133862)\n",
      "Testing 3985/5184\n",
      "0.2 1 2 8 log2 friedman_mse 0.5 50: Weighted 0.818518 (0.069248)\n",
      "0.2 1 2 8 log2 friedman_mse 0.5 50: Macro 0.717191 (0.097000)\n",
      "Testing 3986/5184\n",
      "0.2 1 2 8 log2 friedman_mse 0.5 100: Weighted 0.815669 (0.070016)\n",
      "0.2 1 2 8 log2 friedman_mse 0.5 100: Macro 0.715834 (0.106757)\n",
      "Testing 3987/5184\n",
      "0.2 1 2 8 log2 friedman_mse 0.5 200: Weighted 0.804863 (0.062741)\n",
      "0.2 1 2 8 log2 friedman_mse 0.5 200: Macro 0.701259 (0.091384)\n",
      "Testing 3988/5184\n",
      "0.2 1 2 8 log2 friedman_mse 0.5 500: Weighted 0.820284 (0.072558)\n",
      "0.2 1 2 8 log2 friedman_mse 0.5 500: Macro 0.720531 (0.101595)\n",
      "Testing 3989/5184\n",
      "0.2 1 2 8 log2 friedman_mse 0.75 50: Weighted 0.791777 (0.077892)\n",
      "0.2 1 2 8 log2 friedman_mse 0.75 50: Macro 0.674057 (0.108004)\n",
      "Testing 3990/5184\n",
      "0.2 1 2 8 log2 friedman_mse 0.75 100: Weighted 0.806878 (0.089336)\n",
      "0.2 1 2 8 log2 friedman_mse 0.75 100: Macro 0.692711 (0.130940)\n",
      "Testing 3991/5184\n",
      "0.2 1 2 8 log2 friedman_mse 0.75 200: Weighted 0.796664 (0.074921)\n",
      "0.2 1 2 8 log2 friedman_mse 0.75 200: Macro 0.685821 (0.098594)\n",
      "Testing 3992/5184\n",
      "0.2 1 2 8 log2 friedman_mse 0.75 500: Weighted 0.810488 (0.072850)\n",
      "0.2 1 2 8 log2 friedman_mse 0.75 500: Macro 0.710751 (0.097248)\n",
      "Testing 3993/5184\n",
      "0.2 1 2 8 log2 friedman_mse 1.0 50: Weighted 0.795249 (0.061787)\n",
      "0.2 1 2 8 log2 friedman_mse 1.0 50: Macro 0.694064 (0.090605)\n",
      "Testing 3994/5184\n",
      "0.2 1 2 8 log2 friedman_mse 1.0 100: Weighted 0.796341 (0.072576)\n",
      "0.2 1 2 8 log2 friedman_mse 1.0 100: Macro 0.682936 (0.105559)\n",
      "Testing 3995/5184\n",
      "0.2 1 2 8 log2 friedman_mse 1.0 200: Weighted 0.785342 (0.061777)\n",
      "0.2 1 2 8 log2 friedman_mse 1.0 200: Macro 0.682214 (0.087981)\n",
      "Testing 3996/5184\n",
      "0.2 1 2 8 log2 friedman_mse 1.0 500: Weighted 0.797358 (0.061820)\n",
      "0.2 1 2 8 log2 friedman_mse 1.0 500: Macro 0.679984 (0.096580)\n",
      "Testing 3997/5184\n",
      "0.2 1 2 8 log2 mae 0.5 50: Weighted 0.797734 (0.065084)\n",
      "0.2 1 2 8 log2 mae 0.5 50: Macro 0.676134 (0.093897)\n",
      "Testing 3998/5184\n",
      "0.2 1 2 8 log2 mae 0.5 100: Weighted 0.793059 (0.050582)\n",
      "0.2 1 2 8 log2 mae 0.5 100: Macro 0.671031 (0.080347)\n",
      "Testing 3999/5184\n",
      "0.2 1 2 8 log2 mae 0.5 200: Weighted 0.804495 (0.054341)\n",
      "0.2 1 2 8 log2 mae 0.5 200: Macro 0.695694 (0.082009)\n",
      "Testing 4000/5184\n",
      "0.2 1 2 8 log2 mae 0.5 500: Weighted 0.802005 (0.083651)\n",
      "0.2 1 2 8 log2 mae 0.5 500: Macro 0.696063 (0.127234)\n",
      "Testing 4001/5184\n",
      "0.2 1 2 8 log2 mae 0.75 50: Weighted 0.784670 (0.056777)\n",
      "0.2 1 2 8 log2 mae 0.75 50: Macro 0.657542 (0.083715)\n",
      "Testing 4002/5184\n",
      "0.2 1 2 8 log2 mae 0.75 100: Weighted 0.765549 (0.056083)\n",
      "0.2 1 2 8 log2 mae 0.75 100: Macro 0.629452 (0.079907)\n",
      "Testing 4003/5184\n",
      "0.2 1 2 8 log2 mae 0.75 200: Weighted 0.788054 (0.080371)\n",
      "0.2 1 2 8 log2 mae 0.75 200: Macro 0.674647 (0.113471)\n",
      "Testing 4004/5184\n",
      "0.2 1 2 8 log2 mae 0.75 500: Weighted 0.779892 (0.073779)\n",
      "0.2 1 2 8 log2 mae 0.75 500: Macro 0.663048 (0.104129)\n",
      "Testing 4005/5184\n",
      "0.2 1 2 8 log2 mae 1.0 50: Weighted 0.778951 (0.060347)\n",
      "0.2 1 2 8 log2 mae 1.0 50: Macro 0.653860 (0.083077)\n",
      "Testing 4006/5184\n",
      "0.2 1 2 8 log2 mae 1.0 100: Weighted 0.788578 (0.086354)\n",
      "0.2 1 2 8 log2 mae 1.0 100: Macro 0.663000 (0.127014)\n",
      "Testing 4007/5184\n",
      "0.2 1 2 8 log2 mae 1.0 200: Weighted 0.778183 (0.080704)\n",
      "0.2 1 2 8 log2 mae 1.0 200: Macro 0.658088 (0.116482)\n",
      "Testing 4008/5184\n",
      "0.2 1 2 8 log2 mae 1.0 500: Weighted 0.790481 (0.086753)\n",
      "0.2 1 2 8 log2 mae 1.0 500: Macro 0.680917 (0.127322)\n",
      "Testing 4009/5184\n",
      "0.2 1 2 8 sqrt friedman_mse 0.5 50: Weighted 0.807166 (0.080450)\n",
      "0.2 1 2 8 sqrt friedman_mse 0.5 50: Macro 0.699210 (0.110860)\n",
      "Testing 4010/5184\n",
      "0.2 1 2 8 sqrt friedman_mse 0.5 100: Weighted 0.818684 (0.088669)\n",
      "0.2 1 2 8 sqrt friedman_mse 0.5 100: Macro 0.718542 (0.127407)\n",
      "Testing 4011/5184\n",
      "0.2 1 2 8 sqrt friedman_mse 0.5 200: Weighted 0.799241 (0.076008)\n",
      "0.2 1 2 8 sqrt friedman_mse 0.5 200: Macro 0.692744 (0.110195)\n",
      "Testing 4012/5184\n",
      "0.2 1 2 8 sqrt friedman_mse 0.5 500: Weighted 0.802206 (0.069133)\n",
      "0.2 1 2 8 sqrt friedman_mse 0.5 500: Macro 0.690270 (0.101161)\n",
      "Testing 4013/5184\n",
      "0.2 1 2 8 sqrt friedman_mse 0.75 50: Weighted 0.805663 (0.099085)\n",
      "0.2 1 2 8 sqrt friedman_mse 0.75 50: Macro 0.700451 (0.146135)\n",
      "Testing 4014/5184\n",
      "0.2 1 2 8 sqrt friedman_mse 0.75 100: Weighted 0.797235 (0.083264)\n",
      "0.2 1 2 8 sqrt friedman_mse 0.75 100: Macro 0.690819 (0.114647)\n",
      "Testing 4015/5184\n",
      "0.2 1 2 8 sqrt friedman_mse 0.75 200: Weighted 0.801190 (0.082362)\n",
      "0.2 1 2 8 sqrt friedman_mse 0.75 200: Macro 0.687877 (0.120545)\n",
      "Testing 4016/5184\n",
      "0.2 1 2 8 sqrt friedman_mse 0.75 500: Weighted 0.814603 (0.075894)\n",
      "0.2 1 2 8 sqrt friedman_mse 0.75 500: Macro 0.711813 (0.107286)\n",
      "Testing 4017/5184\n",
      "0.2 1 2 8 sqrt friedman_mse 1.0 50: Weighted 0.791204 (0.069854)\n",
      "0.2 1 2 8 sqrt friedman_mse 1.0 50: Macro 0.678487 (0.104546)\n",
      "Testing 4018/5184\n",
      "0.2 1 2 8 sqrt friedman_mse 1.0 100: Weighted 0.793470 (0.058726)\n",
      "0.2 1 2 8 sqrt friedman_mse 1.0 100: Macro 0.681943 (0.094797)\n",
      "Testing 4019/5184\n",
      "0.2 1 2 8 sqrt friedman_mse 1.0 200: Weighted 0.787848 (0.065726)\n",
      "0.2 1 2 8 sqrt friedman_mse 1.0 200: Macro 0.670550 (0.085866)\n",
      "Testing 4020/5184\n",
      "0.2 1 2 8 sqrt friedman_mse 1.0 500: Weighted 0.773909 (0.055824)\n",
      "0.2 1 2 8 sqrt friedman_mse 1.0 500: Macro 0.664055 (0.082843)\n",
      "Testing 4021/5184\n",
      "0.2 1 2 8 sqrt mae 0.5 50: Weighted 0.805196 (0.057001)\n",
      "0.2 1 2 8 sqrt mae 0.5 50: Macro 0.699065 (0.087484)\n",
      "Testing 4022/5184\n",
      "0.2 1 2 8 sqrt mae 0.5 100: Weighted 0.811302 (0.065476)\n",
      "0.2 1 2 8 sqrt mae 0.5 100: Macro 0.708617 (0.098845)\n",
      "Testing 4023/5184\n",
      "0.2 1 2 8 sqrt mae 0.5 200: Weighted 0.805032 (0.071746)\n",
      "0.2 1 2 8 sqrt mae 0.5 200: Macro 0.696095 (0.104949)\n",
      "Testing 4024/5184\n",
      "0.2 1 2 8 sqrt mae 0.5 500: Weighted 0.797590 (0.070655)\n",
      "0.2 1 2 8 sqrt mae 0.5 500: Macro 0.683081 (0.106555)\n",
      "Testing 4025/5184\n",
      "0.2 1 2 8 sqrt mae 0.75 50: Weighted 0.794795 (0.063216)\n",
      "0.2 1 2 8 sqrt mae 0.75 50: Macro 0.682615 (0.088891)\n",
      "Testing 4026/5184\n",
      "0.2 1 2 8 sqrt mae 0.75 100: Weighted 0.790706 (0.067982)\n",
      "0.2 1 2 8 sqrt mae 0.75 100: Macro 0.679580 (0.092556)\n",
      "Testing 4027/5184\n",
      "0.2 1 2 8 sqrt mae 0.75 200: Weighted 0.784774 (0.068703)\n",
      "0.2 1 2 8 sqrt mae 0.75 200: Macro 0.666038 (0.104672)\n",
      "Testing 4028/5184\n",
      "0.2 1 2 8 sqrt mae 0.75 500: Weighted 0.781485 (0.087692)\n",
      "0.2 1 2 8 sqrt mae 0.75 500: Macro 0.654750 (0.128827)\n",
      "Testing 4029/5184\n",
      "0.2 1 2 8 sqrt mae 1.0 50: Weighted 0.773367 (0.079127)\n",
      "0.2 1 2 8 sqrt mae 1.0 50: Macro 0.650926 (0.110131)\n",
      "Testing 4030/5184\n",
      "0.2 1 2 8 sqrt mae 1.0 100: Weighted 0.772531 (0.077922)\n",
      "0.2 1 2 8 sqrt mae 1.0 100: Macro 0.646273 (0.113231)\n",
      "Testing 4031/5184\n",
      "0.2 1 2 8 sqrt mae 1.0 200: Weighted 0.773075 (0.068684)\n",
      "0.2 1 2 8 sqrt mae 1.0 200: Macro 0.652235 (0.096171)\n",
      "Testing 4032/5184\n",
      "0.2 1 2 8 sqrt mae 1.0 500: Weighted 0.777555 (0.089509)\n",
      "0.2 1 2 8 sqrt mae 1.0 500: Macro 0.651249 (0.115499)\n",
      "Testing 4033/5184\n",
      "0.2 1 4 3 log2 friedman_mse 0.5 50: Weighted 0.792607 (0.047757)\n",
      "0.2 1 4 3 log2 friedman_mse 0.5 50: Macro 0.677188 (0.073014)\n",
      "Testing 4034/5184\n",
      "0.2 1 4 3 log2 friedman_mse 0.5 100: Weighted 0.803268 (0.052035)\n",
      "0.2 1 4 3 log2 friedman_mse 0.5 100: Macro 0.695557 (0.069578)\n",
      "Testing 4035/5184\n",
      "0.2 1 4 3 log2 friedman_mse 0.5 200: Weighted 0.814518 (0.052672)\n",
      "0.2 1 4 3 log2 friedman_mse 0.5 200: Macro 0.715750 (0.081757)\n",
      "Testing 4036/5184\n",
      "0.2 1 4 3 log2 friedman_mse 0.5 500: Weighted 0.794994 (0.055885)\n",
      "0.2 1 4 3 log2 friedman_mse 0.5 500: Macro 0.674636 (0.084388)\n",
      "Testing 4037/5184\n",
      "0.2 1 4 3 log2 friedman_mse 0.75 50: Weighted 0.801624 (0.064764)\n",
      "0.2 1 4 3 log2 friedman_mse 0.75 50: Macro 0.695409 (0.092923)\n",
      "Testing 4038/5184\n",
      "0.2 1 4 3 log2 friedman_mse 0.75 100: Weighted 0.804572 (0.063654)\n",
      "0.2 1 4 3 log2 friedman_mse 0.75 100: Macro 0.703439 (0.093732)\n",
      "Testing 4039/5184\n",
      "0.2 1 4 3 log2 friedman_mse 0.75 200: Weighted 0.797972 (0.068499)\n",
      "0.2 1 4 3 log2 friedman_mse 0.75 200: Macro 0.694715 (0.102659)\n",
      "Testing 4040/5184\n",
      "0.2 1 4 3 log2 friedman_mse 0.75 500: Weighted 0.793381 (0.061727)\n",
      "0.2 1 4 3 log2 friedman_mse 0.75 500: Macro 0.689308 (0.099037)\n",
      "Testing 4041/5184\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2 1 4 3 log2 friedman_mse 1.0 50: Weighted 0.802361 (0.046027)\n",
      "0.2 1 4 3 log2 friedman_mse 1.0 50: Macro 0.703416 (0.073941)\n",
      "Testing 4042/5184\n",
      "0.2 1 4 3 log2 friedman_mse 1.0 100: Weighted 0.811402 (0.062384)\n",
      "0.2 1 4 3 log2 friedman_mse 1.0 100: Macro 0.722024 (0.098130)\n",
      "Testing 4043/5184\n",
      "0.2 1 4 3 log2 friedman_mse 1.0 200: Weighted 0.790223 (0.065497)\n",
      "0.2 1 4 3 log2 friedman_mse 1.0 200: Macro 0.692158 (0.097081)\n",
      "Testing 4044/5184\n",
      "0.2 1 4 3 log2 friedman_mse 1.0 500: Weighted 0.791581 (0.065300)\n",
      "0.2 1 4 3 log2 friedman_mse 1.0 500: Macro 0.684846 (0.105658)\n",
      "Testing 4045/5184\n",
      "0.2 1 4 3 log2 mae 0.5 50: Weighted 0.797882 (0.037721)\n",
      "0.2 1 4 3 log2 mae 0.5 50: Macro 0.690581 (0.045031)\n",
      "Testing 4046/5184\n",
      "0.2 1 4 3 log2 mae 0.5 100: Weighted 0.770788 (0.059013)\n",
      "0.2 1 4 3 log2 mae 0.5 100: Macro 0.641741 (0.089106)\n",
      "Testing 4047/5184\n",
      "0.2 1 4 3 log2 mae 0.5 200: Weighted 0.776644 (0.073499)\n",
      "0.2 1 4 3 log2 mae 0.5 200: Macro 0.651686 (0.108082)\n",
      "Testing 4048/5184\n",
      "0.2 1 4 3 log2 mae 0.5 500: Weighted 0.782135 (0.091961)\n",
      "0.2 1 4 3 log2 mae 0.5 500: Macro 0.670562 (0.131054)\n",
      "Testing 4049/5184\n",
      "0.2 1 4 3 log2 mae 0.75 50: Weighted 0.752580 (0.049762)\n",
      "0.2 1 4 3 log2 mae 0.75 50: Macro 0.616326 (0.069873)\n",
      "Testing 4050/5184\n",
      "0.2 1 4 3 log2 mae 0.75 100: Weighted 0.756990 (0.065131)\n",
      "0.2 1 4 3 log2 mae 0.75 100: Macro 0.624501 (0.094380)\n",
      "Testing 4051/5184\n",
      "0.2 1 4 3 log2 mae 0.75 200: Weighted 0.773846 (0.077145)\n",
      "0.2 1 4 3 log2 mae 0.75 200: Macro 0.639937 (0.122216)\n",
      "Testing 4052/5184\n",
      "0.2 1 4 3 log2 mae 0.75 500: Weighted 0.767488 (0.064681)\n",
      "0.2 1 4 3 log2 mae 0.75 500: Macro 0.630082 (0.087545)\n",
      "Testing 4053/5184\n",
      "0.2 1 4 3 log2 mae 1.0 50: Weighted 0.751127 (0.058202)\n",
      "0.2 1 4 3 log2 mae 1.0 50: Macro 0.616542 (0.091561)\n",
      "Testing 4054/5184\n",
      "0.2 1 4 3 log2 mae 1.0 100: Weighted 0.733329 (0.053398)\n",
      "0.2 1 4 3 log2 mae 1.0 100: Macro 0.575023 (0.080422)\n",
      "Testing 4055/5184\n",
      "0.2 1 4 3 log2 mae 1.0 200: Weighted 0.778047 (0.081447)\n",
      "0.2 1 4 3 log2 mae 1.0 200: Macro 0.647574 (0.123557)\n",
      "Testing 4056/5184\n",
      "0.2 1 4 3 log2 mae 1.0 500: Weighted 0.780021 (0.076429)\n",
      "0.2 1 4 3 log2 mae 1.0 500: Macro 0.647125 (0.110952)\n",
      "Testing 4057/5184\n",
      "0.2 1 4 3 sqrt friedman_mse 0.5 50: Weighted 0.813292 (0.056196)\n",
      "0.2 1 4 3 sqrt friedman_mse 0.5 50: Macro 0.718399 (0.081350)\n",
      "Testing 4058/5184\n",
      "0.2 1 4 3 sqrt friedman_mse 0.5 100: Weighted 0.803513 (0.063364)\n",
      "0.2 1 4 3 sqrt friedman_mse 0.5 100: Macro 0.684543 (0.096269)\n",
      "Testing 4059/5184\n",
      "0.2 1 4 3 sqrt friedman_mse 0.5 200: Weighted 0.790021 (0.063465)\n",
      "0.2 1 4 3 sqrt friedman_mse 0.5 200: Macro 0.676667 (0.093485)\n",
      "Testing 4060/5184\n",
      "0.2 1 4 3 sqrt friedman_mse 0.5 500: Weighted 0.815937 (0.055517)\n",
      "0.2 1 4 3 sqrt friedman_mse 0.5 500: Macro 0.714938 (0.082678)\n",
      "Testing 4061/5184\n",
      "0.2 1 4 3 sqrt friedman_mse 0.75 50: Weighted 0.795914 (0.076234)\n",
      "0.2 1 4 3 sqrt friedman_mse 0.75 50: Macro 0.684848 (0.108234)\n",
      "Testing 4062/5184\n",
      "0.2 1 4 3 sqrt friedman_mse 0.75 100: Weighted 0.816110 (0.064270)\n",
      "0.2 1 4 3 sqrt friedman_mse 0.75 100: Macro 0.720892 (0.097349)\n",
      "Testing 4063/5184\n",
      "0.2 1 4 3 sqrt friedman_mse 0.75 200: Weighted 0.791923 (0.047422)\n",
      "0.2 1 4 3 sqrt friedman_mse 0.75 200: Macro 0.680023 (0.074177)\n",
      "Testing 4064/5184\n",
      "0.2 1 4 3 sqrt friedman_mse 0.75 500: Weighted 0.797712 (0.049695)\n",
      "0.2 1 4 3 sqrt friedman_mse 0.75 500: Macro 0.702616 (0.074685)\n",
      "Testing 4065/5184\n",
      "0.2 1 4 3 sqrt friedman_mse 1.0 50: Weighted 0.794512 (0.052702)\n",
      "0.2 1 4 3 sqrt friedman_mse 1.0 50: Macro 0.694044 (0.083990)\n",
      "Testing 4066/5184\n",
      "0.2 1 4 3 sqrt friedman_mse 1.0 100: Weighted 0.802797 (0.045293)\n",
      "0.2 1 4 3 sqrt friedman_mse 1.0 100: Macro 0.699880 (0.069177)\n",
      "Testing 4067/5184\n",
      "0.2 1 4 3 sqrt friedman_mse 1.0 200: Weighted 0.798486 (0.056428)\n",
      "0.2 1 4 3 sqrt friedman_mse 1.0 200: Macro 0.704494 (0.090395)\n",
      "Testing 4068/5184\n",
      "0.2 1 4 3 sqrt friedman_mse 1.0 500: Weighted 0.797473 (0.057613)\n",
      "0.2 1 4 3 sqrt friedman_mse 1.0 500: Macro 0.700088 (0.088463)\n",
      "Testing 4069/5184\n",
      "0.2 1 4 3 sqrt mae 0.5 50: Weighted 0.786231 (0.032574)\n",
      "0.2 1 4 3 sqrt mae 0.5 50: Macro 0.657920 (0.047325)\n",
      "Testing 4070/5184\n",
      "0.2 1 4 3 sqrt mae 0.5 100: Weighted 0.796228 (0.066472)\n",
      "0.2 1 4 3 sqrt mae 0.5 100: Macro 0.690312 (0.091950)\n",
      "Testing 4071/5184\n",
      "0.2 1 4 3 sqrt mae 0.5 200: Weighted 0.801528 (0.065117)\n",
      "0.2 1 4 3 sqrt mae 0.5 200: Macro 0.686091 (0.102613)\n",
      "Testing 4072/5184\n",
      "0.2 1 4 3 sqrt mae 0.5 500: Weighted 0.770793 (0.054260)\n",
      "0.2 1 4 3 sqrt mae 0.5 500: Macro 0.645245 (0.071445)\n",
      "Testing 4073/5184\n",
      "0.2 1 4 3 sqrt mae 0.75 50: Weighted 0.765658 (0.057141)\n",
      "0.2 1 4 3 sqrt mae 0.75 50: Macro 0.645470 (0.079578)\n",
      "Testing 4074/5184\n",
      "0.2 1 4 3 sqrt mae 0.75 100: Weighted 0.762665 (0.078189)\n",
      "0.2 1 4 3 sqrt mae 0.75 100: Macro 0.637729 (0.113716)\n",
      "Testing 4075/5184\n",
      "0.2 1 4 3 sqrt mae 0.75 200: Weighted 0.776352 (0.068255)\n",
      "0.2 1 4 3 sqrt mae 0.75 200: Macro 0.649268 (0.099116)\n",
      "Testing 4076/5184\n",
      "0.2 1 4 3 sqrt mae 0.75 500: Weighted 0.779671 (0.069650)\n",
      "0.2 1 4 3 sqrt mae 0.75 500: Macro 0.649064 (0.105856)\n",
      "Testing 4077/5184\n",
      "0.2 1 4 3 sqrt mae 1.0 50: Weighted 0.756960 (0.065578)\n",
      "0.2 1 4 3 sqrt mae 1.0 50: Macro 0.625399 (0.103073)\n",
      "Testing 4078/5184\n",
      "0.2 1 4 3 sqrt mae 1.0 100: Weighted 0.743284 (0.054321)\n",
      "0.2 1 4 3 sqrt mae 1.0 100: Macro 0.590136 (0.077212)\n",
      "Testing 4079/5184\n",
      "0.2 1 4 3 sqrt mae 1.0 200: Weighted 0.760727 (0.069618)\n",
      "0.2 1 4 3 sqrt mae 1.0 200: Macro 0.621240 (0.095949)\n",
      "Testing 4080/5184\n",
      "0.2 1 4 3 sqrt mae 1.0 500: Weighted 0.780218 (0.077240)\n",
      "0.2 1 4 3 sqrt mae 1.0 500: Macro 0.639761 (0.120024)\n",
      "Testing 4081/5184\n",
      "0.2 1 4 5 log2 friedman_mse 0.5 50: Weighted 0.791568 (0.054372)\n",
      "0.2 1 4 5 log2 friedman_mse 0.5 50: Macro 0.669219 (0.070904)\n",
      "Testing 4082/5184\n",
      "0.2 1 4 5 log2 friedman_mse 0.5 100: Weighted 0.814702 (0.070121)\n",
      "0.2 1 4 5 log2 friedman_mse 0.5 100: Macro 0.708426 (0.097466)\n",
      "Testing 4083/5184\n",
      "0.2 1 4 5 log2 friedman_mse 0.5 200: Weighted 0.816672 (0.077677)\n",
      "0.2 1 4 5 log2 friedman_mse 0.5 200: Macro 0.718959 (0.117182)\n",
      "Testing 4084/5184\n",
      "0.2 1 4 5 log2 friedman_mse 0.5 500: Weighted 0.806329 (0.060191)\n",
      "0.2 1 4 5 log2 friedman_mse 0.5 500: Macro 0.702934 (0.094306)\n",
      "Testing 4085/5184\n",
      "0.2 1 4 5 log2 friedman_mse 0.75 50: Weighted 0.811564 (0.078135)\n",
      "0.2 1 4 5 log2 friedman_mse 0.75 50: Macro 0.719632 (0.110650)\n",
      "Testing 4086/5184\n",
      "0.2 1 4 5 log2 friedman_mse 0.75 100: Weighted 0.789751 (0.085952)\n",
      "0.2 1 4 5 log2 friedman_mse 0.75 100: Macro 0.684649 (0.132071)\n",
      "Testing 4087/5184\n",
      "0.2 1 4 5 log2 friedman_mse 0.75 200: Weighted 0.797123 (0.069843)\n",
      "0.2 1 4 5 log2 friedman_mse 0.75 200: Macro 0.684517 (0.095318)\n",
      "Testing 4088/5184\n",
      "0.2 1 4 5 log2 friedman_mse 0.75 500: Weighted 0.812965 (0.076492)\n",
      "0.2 1 4 5 log2 friedman_mse 0.75 500: Macro 0.713522 (0.104545)\n",
      "Testing 4089/5184\n",
      "0.2 1 4 5 log2 friedman_mse 1.0 50: Weighted 0.794028 (0.073371)\n",
      "0.2 1 4 5 log2 friedman_mse 1.0 50: Macro 0.691409 (0.109004)\n",
      "Testing 4090/5184\n",
      "0.2 1 4 5 log2 friedman_mse 1.0 100: Weighted 0.799041 (0.068114)\n",
      "0.2 1 4 5 log2 friedman_mse 1.0 100: Macro 0.695653 (0.103097)\n",
      "Testing 4091/5184\n",
      "0.2 1 4 5 log2 friedman_mse 1.0 200: Weighted 0.797545 (0.078535)\n",
      "0.2 1 4 5 log2 friedman_mse 1.0 200: Macro 0.692340 (0.123105)\n",
      "Testing 4092/5184\n",
      "0.2 1 4 5 log2 friedman_mse 1.0 500: Weighted 0.797136 (0.083062)\n",
      "0.2 1 4 5 log2 friedman_mse 1.0 500: Macro 0.688516 (0.123452)\n",
      "Testing 4093/5184\n",
      "0.2 1 4 5 log2 mae 0.5 50: Weighted 0.789510 (0.058230)\n",
      "0.2 1 4 5 log2 mae 0.5 50: Macro 0.673785 (0.085574)\n",
      "Testing 4094/5184\n",
      "0.2 1 4 5 log2 mae 0.5 100: Weighted 0.780472 (0.057388)\n",
      "0.2 1 4 5 log2 mae 0.5 100: Macro 0.662331 (0.078564)\n",
      "Testing 4095/5184\n",
      "0.2 1 4 5 log2 mae 0.5 200: Weighted 0.799117 (0.073128)\n",
      "0.2 1 4 5 log2 mae 0.5 200: Macro 0.687564 (0.114926)\n",
      "Testing 4096/5184\n",
      "0.2 1 4 5 log2 mae 0.5 500: Weighted 0.763130 (0.060065)\n",
      "0.2 1 4 5 log2 mae 0.5 500: Macro 0.627583 (0.082538)\n",
      "Testing 4097/5184\n",
      "0.2 1 4 5 log2 mae 0.75 50: Weighted 0.781876 (0.061172)\n",
      "0.2 1 4 5 log2 mae 0.75 50: Macro 0.665540 (0.087743)\n",
      "Testing 4098/5184\n",
      "0.2 1 4 5 log2 mae 0.75 100: Weighted 0.767432 (0.063994)\n",
      "0.2 1 4 5 log2 mae 0.75 100: Macro 0.634288 (0.096533)\n",
      "Testing 4099/5184\n",
      "0.2 1 4 5 log2 mae 0.75 200: Weighted 0.781518 (0.067961)\n",
      "0.2 1 4 5 log2 mae 0.75 200: Macro 0.653620 (0.098311)\n",
      "Testing 4100/5184\n",
      "0.2 1 4 5 log2 mae 0.75 500: Weighted 0.799817 (0.077642)\n",
      "0.2 1 4 5 log2 mae 0.75 500: Macro 0.687247 (0.121814)\n",
      "Testing 4101/5184\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2 1 4 5 log2 mae 1.0 50: Weighted 0.763824 (0.064311)\n",
      "0.2 1 4 5 log2 mae 1.0 50: Macro 0.619207 (0.100439)\n",
      "Testing 4102/5184\n",
      "0.2 1 4 5 log2 mae 1.0 100: Weighted 0.783167 (0.075868)\n",
      "0.2 1 4 5 log2 mae 1.0 100: Macro 0.658498 (0.103055)\n",
      "Testing 4103/5184\n",
      "0.2 1 4 5 log2 mae 1.0 200: Weighted 0.777328 (0.089907)\n",
      "0.2 1 4 5 log2 mae 1.0 200: Macro 0.652938 (0.127755)\n",
      "Testing 4104/5184\n",
      "0.2 1 4 5 log2 mae 1.0 500: Weighted 0.777603 (0.071238)\n",
      "0.2 1 4 5 log2 mae 1.0 500: Macro 0.638310 (0.096316)\n",
      "Testing 4105/5184\n",
      "0.2 1 4 5 sqrt friedman_mse 0.5 50: Weighted 0.807039 (0.071226)\n",
      "0.2 1 4 5 sqrt friedman_mse 0.5 50: Macro 0.705530 (0.102398)\n",
      "Testing 4106/5184\n",
      "0.2 1 4 5 sqrt friedman_mse 0.5 100: Weighted 0.820869 (0.076133)\n",
      "0.2 1 4 5 sqrt friedman_mse 0.5 100: Macro 0.727298 (0.107820)\n",
      "Testing 4107/5184\n",
      "0.2 1 4 5 sqrt friedman_mse 0.5 200: Weighted 0.807632 (0.061114)\n",
      "0.2 1 4 5 sqrt friedman_mse 0.5 200: Macro 0.700033 (0.092055)\n",
      "Testing 4108/5184\n",
      "0.2 1 4 5 sqrt friedman_mse 0.5 500: Weighted 0.821148 (0.074968)\n",
      "0.2 1 4 5 sqrt friedman_mse 0.5 500: Macro 0.720873 (0.117124)\n",
      "Testing 4109/5184\n",
      "0.2 1 4 5 sqrt friedman_mse 0.75 50: Weighted 0.807093 (0.076283)\n",
      "0.2 1 4 5 sqrt friedman_mse 0.75 50: Macro 0.698049 (0.107919)\n",
      "Testing 4110/5184\n",
      "0.2 1 4 5 sqrt friedman_mse 0.75 100: Weighted 0.806559 (0.068305)\n",
      "0.2 1 4 5 sqrt friedman_mse 0.75 100: Macro 0.704250 (0.102002)\n",
      "Testing 4111/5184\n",
      "0.2 1 4 5 sqrt friedman_mse 0.75 200: Weighted 0.798835 (0.067930)\n",
      "0.2 1 4 5 sqrt friedman_mse 0.75 200: Macro 0.693236 (0.101042)\n",
      "Testing 4112/5184\n",
      "0.2 1 4 5 sqrt friedman_mse 0.75 500: Weighted 0.797580 (0.072275)\n",
      "0.2 1 4 5 sqrt friedman_mse 0.75 500: Macro 0.698676 (0.108431)\n",
      "Testing 4113/5184\n",
      "0.2 1 4 5 sqrt friedman_mse 1.0 50: Weighted 0.793656 (0.085190)\n",
      "0.2 1 4 5 sqrt friedman_mse 1.0 50: Macro 0.683754 (0.126571)\n",
      "Testing 4114/5184\n",
      "0.2 1 4 5 sqrt friedman_mse 1.0 100: Weighted 0.794600 (0.080665)\n",
      "0.2 1 4 5 sqrt friedman_mse 1.0 100: Macro 0.696228 (0.118109)\n",
      "Testing 4115/5184\n",
      "0.2 1 4 5 sqrt friedman_mse 1.0 200: Weighted 0.810750 (0.075358)\n",
      "0.2 1 4 5 sqrt friedman_mse 1.0 200: Macro 0.712699 (0.109850)\n",
      "Testing 4116/5184\n",
      "0.2 1 4 5 sqrt friedman_mse 1.0 500: Weighted 0.798503 (0.077407)\n",
      "0.2 1 4 5 sqrt friedman_mse 1.0 500: Macro 0.691448 (0.124162)\n",
      "Testing 4117/5184\n",
      "0.2 1 4 5 sqrt mae 0.5 50: Weighted 0.799444 (0.096180)\n",
      "0.2 1 4 5 sqrt mae 0.5 50: Macro 0.688765 (0.133029)\n",
      "Testing 4118/5184\n",
      "0.2 1 4 5 sqrt mae 0.5 100: Weighted 0.808737 (0.068282)\n",
      "0.2 1 4 5 sqrt mae 0.5 100: Macro 0.702898 (0.105129)\n",
      "Testing 4119/5184\n",
      "0.2 1 4 5 sqrt mae 0.5 200: Weighted 0.807320 (0.078816)\n",
      "0.2 1 4 5 sqrt mae 0.5 200: Macro 0.698633 (0.120914)\n",
      "Testing 4120/5184\n",
      "0.2 1 4 5 sqrt mae 0.5 500: Weighted 0.799221 (0.072918)\n",
      "0.2 1 4 5 sqrt mae 0.5 500: Macro 0.691277 (0.106451)\n",
      "Testing 4121/5184\n",
      "0.2 1 4 5 sqrt mae 0.75 50: Weighted 0.778194 (0.072405)\n",
      "0.2 1 4 5 sqrt mae 0.75 50: Macro 0.649756 (0.114159)\n",
      "Testing 4122/5184\n",
      "0.2 1 4 5 sqrt mae 0.75 100: Weighted 0.777844 (0.079348)\n",
      "0.2 1 4 5 sqrt mae 0.75 100: Macro 0.645658 (0.116333)\n",
      "Testing 4123/5184\n",
      "0.2 1 4 5 sqrt mae 0.75 200: Weighted 0.793624 (0.073570)\n",
      "0.2 1 4 5 sqrt mae 0.75 200: Macro 0.678656 (0.108375)\n",
      "Testing 4124/5184\n",
      "0.2 1 4 5 sqrt mae 0.75 500: Weighted 0.797703 (0.088310)\n",
      "0.2 1 4 5 sqrt mae 0.75 500: Macro 0.682095 (0.136417)\n",
      "Testing 4125/5184\n",
      "0.2 1 4 5 sqrt mae 1.0 50: Weighted 0.756100 (0.057261)\n",
      "0.2 1 4 5 sqrt mae 1.0 50: Macro 0.614078 (0.081978)\n",
      "Testing 4126/5184\n",
      "0.2 1 4 5 sqrt mae 1.0 100: Weighted 0.781344 (0.056899)\n",
      "0.2 1 4 5 sqrt mae 1.0 100: Macro 0.651521 (0.063756)\n",
      "Testing 4127/5184\n",
      "0.2 1 4 5 sqrt mae 1.0 200: Weighted 0.762340 (0.077131)\n",
      "0.2 1 4 5 sqrt mae 1.0 200: Macro 0.628690 (0.106951)\n",
      "Testing 4128/5184\n",
      "0.2 1 4 5 sqrt mae 1.0 500: Weighted 0.778883 (0.069471)\n",
      "0.2 1 4 5 sqrt mae 1.0 500: Macro 0.636645 (0.102936)\n",
      "Testing 4129/5184\n",
      "0.2 1 4 8 log2 friedman_mse 0.5 50: Weighted 0.824280 (0.077079)\n",
      "0.2 1 4 8 log2 friedman_mse 0.5 50: Macro 0.721504 (0.114498)\n",
      "Testing 4130/5184\n",
      "0.2 1 4 8 log2 friedman_mse 0.5 100: Weighted 0.815669 (0.070016)\n",
      "0.2 1 4 8 log2 friedman_mse 0.5 100: Macro 0.715834 (0.106757)\n",
      "Testing 4131/5184\n",
      "0.2 1 4 8 log2 friedman_mse 0.5 200: Weighted 0.804844 (0.044683)\n",
      "0.2 1 4 8 log2 friedman_mse 0.5 200: Macro 0.706727 (0.066031)\n",
      "Testing 4132/5184\n",
      "0.2 1 4 8 log2 friedman_mse 0.5 500: Weighted 0.811372 (0.072092)\n",
      "0.2 1 4 8 log2 friedman_mse 0.5 500: Macro 0.702309 (0.104852)\n",
      "Testing 4133/5184\n",
      "0.2 1 4 8 log2 friedman_mse 0.75 50: Weighted 0.805967 (0.081454)\n",
      "0.2 1 4 8 log2 friedman_mse 0.75 50: Macro 0.710662 (0.120875)\n",
      "Testing 4134/5184\n",
      "0.2 1 4 8 log2 friedman_mse 0.75 100: Weighted 0.815968 (0.074187)\n",
      "0.2 1 4 8 log2 friedman_mse 0.75 100: Macro 0.715135 (0.113226)\n",
      "Testing 4135/5184\n",
      "0.2 1 4 8 log2 friedman_mse 0.75 200: Weighted 0.808056 (0.071312)\n",
      "0.2 1 4 8 log2 friedman_mse 0.75 200: Macro 0.702107 (0.117822)\n",
      "Testing 4136/5184\n",
      "0.2 1 4 8 log2 friedman_mse 0.75 500: Weighted 0.810540 (0.077923)\n",
      "0.2 1 4 8 log2 friedman_mse 0.75 500: Macro 0.716545 (0.122030)\n",
      "Testing 4137/5184\n",
      "0.2 1 4 8 log2 friedman_mse 1.0 50: Weighted 0.815008 (0.071918)\n",
      "0.2 1 4 8 log2 friedman_mse 1.0 50: Macro 0.715074 (0.106672)\n",
      "Testing 4138/5184\n",
      "0.2 1 4 8 log2 friedman_mse 1.0 100: Weighted 0.798443 (0.060555)\n",
      "0.2 1 4 8 log2 friedman_mse 1.0 100: Macro 0.692565 (0.079965)\n",
      "Testing 4139/5184\n",
      "0.2 1 4 8 log2 friedman_mse 1.0 200: Weighted 0.786162 (0.061549)\n",
      "0.2 1 4 8 log2 friedman_mse 1.0 200: Macro 0.685830 (0.089465)\n",
      "Testing 4140/5184\n",
      "0.2 1 4 8 log2 friedman_mse 1.0 500: Weighted 0.797208 (0.062322)\n",
      "0.2 1 4 8 log2 friedman_mse 1.0 500: Macro 0.697302 (0.086709)\n",
      "Testing 4141/5184\n",
      "0.2 1 4 8 log2 mae 0.5 50: Weighted 0.769388 (0.044714)\n",
      "0.2 1 4 8 log2 mae 0.5 50: Macro 0.629253 (0.069744)\n",
      "Testing 4142/5184\n",
      "0.2 1 4 8 log2 mae 0.5 100: Weighted 0.793329 (0.057366)\n",
      "0.2 1 4 8 log2 mae 0.5 100: Macro 0.675888 (0.089548)\n",
      "Testing 4143/5184\n",
      "0.2 1 4 8 log2 mae 0.5 200: Weighted 0.785007 (0.055591)\n",
      "0.2 1 4 8 log2 mae 0.5 200: Macro 0.661302 (0.083962)\n",
      "Testing 4144/5184\n",
      "0.2 1 4 8 log2 mae 0.5 500: Weighted 0.806161 (0.079884)\n",
      "0.2 1 4 8 log2 mae 0.5 500: Macro 0.703250 (0.121046)\n",
      "Testing 4145/5184\n",
      "0.2 1 4 8 log2 mae 0.75 50: Weighted 0.786360 (0.072596)\n",
      "0.2 1 4 8 log2 mae 0.75 50: Macro 0.674187 (0.098466)\n",
      "Testing 4146/5184\n",
      "0.2 1 4 8 log2 mae 0.75 100: Weighted 0.805960 (0.080153)\n",
      "0.2 1 4 8 log2 mae 0.75 100: Macro 0.699820 (0.118865)\n",
      "Testing 4147/5184\n",
      "0.2 1 4 8 log2 mae 0.75 200: Weighted 0.758738 (0.073726)\n",
      "0.2 1 4 8 log2 mae 0.75 200: Macro 0.625901 (0.106016)\n",
      "Testing 4148/5184\n",
      "0.2 1 4 8 log2 mae 0.75 500: Weighted 0.791395 (0.062276)\n",
      "0.2 1 4 8 log2 mae 0.75 500: Macro 0.676676 (0.086193)\n",
      "Testing 4149/5184\n",
      "0.2 1 4 8 log2 mae 1.0 50: Weighted 0.786142 (0.082028)\n",
      "0.2 1 4 8 log2 mae 1.0 50: Macro 0.680116 (0.111943)\n",
      "Testing 4150/5184\n",
      "0.2 1 4 8 log2 mae 1.0 100: Weighted 0.785086 (0.064395)\n",
      "0.2 1 4 8 log2 mae 1.0 100: Macro 0.663988 (0.082313)\n",
      "Testing 4151/5184\n",
      "0.2 1 4 8 log2 mae 1.0 200: Weighted 0.771372 (0.051531)\n",
      "0.2 1 4 8 log2 mae 1.0 200: Macro 0.639969 (0.073929)\n",
      "Testing 4152/5184\n",
      "0.2 1 4 8 log2 mae 1.0 500: Weighted 0.771838 (0.087285)\n",
      "0.2 1 4 8 log2 mae 1.0 500: Macro 0.640817 (0.117249)\n",
      "Testing 4153/5184\n",
      "0.2 1 4 8 sqrt friedman_mse 0.5 50: Weighted 0.810265 (0.078463)\n",
      "0.2 1 4 8 sqrt friedman_mse 0.5 50: Macro 0.709787 (0.117190)\n",
      "Testing 4154/5184\n",
      "0.2 1 4 8 sqrt friedman_mse 0.5 100: Weighted 0.802541 (0.069024)\n",
      "0.2 1 4 8 sqrt friedman_mse 0.5 100: Macro 0.694422 (0.101831)\n",
      "Testing 4155/5184\n",
      "0.2 1 4 8 sqrt friedman_mse 0.5 200: Weighted 0.796419 (0.064585)\n",
      "0.2 1 4 8 sqrt friedman_mse 0.5 200: Macro 0.675821 (0.094523)\n",
      "Testing 4156/5184\n",
      "0.2 1 4 8 sqrt friedman_mse 0.5 500: Weighted 0.813604 (0.070359)\n",
      "0.2 1 4 8 sqrt friedman_mse 0.5 500: Macro 0.714371 (0.104326)\n",
      "Testing 4157/5184\n",
      "0.2 1 4 8 sqrt friedman_mse 0.75 50: Weighted 0.807456 (0.090773)\n",
      "0.2 1 4 8 sqrt friedman_mse 0.75 50: Macro 0.706501 (0.138772)\n",
      "Testing 4158/5184\n",
      "0.2 1 4 8 sqrt friedman_mse 0.75 100: Weighted 0.811216 (0.074550)\n",
      "0.2 1 4 8 sqrt friedman_mse 0.75 100: Macro 0.712470 (0.110456)\n",
      "Testing 4159/5184\n",
      "0.2 1 4 8 sqrt friedman_mse 0.75 200: Weighted 0.799966 (0.069561)\n",
      "0.2 1 4 8 sqrt friedman_mse 0.75 200: Macro 0.695306 (0.099500)\n",
      "Testing 4160/5184\n",
      "0.2 1 4 8 sqrt friedman_mse 0.75 500: Weighted 0.834272 (0.090971)\n",
      "0.2 1 4 8 sqrt friedman_mse 0.75 500: Macro 0.750834 (0.130596)\n",
      "Testing 4161/5184\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2 1 4 8 sqrt friedman_mse 1.0 50: Weighted 0.806528 (0.080356)\n",
      "0.2 1 4 8 sqrt friedman_mse 1.0 50: Macro 0.699855 (0.124835)\n",
      "Testing 4162/5184\n",
      "0.2 1 4 8 sqrt friedman_mse 1.0 100: Weighted 0.787780 (0.081105)\n",
      "0.2 1 4 8 sqrt friedman_mse 1.0 100: Macro 0.687004 (0.113340)\n",
      "Testing 4163/5184\n",
      "0.2 1 4 8 sqrt friedman_mse 1.0 200: Weighted 0.800194 (0.068349)\n",
      "0.2 1 4 8 sqrt friedman_mse 1.0 200: Macro 0.701949 (0.098511)\n",
      "Testing 4164/5184\n",
      "0.2 1 4 8 sqrt friedman_mse 1.0 500: Weighted 0.794313 (0.065078)\n",
      "0.2 1 4 8 sqrt friedman_mse 1.0 500: Macro 0.692059 (0.092413)\n",
      "Testing 4165/5184\n",
      "0.2 1 4 8 sqrt mae 0.5 50: Weighted 0.780783 (0.040644)\n",
      "0.2 1 4 8 sqrt mae 0.5 50: Macro 0.649956 (0.063767)\n",
      "Testing 4166/5184\n",
      "0.2 1 4 8 sqrt mae 0.5 100: Weighted 0.799748 (0.067571)\n",
      "0.2 1 4 8 sqrt mae 0.5 100: Macro 0.688813 (0.096621)\n",
      "Testing 4167/5184\n",
      "0.2 1 4 8 sqrt mae 0.5 200: Weighted 0.805771 (0.071647)\n",
      "0.2 1 4 8 sqrt mae 0.5 200: Macro 0.699798 (0.100790)\n",
      "Testing 4168/5184\n",
      "0.2 1 4 8 sqrt mae 0.5 500: Weighted 0.804035 (0.081751)\n",
      "0.2 1 4 8 sqrt mae 0.5 500: Macro 0.701648 (0.119667)\n",
      "Testing 4169/5184\n",
      "0.2 1 4 8 sqrt mae 0.75 50: Weighted 0.789252 (0.072011)\n",
      "0.2 1 4 8 sqrt mae 0.75 50: Macro 0.681920 (0.099159)\n",
      "Testing 4170/5184\n",
      "0.2 1 4 8 sqrt mae 0.75 100: Weighted 0.776294 (0.057001)\n",
      "0.2 1 4 8 sqrt mae 0.75 100: Macro 0.651582 (0.083121)\n",
      "Testing 4171/5184\n",
      "0.2 1 4 8 sqrt mae 0.75 200: Weighted 0.804735 (0.085943)\n",
      "0.2 1 4 8 sqrt mae 0.75 200: Macro 0.693019 (0.140562)\n",
      "Testing 4172/5184\n",
      "0.2 1 4 8 sqrt mae 0.75 500: Weighted 0.788749 (0.068041)\n",
      "0.2 1 4 8 sqrt mae 0.75 500: Macro 0.668313 (0.102023)\n",
      "Testing 4173/5184\n",
      "0.2 1 4 8 sqrt mae 1.0 50: Weighted 0.768509 (0.078902)\n",
      "0.2 1 4 8 sqrt mae 1.0 50: Macro 0.650046 (0.112983)\n",
      "Testing 4174/5184\n",
      "0.2 1 4 8 sqrt mae 1.0 100: Weighted 0.783266 (0.068762)\n",
      "0.2 1 4 8 sqrt mae 1.0 100: Macro 0.662048 (0.097095)\n",
      "Testing 4175/5184\n",
      "0.2 1 4 8 sqrt mae 1.0 200: Weighted 0.768807 (0.062456)\n",
      "0.2 1 4 8 sqrt mae 1.0 200: Macro 0.642834 (0.087645)\n",
      "Testing 4176/5184\n",
      "0.2 1 4 8 sqrt mae 1.0 500: Weighted 0.783331 (0.079812)\n",
      "0.2 1 4 8 sqrt mae 1.0 500: Macro 0.659889 (0.121647)\n",
      "Testing 4177/5184\n",
      "0.2 1 6 3 log2 friedman_mse 0.5 50: Weighted 0.798981 (0.060884)\n",
      "0.2 1 6 3 log2 friedman_mse 0.5 50: Macro 0.692142 (0.083573)\n",
      "Testing 4178/5184\n",
      "0.2 1 6 3 log2 friedman_mse 0.5 100: Weighted 0.793723 (0.040780)\n",
      "0.2 1 6 3 log2 friedman_mse 0.5 100: Macro 0.684560 (0.046511)\n",
      "Testing 4179/5184\n",
      "0.2 1 6 3 log2 friedman_mse 0.5 200: Weighted 0.816785 (0.070882)\n",
      "0.2 1 6 3 log2 friedman_mse 0.5 200: Macro 0.715215 (0.107077)\n",
      "Testing 4180/5184\n",
      "0.2 1 6 3 log2 friedman_mse 0.5 500: Weighted 0.815773 (0.061240)\n",
      "0.2 1 6 3 log2 friedman_mse 0.5 500: Macro 0.717509 (0.104223)\n",
      "Testing 4181/5184\n",
      "0.2 1 6 3 log2 friedman_mse 0.75 50: Weighted 0.808244 (0.064926)\n",
      "0.2 1 6 3 log2 friedman_mse 0.75 50: Macro 0.711573 (0.093785)\n",
      "Testing 4182/5184\n",
      "0.2 1 6 3 log2 friedman_mse 0.75 100: Weighted 0.802740 (0.052183)\n",
      "0.2 1 6 3 log2 friedman_mse 0.75 100: Macro 0.703443 (0.078822)\n",
      "Testing 4183/5184\n",
      "0.2 1 6 3 log2 friedman_mse 0.75 200: Weighted 0.788535 (0.071534)\n",
      "0.2 1 6 3 log2 friedman_mse 0.75 200: Macro 0.682664 (0.103607)\n",
      "Testing 4184/5184\n",
      "0.2 1 6 3 log2 friedman_mse 0.75 500: Weighted 0.806129 (0.051167)\n",
      "0.2 1 6 3 log2 friedman_mse 0.75 500: Macro 0.705931 (0.077160)\n",
      "Testing 4185/5184\n",
      "0.2 1 6 3 log2 friedman_mse 1.0 50: Weighted 0.793651 (0.036242)\n",
      "0.2 1 6 3 log2 friedman_mse 1.0 50: Macro 0.687201 (0.063115)\n",
      "Testing 4186/5184\n",
      "0.2 1 6 3 log2 friedman_mse 1.0 100: Weighted 0.791950 (0.055858)\n",
      "0.2 1 6 3 log2 friedman_mse 1.0 100: Macro 0.692137 (0.075675)\n",
      "Testing 4187/5184\n",
      "0.2 1 6 3 log2 friedman_mse 1.0 200: Weighted 0.785771 (0.071516)\n",
      "0.2 1 6 3 log2 friedman_mse 1.0 200: Macro 0.670551 (0.112389)\n",
      "Testing 4188/5184\n",
      "0.2 1 6 3 log2 friedman_mse 1.0 500: Weighted 0.794138 (0.061045)\n",
      "0.2 1 6 3 log2 friedman_mse 1.0 500: Macro 0.694622 (0.094274)\n",
      "Testing 4189/5184\n",
      "0.2 1 6 3 log2 mae 0.5 50: Weighted 0.783162 (0.057267)\n",
      "0.2 1 6 3 log2 mae 0.5 50: Macro 0.675896 (0.082789)\n",
      "Testing 4190/5184\n",
      "0.2 1 6 3 log2 mae 0.5 100: Weighted 0.780189 (0.079623)\n",
      "0.2 1 6 3 log2 mae 0.5 100: Macro 0.663548 (0.116501)\n",
      "Testing 4191/5184\n",
      "0.2 1 6 3 log2 mae 0.5 200: Weighted 0.801831 (0.075871)\n",
      "0.2 1 6 3 log2 mae 0.5 200: Macro 0.684153 (0.117262)\n",
      "Testing 4192/5184\n",
      "0.2 1 6 3 log2 mae 0.5 500: Weighted 0.787983 (0.049476)\n",
      "0.2 1 6 3 log2 mae 0.5 500: Macro 0.668066 (0.069736)\n",
      "Testing 4193/5184\n",
      "0.2 1 6 3 log2 mae 0.75 50: Weighted 0.753836 (0.040373)\n",
      "0.2 1 6 3 log2 mae 0.75 50: Macro 0.614595 (0.056360)\n",
      "Testing 4194/5184\n",
      "0.2 1 6 3 log2 mae 0.75 100: Weighted 0.761085 (0.069274)\n",
      "0.2 1 6 3 log2 mae 0.75 100: Macro 0.627212 (0.100114)\n",
      "Testing 4195/5184\n",
      "0.2 1 6 3 log2 mae 0.75 200: Weighted 0.757906 (0.051967)\n",
      "0.2 1 6 3 log2 mae 0.75 200: Macro 0.620363 (0.069450)\n",
      "Testing 4196/5184\n",
      "0.2 1 6 3 log2 mae 0.75 500: Weighted 0.788306 (0.052008)\n",
      "0.2 1 6 3 log2 mae 0.75 500: Macro 0.659798 (0.075162)\n",
      "Testing 4197/5184\n",
      "0.2 1 6 3 log2 mae 1.0 50: Weighted 0.775697 (0.074060)\n",
      "0.2 1 6 3 log2 mae 1.0 50: Macro 0.651886 (0.108664)\n",
      "Testing 4198/5184\n",
      "0.2 1 6 3 log2 mae 1.0 100: Weighted 0.753229 (0.053513)\n",
      "0.2 1 6 3 log2 mae 1.0 100: Macro 0.610539 (0.073893)\n",
      "Testing 4199/5184\n",
      "0.2 1 6 3 log2 mae 1.0 200: Weighted 0.784671 (0.054404)\n",
      "0.2 1 6 3 log2 mae 1.0 200: Macro 0.646508 (0.084402)\n",
      "Testing 4200/5184\n",
      "0.2 1 6 3 log2 mae 1.0 500: Weighted 0.786650 (0.068745)\n",
      "0.2 1 6 3 log2 mae 1.0 500: Macro 0.647355 (0.094125)\n",
      "Testing 4201/5184\n",
      "0.2 1 6 3 sqrt friedman_mse 0.5 50: Weighted 0.809017 (0.072500)\n",
      "0.2 1 6 3 sqrt friedman_mse 0.5 50: Macro 0.701088 (0.106221)\n",
      "Testing 4202/5184\n",
      "0.2 1 6 3 sqrt friedman_mse 0.5 100: Weighted 0.808016 (0.065502)\n",
      "0.2 1 6 3 sqrt friedman_mse 0.5 100: Macro 0.697821 (0.094815)\n",
      "Testing 4203/5184\n",
      "0.2 1 6 3 sqrt friedman_mse 0.5 200: Weighted 0.816919 (0.064344)\n",
      "0.2 1 6 3 sqrt friedman_mse 0.5 200: Macro 0.725530 (0.100713)\n",
      "Testing 4204/5184\n",
      "0.2 1 6 3 sqrt friedman_mse 0.5 500: Weighted 0.796184 (0.076701)\n",
      "0.2 1 6 3 sqrt friedman_mse 0.5 500: Macro 0.688852 (0.119884)\n",
      "Testing 4205/5184\n",
      "0.2 1 6 3 sqrt friedman_mse 0.75 50: Weighted 0.805945 (0.062115)\n",
      "0.2 1 6 3 sqrt friedman_mse 0.75 50: Macro 0.694916 (0.096183)\n",
      "Testing 4206/5184\n",
      "0.2 1 6 3 sqrt friedman_mse 0.75 100: Weighted 0.806335 (0.069267)\n",
      "0.2 1 6 3 sqrt friedman_mse 0.75 100: Macro 0.698349 (0.100221)\n",
      "Testing 4207/5184\n",
      "0.2 1 6 3 sqrt friedman_mse 0.75 200: Weighted 0.785956 (0.058471)\n",
      "0.2 1 6 3 sqrt friedman_mse 0.75 200: Macro 0.675274 (0.090460)\n",
      "Testing 4208/5184\n",
      "0.2 1 6 3 sqrt friedman_mse 0.75 500: Weighted 0.786299 (0.042321)\n",
      "0.2 1 6 3 sqrt friedman_mse 0.75 500: Macro 0.682046 (0.062273)\n",
      "Testing 4209/5184\n",
      "0.2 1 6 3 sqrt friedman_mse 1.0 50: Weighted 0.808744 (0.057277)\n",
      "0.2 1 6 3 sqrt friedman_mse 1.0 50: Macro 0.718593 (0.090782)\n",
      "Testing 4210/5184\n",
      "0.2 1 6 3 sqrt friedman_mse 1.0 100: Weighted 0.790267 (0.066911)\n",
      "0.2 1 6 3 sqrt friedman_mse 1.0 100: Macro 0.675077 (0.107482)\n",
      "Testing 4211/5184\n",
      "0.2 1 6 3 sqrt friedman_mse 1.0 200: Weighted 0.793132 (0.062245)\n",
      "0.2 1 6 3 sqrt friedman_mse 1.0 200: Macro 0.690025 (0.099110)\n",
      "Testing 4212/5184\n",
      "0.2 1 6 3 sqrt friedman_mse 1.0 500: Weighted 0.791523 (0.044842)\n",
      "0.2 1 6 3 sqrt friedman_mse 1.0 500: Macro 0.686302 (0.067466)\n",
      "Testing 4213/5184\n",
      "0.2 1 6 3 sqrt mae 0.5 50: Weighted 0.779702 (0.068387)\n",
      "0.2 1 6 3 sqrt mae 0.5 50: Macro 0.662667 (0.109109)\n",
      "Testing 4214/5184\n",
      "0.2 1 6 3 sqrt mae 0.5 100: Weighted 0.777856 (0.064159)\n",
      "0.2 1 6 3 sqrt mae 0.5 100: Macro 0.657855 (0.098839)\n",
      "Testing 4215/5184\n",
      "0.2 1 6 3 sqrt mae 0.5 200: Weighted 0.779556 (0.061853)\n",
      "0.2 1 6 3 sqrt mae 0.5 200: Macro 0.657037 (0.089383)\n",
      "Testing 4216/5184\n",
      "0.2 1 6 3 sqrt mae 0.5 500: Weighted 0.764814 (0.078748)\n",
      "0.2 1 6 3 sqrt mae 0.5 500: Macro 0.648490 (0.109242)\n",
      "Testing 4217/5184\n",
      "0.2 1 6 3 sqrt mae 0.75 50: Weighted 0.783806 (0.067025)\n",
      "0.2 1 6 3 sqrt mae 0.75 50: Macro 0.662051 (0.092900)\n",
      "Testing 4218/5184\n",
      "0.2 1 6 3 sqrt mae 0.75 100: Weighted 0.781486 (0.054531)\n",
      "0.2 1 6 3 sqrt mae 0.75 100: Macro 0.648993 (0.085196)\n",
      "Testing 4219/5184\n",
      "0.2 1 6 3 sqrt mae 0.75 200: Weighted 0.772376 (0.067932)\n",
      "0.2 1 6 3 sqrt mae 0.75 200: Macro 0.643981 (0.099767)\n",
      "Testing 4220/5184\n",
      "0.2 1 6 3 sqrt mae 0.75 500: Weighted 0.782365 (0.064838)\n",
      "0.2 1 6 3 sqrt mae 0.75 500: Macro 0.651275 (0.096062)\n",
      "Testing 4221/5184\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2 1 6 3 sqrt mae 1.0 50: Weighted 0.778798 (0.052524)\n",
      "0.2 1 6 3 sqrt mae 1.0 50: Macro 0.654903 (0.082281)\n",
      "Testing 4222/5184\n",
      "0.2 1 6 3 sqrt mae 1.0 100: Weighted 0.759357 (0.064208)\n",
      "0.2 1 6 3 sqrt mae 1.0 100: Macro 0.616900 (0.090340)\n",
      "Testing 4223/5184\n",
      "0.2 1 6 3 sqrt mae 1.0 200: Weighted 0.766866 (0.074570)\n",
      "0.2 1 6 3 sqrt mae 1.0 200: Macro 0.634788 (0.118050)\n",
      "Testing 4224/5184\n",
      "0.2 1 6 3 sqrt mae 1.0 500: Weighted 0.761310 (0.062498)\n",
      "0.2 1 6 3 sqrt mae 1.0 500: Macro 0.624620 (0.086118)\n",
      "Testing 4225/5184\n",
      "0.2 1 6 5 log2 friedman_mse 0.5 50: Weighted 0.825866 (0.082056)\n",
      "0.2 1 6 5 log2 friedman_mse 0.5 50: Macro 0.726563 (0.121224)\n",
      "Testing 4226/5184\n",
      "0.2 1 6 5 log2 friedman_mse 0.5 100: Weighted 0.804888 (0.077059)\n",
      "0.2 1 6 5 log2 friedman_mse 0.5 100: Macro 0.694055 (0.111339)\n",
      "Testing 4227/5184\n",
      "0.2 1 6 5 log2 friedman_mse 0.5 200: Weighted 0.819239 (0.073269)\n",
      "0.2 1 6 5 log2 friedman_mse 0.5 200: Macro 0.728026 (0.117021)\n",
      "Testing 4228/5184\n",
      "0.2 1 6 5 log2 friedman_mse 0.5 500: Weighted 0.794777 (0.075003)\n",
      "0.2 1 6 5 log2 friedman_mse 0.5 500: Macro 0.688894 (0.118866)\n",
      "Testing 4229/5184\n",
      "0.2 1 6 5 log2 friedman_mse 0.75 50: Weighted 0.802374 (0.080368)\n",
      "0.2 1 6 5 log2 friedman_mse 0.75 50: Macro 0.686636 (0.118581)\n",
      "Testing 4230/5184\n",
      "0.2 1 6 5 log2 friedman_mse 0.75 100: Weighted 0.793705 (0.072455)\n",
      "0.2 1 6 5 log2 friedman_mse 0.75 100: Macro 0.687340 (0.116563)\n",
      "Testing 4231/5184\n",
      "0.2 1 6 5 log2 friedman_mse 0.75 200: Weighted 0.788570 (0.071240)\n",
      "0.2 1 6 5 log2 friedman_mse 0.75 200: Macro 0.675727 (0.113360)\n",
      "Testing 4232/5184\n",
      "0.2 1 6 5 log2 friedman_mse 0.75 500: Weighted 0.804259 (0.074476)\n",
      "0.2 1 6 5 log2 friedman_mse 0.75 500: Macro 0.697825 (0.117845)\n",
      "Testing 4233/5184\n",
      "0.2 1 6 5 log2 friedman_mse 1.0 50: Weighted 0.803655 (0.079993)\n",
      "0.2 1 6 5 log2 friedman_mse 1.0 50: Macro 0.706105 (0.123415)\n",
      "Testing 4234/5184\n",
      "0.2 1 6 5 log2 friedman_mse 1.0 100: Weighted 0.806218 (0.067953)\n",
      "0.2 1 6 5 log2 friedman_mse 1.0 100: Macro 0.706795 (0.103930)\n",
      "Testing 4235/5184\n",
      "0.2 1 6 5 log2 friedman_mse 1.0 200: Weighted 0.799323 (0.084602)\n",
      "0.2 1 6 5 log2 friedman_mse 1.0 200: Macro 0.696481 (0.118915)\n",
      "Testing 4236/5184\n",
      "0.2 1 6 5 log2 friedman_mse 1.0 500: Weighted 0.815391 (0.060163)\n",
      "0.2 1 6 5 log2 friedman_mse 1.0 500: Macro 0.723251 (0.092237)\n",
      "Testing 4237/5184\n",
      "0.2 1 6 5 log2 mae 0.5 50: Weighted 0.789554 (0.051626)\n",
      "0.2 1 6 5 log2 mae 0.5 50: Macro 0.663216 (0.080469)\n",
      "Testing 4238/5184\n",
      "0.2 1 6 5 log2 mae 0.5 100: Weighted 0.789981 (0.060719)\n",
      "0.2 1 6 5 log2 mae 0.5 100: Macro 0.669061 (0.091859)\n",
      "Testing 4239/5184\n",
      "0.2 1 6 5 log2 mae 0.5 200: Weighted 0.790531 (0.058818)\n",
      "0.2 1 6 5 log2 mae 0.5 200: Macro 0.663730 (0.089815)\n",
      "Testing 4240/5184\n",
      "0.2 1 6 5 log2 mae 0.5 500: Weighted 0.797064 (0.063312)\n",
      "0.2 1 6 5 log2 mae 0.5 500: Macro 0.683871 (0.087392)\n",
      "Testing 4241/5184\n",
      "0.2 1 6 5 log2 mae 0.75 50: Weighted 0.779110 (0.062498)\n",
      "0.2 1 6 5 log2 mae 0.75 50: Macro 0.656735 (0.086988)\n",
      "Testing 4242/5184\n",
      "0.2 1 6 5 log2 mae 0.75 100: Weighted 0.774335 (0.064052)\n",
      "0.2 1 6 5 log2 mae 0.75 100: Macro 0.646486 (0.088194)\n",
      "Testing 4243/5184\n",
      "0.2 1 6 5 log2 mae 0.75 200: Weighted 0.797976 (0.068776)\n",
      "0.2 1 6 5 log2 mae 0.75 200: Macro 0.676992 (0.104660)\n",
      "Testing 4244/5184\n",
      "0.2 1 6 5 log2 mae 0.75 500: Weighted 0.766953 (0.072180)\n",
      "0.2 1 6 5 log2 mae 0.75 500: Macro 0.633591 (0.101731)\n",
      "Testing 4245/5184\n",
      "0.2 1 6 5 log2 mae 1.0 50: Weighted 0.786765 (0.049397)\n",
      "0.2 1 6 5 log2 mae 1.0 50: Macro 0.652259 (0.073071)\n",
      "Testing 4246/5184\n",
      "0.2 1 6 5 log2 mae 1.0 100: Weighted 0.780063 (0.079647)\n",
      "0.2 1 6 5 log2 mae 1.0 100: Macro 0.653013 (0.123293)\n",
      "Testing 4247/5184\n",
      "0.2 1 6 5 log2 mae 1.0 200: Weighted 0.790535 (0.066550)\n",
      "0.2 1 6 5 log2 mae 1.0 200: Macro 0.663470 (0.094534)\n",
      "Testing 4248/5184\n",
      "0.2 1 6 5 log2 mae 1.0 500: Weighted 0.769770 (0.077569)\n",
      "0.2 1 6 5 log2 mae 1.0 500: Macro 0.638587 (0.111480)\n",
      "Testing 4249/5184\n",
      "0.2 1 6 5 sqrt friedman_mse 0.5 50: Weighted 0.809166 (0.067643)\n",
      "0.2 1 6 5 sqrt friedman_mse 0.5 50: Macro 0.703581 (0.096577)\n",
      "Testing 4250/5184\n",
      "0.2 1 6 5 sqrt friedman_mse 0.5 100: Weighted 0.821051 (0.064125)\n",
      "0.2 1 6 5 sqrt friedman_mse 0.5 100: Macro 0.722315 (0.091836)\n",
      "Testing 4251/5184\n",
      "0.2 1 6 5 sqrt friedman_mse 0.5 200: Weighted 0.816938 (0.065131)\n",
      "0.2 1 6 5 sqrt friedman_mse 0.5 200: Macro 0.720667 (0.102791)\n",
      "Testing 4252/5184\n",
      "0.2 1 6 5 sqrt friedman_mse 0.5 500: Weighted 0.801324 (0.058744)\n",
      "0.2 1 6 5 sqrt friedman_mse 0.5 500: Macro 0.697308 (0.083650)\n",
      "Testing 4253/5184\n",
      "0.2 1 6 5 sqrt friedman_mse 0.75 50: Weighted 0.804373 (0.074630)\n",
      "0.2 1 6 5 sqrt friedman_mse 0.75 50: Macro 0.693514 (0.112390)\n",
      "Testing 4254/5184\n",
      "0.2 1 6 5 sqrt friedman_mse 0.75 100: Weighted 0.801115 (0.078714)\n",
      "0.2 1 6 5 sqrt friedman_mse 0.75 100: Macro 0.696483 (0.123197)\n",
      "Testing 4255/5184\n",
      "0.2 1 6 5 sqrt friedman_mse 0.75 200: Weighted 0.792328 (0.055220)\n",
      "0.2 1 6 5 sqrt friedman_mse 0.75 200: Macro 0.682791 (0.084292)\n",
      "Testing 4256/5184\n",
      "0.2 1 6 5 sqrt friedman_mse 0.75 500: Weighted 0.806521 (0.071503)\n",
      "0.2 1 6 5 sqrt friedman_mse 0.75 500: Macro 0.706204 (0.110869)\n",
      "Testing 4257/5184\n",
      "0.2 1 6 5 sqrt friedman_mse 1.0 50: Weighted 0.795020 (0.062059)\n",
      "0.2 1 6 5 sqrt friedman_mse 1.0 50: Macro 0.694166 (0.090445)\n",
      "Testing 4258/5184\n",
      "0.2 1 6 5 sqrt friedman_mse 1.0 100: Weighted 0.802157 (0.073284)\n",
      "0.2 1 6 5 sqrt friedman_mse 1.0 100: Macro 0.704737 (0.109630)\n",
      "Testing 4259/5184\n",
      "0.2 1 6 5 sqrt friedman_mse 1.0 200: Weighted 0.798684 (0.079510)\n",
      "0.2 1 6 5 sqrt friedman_mse 1.0 200: Macro 0.694090 (0.113166)\n",
      "Testing 4260/5184\n",
      "0.2 1 6 5 sqrt friedman_mse 1.0 500: Weighted 0.792237 (0.085131)\n",
      "0.2 1 6 5 sqrt friedman_mse 1.0 500: Macro 0.691952 (0.136646)\n",
      "Testing 4261/5184\n",
      "0.2 1 6 5 sqrt mae 0.5 50: Weighted 0.763423 (0.058147)\n",
      "0.2 1 6 5 sqrt mae 0.5 50: Macro 0.618436 (0.094046)\n",
      "Testing 4262/5184\n",
      "0.2 1 6 5 sqrt mae 0.5 100: Weighted 0.783588 (0.060867)\n",
      "0.2 1 6 5 sqrt mae 0.5 100: Macro 0.657000 (0.092087)\n",
      "Testing 4263/5184\n",
      "0.2 1 6 5 sqrt mae 0.5 200: Weighted 0.772626 (0.052456)\n",
      "0.2 1 6 5 sqrt mae 0.5 200: Macro 0.640720 (0.076003)\n",
      "Testing 4264/5184\n",
      "0.2 1 6 5 sqrt mae 0.5 500: Weighted 0.794382 (0.055335)\n",
      "0.2 1 6 5 sqrt mae 0.5 500: Macro 0.676314 (0.082226)\n",
      "Testing 4265/5184\n",
      "0.2 1 6 5 sqrt mae 0.75 50: Weighted 0.780950 (0.059216)\n",
      "0.2 1 6 5 sqrt mae 0.75 50: Macro 0.656691 (0.089639)\n",
      "Testing 4266/5184\n",
      "0.2 1 6 5 sqrt mae 0.75 100: Weighted 0.787640 (0.061888)\n",
      "0.2 1 6 5 sqrt mae 0.75 100: Macro 0.667360 (0.095958)\n",
      "Testing 4267/5184\n",
      "0.2 1 6 5 sqrt mae 0.75 200: Weighted 0.787597 (0.073433)\n",
      "0.2 1 6 5 sqrt mae 0.75 200: Macro 0.666196 (0.112118)\n",
      "Testing 4268/5184\n",
      "0.2 1 6 5 sqrt mae 0.75 500: Weighted 0.801429 (0.074877)\n",
      "0.2 1 6 5 sqrt mae 0.75 500: Macro 0.679680 (0.106642)\n",
      "Testing 4269/5184\n",
      "0.2 1 6 5 sqrt mae 1.0 50: Weighted 0.782702 (0.094327)\n",
      "0.2 1 6 5 sqrt mae 1.0 50: Macro 0.653664 (0.143460)\n",
      "Testing 4270/5184\n",
      "0.2 1 6 5 sqrt mae 1.0 100: Weighted 0.796559 (0.070822)\n",
      "0.2 1 6 5 sqrt mae 1.0 100: Macro 0.680491 (0.106293)\n",
      "Testing 4271/5184\n",
      "0.2 1 6 5 sqrt mae 1.0 200: Weighted 0.783988 (0.085486)\n",
      "0.2 1 6 5 sqrt mae 1.0 200: Macro 0.654240 (0.123647)\n",
      "Testing 4272/5184\n",
      "0.2 1 6 5 sqrt mae 1.0 500: Weighted 0.785047 (0.061871)\n",
      "0.2 1 6 5 sqrt mae 1.0 500: Macro 0.657804 (0.090757)\n",
      "Testing 4273/5184\n",
      "0.2 1 6 8 log2 friedman_mse 0.5 50: Weighted 0.802291 (0.075865)\n",
      "0.2 1 6 8 log2 friedman_mse 0.5 50: Macro 0.699223 (0.100873)\n",
      "Testing 4274/5184\n",
      "0.2 1 6 8 log2 friedman_mse 0.5 100: Weighted 0.801188 (0.075725)\n",
      "0.2 1 6 8 log2 friedman_mse 0.5 100: Macro 0.693526 (0.116684)\n",
      "Testing 4275/5184\n",
      "0.2 1 6 8 log2 friedman_mse 0.5 200: Weighted 0.824919 (0.066147)\n",
      "0.2 1 6 8 log2 friedman_mse 0.5 200: Macro 0.725431 (0.113220)\n",
      "Testing 4276/5184\n",
      "0.2 1 6 8 log2 friedman_mse 0.5 500: Weighted 0.808154 (0.074984)\n",
      "0.2 1 6 8 log2 friedman_mse 0.5 500: Macro 0.705777 (0.119608)\n",
      "Testing 4277/5184\n",
      "0.2 1 6 8 log2 friedman_mse 0.75 50: Weighted 0.804713 (0.069389)\n",
      "0.2 1 6 8 log2 friedman_mse 0.75 50: Macro 0.711849 (0.108242)\n",
      "Testing 4278/5184\n",
      "0.2 1 6 8 log2 friedman_mse 0.75 100: Weighted 0.798768 (0.074274)\n",
      "0.2 1 6 8 log2 friedman_mse 0.75 100: Macro 0.691433 (0.114930)\n",
      "Testing 4279/5184\n",
      "0.2 1 6 8 log2 friedman_mse 0.75 200: Weighted 0.805650 (0.068538)\n",
      "0.2 1 6 8 log2 friedman_mse 0.75 200: Macro 0.702782 (0.120196)\n",
      "Testing 4280/5184\n",
      "0.2 1 6 8 log2 friedman_mse 0.75 500: Weighted 0.813373 (0.070055)\n",
      "0.2 1 6 8 log2 friedman_mse 0.75 500: Macro 0.710729 (0.106615)\n",
      "Testing 4281/5184\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2 1 6 8 log2 friedman_mse 1.0 50: Weighted 0.788510 (0.078889)\n",
      "0.2 1 6 8 log2 friedman_mse 1.0 50: Macro 0.683180 (0.124214)\n",
      "Testing 4282/5184\n",
      "0.2 1 6 8 log2 friedman_mse 1.0 100: Weighted 0.796726 (0.074533)\n",
      "0.2 1 6 8 log2 friedman_mse 1.0 100: Macro 0.688632 (0.117748)\n",
      "Testing 4283/5184\n",
      "0.2 1 6 8 log2 friedman_mse 1.0 200: Weighted 0.802930 (0.074349)\n",
      "0.2 1 6 8 log2 friedman_mse 1.0 200: Macro 0.702406 (0.115575)\n",
      "Testing 4284/5184\n",
      "0.2 1 6 8 log2 friedman_mse 1.0 500: Weighted 0.796441 (0.079923)\n",
      "0.2 1 6 8 log2 friedman_mse 1.0 500: Macro 0.687701 (0.121233)\n",
      "Testing 4285/5184\n",
      "0.2 1 6 8 log2 mae 0.5 50: Weighted 0.792781 (0.038857)\n",
      "0.2 1 6 8 log2 mae 0.5 50: Macro 0.674854 (0.056064)\n",
      "Testing 4286/5184\n",
      "0.2 1 6 8 log2 mae 0.5 100: Weighted 0.795374 (0.073353)\n",
      "0.2 1 6 8 log2 mae 0.5 100: Macro 0.681276 (0.112865)\n",
      "Testing 4287/5184\n",
      "0.2 1 6 8 log2 mae 0.5 200: Weighted 0.810374 (0.065679)\n",
      "0.2 1 6 8 log2 mae 0.5 200: Macro 0.698469 (0.103699)\n",
      "Testing 4288/5184\n",
      "0.2 1 6 8 log2 mae 0.5 500: Weighted 0.793711 (0.055923)\n",
      "0.2 1 6 8 log2 mae 0.5 500: Macro 0.681249 (0.075619)\n",
      "Testing 4289/5184\n",
      "0.2 1 6 8 log2 mae 0.75 50: Weighted 0.784324 (0.079472)\n",
      "0.2 1 6 8 log2 mae 0.75 50: Macro 0.670568 (0.114233)\n",
      "Testing 4290/5184\n",
      "0.2 1 6 8 log2 mae 0.75 100: Weighted 0.793324 (0.076072)\n",
      "0.2 1 6 8 log2 mae 0.75 100: Macro 0.680722 (0.115727)\n",
      "Testing 4291/5184\n",
      "0.2 1 6 8 log2 mae 0.75 200: Weighted 0.794130 (0.068138)\n",
      "0.2 1 6 8 log2 mae 0.75 200: Macro 0.680494 (0.105264)\n",
      "Testing 4292/5184\n",
      "0.2 1 6 8 log2 mae 0.75 500: Weighted 0.765656 (0.075250)\n",
      "0.2 1 6 8 log2 mae 0.75 500: Macro 0.633157 (0.117277)\n",
      "Testing 4293/5184\n",
      "0.2 1 6 8 log2 mae 1.0 50: Weighted 0.770777 (0.076829)\n",
      "0.2 1 6 8 log2 mae 1.0 50: Macro 0.643257 (0.114369)\n",
      "Testing 4294/5184\n",
      "0.2 1 6 8 log2 mae 1.0 100: Weighted 0.763766 (0.070939)\n",
      "0.2 1 6 8 log2 mae 1.0 100: Macro 0.631943 (0.108246)\n",
      "Testing 4295/5184\n",
      "0.2 1 6 8 log2 mae 1.0 200: Weighted 0.788313 (0.060790)\n",
      "0.2 1 6 8 log2 mae 1.0 200: Macro 0.668745 (0.089206)\n",
      "Testing 4296/5184\n",
      "0.2 1 6 8 log2 mae 1.0 500: Weighted 0.787102 (0.064897)\n",
      "0.2 1 6 8 log2 mae 1.0 500: Macro 0.672326 (0.094628)\n",
      "Testing 4297/5184\n",
      "0.2 1 6 8 sqrt friedman_mse 0.5 50: Weighted 0.815815 (0.082708)\n",
      "0.2 1 6 8 sqrt friedman_mse 0.5 50: Macro 0.716089 (0.119721)\n",
      "Testing 4298/5184\n",
      "0.2 1 6 8 sqrt friedman_mse 0.5 100: Weighted 0.805899 (0.072479)\n",
      "0.2 1 6 8 sqrt friedman_mse 0.5 100: Macro 0.696737 (0.124134)\n",
      "Testing 4299/5184\n",
      "0.2 1 6 8 sqrt friedman_mse 0.5 200: Weighted 0.812618 (0.080174)\n",
      "0.2 1 6 8 sqrt friedman_mse 0.5 200: Macro 0.722006 (0.134924)\n",
      "Testing 4300/5184\n",
      "0.2 1 6 8 sqrt friedman_mse 0.5 500: Weighted 0.818358 (0.054613)\n",
      "0.2 1 6 8 sqrt friedman_mse 0.5 500: Macro 0.719006 (0.087363)\n",
      "Testing 4301/5184\n",
      "0.2 1 6 8 sqrt friedman_mse 0.75 50: Weighted 0.806777 (0.071397)\n",
      "0.2 1 6 8 sqrt friedman_mse 0.75 50: Macro 0.703551 (0.103899)\n",
      "Testing 4302/5184\n",
      "0.2 1 6 8 sqrt friedman_mse 0.75 100: Weighted 0.797588 (0.067523)\n",
      "0.2 1 6 8 sqrt friedman_mse 0.75 100: Macro 0.699224 (0.108619)\n",
      "Testing 4303/5184\n",
      "0.2 1 6 8 sqrt friedman_mse 0.75 200: Weighted 0.820116 (0.065945)\n",
      "0.2 1 6 8 sqrt friedman_mse 0.75 200: Macro 0.719122 (0.103917)\n",
      "Testing 4304/5184\n",
      "0.2 1 6 8 sqrt friedman_mse 0.75 500: Weighted 0.813665 (0.082970)\n",
      "0.2 1 6 8 sqrt friedman_mse 0.75 500: Macro 0.709408 (0.127341)\n",
      "Testing 4305/5184\n",
      "0.2 1 6 8 sqrt friedman_mse 1.0 50: Weighted 0.794487 (0.067058)\n",
      "0.2 1 6 8 sqrt friedman_mse 1.0 50: Macro 0.696157 (0.098112)\n",
      "Testing 4306/5184\n",
      "0.2 1 6 8 sqrt friedman_mse 1.0 100: Weighted 0.788384 (0.054363)\n",
      "0.2 1 6 8 sqrt friedman_mse 1.0 100: Macro 0.683696 (0.077449)\n",
      "Testing 4307/5184\n",
      "0.2 1 6 8 sqrt friedman_mse 1.0 200: Weighted 0.804131 (0.066392)\n",
      "0.2 1 6 8 sqrt friedman_mse 1.0 200: Macro 0.703464 (0.097863)\n",
      "Testing 4308/5184\n",
      "0.2 1 6 8 sqrt friedman_mse 1.0 500: Weighted 0.792997 (0.065876)\n",
      "0.2 1 6 8 sqrt friedman_mse 1.0 500: Macro 0.688805 (0.101941)\n",
      "Testing 4309/5184\n",
      "0.2 1 6 8 sqrt mae 0.5 50: Weighted 0.818516 (0.084564)\n",
      "0.2 1 6 8 sqrt mae 0.5 50: Macro 0.708541 (0.137174)\n",
      "Testing 4310/5184\n",
      "0.2 1 6 8 sqrt mae 0.5 100: Weighted 0.792228 (0.058903)\n",
      "0.2 1 6 8 sqrt mae 0.5 100: Macro 0.675525 (0.084655)\n",
      "Testing 4311/5184\n",
      "0.2 1 6 8 sqrt mae 0.5 200: Weighted 0.797563 (0.070792)\n",
      "0.2 1 6 8 sqrt mae 0.5 200: Macro 0.684618 (0.107066)\n",
      "Testing 4312/5184\n",
      "0.2 1 6 8 sqrt mae 0.5 500: Weighted 0.806558 (0.060991)\n",
      "0.2 1 6 8 sqrt mae 0.5 500: Macro 0.702067 (0.089755)\n",
      "Testing 4313/5184\n",
      "0.2 1 6 8 sqrt mae 0.75 50: Weighted 0.774522 (0.062467)\n",
      "0.2 1 6 8 sqrt mae 0.75 50: Macro 0.644947 (0.093737)\n",
      "Testing 4314/5184\n",
      "0.2 1 6 8 sqrt mae 0.75 100: Weighted 0.791932 (0.065924)\n",
      "0.2 1 6 8 sqrt mae 0.75 100: Macro 0.676486 (0.094592)\n",
      "Testing 4315/5184\n",
      "0.2 1 6 8 sqrt mae 0.75 200: Weighted 0.777809 (0.064943)\n",
      "0.2 1 6 8 sqrt mae 0.75 200: Macro 0.645533 (0.100456)\n",
      "Testing 4316/5184\n",
      "0.2 1 6 8 sqrt mae 0.75 500: Weighted 0.785185 (0.066869)\n",
      "0.2 1 6 8 sqrt mae 0.75 500: Macro 0.669916 (0.098165)\n",
      "Testing 4317/5184\n",
      "0.2 1 6 8 sqrt mae 1.0 50: Weighted 0.783755 (0.045678)\n",
      "0.2 1 6 8 sqrt mae 1.0 50: Macro 0.668557 (0.065626)\n",
      "Testing 4318/5184\n",
      "0.2 1 6 8 sqrt mae 1.0 100: Weighted 0.780752 (0.073984)\n",
      "0.2 1 6 8 sqrt mae 1.0 100: Macro 0.667539 (0.102819)\n",
      "Testing 4319/5184\n",
      "0.2 1 6 8 sqrt mae 1.0 200: Weighted 0.784383 (0.083308)\n",
      "0.2 1 6 8 sqrt mae 1.0 200: Macro 0.669089 (0.123090)\n",
      "Testing 4320/5184\n",
      "0.2 1 6 8 sqrt mae 1.0 500: Weighted 0.793958 (0.074539)\n",
      "0.2 1 6 8 sqrt mae 1.0 500: Macro 0.672503 (0.123338)\n",
      "Testing 4321/5184\n",
      "0.2 3 2 3 log2 friedman_mse 0.5 50: Weighted 0.810287 (0.056906)\n",
      "0.2 3 2 3 log2 friedman_mse 0.5 50: Macro 0.698342 (0.094746)\n",
      "Testing 4322/5184\n",
      "0.2 3 2 3 log2 friedman_mse 0.5 100: Weighted 0.816587 (0.069078)\n",
      "0.2 3 2 3 log2 friedman_mse 0.5 100: Macro 0.728418 (0.090744)\n",
      "Testing 4323/5184\n",
      "0.2 3 2 3 log2 friedman_mse 0.5 200: Weighted 0.810232 (0.061275)\n",
      "0.2 3 2 3 log2 friedman_mse 0.5 200: Macro 0.703438 (0.097004)\n",
      "Testing 4324/5184\n",
      "0.2 3 2 3 log2 friedman_mse 0.5 500: Weighted 0.819747 (0.067890)\n",
      "0.2 3 2 3 log2 friedman_mse 0.5 500: Macro 0.724029 (0.103936)\n",
      "Testing 4325/5184\n",
      "0.2 3 2 3 log2 friedman_mse 0.75 50: Weighted 0.795208 (0.070702)\n",
      "0.2 3 2 3 log2 friedman_mse 0.75 50: Macro 0.677719 (0.099606)\n",
      "Testing 4326/5184\n",
      "0.2 3 2 3 log2 friedman_mse 0.75 100: Weighted 0.811961 (0.049605)\n",
      "0.2 3 2 3 log2 friedman_mse 0.75 100: Macro 0.710652 (0.070117)\n",
      "Testing 4327/5184\n",
      "0.2 3 2 3 log2 friedman_mse 0.75 200: Weighted 0.816395 (0.067685)\n",
      "0.2 3 2 3 log2 friedman_mse 0.75 200: Macro 0.722286 (0.105991)\n",
      "Testing 4328/5184\n",
      "0.2 3 2 3 log2 friedman_mse 0.75 500: Weighted 0.818614 (0.056526)\n",
      "0.2 3 2 3 log2 friedman_mse 0.75 500: Macro 0.728161 (0.083065)\n",
      "Testing 4329/5184\n",
      "0.2 3 2 3 log2 friedman_mse 1.0 50: Weighted 0.803697 (0.064108)\n",
      "0.2 3 2 3 log2 friedman_mse 1.0 50: Macro 0.707967 (0.083083)\n",
      "Testing 4330/5184\n",
      "0.2 3 2 3 log2 friedman_mse 1.0 100: Weighted 0.813496 (0.052876)\n",
      "0.2 3 2 3 log2 friedman_mse 1.0 100: Macro 0.713269 (0.077361)\n",
      "Testing 4331/5184\n",
      "0.2 3 2 3 log2 friedman_mse 1.0 200: Weighted 0.796345 (0.050941)\n",
      "0.2 3 2 3 log2 friedman_mse 1.0 200: Macro 0.690221 (0.071959)\n",
      "Testing 4332/5184\n",
      "0.2 3 2 3 log2 friedman_mse 1.0 500: Weighted 0.805921 (0.060944)\n",
      "0.2 3 2 3 log2 friedman_mse 1.0 500: Macro 0.704371 (0.088306)\n",
      "Testing 4333/5184\n",
      "0.2 3 2 3 log2 mae 0.5 50: Weighted 0.811139 (0.067466)\n",
      "0.2 3 2 3 log2 mae 0.5 50: Macro 0.711707 (0.088763)\n",
      "Testing 4334/5184\n",
      "0.2 3 2 3 log2 mae 0.5 100: Weighted 0.765528 (0.062485)\n",
      "0.2 3 2 3 log2 mae 0.5 100: Macro 0.629095 (0.090424)\n",
      "Testing 4335/5184\n",
      "0.2 3 2 3 log2 mae 0.5 200: Weighted 0.783646 (0.071521)\n",
      "0.2 3 2 3 log2 mae 0.5 200: Macro 0.662752 (0.106616)\n",
      "Testing 4336/5184\n",
      "0.2 3 2 3 log2 mae 0.5 500: Weighted 0.787282 (0.069906)\n",
      "0.2 3 2 3 log2 mae 0.5 500: Macro 0.660773 (0.094217)\n",
      "Testing 4337/5184\n",
      "0.2 3 2 3 log2 mae 0.75 50: Weighted 0.775778 (0.075353)\n",
      "0.2 3 2 3 log2 mae 0.75 50: Macro 0.654568 (0.097212)\n",
      "Testing 4338/5184\n",
      "0.2 3 2 3 log2 mae 0.75 100: Weighted 0.776463 (0.069165)\n",
      "0.2 3 2 3 log2 mae 0.75 100: Macro 0.652407 (0.097428)\n",
      "Testing 4339/5184\n",
      "0.2 3 2 3 log2 mae 0.75 200: Weighted 0.795543 (0.071314)\n",
      "0.2 3 2 3 log2 mae 0.75 200: Macro 0.676635 (0.090110)\n",
      "Testing 4340/5184\n",
      "0.2 3 2 3 log2 mae 0.75 500: Weighted 0.784233 (0.061064)\n",
      "0.2 3 2 3 log2 mae 0.75 500: Macro 0.666048 (0.083032)\n",
      "Testing 4341/5184\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2 3 2 3 log2 mae 1.0 50: Weighted 0.764839 (0.063957)\n",
      "0.2 3 2 3 log2 mae 1.0 50: Macro 0.635561 (0.090972)\n",
      "Testing 4342/5184\n",
      "0.2 3 2 3 log2 mae 1.0 100: Weighted 0.764815 (0.081299)\n",
      "0.2 3 2 3 log2 mae 1.0 100: Macro 0.629362 (0.123455)\n",
      "Testing 4343/5184\n",
      "0.2 3 2 3 log2 mae 1.0 200: Weighted 0.772977 (0.065552)\n",
      "0.2 3 2 3 log2 mae 1.0 200: Macro 0.637255 (0.088026)\n",
      "Testing 4344/5184\n",
      "0.2 3 2 3 log2 mae 1.0 500: Weighted 0.775436 (0.091844)\n",
      "0.2 3 2 3 log2 mae 1.0 500: Macro 0.650494 (0.132520)\n",
      "Testing 4345/5184\n",
      "0.2 3 2 3 sqrt friedman_mse 0.5 50: Weighted 0.819755 (0.052692)\n",
      "0.2 3 2 3 sqrt friedman_mse 0.5 50: Macro 0.725188 (0.070757)\n",
      "Testing 4346/5184\n",
      "0.2 3 2 3 sqrt friedman_mse 0.5 100: Weighted 0.802107 (0.046489)\n",
      "0.2 3 2 3 sqrt friedman_mse 0.5 100: Macro 0.685350 (0.073078)\n",
      "Testing 4347/5184\n",
      "0.2 3 2 3 sqrt friedman_mse 0.5 200: Weighted 0.819362 (0.067242)\n",
      "0.2 3 2 3 sqrt friedman_mse 0.5 200: Macro 0.721264 (0.108649)\n",
      "Testing 4348/5184\n",
      "0.2 3 2 3 sqrt friedman_mse 0.5 500: Weighted 0.818771 (0.049081)\n",
      "0.2 3 2 3 sqrt friedman_mse 0.5 500: Macro 0.719734 (0.062040)\n",
      "Testing 4349/5184\n",
      "0.2 3 2 3 sqrt friedman_mse 0.75 50: Weighted 0.798149 (0.073054)\n",
      "0.2 3 2 3 sqrt friedman_mse 0.75 50: Macro 0.689809 (0.106296)\n",
      "Testing 4350/5184\n",
      "0.2 3 2 3 sqrt friedman_mse 0.75 100: Weighted 0.820376 (0.058218)\n",
      "0.2 3 2 3 sqrt friedman_mse 0.75 100: Macro 0.730850 (0.088362)\n",
      "Testing 4351/5184\n",
      "0.2 3 2 3 sqrt friedman_mse 0.75 200: Weighted 0.814926 (0.064207)\n",
      "0.2 3 2 3 sqrt friedman_mse 0.75 200: Macro 0.720626 (0.095826)\n",
      "Testing 4352/5184\n",
      "0.2 3 2 3 sqrt friedman_mse 0.75 500: Weighted 0.831540 (0.059064)\n",
      "0.2 3 2 3 sqrt friedman_mse 0.75 500: Macro 0.752615 (0.091196)\n",
      "Testing 4353/5184\n",
      "0.2 3 2 3 sqrt friedman_mse 1.0 50: Weighted 0.808380 (0.063770)\n",
      "0.2 3 2 3 sqrt friedman_mse 1.0 50: Macro 0.703718 (0.093713)\n",
      "Testing 4354/5184\n",
      "0.2 3 2 3 sqrt friedman_mse 1.0 100: Weighted 0.799157 (0.066180)\n",
      "0.2 3 2 3 sqrt friedman_mse 1.0 100: Macro 0.691112 (0.096942)\n",
      "Testing 4355/5184\n",
      "0.2 3 2 3 sqrt friedman_mse 1.0 200: Weighted 0.805792 (0.070378)\n",
      "0.2 3 2 3 sqrt friedman_mse 1.0 200: Macro 0.702095 (0.103390)\n",
      "Testing 4356/5184\n",
      "0.2 3 2 3 sqrt friedman_mse 1.0 500: Weighted 0.803193 (0.053182)\n",
      "0.2 3 2 3 sqrt friedman_mse 1.0 500: Macro 0.703409 (0.071149)\n",
      "Testing 4357/5184\n",
      "0.2 3 2 3 sqrt mae 0.5 50: Weighted 0.783319 (0.064214)\n",
      "0.2 3 2 3 sqrt mae 0.5 50: Macro 0.663480 (0.079791)\n",
      "Testing 4358/5184\n",
      "0.2 3 2 3 sqrt mae 0.5 100: Weighted 0.765274 (0.065634)\n",
      "0.2 3 2 3 sqrt mae 0.5 100: Macro 0.635992 (0.081850)\n",
      "Testing 4359/5184\n",
      "0.2 3 2 3 sqrt mae 0.5 200: Weighted 0.789004 (0.077350)\n",
      "0.2 3 2 3 sqrt mae 0.5 200: Macro 0.676238 (0.114829)\n",
      "Testing 4360/5184\n",
      "0.2 3 2 3 sqrt mae 0.5 500: Weighted 0.778615 (0.073835)\n",
      "0.2 3 2 3 sqrt mae 0.5 500: Macro 0.651483 (0.098241)\n",
      "Testing 4361/5184\n",
      "0.2 3 2 3 sqrt mae 0.75 50: Weighted 0.759546 (0.070131)\n",
      "0.2 3 2 3 sqrt mae 0.75 50: Macro 0.627978 (0.094017)\n",
      "Testing 4362/5184\n",
      "0.2 3 2 3 sqrt mae 0.75 100: Weighted 0.776460 (0.072976)\n",
      "0.2 3 2 3 sqrt mae 0.75 100: Macro 0.645420 (0.105175)\n",
      "Testing 4363/5184\n",
      "0.2 3 2 3 sqrt mae 0.75 200: Weighted 0.770040 (0.097067)\n",
      "0.2 3 2 3 sqrt mae 0.75 200: Macro 0.635458 (0.143226)\n",
      "Testing 4364/5184\n",
      "0.2 3 2 3 sqrt mae 0.75 500: Weighted 0.770201 (0.076907)\n",
      "0.2 3 2 3 sqrt mae 0.75 500: Macro 0.633562 (0.097122)\n",
      "Testing 4365/5184\n",
      "0.2 3 2 3 sqrt mae 1.0 50: Weighted 0.768016 (0.058923)\n",
      "0.2 3 2 3 sqrt mae 1.0 50: Macro 0.628374 (0.076695)\n",
      "Testing 4366/5184\n",
      "0.2 3 2 3 sqrt mae 1.0 100: Weighted 0.757479 (0.058861)\n",
      "0.2 3 2 3 sqrt mae 1.0 100: Macro 0.615324 (0.080097)\n",
      "Testing 4367/5184\n",
      "0.2 3 2 3 sqrt mae 1.0 200: Weighted 0.772199 (0.078437)\n",
      "0.2 3 2 3 sqrt mae 1.0 200: Macro 0.628561 (0.100478)\n",
      "Testing 4368/5184\n",
      "0.2 3 2 3 sqrt mae 1.0 500: Weighted 0.778324 (0.069349)\n",
      "0.2 3 2 3 sqrt mae 1.0 500: Macro 0.643240 (0.094520)\n",
      "Testing 4369/5184\n",
      "0.2 3 2 5 log2 friedman_mse 0.5 50: Weighted 0.836433 (0.066484)\n",
      "0.2 3 2 5 log2 friedman_mse 0.5 50: Macro 0.749727 (0.088970)\n",
      "Testing 4370/5184\n",
      "0.2 3 2 5 log2 friedman_mse 0.5 100: Weighted 0.815821 (0.061241)\n",
      "0.2 3 2 5 log2 friedman_mse 0.5 100: Macro 0.714792 (0.091679)\n",
      "Testing 4371/5184\n",
      "0.2 3 2 5 log2 friedman_mse 0.5 200: Weighted 0.815789 (0.059999)\n",
      "0.2 3 2 5 log2 friedman_mse 0.5 200: Macro 0.721354 (0.091324)\n",
      "Testing 4372/5184\n",
      "0.2 3 2 5 log2 friedman_mse 0.5 500: Weighted 0.815698 (0.072061)\n",
      "0.2 3 2 5 log2 friedman_mse 0.5 500: Macro 0.712256 (0.112055)\n",
      "Testing 4373/5184\n",
      "0.2 3 2 5 log2 friedman_mse 0.75 50: Weighted 0.819961 (0.089524)\n",
      "0.2 3 2 5 log2 friedman_mse 0.75 50: Macro 0.713475 (0.136050)\n",
      "Testing 4374/5184\n",
      "0.2 3 2 5 log2 friedman_mse 0.75 100: Weighted 0.811579 (0.084835)\n",
      "0.2 3 2 5 log2 friedman_mse 0.75 100: Macro 0.707210 (0.120122)\n",
      "Testing 4375/5184\n",
      "0.2 3 2 5 log2 friedman_mse 0.75 200: Weighted 0.818535 (0.057240)\n",
      "0.2 3 2 5 log2 friedman_mse 0.75 200: Macro 0.717413 (0.081996)\n",
      "Testing 4376/5184\n",
      "0.2 3 2 5 log2 friedman_mse 0.75 500: Weighted 0.811199 (0.084692)\n",
      "0.2 3 2 5 log2 friedman_mse 0.75 500: Macro 0.705272 (0.134335)\n",
      "Testing 4377/5184\n",
      "0.2 3 2 5 log2 friedman_mse 1.0 50: Weighted 0.816442 (0.089768)\n",
      "0.2 3 2 5 log2 friedman_mse 1.0 50: Macro 0.721189 (0.133204)\n",
      "Testing 4378/5184\n",
      "0.2 3 2 5 log2 friedman_mse 1.0 100: Weighted 0.803140 (0.071945)\n",
      "0.2 3 2 5 log2 friedman_mse 1.0 100: Macro 0.702665 (0.110119)\n",
      "Testing 4379/5184\n",
      "0.2 3 2 5 log2 friedman_mse 1.0 200: Weighted 0.815767 (0.078766)\n",
      "0.2 3 2 5 log2 friedman_mse 1.0 200: Macro 0.721813 (0.120941)\n",
      "Testing 4380/5184\n",
      "0.2 3 2 5 log2 friedman_mse 1.0 500: Weighted 0.798210 (0.078382)\n",
      "0.2 3 2 5 log2 friedman_mse 1.0 500: Macro 0.691681 (0.123267)\n",
      "Testing 4381/5184\n",
      "0.2 3 2 5 log2 mae 0.5 50: Weighted 0.776246 (0.073956)\n",
      "0.2 3 2 5 log2 mae 0.5 50: Macro 0.640886 (0.108554)\n",
      "Testing 4382/5184\n",
      "0.2 3 2 5 log2 mae 0.5 100: Weighted 0.806199 (0.068222)\n",
      "0.2 3 2 5 log2 mae 0.5 100: Macro 0.683662 (0.098045)\n",
      "Testing 4383/5184\n",
      "0.2 3 2 5 log2 mae 0.5 200: Weighted 0.786712 (0.098515)\n",
      "0.2 3 2 5 log2 mae 0.5 200: Macro 0.666645 (0.134206)\n",
      "Testing 4384/5184\n",
      "0.2 3 2 5 log2 mae 0.5 500: Weighted 0.766508 (0.065730)\n",
      "0.2 3 2 5 log2 mae 0.5 500: Macro 0.635187 (0.095835)\n",
      "Testing 4385/5184\n",
      "0.2 3 2 5 log2 mae 0.75 50: Weighted 0.779695 (0.078184)\n",
      "0.2 3 2 5 log2 mae 0.75 50: Macro 0.646406 (0.110569)\n",
      "Testing 4386/5184\n",
      "0.2 3 2 5 log2 mae 0.75 100: Weighted 0.784443 (0.075681)\n",
      "0.2 3 2 5 log2 mae 0.75 100: Macro 0.651890 (0.091315)\n",
      "Testing 4387/5184\n",
      "0.2 3 2 5 log2 mae 0.75 200: Weighted 0.795478 (0.060334)\n",
      "0.2 3 2 5 log2 mae 0.75 200: Macro 0.670843 (0.085171)\n",
      "Testing 4388/5184\n",
      "0.2 3 2 5 log2 mae 0.75 500: Weighted 0.784003 (0.064669)\n",
      "0.2 3 2 5 log2 mae 0.75 500: Macro 0.652314 (0.084525)\n",
      "Testing 4389/5184\n",
      "0.2 3 2 5 log2 mae 1.0 50: Weighted 0.772115 (0.068553)\n",
      "0.2 3 2 5 log2 mae 1.0 50: Macro 0.635842 (0.084583)\n",
      "Testing 4390/5184\n",
      "0.2 3 2 5 log2 mae 1.0 100: Weighted 0.766189 (0.090078)\n",
      "0.2 3 2 5 log2 mae 1.0 100: Macro 0.627433 (0.125492)\n",
      "Testing 4391/5184\n",
      "0.2 3 2 5 log2 mae 1.0 200: Weighted 0.779829 (0.076949)\n",
      "0.2 3 2 5 log2 mae 1.0 200: Macro 0.647087 (0.095782)\n",
      "Testing 4392/5184\n",
      "0.2 3 2 5 log2 mae 1.0 500: Weighted 0.793205 (0.090865)\n",
      "0.2 3 2 5 log2 mae 1.0 500: Macro 0.670123 (0.124101)\n",
      "Testing 4393/5184\n",
      "0.2 3 2 5 sqrt friedman_mse 0.5 50: Weighted 0.810913 (0.055914)\n",
      "0.2 3 2 5 sqrt friedman_mse 0.5 50: Macro 0.700655 (0.083781)\n",
      "Testing 4394/5184\n",
      "0.2 3 2 5 sqrt friedman_mse 0.5 100: Weighted 0.805009 (0.074348)\n",
      "0.2 3 2 5 sqrt friedman_mse 0.5 100: Macro 0.691230 (0.115489)\n",
      "Testing 4395/5184\n",
      "0.2 3 2 5 sqrt friedman_mse 0.5 200: Weighted 0.818188 (0.059994)\n",
      "0.2 3 2 5 sqrt friedman_mse 0.5 200: Macro 0.718859 (0.082351)\n",
      "Testing 4396/5184\n",
      "0.2 3 2 5 sqrt friedman_mse 0.5 500: Weighted 0.819888 (0.083061)\n",
      "0.2 3 2 5 sqrt friedman_mse 0.5 500: Macro 0.725658 (0.111537)\n",
      "Testing 4397/5184\n",
      "0.2 3 2 5 sqrt friedman_mse 0.75 50: Weighted 0.802123 (0.088673)\n",
      "0.2 3 2 5 sqrt friedman_mse 0.75 50: Macro 0.692205 (0.120893)\n",
      "Testing 4398/5184\n",
      "0.2 3 2 5 sqrt friedman_mse 0.75 100: Weighted 0.814714 (0.060964)\n",
      "0.2 3 2 5 sqrt friedman_mse 0.75 100: Macro 0.713641 (0.086084)\n",
      "Testing 4399/5184\n",
      "0.2 3 2 5 sqrt friedman_mse 0.75 200: Weighted 0.810075 (0.092733)\n",
      "0.2 3 2 5 sqrt friedman_mse 0.75 200: Macro 0.709769 (0.142249)\n",
      "Testing 4400/5184\n",
      "0.2 3 2 5 sqrt friedman_mse 0.75 500: Weighted 0.806408 (0.074229)\n",
      "0.2 3 2 5 sqrt friedman_mse 0.75 500: Macro 0.710845 (0.108477)\n",
      "Testing 4401/5184\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2 3 2 5 sqrt friedman_mse 1.0 50: Weighted 0.801874 (0.089328)\n",
      "0.2 3 2 5 sqrt friedman_mse 1.0 50: Macro 0.690535 (0.128706)\n",
      "Testing 4402/5184\n",
      "0.2 3 2 5 sqrt friedman_mse 1.0 100: Weighted 0.815530 (0.061303)\n",
      "0.2 3 2 5 sqrt friedman_mse 1.0 100: Macro 0.715646 (0.091671)\n",
      "Testing 4403/5184\n",
      "0.2 3 2 5 sqrt friedman_mse 1.0 200: Weighted 0.803913 (0.085260)\n",
      "0.2 3 2 5 sqrt friedman_mse 1.0 200: Macro 0.698788 (0.117259)\n",
      "Testing 4404/5184\n",
      "0.2 3 2 5 sqrt friedman_mse 1.0 500: Weighted 0.805545 (0.058983)\n",
      "0.2 3 2 5 sqrt friedman_mse 1.0 500: Macro 0.712384 (0.091897)\n",
      "Testing 4405/5184\n",
      "0.2 3 2 5 sqrt mae 0.5 50: Weighted 0.778999 (0.070491)\n",
      "0.2 3 2 5 sqrt mae 0.5 50: Macro 0.645700 (0.093207)\n",
      "Testing 4406/5184\n",
      "0.2 3 2 5 sqrt mae 0.5 100: Weighted 0.789822 (0.071086)\n",
      "0.2 3 2 5 sqrt mae 0.5 100: Macro 0.665136 (0.098388)\n",
      "Testing 4407/5184\n",
      "0.2 3 2 5 sqrt mae 0.5 200: Weighted 0.794990 (0.081946)\n",
      "0.2 3 2 5 sqrt mae 0.5 200: Macro 0.675884 (0.118089)\n",
      "Testing 4408/5184\n",
      "0.2 3 2 5 sqrt mae 0.5 500: Weighted 0.776897 (0.091658)\n",
      "0.2 3 2 5 sqrt mae 0.5 500: Macro 0.664405 (0.132013)\n",
      "Testing 4409/5184\n",
      "0.2 3 2 5 sqrt mae 0.75 50: Weighted 0.776738 (0.061921)\n",
      "0.2 3 2 5 sqrt mae 0.75 50: Macro 0.641193 (0.082458)\n",
      "Testing 4410/5184\n",
      "0.2 3 2 5 sqrt mae 0.75 100: Weighted 0.782039 (0.094990)\n",
      "0.2 3 2 5 sqrt mae 0.75 100: Macro 0.649315 (0.134789)\n",
      "Testing 4411/5184\n",
      "0.2 3 2 5 sqrt mae 0.75 200: Weighted 0.793324 (0.062111)\n",
      "0.2 3 2 5 sqrt mae 0.75 200: Macro 0.665208 (0.076536)\n",
      "Testing 4412/5184\n",
      "0.2 3 2 5 sqrt mae 0.75 500: Weighted 0.770450 (0.084567)\n",
      "0.2 3 2 5 sqrt mae 0.75 500: Macro 0.634600 (0.114306)\n",
      "Testing 4413/5184\n",
      "0.2 3 2 5 sqrt mae 1.0 50: Weighted 0.792524 (0.089639)\n",
      "0.2 3 2 5 sqrt mae 1.0 50: Macro 0.668026 (0.128631)\n",
      "Testing 4414/5184\n",
      "0.2 3 2 5 sqrt mae 1.0 100: Weighted 0.771069 (0.076893)\n",
      "0.2 3 2 5 sqrt mae 1.0 100: Macro 0.629947 (0.107156)\n",
      "Testing 4415/5184\n",
      "0.2 3 2 5 sqrt mae 1.0 200: Weighted 0.781731 (0.085506)\n",
      "0.2 3 2 5 sqrt mae 1.0 200: Macro 0.653593 (0.110589)\n",
      "Testing 4416/5184\n",
      "0.2 3 2 5 sqrt mae 1.0 500: Weighted 0.784540 (0.078197)\n",
      "0.2 3 2 5 sqrt mae 1.0 500: Macro 0.653981 (0.105378)\n",
      "Testing 4417/5184\n",
      "0.2 3 2 8 log2 friedman_mse 0.5 50: Weighted 0.804557 (0.046708)\n",
      "0.2 3 2 8 log2 friedman_mse 0.5 50: Macro 0.706872 (0.072700)\n",
      "Testing 4418/5184\n",
      "0.2 3 2 8 log2 friedman_mse 0.5 100: Weighted 0.807582 (0.058574)\n",
      "0.2 3 2 8 log2 friedman_mse 0.5 100: Macro 0.701256 (0.091121)\n",
      "Testing 4419/5184\n",
      "0.2 3 2 8 log2 friedman_mse 0.5 200: Weighted 0.803751 (0.060255)\n",
      "0.2 3 2 8 log2 friedman_mse 0.5 200: Macro 0.697066 (0.093106)\n",
      "Testing 4420/5184\n",
      "0.2 3 2 8 log2 friedman_mse 0.5 500: Weighted 0.794563 (0.066009)\n",
      "0.2 3 2 8 log2 friedman_mse 0.5 500: Macro 0.683605 (0.110295)\n",
      "Testing 4421/5184\n",
      "0.2 3 2 8 log2 friedman_mse 0.75 50: Weighted 0.802118 (0.078498)\n",
      "0.2 3 2 8 log2 friedman_mse 0.75 50: Macro 0.696833 (0.116402)\n",
      "Testing 4422/5184\n",
      "0.2 3 2 8 log2 friedman_mse 0.75 100: Weighted 0.830157 (0.084903)\n",
      "0.2 3 2 8 log2 friedman_mse 0.75 100: Macro 0.734727 (0.126534)\n",
      "Testing 4423/5184\n",
      "0.2 3 2 8 log2 friedman_mse 0.75 200: Weighted 0.833986 (0.074637)\n",
      "0.2 3 2 8 log2 friedman_mse 0.75 200: Macro 0.742066 (0.108620)\n",
      "Testing 4424/5184\n",
      "0.2 3 2 8 log2 friedman_mse 0.75 500: Weighted 0.822125 (0.089841)\n",
      "0.2 3 2 8 log2 friedman_mse 0.75 500: Macro 0.718884 (0.136662)\n",
      "Testing 4425/5184\n",
      "0.2 3 2 8 log2 friedman_mse 1.0 50: Weighted 0.786222 (0.069780)\n",
      "0.2 3 2 8 log2 friedman_mse 1.0 50: Macro 0.673624 (0.105696)\n",
      "Testing 4426/5184\n",
      "0.2 3 2 8 log2 friedman_mse 1.0 100: Weighted 0.800172 (0.086057)\n",
      "0.2 3 2 8 log2 friedman_mse 1.0 100: Macro 0.699787 (0.129348)\n",
      "Testing 4427/5184\n",
      "0.2 3 2 8 log2 friedman_mse 1.0 200: Weighted 0.820545 (0.080444)\n",
      "0.2 3 2 8 log2 friedman_mse 1.0 200: Macro 0.715831 (0.124732)\n",
      "Testing 4428/5184\n",
      "0.2 3 2 8 log2 friedman_mse 1.0 500: Weighted 0.818933 (0.087203)\n",
      "0.2 3 2 8 log2 friedman_mse 1.0 500: Macro 0.727021 (0.123621)\n",
      "Testing 4429/5184\n",
      "0.2 3 2 8 log2 mae 0.5 50: Weighted 0.806059 (0.081433)\n",
      "0.2 3 2 8 log2 mae 0.5 50: Macro 0.690896 (0.121045)\n",
      "Testing 4430/5184\n",
      "0.2 3 2 8 log2 mae 0.5 100: Weighted 0.799714 (0.059536)\n",
      "0.2 3 2 8 log2 mae 0.5 100: Macro 0.686991 (0.073529)\n",
      "Testing 4431/5184\n",
      "0.2 3 2 8 log2 mae 0.5 200: Weighted 0.810741 (0.057132)\n",
      "0.2 3 2 8 log2 mae 0.5 200: Macro 0.693198 (0.085368)\n",
      "Testing 4432/5184\n",
      "0.2 3 2 8 log2 mae 0.5 500: Weighted 0.798663 (0.071480)\n",
      "0.2 3 2 8 log2 mae 0.5 500: Macro 0.679705 (0.106231)\n",
      "Testing 4433/5184\n",
      "0.2 3 2 8 log2 mae 0.75 50: Weighted 0.770496 (0.078476)\n",
      "0.2 3 2 8 log2 mae 0.75 50: Macro 0.633145 (0.116798)\n",
      "Testing 4434/5184\n",
      "0.2 3 2 8 log2 mae 0.75 100: Weighted 0.782662 (0.079495)\n",
      "0.2 3 2 8 log2 mae 0.75 100: Macro 0.648386 (0.115714)\n",
      "Testing 4435/5184\n",
      "0.2 3 2 8 log2 mae 0.75 200: Weighted 0.800966 (0.077067)\n",
      "0.2 3 2 8 log2 mae 0.75 200: Macro 0.671083 (0.123183)\n",
      "Testing 4436/5184\n",
      "0.2 3 2 8 log2 mae 0.75 500: Weighted 0.804775 (0.058474)\n",
      "0.2 3 2 8 log2 mae 0.75 500: Macro 0.700390 (0.079925)\n",
      "Testing 4437/5184\n",
      "0.2 3 2 8 log2 mae 1.0 50: Weighted 0.772486 (0.089510)\n",
      "0.2 3 2 8 log2 mae 1.0 50: Macro 0.647459 (0.131759)\n",
      "Testing 4438/5184\n",
      "0.2 3 2 8 log2 mae 1.0 100: Weighted 0.795450 (0.083715)\n",
      "0.2 3 2 8 log2 mae 1.0 100: Macro 0.670486 (0.117482)\n",
      "Testing 4439/5184\n",
      "0.2 3 2 8 log2 mae 1.0 200: Weighted 0.787957 (0.094168)\n",
      "0.2 3 2 8 log2 mae 1.0 200: Macro 0.669053 (0.135382)\n",
      "Testing 4440/5184\n",
      "0.2 3 2 8 log2 mae 1.0 500: Weighted 0.786289 (0.080020)\n",
      "0.2 3 2 8 log2 mae 1.0 500: Macro 0.652581 (0.111908)\n",
      "Testing 4441/5184\n",
      "0.2 3 2 8 sqrt friedman_mse 0.5 50: Weighted 0.828519 (0.080578)\n",
      "0.2 3 2 8 sqrt friedman_mse 0.5 50: Macro 0.725950 (0.121129)\n",
      "Testing 4442/5184\n",
      "0.2 3 2 8 sqrt friedman_mse 0.5 100: Weighted 0.822576 (0.086275)\n",
      "0.2 3 2 8 sqrt friedman_mse 0.5 100: Macro 0.716193 (0.128778)\n",
      "Testing 4443/5184\n",
      "0.2 3 2 8 sqrt friedman_mse 0.5 200: Weighted 0.829964 (0.094360)\n",
      "0.2 3 2 8 sqrt friedman_mse 0.5 200: Macro 0.729623 (0.145071)\n",
      "Testing 4444/5184\n",
      "0.2 3 2 8 sqrt friedman_mse 0.5 500: Weighted 0.826009 (0.067375)\n",
      "0.2 3 2 8 sqrt friedman_mse 0.5 500: Macro 0.724542 (0.114298)\n",
      "Testing 4445/5184\n",
      "0.2 3 2 8 sqrt friedman_mse 0.75 50: Weighted 0.829303 (0.088887)\n",
      "0.2 3 2 8 sqrt friedman_mse 0.75 50: Macro 0.742294 (0.126129)\n",
      "Testing 4446/5184\n",
      "0.2 3 2 8 sqrt friedman_mse 0.75 100: Weighted 0.827463 (0.074067)\n",
      "0.2 3 2 8 sqrt friedman_mse 0.75 100: Macro 0.727693 (0.109504)\n",
      "Testing 4447/5184\n",
      "0.2 3 2 8 sqrt friedman_mse 0.75 200: Weighted 0.812916 (0.087312)\n",
      "0.2 3 2 8 sqrt friedman_mse 0.75 200: Macro 0.714080 (0.137980)\n",
      "Testing 4448/5184\n",
      "0.2 3 2 8 sqrt friedman_mse 0.75 500: Weighted 0.814159 (0.076777)\n",
      "0.2 3 2 8 sqrt friedman_mse 0.75 500: Macro 0.700455 (0.115023)\n",
      "Testing 4449/5184\n",
      "0.2 3 2 8 sqrt friedman_mse 1.0 50: Weighted 0.803016 (0.089662)\n",
      "0.2 3 2 8 sqrt friedman_mse 1.0 50: Macro 0.700704 (0.126596)\n",
      "Testing 4450/5184\n",
      "0.2 3 2 8 sqrt friedman_mse 1.0 100: Weighted 0.803211 (0.087317)\n",
      "0.2 3 2 8 sqrt friedman_mse 1.0 100: Macro 0.705618 (0.113760)\n",
      "Testing 4451/5184\n",
      "0.2 3 2 8 sqrt friedman_mse 1.0 200: Weighted 0.802578 (0.096625)\n",
      "0.2 3 2 8 sqrt friedman_mse 1.0 200: Macro 0.696451 (0.137639)\n",
      "Testing 4452/5184\n",
      "0.2 3 2 8 sqrt friedman_mse 1.0 500: Weighted 0.796034 (0.083972)\n",
      "0.2 3 2 8 sqrt friedman_mse 1.0 500: Macro 0.688392 (0.120874)\n",
      "Testing 4453/5184\n",
      "0.2 3 2 8 sqrt mae 0.5 50: Weighted 0.798338 (0.071082)\n",
      "0.2 3 2 8 sqrt mae 0.5 50: Macro 0.678772 (0.101367)\n",
      "Testing 4454/5184\n",
      "0.2 3 2 8 sqrt mae 0.5 100: Weighted 0.804698 (0.083155)\n",
      "0.2 3 2 8 sqrt mae 0.5 100: Macro 0.697656 (0.113939)\n",
      "Testing 4455/5184\n",
      "0.2 3 2 8 sqrt mae 0.5 200: Weighted 0.807901 (0.078924)\n",
      "0.2 3 2 8 sqrt mae 0.5 200: Macro 0.699753 (0.109099)\n",
      "Testing 4456/5184\n",
      "0.2 3 2 8 sqrt mae 0.5 500: Weighted 0.799457 (0.096293)\n",
      "0.2 3 2 8 sqrt mae 0.5 500: Macro 0.688568 (0.133826)\n",
      "Testing 4457/5184\n",
      "0.2 3 2 8 sqrt mae 0.75 50: Weighted 0.774931 (0.070129)\n",
      "0.2 3 2 8 sqrt mae 0.75 50: Macro 0.643104 (0.107779)\n",
      "Testing 4458/5184\n",
      "0.2 3 2 8 sqrt mae 0.75 100: Weighted 0.793555 (0.104950)\n",
      "0.2 3 2 8 sqrt mae 0.75 100: Macro 0.679159 (0.153092)\n",
      "Testing 4459/5184\n",
      "0.2 3 2 8 sqrt mae 0.75 200: Weighted 0.792465 (0.082805)\n",
      "0.2 3 2 8 sqrt mae 0.75 200: Macro 0.665145 (0.121751)\n",
      "Testing 4460/5184\n",
      "0.2 3 2 8 sqrt mae 0.75 500: Weighted 0.791580 (0.081597)\n",
      "0.2 3 2 8 sqrt mae 0.75 500: Macro 0.668052 (0.125450)\n",
      "Testing 4461/5184\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2 3 2 8 sqrt mae 1.0 50: Weighted 0.780200 (0.083684)\n",
      "0.2 3 2 8 sqrt mae 1.0 50: Macro 0.652015 (0.122175)\n",
      "Testing 4462/5184\n",
      "0.2 3 2 8 sqrt mae 1.0 100: Weighted 0.797573 (0.091042)\n",
      "0.2 3 2 8 sqrt mae 1.0 100: Macro 0.681619 (0.125496)\n",
      "Testing 4463/5184\n",
      "0.2 3 2 8 sqrt mae 1.0 200: Weighted 0.793873 (0.090745)\n",
      "0.2 3 2 8 sqrt mae 1.0 200: Macro 0.670871 (0.134784)\n",
      "Testing 4464/5184\n",
      "0.2 3 2 8 sqrt mae 1.0 500: Weighted 0.781228 (0.101521)\n",
      "0.2 3 2 8 sqrt mae 1.0 500: Macro 0.647977 (0.141701)\n",
      "Testing 4465/5184\n",
      "0.2 3 4 3 log2 friedman_mse 0.5 50: Weighted 0.794678 (0.062799)\n",
      "0.2 3 4 3 log2 friedman_mse 0.5 50: Macro 0.689638 (0.090365)\n",
      "Testing 4466/5184\n",
      "0.2 3 4 3 log2 friedman_mse 0.5 100: Weighted 0.818863 (0.084078)\n",
      "0.2 3 4 3 log2 friedman_mse 0.5 100: Macro 0.711144 (0.122511)\n",
      "Testing 4467/5184\n",
      "0.2 3 4 3 log2 friedman_mse 0.5 200: Weighted 0.801720 (0.064720)\n",
      "0.2 3 4 3 log2 friedman_mse 0.5 200: Macro 0.688151 (0.101055)\n",
      "Testing 4468/5184\n",
      "0.2 3 4 3 log2 friedman_mse 0.5 500: Weighted 0.826624 (0.062160)\n",
      "0.2 3 4 3 log2 friedman_mse 0.5 500: Macro 0.744162 (0.094637)\n",
      "Testing 4469/5184\n",
      "0.2 3 4 3 log2 friedman_mse 0.75 50: Weighted 0.820683 (0.076823)\n",
      "0.2 3 4 3 log2 friedman_mse 0.75 50: Macro 0.720034 (0.107850)\n",
      "Testing 4470/5184\n",
      "0.2 3 4 3 log2 friedman_mse 0.75 100: Weighted 0.818078 (0.052375)\n",
      "0.2 3 4 3 log2 friedman_mse 0.75 100: Macro 0.722535 (0.080786)\n",
      "Testing 4471/5184\n",
      "0.2 3 4 3 log2 friedman_mse 0.75 200: Weighted 0.812417 (0.062408)\n",
      "0.2 3 4 3 log2 friedman_mse 0.75 200: Macro 0.707102 (0.091506)\n",
      "Testing 4472/5184\n",
      "0.2 3 4 3 log2 friedman_mse 0.75 500: Weighted 0.815025 (0.055687)\n",
      "0.2 3 4 3 log2 friedman_mse 0.75 500: Macro 0.721688 (0.074118)\n",
      "Testing 4473/5184\n",
      "0.2 3 4 3 log2 friedman_mse 1.0 50: Weighted 0.794300 (0.053662)\n",
      "0.2 3 4 3 log2 friedman_mse 1.0 50: Macro 0.686245 (0.081050)\n",
      "Testing 4474/5184\n",
      "0.2 3 4 3 log2 friedman_mse 1.0 100: Weighted 0.809973 (0.050371)\n",
      "0.2 3 4 3 log2 friedman_mse 1.0 100: Macro 0.708065 (0.063595)\n",
      "Testing 4475/5184\n",
      "0.2 3 4 3 log2 friedman_mse 1.0 200: Weighted 0.815530 (0.061303)\n",
      "0.2 3 4 3 log2 friedman_mse 1.0 200: Macro 0.715646 (0.091671)\n",
      "Testing 4476/5184\n",
      "0.2 3 4 3 log2 friedman_mse 1.0 500: Weighted 0.813934 (0.054463)\n",
      "0.2 3 4 3 log2 friedman_mse 1.0 500: Macro 0.717622 (0.082554)\n",
      "Testing 4477/5184\n",
      "0.2 3 4 3 log2 mae 0.5 50: Weighted 0.795158 (0.051713)\n",
      "0.2 3 4 3 log2 mae 0.5 50: Macro 0.676859 (0.078740)\n",
      "Testing 4478/5184\n",
      "0.2 3 4 3 log2 mae 0.5 100: Weighted 0.800252 (0.066724)\n",
      "0.2 3 4 3 log2 mae 0.5 100: Macro 0.686235 (0.085280)\n",
      "Testing 4479/5184\n",
      "0.2 3 4 3 log2 mae 0.5 200: Weighted 0.793426 (0.074967)\n",
      "0.2 3 4 3 log2 mae 0.5 200: Macro 0.677800 (0.105023)\n",
      "Testing 4480/5184\n",
      "0.2 3 4 3 log2 mae 0.5 500: Weighted 0.764803 (0.064294)\n",
      "0.2 3 4 3 log2 mae 0.5 500: Macro 0.636628 (0.082359)\n",
      "Testing 4481/5184\n",
      "0.2 3 4 3 log2 mae 0.75 50: Weighted 0.776972 (0.073612)\n",
      "0.2 3 4 3 log2 mae 0.75 50: Macro 0.653732 (0.103701)\n",
      "Testing 4482/5184\n",
      "0.2 3 4 3 log2 mae 0.75 100: Weighted 0.789708 (0.087849)\n",
      "0.2 3 4 3 log2 mae 0.75 100: Macro 0.667964 (0.124773)\n",
      "Testing 4483/5184\n",
      "0.2 3 4 3 log2 mae 0.75 200: Weighted 0.784910 (0.075613)\n",
      "0.2 3 4 3 log2 mae 0.75 200: Macro 0.654670 (0.109851)\n",
      "Testing 4484/5184\n",
      "0.2 3 4 3 log2 mae 0.75 500: Weighted 0.782928 (0.055798)\n",
      "0.2 3 4 3 log2 mae 0.75 500: Macro 0.654165 (0.071291)\n",
      "Testing 4485/5184\n",
      "0.2 3 4 3 log2 mae 1.0 50: Weighted 0.772314 (0.066125)\n",
      "0.2 3 4 3 log2 mae 1.0 50: Macro 0.643773 (0.092530)\n",
      "Testing 4486/5184\n",
      "0.2 3 4 3 log2 mae 1.0 100: Weighted 0.755843 (0.059611)\n",
      "0.2 3 4 3 log2 mae 1.0 100: Macro 0.608459 (0.083824)\n",
      "Testing 4487/5184\n",
      "0.2 3 4 3 log2 mae 1.0 200: Weighted 0.779916 (0.070361)\n",
      "0.2 3 4 3 log2 mae 1.0 200: Macro 0.641710 (0.100949)\n",
      "Testing 4488/5184\n",
      "0.2 3 4 3 log2 mae 1.0 500: Weighted 0.771217 (0.095252)\n",
      "0.2 3 4 3 log2 mae 1.0 500: Macro 0.637063 (0.129097)\n",
      "Testing 4489/5184\n",
      "0.2 3 4 3 sqrt friedman_mse 0.5 50: Weighted 0.814738 (0.050441)\n",
      "0.2 3 4 3 sqrt friedman_mse 0.5 50: Macro 0.704854 (0.069064)\n",
      "Testing 4490/5184\n",
      "0.2 3 4 3 sqrt friedman_mse 0.5 100: Weighted 0.810415 (0.063546)\n",
      "0.2 3 4 3 sqrt friedman_mse 0.5 100: Macro 0.704627 (0.101305)\n",
      "Testing 4491/5184\n",
      "0.2 3 4 3 sqrt friedman_mse 0.5 200: Weighted 0.821556 (0.045061)\n",
      "0.2 3 4 3 sqrt friedman_mse 0.5 200: Macro 0.721877 (0.069273)\n",
      "Testing 4492/5184\n",
      "0.2 3 4 3 sqrt friedman_mse 0.5 500: Weighted 0.813473 (0.049366)\n",
      "0.2 3 4 3 sqrt friedman_mse 0.5 500: Macro 0.710529 (0.076112)\n",
      "Testing 4493/5184\n",
      "0.2 3 4 3 sqrt friedman_mse 0.75 50: Weighted 0.823669 (0.049535)\n",
      "0.2 3 4 3 sqrt friedman_mse 0.75 50: Macro 0.726781 (0.071201)\n",
      "Testing 4494/5184\n",
      "0.2 3 4 3 sqrt friedman_mse 0.75 100: Weighted 0.818251 (0.057060)\n",
      "0.2 3 4 3 sqrt friedman_mse 0.75 100: Macro 0.719453 (0.083473)\n",
      "Testing 4495/5184\n",
      "0.2 3 4 3 sqrt friedman_mse 0.75 200: Weighted 0.817803 (0.059582)\n",
      "0.2 3 4 3 sqrt friedman_mse 0.75 200: Macro 0.727033 (0.093647)\n",
      "Testing 4496/5184\n",
      "0.2 3 4 3 sqrt friedman_mse 0.75 500: Weighted 0.818207 (0.048488)\n",
      "0.2 3 4 3 sqrt friedman_mse 0.75 500: Macro 0.722935 (0.066680)\n",
      "Testing 4497/5184\n",
      "0.2 3 4 3 sqrt friedman_mse 1.0 50: Weighted 0.800691 (0.059978)\n",
      "0.2 3 4 3 sqrt friedman_mse 1.0 50: Macro 0.693615 (0.086236)\n",
      "Testing 4498/5184\n",
      "0.2 3 4 3 sqrt friedman_mse 1.0 100: Weighted 0.813932 (0.065164)\n",
      "0.2 3 4 3 sqrt friedman_mse 1.0 100: Macro 0.709711 (0.090495)\n",
      "Testing 4499/5184\n",
      "0.2 3 4 3 sqrt friedman_mse 1.0 200: Weighted 0.801498 (0.063758)\n",
      "0.2 3 4 3 sqrt friedman_mse 1.0 200: Macro 0.701053 (0.090499)\n",
      "Testing 4500/5184\n",
      "0.2 3 4 3 sqrt friedman_mse 1.0 500: Weighted 0.797945 (0.057597)\n",
      "0.2 3 4 3 sqrt friedman_mse 1.0 500: Macro 0.693384 (0.081701)\n",
      "Testing 4501/5184\n",
      "0.2 3 4 3 sqrt mae 0.5 50: Weighted 0.806720 (0.079327)\n",
      "0.2 3 4 3 sqrt mae 0.5 50: Macro 0.699036 (0.110694)\n",
      "Testing 4502/5184\n",
      "0.2 3 4 3 sqrt mae 0.5 100: Weighted 0.770866 (0.057413)\n",
      "0.2 3 4 3 sqrt mae 0.5 100: Macro 0.639197 (0.079741)\n",
      "Testing 4503/5184\n",
      "0.2 3 4 3 sqrt mae 0.5 200: Weighted 0.767224 (0.067830)\n",
      "0.2 3 4 3 sqrt mae 0.5 200: Macro 0.639881 (0.098870)\n",
      "Testing 4504/5184\n",
      "0.2 3 4 3 sqrt mae 0.5 500: Weighted 0.770859 (0.056166)\n",
      "0.2 3 4 3 sqrt mae 0.5 500: Macro 0.638514 (0.075613)\n",
      "Testing 4505/5184\n",
      "0.2 3 4 3 sqrt mae 0.75 50: Weighted 0.781110 (0.059372)\n",
      "0.2 3 4 3 sqrt mae 0.75 50: Macro 0.651508 (0.090011)\n",
      "Testing 4506/5184\n",
      "0.2 3 4 3 sqrt mae 0.75 100: Weighted 0.762516 (0.069088)\n",
      "0.2 3 4 3 sqrt mae 0.75 100: Macro 0.621563 (0.096432)\n",
      "Testing 4507/5184\n",
      "0.2 3 4 3 sqrt mae 0.75 200: Weighted 0.774654 (0.073013)\n",
      "0.2 3 4 3 sqrt mae 0.75 200: Macro 0.629072 (0.108928)\n",
      "Testing 4508/5184\n",
      "0.2 3 4 3 sqrt mae 0.75 500: Weighted 0.784257 (0.078297)\n",
      "0.2 3 4 3 sqrt mae 0.75 500: Macro 0.657478 (0.105438)\n",
      "Testing 4509/5184\n",
      "0.2 3 4 3 sqrt mae 1.0 50: Weighted 0.759546 (0.070131)\n",
      "0.2 3 4 3 sqrt mae 1.0 50: Macro 0.627978 (0.094017)\n",
      "Testing 4510/5184\n",
      "0.2 3 4 3 sqrt mae 1.0 100: Weighted 0.769232 (0.052253)\n",
      "0.2 3 4 3 sqrt mae 1.0 100: Macro 0.629448 (0.068854)\n",
      "Testing 4511/5184\n",
      "0.2 3 4 3 sqrt mae 1.0 200: Weighted 0.781048 (0.075447)\n",
      "0.2 3 4 3 sqrt mae 1.0 200: Macro 0.651833 (0.100737)\n",
      "Testing 4512/5184\n",
      "0.2 3 4 3 sqrt mae 1.0 500: Weighted 0.790264 (0.073514)\n",
      "0.2 3 4 3 sqrt mae 1.0 500: Macro 0.658652 (0.097230)\n",
      "Testing 4513/5184\n",
      "0.2 3 4 5 log2 friedman_mse 0.5 50: Weighted 0.801341 (0.070981)\n",
      "0.2 3 4 5 log2 friedman_mse 0.5 50: Macro 0.695753 (0.099167)\n",
      "Testing 4514/5184\n",
      "0.2 3 4 5 log2 friedman_mse 0.5 100: Weighted 0.830526 (0.077454)\n",
      "0.2 3 4 5 log2 friedman_mse 0.5 100: Macro 0.735748 (0.113283)\n",
      "Testing 4515/5184\n",
      "0.2 3 4 5 log2 friedman_mse 0.5 200: Weighted 0.811259 (0.060603)\n",
      "0.2 3 4 5 log2 friedman_mse 0.5 200: Macro 0.703718 (0.097466)\n",
      "Testing 4516/5184\n",
      "0.2 3 4 5 log2 friedman_mse 0.5 500: Weighted 0.814801 (0.062368)\n",
      "0.2 3 4 5 log2 friedman_mse 0.5 500: Macro 0.711435 (0.087960)\n",
      "Testing 4517/5184\n",
      "0.2 3 4 5 log2 friedman_mse 0.75 50: Weighted 0.815957 (0.070917)\n",
      "0.2 3 4 5 log2 friedman_mse 0.75 50: Macro 0.714241 (0.106044)\n",
      "Testing 4518/5184\n",
      "0.2 3 4 5 log2 friedman_mse 0.75 100: Weighted 0.801895 (0.074941)\n",
      "0.2 3 4 5 log2 friedman_mse 0.75 100: Macro 0.692193 (0.099340)\n",
      "Testing 4519/5184\n",
      "0.2 3 4 5 log2 friedman_mse 0.75 200: Weighted 0.802766 (0.084415)\n",
      "0.2 3 4 5 log2 friedman_mse 0.75 200: Macro 0.696526 (0.112003)\n",
      "Testing 4520/5184\n",
      "0.2 3 4 5 log2 friedman_mse 0.75 500: Weighted 0.806369 (0.064677)\n",
      "0.2 3 4 5 log2 friedman_mse 0.75 500: Macro 0.692161 (0.094728)\n",
      "Testing 4521/5184\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2 3 4 5 log2 friedman_mse 1.0 50: Weighted 0.816466 (0.079878)\n",
      "0.2 3 4 5 log2 friedman_mse 1.0 50: Macro 0.715155 (0.115643)\n",
      "Testing 4522/5184\n",
      "0.2 3 4 5 log2 friedman_mse 1.0 100: Weighted 0.802105 (0.073390)\n",
      "0.2 3 4 5 log2 friedman_mse 1.0 100: Macro 0.692708 (0.119843)\n",
      "Testing 4523/5184\n",
      "0.2 3 4 5 log2 friedman_mse 1.0 200: Weighted 0.792504 (0.065693)\n",
      "0.2 3 4 5 log2 friedman_mse 1.0 200: Macro 0.688470 (0.100315)\n",
      "Testing 4524/5184\n",
      "0.2 3 4 5 log2 friedman_mse 1.0 500: Weighted 0.806751 (0.079748)\n",
      "0.2 3 4 5 log2 friedman_mse 1.0 500: Macro 0.706472 (0.114481)\n",
      "Testing 4525/5184\n",
      "0.2 3 4 5 log2 mae 0.5 50: Weighted 0.788618 (0.079295)\n",
      "0.2 3 4 5 log2 mae 0.5 50: Macro 0.670506 (0.108034)\n",
      "Testing 4526/5184\n",
      "0.2 3 4 5 log2 mae 0.5 100: Weighted 0.801613 (0.078357)\n",
      "0.2 3 4 5 log2 mae 0.5 100: Macro 0.685869 (0.114489)\n",
      "Testing 4527/5184\n",
      "0.2 3 4 5 log2 mae 0.5 200: Weighted 0.779935 (0.071186)\n",
      "0.2 3 4 5 log2 mae 0.5 200: Macro 0.653830 (0.095994)\n",
      "Testing 4528/5184\n",
      "0.2 3 4 5 log2 mae 0.5 500: Weighted 0.778735 (0.078819)\n",
      "0.2 3 4 5 log2 mae 0.5 500: Macro 0.652765 (0.105338)\n",
      "Testing 4529/5184\n",
      "0.2 3 4 5 log2 mae 0.75 50: Weighted 0.777358 (0.064149)\n",
      "0.2 3 4 5 log2 mae 0.75 50: Macro 0.644427 (0.086835)\n",
      "Testing 4530/5184\n",
      "0.2 3 4 5 log2 mae 0.75 100: Weighted 0.761308 (0.083556)\n",
      "0.2 3 4 5 log2 mae 0.75 100: Macro 0.622841 (0.113739)\n",
      "Testing 4531/5184\n",
      "0.2 3 4 5 log2 mae 0.75 200: Weighted 0.812528 (0.066861)\n",
      "0.2 3 4 5 log2 mae 0.75 200: Macro 0.704472 (0.086455)\n",
      "Testing 4532/5184\n",
      "0.2 3 4 5 log2 mae 0.75 500: Weighted 0.786697 (0.085144)\n",
      "0.2 3 4 5 log2 mae 0.75 500: Macro 0.656208 (0.122922)\n",
      "Testing 4533/5184\n",
      "0.2 3 4 5 log2 mae 1.0 50: Weighted 0.779860 (0.086349)\n",
      "0.2 3 4 5 log2 mae 1.0 50: Macro 0.659750 (0.128382)\n",
      "Testing 4534/5184\n",
      "0.2 3 4 5 log2 mae 1.0 100: Weighted 0.768576 (0.087694)\n",
      "0.2 3 4 5 log2 mae 1.0 100: Macro 0.629735 (0.123325)\n",
      "Testing 4535/5184\n",
      "0.2 3 4 5 log2 mae 1.0 200: Weighted 0.776607 (0.074020)\n",
      "0.2 3 4 5 log2 mae 1.0 200: Macro 0.642189 (0.103935)\n",
      "Testing 4536/5184\n",
      "0.2 3 4 5 log2 mae 1.0 500: Weighted 0.772577 (0.094866)\n",
      "0.2 3 4 5 log2 mae 1.0 500: Macro 0.645795 (0.134686)\n",
      "Testing 4537/5184\n",
      "0.2 3 4 5 sqrt friedman_mse 0.5 50: Weighted 0.820665 (0.061939)\n",
      "0.2 3 4 5 sqrt friedman_mse 0.5 50: Macro 0.723866 (0.076230)\n",
      "Testing 4538/5184\n",
      "0.2 3 4 5 sqrt friedman_mse 0.5 100: Weighted 0.812300 (0.073489)\n",
      "0.2 3 4 5 sqrt friedman_mse 0.5 100: Macro 0.711039 (0.111290)\n",
      "Testing 4539/5184\n",
      "0.2 3 4 5 sqrt friedman_mse 0.5 200: Weighted 0.802425 (0.074245)\n",
      "0.2 3 4 5 sqrt friedman_mse 0.5 200: Macro 0.688790 (0.108365)\n",
      "Testing 4540/5184\n",
      "0.2 3 4 5 sqrt friedman_mse 0.5 500: Weighted 0.820219 (0.056790)\n",
      "0.2 3 4 5 sqrt friedman_mse 0.5 500: Macro 0.719871 (0.101501)\n",
      "Testing 4541/5184\n",
      "0.2 3 4 5 sqrt friedman_mse 0.75 50: Weighted 0.808700 (0.061733)\n",
      "0.2 3 4 5 sqrt friedman_mse 0.75 50: Macro 0.715193 (0.091764)\n",
      "Testing 4542/5184\n",
      "0.2 3 4 5 sqrt friedman_mse 0.75 100: Weighted 0.811705 (0.084397)\n",
      "0.2 3 4 5 sqrt friedman_mse 0.75 100: Macro 0.703210 (0.113650)\n",
      "Testing 4543/5184\n",
      "0.2 3 4 5 sqrt friedman_mse 0.75 200: Weighted 0.813223 (0.071449)\n",
      "0.2 3 4 5 sqrt friedman_mse 0.75 200: Macro 0.702452 (0.111912)\n",
      "Testing 4544/5184\n",
      "0.2 3 4 5 sqrt friedman_mse 0.75 500: Weighted 0.810108 (0.086858)\n",
      "0.2 3 4 5 sqrt friedman_mse 0.75 500: Macro 0.700339 (0.134680)\n",
      "Testing 4545/5184\n",
      "0.2 3 4 5 sqrt friedman_mse 1.0 50: Weighted 0.804987 (0.080857)\n",
      "0.2 3 4 5 sqrt friedman_mse 1.0 50: Macro 0.698672 (0.123384)\n",
      "Testing 4546/5184\n",
      "0.2 3 4 5 sqrt friedman_mse 1.0 100: Weighted 0.808097 (0.081282)\n",
      "0.2 3 4 5 sqrt friedman_mse 1.0 100: Macro 0.704544 (0.116705)\n",
      "Testing 4547/5184\n",
      "0.2 3 4 5 sqrt friedman_mse 1.0 200: Weighted 0.808533 (0.075805)\n",
      "0.2 3 4 5 sqrt friedman_mse 1.0 200: Macro 0.709942 (0.108733)\n",
      "Testing 4548/5184\n",
      "0.2 3 4 5 sqrt friedman_mse 1.0 500: Weighted 0.807299 (0.081755)\n",
      "0.2 3 4 5 sqrt friedman_mse 1.0 500: Macro 0.701745 (0.114325)\n",
      "Testing 4549/5184\n",
      "0.2 3 4 5 sqrt mae 0.5 50: Weighted 0.788955 (0.069446)\n",
      "0.2 3 4 5 sqrt mae 0.5 50: Macro 0.662763 (0.100690)\n",
      "Testing 4550/5184\n",
      "0.2 3 4 5 sqrt mae 0.5 100: Weighted 0.804643 (0.089895)\n",
      "0.2 3 4 5 sqrt mae 0.5 100: Macro 0.683122 (0.127683)\n",
      "Testing 4551/5184\n",
      "0.2 3 4 5 sqrt mae 0.5 200: Weighted 0.789334 (0.066440)\n",
      "0.2 3 4 5 sqrt mae 0.5 200: Macro 0.662221 (0.094009)\n",
      "Testing 4552/5184\n",
      "0.2 3 4 5 sqrt mae 0.5 500: Weighted 0.774687 (0.071422)\n",
      "0.2 3 4 5 sqrt mae 0.5 500: Macro 0.648437 (0.094271)\n",
      "Testing 4553/5184\n",
      "0.2 3 4 5 sqrt mae 0.75 50: Weighted 0.758767 (0.072736)\n",
      "0.2 3 4 5 sqrt mae 0.75 50: Macro 0.608681 (0.101720)\n",
      "Testing 4554/5184\n",
      "0.2 3 4 5 sqrt mae 0.75 100: Weighted 0.782438 (0.085189)\n",
      "0.2 3 4 5 sqrt mae 0.75 100: Macro 0.658257 (0.114477)\n",
      "Testing 4555/5184\n",
      "0.2 3 4 5 sqrt mae 0.75 200: Weighted 0.799434 (0.083728)\n",
      "0.2 3 4 5 sqrt mae 0.75 200: Macro 0.684718 (0.114982)\n",
      "Testing 4556/5184\n",
      "0.2 3 4 5 sqrt mae 0.75 500: Weighted 0.792786 (0.071942)\n",
      "0.2 3 4 5 sqrt mae 0.75 500: Macro 0.676064 (0.101826)\n",
      "Testing 4557/5184\n",
      "0.2 3 4 5 sqrt mae 1.0 50: Weighted 0.783688 (0.060819)\n",
      "0.2 3 4 5 sqrt mae 1.0 50: Macro 0.659081 (0.079428)\n",
      "Testing 4558/5184\n",
      "0.2 3 4 5 sqrt mae 1.0 100: Weighted 0.770345 (0.075953)\n",
      "0.2 3 4 5 sqrt mae 1.0 100: Macro 0.627443 (0.106438)\n",
      "Testing 4559/5184\n",
      "0.2 3 4 5 sqrt mae 1.0 200: Weighted 0.764098 (0.084997)\n",
      "0.2 3 4 5 sqrt mae 1.0 200: Macro 0.624412 (0.113713)\n",
      "Testing 4560/5184\n",
      "0.2 3 4 5 sqrt mae 1.0 500: Weighted 0.770591 (0.075718)\n",
      "0.2 3 4 5 sqrt mae 1.0 500: Macro 0.635838 (0.109657)\n",
      "Testing 4561/5184\n",
      "0.2 3 4 8 log2 friedman_mse 0.5 50: Weighted 0.825651 (0.069396)\n",
      "0.2 3 4 8 log2 friedman_mse 0.5 50: Macro 0.732176 (0.106805)\n",
      "Testing 4562/5184\n",
      "0.2 3 4 8 log2 friedman_mse 0.5 100: Weighted 0.818933 (0.071108)\n",
      "0.2 3 4 8 log2 friedman_mse 0.5 100: Macro 0.711016 (0.122468)\n",
      "Testing 4563/5184\n",
      "0.2 3 4 8 log2 friedman_mse 0.5 200: Weighted 0.821086 (0.076740)\n",
      "0.2 3 4 8 log2 friedman_mse 0.5 200: Macro 0.715665 (0.114390)\n",
      "Testing 4564/5184\n",
      "0.2 3 4 8 log2 friedman_mse 0.5 500: Weighted 0.797773 (0.066572)\n",
      "0.2 3 4 8 log2 friedman_mse 0.5 500: Macro 0.687569 (0.103804)\n",
      "Testing 4565/5184\n",
      "0.2 3 4 8 log2 friedman_mse 0.75 50: Weighted 0.810121 (0.098294)\n",
      "0.2 3 4 8 log2 friedman_mse 0.75 50: Macro 0.707675 (0.142258)\n",
      "Testing 4566/5184\n",
      "0.2 3 4 8 log2 friedman_mse 0.75 100: Weighted 0.826624 (0.080708)\n",
      "0.2 3 4 8 log2 friedman_mse 0.75 100: Macro 0.722703 (0.124156)\n",
      "Testing 4567/5184\n",
      "0.2 3 4 8 log2 friedman_mse 0.75 200: Weighted 0.813858 (0.083176)\n",
      "0.2 3 4 8 log2 friedman_mse 0.75 200: Macro 0.704140 (0.121535)\n",
      "Testing 4568/5184\n",
      "0.2 3 4 8 log2 friedman_mse 0.75 500: Weighted 0.819424 (0.063444)\n",
      "0.2 3 4 8 log2 friedman_mse 0.75 500: Macro 0.722525 (0.091439)\n",
      "Testing 4569/5184\n",
      "0.2 3 4 8 log2 friedman_mse 1.0 50: Weighted 0.802362 (0.085299)\n",
      "0.2 3 4 8 log2 friedman_mse 1.0 50: Macro 0.707948 (0.114496)\n",
      "Testing 4570/5184\n",
      "0.2 3 4 8 log2 friedman_mse 1.0 100: Weighted 0.786483 (0.098177)\n",
      "0.2 3 4 8 log2 friedman_mse 1.0 100: Macro 0.678517 (0.138156)\n",
      "Testing 4571/5184\n",
      "0.2 3 4 8 log2 friedman_mse 1.0 200: Weighted 0.798333 (0.099517)\n",
      "0.2 3 4 8 log2 friedman_mse 1.0 200: Macro 0.695791 (0.143846)\n",
      "Testing 4572/5184\n",
      "0.2 3 4 8 log2 friedman_mse 1.0 500: Weighted 0.792128 (0.064277)\n",
      "0.2 3 4 8 log2 friedman_mse 1.0 500: Macro 0.686868 (0.092659)\n",
      "Testing 4573/5184\n",
      "0.2 3 4 8 log2 mae 0.5 50: Weighted 0.807458 (0.050440)\n",
      "0.2 3 4 8 log2 mae 0.5 50: Macro 0.690564 (0.060694)\n",
      "Testing 4574/5184\n",
      "0.2 3 4 8 log2 mae 0.5 100: Weighted 0.823336 (0.075236)\n",
      "0.2 3 4 8 log2 mae 0.5 100: Macro 0.726451 (0.108474)\n",
      "Testing 4575/5184\n",
      "0.2 3 4 8 log2 mae 0.5 200: Weighted 0.824459 (0.072104)\n",
      "0.2 3 4 8 log2 mae 0.5 200: Macro 0.715194 (0.104070)\n",
      "Testing 4576/5184\n",
      "0.2 3 4 8 log2 mae 0.5 500: Weighted 0.806819 (0.079062)\n",
      "0.2 3 4 8 log2 mae 0.5 500: Macro 0.695208 (0.119606)\n",
      "Testing 4577/5184\n",
      "0.2 3 4 8 log2 mae 0.75 50: Weighted 0.784042 (0.093021)\n",
      "0.2 3 4 8 log2 mae 0.75 50: Macro 0.656121 (0.144798)\n",
      "Testing 4578/5184\n",
      "0.2 3 4 8 log2 mae 0.75 100: Weighted 0.803177 (0.079945)\n",
      "0.2 3 4 8 log2 mae 0.75 100: Macro 0.689611 (0.109269)\n",
      "Testing 4579/5184\n",
      "0.2 3 4 8 log2 mae 0.75 200: Weighted 0.788304 (0.089611)\n",
      "0.2 3 4 8 log2 mae 0.75 200: Macro 0.667001 (0.132098)\n",
      "Testing 4580/5184\n",
      "0.2 3 4 8 log2 mae 0.75 500: Weighted 0.802413 (0.084312)\n",
      "0.2 3 4 8 log2 mae 0.75 500: Macro 0.686297 (0.121493)\n",
      "Testing 4581/5184\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2 3 4 8 log2 mae 1.0 50: Weighted 0.765628 (0.091346)\n",
      "0.2 3 4 8 log2 mae 1.0 50: Macro 0.628756 (0.121981)\n",
      "Testing 4582/5184\n",
      "0.2 3 4 8 log2 mae 1.0 100: Weighted 0.786713 (0.081287)\n",
      "0.2 3 4 8 log2 mae 1.0 100: Macro 0.653970 (0.113719)\n",
      "Testing 4583/5184\n",
      "0.2 3 4 8 log2 mae 1.0 200: Weighted 0.799774 (0.098527)\n",
      "0.2 3 4 8 log2 mae 1.0 200: Macro 0.691280 (0.142270)\n",
      "Testing 4584/5184\n",
      "0.2 3 4 8 log2 mae 1.0 500: Weighted 0.787158 (0.102106)\n",
      "0.2 3 4 8 log2 mae 1.0 500: Macro 0.663064 (0.148140)\n",
      "Testing 4585/5184\n",
      "0.2 3 4 8 sqrt friedman_mse 0.5 50: Weighted 0.835743 (0.071339)\n",
      "0.2 3 4 8 sqrt friedman_mse 0.5 50: Macro 0.740672 (0.101948)\n",
      "Testing 4586/5184\n",
      "0.2 3 4 8 sqrt friedman_mse 0.5 100: Weighted 0.809029 (0.065680)\n",
      "0.2 3 4 8 sqrt friedman_mse 0.5 100: Macro 0.713925 (0.093550)\n",
      "Testing 4587/5184\n",
      "0.2 3 4 8 sqrt friedman_mse 0.5 200: Weighted 0.808538 (0.046507)\n",
      "0.2 3 4 8 sqrt friedman_mse 0.5 200: Macro 0.707611 (0.068909)\n",
      "Testing 4588/5184\n",
      "0.2 3 4 8 sqrt friedman_mse 0.5 500: Weighted 0.826183 (0.064900)\n",
      "0.2 3 4 8 sqrt friedman_mse 0.5 500: Macro 0.726820 (0.102201)\n",
      "Testing 4589/5184\n",
      "0.2 3 4 8 sqrt friedman_mse 0.75 50: Weighted 0.801592 (0.069705)\n",
      "0.2 3 4 8 sqrt friedman_mse 0.75 50: Macro 0.688154 (0.095172)\n",
      "Testing 4590/5184\n",
      "0.2 3 4 8 sqrt friedman_mse 0.75 100: Weighted 0.786994 (0.063675)\n",
      "0.2 3 4 8 sqrt friedman_mse 0.75 100: Macro 0.667760 (0.098200)\n",
      "Testing 4591/5184\n",
      "0.2 3 4 8 sqrt friedman_mse 0.75 200: Weighted 0.817840 (0.069047)\n",
      "0.2 3 4 8 sqrt friedman_mse 0.75 200: Macro 0.715786 (0.102428)\n",
      "Testing 4592/5184\n",
      "0.2 3 4 8 sqrt friedman_mse 0.75 500: Weighted 0.819561 (0.098010)\n",
      "0.2 3 4 8 sqrt friedman_mse 0.75 500: Macro 0.718999 (0.147340)\n",
      "Testing 4593/5184\n",
      "0.2 3 4 8 sqrt friedman_mse 1.0 50: Weighted 0.806305 (0.089705)\n",
      "0.2 3 4 8 sqrt friedman_mse 1.0 50: Macro 0.699319 (0.129538)\n",
      "Testing 4594/5184\n",
      "0.2 3 4 8 sqrt friedman_mse 1.0 100: Weighted 0.806423 (0.093055)\n",
      "0.2 3 4 8 sqrt friedman_mse 1.0 100: Macro 0.718724 (0.124084)\n",
      "Testing 4595/5184\n",
      "0.2 3 4 8 sqrt friedman_mse 1.0 200: Weighted 0.790917 (0.079962)\n",
      "0.2 3 4 8 sqrt friedman_mse 1.0 200: Macro 0.676305 (0.110724)\n",
      "Testing 4596/5184\n",
      "0.2 3 4 8 sqrt friedman_mse 1.0 500: Weighted 0.814136 (0.087879)\n",
      "0.2 3 4 8 sqrt friedman_mse 1.0 500: Macro 0.702700 (0.129848)\n",
      "Testing 4597/5184\n",
      "0.2 3 4 8 sqrt mae 0.5 50: Weighted 0.798220 (0.081299)\n",
      "0.2 3 4 8 sqrt mae 0.5 50: Macro 0.684948 (0.110082)\n",
      "Testing 4598/5184\n",
      "0.2 3 4 8 sqrt mae 0.5 100: Weighted 0.805184 (0.082261)\n",
      "0.2 3 4 8 sqrt mae 0.5 100: Macro 0.689765 (0.119183)\n",
      "Testing 4599/5184\n",
      "0.2 3 4 8 sqrt mae 0.5 200: Weighted 0.789695 (0.077907)\n",
      "0.2 3 4 8 sqrt mae 0.5 200: Macro 0.678856 (0.104507)\n",
      "Testing 4600/5184\n",
      "0.2 3 4 8 sqrt mae 0.5 500: Weighted 0.789685 (0.078165)\n",
      "0.2 3 4 8 sqrt mae 0.5 500: Macro 0.669118 (0.109937)\n",
      "Testing 4601/5184\n",
      "0.2 3 4 8 sqrt mae 0.75 50: Weighted 0.784710 (0.082003)\n",
      "0.2 3 4 8 sqrt mae 0.75 50: Macro 0.652250 (0.115003)\n",
      "Testing 4602/5184\n",
      "0.2 3 4 8 sqrt mae 0.75 100: Weighted 0.807297 (0.077319)\n",
      "0.2 3 4 8 sqrt mae 0.75 100: Macro 0.693500 (0.107438)\n",
      "Testing 4603/5184\n",
      "0.2 3 4 8 sqrt mae 0.75 200: Weighted 0.792889 (0.095223)\n",
      "0.2 3 4 8 sqrt mae 0.75 200: Macro 0.678163 (0.139727)\n",
      "Testing 4604/5184\n",
      "0.2 3 4 8 sqrt mae 0.75 500: Weighted 0.786563 (0.059859)\n",
      "0.2 3 4 8 sqrt mae 0.75 500: Macro 0.659759 (0.082948)\n",
      "Testing 4605/5184\n",
      "0.2 3 4 8 sqrt mae 1.0 50: Weighted 0.778706 (0.078168)\n",
      "0.2 3 4 8 sqrt mae 1.0 50: Macro 0.641597 (0.108552)\n",
      "Testing 4606/5184\n",
      "0.2 3 4 8 sqrt mae 1.0 100: Weighted 0.770557 (0.065507)\n",
      "0.2 3 4 8 sqrt mae 1.0 100: Macro 0.640761 (0.100063)\n",
      "Testing 4607/5184\n",
      "0.2 3 4 8 sqrt mae 1.0 200: Weighted 0.773302 (0.091275)\n",
      "0.2 3 4 8 sqrt mae 1.0 200: Macro 0.629129 (0.125370)\n",
      "Testing 4608/5184\n",
      "0.2 3 4 8 sqrt mae 1.0 500: Weighted 0.771207 (0.083790)\n",
      "0.2 3 4 8 sqrt mae 1.0 500: Macro 0.632743 (0.120429)\n",
      "Testing 4609/5184\n",
      "0.2 3 6 3 log2 friedman_mse 0.5 50: Weighted 0.815769 (0.038699)\n",
      "0.2 3 6 3 log2 friedman_mse 0.5 50: Macro 0.700844 (0.060880)\n",
      "Testing 4610/5184\n",
      "0.2 3 6 3 log2 friedman_mse 0.5 100: Weighted 0.810544 (0.057649)\n",
      "0.2 3 6 3 log2 friedman_mse 0.5 100: Macro 0.702308 (0.086947)\n",
      "Testing 4611/5184\n",
      "0.2 3 6 3 log2 friedman_mse 0.5 200: Weighted 0.816087 (0.057304)\n",
      "0.2 3 6 3 log2 friedman_mse 0.5 200: Macro 0.714693 (0.083667)\n",
      "Testing 4612/5184\n",
      "0.2 3 6 3 log2 friedman_mse 0.5 500: Weighted 0.813019 (0.064629)\n",
      "0.2 3 6 3 log2 friedman_mse 0.5 500: Macro 0.720241 (0.090047)\n",
      "Testing 4613/5184\n",
      "0.2 3 6 3 log2 friedman_mse 0.75 50: Weighted 0.800563 (0.081780)\n",
      "0.2 3 6 3 log2 friedman_mse 0.75 50: Macro 0.697481 (0.108758)\n",
      "Testing 4614/5184\n",
      "0.2 3 6 3 log2 friedman_mse 0.75 100: Weighted 0.814491 (0.085754)\n",
      "0.2 3 6 3 log2 friedman_mse 0.75 100: Macro 0.712554 (0.122378)\n",
      "Testing 4615/5184\n",
      "0.2 3 6 3 log2 friedman_mse 0.75 200: Weighted 0.798314 (0.053976)\n",
      "0.2 3 6 3 log2 friedman_mse 0.75 200: Macro 0.686291 (0.071122)\n",
      "Testing 4616/5184\n",
      "0.2 3 6 3 log2 friedman_mse 0.75 500: Weighted 0.810110 (0.052979)\n",
      "0.2 3 6 3 log2 friedman_mse 0.75 500: Macro 0.705559 (0.065782)\n",
      "Testing 4617/5184\n",
      "0.2 3 6 3 log2 friedman_mse 1.0 50: Weighted 0.818147 (0.048229)\n",
      "0.2 3 6 3 log2 friedman_mse 1.0 50: Macro 0.723081 (0.066124)\n",
      "Testing 4618/5184\n",
      "0.2 3 6 3 log2 friedman_mse 1.0 100: Weighted 0.826795 (0.059573)\n",
      "0.2 3 6 3 log2 friedman_mse 1.0 100: Macro 0.735054 (0.085954)\n",
      "Testing 4619/5184\n",
      "0.2 3 6 3 log2 friedman_mse 1.0 200: Weighted 0.801703 (0.063701)\n",
      "0.2 3 6 3 log2 friedman_mse 1.0 200: Macro 0.697835 (0.098947)\n",
      "Testing 4620/5184\n",
      "0.2 3 6 3 log2 friedman_mse 1.0 500: Weighted 0.810898 (0.067616)\n",
      "0.2 3 6 3 log2 friedman_mse 1.0 500: Macro 0.711008 (0.096966)\n",
      "Testing 4621/5184\n",
      "0.2 3 6 3 log2 mae 0.5 50: Weighted 0.790828 (0.078020)\n",
      "0.2 3 6 3 log2 mae 0.5 50: Macro 0.670922 (0.117502)\n",
      "Testing 4622/5184\n",
      "0.2 3 6 3 log2 mae 0.5 100: Weighted 0.772926 (0.053584)\n",
      "0.2 3 6 3 log2 mae 0.5 100: Macro 0.634087 (0.076447)\n",
      "Testing 4623/5184\n",
      "0.2 3 6 3 log2 mae 0.5 200: Weighted 0.787342 (0.072053)\n",
      "0.2 3 6 3 log2 mae 0.5 200: Macro 0.667501 (0.093464)\n",
      "Testing 4624/5184\n",
      "0.2 3 6 3 log2 mae 0.5 500: Weighted 0.803469 (0.069664)\n",
      "0.2 3 6 3 log2 mae 0.5 500: Macro 0.691173 (0.100829)\n",
      "Testing 4625/5184\n",
      "0.2 3 6 3 log2 mae 0.75 50: Weighted 0.793012 (0.073721)\n",
      "0.2 3 6 3 log2 mae 0.75 50: Macro 0.685135 (0.098879)\n",
      "Testing 4626/5184\n",
      "0.2 3 6 3 log2 mae 0.75 100: Weighted 0.783338 (0.084130)\n",
      "0.2 3 6 3 log2 mae 0.75 100: Macro 0.653925 (0.118573)\n",
      "Testing 4627/5184\n",
      "0.2 3 6 3 log2 mae 0.75 200: Weighted 0.784070 (0.063591)\n",
      "0.2 3 6 3 log2 mae 0.75 200: Macro 0.654510 (0.087252)\n",
      "Testing 4628/5184\n",
      "0.2 3 6 3 log2 mae 0.75 500: Weighted 0.778354 (0.078489)\n",
      "0.2 3 6 3 log2 mae 0.75 500: Macro 0.649900 (0.108023)\n",
      "Testing 4629/5184\n",
      "0.2 3 6 3 log2 mae 1.0 50: Weighted 0.762142 (0.055551)\n",
      "0.2 3 6 3 log2 mae 1.0 50: Macro 0.621561 (0.080167)\n",
      "Testing 4630/5184\n",
      "0.2 3 6 3 log2 mae 1.0 100: Weighted 0.774425 (0.077503)\n",
      "0.2 3 6 3 log2 mae 1.0 100: Macro 0.636960 (0.109510)\n",
      "Testing 4631/5184\n",
      "0.2 3 6 3 log2 mae 1.0 200: Weighted 0.777794 (0.079307)\n",
      "0.2 3 6 3 log2 mae 1.0 200: Macro 0.643030 (0.107962)\n",
      "Testing 4632/5184\n",
      "0.2 3 6 3 log2 mae 1.0 500: Weighted 0.794592 (0.063210)\n",
      "0.2 3 6 3 log2 mae 1.0 500: Macro 0.669697 (0.095036)\n",
      "Testing 4633/5184\n",
      "0.2 3 6 3 sqrt friedman_mse 0.5 50: Weighted 0.812170 (0.053359)\n",
      "0.2 3 6 3 sqrt friedman_mse 0.5 50: Macro 0.702235 (0.089767)\n",
      "Testing 4634/5184\n",
      "0.2 3 6 3 sqrt friedman_mse 0.5 100: Weighted 0.789487 (0.059693)\n",
      "0.2 3 6 3 sqrt friedman_mse 0.5 100: Macro 0.682623 (0.079347)\n",
      "Testing 4635/5184\n",
      "0.2 3 6 3 sqrt friedman_mse 0.5 200: Weighted 0.797430 (0.053493)\n",
      "0.2 3 6 3 sqrt friedman_mse 0.5 200: Macro 0.682418 (0.073413)\n",
      "Testing 4636/5184\n",
      "0.2 3 6 3 sqrt friedman_mse 0.5 500: Weighted 0.797869 (0.069811)\n",
      "0.2 3 6 3 sqrt friedman_mse 0.5 500: Macro 0.686856 (0.097780)\n",
      "Testing 4637/5184\n",
      "0.2 3 6 3 sqrt friedman_mse 0.75 50: Weighted 0.788056 (0.064259)\n",
      "0.2 3 6 3 sqrt friedman_mse 0.75 50: Macro 0.671209 (0.081961)\n",
      "Testing 4638/5184\n",
      "0.2 3 6 3 sqrt friedman_mse 0.75 100: Weighted 0.811599 (0.044734)\n",
      "0.2 3 6 3 sqrt friedman_mse 0.75 100: Macro 0.704062 (0.065961)\n",
      "Testing 4639/5184\n",
      "0.2 3 6 3 sqrt friedman_mse 0.75 200: Weighted 0.801334 (0.067569)\n",
      "0.2 3 6 3 sqrt friedman_mse 0.75 200: Macro 0.700527 (0.107091)\n",
      "Testing 4640/5184\n",
      "0.2 3 6 3 sqrt friedman_mse 0.75 500: Weighted 0.814841 (0.060608)\n",
      "0.2 3 6 3 sqrt friedman_mse 0.75 500: Macro 0.717863 (0.087036)\n",
      "Testing 4641/5184\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2 3 6 3 sqrt friedman_mse 1.0 50: Weighted 0.817736 (0.059110)\n",
      "0.2 3 6 3 sqrt friedman_mse 1.0 50: Macro 0.714664 (0.075418)\n",
      "Testing 4642/5184\n",
      "0.2 3 6 3 sqrt friedman_mse 1.0 100: Weighted 0.812535 (0.064146)\n",
      "0.2 3 6 3 sqrt friedman_mse 1.0 100: Macro 0.710469 (0.095534)\n",
      "Testing 4643/5184\n",
      "0.2 3 6 3 sqrt friedman_mse 1.0 200: Weighted 0.792534 (0.065269)\n",
      "0.2 3 6 3 sqrt friedman_mse 1.0 200: Macro 0.693061 (0.092825)\n",
      "Testing 4644/5184\n",
      "0.2 3 6 3 sqrt friedman_mse 1.0 500: Weighted 0.811576 (0.054947)\n",
      "0.2 3 6 3 sqrt friedman_mse 1.0 500: Macro 0.717175 (0.080458)\n",
      "Testing 4645/5184\n",
      "0.2 3 6 3 sqrt mae 0.5 50: Weighted 0.791521 (0.068979)\n",
      "0.2 3 6 3 sqrt mae 0.5 50: Macro 0.669276 (0.091858)\n",
      "Testing 4646/5184\n",
      "0.2 3 6 3 sqrt mae 0.5 100: Weighted 0.794323 (0.083273)\n",
      "0.2 3 6 3 sqrt mae 0.5 100: Macro 0.678331 (0.125923)\n",
      "Testing 4647/5184\n",
      "0.2 3 6 3 sqrt mae 0.5 200: Weighted 0.772322 (0.067892)\n",
      "0.2 3 6 3 sqrt mae 0.5 200: Macro 0.641259 (0.089638)\n",
      "Testing 4648/5184\n",
      "0.2 3 6 3 sqrt mae 0.5 500: Weighted 0.796192 (0.065837)\n",
      "0.2 3 6 3 sqrt mae 0.5 500: Macro 0.682384 (0.087330)\n",
      "Testing 4649/5184\n",
      "0.2 3 6 3 sqrt mae 0.75 50: Weighted 0.774261 (0.063602)\n",
      "0.2 3 6 3 sqrt mae 0.75 50: Macro 0.646519 (0.094263)\n",
      "Testing 4650/5184\n",
      "0.2 3 6 3 sqrt mae 0.75 100: Weighted 0.777041 (0.069866)\n",
      "0.2 3 6 3 sqrt mae 0.75 100: Macro 0.652717 (0.100093)\n",
      "Testing 4651/5184\n",
      "0.2 3 6 3 sqrt mae 0.75 200: Weighted 0.778805 (0.079871)\n",
      "0.2 3 6 3 sqrt mae 0.75 200: Macro 0.648729 (0.117031)\n",
      "Testing 4652/5184\n",
      "0.2 3 6 3 sqrt mae 0.75 500: Weighted 0.780328 (0.077558)\n",
      "0.2 3 6 3 sqrt mae 0.75 500: Macro 0.654802 (0.103431)\n",
      "Testing 4653/5184\n",
      "0.2 3 6 3 sqrt mae 1.0 50: Weighted 0.763049 (0.047016)\n",
      "0.2 3 6 3 sqrt mae 1.0 50: Macro 0.632946 (0.058384)\n",
      "Testing 4654/5184\n",
      "0.2 3 6 3 sqrt mae 1.0 100: Weighted 0.743139 (0.062557)\n",
      "0.2 3 6 3 sqrt mae 1.0 100: Macro 0.599672 (0.085221)\n",
      "Testing 4655/5184\n",
      "0.2 3 6 3 sqrt mae 1.0 200: Weighted 0.779017 (0.092744)\n",
      "0.2 3 6 3 sqrt mae 1.0 200: Macro 0.647144 (0.136172)\n",
      "Testing 4656/5184\n",
      "0.2 3 6 3 sqrt mae 1.0 500: Weighted 0.783797 (0.051260)\n",
      "0.2 3 6 3 sqrt mae 1.0 500: Macro 0.641699 (0.069055)\n",
      "Testing 4657/5184\n",
      "0.2 3 6 5 log2 friedman_mse 0.5 50: Weighted 0.801404 (0.062164)\n",
      "0.2 3 6 5 log2 friedman_mse 0.5 50: Macro 0.685518 (0.090568)\n",
      "Testing 4658/5184\n",
      "0.2 3 6 5 log2 friedman_mse 0.5 100: Weighted 0.825445 (0.075734)\n",
      "0.2 3 6 5 log2 friedman_mse 0.5 100: Macro 0.731458 (0.116072)\n",
      "Testing 4659/5184\n",
      "0.2 3 6 5 log2 friedman_mse 0.5 200: Weighted 0.815205 (0.060014)\n",
      "0.2 3 6 5 log2 friedman_mse 0.5 200: Macro 0.719143 (0.088340)\n",
      "Testing 4660/5184\n",
      "0.2 3 6 5 log2 friedman_mse 0.5 500: Weighted 0.791747 (0.063729)\n",
      "0.2 3 6 5 log2 friedman_mse 0.5 500: Macro 0.669360 (0.080113)\n",
      "Testing 4661/5184\n",
      "0.2 3 6 5 log2 friedman_mse 0.75 50: Weighted 0.812959 (0.088188)\n",
      "0.2 3 6 5 log2 friedman_mse 0.75 50: Macro 0.707674 (0.123686)\n",
      "Testing 4662/5184\n",
      "0.2 3 6 5 log2 friedman_mse 0.75 100: Weighted 0.801402 (0.077085)\n",
      "0.2 3 6 5 log2 friedman_mse 0.75 100: Macro 0.687328 (0.112142)\n",
      "Testing 4663/5184\n",
      "0.2 3 6 5 log2 friedman_mse 0.75 200: Weighted 0.818131 (0.070355)\n",
      "0.2 3 6 5 log2 friedman_mse 0.75 200: Macro 0.718928 (0.107196)\n",
      "Testing 4664/5184\n",
      "0.2 3 6 5 log2 friedman_mse 0.75 500: Weighted 0.791909 (0.071545)\n",
      "0.2 3 6 5 log2 friedman_mse 0.75 500: Macro 0.689550 (0.106154)\n",
      "Testing 4665/5184\n",
      "0.2 3 6 5 log2 friedman_mse 1.0 50: Weighted 0.800841 (0.083251)\n",
      "0.2 3 6 5 log2 friedman_mse 1.0 50: Macro 0.685554 (0.122441)\n",
      "Testing 4666/5184\n",
      "0.2 3 6 5 log2 friedman_mse 1.0 100: Weighted 0.811253 (0.085098)\n",
      "0.2 3 6 5 log2 friedman_mse 1.0 100: Macro 0.702083 (0.127208)\n",
      "Testing 4667/5184\n",
      "0.2 3 6 5 log2 friedman_mse 1.0 200: Weighted 0.806812 (0.080609)\n",
      "0.2 3 6 5 log2 friedman_mse 1.0 200: Macro 0.697681 (0.124667)\n",
      "Testing 4668/5184\n",
      "0.2 3 6 5 log2 friedman_mse 1.0 500: Weighted 0.819831 (0.097944)\n",
      "0.2 3 6 5 log2 friedman_mse 1.0 500: Macro 0.729848 (0.142265)\n",
      "Testing 4669/5184\n",
      "0.2 3 6 5 log2 mae 0.5 50: Weighted 0.798912 (0.068957)\n",
      "0.2 3 6 5 log2 mae 0.5 50: Macro 0.673182 (0.111639)\n",
      "Testing 4670/5184\n",
      "0.2 3 6 5 log2 mae 0.5 100: Weighted 0.802723 (0.080658)\n",
      "0.2 3 6 5 log2 mae 0.5 100: Macro 0.691111 (0.109312)\n",
      "Testing 4671/5184\n",
      "0.2 3 6 5 log2 mae 0.5 200: Weighted 0.781666 (0.066047)\n",
      "0.2 3 6 5 log2 mae 0.5 200: Macro 0.656584 (0.081086)\n",
      "Testing 4672/5184\n",
      "0.2 3 6 5 log2 mae 0.5 500: Weighted 0.800842 (0.074890)\n",
      "0.2 3 6 5 log2 mae 0.5 500: Macro 0.694218 (0.112686)\n",
      "Testing 4673/5184\n",
      "0.2 3 6 5 log2 mae 0.75 50: Weighted 0.780173 (0.069596)\n",
      "0.2 3 6 5 log2 mae 0.75 50: Macro 0.649961 (0.089856)\n",
      "Testing 4674/5184\n",
      "0.2 3 6 5 log2 mae 0.75 100: Weighted 0.779166 (0.078622)\n",
      "0.2 3 6 5 log2 mae 0.75 100: Macro 0.653697 (0.103696)\n",
      "Testing 4675/5184\n",
      "0.2 3 6 5 log2 mae 0.75 200: Weighted 0.783177 (0.088086)\n",
      "0.2 3 6 5 log2 mae 0.75 200: Macro 0.651833 (0.123691)\n",
      "Testing 4676/5184\n",
      "0.2 3 6 5 log2 mae 0.75 500: Weighted 0.779184 (0.074585)\n",
      "0.2 3 6 5 log2 mae 0.75 500: Macro 0.654436 (0.102544)\n",
      "Testing 4677/5184\n",
      "0.2 3 6 5 log2 mae 1.0 50: Weighted 0.773868 (0.097162)\n",
      "0.2 3 6 5 log2 mae 1.0 50: Macro 0.641694 (0.142506)\n",
      "Testing 4678/5184\n",
      "0.2 3 6 5 log2 mae 1.0 100: Weighted 0.766012 (0.072216)\n",
      "0.2 3 6 5 log2 mae 1.0 100: Macro 0.615816 (0.099347)\n",
      "Testing 4679/5184\n",
      "0.2 3 6 5 log2 mae 1.0 200: Weighted 0.781001 (0.083025)\n",
      "0.2 3 6 5 log2 mae 1.0 200: Macro 0.656116 (0.110330)\n",
      "Testing 4680/5184\n",
      "0.2 3 6 5 log2 mae 1.0 500: Weighted 0.778160 (0.088999)\n",
      "0.2 3 6 5 log2 mae 1.0 500: Macro 0.650237 (0.128761)\n",
      "Testing 4681/5184\n",
      "0.2 3 6 5 sqrt friedman_mse 0.5 50: Weighted 0.822158 (0.052189)\n",
      "0.2 3 6 5 sqrt friedman_mse 0.5 50: Macro 0.722155 (0.068846)\n",
      "Testing 4682/5184\n",
      "0.2 3 6 5 sqrt friedman_mse 0.5 100: Weighted 0.803441 (0.078831)\n",
      "0.2 3 6 5 sqrt friedman_mse 0.5 100: Macro 0.697724 (0.122065)\n",
      "Testing 4683/5184\n",
      "0.2 3 6 5 sqrt friedman_mse 0.5 200: Weighted 0.828869 (0.066462)\n",
      "0.2 3 6 5 sqrt friedman_mse 0.5 200: Macro 0.720771 (0.097226)\n",
      "Testing 4684/5184\n",
      "0.2 3 6 5 sqrt friedman_mse 0.5 500: Weighted 0.811519 (0.053454)\n",
      "0.2 3 6 5 sqrt friedman_mse 0.5 500: Macro 0.712558 (0.080605)\n",
      "Testing 4685/5184\n",
      "0.2 3 6 5 sqrt friedman_mse 0.75 50: Weighted 0.803226 (0.067440)\n",
      "0.2 3 6 5 sqrt friedman_mse 0.75 50: Macro 0.694167 (0.087053)\n",
      "Testing 4686/5184\n",
      "0.2 3 6 5 sqrt friedman_mse 0.75 100: Weighted 0.825207 (0.069953)\n",
      "0.2 3 6 5 sqrt friedman_mse 0.75 100: Macro 0.727343 (0.096811)\n",
      "Testing 4687/5184\n",
      "0.2 3 6 5 sqrt friedman_mse 0.75 200: Weighted 0.821074 (0.084735)\n",
      "0.2 3 6 5 sqrt friedman_mse 0.75 200: Macro 0.725349 (0.130757)\n",
      "Testing 4688/5184\n",
      "0.2 3 6 5 sqrt friedman_mse 0.75 500: Weighted 0.827887 (0.075052)\n",
      "0.2 3 6 5 sqrt friedman_mse 0.75 500: Macro 0.729025 (0.108235)\n",
      "Testing 4689/5184\n",
      "0.2 3 6 5 sqrt friedman_mse 1.0 50: Weighted 0.825728 (0.071113)\n",
      "0.2 3 6 5 sqrt friedman_mse 1.0 50: Macro 0.729255 (0.102970)\n",
      "Testing 4690/5184\n",
      "0.2 3 6 5 sqrt friedman_mse 1.0 100: Weighted 0.802090 (0.063922)\n",
      "0.2 3 6 5 sqrt friedman_mse 1.0 100: Macro 0.694741 (0.093431)\n",
      "Testing 4691/5184\n",
      "0.2 3 6 5 sqrt friedman_mse 1.0 200: Weighted 0.802837 (0.083769)\n",
      "0.2 3 6 5 sqrt friedman_mse 1.0 200: Macro 0.694374 (0.126638)\n",
      "Testing 4692/5184\n",
      "0.2 3 6 5 sqrt friedman_mse 1.0 500: Weighted 0.820249 (0.077180)\n",
      "0.2 3 6 5 sqrt friedman_mse 1.0 500: Macro 0.723459 (0.114973)\n",
      "Testing 4693/5184\n",
      "0.2 3 6 5 sqrt mae 0.5 50: Weighted 0.785433 (0.067343)\n",
      "0.2 3 6 5 sqrt mae 0.5 50: Macro 0.657493 (0.094533)\n",
      "Testing 4694/5184\n",
      "0.2 3 6 5 sqrt mae 0.5 100: Weighted 0.800097 (0.078033)\n",
      "0.2 3 6 5 sqrt mae 0.5 100: Macro 0.683407 (0.111402)\n",
      "Testing 4695/5184\n",
      "0.2 3 6 5 sqrt mae 0.5 200: Weighted 0.796958 (0.087474)\n",
      "0.2 3 6 5 sqrt mae 0.5 200: Macro 0.676723 (0.116734)\n",
      "Testing 4696/5184\n",
      "0.2 3 6 5 sqrt mae 0.5 500: Weighted 0.787371 (0.078908)\n",
      "0.2 3 6 5 sqrt mae 0.5 500: Macro 0.682451 (0.107268)\n",
      "Testing 4697/5184\n",
      "0.2 3 6 5 sqrt mae 0.75 50: Weighted 0.776638 (0.062043)\n",
      "0.2 3 6 5 sqrt mae 0.75 50: Macro 0.662963 (0.077725)\n",
      "Testing 4698/5184\n",
      "0.2 3 6 5 sqrt mae 0.75 100: Weighted 0.767559 (0.081642)\n",
      "0.2 3 6 5 sqrt mae 0.75 100: Macro 0.632654 (0.108692)\n",
      "Testing 4699/5184\n",
      "0.2 3 6 5 sqrt mae 0.75 200: Weighted 0.775016 (0.080300)\n",
      "0.2 3 6 5 sqrt mae 0.75 200: Macro 0.632007 (0.112900)\n",
      "Testing 4700/5184\n",
      "0.2 3 6 5 sqrt mae 0.75 500: Weighted 0.768248 (0.075769)\n",
      "0.2 3 6 5 sqrt mae 0.75 500: Macro 0.633436 (0.104748)\n",
      "Testing 4701/5184\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2 3 6 5 sqrt mae 1.0 50: Weighted 0.794032 (0.093811)\n",
      "0.2 3 6 5 sqrt mae 1.0 50: Macro 0.677158 (0.135957)\n",
      "Testing 4702/5184\n",
      "0.2 3 6 5 sqrt mae 1.0 100: Weighted 0.790609 (0.088543)\n",
      "0.2 3 6 5 sqrt mae 1.0 100: Macro 0.666304 (0.125021)\n",
      "Testing 4703/5184\n",
      "0.2 3 6 5 sqrt mae 1.0 200: Weighted 0.778226 (0.077759)\n",
      "0.2 3 6 5 sqrt mae 1.0 200: Macro 0.646340 (0.105187)\n",
      "Testing 4704/5184\n",
      "0.2 3 6 5 sqrt mae 1.0 500: Weighted 0.765849 (0.074381)\n",
      "0.2 3 6 5 sqrt mae 1.0 500: Macro 0.626072 (0.098759)\n",
      "Testing 4705/5184\n",
      "0.2 3 6 8 log2 friedman_mse 0.5 50: Weighted 0.811748 (0.077711)\n",
      "0.2 3 6 8 log2 friedman_mse 0.5 50: Macro 0.716827 (0.101322)\n",
      "Testing 4706/5184\n",
      "0.2 3 6 8 log2 friedman_mse 0.5 100: Weighted 0.813746 (0.080984)\n",
      "0.2 3 6 8 log2 friedman_mse 0.5 100: Macro 0.711714 (0.128062)\n",
      "Testing 4707/5184\n",
      "0.2 3 6 8 log2 friedman_mse 0.5 200: Weighted 0.796331 (0.077125)\n",
      "0.2 3 6 8 log2 friedman_mse 0.5 200: Macro 0.682319 (0.118023)\n",
      "Testing 4708/5184\n",
      "0.2 3 6 8 log2 friedman_mse 0.5 500: Weighted 0.807793 (0.061547)\n",
      "0.2 3 6 8 log2 friedman_mse 0.5 500: Macro 0.707801 (0.098320)\n",
      "Testing 4709/5184\n",
      "0.2 3 6 8 log2 friedman_mse 0.75 50: Weighted 0.807002 (0.089424)\n",
      "0.2 3 6 8 log2 friedman_mse 0.75 50: Macro 0.691692 (0.138848)\n",
      "Testing 4710/5184\n",
      "0.2 3 6 8 log2 friedman_mse 0.75 100: Weighted 0.820103 (0.078702)\n",
      "0.2 3 6 8 log2 friedman_mse 0.75 100: Macro 0.732192 (0.119208)\n",
      "Testing 4711/5184\n",
      "0.2 3 6 8 log2 friedman_mse 0.75 200: Weighted 0.812881 (0.081481)\n",
      "0.2 3 6 8 log2 friedman_mse 0.75 200: Macro 0.712011 (0.126100)\n",
      "Testing 4712/5184\n",
      "0.2 3 6 8 log2 friedman_mse 0.75 500: Weighted 0.819102 (0.081342)\n",
      "0.2 3 6 8 log2 friedman_mse 0.75 500: Macro 0.719619 (0.117071)\n",
      "Testing 4713/5184\n",
      "0.2 3 6 8 log2 friedman_mse 1.0 50: Weighted 0.803851 (0.078622)\n",
      "0.2 3 6 8 log2 friedman_mse 1.0 50: Macro 0.690405 (0.115895)\n",
      "Testing 4714/5184\n",
      "0.2 3 6 8 log2 friedman_mse 1.0 100: Weighted 0.801257 (0.080015)\n",
      "0.2 3 6 8 log2 friedman_mse 1.0 100: Macro 0.693106 (0.116688)\n",
      "Testing 4715/5184\n",
      "0.2 3 6 8 log2 friedman_mse 1.0 200: Weighted 0.804370 (0.088346)\n",
      "0.2 3 6 8 log2 friedman_mse 1.0 200: Macro 0.696970 (0.130341)\n",
      "Testing 4716/5184\n",
      "0.2 3 6 8 log2 friedman_mse 1.0 500: Weighted 0.806462 (0.081505)\n",
      "0.2 3 6 8 log2 friedman_mse 1.0 500: Macro 0.701416 (0.121088)\n",
      "Testing 4717/5184\n",
      "0.2 3 6 8 log2 mae 0.5 50: Weighted 0.807487 (0.080674)\n",
      "0.2 3 6 8 log2 mae 0.5 50: Macro 0.699517 (0.108227)\n",
      "Testing 4718/5184\n",
      "0.2 3 6 8 log2 mae 0.5 100: Weighted 0.787694 (0.080094)\n",
      "0.2 3 6 8 log2 mae 0.5 100: Macro 0.662983 (0.111262)\n",
      "Testing 4719/5184\n",
      "0.2 3 6 8 log2 mae 0.5 200: Weighted 0.789492 (0.060771)\n",
      "0.2 3 6 8 log2 mae 0.5 200: Macro 0.672201 (0.074634)\n",
      "Testing 4720/5184\n",
      "0.2 3 6 8 log2 mae 0.5 500: Weighted 0.800769 (0.058076)\n",
      "0.2 3 6 8 log2 mae 0.5 500: Macro 0.692324 (0.079189)\n",
      "Testing 4721/5184\n",
      "0.2 3 6 8 log2 mae 0.75 50: Weighted 0.790459 (0.075984)\n",
      "0.2 3 6 8 log2 mae 0.75 50: Macro 0.671506 (0.104977)\n",
      "Testing 4722/5184\n",
      "0.2 3 6 8 log2 mae 0.75 100: Weighted 0.805141 (0.081525)\n",
      "0.2 3 6 8 log2 mae 0.75 100: Macro 0.682308 (0.128037)\n",
      "Testing 4723/5184\n",
      "0.2 3 6 8 log2 mae 0.75 200: Weighted 0.804318 (0.088710)\n",
      "0.2 3 6 8 log2 mae 0.75 200: Macro 0.691867 (0.127870)\n",
      "Testing 4724/5184\n",
      "0.2 3 6 8 log2 mae 0.75 500: Weighted 0.776932 (0.072116)\n",
      "0.2 3 6 8 log2 mae 0.75 500: Macro 0.633110 (0.107453)\n",
      "Testing 4725/5184\n",
      "0.2 3 6 8 log2 mae 1.0 50: Weighted 0.777738 (0.077112)\n",
      "0.2 3 6 8 log2 mae 1.0 50: Macro 0.640734 (0.113061)\n",
      "Testing 4726/5184\n",
      "0.2 3 6 8 log2 mae 1.0 100: Weighted 0.788107 (0.089786)\n",
      "0.2 3 6 8 log2 mae 1.0 100: Macro 0.659794 (0.128643)\n",
      "Testing 4727/5184\n",
      "0.2 3 6 8 log2 mae 1.0 200: Weighted 0.753180 (0.087041)\n",
      "0.2 3 6 8 log2 mae 1.0 200: Macro 0.609435 (0.121599)\n",
      "Testing 4728/5184\n",
      "0.2 3 6 8 log2 mae 1.0 500: Weighted 0.762601 (0.085303)\n",
      "0.2 3 6 8 log2 mae 1.0 500: Macro 0.621842 (0.116851)\n",
      "Testing 4729/5184\n",
      "0.2 3 6 8 sqrt friedman_mse 0.5 50: Weighted 0.814417 (0.062217)\n",
      "0.2 3 6 8 sqrt friedman_mse 0.5 50: Macro 0.721233 (0.088029)\n",
      "Testing 4730/5184\n",
      "0.2 3 6 8 sqrt friedman_mse 0.5 100: Weighted 0.799604 (0.066626)\n",
      "0.2 3 6 8 sqrt friedman_mse 0.5 100: Macro 0.677972 (0.098236)\n",
      "Testing 4731/5184\n",
      "0.2 3 6 8 sqrt friedman_mse 0.5 200: Weighted 0.817222 (0.059024)\n",
      "0.2 3 6 8 sqrt friedman_mse 0.5 200: Macro 0.727904 (0.100401)\n",
      "Testing 4732/5184\n",
      "0.2 3 6 8 sqrt friedman_mse 0.5 500: Weighted 0.789995 (0.047798)\n",
      "0.2 3 6 8 sqrt friedman_mse 0.5 500: Macro 0.666272 (0.069640)\n",
      "Testing 4733/5184\n",
      "0.2 3 6 8 sqrt friedman_mse 0.75 50: Weighted 0.820584 (0.081089)\n",
      "0.2 3 6 8 sqrt friedman_mse 0.75 50: Macro 0.718900 (0.118625)\n",
      "Testing 4734/5184\n",
      "0.2 3 6 8 sqrt friedman_mse 0.75 100: Weighted 0.801455 (0.082242)\n",
      "0.2 3 6 8 sqrt friedman_mse 0.75 100: Macro 0.686787 (0.131634)\n",
      "Testing 4735/5184\n",
      "0.2 3 6 8 sqrt friedman_mse 0.75 200: Weighted 0.798349 (0.068896)\n",
      "0.2 3 6 8 sqrt friedman_mse 0.75 200: Macro 0.684374 (0.102748)\n",
      "Testing 4736/5184\n",
      "0.2 3 6 8 sqrt friedman_mse 0.75 500: Weighted 0.828667 (0.089946)\n",
      "0.2 3 6 8 sqrt friedman_mse 0.75 500: Macro 0.723120 (0.144246)\n",
      "Testing 4737/5184\n",
      "0.2 3 6 8 sqrt friedman_mse 1.0 50: Weighted 0.826415 (0.092205)\n",
      "0.2 3 6 8 sqrt friedman_mse 1.0 50: Macro 0.737885 (0.130538)\n",
      "Testing 4738/5184\n",
      "0.2 3 6 8 sqrt friedman_mse 1.0 100: Weighted 0.800896 (0.080699)\n",
      "0.2 3 6 8 sqrt friedman_mse 1.0 100: Macro 0.696842 (0.113136)\n",
      "Testing 4739/5184\n",
      "0.2 3 6 8 sqrt friedman_mse 1.0 200: Weighted 0.810905 (0.095955)\n",
      "0.2 3 6 8 sqrt friedman_mse 1.0 200: Macro 0.709134 (0.138093)\n",
      "Testing 4740/5184\n",
      "0.2 3 6 8 sqrt friedman_mse 1.0 500: Weighted 0.808986 (0.090742)\n",
      "0.2 3 6 8 sqrt friedman_mse 1.0 500: Macro 0.701562 (0.132476)\n",
      "Testing 4741/5184\n",
      "0.2 3 6 8 sqrt mae 0.5 50: Weighted 0.807287 (0.078944)\n",
      "0.2 3 6 8 sqrt mae 0.5 50: Macro 0.690808 (0.109305)\n",
      "Testing 4742/5184\n",
      "0.2 3 6 8 sqrt mae 0.5 100: Weighted 0.799256 (0.077658)\n",
      "0.2 3 6 8 sqrt mae 0.5 100: Macro 0.681224 (0.100486)\n",
      "Testing 4743/5184\n",
      "0.2 3 6 8 sqrt mae 0.5 200: Weighted 0.792282 (0.055598)\n",
      "0.2 3 6 8 sqrt mae 0.5 200: Macro 0.671387 (0.073133)\n",
      "Testing 4744/5184\n",
      "0.2 3 6 8 sqrt mae 0.5 500: Weighted 0.788210 (0.089603)\n",
      "0.2 3 6 8 sqrt mae 0.5 500: Macro 0.664430 (0.133241)\n",
      "Testing 4745/5184\n",
      "0.2 3 6 8 sqrt mae 0.75 50: Weighted 0.775794 (0.067705)\n",
      "0.2 3 6 8 sqrt mae 0.75 50: Macro 0.649381 (0.096041)\n",
      "Testing 4746/5184\n",
      "0.2 3 6 8 sqrt mae 0.75 100: Weighted 0.775355 (0.093719)\n",
      "0.2 3 6 8 sqrt mae 0.75 100: Macro 0.649854 (0.136753)\n",
      "Testing 4747/5184\n",
      "0.2 3 6 8 sqrt mae 0.75 200: Weighted 0.792705 (0.102498)\n",
      "0.2 3 6 8 sqrt mae 0.75 200: Macro 0.662656 (0.154730)\n",
      "Testing 4748/5184\n",
      "0.2 3 6 8 sqrt mae 0.75 500: Weighted 0.792547 (0.084203)\n",
      "0.2 3 6 8 sqrt mae 0.75 500: Macro 0.670495 (0.124390)\n",
      "Testing 4749/5184\n",
      "0.2 3 6 8 sqrt mae 1.0 50: Weighted 0.775597 (0.087989)\n",
      "0.2 3 6 8 sqrt mae 1.0 50: Macro 0.641813 (0.130277)\n",
      "Testing 4750/5184\n",
      "0.2 3 6 8 sqrt mae 1.0 100: Weighted 0.772476 (0.090120)\n",
      "0.2 3 6 8 sqrt mae 1.0 100: Macro 0.645977 (0.126712)\n",
      "Testing 4751/5184\n",
      "0.2 3 6 8 sqrt mae 1.0 200: Weighted 0.793059 (0.093175)\n",
      "0.2 3 6 8 sqrt mae 1.0 200: Macro 0.670347 (0.130383)\n",
      "Testing 4752/5184\n",
      "0.2 3 6 8 sqrt mae 1.0 500: Weighted 0.789638 (0.086792)\n",
      "0.2 3 6 8 sqrt mae 1.0 500: Macro 0.659776 (0.132216)\n",
      "Testing 4753/5184\n",
      "0.2 5 2 3 log2 friedman_mse 0.5 50: Weighted 0.796269 (0.055790)\n",
      "0.2 5 2 3 log2 friedman_mse 0.5 50: Macro 0.678151 (0.077643)\n",
      "Testing 4754/5184\n",
      "0.2 5 2 3 log2 friedman_mse 0.5 100: Weighted 0.806443 (0.044858)\n",
      "0.2 5 2 3 log2 friedman_mse 0.5 100: Macro 0.702680 (0.059963)\n",
      "Testing 4755/5184\n",
      "0.2 5 2 3 log2 friedman_mse 0.5 200: Weighted 0.829675 (0.063169)\n",
      "0.2 5 2 3 log2 friedman_mse 0.5 200: Macro 0.742212 (0.098022)\n",
      "Testing 4756/5184\n",
      "0.2 5 2 3 log2 friedman_mse 0.5 500: Weighted 0.803755 (0.040856)\n",
      "0.2 5 2 3 log2 friedman_mse 0.5 500: Macro 0.689722 (0.061838)\n",
      "Testing 4757/5184\n",
      "0.2 5 2 3 log2 friedman_mse 0.75 50: Weighted 0.803159 (0.063424)\n",
      "0.2 5 2 3 log2 friedman_mse 0.75 50: Macro 0.696594 (0.082516)\n",
      "Testing 4758/5184\n",
      "0.2 5 2 3 log2 friedman_mse 0.75 100: Weighted 0.797009 (0.055165)\n",
      "0.2 5 2 3 log2 friedman_mse 0.75 100: Macro 0.687471 (0.083652)\n",
      "Testing 4759/5184\n",
      "0.2 5 2 3 log2 friedman_mse 0.75 200: Weighted 0.794575 (0.052743)\n",
      "0.2 5 2 3 log2 friedman_mse 0.75 200: Macro 0.685844 (0.079462)\n",
      "Testing 4760/5184\n",
      "0.2 5 2 3 log2 friedman_mse 0.75 500: Weighted 0.808588 (0.065702)\n",
      "0.2 5 2 3 log2 friedman_mse 0.75 500: Macro 0.714903 (0.099145)\n",
      "Testing 4761/5184\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2 5 2 3 log2 friedman_mse 1.0 50: Weighted 0.807293 (0.076338)\n",
      "0.2 5 2 3 log2 friedman_mse 1.0 50: Macro 0.703683 (0.102519)\n",
      "Testing 4762/5184\n",
      "0.2 5 2 3 log2 friedman_mse 1.0 100: Weighted 0.825753 (0.068624)\n",
      "0.2 5 2 3 log2 friedman_mse 1.0 100: Macro 0.736356 (0.095491)\n",
      "Testing 4763/5184\n",
      "0.2 5 2 3 log2 friedman_mse 1.0 200: Weighted 0.794089 (0.045537)\n",
      "0.2 5 2 3 log2 friedman_mse 1.0 200: Macro 0.692426 (0.060329)\n",
      "Testing 4764/5184\n",
      "0.2 5 2 3 log2 friedman_mse 1.0 500: Weighted 0.801478 (0.046709)\n",
      "0.2 5 2 3 log2 friedman_mse 1.0 500: Macro 0.708943 (0.065830)\n",
      "Testing 4765/5184\n",
      "0.2 5 2 3 log2 mae 0.5 50: Weighted 0.790579 (0.068765)\n",
      "0.2 5 2 3 log2 mae 0.5 50: Macro 0.664425 (0.105880)\n",
      "Testing 4766/5184\n",
      "0.2 5 2 3 log2 mae 0.5 100: Weighted 0.782477 (0.067437)\n",
      "0.2 5 2 3 log2 mae 0.5 100: Macro 0.660273 (0.087529)\n",
      "Testing 4767/5184\n",
      "0.2 5 2 3 log2 mae 0.5 200: Weighted 0.782682 (0.072203)\n",
      "0.2 5 2 3 log2 mae 0.5 200: Macro 0.654039 (0.101353)\n",
      "Testing 4768/5184\n",
      "0.2 5 2 3 log2 mae 0.5 500: Weighted 0.798318 (0.076685)\n",
      "0.2 5 2 3 log2 mae 0.5 500: Macro 0.676280 (0.106781)\n",
      "Testing 4769/5184\n",
      "0.2 5 2 3 log2 mae 0.75 50: Weighted 0.789699 (0.071103)\n",
      "0.2 5 2 3 log2 mae 0.75 50: Macro 0.670841 (0.096187)\n",
      "Testing 4770/5184\n",
      "0.2 5 2 3 log2 mae 0.75 100: Weighted 0.774719 (0.083338)\n",
      "0.2 5 2 3 log2 mae 0.75 100: Macro 0.647924 (0.114128)\n",
      "Testing 4771/5184\n",
      "0.2 5 2 3 log2 mae 0.75 200: Weighted 0.764812 (0.082880)\n",
      "0.2 5 2 3 log2 mae 0.75 200: Macro 0.626174 (0.111482)\n",
      "Testing 4772/5184\n",
      "0.2 5 2 3 log2 mae 0.75 500: Weighted 0.777151 (0.077807)\n",
      "0.2 5 2 3 log2 mae 0.75 500: Macro 0.647067 (0.102716)\n",
      "Testing 4773/5184\n",
      "0.2 5 2 3 log2 mae 1.0 50: Weighted 0.777562 (0.060082)\n",
      "0.2 5 2 3 log2 mae 1.0 50: Macro 0.645783 (0.079672)\n",
      "Testing 4774/5184\n",
      "0.2 5 2 3 log2 mae 1.0 100: Weighted 0.776317 (0.074752)\n",
      "0.2 5 2 3 log2 mae 1.0 100: Macro 0.645070 (0.114217)\n",
      "Testing 4775/5184\n",
      "0.2 5 2 3 log2 mae 1.0 200: Weighted 0.764798 (0.072572)\n",
      "0.2 5 2 3 log2 mae 1.0 200: Macro 0.629284 (0.102829)\n",
      "Testing 4776/5184\n",
      "0.2 5 2 3 log2 mae 1.0 500: Weighted 0.770768 (0.058201)\n",
      "0.2 5 2 3 log2 mae 1.0 500: Macro 0.638162 (0.091746)\n",
      "Testing 4777/5184\n",
      "0.2 5 2 3 sqrt friedman_mse 0.5 50: Weighted 0.837955 (0.059805)\n",
      "0.2 5 2 3 sqrt friedman_mse 0.5 50: Macro 0.744252 (0.077857)\n",
      "Testing 4778/5184\n",
      "0.2 5 2 3 sqrt friedman_mse 0.5 100: Weighted 0.833598 (0.064540)\n",
      "0.2 5 2 3 sqrt friedman_mse 0.5 100: Macro 0.740349 (0.095047)\n",
      "Testing 4779/5184\n",
      "0.2 5 2 3 sqrt friedman_mse 0.5 200: Weighted 0.828583 (0.057570)\n",
      "0.2 5 2 3 sqrt friedman_mse 0.5 200: Macro 0.729407 (0.087554)\n",
      "Testing 4780/5184\n",
      "0.2 5 2 3 sqrt friedman_mse 0.5 500: Weighted 0.794155 (0.049804)\n",
      "0.2 5 2 3 sqrt friedman_mse 0.5 500: Macro 0.688798 (0.074752)\n",
      "Testing 4781/5184\n",
      "0.2 5 2 3 sqrt friedman_mse 0.75 50: Weighted 0.807436 (0.055169)\n",
      "0.2 5 2 3 sqrt friedman_mse 0.75 50: Macro 0.709780 (0.078089)\n",
      "Testing 4782/5184\n",
      "0.2 5 2 3 sqrt friedman_mse 0.75 100: Weighted 0.812364 (0.072681)\n",
      "0.2 5 2 3 sqrt friedman_mse 0.75 100: Macro 0.710407 (0.095321)\n",
      "Testing 4783/5184\n",
      "0.2 5 2 3 sqrt friedman_mse 0.75 200: Weighted 0.804595 (0.047541)\n",
      "0.2 5 2 3 sqrt friedman_mse 0.75 200: Macro 0.703315 (0.069620)\n",
      "Testing 4784/5184\n",
      "0.2 5 2 3 sqrt friedman_mse 0.75 500: Weighted 0.805605 (0.063768)\n",
      "0.2 5 2 3 sqrt friedman_mse 0.75 500: Macro 0.709799 (0.091576)\n",
      "Testing 4785/5184\n",
      "0.2 5 2 3 sqrt friedman_mse 1.0 50: Weighted 0.814464 (0.075622)\n",
      "0.2 5 2 3 sqrt friedman_mse 1.0 50: Macro 0.713302 (0.103388)\n",
      "Testing 4786/5184\n",
      "0.2 5 2 3 sqrt friedman_mse 1.0 100: Weighted 0.805747 (0.069912)\n",
      "0.2 5 2 3 sqrt friedman_mse 1.0 100: Macro 0.697305 (0.101025)\n",
      "Testing 4787/5184\n",
      "0.2 5 2 3 sqrt friedman_mse 1.0 200: Weighted 0.810201 (0.051053)\n",
      "0.2 5 2 3 sqrt friedman_mse 1.0 200: Macro 0.714847 (0.064369)\n",
      "Testing 4788/5184\n",
      "0.2 5 2 3 sqrt friedman_mse 1.0 500: Weighted 0.804747 (0.051608)\n",
      "0.2 5 2 3 sqrt friedman_mse 1.0 500: Macro 0.712822 (0.069587)\n",
      "Testing 4789/5184\n",
      "0.2 5 2 3 sqrt mae 0.5 50: Weighted 0.802743 (0.056462)\n",
      "0.2 5 2 3 sqrt mae 0.5 50: Macro 0.688020 (0.077973)\n",
      "Testing 4790/5184\n",
      "0.2 5 2 3 sqrt mae 0.5 100: Weighted 0.811452 (0.059287)\n",
      "0.2 5 2 3 sqrt mae 0.5 100: Macro 0.697743 (0.075421)\n",
      "Testing 4791/5184\n",
      "0.2 5 2 3 sqrt mae 0.5 200: Weighted 0.793976 (0.072537)\n",
      "0.2 5 2 3 sqrt mae 0.5 200: Macro 0.671594 (0.101608)\n",
      "Testing 4792/5184\n",
      "0.2 5 2 3 sqrt mae 0.5 500: Weighted 0.770733 (0.053017)\n",
      "0.2 5 2 3 sqrt mae 0.5 500: Macro 0.643316 (0.069040)\n",
      "Testing 4793/5184\n",
      "0.2 5 2 3 sqrt mae 0.75 50: Weighted 0.781370 (0.057663)\n",
      "0.2 5 2 3 sqrt mae 0.75 50: Macro 0.651307 (0.076164)\n",
      "Testing 4794/5184\n",
      "0.2 5 2 3 sqrt mae 0.75 100: Weighted 0.789794 (0.069182)\n",
      "0.2 5 2 3 sqrt mae 0.75 100: Macro 0.660036 (0.101234)\n",
      "Testing 4795/5184\n",
      "0.2 5 2 3 sqrt mae 0.75 200: Weighted 0.778275 (0.069445)\n",
      "0.2 5 2 3 sqrt mae 0.75 200: Macro 0.649748 (0.103900)\n",
      "Testing 4796/5184\n",
      "0.2 5 2 3 sqrt mae 0.75 500: Weighted 0.760941 (0.042513)\n",
      "0.2 5 2 3 sqrt mae 0.75 500: Macro 0.624895 (0.062608)\n",
      "Testing 4797/5184\n",
      "0.2 5 2 3 sqrt mae 1.0 50: Weighted 0.764798 (0.052020)\n",
      "0.2 5 2 3 sqrt mae 1.0 50: Macro 0.623123 (0.072179)\n",
      "Testing 4798/5184\n",
      "0.2 5 2 3 sqrt mae 1.0 100: Weighted 0.764919 (0.077153)\n",
      "0.2 5 2 3 sqrt mae 1.0 100: Macro 0.621777 (0.107135)\n",
      "Testing 4799/5184\n",
      "0.2 5 2 3 sqrt mae 1.0 200: Weighted 0.767099 (0.089298)\n",
      "0.2 5 2 3 sqrt mae 1.0 200: Macro 0.632108 (0.121113)\n",
      "Testing 4800/5184\n",
      "0.2 5 2 3 sqrt mae 1.0 500: Weighted 0.769043 (0.059907)\n",
      "0.2 5 2 3 sqrt mae 1.0 500: Macro 0.631000 (0.082419)\n",
      "Testing 4801/5184\n",
      "0.2 5 2 5 log2 friedman_mse 0.5 50: Weighted 0.817190 (0.078487)\n",
      "0.2 5 2 5 log2 friedman_mse 0.5 50: Macro 0.709158 (0.116139)\n",
      "Testing 4802/5184\n",
      "0.2 5 2 5 log2 friedman_mse 0.5 100: Weighted 0.813942 (0.062262)\n",
      "0.2 5 2 5 log2 friedman_mse 0.5 100: Macro 0.710189 (0.093236)\n",
      "Testing 4803/5184\n",
      "0.2 5 2 5 log2 friedman_mse 0.5 200: Weighted 0.815729 (0.059600)\n",
      "0.2 5 2 5 log2 friedman_mse 0.5 200: Macro 0.717415 (0.087925)\n",
      "Testing 4804/5184\n",
      "0.2 5 2 5 log2 friedman_mse 0.5 500: Weighted 0.828886 (0.056141)\n",
      "0.2 5 2 5 log2 friedman_mse 0.5 500: Macro 0.735554 (0.083697)\n",
      "Testing 4805/5184\n",
      "0.2 5 2 5 log2 friedman_mse 0.75 50: Weighted 0.830955 (0.073110)\n",
      "0.2 5 2 5 log2 friedman_mse 0.75 50: Macro 0.737979 (0.099007)\n",
      "Testing 4806/5184\n",
      "0.2 5 2 5 log2 friedman_mse 0.75 100: Weighted 0.798732 (0.064896)\n",
      "0.2 5 2 5 log2 friedman_mse 0.75 100: Macro 0.690738 (0.096187)\n",
      "Testing 4807/5184\n",
      "0.2 5 2 5 log2 friedman_mse 0.75 200: Weighted 0.827300 (0.086605)\n",
      "0.2 5 2 5 log2 friedman_mse 0.75 200: Macro 0.734018 (0.128852)\n",
      "Testing 4808/5184\n",
      "0.2 5 2 5 log2 friedman_mse 0.75 500: Weighted 0.802747 (0.074707)\n",
      "0.2 5 2 5 log2 friedman_mse 0.75 500: Macro 0.692543 (0.116689)\n",
      "Testing 4809/5184\n",
      "0.2 5 2 5 log2 friedman_mse 1.0 50: Weighted 0.814240 (0.086170)\n",
      "0.2 5 2 5 log2 friedman_mse 1.0 50: Macro 0.712829 (0.122089)\n",
      "Testing 4810/5184\n",
      "0.2 5 2 5 log2 friedman_mse 1.0 100: Weighted 0.790064 (0.072471)\n",
      "0.2 5 2 5 log2 friedman_mse 1.0 100: Macro 0.684479 (0.102610)\n",
      "Testing 4811/5184\n",
      "0.2 5 2 5 log2 friedman_mse 1.0 200: Weighted 0.820242 (0.086759)\n",
      "0.2 5 2 5 log2 friedman_mse 1.0 200: Macro 0.726506 (0.118011)\n",
      "Testing 4812/5184\n",
      "0.2 5 2 5 log2 friedman_mse 1.0 500: Weighted 0.795433 (0.067900)\n",
      "0.2 5 2 5 log2 friedman_mse 1.0 500: Macro 0.687644 (0.096080)\n",
      "Testing 4813/5184\n",
      "0.2 5 2 5 log2 mae 0.5 50: Weighted 0.791147 (0.058542)\n",
      "0.2 5 2 5 log2 mae 0.5 50: Macro 0.658493 (0.082921)\n",
      "Testing 4814/5184\n",
      "0.2 5 2 5 log2 mae 0.5 100: Weighted 0.808656 (0.084785)\n",
      "0.2 5 2 5 log2 mae 0.5 100: Macro 0.701147 (0.116263)\n",
      "Testing 4815/5184\n",
      "0.2 5 2 5 log2 mae 0.5 200: Weighted 0.784790 (0.053514)\n",
      "0.2 5 2 5 log2 mae 0.5 200: Macro 0.655304 (0.064627)\n",
      "Testing 4816/5184\n",
      "0.2 5 2 5 log2 mae 0.5 500: Weighted 0.802840 (0.098308)\n",
      "0.2 5 2 5 log2 mae 0.5 500: Macro 0.700019 (0.133741)\n",
      "Testing 4817/5184\n",
      "0.2 5 2 5 log2 mae 0.75 50: Weighted 0.767887 (0.081365)\n",
      "0.2 5 2 5 log2 mae 0.75 50: Macro 0.629054 (0.109794)\n",
      "Testing 4818/5184\n",
      "0.2 5 2 5 log2 mae 0.75 100: Weighted 0.759058 (0.070775)\n",
      "0.2 5 2 5 log2 mae 0.75 100: Macro 0.612217 (0.097050)\n",
      "Testing 4819/5184\n",
      "0.2 5 2 5 log2 mae 0.75 200: Weighted 0.767709 (0.078140)\n",
      "0.2 5 2 5 log2 mae 0.75 200: Macro 0.627513 (0.111000)\n",
      "Testing 4820/5184\n",
      "0.2 5 2 5 log2 mae 0.75 500: Weighted 0.774045 (0.072134)\n",
      "0.2 5 2 5 log2 mae 0.75 500: Macro 0.636358 (0.107494)\n",
      "Testing 4821/5184\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2 5 2 5 log2 mae 1.0 50: Weighted 0.784777 (0.084118)\n",
      "0.2 5 2 5 log2 mae 1.0 50: Macro 0.660125 (0.115850)\n",
      "Testing 4822/5184\n",
      "0.2 5 2 5 log2 mae 1.0 100: Weighted 0.762829 (0.084566)\n",
      "0.2 5 2 5 log2 mae 1.0 100: Macro 0.614965 (0.114192)\n",
      "Testing 4823/5184\n",
      "0.2 5 2 5 log2 mae 1.0 200: Weighted 0.776572 (0.095870)\n",
      "0.2 5 2 5 log2 mae 1.0 200: Macro 0.640502 (0.129958)\n",
      "Testing 4824/5184\n",
      "0.2 5 2 5 log2 mae 1.0 500: Weighted 0.765763 (0.076086)\n",
      "0.2 5 2 5 log2 mae 1.0 500: Macro 0.628958 (0.112993)\n",
      "Testing 4825/5184\n",
      "0.2 5 2 5 sqrt friedman_mse 0.5 50: Weighted 0.786155 (0.078247)\n",
      "0.2 5 2 5 sqrt friedman_mse 0.5 50: Macro 0.677449 (0.099971)\n",
      "Testing 4826/5184\n",
      "0.2 5 2 5 sqrt friedman_mse 0.5 100: Weighted 0.809149 (0.058027)\n",
      "0.2 5 2 5 sqrt friedman_mse 0.5 100: Macro 0.704782 (0.090920)\n",
      "Testing 4827/5184\n",
      "0.2 5 2 5 sqrt friedman_mse 0.5 200: Weighted 0.813668 (0.050154)\n",
      "0.2 5 2 5 sqrt friedman_mse 0.5 200: Macro 0.705327 (0.069402)\n",
      "Testing 4828/5184\n",
      "0.2 5 2 5 sqrt friedman_mse 0.5 500: Weighted 0.803937 (0.065216)\n",
      "0.2 5 2 5 sqrt friedman_mse 0.5 500: Macro 0.706420 (0.093703)\n",
      "Testing 4829/5184\n",
      "0.2 5 2 5 sqrt friedman_mse 0.75 50: Weighted 0.803051 (0.093928)\n",
      "0.2 5 2 5 sqrt friedman_mse 0.75 50: Macro 0.694940 (0.136241)\n",
      "Testing 4830/5184\n",
      "0.2 5 2 5 sqrt friedman_mse 0.75 100: Weighted 0.805429 (0.091246)\n",
      "0.2 5 2 5 sqrt friedman_mse 0.75 100: Macro 0.698254 (0.132663)\n",
      "Testing 4831/5184\n",
      "0.2 5 2 5 sqrt friedman_mse 0.75 200: Weighted 0.825473 (0.068732)\n",
      "0.2 5 2 5 sqrt friedman_mse 0.75 200: Macro 0.725455 (0.096948)\n",
      "Testing 4832/5184\n",
      "0.2 5 2 5 sqrt friedman_mse 0.75 500: Weighted 0.809234 (0.069095)\n",
      "0.2 5 2 5 sqrt friedman_mse 0.75 500: Macro 0.703950 (0.104013)\n",
      "Testing 4833/5184\n",
      "0.2 5 2 5 sqrt friedman_mse 1.0 50: Weighted 0.805517 (0.069075)\n",
      "0.2 5 2 5 sqrt friedman_mse 1.0 50: Macro 0.702861 (0.089197)\n",
      "Testing 4834/5184\n",
      "0.2 5 2 5 sqrt friedman_mse 1.0 100: Weighted 0.819273 (0.068707)\n",
      "0.2 5 2 5 sqrt friedman_mse 1.0 100: Macro 0.721869 (0.096873)\n",
      "Testing 4835/5184\n",
      "0.2 5 2 5 sqrt friedman_mse 1.0 200: Weighted 0.817428 (0.068269)\n",
      "0.2 5 2 5 sqrt friedman_mse 1.0 200: Macro 0.723332 (0.095368)\n",
      "Testing 4836/5184\n",
      "0.2 5 2 5 sqrt friedman_mse 1.0 500: Weighted 0.806217 (0.082615)\n",
      "0.2 5 2 5 sqrt friedman_mse 1.0 500: Macro 0.699818 (0.113741)\n",
      "Testing 4837/5184\n",
      "0.2 5 2 5 sqrt mae 0.5 50: Weighted 0.786647 (0.071866)\n",
      "0.2 5 2 5 sqrt mae 0.5 50: Macro 0.659158 (0.105190)\n",
      "Testing 4838/5184\n",
      "0.2 5 2 5 sqrt mae 0.5 100: Weighted 0.775293 (0.077454)\n",
      "0.2 5 2 5 sqrt mae 0.5 100: Macro 0.644366 (0.116790)\n",
      "Testing 4839/5184\n",
      "0.2 5 2 5 sqrt mae 0.5 200: Weighted 0.800704 (0.074638)\n",
      "0.2 5 2 5 sqrt mae 0.5 200: Macro 0.693649 (0.098533)\n",
      "Testing 4840/5184\n",
      "0.2 5 2 5 sqrt mae 0.5 500: Weighted 0.789797 (0.072243)\n",
      "0.2 5 2 5 sqrt mae 0.5 500: Macro 0.680399 (0.087046)\n",
      "Testing 4841/5184\n",
      "0.2 5 2 5 sqrt mae 0.75 50: Weighted 0.789220 (0.088146)\n",
      "0.2 5 2 5 sqrt mae 0.75 50: Macro 0.669018 (0.123936)\n",
      "Testing 4842/5184\n",
      "0.2 5 2 5 sqrt mae 0.75 100: Weighted 0.777423 (0.068587)\n",
      "0.2 5 2 5 sqrt mae 0.75 100: Macro 0.645254 (0.085206)\n",
      "Testing 4843/5184\n",
      "0.2 5 2 5 sqrt mae 0.75 200: Weighted 0.784514 (0.092303)\n",
      "0.2 5 2 5 sqrt mae 0.75 200: Macro 0.659119 (0.135807)\n",
      "Testing 4844/5184\n",
      "0.2 5 2 5 sqrt mae 0.75 500: Weighted 0.765351 (0.089292)\n",
      "0.2 5 2 5 sqrt mae 0.75 500: Macro 0.632022 (0.118642)\n",
      "Testing 4845/5184\n",
      "0.2 5 2 5 sqrt mae 1.0 50: Weighted 0.754128 (0.066174)\n",
      "0.2 5 2 5 sqrt mae 1.0 50: Macro 0.600198 (0.091925)\n",
      "Testing 4846/5184\n",
      "0.2 5 2 5 sqrt mae 1.0 100: Weighted 0.770852 (0.071817)\n",
      "0.2 5 2 5 sqrt mae 1.0 100: Macro 0.628625 (0.097765)\n",
      "Testing 4847/5184\n",
      "0.2 5 2 5 sqrt mae 1.0 200: Weighted 0.776311 (0.081962)\n",
      "0.2 5 2 5 sqrt mae 1.0 200: Macro 0.640902 (0.112534)\n",
      "Testing 4848/5184\n",
      "0.2 5 2 5 sqrt mae 1.0 500: Weighted 0.771056 (0.074856)\n",
      "0.2 5 2 5 sqrt mae 1.0 500: Macro 0.640746 (0.096816)\n",
      "Testing 4849/5184\n",
      "0.2 5 2 8 log2 friedman_mse 0.5 50: Weighted 0.804260 (0.066453)\n",
      "0.2 5 2 8 log2 friedman_mse 0.5 50: Macro 0.698445 (0.098639)\n",
      "Testing 4850/5184\n",
      "0.2 5 2 8 log2 friedman_mse 0.5 100: Weighted 0.827635 (0.078062)\n",
      "0.2 5 2 8 log2 friedman_mse 0.5 100: Macro 0.725252 (0.107251)\n",
      "Testing 4851/5184\n",
      "0.2 5 2 8 log2 friedman_mse 0.5 200: Weighted 0.823784 (0.060528)\n",
      "0.2 5 2 8 log2 friedman_mse 0.5 200: Macro 0.725965 (0.087592)\n",
      "Testing 4852/5184\n",
      "0.2 5 2 8 log2 friedman_mse 0.5 500: Weighted 0.799049 (0.046285)\n",
      "0.2 5 2 8 log2 friedman_mse 0.5 500: Macro 0.684704 (0.070640)\n",
      "Testing 4853/5184\n",
      "0.2 5 2 8 log2 friedman_mse 0.75 50: Weighted 0.817599 (0.068774)\n",
      "0.2 5 2 8 log2 friedman_mse 0.75 50: Macro 0.719175 (0.102070)\n",
      "Testing 4854/5184\n",
      "0.2 5 2 8 log2 friedman_mse 0.75 100: Weighted 0.812716 (0.091542)\n",
      "0.2 5 2 8 log2 friedman_mse 0.75 100: Macro 0.698312 (0.144748)\n",
      "Testing 4855/5184\n",
      "0.2 5 2 8 log2 friedman_mse 0.75 200: Weighted 0.841169 (0.078309)\n",
      "0.2 5 2 8 log2 friedman_mse 0.75 200: Macro 0.754603 (0.114704)\n",
      "Testing 4856/5184\n",
      "0.2 5 2 8 log2 friedman_mse 0.75 500: Weighted 0.815535 (0.072387)\n",
      "0.2 5 2 8 log2 friedman_mse 0.75 500: Macro 0.719767 (0.104880)\n",
      "Testing 4857/5184\n",
      "0.2 5 2 8 log2 friedman_mse 1.0 50: Weighted 0.797782 (0.089729)\n",
      "0.2 5 2 8 log2 friedman_mse 1.0 50: Macro 0.689681 (0.131301)\n",
      "Testing 4858/5184\n",
      "0.2 5 2 8 log2 friedman_mse 1.0 100: Weighted 0.791542 (0.075637)\n",
      "0.2 5 2 8 log2 friedman_mse 1.0 100: Macro 0.692709 (0.112267)\n",
      "Testing 4859/5184\n",
      "0.2 5 2 8 log2 friedman_mse 1.0 200: Weighted 0.794382 (0.100699)\n",
      "0.2 5 2 8 log2 friedman_mse 1.0 200: Macro 0.685755 (0.153018)\n",
      "Testing 4860/5184\n",
      "0.2 5 2 8 log2 friedman_mse 1.0 500: Weighted 0.828833 (0.075106)\n",
      "0.2 5 2 8 log2 friedman_mse 1.0 500: Macro 0.749063 (0.106938)\n",
      "Testing 4861/5184\n",
      "0.2 5 2 8 log2 mae 0.5 50: Weighted 0.801375 (0.070309)\n",
      "0.2 5 2 8 log2 mae 0.5 50: Macro 0.682671 (0.094724)\n",
      "Testing 4862/5184\n",
      "0.2 5 2 8 log2 mae 0.5 100: Weighted 0.774319 (0.057317)\n",
      "0.2 5 2 8 log2 mae 0.5 100: Macro 0.653740 (0.070823)\n",
      "Testing 4863/5184\n",
      "0.2 5 2 8 log2 mae 0.5 200: Weighted 0.813132 (0.072619)\n",
      "0.2 5 2 8 log2 mae 0.5 200: Macro 0.701489 (0.100521)\n",
      "Testing 4864/5184\n",
      "0.2 5 2 8 log2 mae 0.5 500: Weighted 0.786579 (0.078944)\n",
      "0.2 5 2 8 log2 mae 0.5 500: Macro 0.661007 (0.104810)\n",
      "Testing 4865/5184\n",
      "0.2 5 2 8 log2 mae 0.75 50: Weighted 0.776877 (0.072159)\n",
      "0.2 5 2 8 log2 mae 0.75 50: Macro 0.643590 (0.108281)\n",
      "Testing 4866/5184\n",
      "0.2 5 2 8 log2 mae 0.75 100: Weighted 0.802315 (0.076141)\n",
      "0.2 5 2 8 log2 mae 0.75 100: Macro 0.683292 (0.107265)\n",
      "Testing 4867/5184\n",
      "0.2 5 2 8 log2 mae 0.75 200: Weighted 0.783609 (0.091718)\n",
      "0.2 5 2 8 log2 mae 0.75 200: Macro 0.663166 (0.122043)\n",
      "Testing 4868/5184\n",
      "0.2 5 2 8 log2 mae 0.75 500: Weighted 0.785951 (0.073324)\n",
      "0.2 5 2 8 log2 mae 0.75 500: Macro 0.666119 (0.099421)\n",
      "Testing 4869/5184\n",
      "0.2 5 2 8 log2 mae 1.0 50: Weighted 0.780916 (0.094517)\n",
      "0.2 5 2 8 log2 mae 1.0 50: Macro 0.647311 (0.139314)\n",
      "Testing 4870/5184\n",
      "0.2 5 2 8 log2 mae 1.0 100: Weighted 0.808166 (0.086778)\n",
      "0.2 5 2 8 log2 mae 1.0 100: Macro 0.691434 (0.128903)\n",
      "Testing 4871/5184\n",
      "0.2 5 2 8 log2 mae 1.0 200: Weighted 0.772587 (0.089504)\n",
      "0.2 5 2 8 log2 mae 1.0 200: Macro 0.650410 (0.129058)\n",
      "Testing 4872/5184\n",
      "0.2 5 2 8 log2 mae 1.0 500: Weighted 0.783741 (0.091453)\n",
      "0.2 5 2 8 log2 mae 1.0 500: Macro 0.667817 (0.119659)\n",
      "Testing 4873/5184\n",
      "0.2 5 2 8 sqrt friedman_mse 0.5 50: Weighted 0.806263 (0.064814)\n",
      "0.2 5 2 8 sqrt friedman_mse 0.5 50: Macro 0.697899 (0.082928)\n",
      "Testing 4874/5184\n",
      "0.2 5 2 8 sqrt friedman_mse 0.5 100: Weighted 0.804181 (0.071332)\n",
      "0.2 5 2 8 sqrt friedman_mse 0.5 100: Macro 0.697172 (0.113472)\n",
      "Testing 4875/5184\n",
      "0.2 5 2 8 sqrt friedman_mse 0.5 200: Weighted 0.799780 (0.076800)\n",
      "0.2 5 2 8 sqrt friedman_mse 0.5 200: Macro 0.693018 (0.121762)\n",
      "Testing 4876/5184\n",
      "0.2 5 2 8 sqrt friedman_mse 0.5 500: Weighted 0.809006 (0.066246)\n",
      "0.2 5 2 8 sqrt friedman_mse 0.5 500: Macro 0.716187 (0.093210)\n",
      "Testing 4877/5184\n",
      "0.2 5 2 8 sqrt friedman_mse 0.75 50: Weighted 0.813593 (0.070401)\n",
      "0.2 5 2 8 sqrt friedman_mse 0.75 50: Macro 0.700698 (0.096898)\n",
      "Testing 4878/5184\n",
      "0.2 5 2 8 sqrt friedman_mse 0.75 100: Weighted 0.803886 (0.090360)\n",
      "0.2 5 2 8 sqrt friedman_mse 0.75 100: Macro 0.695142 (0.142592)\n",
      "Testing 4879/5184\n",
      "0.2 5 2 8 sqrt friedman_mse 0.75 200: Weighted 0.798085 (0.066083)\n",
      "0.2 5 2 8 sqrt friedman_mse 0.75 200: Macro 0.690623 (0.100922)\n",
      "Testing 4880/5184\n",
      "0.2 5 2 8 sqrt friedman_mse 0.75 500: Weighted 0.821089 (0.077254)\n",
      "0.2 5 2 8 sqrt friedman_mse 0.75 500: Macro 0.719213 (0.122880)\n",
      "Testing 4881/5184\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2 5 2 8 sqrt friedman_mse 1.0 50: Weighted 0.806066 (0.083347)\n",
      "0.2 5 2 8 sqrt friedman_mse 1.0 50: Macro 0.704388 (0.118880)\n",
      "Testing 4882/5184\n",
      "0.2 5 2 8 sqrt friedman_mse 1.0 100: Weighted 0.787464 (0.060348)\n",
      "0.2 5 2 8 sqrt friedman_mse 1.0 100: Macro 0.677195 (0.089187)\n",
      "Testing 4883/5184\n",
      "0.2 5 2 8 sqrt friedman_mse 1.0 200: Weighted 0.816573 (0.089284)\n",
      "0.2 5 2 8 sqrt friedman_mse 1.0 200: Macro 0.725074 (0.137764)\n",
      "Testing 4884/5184\n",
      "0.2 5 2 8 sqrt friedman_mse 1.0 500: Weighted 0.808390 (0.088652)\n",
      "0.2 5 2 8 sqrt friedman_mse 1.0 500: Macro 0.709137 (0.123929)\n",
      "Testing 4885/5184\n",
      "0.2 5 2 8 sqrt mae 0.5 50: Weighted 0.785034 (0.065731)\n",
      "0.2 5 2 8 sqrt mae 0.5 50: Macro 0.660914 (0.079733)\n",
      "Testing 4886/5184\n",
      "0.2 5 2 8 sqrt mae 0.5 100: Weighted 0.798022 (0.083934)\n",
      "0.2 5 2 8 sqrt mae 0.5 100: Macro 0.685168 (0.108639)\n",
      "Testing 4887/5184\n",
      "0.2 5 2 8 sqrt mae 0.5 200: Weighted 0.795030 (0.072087)\n",
      "0.2 5 2 8 sqrt mae 0.5 200: Macro 0.674301 (0.093255)\n",
      "Testing 4888/5184\n",
      "0.2 5 2 8 sqrt mae 0.5 500: Weighted 0.804786 (0.062437)\n",
      "0.2 5 2 8 sqrt mae 0.5 500: Macro 0.703027 (0.076355)\n",
      "Testing 4889/5184\n",
      "0.2 5 2 8 sqrt mae 0.75 50: Weighted 0.784133 (0.089301)\n",
      "0.2 5 2 8 sqrt mae 0.75 50: Macro 0.655962 (0.130996)\n",
      "Testing 4890/5184\n",
      "0.2 5 2 8 sqrt mae 0.75 100: Weighted 0.795336 (0.088536)\n",
      "0.2 5 2 8 sqrt mae 0.75 100: Macro 0.669778 (0.123620)\n",
      "Testing 4891/5184\n",
      "0.2 5 2 8 sqrt mae 0.75 200: Weighted 0.787725 (0.077647)\n",
      "0.2 5 2 8 sqrt mae 0.75 200: Macro 0.664127 (0.101788)\n",
      "Testing 4892/5184\n",
      "0.2 5 2 8 sqrt mae 0.75 500: Weighted 0.805055 (0.092116)\n",
      "0.2 5 2 8 sqrt mae 0.75 500: Macro 0.685719 (0.139373)\n",
      "Testing 4893/5184\n",
      "0.2 5 2 8 sqrt mae 1.0 50: Weighted 0.782788 (0.104941)\n",
      "0.2 5 2 8 sqrt mae 1.0 50: Macro 0.649996 (0.155420)\n",
      "Testing 4894/5184\n",
      "0.2 5 2 8 sqrt mae 1.0 100: Weighted 0.767322 (0.091042)\n",
      "0.2 5 2 8 sqrt mae 1.0 100: Macro 0.629328 (0.125182)\n",
      "Testing 4895/5184\n",
      "0.2 5 2 8 sqrt mae 1.0 200: Weighted 0.769932 (0.085585)\n",
      "0.2 5 2 8 sqrt mae 1.0 200: Macro 0.630992 (0.114185)\n",
      "Testing 4896/5184\n",
      "0.2 5 2 8 sqrt mae 1.0 500: Weighted 0.778271 (0.091091)\n",
      "0.2 5 2 8 sqrt mae 1.0 500: Macro 0.647687 (0.133275)\n",
      "Testing 4897/5184\n",
      "0.2 5 4 3 log2 friedman_mse 0.5 50: Weighted 0.802904 (0.061206)\n",
      "0.2 5 4 3 log2 friedman_mse 0.5 50: Macro 0.696551 (0.070275)\n",
      "Testing 4898/5184\n",
      "0.2 5 4 3 log2 friedman_mse 0.5 100: Weighted 0.793270 (0.055831)\n",
      "0.2 5 4 3 log2 friedman_mse 0.5 100: Macro 0.687027 (0.062703)\n",
      "Testing 4899/5184\n",
      "0.2 5 4 3 log2 friedman_mse 0.5 200: Weighted 0.787707 (0.058312)\n",
      "0.2 5 4 3 log2 friedman_mse 0.5 200: Macro 0.682394 (0.085129)\n",
      "Testing 4900/5184\n",
      "0.2 5 4 3 log2 friedman_mse 0.5 500: Weighted 0.807768 (0.061583)\n",
      "0.2 5 4 3 log2 friedman_mse 0.5 500: Macro 0.712676 (0.085189)\n",
      "Testing 4901/5184\n",
      "0.2 5 4 3 log2 friedman_mse 0.75 50: Weighted 0.811685 (0.060970)\n",
      "0.2 5 4 3 log2 friedman_mse 0.75 50: Macro 0.712307 (0.095314)\n",
      "Testing 4902/5184\n",
      "0.2 5 4 3 log2 friedman_mse 0.75 100: Weighted 0.797420 (0.063536)\n",
      "0.2 5 4 3 log2 friedman_mse 0.75 100: Macro 0.690355 (0.096225)\n",
      "Testing 4903/5184\n",
      "0.2 5 4 3 log2 friedman_mse 0.75 200: Weighted 0.818163 (0.063630)\n",
      "0.2 5 4 3 log2 friedman_mse 0.75 200: Macro 0.728456 (0.099233)\n",
      "Testing 4904/5184\n",
      "0.2 5 4 3 log2 friedman_mse 0.75 500: Weighted 0.822818 (0.048862)\n",
      "0.2 5 4 3 log2 friedman_mse 0.75 500: Macro 0.730274 (0.068204)\n",
      "Testing 4905/5184\n",
      "0.2 5 4 3 log2 friedman_mse 1.0 50: Weighted 0.812495 (0.047343)\n",
      "0.2 5 4 3 log2 friedman_mse 1.0 50: Macro 0.709535 (0.060814)\n",
      "Testing 4906/5184\n",
      "0.2 5 4 3 log2 friedman_mse 1.0 100: Weighted 0.800723 (0.055564)\n",
      "0.2 5 4 3 log2 friedman_mse 1.0 100: Macro 0.694474 (0.078624)\n",
      "Testing 4907/5184\n",
      "0.2 5 4 3 log2 friedman_mse 1.0 200: Weighted 0.814692 (0.054191)\n",
      "0.2 5 4 3 log2 friedman_mse 1.0 200: Macro 0.726626 (0.075095)\n",
      "Testing 4908/5184\n",
      "0.2 5 4 3 log2 friedman_mse 1.0 500: Weighted 0.796990 (0.060781)\n",
      "0.2 5 4 3 log2 friedman_mse 1.0 500: Macro 0.699171 (0.087185)\n",
      "Testing 4909/5184\n",
      "0.2 5 4 3 log2 mae 0.5 50: Weighted 0.816590 (0.054000)\n",
      "0.2 5 4 3 log2 mae 0.5 50: Macro 0.711233 (0.061185)\n",
      "Testing 4910/5184\n",
      "0.2 5 4 3 log2 mae 0.5 100: Weighted 0.781825 (0.064723)\n",
      "0.2 5 4 3 log2 mae 0.5 100: Macro 0.655553 (0.083165)\n",
      "Testing 4911/5184\n",
      "0.2 5 4 3 log2 mae 0.5 200: Weighted 0.807575 (0.088067)\n",
      "0.2 5 4 3 log2 mae 0.5 200: Macro 0.694152 (0.131341)\n",
      "Testing 4912/5184\n",
      "0.2 5 4 3 log2 mae 0.5 500: Weighted 0.788336 (0.071229)\n",
      "0.2 5 4 3 log2 mae 0.5 500: Macro 0.675901 (0.089407)\n",
      "Testing 4913/5184\n",
      "0.2 5 4 3 log2 mae 0.75 50: Weighted 0.804062 (0.064321)\n",
      "0.2 5 4 3 log2 mae 0.75 50: Macro 0.683228 (0.092701)\n",
      "Testing 4914/5184\n",
      "0.2 5 4 3 log2 mae 0.75 100: Weighted 0.766974 (0.064990)\n",
      "0.2 5 4 3 log2 mae 0.75 100: Macro 0.627875 (0.085918)\n",
      "Testing 4915/5184\n",
      "0.2 5 4 3 log2 mae 0.75 200: Weighted 0.768826 (0.069736)\n",
      "0.2 5 4 3 log2 mae 0.75 200: Macro 0.635469 (0.089666)\n",
      "Testing 4916/5184\n",
      "0.2 5 4 3 log2 mae 0.75 500: Weighted 0.772526 (0.085598)\n",
      "0.2 5 4 3 log2 mae 0.75 500: Macro 0.647786 (0.115912)\n",
      "Testing 4917/5184\n",
      "0.2 5 4 3 log2 mae 1.0 50: Weighted 0.777010 (0.063934)\n",
      "0.2 5 4 3 log2 mae 1.0 50: Macro 0.650977 (0.095520)\n",
      "Testing 4918/5184\n",
      "0.2 5 4 3 log2 mae 1.0 100: Weighted 0.757119 (0.065975)\n",
      "0.2 5 4 3 log2 mae 1.0 100: Macro 0.609335 (0.092016)\n",
      "Testing 4919/5184\n",
      "0.2 5 4 3 log2 mae 1.0 200: Weighted 0.781772 (0.065662)\n",
      "0.2 5 4 3 log2 mae 1.0 200: Macro 0.645453 (0.089442)\n",
      "Testing 4920/5184\n",
      "0.2 5 4 3 log2 mae 1.0 500: Weighted 0.782938 (0.064909)\n",
      "0.2 5 4 3 log2 mae 1.0 500: Macro 0.648142 (0.089409)\n",
      "Testing 4921/5184\n",
      "0.2 5 4 3 sqrt friedman_mse 0.5 50: Weighted 0.817918 (0.031853)\n",
      "0.2 5 4 3 sqrt friedman_mse 0.5 50: Macro 0.714906 (0.045116)\n",
      "Testing 4922/5184\n",
      "0.2 5 4 3 sqrt friedman_mse 0.5 100: Weighted 0.802329 (0.039973)\n",
      "0.2 5 4 3 sqrt friedman_mse 0.5 100: Macro 0.703006 (0.057906)\n",
      "Testing 4923/5184\n",
      "0.2 5 4 3 sqrt friedman_mse 0.5 200: Weighted 0.797982 (0.048914)\n",
      "0.2 5 4 3 sqrt friedman_mse 0.5 200: Macro 0.692845 (0.078317)\n",
      "Testing 4924/5184\n",
      "0.2 5 4 3 sqrt friedman_mse 0.5 500: Weighted 0.803240 (0.043703)\n",
      "0.2 5 4 3 sqrt friedman_mse 0.5 500: Macro 0.702332 (0.068291)\n",
      "Testing 4925/5184\n",
      "0.2 5 4 3 sqrt friedman_mse 0.75 50: Weighted 0.807064 (0.057527)\n",
      "0.2 5 4 3 sqrt friedman_mse 0.75 50: Macro 0.698389 (0.078692)\n",
      "Testing 4926/5184\n",
      "0.2 5 4 3 sqrt friedman_mse 0.75 100: Weighted 0.809830 (0.056437)\n",
      "0.2 5 4 3 sqrt friedman_mse 0.75 100: Macro 0.704797 (0.084289)\n",
      "Testing 4927/5184\n",
      "0.2 5 4 3 sqrt friedman_mse 0.75 200: Weighted 0.818945 (0.065454)\n",
      "0.2 5 4 3 sqrt friedman_mse 0.75 200: Macro 0.728658 (0.099470)\n",
      "Testing 4928/5184\n",
      "0.2 5 4 3 sqrt friedman_mse 0.75 500: Weighted 0.809000 (0.057381)\n",
      "0.2 5 4 3 sqrt friedman_mse 0.75 500: Macro 0.712951 (0.082477)\n",
      "Testing 4929/5184\n",
      "0.2 5 4 3 sqrt friedman_mse 1.0 50: Weighted 0.806897 (0.059090)\n",
      "0.2 5 4 3 sqrt friedman_mse 1.0 50: Macro 0.705898 (0.082723)\n",
      "Testing 4930/5184\n",
      "0.2 5 4 3 sqrt friedman_mse 1.0 100: Weighted 0.809536 (0.058735)\n",
      "0.2 5 4 3 sqrt friedman_mse 1.0 100: Macro 0.704486 (0.073869)\n",
      "Testing 4931/5184\n",
      "0.2 5 4 3 sqrt friedman_mse 1.0 200: Weighted 0.810961 (0.057418)\n",
      "0.2 5 4 3 sqrt friedman_mse 1.0 200: Macro 0.712947 (0.071033)\n",
      "Testing 4932/5184\n",
      "0.2 5 4 3 sqrt friedman_mse 1.0 500: Weighted 0.802998 (0.064079)\n",
      "0.2 5 4 3 sqrt friedman_mse 1.0 500: Macro 0.701916 (0.090632)\n",
      "Testing 4933/5184\n",
      "0.2 5 4 3 sqrt mae 0.5 50: Weighted 0.784256 (0.042395)\n",
      "0.2 5 4 3 sqrt mae 0.5 50: Macro 0.657784 (0.057773)\n",
      "Testing 4934/5184\n",
      "0.2 5 4 3 sqrt mae 0.5 100: Weighted 0.807481 (0.061168)\n",
      "0.2 5 4 3 sqrt mae 0.5 100: Macro 0.690698 (0.081344)\n",
      "Testing 4935/5184\n",
      "0.2 5 4 3 sqrt mae 0.5 200: Weighted 0.773238 (0.073776)\n",
      "0.2 5 4 3 sqrt mae 0.5 200: Macro 0.658729 (0.105204)\n",
      "Testing 4936/5184\n",
      "0.2 5 4 3 sqrt mae 0.5 500: Weighted 0.769879 (0.058592)\n",
      "0.2 5 4 3 sqrt mae 0.5 500: Macro 0.641223 (0.064351)\n",
      "Testing 4937/5184\n",
      "0.2 5 4 3 sqrt mae 0.75 50: Weighted 0.788034 (0.071872)\n",
      "0.2 5 4 3 sqrt mae 0.75 50: Macro 0.660027 (0.100474)\n",
      "Testing 4938/5184\n",
      "0.2 5 4 3 sqrt mae 0.75 100: Weighted 0.783880 (0.073942)\n",
      "0.2 5 4 3 sqrt mae 0.75 100: Macro 0.650799 (0.101777)\n",
      "Testing 4939/5184\n",
      "0.2 5 4 3 sqrt mae 0.75 200: Weighted 0.783973 (0.081599)\n",
      "0.2 5 4 3 sqrt mae 0.75 200: Macro 0.654473 (0.110498)\n",
      "Testing 4940/5184\n",
      "0.2 5 4 3 sqrt mae 0.75 500: Weighted 0.789239 (0.076133)\n",
      "0.2 5 4 3 sqrt mae 0.75 500: Macro 0.662142 (0.103490)\n",
      "Testing 4941/5184\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2 5 4 3 sqrt mae 1.0 50: Weighted 0.783439 (0.070885)\n",
      "0.2 5 4 3 sqrt mae 1.0 50: Macro 0.649925 (0.105116)\n",
      "Testing 4942/5184\n",
      "0.2 5 4 3 sqrt mae 1.0 100: Weighted 0.777039 (0.064509)\n",
      "0.2 5 4 3 sqrt mae 1.0 100: Macro 0.643159 (0.100723)\n",
      "Testing 4943/5184\n",
      "0.2 5 4 3 sqrt mae 1.0 200: Weighted 0.759293 (0.077991)\n",
      "0.2 5 4 3 sqrt mae 1.0 200: Macro 0.613611 (0.106395)\n",
      "Testing 4944/5184\n",
      "0.2 5 4 3 sqrt mae 1.0 500: Weighted 0.777975 (0.074887)\n",
      "0.2 5 4 3 sqrt mae 1.0 500: Macro 0.645222 (0.109379)\n",
      "Testing 4945/5184\n",
      "0.2 5 4 5 log2 friedman_mse 0.5 50: Weighted 0.786613 (0.060648)\n",
      "0.2 5 4 5 log2 friedman_mse 0.5 50: Macro 0.681153 (0.087156)\n",
      "Testing 4946/5184\n",
      "0.2 5 4 5 log2 friedman_mse 0.5 100: Weighted 0.820822 (0.087363)\n",
      "0.2 5 4 5 log2 friedman_mse 0.5 100: Macro 0.725065 (0.117364)\n",
      "Testing 4947/5184\n",
      "0.2 5 4 5 log2 friedman_mse 0.5 200: Weighted 0.821545 (0.060553)\n",
      "0.2 5 4 5 log2 friedman_mse 0.5 200: Macro 0.729398 (0.091613)\n",
      "Testing 4948/5184\n",
      "0.2 5 4 5 log2 friedman_mse 0.5 500: Weighted 0.809010 (0.059276)\n",
      "0.2 5 4 5 log2 friedman_mse 0.5 500: Macro 0.701412 (0.095224)\n",
      "Testing 4949/5184\n",
      "0.2 5 4 5 log2 friedman_mse 0.75 50: Weighted 0.821103 (0.072096)\n",
      "0.2 5 4 5 log2 friedman_mse 0.75 50: Macro 0.717228 (0.098712)\n",
      "Testing 4950/5184\n",
      "0.2 5 4 5 log2 friedman_mse 0.75 100: Weighted 0.816392 (0.078568)\n",
      "0.2 5 4 5 log2 friedman_mse 0.75 100: Macro 0.719169 (0.106223)\n",
      "Testing 4951/5184\n",
      "0.2 5 4 5 log2 friedman_mse 0.75 200: Weighted 0.809965 (0.078009)\n",
      "0.2 5 4 5 log2 friedman_mse 0.75 200: Macro 0.708293 (0.110834)\n",
      "Testing 4952/5184\n",
      "0.2 5 4 5 log2 friedman_mse 0.75 500: Weighted 0.815121 (0.067773)\n",
      "0.2 5 4 5 log2 friedman_mse 0.75 500: Macro 0.716590 (0.083699)\n",
      "Testing 4953/5184\n",
      "0.2 5 4 5 log2 friedman_mse 1.0 50: Weighted 0.805134 (0.087152)\n",
      "0.2 5 4 5 log2 friedman_mse 1.0 50: Macro 0.696316 (0.123959)\n",
      "Testing 4954/5184\n",
      "0.2 5 4 5 log2 friedman_mse 1.0 100: Weighted 0.801526 (0.081780)\n",
      "0.2 5 4 5 log2 friedman_mse 1.0 100: Macro 0.694615 (0.111124)\n",
      "Testing 4955/5184\n",
      "0.2 5 4 5 log2 friedman_mse 1.0 200: Weighted 0.802390 (0.071430)\n",
      "0.2 5 4 5 log2 friedman_mse 1.0 200: Macro 0.696871 (0.102091)\n",
      "Testing 4956/5184\n",
      "0.2 5 4 5 log2 friedman_mse 1.0 500: Weighted 0.794420 (0.063940)\n",
      "0.2 5 4 5 log2 friedman_mse 1.0 500: Macro 0.694356 (0.101688)\n",
      "Testing 4957/5184\n",
      "0.2 5 4 5 log2 mae 0.5 50: Weighted 0.790456 (0.066783)\n",
      "0.2 5 4 5 log2 mae 0.5 50: Macro 0.661992 (0.091176)\n",
      "Testing 4958/5184\n",
      "0.2 5 4 5 log2 mae 0.5 100: Weighted 0.787195 (0.070492)\n",
      "0.2 5 4 5 log2 mae 0.5 100: Macro 0.663016 (0.088432)\n",
      "Testing 4959/5184\n",
      "0.2 5 4 5 log2 mae 0.5 200: Weighted 0.823135 (0.070403)\n",
      "0.2 5 4 5 log2 mae 0.5 200: Macro 0.728774 (0.093619)\n",
      "Testing 4960/5184\n",
      "0.2 5 4 5 log2 mae 0.5 500: Weighted 0.789340 (0.069240)\n",
      "0.2 5 4 5 log2 mae 0.5 500: Macro 0.678957 (0.086610)\n",
      "Testing 4961/5184\n",
      "0.2 5 4 5 log2 mae 0.75 50: Weighted 0.770655 (0.082800)\n",
      "0.2 5 4 5 log2 mae 0.75 50: Macro 0.640514 (0.112422)\n",
      "Testing 4962/5184\n",
      "0.2 5 4 5 log2 mae 0.75 100: Weighted 0.782860 (0.102700)\n",
      "0.2 5 4 5 log2 mae 0.75 100: Macro 0.661706 (0.138919)\n",
      "Testing 4963/5184\n",
      "0.2 5 4 5 log2 mae 0.75 200: Weighted 0.775567 (0.073339)\n",
      "0.2 5 4 5 log2 mae 0.75 200: Macro 0.641463 (0.093245)\n",
      "Testing 4964/5184\n",
      "0.2 5 4 5 log2 mae 0.75 500: Weighted 0.768716 (0.088428)\n",
      "0.2 5 4 5 log2 mae 0.75 500: Macro 0.640103 (0.127548)\n",
      "Testing 4965/5184\n",
      "0.2 5 4 5 log2 mae 1.0 50: Weighted 0.774464 (0.084521)\n",
      "0.2 5 4 5 log2 mae 1.0 50: Macro 0.645017 (0.119058)\n",
      "Testing 4966/5184\n",
      "0.2 5 4 5 log2 mae 1.0 100: Weighted 0.774409 (0.079258)\n",
      "0.2 5 4 5 log2 mae 1.0 100: Macro 0.638658 (0.109956)\n",
      "Testing 4967/5184\n",
      "0.2 5 4 5 log2 mae 1.0 200: Weighted 0.767914 (0.080472)\n",
      "0.2 5 4 5 log2 mae 1.0 200: Macro 0.634938 (0.102147)\n",
      "Testing 4968/5184\n",
      "0.2 5 4 5 log2 mae 1.0 500: Weighted 0.782097 (0.092961)\n",
      "0.2 5 4 5 log2 mae 1.0 500: Macro 0.657952 (0.127736)\n",
      "Testing 4969/5184\n",
      "0.2 5 4 5 sqrt friedman_mse 0.5 50: Weighted 0.813924 (0.082359)\n",
      "0.2 5 4 5 sqrt friedman_mse 0.5 50: Macro 0.708664 (0.110336)\n",
      "Testing 4970/5184\n",
      "0.2 5 4 5 sqrt friedman_mse 0.5 100: Weighted 0.819714 (0.064795)\n",
      "0.2 5 4 5 sqrt friedman_mse 0.5 100: Macro 0.736546 (0.102729)\n",
      "Testing 4971/5184\n",
      "0.2 5 4 5 sqrt friedman_mse 0.5 200: Weighted 0.816626 (0.057799)\n",
      "0.2 5 4 5 sqrt friedman_mse 0.5 200: Macro 0.731652 (0.095535)\n",
      "Testing 4972/5184\n",
      "0.2 5 4 5 sqrt friedman_mse 0.5 500: Weighted 0.808215 (0.069693)\n",
      "0.2 5 4 5 sqrt friedman_mse 0.5 500: Macro 0.710542 (0.113930)\n",
      "Testing 4973/5184\n",
      "0.2 5 4 5 sqrt friedman_mse 0.75 50: Weighted 0.824210 (0.076691)\n",
      "0.2 5 4 5 sqrt friedman_mse 0.75 50: Macro 0.739741 (0.119491)\n",
      "Testing 4974/5184\n",
      "0.2 5 4 5 sqrt friedman_mse 0.75 100: Weighted 0.802462 (0.080151)\n",
      "0.2 5 4 5 sqrt friedman_mse 0.75 100: Macro 0.698354 (0.113546)\n",
      "Testing 4975/5184\n",
      "0.2 5 4 5 sqrt friedman_mse 0.75 200: Weighted 0.809309 (0.079993)\n",
      "0.2 5 4 5 sqrt friedman_mse 0.75 200: Macro 0.710450 (0.126202)\n",
      "Testing 4976/5184\n",
      "0.2 5 4 5 sqrt friedman_mse 0.75 500: Weighted 0.810661 (0.082509)\n",
      "0.2 5 4 5 sqrt friedman_mse 0.75 500: Macro 0.715377 (0.119701)\n",
      "Testing 4977/5184\n",
      "0.2 5 4 5 sqrt friedman_mse 1.0 50: Weighted 0.804573 (0.076802)\n",
      "0.2 5 4 5 sqrt friedman_mse 1.0 50: Macro 0.702145 (0.097463)\n",
      "Testing 4978/5184\n",
      "0.2 5 4 5 sqrt friedman_mse 1.0 100: Weighted 0.808844 (0.074217)\n",
      "0.2 5 4 5 sqrt friedman_mse 1.0 100: Macro 0.705508 (0.106588)\n",
      "Testing 4979/5184\n",
      "0.2 5 4 5 sqrt friedman_mse 1.0 200: Weighted 0.809746 (0.076129)\n",
      "0.2 5 4 5 sqrt friedman_mse 1.0 200: Macro 0.723698 (0.114089)\n",
      "Testing 4980/5184\n",
      "0.2 5 4 5 sqrt friedman_mse 1.0 500: Weighted 0.797087 (0.066661)\n",
      "0.2 5 4 5 sqrt friedman_mse 1.0 500: Macro 0.703700 (0.098005)\n",
      "Testing 4981/5184\n",
      "0.2 5 4 5 sqrt mae 0.5 50: Weighted 0.779900 (0.070013)\n",
      "0.2 5 4 5 sqrt mae 0.5 50: Macro 0.646298 (0.100999)\n",
      "Testing 4982/5184\n",
      "0.2 5 4 5 sqrt mae 0.5 100: Weighted 0.789034 (0.078587)\n",
      "0.2 5 4 5 sqrt mae 0.5 100: Macro 0.668592 (0.114711)\n",
      "Testing 4983/5184\n",
      "0.2 5 4 5 sqrt mae 0.5 200: Weighted 0.781752 (0.077574)\n",
      "0.2 5 4 5 sqrt mae 0.5 200: Macro 0.657431 (0.107595)\n",
      "Testing 4984/5184\n",
      "0.2 5 4 5 sqrt mae 0.5 500: Weighted 0.783640 (0.072351)\n",
      "0.2 5 4 5 sqrt mae 0.5 500: Macro 0.660291 (0.085106)\n",
      "Testing 4985/5184\n",
      "0.2 5 4 5 sqrt mae 0.75 50: Weighted 0.779017 (0.078866)\n",
      "0.2 5 4 5 sqrt mae 0.75 50: Macro 0.643852 (0.114547)\n",
      "Testing 4986/5184\n",
      "0.2 5 4 5 sqrt mae 0.75 100: Weighted 0.779882 (0.086690)\n",
      "0.2 5 4 5 sqrt mae 0.75 100: Macro 0.646983 (0.115302)\n",
      "Testing 4987/5184\n",
      "0.2 5 4 5 sqrt mae 0.75 200: Weighted 0.773933 (0.086349)\n",
      "0.2 5 4 5 sqrt mae 0.75 200: Macro 0.640831 (0.121068)\n",
      "Testing 4988/5184\n",
      "0.2 5 4 5 sqrt mae 0.75 500: Weighted 0.764099 (0.083297)\n",
      "0.2 5 4 5 sqrt mae 0.75 500: Macro 0.624893 (0.110640)\n",
      "Testing 4989/5184\n",
      "0.2 5 4 5 sqrt mae 1.0 50: Weighted 0.766863 (0.071410)\n",
      "0.2 5 4 5 sqrt mae 1.0 50: Macro 0.621811 (0.093723)\n",
      "Testing 4990/5184\n",
      "0.2 5 4 5 sqrt mae 1.0 100: Weighted 0.773619 (0.093255)\n",
      "0.2 5 4 5 sqrt mae 1.0 100: Macro 0.635695 (0.130897)\n",
      "Testing 4991/5184\n",
      "0.2 5 4 5 sqrt mae 1.0 200: Weighted 0.780427 (0.090733)\n",
      "0.2 5 4 5 sqrt mae 1.0 200: Macro 0.648416 (0.126186)\n",
      "Testing 4992/5184\n",
      "0.2 5 4 5 sqrt mae 1.0 500: Weighted 0.800413 (0.085849)\n",
      "0.2 5 4 5 sqrt mae 1.0 500: Macro 0.674267 (0.124327)\n",
      "Testing 4993/5184\n",
      "0.2 5 4 8 log2 friedman_mse 0.5 50: Weighted 0.808977 (0.055752)\n",
      "0.2 5 4 8 log2 friedman_mse 0.5 50: Macro 0.702515 (0.082385)\n",
      "Testing 4994/5184\n",
      "0.2 5 4 8 log2 friedman_mse 0.5 100: Weighted 0.818956 (0.076221)\n",
      "0.2 5 4 8 log2 friedman_mse 0.5 100: Macro 0.717625 (0.121224)\n",
      "Testing 4995/5184\n",
      "0.2 5 4 8 log2 friedman_mse 0.5 200: Weighted 0.808311 (0.069026)\n",
      "0.2 5 4 8 log2 friedman_mse 0.5 200: Macro 0.706059 (0.102637)\n",
      "Testing 4996/5184\n",
      "0.2 5 4 8 log2 friedman_mse 0.5 500: Weighted 0.818521 (0.065275)\n",
      "0.2 5 4 8 log2 friedman_mse 0.5 500: Macro 0.728404 (0.099067)\n",
      "Testing 4997/5184\n",
      "0.2 5 4 8 log2 friedman_mse 0.75 50: Weighted 0.804770 (0.083571)\n",
      "0.2 5 4 8 log2 friedman_mse 0.75 50: Macro 0.699170 (0.128011)\n",
      "Testing 4998/5184\n",
      "0.2 5 4 8 log2 friedman_mse 0.75 100: Weighted 0.831586 (0.071979)\n",
      "0.2 5 4 8 log2 friedman_mse 0.75 100: Macro 0.736743 (0.110868)\n",
      "Testing 4999/5184\n",
      "0.2 5 4 8 log2 friedman_mse 0.75 200: Weighted 0.812619 (0.076005)\n",
      "0.2 5 4 8 log2 friedman_mse 0.75 200: Macro 0.717311 (0.109731)\n",
      "Testing 5000/5184\n",
      "0.2 5 4 8 log2 friedman_mse 0.75 500: Weighted 0.809147 (0.086930)\n",
      "0.2 5 4 8 log2 friedman_mse 0.75 500: Macro 0.694261 (0.131799)\n",
      "Testing 5001/5184\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2 5 4 8 log2 friedman_mse 1.0 50: Weighted 0.812567 (0.082465)\n",
      "0.2 5 4 8 log2 friedman_mse 1.0 50: Macro 0.723375 (0.116915)\n",
      "Testing 5002/5184\n",
      "0.2 5 4 8 log2 friedman_mse 1.0 100: Weighted 0.810934 (0.087454)\n",
      "0.2 5 4 8 log2 friedman_mse 1.0 100: Macro 0.727470 (0.124004)\n",
      "Testing 5003/5184\n",
      "0.2 5 4 8 log2 friedman_mse 1.0 200: Weighted 0.800164 (0.086750)\n",
      "0.2 5 4 8 log2 friedman_mse 1.0 200: Macro 0.710179 (0.130343)\n",
      "Testing 5004/5184\n",
      "0.2 5 4 8 log2 friedman_mse 1.0 500: Weighted 0.816221 (0.077909)\n",
      "0.2 5 4 8 log2 friedman_mse 1.0 500: Macro 0.726980 (0.114639)\n",
      "Testing 5005/5184\n",
      "0.2 5 4 8 log2 mae 0.5 50: Weighted 0.801988 (0.065819)\n",
      "0.2 5 4 8 log2 mae 0.5 50: Macro 0.688491 (0.096306)\n",
      "Testing 5006/5184\n",
      "0.2 5 4 8 log2 mae 0.5 100: Weighted 0.812315 (0.055747)\n",
      "0.2 5 4 8 log2 mae 0.5 100: Macro 0.709056 (0.078074)\n",
      "Testing 5007/5184\n",
      "0.2 5 4 8 log2 mae 0.5 200: Weighted 0.798066 (0.052243)\n",
      "0.2 5 4 8 log2 mae 0.5 200: Macro 0.673191 (0.066505)\n",
      "Testing 5008/5184\n",
      "0.2 5 4 8 log2 mae 0.5 500: Weighted 0.799959 (0.075225)\n",
      "0.2 5 4 8 log2 mae 0.5 500: Macro 0.689027 (0.090403)\n",
      "Testing 5009/5184\n",
      "0.2 5 4 8 log2 mae 0.75 50: Weighted 0.783925 (0.090854)\n",
      "0.2 5 4 8 log2 mae 0.75 50: Macro 0.655126 (0.123741)\n",
      "Testing 5010/5184\n",
      "0.2 5 4 8 log2 mae 0.75 100: Weighted 0.788405 (0.086120)\n",
      "0.2 5 4 8 log2 mae 0.75 100: Macro 0.665856 (0.112902)\n",
      "Testing 5011/5184\n",
      "0.2 5 4 8 log2 mae 0.75 200: Weighted 0.776517 (0.094365)\n",
      "0.2 5 4 8 log2 mae 0.75 200: Macro 0.658279 (0.120151)\n",
      "Testing 5012/5184\n",
      "0.2 5 4 8 log2 mae 0.75 500: Weighted 0.783594 (0.082264)\n",
      "0.2 5 4 8 log2 mae 0.75 500: Macro 0.664999 (0.112911)\n",
      "Testing 5013/5184\n",
      "0.2 5 4 8 log2 mae 1.0 50: Weighted 0.775240 (0.088992)\n",
      "0.2 5 4 8 log2 mae 1.0 50: Macro 0.642964 (0.126748)\n",
      "Testing 5014/5184\n",
      "0.2 5 4 8 log2 mae 1.0 100: Weighted 0.778268 (0.102721)\n",
      "0.2 5 4 8 log2 mae 1.0 100: Macro 0.643097 (0.151978)\n",
      "Testing 5015/5184\n",
      "0.2 5 4 8 log2 mae 1.0 200: Weighted 0.770812 (0.113157)\n",
      "0.2 5 4 8 log2 mae 1.0 200: Macro 0.642649 (0.164335)\n",
      "Testing 5016/5184\n",
      "0.2 5 4 8 log2 mae 1.0 500: Weighted 0.778996 (0.087457)\n",
      "0.2 5 4 8 log2 mae 1.0 500: Macro 0.654767 (0.128510)\n",
      "Testing 5017/5184\n",
      "0.2 5 4 8 sqrt friedman_mse 0.5 50: Weighted 0.795557 (0.069190)\n",
      "0.2 5 4 8 sqrt friedman_mse 0.5 50: Macro 0.685260 (0.100272)\n",
      "Testing 5018/5184\n",
      "0.2 5 4 8 sqrt friedman_mse 0.5 100: Weighted 0.812310 (0.051384)\n",
      "0.2 5 4 8 sqrt friedman_mse 0.5 100: Macro 0.709597 (0.072156)\n",
      "Testing 5019/5184\n",
      "0.2 5 4 8 sqrt friedman_mse 0.5 200: Weighted 0.812854 (0.057567)\n",
      "0.2 5 4 8 sqrt friedman_mse 0.5 200: Macro 0.709870 (0.085591)\n",
      "Testing 5020/5184\n",
      "0.2 5 4 8 sqrt friedman_mse 0.5 500: Weighted 0.811867 (0.052034)\n",
      "0.2 5 4 8 sqrt friedman_mse 0.5 500: Macro 0.717677 (0.078798)\n",
      "Testing 5021/5184\n",
      "0.2 5 4 8 sqrt friedman_mse 0.75 50: Weighted 0.813865 (0.092146)\n",
      "0.2 5 4 8 sqrt friedman_mse 0.75 50: Macro 0.699230 (0.138296)\n",
      "Testing 5022/5184\n",
      "0.2 5 4 8 sqrt friedman_mse 0.75 100: Weighted 0.794837 (0.079682)\n",
      "0.2 5 4 8 sqrt friedman_mse 0.75 100: Macro 0.680725 (0.111669)\n",
      "Testing 5023/5184\n",
      "0.2 5 4 8 sqrt friedman_mse 0.75 200: Weighted 0.829264 (0.078359)\n",
      "0.2 5 4 8 sqrt friedman_mse 0.75 200: Macro 0.737384 (0.111441)\n",
      "Testing 5024/5184\n",
      "0.2 5 4 8 sqrt friedman_mse 0.75 500: Weighted 0.817937 (0.055185)\n",
      "0.2 5 4 8 sqrt friedman_mse 0.75 500: Macro 0.710532 (0.072199)\n",
      "Testing 5025/5184\n",
      "0.2 5 4 8 sqrt friedman_mse 1.0 50: Weighted 0.800886 (0.085773)\n",
      "0.2 5 4 8 sqrt friedman_mse 1.0 50: Macro 0.698475 (0.128766)\n",
      "Testing 5026/5184\n",
      "0.2 5 4 8 sqrt friedman_mse 1.0 100: Weighted 0.797259 (0.079736)\n",
      "0.2 5 4 8 sqrt friedman_mse 1.0 100: Macro 0.695050 (0.117439)\n",
      "Testing 5027/5184\n",
      "0.2 5 4 8 sqrt friedman_mse 1.0 200: Weighted 0.801856 (0.077680)\n",
      "0.2 5 4 8 sqrt friedman_mse 1.0 200: Macro 0.701842 (0.112016)\n",
      "Testing 5028/5184\n",
      "0.2 5 4 8 sqrt friedman_mse 1.0 500: Weighted 0.801664 (0.087849)\n",
      "0.2 5 4 8 sqrt friedman_mse 1.0 500: Macro 0.693360 (0.127997)\n",
      "Testing 5029/5184\n",
      "0.2 5 4 8 sqrt mae 0.5 50: Weighted 0.789932 (0.077766)\n",
      "0.2 5 4 8 sqrt mae 0.5 50: Macro 0.668412 (0.114904)\n",
      "Testing 5030/5184\n",
      "0.2 5 4 8 sqrt mae 0.5 100: Weighted 0.809154 (0.080479)\n",
      "0.2 5 4 8 sqrt mae 0.5 100: Macro 0.696692 (0.112321)\n",
      "Testing 5031/5184\n",
      "0.2 5 4 8 sqrt mae 0.5 200: Weighted 0.792383 (0.063312)\n",
      "0.2 5 4 8 sqrt mae 0.5 200: Macro 0.676496 (0.085165)\n",
      "Testing 5032/5184\n",
      "0.2 5 4 8 sqrt mae 0.5 500: Weighted 0.789721 (0.067645)\n",
      "0.2 5 4 8 sqrt mae 0.5 500: Macro 0.677527 (0.084623)\n",
      "Testing 5033/5184\n",
      "0.2 5 4 8 sqrt mae 0.75 50: Weighted 0.791528 (0.092897)\n",
      "0.2 5 4 8 sqrt mae 0.75 50: Macro 0.668781 (0.130258)\n",
      "Testing 5034/5184\n",
      "0.2 5 4 8 sqrt mae 0.75 100: Weighted 0.792341 (0.096150)\n",
      "0.2 5 4 8 sqrt mae 0.75 100: Macro 0.676898 (0.130812)\n",
      "Testing 5035/5184\n",
      "0.2 5 4 8 sqrt mae 0.75 200: Weighted 0.772657 (0.082969)\n",
      "0.2 5 4 8 sqrt mae 0.75 200: Macro 0.642135 (0.116218)\n",
      "Testing 5036/5184\n",
      "0.2 5 4 8 sqrt mae 0.75 500: Weighted 0.784424 (0.081023)\n",
      "0.2 5 4 8 sqrt mae 0.75 500: Macro 0.660966 (0.104098)\n",
      "Testing 5037/5184\n",
      "0.2 5 4 8 sqrt mae 1.0 50: Weighted 0.770153 (0.077397)\n",
      "0.2 5 4 8 sqrt mae 1.0 50: Macro 0.637912 (0.105801)\n",
      "Testing 5038/5184\n",
      "0.2 5 4 8 sqrt mae 1.0 100: Weighted 0.782182 (0.098162)\n",
      "0.2 5 4 8 sqrt mae 1.0 100: Macro 0.660526 (0.138180)\n",
      "Testing 5039/5184\n",
      "0.2 5 4 8 sqrt mae 1.0 200: Weighted 0.802739 (0.080995)\n",
      "0.2 5 4 8 sqrt mae 1.0 200: Macro 0.675246 (0.120348)\n",
      "Testing 5040/5184\n",
      "0.2 5 4 8 sqrt mae 1.0 500: Weighted 0.802530 (0.074443)\n",
      "0.2 5 4 8 sqrt mae 1.0 500: Macro 0.679689 (0.102808)\n",
      "Testing 5041/5184\n",
      "0.2 5 6 3 log2 friedman_mse 0.5 50: Weighted 0.803050 (0.067816)\n",
      "0.2 5 6 3 log2 friedman_mse 0.5 50: Macro 0.699719 (0.093636)\n",
      "Testing 5042/5184\n",
      "0.2 5 6 3 log2 friedman_mse 0.5 100: Weighted 0.812763 (0.052875)\n",
      "0.2 5 6 3 log2 friedman_mse 0.5 100: Macro 0.704496 (0.064158)\n",
      "Testing 5043/5184\n",
      "0.2 5 6 3 log2 friedman_mse 0.5 200: Weighted 0.813869 (0.053534)\n",
      "0.2 5 6 3 log2 friedman_mse 0.5 200: Macro 0.717831 (0.089738)\n",
      "Testing 5044/5184\n",
      "0.2 5 6 3 log2 friedman_mse 0.5 500: Weighted 0.802110 (0.054399)\n",
      "0.2 5 6 3 log2 friedman_mse 0.5 500: Macro 0.700631 (0.081587)\n",
      "Testing 5045/5184\n",
      "0.2 5 6 3 log2 friedman_mse 0.75 50: Weighted 0.804313 (0.058120)\n",
      "0.2 5 6 3 log2 friedman_mse 0.75 50: Macro 0.699614 (0.078265)\n",
      "Testing 5046/5184\n",
      "0.2 5 6 3 log2 friedman_mse 0.75 100: Weighted 0.824913 (0.060413)\n",
      "0.2 5 6 3 log2 friedman_mse 0.75 100: Macro 0.723051 (0.078835)\n",
      "Testing 5047/5184\n",
      "0.2 5 6 3 log2 friedman_mse 0.75 200: Weighted 0.819779 (0.062969)\n",
      "0.2 5 6 3 log2 friedman_mse 0.75 200: Macro 0.736088 (0.087439)\n",
      "Testing 5048/5184\n",
      "0.2 5 6 3 log2 friedman_mse 0.75 500: Weighted 0.812351 (0.071068)\n",
      "0.2 5 6 3 log2 friedman_mse 0.75 500: Macro 0.708746 (0.093897)\n",
      "Testing 5049/5184\n",
      "0.2 5 6 3 log2 friedman_mse 1.0 50: Weighted 0.806777 (0.072870)\n",
      "0.2 5 6 3 log2 friedman_mse 1.0 50: Macro 0.702561 (0.096312)\n",
      "Testing 5050/5184\n",
      "0.2 5 6 3 log2 friedman_mse 1.0 100: Weighted 0.812964 (0.066029)\n",
      "0.2 5 6 3 log2 friedman_mse 1.0 100: Macro 0.711563 (0.081234)\n",
      "Testing 5051/5184\n",
      "0.2 5 6 3 log2 friedman_mse 1.0 200: Weighted 0.789088 (0.057741)\n",
      "0.2 5 6 3 log2 friedman_mse 1.0 200: Macro 0.679811 (0.086944)\n",
      "Testing 5052/5184\n",
      "0.2 5 6 3 log2 friedman_mse 1.0 500: Weighted 0.802537 (0.065503)\n",
      "0.2 5 6 3 log2 friedman_mse 1.0 500: Macro 0.697510 (0.087464)\n",
      "Testing 5053/5184\n",
      "0.2 5 6 3 log2 mae 0.5 50: Weighted 0.801236 (0.076452)\n",
      "0.2 5 6 3 log2 mae 0.5 50: Macro 0.686291 (0.114366)\n",
      "Testing 5054/5184\n",
      "0.2 5 6 3 log2 mae 0.5 100: Weighted 0.775435 (0.065402)\n",
      "0.2 5 6 3 log2 mae 0.5 100: Macro 0.648673 (0.081519)\n",
      "Testing 5055/5184\n",
      "0.2 5 6 3 log2 mae 0.5 200: Weighted 0.790801 (0.074706)\n",
      "0.2 5 6 3 log2 mae 0.5 200: Macro 0.670784 (0.094265)\n",
      "Testing 5056/5184\n",
      "0.2 5 6 3 log2 mae 0.5 500: Weighted 0.757925 (0.076120)\n",
      "0.2 5 6 3 log2 mae 0.5 500: Macro 0.633121 (0.098468)\n",
      "Testing 5057/5184\n",
      "0.2 5 6 3 log2 mae 0.75 50: Weighted 0.789684 (0.060569)\n",
      "0.2 5 6 3 log2 mae 0.75 50: Macro 0.657152 (0.089691)\n",
      "Testing 5058/5184\n",
      "0.2 5 6 3 log2 mae 0.75 100: Weighted 0.779739 (0.068968)\n",
      "0.2 5 6 3 log2 mae 0.75 100: Macro 0.651937 (0.100010)\n",
      "Testing 5059/5184\n",
      "0.2 5 6 3 log2 mae 0.75 200: Weighted 0.768553 (0.079736)\n",
      "0.2 5 6 3 log2 mae 0.75 200: Macro 0.628483 (0.106666)\n",
      "Testing 5060/5184\n",
      "0.2 5 6 3 log2 mae 0.75 500: Weighted 0.765597 (0.083433)\n",
      "0.2 5 6 3 log2 mae 0.75 500: Macro 0.632480 (0.102014)\n",
      "Testing 5061/5184\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2 5 6 3 log2 mae 1.0 50: Weighted 0.765972 (0.076475)\n",
      "0.2 5 6 3 log2 mae 1.0 50: Macro 0.631180 (0.110385)\n",
      "Testing 5062/5184\n",
      "0.2 5 6 3 log2 mae 1.0 100: Weighted 0.770143 (0.059490)\n",
      "0.2 5 6 3 log2 mae 1.0 100: Macro 0.634183 (0.080663)\n",
      "Testing 5063/5184\n",
      "0.2 5 6 3 log2 mae 1.0 200: Weighted 0.759239 (0.074635)\n",
      "0.2 5 6 3 log2 mae 1.0 200: Macro 0.628939 (0.116467)\n",
      "Testing 5064/5184\n",
      "0.2 5 6 3 log2 mae 1.0 500: Weighted 0.761079 (0.067195)\n",
      "0.2 5 6 3 log2 mae 1.0 500: Macro 0.622803 (0.083308)\n",
      "Testing 5065/5184\n",
      "0.2 5 6 3 sqrt friedman_mse 0.5 50: Weighted 0.810852 (0.047848)\n",
      "0.2 5 6 3 sqrt friedman_mse 0.5 50: Macro 0.699857 (0.073865)\n",
      "Testing 5066/5184\n",
      "0.2 5 6 3 sqrt friedman_mse 0.5 100: Weighted 0.805951 (0.043735)\n",
      "0.2 5 6 3 sqrt friedman_mse 0.5 100: Macro 0.700914 (0.046590)\n",
      "Testing 5067/5184\n",
      "0.2 5 6 3 sqrt friedman_mse 0.5 200: Weighted 0.806963 (0.025863)\n",
      "0.2 5 6 3 sqrt friedman_mse 0.5 200: Macro 0.708313 (0.040393)\n",
      "Testing 5068/5184\n",
      "0.2 5 6 3 sqrt friedman_mse 0.5 500: Weighted 0.793185 (0.044785)\n",
      "0.2 5 6 3 sqrt friedman_mse 0.5 500: Macro 0.677841 (0.061074)\n",
      "Testing 5069/5184\n",
      "0.2 5 6 3 sqrt friedman_mse 0.75 50: Weighted 0.829728 (0.083491)\n",
      "0.2 5 6 3 sqrt friedman_mse 0.75 50: Macro 0.733652 (0.119611)\n",
      "Testing 5070/5184\n",
      "0.2 5 6 3 sqrt friedman_mse 0.75 100: Weighted 0.797664 (0.060385)\n",
      "0.2 5 6 3 sqrt friedman_mse 0.75 100: Macro 0.686326 (0.099756)\n",
      "Testing 5071/5184\n",
      "0.2 5 6 3 sqrt friedman_mse 0.75 200: Weighted 0.806267 (0.047311)\n",
      "0.2 5 6 3 sqrt friedman_mse 0.75 200: Macro 0.706138 (0.061728)\n",
      "Testing 5072/5184\n",
      "0.2 5 6 3 sqrt friedman_mse 0.75 500: Weighted 0.823559 (0.043765)\n",
      "0.2 5 6 3 sqrt friedman_mse 0.75 500: Macro 0.734034 (0.058077)\n",
      "Testing 5073/5184\n",
      "0.2 5 6 3 sqrt friedman_mse 1.0 50: Weighted 0.820463 (0.064684)\n",
      "0.2 5 6 3 sqrt friedman_mse 1.0 50: Macro 0.726140 (0.091962)\n",
      "Testing 5074/5184\n",
      "0.2 5 6 3 sqrt friedman_mse 1.0 100: Weighted 0.819485 (0.061493)\n",
      "0.2 5 6 3 sqrt friedman_mse 1.0 100: Macro 0.725284 (0.078774)\n",
      "Testing 5075/5184\n",
      "0.2 5 6 3 sqrt friedman_mse 1.0 200: Weighted 0.806532 (0.051993)\n",
      "0.2 5 6 3 sqrt friedman_mse 1.0 200: Macro 0.709385 (0.066828)\n",
      "Testing 5076/5184\n",
      "0.2 5 6 3 sqrt friedman_mse 1.0 500: Weighted 0.803053 (0.065119)\n",
      "0.2 5 6 3 sqrt friedman_mse 1.0 500: Macro 0.704513 (0.086355)\n",
      "Testing 5077/5184\n",
      "0.2 5 6 3 sqrt mae 0.5 50: Weighted 0.798637 (0.079313)\n",
      "0.2 5 6 3 sqrt mae 0.5 50: Macro 0.686908 (0.113648)\n",
      "Testing 5078/5184\n",
      "0.2 5 6 3 sqrt mae 0.5 100: Weighted 0.787904 (0.062545)\n",
      "0.2 5 6 3 sqrt mae 0.5 100: Macro 0.667270 (0.087214)\n",
      "Testing 5079/5184\n",
      "0.2 5 6 3 sqrt mae 0.5 200: Weighted 0.775784 (0.071752)\n",
      "0.2 5 6 3 sqrt mae 0.5 200: Macro 0.642143 (0.092706)\n",
      "Testing 5080/5184\n",
      "0.2 5 6 3 sqrt mae 0.5 500: Weighted 0.780441 (0.076730)\n",
      "0.2 5 6 3 sqrt mae 0.5 500: Macro 0.651765 (0.099453)\n",
      "Testing 5081/5184\n",
      "0.2 5 6 3 sqrt mae 0.75 50: Weighted 0.773089 (0.057250)\n",
      "0.2 5 6 3 sqrt mae 0.75 50: Macro 0.645792 (0.071446)\n",
      "Testing 5082/5184\n",
      "0.2 5 6 3 sqrt mae 0.75 100: Weighted 0.773528 (0.074228)\n",
      "0.2 5 6 3 sqrt mae 0.75 100: Macro 0.642011 (0.096260)\n",
      "Testing 5083/5184\n",
      "0.2 5 6 3 sqrt mae 0.75 200: Weighted 0.768200 (0.065194)\n",
      "0.2 5 6 3 sqrt mae 0.75 200: Macro 0.635574 (0.089479)\n",
      "Testing 5084/5184\n",
      "0.2 5 6 3 sqrt mae 0.75 500: Weighted 0.783100 (0.073586)\n",
      "0.2 5 6 3 sqrt mae 0.75 500: Macro 0.659967 (0.110464)\n",
      "Testing 5085/5184\n",
      "0.2 5 6 3 sqrt mae 1.0 50: Weighted 0.787019 (0.076337)\n",
      "0.2 5 6 3 sqrt mae 1.0 50: Macro 0.665544 (0.107074)\n",
      "Testing 5086/5184\n",
      "0.2 5 6 3 sqrt mae 1.0 100: Weighted 0.770222 (0.061687)\n",
      "0.2 5 6 3 sqrt mae 1.0 100: Macro 0.626365 (0.095931)\n",
      "Testing 5087/5184\n",
      "0.2 5 6 3 sqrt mae 1.0 200: Weighted 0.751545 (0.068754)\n",
      "0.2 5 6 3 sqrt mae 1.0 200: Macro 0.620578 (0.104503)\n",
      "Testing 5088/5184\n",
      "0.2 5 6 3 sqrt mae 1.0 500: Weighted 0.779054 (0.076965)\n",
      "0.2 5 6 3 sqrt mae 1.0 500: Macro 0.648414 (0.109333)\n",
      "Testing 5089/5184\n",
      "0.2 5 6 5 log2 friedman_mse 0.5 50: Weighted 0.816363 (0.065407)\n",
      "0.2 5 6 5 log2 friedman_mse 0.5 50: Macro 0.709260 (0.085384)\n",
      "Testing 5090/5184\n",
      "0.2 5 6 5 log2 friedman_mse 0.5 100: Weighted 0.797838 (0.076264)\n",
      "0.2 5 6 5 log2 friedman_mse 0.5 100: Macro 0.689379 (0.109673)\n",
      "Testing 5091/5184\n",
      "0.2 5 6 5 log2 friedman_mse 0.5 200: Weighted 0.805036 (0.058252)\n",
      "0.2 5 6 5 log2 friedman_mse 0.5 200: Macro 0.708191 (0.083014)\n",
      "Testing 5092/5184\n",
      "0.2 5 6 5 log2 friedman_mse 0.5 500: Weighted 0.821503 (0.054588)\n",
      "0.2 5 6 5 log2 friedman_mse 0.5 500: Macro 0.721569 (0.079492)\n",
      "Testing 5093/5184\n",
      "0.2 5 6 5 log2 friedman_mse 0.75 50: Weighted 0.822047 (0.086300)\n",
      "0.2 5 6 5 log2 friedman_mse 0.75 50: Macro 0.718280 (0.124055)\n",
      "Testing 5094/5184\n",
      "0.2 5 6 5 log2 friedman_mse 0.75 100: Weighted 0.826460 (0.064720)\n",
      "0.2 5 6 5 log2 friedman_mse 0.75 100: Macro 0.732756 (0.093940)\n",
      "Testing 5095/5184\n",
      "0.2 5 6 5 log2 friedman_mse 0.75 200: Weighted 0.800275 (0.070946)\n",
      "0.2 5 6 5 log2 friedman_mse 0.75 200: Macro 0.698638 (0.107271)\n",
      "Testing 5096/5184\n",
      "0.2 5 6 5 log2 friedman_mse 0.75 500: Weighted 0.819297 (0.072528)\n",
      "0.2 5 6 5 log2 friedman_mse 0.75 500: Macro 0.714988 (0.108213)\n",
      "Testing 5097/5184\n",
      "0.2 5 6 5 log2 friedman_mse 1.0 50: Weighted 0.814136 (0.067150)\n",
      "0.2 5 6 5 log2 friedman_mse 1.0 50: Macro 0.716354 (0.091806)\n",
      "Testing 5098/5184\n",
      "0.2 5 6 5 log2 friedman_mse 1.0 100: Weighted 0.799007 (0.076634)\n",
      "0.2 5 6 5 log2 friedman_mse 1.0 100: Macro 0.696606 (0.123894)\n",
      "Testing 5099/5184\n",
      "0.2 5 6 5 log2 friedman_mse 1.0 200: Weighted 0.791580 (0.074239)\n",
      "0.2 5 6 5 log2 friedman_mse 1.0 200: Macro 0.681523 (0.112571)\n",
      "Testing 5100/5184\n",
      "0.2 5 6 5 log2 friedman_mse 1.0 500: Weighted 0.805852 (0.067422)\n",
      "0.2 5 6 5 log2 friedman_mse 1.0 500: Macro 0.698818 (0.097708)\n",
      "Testing 5101/5184\n",
      "0.2 5 6 5 log2 mae 0.5 50: Weighted 0.797781 (0.085870)\n",
      "0.2 5 6 5 log2 mae 0.5 50: Macro 0.681376 (0.120359)\n",
      "Testing 5102/5184\n",
      "0.2 5 6 5 log2 mae 0.5 100: Weighted 0.771671 (0.067992)\n",
      "0.2 5 6 5 log2 mae 0.5 100: Macro 0.647771 (0.083602)\n",
      "Testing 5103/5184\n",
      "0.2 5 6 5 log2 mae 0.5 200: Weighted 0.784186 (0.075134)\n",
      "0.2 5 6 5 log2 mae 0.5 200: Macro 0.661175 (0.103830)\n",
      "Testing 5104/5184\n",
      "0.2 5 6 5 log2 mae 0.5 500: Weighted 0.781122 (0.072882)\n",
      "0.2 5 6 5 log2 mae 0.5 500: Macro 0.658791 (0.084503)\n",
      "Testing 5105/5184\n",
      "0.2 5 6 5 log2 mae 0.75 50: Weighted 0.794613 (0.091944)\n",
      "0.2 5 6 5 log2 mae 0.75 50: Macro 0.676192 (0.132397)\n",
      "Testing 5106/5184\n",
      "0.2 5 6 5 log2 mae 0.75 100: Weighted 0.797174 (0.105660)\n",
      "0.2 5 6 5 log2 mae 0.75 100: Macro 0.683877 (0.146560)\n",
      "Testing 5107/5184\n",
      "0.2 5 6 5 log2 mae 0.75 200: Weighted 0.788893 (0.077576)\n",
      "0.2 5 6 5 log2 mae 0.75 200: Macro 0.669088 (0.108987)\n",
      "Testing 5108/5184\n",
      "0.2 5 6 5 log2 mae 0.75 500: Weighted 0.760592 (0.093483)\n",
      "0.2 5 6 5 log2 mae 0.75 500: Macro 0.621096 (0.125132)\n",
      "Testing 5109/5184\n",
      "0.2 5 6 5 log2 mae 1.0 50: Weighted 0.785368 (0.084223)\n",
      "0.2 5 6 5 log2 mae 1.0 50: Macro 0.653106 (0.117092)\n",
      "Testing 5110/5184\n",
      "0.2 5 6 5 log2 mae 1.0 100: Weighted 0.782463 (0.089610)\n",
      "0.2 5 6 5 log2 mae 1.0 100: Macro 0.642721 (0.126339)\n",
      "Testing 5111/5184\n",
      "0.2 5 6 5 log2 mae 1.0 200: Weighted 0.771845 (0.092353)\n",
      "0.2 5 6 5 log2 mae 1.0 200: Macro 0.640859 (0.125335)\n",
      "Testing 5112/5184\n",
      "0.2 5 6 5 log2 mae 1.0 500: Weighted 0.774986 (0.082561)\n",
      "0.2 5 6 5 log2 mae 1.0 500: Macro 0.642119 (0.114762)\n",
      "Testing 5113/5184\n",
      "0.2 5 6 5 sqrt friedman_mse 0.5 50: Weighted 0.813564 (0.075283)\n",
      "0.2 5 6 5 sqrt friedman_mse 0.5 50: Macro 0.704455 (0.102378)\n",
      "Testing 5114/5184\n",
      "0.2 5 6 5 sqrt friedman_mse 0.5 100: Weighted 0.824344 (0.060211)\n",
      "0.2 5 6 5 sqrt friedman_mse 0.5 100: Macro 0.730031 (0.086047)\n",
      "Testing 5115/5184\n",
      "0.2 5 6 5 sqrt friedman_mse 0.5 200: Weighted 0.809160 (0.058464)\n",
      "0.2 5 6 5 sqrt friedman_mse 0.5 200: Macro 0.713638 (0.092932)\n",
      "Testing 5116/5184\n",
      "0.2 5 6 5 sqrt friedman_mse 0.5 500: Weighted 0.791949 (0.055125)\n",
      "0.2 5 6 5 sqrt friedman_mse 0.5 500: Macro 0.695939 (0.087183)\n",
      "Testing 5117/5184\n",
      "0.2 5 6 5 sqrt friedman_mse 0.75 50: Weighted 0.792553 (0.073152)\n",
      "0.2 5 6 5 sqrt friedman_mse 0.75 50: Macro 0.682407 (0.096336)\n",
      "Testing 5118/5184\n",
      "0.2 5 6 5 sqrt friedman_mse 0.75 100: Weighted 0.805596 (0.073988)\n",
      "0.2 5 6 5 sqrt friedman_mse 0.75 100: Macro 0.705275 (0.113955)\n",
      "Testing 5119/5184\n",
      "0.2 5 6 5 sqrt friedman_mse 0.75 200: Weighted 0.815245 (0.072803)\n",
      "0.2 5 6 5 sqrt friedman_mse 0.75 200: Macro 0.718632 (0.111924)\n",
      "Testing 5120/5184\n",
      "0.2 5 6 5 sqrt friedman_mse 0.75 500: Weighted 0.808778 (0.066973)\n",
      "0.2 5 6 5 sqrt friedman_mse 0.75 500: Macro 0.695158 (0.087816)\n",
      "Testing 5121/5184\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2 5 6 5 sqrt friedman_mse 1.0 50: Weighted 0.801095 (0.076255)\n",
      "0.2 5 6 5 sqrt friedman_mse 1.0 50: Macro 0.694980 (0.106463)\n",
      "Testing 5122/5184\n",
      "0.2 5 6 5 sqrt friedman_mse 1.0 100: Weighted 0.801050 (0.081419)\n",
      "0.2 5 6 5 sqrt friedman_mse 1.0 100: Macro 0.706811 (0.107341)\n",
      "Testing 5123/5184\n",
      "0.2 5 6 5 sqrt friedman_mse 1.0 200: Weighted 0.805929 (0.070019)\n",
      "0.2 5 6 5 sqrt friedman_mse 1.0 200: Macro 0.712380 (0.110968)\n",
      "Testing 5124/5184\n",
      "0.2 5 6 5 sqrt friedman_mse 1.0 500: Weighted 0.796174 (0.076038)\n",
      "0.2 5 6 5 sqrt friedman_mse 1.0 500: Macro 0.686552 (0.116422)\n",
      "Testing 5125/5184\n",
      "0.2 5 6 5 sqrt mae 0.5 50: Weighted 0.792853 (0.075905)\n",
      "0.2 5 6 5 sqrt mae 0.5 50: Macro 0.674134 (0.098732)\n",
      "Testing 5126/5184\n",
      "0.2 5 6 5 sqrt mae 0.5 100: Weighted 0.806460 (0.080939)\n",
      "0.2 5 6 5 sqrt mae 0.5 100: Macro 0.689610 (0.122778)\n",
      "Testing 5127/5184\n",
      "0.2 5 6 5 sqrt mae 0.5 200: Weighted 0.783591 (0.086400)\n",
      "0.2 5 6 5 sqrt mae 0.5 200: Macro 0.664869 (0.116851)\n",
      "Testing 5128/5184\n",
      "0.2 5 6 5 sqrt mae 0.5 500: Weighted 0.771221 (0.067480)\n",
      "0.2 5 6 5 sqrt mae 0.5 500: Macro 0.654889 (0.090004)\n",
      "Testing 5129/5184\n",
      "0.2 5 6 5 sqrt mae 0.75 50: Weighted 0.788407 (0.075270)\n",
      "0.2 5 6 5 sqrt mae 0.75 50: Macro 0.665855 (0.103770)\n",
      "Testing 5130/5184\n",
      "0.2 5 6 5 sqrt mae 0.75 100: Weighted 0.781657 (0.093098)\n",
      "0.2 5 6 5 sqrt mae 0.75 100: Macro 0.652624 (0.135472)\n",
      "Testing 5131/5184\n",
      "0.2 5 6 5 sqrt mae 0.75 200: Weighted 0.769674 (0.085767)\n",
      "0.2 5 6 5 sqrt mae 0.75 200: Macro 0.636965 (0.120123)\n",
      "Testing 5132/5184\n",
      "0.2 5 6 5 sqrt mae 0.75 500: Weighted 0.775176 (0.089450)\n",
      "0.2 5 6 5 sqrt mae 0.75 500: Macro 0.648109 (0.126572)\n",
      "Testing 5133/5184\n",
      "0.2 5 6 5 sqrt mae 1.0 50: Weighted 0.763531 (0.076067)\n",
      "0.2 5 6 5 sqrt mae 1.0 50: Macro 0.624312 (0.100118)\n",
      "Testing 5134/5184\n",
      "0.2 5 6 5 sqrt mae 1.0 100: Weighted 0.775616 (0.092201)\n",
      "0.2 5 6 5 sqrt mae 1.0 100: Macro 0.640652 (0.134745)\n",
      "Testing 5135/5184\n",
      "0.2 5 6 5 sqrt mae 1.0 200: Weighted 0.774683 (0.089430)\n",
      "0.2 5 6 5 sqrt mae 1.0 200: Macro 0.641457 (0.113673)\n",
      "Testing 5136/5184\n",
      "0.2 5 6 5 sqrt mae 1.0 500: Weighted 0.786118 (0.088570)\n",
      "0.2 5 6 5 sqrt mae 1.0 500: Macro 0.665795 (0.123503)\n",
      "Testing 5137/5184\n",
      "0.2 5 6 8 log2 friedman_mse 0.5 50: Weighted 0.816587 (0.068120)\n",
      "0.2 5 6 8 log2 friedman_mse 0.5 50: Macro 0.713446 (0.091650)\n",
      "Testing 5138/5184\n",
      "0.2 5 6 8 log2 friedman_mse 0.5 100: Weighted 0.808503 (0.091008)\n",
      "0.2 5 6 8 log2 friedman_mse 0.5 100: Macro 0.708140 (0.138311)\n",
      "Testing 5139/5184\n",
      "0.2 5 6 8 log2 friedman_mse 0.5 200: Weighted 0.818668 (0.074599)\n",
      "0.2 5 6 8 log2 friedman_mse 0.5 200: Macro 0.719546 (0.119579)\n",
      "Testing 5140/5184\n",
      "0.2 5 6 8 log2 friedman_mse 0.5 500: Weighted 0.813875 (0.061266)\n",
      "0.2 5 6 8 log2 friedman_mse 0.5 500: Macro 0.724092 (0.097786)\n",
      "Testing 5141/5184\n",
      "0.2 5 6 8 log2 friedman_mse 0.75 50: Weighted 0.808684 (0.059645)\n",
      "0.2 5 6 8 log2 friedman_mse 0.75 50: Macro 0.705548 (0.086415)\n",
      "Testing 5142/5184\n",
      "0.2 5 6 8 log2 friedman_mse 0.75 100: Weighted 0.805443 (0.102342)\n",
      "0.2 5 6 8 log2 friedman_mse 0.75 100: Macro 0.690052 (0.151326)\n",
      "Testing 5143/5184\n",
      "0.2 5 6 8 log2 friedman_mse 0.75 200: Weighted 0.796573 (0.066790)\n",
      "0.2 5 6 8 log2 friedman_mse 0.75 200: Macro 0.683509 (0.099528)\n",
      "Testing 5144/5184\n",
      "0.2 5 6 8 log2 friedman_mse 0.75 500: Weighted 0.826309 (0.065425)\n",
      "0.2 5 6 8 log2 friedman_mse 0.75 500: Macro 0.737440 (0.096318)\n",
      "Testing 5145/5184\n",
      "0.2 5 6 8 log2 friedman_mse 1.0 50: Weighted 0.813218 (0.100716)\n",
      "0.2 5 6 8 log2 friedman_mse 1.0 50: Macro 0.710353 (0.159958)\n",
      "Testing 5146/5184\n",
      "0.2 5 6 8 log2 friedman_mse 1.0 100: Weighted 0.800874 (0.108157)\n",
      "0.2 5 6 8 log2 friedman_mse 1.0 100: Macro 0.703328 (0.156636)\n",
      "Testing 5147/5184\n",
      "0.2 5 6 8 log2 friedman_mse 1.0 200: Weighted 0.797862 (0.097898)\n",
      "0.2 5 6 8 log2 friedman_mse 1.0 200: Macro 0.683303 (0.145169)\n",
      "Testing 5148/5184\n",
      "0.2 5 6 8 log2 friedman_mse 1.0 500: Weighted 0.803326 (0.090385)\n",
      "0.2 5 6 8 log2 friedman_mse 1.0 500: Macro 0.711989 (0.132403)\n",
      "Testing 5149/5184\n",
      "0.2 5 6 8 log2 mae 0.5 50: Weighted 0.789464 (0.088478)\n",
      "0.2 5 6 8 log2 mae 0.5 50: Macro 0.676512 (0.113718)\n",
      "Testing 5150/5184\n",
      "0.2 5 6 8 log2 mae 0.5 100: Weighted 0.795191 (0.070872)\n",
      "0.2 5 6 8 log2 mae 0.5 100: Macro 0.672332 (0.100729)\n",
      "Testing 5151/5184\n",
      "0.2 5 6 8 log2 mae 0.5 200: Weighted 0.805024 (0.075466)\n",
      "0.2 5 6 8 log2 mae 0.5 200: Macro 0.687487 (0.113271)\n",
      "Testing 5152/5184\n",
      "0.2 5 6 8 log2 mae 0.5 500: Weighted 0.787820 (0.074139)\n",
      "0.2 5 6 8 log2 mae 0.5 500: Macro 0.661309 (0.108363)\n",
      "Testing 5153/5184\n",
      "0.2 5 6 8 log2 mae 0.75 50: Weighted 0.773231 (0.086939)\n",
      "0.2 5 6 8 log2 mae 0.75 50: Macro 0.639500 (0.121718)\n",
      "Testing 5154/5184\n",
      "0.2 5 6 8 log2 mae 0.75 100: Weighted 0.788535 (0.094483)\n",
      "0.2 5 6 8 log2 mae 0.75 100: Macro 0.669551 (0.124872)\n",
      "Testing 5155/5184\n",
      "0.2 5 6 8 log2 mae 0.75 200: Weighted 0.785010 (0.099976)\n",
      "0.2 5 6 8 log2 mae 0.75 200: Macro 0.661526 (0.140785)\n",
      "Testing 5156/5184\n",
      "0.2 5 6 8 log2 mae 0.75 500: Weighted 0.789801 (0.086251)\n",
      "0.2 5 6 8 log2 mae 0.75 500: Macro 0.669700 (0.117418)\n",
      "Testing 5157/5184\n",
      "0.2 5 6 8 log2 mae 1.0 50: Weighted 0.764541 (0.076513)\n",
      "0.2 5 6 8 log2 mae 1.0 50: Macro 0.626043 (0.113214)\n",
      "Testing 5158/5184\n",
      "0.2 5 6 8 log2 mae 1.0 100: Weighted 0.783439 (0.077099)\n",
      "0.2 5 6 8 log2 mae 1.0 100: Macro 0.659888 (0.103111)\n",
      "Testing 5159/5184\n",
      "0.2 5 6 8 log2 mae 1.0 200: Weighted 0.778800 (0.112713)\n",
      "0.2 5 6 8 log2 mae 1.0 200: Macro 0.655813 (0.163279)\n",
      "Testing 5160/5184\n",
      "0.2 5 6 8 log2 mae 1.0 500: Weighted 0.793362 (0.084937)\n",
      "0.2 5 6 8 log2 mae 1.0 500: Macro 0.669803 (0.123831)\n",
      "Testing 5161/5184\n",
      "0.2 5 6 8 sqrt friedman_mse 0.5 50: Weighted 0.812836 (0.056119)\n",
      "0.2 5 6 8 sqrt friedman_mse 0.5 50: Macro 0.694602 (0.078165)\n",
      "Testing 5162/5184\n",
      "0.2 5 6 8 sqrt friedman_mse 0.5 100: Weighted 0.799669 (0.057990)\n",
      "0.2 5 6 8 sqrt friedman_mse 0.5 100: Macro 0.700255 (0.082822)\n",
      "Testing 5163/5184\n",
      "0.2 5 6 8 sqrt friedman_mse 0.5 200: Weighted 0.809389 (0.065791)\n",
      "0.2 5 6 8 sqrt friedman_mse 0.5 200: Macro 0.706566 (0.091949)\n",
      "Testing 5164/5184\n",
      "0.2 5 6 8 sqrt friedman_mse 0.5 500: Weighted 0.814478 (0.062841)\n",
      "0.2 5 6 8 sqrt friedman_mse 0.5 500: Macro 0.712383 (0.098475)\n",
      "Testing 5165/5184\n",
      "0.2 5 6 8 sqrt friedman_mse 0.75 50: Weighted 0.822793 (0.060941)\n",
      "0.2 5 6 8 sqrt friedman_mse 0.75 50: Macro 0.726304 (0.087381)\n",
      "Testing 5166/5184\n",
      "0.2 5 6 8 sqrt friedman_mse 0.75 100: Weighted 0.811736 (0.070986)\n",
      "0.2 5 6 8 sqrt friedman_mse 0.75 100: Macro 0.695669 (0.111523)\n",
      "Testing 5167/5184\n",
      "0.2 5 6 8 sqrt friedman_mse 0.75 200: Weighted 0.808693 (0.069494)\n",
      "0.2 5 6 8 sqrt friedman_mse 0.75 200: Macro 0.710362 (0.121587)\n",
      "Testing 5168/5184\n",
      "0.2 5 6 8 sqrt friedman_mse 0.75 500: Weighted 0.805462 (0.084420)\n",
      "0.2 5 6 8 sqrt friedman_mse 0.75 500: Macro 0.693950 (0.126322)\n",
      "Testing 5169/5184\n",
      "0.2 5 6 8 sqrt friedman_mse 1.0 50: Weighted 0.793059 (0.098161)\n",
      "0.2 5 6 8 sqrt friedman_mse 1.0 50: Macro 0.691438 (0.146431)\n",
      "Testing 5170/5184\n",
      "0.2 5 6 8 sqrt friedman_mse 1.0 100: Weighted 0.819827 (0.095253)\n",
      "0.2 5 6 8 sqrt friedman_mse 1.0 100: Macro 0.729665 (0.144919)\n",
      "Testing 5171/5184\n",
      "0.2 5 6 8 sqrt friedman_mse 1.0 200: Weighted 0.797138 (0.082712)\n",
      "0.2 5 6 8 sqrt friedman_mse 1.0 200: Macro 0.691889 (0.115527)\n",
      "Testing 5172/5184\n",
      "0.2 5 6 8 sqrt friedman_mse 1.0 500: Weighted 0.808037 (0.078877)\n",
      "0.2 5 6 8 sqrt friedman_mse 1.0 500: Macro 0.715043 (0.128093)\n",
      "Testing 5173/5184\n",
      "0.2 5 6 8 sqrt mae 0.5 50: Weighted 0.805607 (0.082154)\n",
      "0.2 5 6 8 sqrt mae 0.5 50: Macro 0.695886 (0.111590)\n",
      "Testing 5174/5184\n",
      "0.2 5 6 8 sqrt mae 0.5 100: Weighted 0.796225 (0.089390)\n",
      "0.2 5 6 8 sqrt mae 0.5 100: Macro 0.676563 (0.124451)\n",
      "Testing 5175/5184\n",
      "0.2 5 6 8 sqrt mae 0.5 200: Weighted 0.787541 (0.077821)\n",
      "0.2 5 6 8 sqrt mae 0.5 200: Macro 0.662430 (0.103250)\n",
      "Testing 5176/5184\n",
      "0.2 5 6 8 sqrt mae 0.5 500: Weighted 0.803878 (0.054748)\n",
      "0.2 5 6 8 sqrt mae 0.5 500: Macro 0.688664 (0.067455)\n",
      "Testing 5177/5184\n",
      "0.2 5 6 8 sqrt mae 0.75 50: Weighted 0.797760 (0.072986)\n",
      "0.2 5 6 8 sqrt mae 0.75 50: Macro 0.684351 (0.098729)\n",
      "Testing 5178/5184\n",
      "0.2 5 6 8 sqrt mae 0.75 100: Weighted 0.796929 (0.088437)\n",
      "0.2 5 6 8 sqrt mae 0.75 100: Macro 0.682189 (0.118784)\n",
      "Testing 5179/5184\n",
      "0.2 5 6 8 sqrt mae 0.75 200: Weighted 0.784935 (0.080551)\n",
      "0.2 5 6 8 sqrt mae 0.75 200: Macro 0.659002 (0.106214)\n",
      "Testing 5180/5184\n",
      "0.2 5 6 8 sqrt mae 0.75 500: Weighted 0.769263 (0.076880)\n",
      "0.2 5 6 8 sqrt mae 0.75 500: Macro 0.637060 (0.108005)\n",
      "Testing 5181/5184\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2 5 6 8 sqrt mae 1.0 50: Weighted 0.787699 (0.080692)\n",
      "0.2 5 6 8 sqrt mae 1.0 50: Macro 0.655858 (0.125113)\n",
      "Testing 5182/5184\n",
      "0.2 5 6 8 sqrt mae 1.0 100: Weighted 0.783123 (0.097180)\n",
      "0.2 5 6 8 sqrt mae 1.0 100: Macro 0.660416 (0.138292)\n",
      "Testing 5183/5184\n",
      "0.2 5 6 8 sqrt mae 1.0 200: Weighted 0.770706 (0.088927)\n",
      "0.2 5 6 8 sqrt mae 1.0 200: Macro 0.631811 (0.124321)\n",
      "Testing 5184/5184\n",
      "0.2 5 6 8 sqrt mae 1.0 500: Weighted 0.798838 (0.096433)\n",
      "0.2 5 6 8 sqrt mae 1.0 500: Macro 0.675628 (0.142593)\n"
     ]
    }
   ],
   "source": [
    "results_weighted = []\n",
    "results_macro = []\n",
    "names = []\n",
    "num_tests = 4*3*3*3*2*2*3*4\n",
    "i = 1\n",
    "\n",
    "for learning_rate in [0.01, 0.05, 0.1, 0.2]:\n",
    "    for min_samples_leaf in [1,3,5]:\n",
    "        for min_samples_split in [2,4,6]:\n",
    "            for max_depth in [3,5,8]:\n",
    "                for max_features in [\"log2\",\"sqrt\"]:\n",
    "                    for criterion in [\"friedman_mse\",  \"mae\"]:\n",
    "                        for subsample in [0.5, 0.75, 1.0]:\n",
    "                            for n_estimators in [50, 100, 200, 500]:\n",
    "                                print(\"Testing {}/{}\".format(i,num_tests))\n",
    "                                i+=1\n",
    "                                kf = StratifiedKFold(n_splits=num_folds, random_state=seed)\n",
    "                                sm = SMOTE(random_state=seed, k_neighbors=7, sampling_strategy=\"not majority\")\n",
    "                                cv_results_weighted = np.array([])\n",
    "                                cv_results_macro = np.array([])\n",
    "                                for train_idx, test_idx, in kf.split(X_train, y_train):\n",
    "                                    X_cross_train, y_cross_train = X_train.iloc[train_idx], y_train.iloc[train_idx]\n",
    "                                    X_cross_test, y_cross_test = X_train.iloc[test_idx], y_train.iloc[test_idx]\n",
    "                                    X_cross_train, y_cross_train = sm.fit_sample(X_cross_train, y_cross_train)\n",
    "                                    model = GradientBoostingClassifier(learning_rate=learning_rate, min_samples_leaf=min_samples_leaf, \n",
    "                                            min_samples_split=min_samples_split, max_depth=max_depth, max_features=max_features,                           \n",
    "                                            criterion=criterion, subsample=subsample, n_estimators=n_estimators)\n",
    "                                    model.fit(X_cross_train, y_cross_train)  \n",
    "                                    y_pred = model.predict(X_cross_test)\n",
    "                                    f1s_weight = f1_score(y_cross_test, y_pred, average=\"weighted\")\n",
    "                                    f1s_macro = f1_score(y_cross_test, y_pred, average=\"macro\")\n",
    "                                    cv_results_weighted = np.append(cv_results_weighted, [f1s_weight])\n",
    "                                    cv_results_macro = np.append(cv_results_macro, [f1s_macro])\n",
    "                                results_weighted.append(cv_results_weighted)\n",
    "                                results_macro.append(cv_results_macro)\n",
    "                                name = \"{} {} {} {} {} {} {} {}\".format(learning_rate, min_samples_leaf, min_samples_split, max_depth, \n",
    "                                    max_features, criterion, subsample, n_estimators)\n",
    "                                names.append(name)\n",
    "                                msg = \"%s: Weighted %f (%f)\" % (name, cv_results_weighted.mean(), cv_results_weighted.std())\n",
    "                                print(msg)\n",
    "                                msg = \"%s: Macro %f (%f)\" % (name, cv_results_macro.mean(), cv_results_macro.std())\n",
    "                                print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimport pickle\\nfile = open(\"names.pkl\", \"rb\")\\nnames = pickle.load(file)\\nfile = open(\"results_weighted.pkl\", \"rb\")\\nresults_weighted = pickle.load(file)\\nfile = open(\"results_macro.pkl\", \"rb\")\\nresults_macro = pickle.load(file)\\n'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "with open('names.pkl', 'wb') as f:\n",
    "    pickle.dump(names, f)\n",
    "with open('results_weighted.pkl', 'wb') as f:\n",
    "    pickle.dump(results_weighted, f)\n",
    "with open('results_macro.pkl', 'wb') as f:\n",
    "    pickle.dump(results_macro, f)\n",
    "'''\n",
    "import pickle\n",
    "file = open(\"names.pkl\", \"rb\")\n",
    "names = pickle.load(file)\n",
    "file = open(\"results_weighted.pkl\", \"rb\")\n",
    "results_weighted = pickle.load(file)\n",
    "file = open(\"results_macro.pkl\", \"rb\")\n",
    "results_macro = pickle.load(file)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2 5 2 8 log2 friedman_mse 0.75 200 - Weighted: 0.7546026754117658 - Normal: 0.8411689608760619\n"
     ]
    }
   ],
   "source": [
    "avg_values_macro = [np.average(item) for item in results_macro]\n",
    "avg_values_weighted = [np.average(item) for item in results_weighted]\n",
    "max_index = avg_values_macro.index(max(avg_values_macro))\n",
    "print(\"{} - Weighted: {} - Normal: {}\".format(names[max_index], avg_values_macro[max_index], avg_values_weighted[max_index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GradientBoostingClassifier(learning_rate=0.2,  min_samples_leaf=5, min_samples_split= 2, max_depth=8, \n",
    "                                    max_features=\"log2\", criterion='friedman_mse',  subsample=0.75,  n_estimators=200)\n",
    "\n",
    "pipeline = Pipeline([('Scaler', StandardScaler()),('Model', model)])\n",
    "\n",
    "pipeline.fit(X_train_res, y_train_res) \n",
    "\n",
    "y_pred = pipeline.predict(X_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1fd51ad3a58>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(y_test, y_pred, classes=class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.50      0.59        16\n",
      "           1       0.12      0.17      0.14         6\n",
      "           2       0.88      0.97      0.92        30\n",
      "\n",
      "    accuracy                           0.73        52\n",
      "   macro avg       0.58      0.54      0.55        52\n",
      "weighted avg       0.75      0.73      0.73        52\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra Tree Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing 1/432\n",
      "1 2 3 log2 gini 50: Weighted 0.821966 (0.072631)\n",
      "1 2 3 log2 gini 50: Macro 0.719453 (0.089391)\n",
      "Testing 2/432\n",
      "1 2 3 log2 gini 100: Weighted 0.805145 (0.060472)\n",
      "1 2 3 log2 gini 100: Macro 0.685759 (0.084529)\n",
      "Testing 3/432\n",
      "1 2 3 log2 gini 200: Weighted 0.819696 (0.087700)\n",
      "1 2 3 log2 gini 200: Macro 0.720863 (0.123112)\n",
      "Testing 4/432\n",
      "1 2 3 log2 gini 500: Weighted 0.810839 (0.078934)\n",
      "1 2 3 log2 gini 500: Macro 0.707476 (0.094278)\n",
      "Testing 5/432\n",
      "1 2 3 log2 entropy 50: Weighted 0.821538 (0.065574)\n",
      "1 2 3 log2 entropy 50: Macro 0.718849 (0.079604)\n",
      "Testing 6/432\n",
      "1 2 3 log2 entropy 100: Weighted 0.808395 (0.065011)\n",
      "1 2 3 log2 entropy 100: Macro 0.696636 (0.072282)\n",
      "Testing 7/432\n",
      "1 2 3 log2 entropy 200: Weighted 0.831310 (0.081029)\n",
      "1 2 3 log2 entropy 200: Macro 0.738221 (0.107753)\n",
      "Testing 8/432\n",
      "1 2 3 log2 entropy 500: Weighted 0.810699 (0.091426)\n",
      "1 2 3 log2 entropy 500: Macro 0.713630 (0.121218)\n",
      "Testing 9/432\n",
      "1 2 3 sqrt gini 50: Weighted 0.809008 (0.056127)\n",
      "1 2 3 sqrt gini 50: Macro 0.692223 (0.071726)\n",
      "Testing 10/432\n",
      "1 2 3 sqrt gini 100: Weighted 0.821218 (0.097618)\n",
      "1 2 3 sqrt gini 100: Macro 0.719508 (0.128826)\n",
      "Testing 11/432\n",
      "1 2 3 sqrt gini 200: Weighted 0.832268 (0.074651)\n",
      "1 2 3 sqrt gini 200: Macro 0.739682 (0.099968)\n",
      "Testing 12/432\n",
      "1 2 3 sqrt gini 500: Weighted 0.804971 (0.083483)\n",
      "1 2 3 sqrt gini 500: Macro 0.700796 (0.104635)\n",
      "Testing 13/432\n",
      "1 2 3 sqrt entropy 50: Weighted 0.813571 (0.054354)\n",
      "1 2 3 sqrt entropy 50: Macro 0.701485 (0.058572)\n",
      "Testing 14/432\n",
      "1 2 3 sqrt entropy 100: Weighted 0.826305 (0.088521)\n",
      "1 2 3 sqrt entropy 100: Macro 0.732159 (0.116938)\n",
      "Testing 15/432\n",
      "1 2 3 sqrt entropy 200: Weighted 0.834146 (0.082528)\n",
      "1 2 3 sqrt entropy 200: Macro 0.740642 (0.114060)\n",
      "Testing 16/432\n",
      "1 2 3 sqrt entropy 500: Weighted 0.819397 (0.089400)\n",
      "1 2 3 sqrt entropy 500: Macro 0.723061 (0.111525)\n",
      "Testing 17/432\n",
      "1 2 5 log2 gini 50: Weighted 0.831191 (0.063438)\n",
      "1 2 5 log2 gini 50: Macro 0.731732 (0.079975)\n",
      "Testing 18/432\n",
      "1 2 5 log2 gini 100: Weighted 0.826068 (0.065340)\n",
      "1 2 5 log2 gini 100: Macro 0.726135 (0.085766)\n",
      "Testing 19/432\n",
      "1 2 5 log2 gini 200: Weighted 0.836839 (0.061979)\n",
      "1 2 5 log2 gini 200: Macro 0.739292 (0.078472)\n",
      "Testing 20/432\n",
      "1 2 5 log2 gini 500: Weighted 0.848545 (0.062042)\n",
      "1 2 5 log2 gini 500: Macro 0.757379 (0.087414)\n",
      "Testing 21/432\n",
      "1 2 5 log2 entropy 50: Weighted 0.830535 (0.066114)\n",
      "1 2 5 log2 entropy 50: Macro 0.725265 (0.094618)\n",
      "Testing 22/432\n",
      "1 2 5 log2 entropy 100: Weighted 0.838109 (0.075915)\n",
      "1 2 5 log2 entropy 100: Macro 0.746476 (0.102322)\n",
      "Testing 23/432\n",
      "1 2 5 log2 entropy 200: Weighted 0.842567 (0.069753)\n",
      "1 2 5 log2 entropy 200: Macro 0.752127 (0.094419)\n",
      "Testing 24/432\n",
      "1 2 5 log2 entropy 500: Weighted 0.850063 (0.061346)\n",
      "1 2 5 log2 entropy 500: Macro 0.756351 (0.087930)\n",
      "Testing 25/432\n",
      "1 2 5 sqrt gini 50: Weighted 0.811169 (0.064924)\n",
      "1 2 5 sqrt gini 50: Macro 0.703690 (0.087940)\n",
      "Testing 26/432\n",
      "1 2 5 sqrt gini 100: Weighted 0.842373 (0.070015)\n",
      "1 2 5 sqrt gini 100: Macro 0.755393 (0.090019)\n",
      "Testing 27/432\n",
      "1 2 5 sqrt gini 200: Weighted 0.848545 (0.062042)\n",
      "1 2 5 sqrt gini 200: Macro 0.757379 (0.087414)\n",
      "Testing 28/432\n",
      "1 2 5 sqrt gini 500: Weighted 0.838197 (0.063767)\n",
      "1 2 5 sqrt gini 500: Macro 0.744235 (0.084277)\n",
      "Testing 29/432\n",
      "1 2 5 sqrt entropy 50: Weighted 0.826808 (0.063922)\n",
      "1 2 5 sqrt entropy 50: Macro 0.727657 (0.084924)\n",
      "Testing 30/432\n",
      "1 2 5 sqrt entropy 100: Weighted 0.835803 (0.056193)\n",
      "1 2 5 sqrt entropy 100: Macro 0.738559 (0.071575)\n",
      "Testing 31/432\n",
      "1 2 5 sqrt entropy 200: Weighted 0.848545 (0.062042)\n",
      "1 2 5 sqrt entropy 200: Macro 0.757379 (0.087414)\n",
      "Testing 32/432\n",
      "1 2 5 sqrt entropy 500: Weighted 0.839212 (0.054660)\n",
      "1 2 5 sqrt entropy 500: Macro 0.740271 (0.073405)\n",
      "Testing 33/432\n",
      "1 2 8 log2 gini 50: Weighted 0.819899 (0.073070)\n",
      "1 2 8 log2 gini 50: Macro 0.720641 (0.092625)\n",
      "Testing 34/432\n",
      "1 2 8 log2 gini 100: Weighted 0.842975 (0.057742)\n",
      "1 2 8 log2 gini 100: Macro 0.749161 (0.076787)\n",
      "Testing 35/432\n",
      "1 2 8 log2 gini 200: Weighted 0.832948 (0.059011)\n",
      "1 2 8 log2 gini 200: Macro 0.735990 (0.074361)\n",
      "Testing 36/432\n",
      "1 2 8 log2 gini 500: Weighted 0.837319 (0.065783)\n",
      "1 2 8 log2 gini 500: Macro 0.743881 (0.086441)\n",
      "Testing 37/432\n",
      "1 2 8 log2 entropy 50: Weighted 0.833217 (0.063073)\n",
      "1 2 8 log2 entropy 50: Macro 0.731159 (0.088216)\n",
      "Testing 38/432\n",
      "1 2 8 log2 entropy 100: Weighted 0.827185 (0.059093)\n",
      "1 2 8 log2 entropy 100: Macro 0.730599 (0.073536)\n",
      "Testing 39/432\n",
      "1 2 8 log2 entropy 200: Weighted 0.828047 (0.062153)\n",
      "1 2 8 log2 entropy 200: Macro 0.733323 (0.076557)\n",
      "Testing 40/432\n",
      "1 2 8 log2 entropy 500: Weighted 0.837174 (0.065769)\n",
      "1 2 8 log2 entropy 500: Macro 0.746514 (0.086782)\n",
      "Testing 41/432\n",
      "1 2 8 sqrt gini 50: Weighted 0.824696 (0.075814)\n",
      "1 2 8 sqrt gini 50: Macro 0.732097 (0.098498)\n",
      "Testing 42/432\n",
      "1 2 8 sqrt gini 100: Weighted 0.835326 (0.080421)\n",
      "1 2 8 sqrt gini 100: Macro 0.737151 (0.121283)\n",
      "Testing 43/432\n",
      "1 2 8 sqrt gini 200: Weighted 0.823112 (0.064179)\n",
      "1 2 8 sqrt gini 200: Macro 0.719209 (0.086963)\n",
      "Testing 44/432\n",
      "1 2 8 sqrt gini 500: Weighted 0.828556 (0.064064)\n",
      "1 2 8 sqrt gini 500: Macro 0.733089 (0.082199)\n",
      "Testing 45/432\n",
      "1 2 8 sqrt entropy 50: Weighted 0.833634 (0.068063)\n",
      "1 2 8 sqrt entropy 50: Macro 0.741192 (0.090036)\n",
      "Testing 46/432\n",
      "1 2 8 sqrt entropy 100: Weighted 0.826745 (0.070477)\n",
      "1 2 8 sqrt entropy 100: Macro 0.726532 (0.094283)\n",
      "Testing 47/432\n",
      "1 2 8 sqrt entropy 200: Weighted 0.837854 (0.071862)\n",
      "1 2 8 sqrt entropy 200: Macro 0.748488 (0.096046)\n",
      "Testing 48/432\n",
      "1 2 8 sqrt entropy 500: Weighted 0.837138 (0.065765)\n",
      "1 2 8 sqrt entropy 500: Macro 0.744806 (0.086533)\n",
      "Testing 49/432\n",
      "1 4 3 log2 gini 50: Weighted 0.790049 (0.058029)\n",
      "1 4 3 log2 gini 50: Macro 0.669973 (0.061726)\n",
      "Testing 50/432\n",
      "1 4 3 log2 gini 100: Weighted 0.817377 (0.064630)\n",
      "1 4 3 log2 gini 100: Macro 0.706246 (0.079497)\n",
      "Testing 51/432\n",
      "1 4 3 log2 gini 200: Weighted 0.814173 (0.088510)\n",
      "1 4 3 log2 gini 200: Macro 0.718677 (0.115450)\n",
      "Testing 52/432\n",
      "1 4 3 log2 gini 500: Weighted 0.819621 (0.075766)\n",
      "1 4 3 log2 gini 500: Macro 0.720612 (0.099102)\n",
      "Testing 53/432\n",
      "1 4 3 log2 entropy 50: Weighted 0.818187 (0.091856)\n",
      "1 4 3 log2 entropy 50: Macro 0.722564 (0.122597)\n",
      "Testing 54/432\n",
      "1 4 3 log2 entropy 100: Weighted 0.814356 (0.083146)\n",
      "1 4 3 log2 entropy 100: Macro 0.715075 (0.107002)\n",
      "Testing 55/432\n",
      "1 4 3 log2 entropy 200: Weighted 0.818650 (0.088116)\n",
      "1 4 3 log2 entropy 200: Macro 0.721229 (0.111928)\n",
      "Testing 56/432\n",
      "1 4 3 log2 entropy 500: Weighted 0.811717 (0.079270)\n",
      "1 4 3 log2 entropy 500: Macro 0.705053 (0.092894)\n",
      "Testing 57/432\n",
      "1 4 3 sqrt gini 50: Weighted 0.824311 (0.065404)\n",
      "1 4 3 sqrt gini 50: Macro 0.721199 (0.079142)\n",
      "Testing 58/432\n",
      "1 4 3 sqrt gini 100: Weighted 0.830352 (0.078637)\n",
      "1 4 3 sqrt gini 100: Macro 0.737286 (0.099415)\n",
      "Testing 59/432\n",
      "1 4 3 sqrt gini 200: Weighted 0.818335 (0.094772)\n",
      "1 4 3 sqrt gini 200: Macro 0.725512 (0.122469)\n",
      "Testing 60/432\n",
      "1 4 3 sqrt gini 500: Weighted 0.833234 (0.062389)\n",
      "1 4 3 sqrt gini 500: Macro 0.735019 (0.080512)\n",
      "Testing 61/432\n",
      "1 4 3 sqrt entropy 50: Weighted 0.813238 (0.053755)\n",
      "1 4 3 sqrt entropy 50: Macro 0.699349 (0.062955)\n",
      "Testing 62/432\n",
      "1 4 3 sqrt entropy 100: Weighted 0.819919 (0.075343)\n",
      "1 4 3 sqrt entropy 100: Macro 0.716878 (0.104569)\n",
      "Testing 63/432\n",
      "1 4 3 sqrt entropy 200: Weighted 0.817957 (0.081466)\n",
      "1 4 3 sqrt entropy 200: Macro 0.720277 (0.104595)\n",
      "Testing 64/432\n",
      "1 4 3 sqrt entropy 500: Weighted 0.819142 (0.074198)\n",
      "1 4 3 sqrt entropy 500: Macro 0.713246 (0.091780)\n",
      "Testing 65/432\n",
      "1 4 5 log2 gini 50: Weighted 0.822294 (0.066271)\n",
      "1 4 5 log2 gini 50: Macro 0.723169 (0.088633)\n",
      "Testing 66/432\n",
      "1 4 5 log2 gini 100: Weighted 0.839904 (0.049830)\n",
      "1 4 5 log2 gini 100: Macro 0.742190 (0.068156)\n",
      "Testing 67/432\n",
      "1 4 5 log2 gini 200: Weighted 0.828811 (0.068613)\n",
      "1 4 5 log2 gini 200: Macro 0.731076 (0.089104)\n",
      "Testing 68/432\n",
      "1 4 5 log2 gini 500: Weighted 0.838197 (0.063767)\n",
      "1 4 5 log2 gini 500: Macro 0.744235 (0.084277)\n",
      "Testing 69/432\n",
      "1 4 5 log2 entropy 50: Weighted 0.828052 (0.065699)\n",
      "1 4 5 log2 entropy 50: Macro 0.731704 (0.082501)\n",
      "Testing 70/432\n",
      "1 4 5 log2 entropy 100: Weighted 0.835026 (0.059990)\n",
      "1 4 5 log2 entropy 100: Macro 0.734909 (0.080664)\n",
      "Testing 71/432\n",
      "1 4 5 log2 entropy 200: Weighted 0.839988 (0.061277)\n",
      "1 4 5 log2 entropy 200: Macro 0.744126 (0.084434)\n",
      "Testing 72/432\n",
      "1 4 5 log2 entropy 500: Weighted 0.828963 (0.056389)\n",
      "1 4 5 log2 entropy 500: Macro 0.727721 (0.070741)\n",
      "Testing 73/432\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 4 5 sqrt gini 50: Weighted 0.817388 (0.054129)\n",
      "1 4 5 sqrt gini 50: Macro 0.702524 (0.074655)\n",
      "Testing 74/432\n",
      "1 4 5 sqrt gini 100: Weighted 0.828989 (0.052823)\n",
      "1 4 5 sqrt gini 100: Macro 0.717875 (0.072166)\n",
      "Testing 75/432\n",
      "1 4 5 sqrt gini 200: Weighted 0.844175 (0.055698)\n",
      "1 4 5 sqrt gini 200: Macro 0.749488 (0.076889)\n",
      "Testing 76/432\n",
      "1 4 5 sqrt gini 500: Weighted 0.848545 (0.062042)\n",
      "1 4 5 sqrt gini 500: Macro 0.757379 (0.087414)\n",
      "Testing 77/432\n",
      "1 4 5 sqrt entropy 50: Weighted 0.834976 (0.048236)\n",
      "1 4 5 sqrt entropy 50: Macro 0.734682 (0.063802)\n",
      "Testing 78/432\n",
      "1 4 5 sqrt entropy 100: Weighted 0.827696 (0.058987)\n",
      "1 4 5 sqrt entropy 100: Macro 0.720674 (0.075132)\n",
      "Testing 79/432\n",
      "1 4 5 sqrt entropy 200: Weighted 0.833269 (0.062395)\n",
      "1 4 5 sqrt entropy 200: Macro 0.736727 (0.080986)\n",
      "Testing 80/432\n",
      "1 4 5 sqrt entropy 500: Weighted 0.838197 (0.063767)\n",
      "1 4 5 sqrt entropy 500: Macro 0.744235 (0.084277)\n",
      "Testing 81/432\n",
      "1 4 8 log2 gini 50: Weighted 0.815535 (0.070481)\n",
      "1 4 8 log2 gini 50: Macro 0.708830 (0.095099)\n",
      "Testing 82/432\n",
      "1 4 8 log2 gini 100: Weighted 0.841852 (0.063507)\n",
      "1 4 8 log2 gini 100: Macro 0.748444 (0.084881)\n",
      "Testing 83/432\n",
      "1 4 8 log2 gini 200: Weighted 0.824079 (0.070094)\n",
      "1 4 8 log2 gini 200: Macro 0.720439 (0.095291)\n",
      "Testing 84/432\n",
      "1 4 8 log2 gini 500: Weighted 0.837640 (0.068815)\n",
      "1 4 8 log2 gini 500: Macro 0.744618 (0.092138)\n",
      "Testing 85/432\n",
      "1 4 8 log2 entropy 50: Weighted 0.824487 (0.046213)\n",
      "1 4 8 log2 entropy 50: Macro 0.728196 (0.050979)\n",
      "Testing 86/432\n",
      "1 4 8 log2 entropy 100: Weighted 0.834216 (0.066758)\n",
      "1 4 8 log2 entropy 100: Macro 0.743871 (0.089919)\n",
      "Testing 87/432\n",
      "1 4 8 log2 entropy 200: Weighted 0.828379 (0.057224)\n",
      "1 4 8 log2 entropy 200: Macro 0.722761 (0.078210)\n",
      "Testing 88/432\n",
      "1 4 8 log2 entropy 500: Weighted 0.843618 (0.061466)\n",
      "1 4 8 log2 entropy 500: Macro 0.749871 (0.085409)\n",
      "Testing 89/432\n",
      "1 4 8 sqrt gini 50: Weighted 0.840033 (0.078644)\n",
      "1 4 8 sqrt gini 50: Macro 0.753130 (0.108694)\n",
      "Testing 90/432\n",
      "1 4 8 sqrt gini 100: Weighted 0.820130 (0.057871)\n",
      "1 4 8 sqrt gini 100: Macro 0.712523 (0.079513)\n",
      "Testing 91/432\n",
      "1 4 8 sqrt gini 200: Weighted 0.834863 (0.068540)\n",
      "1 4 8 sqrt gini 200: Macro 0.738238 (0.093176)\n",
      "Testing 92/432\n",
      "1 4 8 sqrt gini 500: Weighted 0.828612 (0.068840)\n",
      "1 4 8 sqrt gini 500: Macro 0.725001 (0.095011)\n",
      "Testing 93/432\n",
      "1 4 8 sqrt entropy 50: Weighted 0.840685 (0.050450)\n",
      "1 4 8 sqrt entropy 50: Macro 0.749176 (0.066987)\n",
      "Testing 94/432\n",
      "1 4 8 sqrt entropy 100: Weighted 0.846453 (0.070689)\n",
      "1 4 8 sqrt entropy 100: Macro 0.758886 (0.098547)\n",
      "Testing 95/432\n",
      "1 4 8 sqrt entropy 200: Weighted 0.842101 (0.066784)\n",
      "1 4 8 sqrt entropy 200: Macro 0.754022 (0.089039)\n",
      "Testing 96/432\n",
      "1 4 8 sqrt entropy 500: Weighted 0.819668 (0.056908)\n",
      "1 4 8 sqrt entropy 500: Macro 0.716015 (0.069538)\n",
      "Testing 97/432\n",
      "1 6 3 log2 gini 50: Weighted 0.825066 (0.077036)\n",
      "1 6 3 log2 gini 50: Macro 0.729090 (0.104179)\n",
      "Testing 98/432\n",
      "1 6 3 log2 gini 100: Weighted 0.816958 (0.072526)\n",
      "1 6 3 log2 gini 100: Macro 0.716001 (0.096247)\n",
      "Testing 99/432\n",
      "1 6 3 log2 gini 200: Weighted 0.808742 (0.074935)\n",
      "1 6 3 log2 gini 200: Macro 0.700897 (0.098945)\n",
      "Testing 100/432\n",
      "1 6 3 log2 gini 500: Weighted 0.820456 (0.085383)\n",
      "1 6 3 log2 gini 500: Macro 0.721344 (0.111755)\n",
      "Testing 101/432\n",
      "1 6 3 log2 entropy 50: Weighted 0.831734 (0.048584)\n",
      "1 6 3 log2 entropy 50: Macro 0.727539 (0.054145)\n",
      "Testing 102/432\n",
      "1 6 3 log2 entropy 100: Weighted 0.810739 (0.082903)\n",
      "1 6 3 log2 entropy 100: Macro 0.707886 (0.113384)\n",
      "Testing 103/432\n",
      "1 6 3 log2 entropy 200: Weighted 0.827904 (0.077992)\n",
      "1 6 3 log2 entropy 200: Macro 0.733772 (0.101294)\n",
      "Testing 104/432\n",
      "1 6 3 log2 entropy 500: Weighted 0.827558 (0.081213)\n",
      "1 6 3 log2 entropy 500: Macro 0.733855 (0.108251)\n",
      "Testing 105/432\n",
      "1 6 3 sqrt gini 50: Weighted 0.812406 (0.083429)\n",
      "1 6 3 sqrt gini 50: Macro 0.713126 (0.118789)\n",
      "Testing 106/432\n",
      "1 6 3 sqrt gini 100: Weighted 0.831637 (0.085313)\n",
      "1 6 3 sqrt gini 100: Macro 0.740660 (0.110772)\n",
      "Testing 107/432\n",
      "1 6 3 sqrt gini 200: Weighted 0.809421 (0.070367)\n",
      "1 6 3 sqrt gini 200: Macro 0.702830 (0.083705)\n",
      "Testing 108/432\n",
      "1 6 3 sqrt gini 500: Weighted 0.805846 (0.077564)\n",
      "1 6 3 sqrt gini 500: Macro 0.699777 (0.090484)\n",
      "Testing 109/432\n",
      "1 6 3 sqrt entropy 50: Weighted 0.810010 (0.056608)\n",
      "1 6 3 sqrt entropy 50: Macro 0.700534 (0.062599)\n",
      "Testing 110/432\n",
      "1 6 3 sqrt entropy 100: Weighted 0.829750 (0.068091)\n",
      "1 6 3 sqrt entropy 100: Macro 0.738541 (0.084654)\n",
      "Testing 111/432\n",
      "1 6 3 sqrt entropy 200: Weighted 0.820185 (0.088557)\n",
      "1 6 3 sqrt entropy 200: Macro 0.719861 (0.116274)\n",
      "Testing 112/432\n",
      "1 6 3 sqrt entropy 500: Weighted 0.811525 (0.089267)\n",
      "1 6 3 sqrt entropy 500: Macro 0.703446 (0.120159)\n",
      "Testing 113/432\n",
      "1 6 5 log2 gini 50: Weighted 0.815392 (0.067787)\n",
      "1 6 5 log2 gini 50: Macro 0.706623 (0.082783)\n",
      "Testing 114/432\n",
      "1 6 5 log2 gini 100: Weighted 0.832151 (0.057137)\n",
      "1 6 5 log2 gini 100: Macro 0.731476 (0.078127)\n",
      "Testing 115/432\n",
      "1 6 5 log2 gini 200: Weighted 0.848545 (0.062042)\n",
      "1 6 5 log2 gini 200: Macro 0.757379 (0.087414)\n",
      "Testing 116/432\n",
      "1 6 5 log2 gini 500: Weighted 0.834387 (0.054937)\n",
      "1 6 5 log2 gini 500: Macro 0.733061 (0.073035)\n",
      "Testing 117/432\n",
      "1 6 5 log2 entropy 50: Weighted 0.811704 (0.056678)\n",
      "1 6 5 log2 entropy 50: Macro 0.698252 (0.075154)\n",
      "Testing 118/432\n",
      "1 6 5 log2 entropy 100: Weighted 0.837604 (0.068812)\n",
      "1 6 5 log2 entropy 100: Macro 0.742910 (0.091869)\n",
      "Testing 119/432\n",
      "1 6 5 log2 entropy 200: Weighted 0.828322 (0.074566)\n",
      "1 6 5 log2 entropy 200: Macro 0.730049 (0.098960)\n",
      "Testing 120/432\n",
      "1 6 5 log2 entropy 500: Weighted 0.838197 (0.063767)\n",
      "1 6 5 log2 entropy 500: Macro 0.744235 (0.084277)\n",
      "Testing 121/432\n",
      "1 6 5 sqrt gini 50: Weighted 0.842391 (0.055092)\n",
      "1 6 5 sqrt gini 50: Macro 0.746603 (0.068217)\n",
      "Testing 122/432\n",
      "1 6 5 sqrt gini 100: Weighted 0.828202 (0.063463)\n",
      "1 6 5 sqrt gini 100: Macro 0.726274 (0.079676)\n",
      "Testing 123/432\n",
      "1 6 5 sqrt gini 200: Weighted 0.843618 (0.061466)\n",
      "1 6 5 sqrt gini 200: Macro 0.749871 (0.085409)\n",
      "Testing 124/432\n",
      "1 6 5 sqrt gini 500: Weighted 0.832780 (0.068919)\n",
      "1 6 5 sqrt gini 500: Macro 0.735699 (0.091781)\n",
      "Testing 125/432\n",
      "1 6 5 sqrt entropy 50: Weighted 0.833141 (0.054953)\n",
      "1 6 5 sqrt entropy 50: Macro 0.731690 (0.067765)\n",
      "Testing 126/432\n",
      "1 6 5 sqrt entropy 100: Weighted 0.821208 (0.064585)\n",
      "1 6 5 sqrt entropy 100: Macro 0.717216 (0.083429)\n",
      "Testing 127/432\n",
      "1 6 5 sqrt entropy 200: Weighted 0.843583 (0.061466)\n",
      "1 6 5 sqrt entropy 200: Macro 0.748163 (0.085224)\n",
      "Testing 128/432\n",
      "1 6 5 sqrt entropy 500: Weighted 0.832926 (0.070624)\n",
      "1 6 5 sqrt entropy 500: Macro 0.740980 (0.093514)\n",
      "Testing 129/432\n",
      "1 6 8 log2 gini 50: Weighted 0.837788 (0.055286)\n",
      "1 6 8 log2 gini 50: Macro 0.744119 (0.073110)\n",
      "Testing 130/432\n",
      "1 6 8 log2 gini 100: Weighted 0.823666 (0.058647)\n",
      "1 6 8 log2 gini 100: Macro 0.719122 (0.078824)\n",
      "Testing 131/432\n",
      "1 6 8 log2 gini 200: Weighted 0.841887 (0.063508)\n",
      "1 6 8 log2 gini 200: Macro 0.750152 (0.085062)\n",
      "Testing 132/432\n",
      "1 6 8 log2 gini 500: Weighted 0.841852 (0.063507)\n",
      "1 6 8 log2 gini 500: Macro 0.748444 (0.084881)\n",
      "Testing 133/432\n",
      "1 6 8 log2 entropy 50: Weighted 0.839904 (0.049830)\n",
      "1 6 8 log2 entropy 50: Macro 0.742190 (0.068156)\n",
      "Testing 134/432\n",
      "1 6 8 log2 entropy 100: Weighted 0.837945 (0.076146)\n",
      "1 6 8 log2 entropy 100: Macro 0.742109 (0.108640)\n",
      "Testing 135/432\n",
      "1 6 8 log2 entropy 200: Weighted 0.832780 (0.068919)\n",
      "1 6 8 log2 entropy 200: Macro 0.735699 (0.091781)\n",
      "Testing 136/432\n",
      "1 6 8 log2 entropy 500: Weighted 0.833926 (0.058275)\n",
      "1 6 8 log2 entropy 500: Macro 0.736937 (0.075890)\n",
      "Testing 137/432\n",
      "1 6 8 sqrt gini 50: Weighted 0.836303 (0.058697)\n",
      "1 6 8 sqrt gini 50: Macro 0.739452 (0.081204)\n",
      "Testing 138/432\n",
      "1 6 8 sqrt gini 100: Weighted 0.840993 (0.063847)\n",
      "1 6 8 sqrt gini 100: Macro 0.749230 (0.084582)\n",
      "Testing 139/432\n",
      "1 6 8 sqrt gini 200: Weighted 0.833926 (0.058275)\n",
      "1 6 8 sqrt gini 200: Macro 0.736937 (0.075890)\n",
      "Testing 140/432\n",
      "1 6 8 sqrt gini 500: Weighted 0.839431 (0.066528)\n",
      "1 6 8 sqrt gini 500: Macro 0.744509 (0.092283)\n",
      "Testing 141/432\n",
      "1 6 8 sqrt entropy 50: Weighted 0.835980 (0.064183)\n",
      "1 6 8 sqrt entropy 50: Macro 0.743168 (0.084975)\n",
      "Testing 142/432\n",
      "1 6 8 sqrt entropy 100: Weighted 0.832272 (0.053567)\n",
      "1 6 8 sqrt entropy 100: Macro 0.726584 (0.071108)\n",
      "Testing 143/432\n",
      "1 6 8 sqrt entropy 200: Weighted 0.828652 (0.062154)\n",
      "1 6 8 sqrt entropy 200: Macro 0.726951 (0.079734)\n",
      "Testing 144/432\n",
      "1 6 8 sqrt entropy 500: Weighted 0.837270 (0.063897)\n",
      "1 6 8 sqrt entropy 500: Macro 0.740376 (0.085421)\n",
      "Testing 145/432\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 2 3 log2 gini 50: Weighted 0.807242 (0.084959)\n",
      "3 2 3 log2 gini 50: Macro 0.704112 (0.111517)\n",
      "Testing 146/432\n",
      "3 2 3 log2 gini 100: Weighted 0.826909 (0.070253)\n",
      "3 2 3 log2 gini 100: Macro 0.730899 (0.087707)\n",
      "Testing 147/432\n",
      "3 2 3 log2 gini 200: Weighted 0.813662 (0.081209)\n",
      "3 2 3 log2 gini 200: Macro 0.716892 (0.116890)\n",
      "Testing 148/432\n",
      "3 2 3 log2 gini 500: Weighted 0.819498 (0.085587)\n",
      "3 2 3 log2 gini 500: Macro 0.721793 (0.111645)\n",
      "Testing 149/432\n",
      "3 2 3 log2 entropy 50: Weighted 0.813810 (0.082222)\n",
      "3 2 3 log2 entropy 50: Macro 0.707754 (0.104609)\n",
      "Testing 150/432\n",
      "3 2 3 log2 entropy 100: Weighted 0.809607 (0.092191)\n",
      "3 2 3 log2 entropy 100: Macro 0.703018 (0.120820)\n",
      "Testing 151/432\n",
      "3 2 3 log2 entropy 200: Weighted 0.833267 (0.082444)\n",
      "3 2 3 log2 entropy 200: Macro 0.743065 (0.114439)\n",
      "Testing 152/432\n",
      "3 2 3 log2 entropy 500: Weighted 0.814456 (0.075604)\n",
      "3 2 3 log2 entropy 500: Macro 0.709638 (0.092761)\n",
      "Testing 153/432\n",
      "3 2 3 sqrt gini 50: Weighted 0.819135 (0.076818)\n",
      "3 2 3 sqrt gini 50: Macro 0.720423 (0.095441)\n",
      "Testing 154/432\n",
      "3 2 3 sqrt gini 100: Weighted 0.809859 (0.071272)\n",
      "3 2 3 sqrt gini 100: Macro 0.699731 (0.092039)\n",
      "Testing 155/432\n",
      "3 2 3 sqrt gini 200: Weighted 0.805982 (0.060352)\n",
      "3 2 3 sqrt gini 200: Macro 0.693462 (0.070012)\n",
      "Testing 156/432\n",
      "3 2 3 sqrt gini 500: Weighted 0.814935 (0.077173)\n",
      "3 2 3 sqrt gini 500: Macro 0.717004 (0.100276)\n",
      "Testing 157/432\n",
      "3 2 3 sqrt entropy 50: Weighted 0.811675 (0.056741)\n",
      "3 2 3 sqrt entropy 50: Macro 0.697368 (0.063301)\n",
      "Testing 158/432\n",
      "3 2 3 sqrt entropy 100: Weighted 0.804162 (0.071737)\n",
      "3 2 3 sqrt entropy 100: Macro 0.690610 (0.094806)\n",
      "Testing 159/432\n",
      "3 2 3 sqrt entropy 200: Weighted 0.817355 (0.079535)\n",
      "3 2 3 sqrt entropy 200: Macro 0.721058 (0.099527)\n",
      "Testing 160/432\n",
      "3 2 3 sqrt entropy 500: Weighted 0.824707 (0.098340)\n",
      "3 2 3 sqrt entropy 500: Macro 0.734361 (0.133654)\n",
      "Testing 161/432\n",
      "3 2 5 log2 gini 50: Weighted 0.818564 (0.063988)\n",
      "3 2 5 log2 gini 50: Macro 0.706711 (0.088014)\n",
      "Testing 162/432\n",
      "3 2 5 log2 gini 100: Weighted 0.829944 (0.067858)\n",
      "3 2 5 log2 gini 100: Macro 0.735275 (0.088700)\n",
      "Testing 163/432\n",
      "3 2 5 log2 gini 200: Weighted 0.837640 (0.068815)\n",
      "3 2 5 log2 gini 200: Macro 0.744618 (0.092138)\n",
      "Testing 164/432\n",
      "3 2 5 log2 gini 500: Weighted 0.828556 (0.064064)\n",
      "3 2 5 log2 gini 500: Macro 0.733089 (0.082199)\n",
      "Testing 165/432\n",
      "3 2 5 log2 entropy 50: Weighted 0.808213 (0.061765)\n",
      "3 2 5 log2 entropy 50: Macro 0.694095 (0.078655)\n",
      "Testing 166/432\n",
      "3 2 5 log2 entropy 100: Weighted 0.824123 (0.059026)\n",
      "3 2 5 log2 entropy 100: Macro 0.719487 (0.074250)\n",
      "Testing 167/432\n",
      "3 2 5 log2 entropy 200: Weighted 0.838197 (0.063767)\n",
      "3 2 5 log2 entropy 200: Macro 0.744235 (0.084277)\n",
      "Testing 168/432\n",
      "3 2 5 log2 entropy 500: Weighted 0.832926 (0.070624)\n",
      "3 2 5 log2 entropy 500: Macro 0.740980 (0.093514)\n",
      "Testing 169/432\n",
      "3 2 5 sqrt gini 50: Weighted 0.831219 (0.059983)\n",
      "3 2 5 sqrt gini 50: Macro 0.733691 (0.073996)\n",
      "Testing 170/432\n",
      "3 2 5 sqrt gini 100: Weighted 0.834398 (0.069942)\n",
      "3 2 5 sqrt gini 100: Macro 0.738238 (0.093629)\n",
      "Testing 171/432\n",
      "3 2 5 sqrt gini 200: Weighted 0.837854 (0.071862)\n",
      "3 2 5 sqrt gini 200: Macro 0.748488 (0.096046)\n",
      "Testing 172/432\n",
      "3 2 5 sqrt gini 500: Weighted 0.833269 (0.062395)\n",
      "3 2 5 sqrt gini 500: Macro 0.736727 (0.080986)\n",
      "Testing 173/432\n",
      "3 2 5 sqrt entropy 50: Weighted 0.819702 (0.071794)\n",
      "3 2 5 sqrt entropy 50: Macro 0.722676 (0.091769)\n",
      "Testing 174/432\n",
      "3 2 5 sqrt entropy 100: Weighted 0.824929 (0.077747)\n",
      "3 2 5 sqrt entropy 100: Macro 0.730007 (0.103103)\n",
      "Testing 175/432\n",
      "3 2 5 sqrt entropy 200: Weighted 0.838109 (0.075915)\n",
      "3 2 5 sqrt entropy 200: Macro 0.746476 (0.102322)\n",
      "Testing 176/432\n",
      "3 2 5 sqrt entropy 500: Weighted 0.824097 (0.069833)\n",
      "3 2 5 sqrt entropy 500: Macro 0.727438 (0.089980)\n",
      "Testing 177/432\n",
      "3 2 8 log2 gini 50: Weighted 0.814842 (0.070672)\n",
      "3 2 8 log2 gini 50: Macro 0.713757 (0.089244)\n",
      "Testing 178/432\n",
      "3 2 8 log2 gini 100: Weighted 0.825580 (0.061727)\n",
      "3 2 8 log2 gini 100: Macro 0.730559 (0.078256)\n",
      "Testing 179/432\n",
      "3 2 8 log2 gini 200: Weighted 0.826344 (0.070481)\n",
      "3 2 8 log2 gini 200: Macro 0.730072 (0.092374)\n",
      "Testing 180/432\n",
      "3 2 8 log2 gini 500: Weighted 0.826187 (0.071475)\n",
      "3 2 8 log2 gini 500: Macro 0.728412 (0.092057)\n",
      "Testing 181/432\n",
      "3 2 8 log2 entropy 50: Weighted 0.836389 (0.078830)\n",
      "3 2 8 log2 entropy 50: Macro 0.745046 (0.113273)\n",
      "Testing 182/432\n",
      "3 2 8 log2 entropy 100: Weighted 0.832216 (0.062883)\n",
      "3 2 8 log2 entropy 100: Macro 0.740779 (0.076226)\n",
      "Testing 183/432\n",
      "3 2 8 log2 entropy 200: Weighted 0.829944 (0.067858)\n",
      "3 2 8 log2 entropy 200: Macro 0.735275 (0.088700)\n",
      "Testing 184/432\n",
      "3 2 8 log2 entropy 500: Weighted 0.833100 (0.056660)\n",
      "3 2 8 log2 entropy 500: Macro 0.736245 (0.068445)\n",
      "Testing 185/432\n",
      "3 2 8 sqrt gini 50: Weighted 0.823092 (0.068182)\n",
      "3 2 8 sqrt gini 50: Macro 0.722944 (0.087309)\n",
      "Testing 186/432\n",
      "3 2 8 sqrt gini 100: Weighted 0.834655 (0.057962)\n",
      "3 2 8 sqrt gini 100: Macro 0.738716 (0.070522)\n",
      "Testing 187/432\n",
      "3 2 8 sqrt gini 200: Weighted 0.834121 (0.074226)\n",
      "3 2 8 sqrt gini 200: Macro 0.746432 (0.095228)\n",
      "Testing 188/432\n",
      "3 2 8 sqrt gini 500: Weighted 0.829352 (0.072551)\n",
      "3 2 8 sqrt gini 500: Macro 0.733950 (0.095819)\n",
      "Testing 189/432\n",
      "3 2 8 sqrt entropy 50: Weighted 0.817556 (0.073934)\n",
      "3 2 8 sqrt entropy 50: Macro 0.714868 (0.096581)\n",
      "Testing 190/432\n",
      "3 2 8 sqrt entropy 100: Weighted 0.816969 (0.062809)\n",
      "3 2 8 sqrt entropy 100: Macro 0.715438 (0.080618)\n",
      "Testing 191/432\n",
      "3 2 8 sqrt entropy 200: Weighted 0.823020 (0.056121)\n",
      "3 2 8 sqrt entropy 200: Macro 0.720778 (0.066341)\n",
      "Testing 192/432\n",
      "3 2 8 sqrt entropy 500: Weighted 0.832780 (0.068919)\n",
      "3 2 8 sqrt entropy 500: Macro 0.735699 (0.091781)\n",
      "Testing 193/432\n",
      "3 4 3 log2 gini 50: Weighted 0.802895 (0.084481)\n",
      "3 4 3 log2 gini 50: Macro 0.687815 (0.111218)\n",
      "Testing 194/432\n",
      "3 4 3 log2 gini 100: Weighted 0.812609 (0.072708)\n",
      "3 4 3 log2 gini 100: Macro 0.704686 (0.095280)\n",
      "Testing 195/432\n",
      "3 4 3 log2 gini 200: Weighted 0.822643 (0.079957)\n",
      "3 4 3 log2 gini 200: Macro 0.723886 (0.103355)\n",
      "Testing 196/432\n",
      "3 4 3 log2 gini 500: Weighted 0.814935 (0.077173)\n",
      "3 4 3 log2 gini 500: Macro 0.717004 (0.100276)\n",
      "Testing 197/432\n",
      "3 4 3 log2 entropy 50: Weighted 0.815562 (0.090105)\n",
      "3 4 3 log2 entropy 50: Macro 0.717000 (0.111064)\n",
      "Testing 198/432\n",
      "3 4 3 log2 entropy 100: Weighted 0.814734 (0.096234)\n",
      "3 4 3 log2 entropy 100: Macro 0.720309 (0.124750)\n",
      "Testing 199/432\n",
      "3 4 3 log2 entropy 200: Weighted 0.818662 (0.075985)\n",
      "3 4 3 log2 entropy 200: Macro 0.721062 (0.098982)\n",
      "Testing 200/432\n",
      "3 4 3 log2 entropy 500: Weighted 0.821032 (0.093357)\n",
      "3 4 3 log2 entropy 500: Macro 0.733522 (0.122226)\n",
      "Testing 201/432\n",
      "3 4 3 sqrt gini 50: Weighted 0.801356 (0.093165)\n",
      "3 4 3 sqrt gini 50: Macro 0.695002 (0.124261)\n",
      "Testing 202/432\n",
      "3 4 3 sqrt gini 100: Weighted 0.802455 (0.064414)\n",
      "3 4 3 sqrt gini 100: Macro 0.685564 (0.077866)\n",
      "Testing 203/432\n",
      "3 4 3 sqrt gini 200: Weighted 0.817656 (0.080402)\n",
      "3 4 3 sqrt gini 200: Macro 0.718865 (0.098437)\n",
      "Testing 204/432\n",
      "3 4 3 sqrt gini 500: Weighted 0.807644 (0.085159)\n",
      "3 4 3 sqrt gini 500: Macro 0.703461 (0.101767)\n",
      "Testing 205/432\n",
      "3 4 3 sqrt entropy 50: Weighted 0.830267 (0.078992)\n",
      "3 4 3 sqrt entropy 50: Macro 0.741578 (0.100010)\n",
      "Testing 206/432\n",
      "3 4 3 sqrt entropy 100: Weighted 0.804198 (0.078819)\n",
      "3 4 3 sqrt entropy 100: Macro 0.692821 (0.098309)\n",
      "Testing 207/432\n",
      "3 4 3 sqrt entropy 200: Weighted 0.809977 (0.076894)\n",
      "3 4 3 sqrt entropy 200: Macro 0.706858 (0.096255)\n",
      "Testing 208/432\n",
      "3 4 3 sqrt entropy 500: Weighted 0.818717 (0.089326)\n",
      "3 4 3 sqrt entropy 500: Macro 0.721732 (0.116978)\n",
      "Testing 209/432\n",
      "3 4 5 log2 gini 50: Weighted 0.823806 (0.061246)\n",
      "3 4 5 log2 gini 50: Macro 0.718158 (0.074433)\n",
      "Testing 210/432\n",
      "3 4 5 log2 gini 100: Weighted 0.829857 (0.079373)\n",
      "3 4 5 log2 gini 100: Macro 0.737515 (0.106184)\n",
      "Testing 211/432\n",
      "3 4 5 log2 gini 200: Weighted 0.815950 (0.062633)\n",
      "3 4 5 log2 gini 200: Macro 0.705141 (0.084031)\n",
      "Testing 212/432\n",
      "3 4 5 log2 gini 500: Weighted 0.824929 (0.077747)\n",
      "3 4 5 log2 gini 500: Macro 0.730007 (0.103103)\n",
      "Testing 213/432\n",
      "3 4 5 log2 entropy 50: Weighted 0.815337 (0.052534)\n",
      "3 4 5 log2 entropy 50: Macro 0.709153 (0.070535)\n",
      "Testing 214/432\n",
      "3 4 5 log2 entropy 100: Weighted 0.828701 (0.075585)\n",
      "3 4 5 log2 entropy 100: Macro 0.734330 (0.101705)\n",
      "Testing 215/432\n",
      "3 4 5 log2 entropy 200: Weighted 0.833738 (0.070177)\n",
      "3 4 5 log2 entropy 200: Macro 0.738584 (0.092565)\n",
      "Testing 216/432\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 4 5 log2 entropy 500: Weighted 0.838197 (0.063767)\n",
      "3 4 5 log2 entropy 500: Macro 0.744235 (0.084277)\n",
      "Testing 217/432\n",
      "3 4 5 sqrt gini 50: Weighted 0.823409 (0.044222)\n",
      "3 4 5 sqrt gini 50: Macro 0.710106 (0.053175)\n",
      "Testing 218/432\n",
      "3 4 5 sqrt gini 100: Weighted 0.821316 (0.054268)\n",
      "3 4 5 sqrt gini 100: Macro 0.716984 (0.070625)\n",
      "Testing 219/432\n",
      "3 4 5 sqrt gini 200: Weighted 0.825017 (0.065956)\n",
      "3 4 5 sqrt gini 200: Macro 0.727766 (0.084789)\n",
      "Testing 220/432\n",
      "3 4 5 sqrt gini 500: Weighted 0.837945 (0.076146)\n",
      "3 4 5 sqrt gini 500: Macro 0.742109 (0.108640)\n",
      "Testing 221/432\n",
      "3 4 5 sqrt entropy 50: Weighted 0.820083 (0.056327)\n",
      "3 4 5 sqrt entropy 50: Macro 0.716515 (0.070679)\n",
      "Testing 222/432\n",
      "3 4 5 sqrt entropy 100: Weighted 0.823023 (0.078791)\n",
      "3 4 5 sqrt entropy 100: Macro 0.724313 (0.106333)\n",
      "Testing 223/432\n",
      "3 4 5 sqrt entropy 200: Weighted 0.820523 (0.071341)\n",
      "3 4 5 sqrt entropy 200: Macro 0.720407 (0.091337)\n",
      "Testing 224/432\n",
      "3 4 5 sqrt entropy 500: Weighted 0.824097 (0.069833)\n",
      "3 4 5 sqrt entropy 500: Macro 0.727438 (0.089980)\n",
      "Testing 225/432\n",
      "3 4 8 log2 gini 50: Weighted 0.826433 (0.065264)\n",
      "3 4 8 log2 gini 50: Macro 0.730296 (0.081333)\n",
      "Testing 226/432\n",
      "3 4 8 log2 gini 100: Weighted 0.837227 (0.063722)\n",
      "3 4 8 log2 gini 100: Macro 0.744993 (0.081168)\n",
      "Testing 227/432\n",
      "3 4 8 log2 gini 200: Weighted 0.829339 (0.072803)\n",
      "3 4 8 log2 gini 200: Macro 0.736291 (0.091970)\n",
      "Testing 228/432\n",
      "3 4 8 log2 gini 500: Weighted 0.829025 (0.071695)\n",
      "3 4 8 log2 gini 500: Macro 0.734946 (0.093700)\n",
      "Testing 229/432\n",
      "3 4 8 log2 entropy 50: Weighted 0.827048 (0.055559)\n",
      "3 4 8 log2 entropy 50: Macro 0.718215 (0.078904)\n",
      "Testing 230/432\n",
      "3 4 8 log2 entropy 100: Weighted 0.823614 (0.068482)\n",
      "3 4 8 log2 entropy 100: Macro 0.726904 (0.089169)\n",
      "Testing 231/432\n",
      "3 4 8 log2 entropy 200: Weighted 0.819425 (0.056887)\n",
      "3 4 8 log2 entropy 200: Macro 0.716872 (0.069635)\n",
      "Testing 232/432\n",
      "3 4 8 log2 entropy 500: Weighted 0.847015 (0.063946)\n",
      "3 4 8 log2 entropy 500: Macro 0.761421 (0.082305)\n",
      "Testing 233/432\n",
      "3 4 8 sqrt gini 50: Weighted 0.828767 (0.088603)\n",
      "3 4 8 sqrt gini 50: Macro 0.731870 (0.125728)\n",
      "Testing 234/432\n",
      "3 4 8 sqrt gini 100: Weighted 0.834639 (0.067853)\n",
      "3 4 8 sqrt gini 100: Macro 0.735268 (0.098610)\n",
      "Testing 235/432\n",
      "3 4 8 sqrt gini 200: Weighted 0.830714 (0.076619)\n",
      "3 4 8 sqrt gini 200: Macro 0.737963 (0.102804)\n",
      "Testing 236/432\n",
      "3 4 8 sqrt gini 500: Weighted 0.824981 (0.065946)\n",
      "3 4 8 sqrt gini 500: Macro 0.726058 (0.084155)\n",
      "Testing 237/432\n",
      "3 4 8 sqrt entropy 50: Weighted 0.815262 (0.070709)\n",
      "3 4 8 sqrt entropy 50: Macro 0.711681 (0.088183)\n",
      "Testing 238/432\n",
      "3 4 8 sqrt entropy 100: Weighted 0.833678 (0.084005)\n",
      "3 4 8 sqrt entropy 100: Macro 0.744827 (0.117144)\n",
      "Testing 239/432\n",
      "3 4 8 sqrt entropy 200: Weighted 0.829857 (0.079373)\n",
      "3 4 8 sqrt entropy 200: Macro 0.737515 (0.106184)\n",
      "Testing 240/432\n",
      "3 4 8 sqrt entropy 500: Weighted 0.833483 (0.065755)\n",
      "3 4 8 sqrt entropy 500: Macro 0.740597 (0.085762)\n",
      "Testing 241/432\n",
      "3 6 3 log2 gini 50: Weighted 0.803557 (0.067022)\n",
      "3 6 3 log2 gini 50: Macro 0.697917 (0.078570)\n",
      "Testing 242/432\n",
      "3 6 3 log2 gini 100: Weighted 0.816767 (0.071255)\n",
      "3 6 3 log2 gini 100: Macro 0.711241 (0.082795)\n",
      "Testing 243/432\n",
      "3 6 3 log2 gini 200: Weighted 0.803035 (0.095183)\n",
      "3 6 3 log2 gini 200: Macro 0.696718 (0.125120)\n",
      "Testing 244/432\n",
      "3 6 3 log2 gini 500: Weighted 0.808428 (0.082791)\n",
      "3 6 3 log2 gini 500: Macro 0.705310 (0.100151)\n",
      "Testing 245/432\n",
      "3 6 3 log2 entropy 50: Weighted 0.812866 (0.065774)\n",
      "3 6 3 log2 entropy 50: Macro 0.705153 (0.087869)\n",
      "Testing 246/432\n",
      "3 6 3 log2 entropy 100: Weighted 0.808414 (0.098251)\n",
      "3 6 3 log2 entropy 100: Macro 0.709723 (0.132183)\n",
      "Testing 247/432\n",
      "3 6 3 log2 entropy 200: Weighted 0.808377 (0.084103)\n",
      "3 6 3 log2 entropy 200: Macro 0.700189 (0.106663)\n",
      "Testing 248/432\n",
      "3 6 3 log2 entropy 500: Weighted 0.814300 (0.090047)\n",
      "3 6 3 log2 entropy 500: Macro 0.718833 (0.119162)\n",
      "Testing 249/432\n",
      "3 6 3 sqrt gini 50: Weighted 0.806453 (0.097125)\n",
      "3 6 3 sqrt gini 50: Macro 0.699232 (0.130164)\n",
      "Testing 250/432\n",
      "3 6 3 sqrt gini 100: Weighted 0.821239 (0.078618)\n",
      "3 6 3 sqrt gini 100: Macro 0.726677 (0.092158)\n",
      "Testing 251/432\n",
      "3 6 3 sqrt gini 200: Weighted 0.816232 (0.076993)\n",
      "3 6 3 sqrt gini 200: Macro 0.714970 (0.091445)\n",
      "Testing 252/432\n",
      "3 6 3 sqrt gini 500: Weighted 0.809957 (0.076427)\n",
      "3 6 3 sqrt gini 500: Macro 0.699816 (0.092602)\n",
      "Testing 253/432\n",
      "3 6 3 sqrt entropy 50: Weighted 0.815696 (0.079330)\n",
      "3 6 3 sqrt entropy 50: Macro 0.715563 (0.100212)\n",
      "Testing 254/432\n",
      "3 6 3 sqrt entropy 100: Weighted 0.814279 (0.078014)\n",
      "3 6 3 sqrt entropy 100: Macro 0.717171 (0.099040)\n",
      "Testing 255/432\n",
      "3 6 3 sqrt entropy 200: Weighted 0.803320 (0.078397)\n",
      "3 6 3 sqrt entropy 200: Macro 0.695244 (0.099914)\n",
      "Testing 256/432\n",
      "3 6 3 sqrt entropy 500: Weighted 0.809001 (0.086927)\n",
      "3 6 3 sqrt entropy 500: Macro 0.708404 (0.107960)\n",
      "Testing 257/432\n",
      "3 6 5 log2 gini 50: Weighted 0.815581 (0.058381)\n",
      "3 6 5 log2 gini 50: Macro 0.713251 (0.072812)\n",
      "Testing 258/432\n",
      "3 6 5 log2 gini 100: Weighted 0.812151 (0.049653)\n",
      "3 6 5 log2 gini 100: Macro 0.699014 (0.055188)\n",
      "Testing 259/432\n",
      "3 6 5 log2 gini 200: Weighted 0.829857 (0.079373)\n",
      "3 6 5 log2 gini 200: Macro 0.737515 (0.106184)\n",
      "Testing 260/432\n",
      "3 6 5 log2 gini 500: Weighted 0.828067 (0.070401)\n",
      "3 6 5 log2 gini 500: Macro 0.732061 (0.092812)\n",
      "Testing 261/432\n",
      "3 6 5 log2 entropy 50: Weighted 0.836494 (0.047770)\n",
      "3 6 5 log2 entropy 50: Macro 0.733654 (0.064143)\n",
      "Testing 262/432\n",
      "3 6 5 log2 entropy 100: Weighted 0.836726 (0.068756)\n",
      "3 6 5 log2 entropy 100: Macro 0.745333 (0.092279)\n",
      "Testing 263/432\n",
      "3 6 5 log2 entropy 200: Weighted 0.833396 (0.077587)\n",
      "3 6 5 log2 entropy 200: Macro 0.742838 (0.103627)\n",
      "Testing 264/432\n",
      "3 6 5 log2 entropy 500: Weighted 0.833396 (0.077587)\n",
      "3 6 5 log2 entropy 500: Macro 0.742838 (0.103627)\n",
      "Testing 265/432\n",
      "3 6 5 sqrt gini 50: Weighted 0.817139 (0.065071)\n",
      "3 6 5 sqrt gini 50: Macro 0.707112 (0.088302)\n",
      "Testing 266/432\n",
      "3 6 5 sqrt gini 100: Weighted 0.821051 (0.068121)\n",
      "3 6 5 sqrt gini 100: Macro 0.717960 (0.093794)\n",
      "Testing 267/432\n",
      "3 6 5 sqrt gini 200: Weighted 0.830172 (0.071243)\n",
      "3 6 5 sqrt gini 200: Macro 0.733233 (0.094376)\n",
      "Testing 268/432\n",
      "3 6 5 sqrt gini 500: Weighted 0.832891 (0.070618)\n",
      "3 6 5 sqrt gini 500: Macro 0.739272 (0.093182)\n",
      "Testing 269/432\n",
      "3 6 5 sqrt entropy 50: Weighted 0.828565 (0.074553)\n",
      "3 6 5 sqrt entropy 50: Macro 0.729192 (0.099006)\n",
      "Testing 270/432\n",
      "3 6 5 sqrt entropy 100: Weighted 0.824364 (0.075033)\n",
      "3 6 5 sqrt entropy 100: Macro 0.719807 (0.102878)\n",
      "Testing 271/432\n",
      "3 6 5 sqrt entropy 200: Weighted 0.828521 (0.064055)\n",
      "3 6 5 sqrt entropy 200: Macro 0.731380 (0.081656)\n",
      "Testing 272/432\n",
      "3 6 5 sqrt entropy 500: Weighted 0.837854 (0.071862)\n",
      "3 6 5 sqrt entropy 500: Macro 0.748488 (0.096046)\n",
      "Testing 273/432\n",
      "3 6 8 log2 gini 50: Weighted 0.825428 (0.077043)\n",
      "3 6 8 log2 gini 50: Macro 0.737030 (0.100567)\n",
      "Testing 274/432\n",
      "3 6 8 log2 gini 100: Weighted 0.835865 (0.067951)\n",
      "3 6 8 log2 gini 100: Macro 0.739157 (0.094435)\n",
      "Testing 275/432\n",
      "3 6 8 log2 gini 200: Weighted 0.828103 (0.072245)\n",
      "3 6 8 log2 gini 200: Macro 0.731475 (0.099801)\n",
      "Testing 276/432\n",
      "3 6 8 log2 gini 500: Weighted 0.832926 (0.070624)\n",
      "3 6 8 log2 gini 500: Macro 0.740980 (0.093514)\n",
      "Testing 277/432\n",
      "3 6 8 log2 entropy 50: Weighted 0.831921 (0.069120)\n",
      "3 6 8 log2 entropy 50: Macro 0.736486 (0.091613)\n",
      "Testing 278/432\n",
      "3 6 8 log2 entropy 100: Weighted 0.850204 (0.049298)\n",
      "3 6 8 log2 entropy 100: Macro 0.757822 (0.065525)\n",
      "Testing 279/432\n",
      "3 6 8 log2 entropy 200: Weighted 0.828647 (0.068847)\n",
      "3 6 8 log2 entropy 200: Macro 0.726710 (0.095592)\n",
      "Testing 280/432\n",
      "3 6 8 log2 entropy 500: Weighted 0.824528 (0.072103)\n",
      "3 6 8 log2 entropy 500: Macro 0.726739 (0.095057)\n",
      "Testing 281/432\n",
      "3 6 8 sqrt gini 50: Weighted 0.837446 (0.069066)\n",
      "3 6 8 sqrt gini 50: Macro 0.747884 (0.087904)\n",
      "Testing 282/432\n",
      "3 6 8 sqrt gini 100: Weighted 0.820733 (0.074505)\n",
      "3 6 8 sqrt gini 100: Macro 0.724802 (0.094872)\n",
      "Testing 283/432\n",
      "3 6 8 sqrt gini 200: Weighted 0.828556 (0.064064)\n",
      "3 6 8 sqrt gini 200: Macro 0.733089 (0.082199)\n",
      "Testing 284/432\n",
      "3 6 8 sqrt gini 500: Weighted 0.828861 (0.071920)\n",
      "3 6 8 sqrt gini 500: Macro 0.730580 (0.100059)\n",
      "Testing 285/432\n",
      "3 6 8 sqrt entropy 50: Weighted 0.826140 (0.044122)\n",
      "3 6 8 sqrt entropy 50: Macro 0.726086 (0.050467)\n",
      "Testing 286/432\n",
      "3 6 8 sqrt entropy 100: Weighted 0.830374 (0.076850)\n",
      "3 6 8 sqrt entropy 100: Macro 0.736623 (0.105842)\n",
      "Testing 287/432\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 6 8 sqrt entropy 200: Weighted 0.834073 (0.070100)\n",
      "3 6 8 sqrt entropy 200: Macro 0.739266 (0.094300)\n",
      "Testing 288/432\n",
      "3 6 8 sqrt entropy 500: Weighted 0.828556 (0.064064)\n",
      "3 6 8 sqrt entropy 500: Macro 0.733089 (0.082199)\n",
      "Testing 289/432\n",
      "5 2 3 log2 gini 50: Weighted 0.805440 (0.076448)\n",
      "5 2 3 log2 gini 50: Macro 0.698069 (0.095217)\n",
      "Testing 290/432\n",
      "5 2 3 log2 gini 100: Weighted 0.801881 (0.067955)\n",
      "5 2 3 log2 gini 100: Macro 0.690376 (0.083726)\n",
      "Testing 291/432\n",
      "5 2 3 log2 gini 200: Weighted 0.826527 (0.091289)\n",
      "5 2 3 log2 gini 200: Macro 0.736539 (0.120871)\n",
      "Testing 292/432\n",
      "5 2 3 log2 gini 500: Weighted 0.817323 (0.082804)\n",
      "5 2 3 log2 gini 500: Macro 0.720688 (0.107364)\n",
      "Testing 293/432\n",
      "5 2 3 log2 entropy 50: Weighted 0.807626 (0.087020)\n",
      "5 2 3 log2 entropy 50: Macro 0.707861 (0.110760)\n",
      "Testing 294/432\n",
      "5 2 3 log2 entropy 100: Weighted 0.830389 (0.094108)\n",
      "5 2 3 log2 entropy 100: Macro 0.747981 (0.120278)\n",
      "Testing 295/432\n",
      "5 2 3 log2 entropy 200: Weighted 0.805464 (0.080387)\n",
      "5 2 3 log2 entropy 200: Macro 0.697834 (0.103895)\n",
      "Testing 296/432\n",
      "5 2 3 log2 entropy 500: Weighted 0.808856 (0.085550)\n",
      "5 2 3 log2 entropy 500: Macro 0.707555 (0.113872)\n",
      "Testing 297/432\n",
      "5 2 3 sqrt gini 50: Weighted 0.825830 (0.098051)\n",
      "5 2 3 sqrt gini 50: Macro 0.738532 (0.134806)\n",
      "Testing 298/432\n",
      "5 2 3 sqrt gini 100: Weighted 0.819811 (0.080107)\n",
      "5 2 3 sqrt gini 100: Macro 0.718045 (0.103421)\n",
      "Testing 299/432\n",
      "5 2 3 sqrt gini 200: Weighted 0.818571 (0.080097)\n",
      "5 2 3 sqrt gini 200: Macro 0.708128 (0.105448)\n",
      "Testing 300/432\n",
      "5 2 3 sqrt gini 500: Weighted 0.827418 (0.066755)\n",
      "5 2 3 sqrt gini 500: Macro 0.724425 (0.082171)\n",
      "Testing 301/432\n",
      "5 2 3 sqrt entropy 50: Weighted 0.811154 (0.076369)\n",
      "5 2 3 sqrt entropy 50: Macro 0.704196 (0.104242)\n",
      "Testing 302/432\n",
      "5 2 3 sqrt entropy 100: Weighted 0.816829 (0.068663)\n",
      "5 2 3 sqrt entropy 100: Macro 0.705379 (0.089175)\n",
      "Testing 303/432\n",
      "5 2 3 sqrt entropy 200: Weighted 0.823372 (0.069533)\n",
      "5 2 3 sqrt entropy 200: Macro 0.726889 (0.090674)\n",
      "Testing 304/432\n",
      "5 2 3 sqrt entropy 500: Weighted 0.807193 (0.079301)\n",
      "5 2 3 sqrt entropy 500: Macro 0.700151 (0.092758)\n",
      "Testing 305/432\n",
      "5 2 5 log2 gini 50: Weighted 0.816984 (0.064288)\n",
      "5 2 5 log2 gini 50: Macro 0.714796 (0.083225)\n",
      "Testing 306/432\n",
      "5 2 5 log2 gini 100: Weighted 0.833080 (0.070529)\n",
      "5 2 5 log2 gini 100: Macro 0.738008 (0.093732)\n",
      "Testing 307/432\n",
      "5 2 5 log2 gini 200: Weighted 0.833396 (0.077587)\n",
      "5 2 5 log2 gini 200: Macro 0.742838 (0.103627)\n",
      "Testing 308/432\n",
      "5 2 5 log2 gini 500: Weighted 0.832891 (0.070618)\n",
      "5 2 5 log2 gini 500: Macro 0.739272 (0.093182)\n",
      "Testing 309/432\n",
      "5 2 5 log2 entropy 50: Weighted 0.819885 (0.058456)\n",
      "5 2 5 log2 entropy 50: Macro 0.721934 (0.079573)\n",
      "Testing 310/432\n",
      "5 2 5 log2 entropy 100: Weighted 0.821293 (0.079812)\n",
      "5 2 5 log2 entropy 100: Macro 0.723096 (0.105468)\n",
      "Testing 311/432\n",
      "5 2 5 log2 entropy 200: Weighted 0.821416 (0.068393)\n",
      "5 2 5 log2 entropy 200: Macro 0.722564 (0.088184)\n",
      "Testing 312/432\n",
      "5 2 5 log2 entropy 500: Weighted 0.824250 (0.057880)\n",
      "5 2 5 log2 entropy 500: Macro 0.724083 (0.071671)\n",
      "Testing 313/432\n",
      "5 2 5 sqrt gini 50: Weighted 0.827947 (0.058512)\n",
      "5 2 5 sqrt gini 50: Macro 0.728286 (0.072004)\n",
      "Testing 314/432\n",
      "5 2 5 sqrt gini 100: Weighted 0.826504 (0.076958)\n",
      "5 2 5 sqrt gini 100: Macro 0.727562 (0.102979)\n",
      "Testing 315/432\n",
      "5 2 5 sqrt gini 200: Weighted 0.820157 (0.065130)\n",
      "5 2 5 sqrt gini 200: Macro 0.718847 (0.082601)\n",
      "Testing 316/432\n",
      "5 2 5 sqrt gini 500: Weighted 0.833269 (0.062395)\n",
      "5 2 5 sqrt gini 500: Macro 0.736727 (0.080986)\n",
      "Testing 317/432\n",
      "5 2 5 sqrt entropy 50: Weighted 0.816958 (0.073393)\n",
      "5 2 5 sqrt entropy 50: Macro 0.716913 (0.094853)\n",
      "Testing 318/432\n",
      "5 2 5 sqrt entropy 100: Weighted 0.807827 (0.065626)\n",
      "5 2 5 sqrt entropy 100: Macro 0.700696 (0.081024)\n",
      "Testing 319/432\n",
      "5 2 5 sqrt entropy 200: Weighted 0.822561 (0.075677)\n",
      "5 2 5 sqrt entropy 200: Macro 0.728345 (0.099760)\n",
      "Testing 320/432\n",
      "5 2 5 sqrt entropy 500: Weighted 0.828521 (0.064055)\n",
      "5 2 5 sqrt entropy 500: Macro 0.731380 (0.081656)\n",
      "Testing 321/432\n",
      "5 2 8 log2 gini 50: Weighted 0.825578 (0.071547)\n",
      "5 2 8 log2 gini 50: Macro 0.725108 (0.095912)\n",
      "Testing 322/432\n",
      "5 2 8 log2 gini 100: Weighted 0.823696 (0.063484)\n",
      "5 2 8 log2 gini 100: Macro 0.724170 (0.080531)\n",
      "Testing 323/432\n",
      "5 2 8 log2 gini 200: Weighted 0.824604 (0.060537)\n",
      "5 2 8 log2 gini 200: Macro 0.728142 (0.072806)\n",
      "Testing 324/432\n",
      "5 2 8 log2 gini 500: Weighted 0.824528 (0.072103)\n",
      "5 2 8 log2 gini 500: Macro 0.726739 (0.095057)\n",
      "Testing 325/432\n",
      "5 2 8 log2 entropy 50: Weighted 0.822938 (0.063791)\n",
      "5 2 8 log2 entropy 50: Macro 0.725065 (0.080281)\n",
      "Testing 326/432\n",
      "5 2 8 log2 entropy 100: Weighted 0.824251 (0.069757)\n",
      "5 2 8 log2 entropy 100: Macro 0.724466 (0.089760)\n",
      "Testing 327/432\n",
      "5 2 8 log2 entropy 200: Weighted 0.824981 (0.065946)\n",
      "5 2 8 log2 entropy 200: Macro 0.726058 (0.084155)\n",
      "Testing 328/432\n",
      "5 2 8 log2 entropy 500: Weighted 0.824528 (0.072103)\n",
      "5 2 8 log2 entropy 500: Macro 0.726739 (0.095057)\n",
      "Testing 329/432\n",
      "5 2 8 sqrt gini 50: Weighted 0.824876 (0.056245)\n",
      "5 2 8 sqrt gini 50: Macro 0.727964 (0.072205)\n",
      "Testing 330/432\n",
      "5 2 8 sqrt gini 100: Weighted 0.824981 (0.065946)\n",
      "5 2 8 sqrt gini 100: Macro 0.726058 (0.084155)\n",
      "Testing 331/432\n",
      "5 2 8 sqrt gini 200: Weighted 0.829352 (0.072551)\n",
      "5 2 8 sqrt gini 200: Macro 0.733950 (0.095819)\n",
      "Testing 332/432\n",
      "5 2 8 sqrt gini 500: Weighted 0.829387 (0.072558)\n",
      "5 2 8 sqrt gini 500: Macro 0.735658 (0.096236)\n",
      "Testing 333/432\n",
      "5 2 8 sqrt entropy 50: Weighted 0.811452 (0.063843)\n",
      "5 2 8 sqrt entropy 50: Macro 0.704457 (0.079301)\n",
      "Testing 334/432\n",
      "5 2 8 sqrt entropy 100: Weighted 0.823884 (0.063412)\n",
      "5 2 8 sqrt entropy 100: Macro 0.722906 (0.080932)\n",
      "Testing 335/432\n",
      "5 2 8 sqrt entropy 200: Weighted 0.823696 (0.063484)\n",
      "5 2 8 sqrt entropy 200: Macro 0.724170 (0.080531)\n",
      "Testing 336/432\n",
      "5 2 8 sqrt entropy 500: Weighted 0.820157 (0.065130)\n",
      "5 2 8 sqrt entropy 500: Macro 0.718847 (0.082601)\n",
      "Testing 337/432\n",
      "5 4 3 log2 gini 50: Weighted 0.807595 (0.073599)\n",
      "5 4 3 log2 gini 50: Macro 0.699069 (0.086997)\n",
      "Testing 338/432\n",
      "5 4 3 log2 gini 100: Weighted 0.811161 (0.068253)\n",
      "5 4 3 log2 gini 100: Macro 0.704700 (0.084969)\n",
      "Testing 339/432\n",
      "5 4 3 log2 gini 200: Weighted 0.814654 (0.082780)\n",
      "5 4 3 log2 gini 200: Macro 0.711340 (0.111900)\n",
      "Testing 340/432\n",
      "5 4 3 log2 gini 500: Weighted 0.822062 (0.093672)\n",
      "5 4 3 log2 gini 500: Macro 0.729570 (0.121127)\n",
      "Testing 341/432\n",
      "5 4 3 log2 entropy 50: Weighted 0.812024 (0.082916)\n",
      "5 4 3 log2 entropy 50: Macro 0.712151 (0.102057)\n",
      "Testing 342/432\n",
      "5 4 3 log2 entropy 100: Weighted 0.833627 (0.082318)\n",
      "5 4 3 log2 entropy 100: Macro 0.743744 (0.114150)\n",
      "Testing 343/432\n",
      "5 4 3 log2 entropy 200: Weighted 0.820197 (0.085515)\n",
      "5 4 3 log2 entropy 200: Macro 0.721868 (0.110725)\n",
      "Testing 344/432\n",
      "5 4 3 log2 entropy 500: Weighted 0.810808 (0.084361)\n",
      "5 4 3 log2 entropy 500: Macro 0.708518 (0.107795)\n",
      "Testing 345/432\n",
      "5 4 3 sqrt gini 50: Weighted 0.807092 (0.081926)\n",
      "5 4 3 sqrt gini 50: Macro 0.698301 (0.103356)\n",
      "Testing 346/432\n",
      "5 4 3 sqrt gini 100: Weighted 0.824918 (0.077138)\n",
      "5 4 3 sqrt gini 100: Macro 0.726360 (0.110038)\n",
      "Testing 347/432\n",
      "5 4 3 sqrt gini 200: Weighted 0.812936 (0.083004)\n",
      "5 4 3 sqrt gini 200: Macro 0.712396 (0.116657)\n",
      "Testing 348/432\n",
      "5 4 3 sqrt gini 500: Weighted 0.818028 (0.089057)\n",
      "5 4 3 sqrt gini 500: Macro 0.722891 (0.118012)\n",
      "Testing 349/432\n",
      "5 4 3 sqrt entropy 50: Weighted 0.836588 (0.069316)\n",
      "5 4 3 sqrt entropy 50: Macro 0.744178 (0.092432)\n",
      "Testing 350/432\n",
      "5 4 3 sqrt entropy 100: Weighted 0.808591 (0.076424)\n",
      "5 4 3 sqrt entropy 100: Macro 0.699780 (0.087595)\n",
      "Testing 351/432\n",
      "5 4 3 sqrt entropy 200: Weighted 0.822082 (0.086893)\n",
      "5 4 3 sqrt entropy 200: Macro 0.720753 (0.110525)\n",
      "Testing 352/432\n",
      "5 4 3 sqrt entropy 500: Weighted 0.823033 (0.082121)\n",
      "5 4 3 sqrt entropy 500: Macro 0.728954 (0.109432)\n",
      "Testing 353/432\n",
      "5 4 5 log2 gini 50: Weighted 0.809615 (0.054226)\n",
      "5 4 5 log2 gini 50: Macro 0.692778 (0.076194)\n",
      "Testing 354/432\n",
      "5 4 5 log2 gini 100: Weighted 0.826503 (0.074009)\n",
      "5 4 5 log2 gini 100: Macro 0.732888 (0.095013)\n",
      "Testing 355/432\n",
      "5 4 5 log2 gini 200: Weighted 0.829376 (0.072537)\n",
      "5 4 5 log2 gini 200: Macro 0.732508 (0.096672)\n",
      "Testing 356/432\n",
      "5 4 5 log2 gini 500: Weighted 0.832891 (0.070618)\n",
      "5 4 5 log2 gini 500: Macro 0.739272 (0.093182)\n",
      "Testing 357/432\n",
      "5 4 5 log2 entropy 50: Weighted 0.813557 (0.054302)\n",
      "5 4 5 log2 entropy 50: Macro 0.697505 (0.060494)\n",
      "Testing 358/432\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 4 5 log2 entropy 100: Weighted 0.819905 (0.077233)\n",
      "5 4 5 log2 entropy 100: Macro 0.716722 (0.106840)\n",
      "Testing 359/432\n",
      "5 4 5 log2 entropy 200: Weighted 0.829857 (0.079373)\n",
      "5 4 5 log2 entropy 200: Macro 0.737515 (0.106184)\n",
      "Testing 360/432\n",
      "5 4 5 log2 entropy 500: Weighted 0.819791 (0.063909)\n",
      "5 4 5 log2 entropy 500: Macro 0.718432 (0.079842)\n",
      "Testing 361/432\n",
      "5 4 5 sqrt gini 50: Weighted 0.823325 (0.064971)\n",
      "5 4 5 sqrt gini 50: Macro 0.718269 (0.087147)\n",
      "Testing 362/432\n",
      "5 4 5 sqrt gini 100: Weighted 0.832999 (0.082974)\n",
      "5 4 5 sqrt gini 100: Macro 0.742355 (0.113390)\n",
      "Testing 363/432\n",
      "5 4 5 sqrt gini 200: Weighted 0.822984 (0.056108)\n",
      "5 4 5 sqrt gini 200: Macro 0.719070 (0.065347)\n",
      "Testing 364/432\n",
      "5 4 5 sqrt gini 500: Weighted 0.824528 (0.072103)\n",
      "5 4 5 sqrt gini 500: Macro 0.726739 (0.095057)\n",
      "Testing 365/432\n",
      "5 4 5 sqrt entropy 50: Weighted 0.823659 (0.063949)\n",
      "5 4 5 sqrt entropy 50: Macro 0.722824 (0.077985)\n",
      "Testing 366/432\n",
      "5 4 5 sqrt entropy 100: Weighted 0.819307 (0.054608)\n",
      "5 4 5 sqrt entropy 100: Macro 0.710145 (0.062914)\n",
      "Testing 367/432\n",
      "5 4 5 sqrt entropy 200: Weighted 0.829352 (0.072551)\n",
      "5 4 5 sqrt entropy 200: Macro 0.733950 (0.095819)\n",
      "Testing 368/432\n",
      "5 4 5 sqrt entropy 500: Weighted 0.823696 (0.063484)\n",
      "5 4 5 sqrt entropy 500: Macro 0.724170 (0.080531)\n",
      "Testing 369/432\n",
      "5 4 8 log2 gini 50: Weighted 0.830719 (0.059407)\n",
      "5 4 8 log2 gini 50: Macro 0.732265 (0.077652)\n",
      "Testing 370/432\n",
      "5 4 8 log2 gini 100: Weighted 0.839560 (0.070998)\n",
      "5 4 8 log2 gini 100: Macro 0.746196 (0.097267)\n",
      "Testing 371/432\n",
      "5 4 8 log2 gini 200: Weighted 0.820157 (0.065130)\n",
      "5 4 8 log2 gini 200: Macro 0.718847 (0.082601)\n",
      "Testing 372/432\n",
      "5 4 8 log2 gini 500: Weighted 0.832891 (0.070618)\n",
      "5 4 8 log2 gini 500: Macro 0.739272 (0.093182)\n",
      "Testing 373/432\n",
      "5 4 8 log2 entropy 50: Weighted 0.826398 (0.060029)\n",
      "5 4 8 log2 entropy 50: Macro 0.730148 (0.083787)\n",
      "Testing 374/432\n",
      "5 4 8 log2 entropy 100: Weighted 0.830063 (0.063421)\n",
      "5 4 8 log2 entropy 100: Macro 0.732054 (0.082628)\n",
      "Testing 375/432\n",
      "5 4 8 log2 entropy 200: Weighted 0.821679 (0.076356)\n",
      "5 4 8 log2 entropy 200: Macro 0.720352 (0.101819)\n",
      "Testing 376/432\n",
      "5 4 8 log2 entropy 500: Weighted 0.833483 (0.065755)\n",
      "5 4 8 log2 entropy 500: Macro 0.740597 (0.085762)\n",
      "Testing 377/432\n",
      "5 4 8 sqrt gini 50: Weighted 0.829464 (0.061072)\n",
      "5 4 8 sqrt gini 50: Macro 0.737060 (0.074170)\n",
      "Testing 378/432\n",
      "5 4 8 sqrt gini 100: Weighted 0.833483 (0.065755)\n",
      "5 4 8 sqrt gini 100: Macro 0.740597 (0.085762)\n",
      "Testing 379/432\n",
      "5 4 8 sqrt gini 200: Weighted 0.829944 (0.067858)\n",
      "5 4 8 sqrt gini 200: Macro 0.735275 (0.088700)\n",
      "Testing 380/432\n",
      "5 4 8 sqrt gini 500: Weighted 0.829387 (0.072558)\n",
      "5 4 8 sqrt gini 500: Macro 0.735658 (0.096236)\n",
      "Testing 381/432\n",
      "5 4 8 sqrt entropy 50: Weighted 0.829050 (0.071843)\n",
      "5 4 8 sqrt entropy 50: Macro 0.729316 (0.100463)\n",
      "Testing 382/432\n",
      "5 4 8 sqrt entropy 100: Weighted 0.833003 (0.058756)\n",
      "5 4 8 sqrt entropy 100: Macro 0.742383 (0.070496)\n",
      "Testing 383/432\n",
      "5 4 8 sqrt entropy 200: Weighted 0.839438 (0.059311)\n",
      "5 4 8 sqrt entropy 200: Macro 0.748857 (0.074392)\n",
      "Testing 384/432\n",
      "5 4 8 sqrt entropy 500: Weighted 0.824981 (0.065946)\n",
      "5 4 8 sqrt entropy 500: Macro 0.726058 (0.084155)\n",
      "Testing 385/432\n",
      "5 6 3 log2 gini 50: Weighted 0.812245 (0.039948)\n",
      "5 6 3 log2 gini 50: Macro 0.699949 (0.038821)\n",
      "Testing 386/432\n",
      "5 6 3 log2 gini 100: Weighted 0.813764 (0.067257)\n",
      "5 6 3 log2 gini 100: Macro 0.702668 (0.079754)\n",
      "Testing 387/432\n",
      "5 6 3 log2 gini 200: Weighted 0.816583 (0.085377)\n",
      "5 6 3 log2 gini 200: Macro 0.717269 (0.112494)\n",
      "Testing 388/432\n",
      "5 6 3 log2 gini 500: Weighted 0.814615 (0.083029)\n",
      "5 6 3 log2 gini 500: Macro 0.714550 (0.108034)\n",
      "Testing 389/432\n",
      "5 6 3 log2 entropy 50: Weighted 0.826186 (0.070884)\n",
      "5 6 3 log2 entropy 50: Macro 0.731947 (0.089128)\n",
      "Testing 390/432\n",
      "5 6 3 log2 entropy 100: Weighted 0.814269 (0.079559)\n",
      "5 6 3 log2 entropy 100: Macro 0.710630 (0.104764)\n",
      "Testing 391/432\n",
      "5 6 3 log2 entropy 200: Weighted 0.820479 (0.090810)\n",
      "5 6 3 log2 entropy 200: Macro 0.732373 (0.123508)\n",
      "Testing 392/432\n",
      "5 6 3 log2 entropy 500: Weighted 0.814051 (0.079857)\n",
      "5 6 3 log2 entropy 500: Macro 0.714591 (0.099195)\n",
      "Testing 393/432\n",
      "5 6 3 sqrt gini 50: Weighted 0.809884 (0.095265)\n",
      "5 6 3 sqrt gini 50: Macro 0.708626 (0.126417)\n",
      "Testing 394/432\n",
      "5 6 3 sqrt gini 100: Weighted 0.816334 (0.086691)\n",
      "5 6 3 sqrt gini 100: Macro 0.716736 (0.106470)\n",
      "Testing 395/432\n",
      "5 6 3 sqrt gini 200: Weighted 0.799410 (0.075094)\n",
      "5 6 3 sqrt gini 200: Macro 0.687864 (0.086504)\n",
      "Testing 396/432\n",
      "5 6 3 sqrt gini 500: Weighted 0.811850 (0.085832)\n",
      "5 6 3 sqrt gini 500: Macro 0.714885 (0.108122)\n",
      "Testing 397/432\n",
      "5 6 3 sqrt entropy 50: Weighted 0.814730 (0.081517)\n",
      "5 6 3 sqrt entropy 50: Macro 0.708314 (0.101857)\n",
      "Testing 398/432\n",
      "5 6 3 sqrt entropy 100: Weighted 0.807307 (0.060172)\n",
      "5 6 3 sqrt entropy 100: Macro 0.696107 (0.070034)\n",
      "Testing 399/432\n",
      "5 6 3 sqrt entropy 200: Weighted 0.805659 (0.078424)\n",
      "5 6 3 sqrt entropy 200: Macro 0.703644 (0.100162)\n",
      "Testing 400/432\n",
      "5 6 3 sqrt entropy 500: Weighted 0.810808 (0.084361)\n",
      "5 6 3 sqrt entropy 500: Macro 0.708518 (0.107795)\n",
      "Testing 401/432\n",
      "5 6 5 log2 gini 50: Weighted 0.826308 (0.064481)\n",
      "5 6 5 log2 gini 50: Macro 0.722933 (0.090949)\n",
      "Testing 402/432\n",
      "5 6 5 log2 gini 100: Weighted 0.828521 (0.064055)\n",
      "5 6 5 log2 gini 100: Macro 0.731380 (0.081656)\n",
      "Testing 403/432\n",
      "5 6 5 log2 gini 200: Weighted 0.830714 (0.076619)\n",
      "5 6 5 log2 gini 200: Macro 0.737963 (0.102804)\n",
      "Testing 404/432\n",
      "5 6 5 log2 gini 500: Weighted 0.824894 (0.077739)\n",
      "5 6 5 log2 gini 500: Macro 0.728299 (0.102619)\n",
      "Testing 405/432\n",
      "5 6 5 log2 entropy 50: Weighted 0.833930 (0.082615)\n",
      "5 6 5 log2 entropy 50: Macro 0.740041 (0.110933)\n",
      "Testing 406/432\n",
      "5 6 5 log2 entropy 100: Weighted 0.824285 (0.057892)\n",
      "5 6 5 log2 entropy 100: Macro 0.725791 (0.072461)\n",
      "Testing 407/432\n",
      "5 6 5 log2 entropy 200: Weighted 0.834038 (0.070096)\n",
      "5 6 5 log2 entropy 200: Macro 0.737558 (0.093940)\n",
      "Testing 408/432\n",
      "5 6 5 log2 entropy 500: Weighted 0.824528 (0.072103)\n",
      "5 6 5 log2 entropy 500: Macro 0.726739 (0.095057)\n",
      "Testing 409/432\n",
      "5 6 5 sqrt gini 50: Weighted 0.828327 (0.064298)\n",
      "5 6 5 sqrt gini 50: Macro 0.734646 (0.077407)\n",
      "Testing 410/432\n",
      "5 6 5 sqrt gini 100: Weighted 0.839361 (0.071093)\n",
      "5 6 5 sqrt gini 100: Macro 0.747454 (0.096579)\n",
      "Testing 411/432\n",
      "5 6 5 sqrt gini 200: Weighted 0.823111 (0.067185)\n",
      "5 6 5 sqrt gini 200: Macro 0.722072 (0.088545)\n",
      "Testing 412/432\n",
      "5 6 5 sqrt gini 500: Weighted 0.829352 (0.072551)\n",
      "5 6 5 sqrt gini 500: Macro 0.733950 (0.095819)\n",
      "Testing 413/432\n",
      "5 6 5 sqrt entropy 50: Weighted 0.828243 (0.058080)\n",
      "5 6 5 sqrt entropy 50: Macro 0.733685 (0.070534)\n",
      "Testing 414/432\n",
      "5 6 5 sqrt entropy 100: Weighted 0.824787 (0.066171)\n",
      "5 6 5 sqrt entropy 100: Macro 0.729324 (0.080256)\n",
      "Testing 415/432\n",
      "5 6 5 sqrt entropy 200: Weighted 0.833115 (0.070534)\n",
      "5 6 5 sqrt entropy 200: Macro 0.739716 (0.094085)\n",
      "Testing 416/432\n",
      "5 6 5 sqrt entropy 500: Weighted 0.824981 (0.065946)\n",
      "5 6 5 sqrt entropy 500: Macro 0.726058 (0.084155)\n",
      "Testing 417/432\n",
      "5 6 8 log2 gini 50: Weighted 0.831554 (0.066840)\n",
      "5 6 8 log2 gini 50: Macro 0.734538 (0.089174)\n",
      "Testing 418/432\n",
      "5 6 8 log2 gini 100: Weighted 0.830293 (0.068416)\n",
      "5 6 8 log2 gini 100: Macro 0.728340 (0.088750)\n",
      "Testing 419/432\n",
      "5 6 8 log2 gini 200: Weighted 0.824528 (0.072103)\n",
      "5 6 8 log2 gini 200: Macro 0.726739 (0.095057)\n",
      "Testing 420/432\n",
      "5 6 8 log2 gini 500: Weighted 0.832891 (0.070618)\n",
      "5 6 8 log2 gini 500: Macro 0.739272 (0.093182)\n",
      "Testing 421/432\n",
      "5 6 8 log2 entropy 50: Weighted 0.825488 (0.061407)\n",
      "5 6 8 log2 entropy 50: Macro 0.724060 (0.080668)\n",
      "Testing 422/432\n",
      "5 6 8 log2 entropy 100: Weighted 0.833799 (0.067858)\n",
      "5 6 8 log2 entropy 100: Macro 0.743244 (0.085897)\n",
      "Testing 423/432\n",
      "5 6 8 log2 entropy 200: Weighted 0.833738 (0.070177)\n",
      "5 6 8 log2 entropy 200: Macro 0.738584 (0.092565)\n",
      "Testing 424/432\n",
      "5 6 8 log2 entropy 500: Weighted 0.829944 (0.067858)\n",
      "5 6 8 log2 entropy 500: Macro 0.735275 (0.088700)\n",
      "Testing 425/432\n",
      "5 6 8 sqrt gini 50: Weighted 0.819087 (0.062793)\n",
      "5 6 8 sqrt gini 50: Macro 0.720415 (0.083185)\n",
      "Testing 426/432\n",
      "5 6 8 sqrt gini 100: Weighted 0.829352 (0.072551)\n",
      "5 6 8 sqrt gini 100: Macro 0.733950 (0.095819)\n",
      "Testing 427/432\n",
      "5 6 8 sqrt gini 200: Weighted 0.837854 (0.071862)\n",
      "5 6 8 sqrt gini 200: Macro 0.748488 (0.096046)\n",
      "Testing 428/432\n",
      "5 6 8 sqrt gini 500: Weighted 0.824981 (0.065946)\n",
      "5 6 8 sqrt gini 500: Macro 0.726058 (0.084155)\n",
      "Testing 429/432\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 6 8 sqrt entropy 50: Weighted 0.837640 (0.068815)\n",
      "5 6 8 sqrt entropy 50: Macro 0.744618 (0.092138)\n",
      "Testing 430/432\n",
      "5 6 8 sqrt entropy 100: Weighted 0.814803 (0.062888)\n",
      "5 6 8 sqrt entropy 100: Macro 0.706855 (0.083847)\n",
      "Testing 431/432\n",
      "5 6 8 sqrt entropy 200: Weighted 0.828409 (0.062170)\n",
      "5 6 8 sqrt entropy 200: Macro 0.727808 (0.079701)\n",
      "Testing 432/432\n",
      "5 6 8 sqrt entropy 500: Weighted 0.820157 (0.065130)\n",
      "5 6 8 sqrt entropy 500: Macro 0.718847 (0.082601)\n"
     ]
    }
   ],
   "source": [
    "results_weighted = []\n",
    "results_macro = []\n",
    "names = []\n",
    "num_tests = 3*3*3*2*2*4\n",
    "i = 1\n",
    "\n",
    "for min_samples_leaf in [1,3,5]:\n",
    "    for min_samples_split in [2,4,6]:\n",
    "        for max_depth in [3,5,8]:\n",
    "            for max_features in [\"log2\",\"sqrt\"]:\n",
    "                for criterion in [\"gini\",  \"entropy\"]:\n",
    "                    for n_estimators in [50, 100, 200, 500]:\n",
    "                        print(\"Testing {}/{}\".format(i,num_tests))\n",
    "                        i+=1\n",
    "                        kf = StratifiedKFold(n_splits=num_folds, random_state=seed)\n",
    "                        sm = SMOTE(random_state=seed, k_neighbors=7, sampling_strategy=\"not majority\")\n",
    "                        cv_results_weighted = np.array([])\n",
    "                        cv_results_macro = np.array([])\n",
    "                        for train_idx, test_idx, in kf.split(X_train, y_train):\n",
    "                            X_cross_train, y_cross_train = X_train.iloc[train_idx], y_train.iloc[train_idx]\n",
    "                            X_cross_test, y_cross_test = X_train.iloc[test_idx], y_train.iloc[test_idx]\n",
    "                            X_cross_train, y_cross_train = sm.fit_sample(X_cross_train, y_cross_train)\n",
    "                            model = ExtraTreesClassifier(min_samples_leaf=min_samples_leaf, \n",
    "                                    min_samples_split=min_samples_split, max_depth=max_depth, max_features=max_features,                           \n",
    "                                    criterion=criterion, n_estimators=n_estimators)\n",
    "                            model.fit(X_cross_train, y_cross_train)  \n",
    "                            y_pred = model.predict(X_cross_test)\n",
    "                            f1s_weight = f1_score(y_cross_test, y_pred, average=\"weighted\")\n",
    "                            f1s_macro = f1_score(y_cross_test, y_pred, average=\"macro\")\n",
    "                            cv_results_weighted = np.append(cv_results_weighted, [f1s_weight])\n",
    "                            cv_results_macro = np.append(cv_results_macro, [f1s_macro])\n",
    "                        results_weighted.append(cv_results_weighted)\n",
    "                        results_macro.append(cv_results_macro)\n",
    "                        name = \"{} {} {} {} {} {}\".format(min_samples_leaf, min_samples_split, max_depth, \n",
    "                            max_features, criterion, n_estimators)\n",
    "                        names.append(name)\n",
    "                        msg = \"%s: Weighted %f (%f)\" % (name, cv_results_weighted.mean(), cv_results_weighted.std())\n",
    "                        print(msg)\n",
    "                        msg = \"%s: Macro %f (%f)\" % (name, cv_results_macro.mean(), cv_results_macro.std())\n",
    "                        print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('names.pkl', 'wb') as f:\n",
    "    pickle.dump(names, f)\n",
    "with open('results_weighted.pkl', 'wb') as f:\n",
    "    pickle.dump(results_weighted, f)\n",
    "with open('results_macro.pkl', 'wb') as f:\n",
    "    pickle.dump(results_macro, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 4 8 log2 entropy 500 - Weighted: 0.7614206169625791 - Normal: 0.8470146292383633\n"
     ]
    }
   ],
   "source": [
    "avg_values_macro = [np.average(item) for item in results_macro]\n",
    "avg_values_weighted = [np.average(item) for item in results_weighted]\n",
    "max_index = avg_values_macro.index(max(avg_values_macro))\n",
    "print(\"{} - Weighted: {} - Normal: {}\".format(names[max_index], avg_values_macro[max_index], avg_values_weighted[max_index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ExtraTreesClassifier(min_samples_leaf=3, min_samples_split= 4, max_depth=8, \n",
    "                                    max_features=\"log2\", criterion='entropy', n_estimators=500)\n",
    "\n",
    "pipeline = Pipeline([('Scaler', StandardScaler()),('Model', model)])\n",
    "\n",
    "pipeline.fit(X_train_res, y_train_res) \n",
    "\n",
    "y_pred = pipeline.predict(X_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1fd51ad3e80>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(y_test, y_pred, classes=class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.62      0.69        16\n",
      "           1       0.25      0.33      0.29         6\n",
      "           2       0.90      0.93      0.92        30\n",
      "\n",
      "    accuracy                           0.77        52\n",
      "   macro avg       0.64      0.63      0.63        52\n",
      "weighted avg       0.79      0.77      0.77        52\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Buone prestazioni nell'identificare normal e obese, fatica a distingure gli overweight ma potrebbe derivare semplicemente dal minor numero di esempi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

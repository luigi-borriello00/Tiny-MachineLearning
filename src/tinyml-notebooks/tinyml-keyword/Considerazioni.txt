Raccogliendo 100 campioni per ogni parola con i quali sono stati testati i vari modelli (Applicando un Robust-Scaler):

- Utilizzando 5 etichette(no, ok, yes, start, stop) notiamo come i modelli non siano affatto efficenti, il migliore Ã¨ stato il Random Forest il quale ha ottenuto
un f1-score pari allo 0,65

GNB - 0,35 0,06
LR - 0,46 0,07
CART - 0,49 0,07
SVC - 0,61 0,06
RF - 0,63 0,06

- Testando i modelli con 3 etichette (tolte start e stop), le performance sono migliorate, tuttavia l'unico modello con f1-score tale da poter essere considerato
"buono" rimane il Random Forest il quale ha misurato un punteggio di 0,81



- Testando i modelli con 2 etichette(no e yes) otteniamo un miglioramento notevole in quasi tutti i modelli, i quali diventano "utilizzabili"

GNB - 0,46 0,13
LR - 0,69 0,14
CART - 0,74 0,11
SVC - 0,84 0,05
RF - 0,86 0,06




- Aumentando i campioni di 50 per ogni label, la precisione non aumenta, anzi va a peggiorare
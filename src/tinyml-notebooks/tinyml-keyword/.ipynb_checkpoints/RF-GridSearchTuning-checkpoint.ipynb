{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8139cab4",
   "metadata": {},
   "source": [
    "# Tuning with Grid Search - Random Forest (150 samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa2c7db",
   "metadata": {},
   "source": [
    "## 01- Import and Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa6efbc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(750, 32)\n"
     ]
    }
   ],
   "source": [
    "# Load libraries\n",
    "import numpy as np\n",
    "from numpy import arange\n",
    "import pickle\n",
    "import pandas as pd\n",
    "#\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#\n",
    "import pandas as pd\n",
    "from pandas import read_csv\n",
    "\n",
    "from sklearn.metrics import confusion_matrix,  classification_report, f1_score, accuracy_score\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold,StratifiedKFold, cross_val_score, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "\n",
    "import tensorflow\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "import warnings\n",
    "import seaborn as sbs\n",
    "import sys\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "tensorflow.random.set_seed(RANDOM_SEED)\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "\n",
    "with open('data/X2.pkl', 'rb') as f:\n",
    "    X = pickle.load(f)\n",
    "\n",
    "with open('data/y2.pkl', 'rb') as f:\n",
    "    y = pickle.load(f)\n",
    "    \n",
    "labels = 5\n",
    "samples = 150\n",
    "X = X[:labels*samples]\n",
    "y = y[:labels*samples]\n",
    "\n",
    "classes = np.unique(y).tolist()\n",
    "for i in range(len(classes)):\n",
    "    y = np.where(y==classes[i], i, y)\n",
    "    \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=RANDOM_SEED)\n",
    "\n",
    "y = np.array(y)\n",
    "\n",
    "scaler = RobustScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fcb18f2",
   "metadata": {},
   "source": [
    "## 02 - Prepare hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a59f37d",
   "metadata": {},
   "source": [
    "Prendiamo in considerazione solamente gli iperparametri **'n_estimators'** ovvero il numero di alberi utilizzati nell'eseguire le predizioni e **'max_features'** ovvero il numero massimo di feature utilizzate per effettuare le predizioni."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e19e750",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model parameters to be test \n",
    "model_params = {\n",
    "    'n_estimators': np.arange(100, 300, 50),\n",
    "    'max_features':  np.arange(1, 33, 4),\n",
    "    'criterion': ['gini', 'entropy'], \n",
    "    'max_depth': [None, 2, 4],\n",
    "    'min_samples_split': np.arange(2, 6, 2),\n",
    "    'min_samples_leaf': np.arange(1, 4, 1),\n",
    "}\n",
    "num_folds = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0388fc13",
   "metadata": {},
   "source": [
    "## 03 - Grid Search SKlearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "725b9b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model = RandomForestClassifier(random_state=RANDOM_SEED)\n",
    "\n",
    "clf = GridSearchCV(rf_model, model_params, cv=num_folds)\n",
    "model = clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "45b32f4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'criterion': 'entropy', 'max_depth': None, 'max_features': 9, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 250} with a score of 0.61\n"
     ]
    }
   ],
   "source": [
    "print(f'Best params: {model.best_params_} with a score of {model.best_score_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a2f33a18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.50      0.50        30\n",
      "           1       0.53      0.64      0.58        25\n",
      "           2       0.57      0.74      0.64        23\n",
      "           3       0.60      0.69      0.64        26\n",
      "           4       0.93      0.61      0.74        46\n",
      "\n",
      "    accuracy                           0.63       150\n",
      "   macro avg       0.63      0.64      0.62       150\n",
      "weighted avg       0.67      0.63      0.63       150\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(X_test)\n",
    "\n",
    "print(classification_report(pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3899b46a",
   "metadata": {},
   "source": [
    "## 04 - Grid-Search reiplemented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6d330ff2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      N_ESTIMATORS  MAX_FEATURES     SCORE\n",
      "0              100             1  0.550000\n",
      "1              100             1  0.587500\n",
      "2              100             1  0.580556\n",
      "3              100             1  0.589583\n",
      "4              100             1  0.561667\n",
      "...            ...           ...       ...\n",
      "5755           250            29  0.566667\n",
      "5756           250            29  0.579167\n",
      "5757           250            29  0.580556\n",
      "5758           250            29  0.570833\n",
      "5759           250            29  0.538333\n",
      "\n",
      "[5760 rows x 3 columns]\n",
      "Best score = 0.61, the best combo is: 250 estimators and 9 features\n"
     ]
    }
   ],
   "source": [
    "def gridSearch(params, X_train, X_test, y_train, y_test):\n",
    "    names = list(params.keys())\n",
    "    values = list(params.values())\n",
    "    best_score, best_values = 0, [0 for item in values]\n",
    "    global_results = []\n",
    "    for estimators in values[0]:\n",
    "        for features in values[1]:\n",
    "            for crit in values[2]:\n",
    "                for depth in values[3]:\n",
    "                    for min_split in values[4]:\n",
    "                        for min_leaf in values[5]:\n",
    "                            model = RandomForestClassifier(random_state=RANDOM_SEED, n_estimators=estimators, \n",
    "                                                           max_features=features, criterion=crit, max_depth=depth,\n",
    "                                                           min_samples_split=min_split, min_samples_leaf=min_leaf\n",
    "                                                          )\n",
    "                            # Cross Validation\n",
    "                            kf = StratifiedKFold(n_splits=num_folds, shuffle=False)\n",
    "                            cv_results = np.array([])\n",
    "                            for train_idx, test_idx, in kf.split(X_train, y_train):\n",
    "                                X_cross_train, y_cross_train = X_train[train_idx], y_train[train_idx]\n",
    "                                X_cross_train = scaler.fit_transform(X_cross_train)\n",
    "                                X_cross_test, y_cross_test = X_train[test_idx], y_train[test_idx]\n",
    "                                X_cross_test = scaler.transform(X_cross_test)\n",
    "                                model.fit(X_cross_train, y_cross_train)  \n",
    "                                y_pred = model.predict(X_cross_test)\n",
    "                                acc = accuracy_score(y_cross_test, y_pred)\n",
    "                                cv_results = np.append(cv_results, [acc])\n",
    "                                global_results.append([estimators, features, cv_results.mean()])\n",
    "                            # Comparing score\n",
    "                            if cv_results.mean() > best_score:\n",
    "                                best_score = cv_results.mean()\n",
    "                                best_values = [estimators, features]\n",
    "    # Print all the combinations results\n",
    "    df = pd.DataFrame(global_results)\n",
    "    df.columns = ['N_ESTIMATORS', 'MAX_FEATURES', 'SCORE']\n",
    "    print(df)\n",
    "    return best_score, best_values\n",
    "\n",
    "best_score, best_combo = gridSearch(model_params, X_train, X_test, y_train, y_test)\n",
    "print(f'Best score = {best_score}, the best combo is: {best_combo[0]} estimators and {best_combo[1]} features')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa544292",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models Comparison for TinyML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Load libraries\n",
    "import numpy as np\n",
    "from numpy import arange\n",
    "import pickle\n",
    "#\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#\n",
    "import pandas as pd\n",
    "from pandas import read_csv\n",
    "\n",
    "from sklearn.metrics import confusion_matrix,  classification_report, f1_score\n",
    "from sklearn.model_selection import train_test_split, KFold,StratifiedKFold, cross_val_score, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from keras.models import Sequential, Model \n",
    "from keras.layers import Dense, Input, concatenate, Activation, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "import tensorflow\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from micromlgen import port\n",
    "import tinymlgen as tiny\n",
    "\n",
    "import warnings\n",
    "import seaborn as sbs\n",
    "import sys\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "tensorflow.random.set_seed(RANDOM_SEED)\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "tasks = [\"2Labels\", \"3Labels\", \"4Labels\", \"5Labels\"]\n",
    "# Change this to change subtask\n",
    "taskIndex = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/X.pkl', 'rb') as f:\n",
    "    X = pickle.load(f)\n",
    "\n",
    "with open('data/y.pkl', 'rb') as f:\n",
    "    y = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_labels = 2 + taskIndex\n",
    "samples = 100\n",
    "X = X[:n_labels*samples]\n",
    "y = y[:n_labels*samples]\n",
    "labels = np.unique(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = np.unique(y).tolist()\n",
    "for i in range(len(classes)):\n",
    "    y = np.where(y==classes[i], i, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
      " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
      " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n",
      " 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n",
      " 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n",
      " 4 4 4 4 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "y = np.array([int(el) for el in y])\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 42)\n",
      "(100,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=RANDOM_SEED)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.1 , -0.04,  0.99,  0.08, -0.03,  0.99,  0.12,  0.06,  1.02,\n",
       "         0.1 , -0.06,  1.16,  0.15, -0.02,  0.93,  0.18, -0.  ,  0.77,\n",
       "         0.17,  0.05,  0.92,  0.11,  0.04,  1.03,  0.07,  0.01,  0.98,\n",
       "         0.04, -0.11,  0.98,  0.1 ,  0.02,  1.02,  0.11,  0.04,  0.99,\n",
       "         0.06, -0.01,  0.98,  0.13,  0.05,  0.91],\n",
       "       [ 0.07,  0.01,  1.  ,  0.08,  0.04,  0.95,  0.09,  0.21,  1.06,\n",
       "         0.08, -0.2 ,  1.13,  0.14, -0.13,  0.86,  0.19,  0.14,  0.68,\n",
       "         0.22,  0.23,  0.91,  0.14,  0.27,  1.08,  0.05,  0.  ,  1.04,\n",
       "         0.06,  0.02,  0.98,  0.07,  0.04,  0.98,  0.08,  0.03,  1.01,\n",
       "         0.08,  0.02,  0.97,  0.07,  0.02,  0.96],\n",
       "       [ 0.05, -0.05,  0.98,  0.01, -0.03,  1.01,  0.03,  0.02,  1.05,\n",
       "         0.11, -0.03,  1.1 ,  0.15, -0.01,  0.82,  0.17,  0.01,  0.8 ,\n",
       "         0.15,  0.08,  0.98,  0.09,  0.15,  1.11,  0.02, -0.02,  1.07,\n",
       "         0.09, -0.02,  0.93,  0.09,  0.03,  1.  ,  0.1 ,  0.09,  1.05,\n",
       "         0.07, -0.01,  0.97,  0.1 ,  0.05,  0.96],\n",
       "       [ 0.04, -0.05,  1.  ,  0.05, -0.03,  0.96,  0.06, -0.22,  1.2 ,\n",
       "         0.11,  0.01,  0.69,  0.08,  0.19,  0.94,  0.01,  0.16,  1.24,\n",
       "        -0.  , -0.06,  1.08,  0.06, -0.05,  0.81,  0.11,  0.06,  0.89,\n",
       "         0.04,  0.16,  1.11, -0.03,  0.01,  1.03, -0.02, -0.  ,  0.97,\n",
       "        -0.01,  0.01,  0.96, -0.02,  0.  ,  0.95],\n",
       "       [ 0.1 , -0.07,  0.98,  0.11, -0.03,  0.95,  0.15, -0.28,  0.97,\n",
       "         0.16, -0.04,  0.76,  0.17,  0.14,  0.86,  0.1 ,  0.16,  1.09,\n",
       "         0.07, -0.09,  1.07,  0.08, -0.05,  0.89,  0.16,  0.01,  0.85,\n",
       "         0.14,  0.07,  0.95,  0.03, -0.02,  1.01,  0.04, -0.1 ,  0.97,\n",
       "         0.07, -0.03,  0.98,  0.08, -0.04,  1.  ],\n",
       "       [-0.06,  0.04,  0.98, -0.08,  0.01,  1.02, -0.02,  0.27,  1.05,\n",
       "        -0.07, -0.22,  1.15,  0.05, -0.15,  0.9 ,  0.16, -0.02,  0.81,\n",
       "         0.18,  0.08,  0.82,  0.15,  0.22,  0.95, -0.  ,  0.08,  1.04,\n",
       "        -0.12, -0.05,  1.08, -0.11, -0.08,  1.01, -0.13, -0.1 ,  0.98,\n",
       "        -0.11, -0.06,  0.98, -0.1 , -0.03,  0.99],\n",
       "       [ 0.04, -0.08,  1.  ,  0.04, -0.02,  0.99,  0.08,  0.05,  1.06,\n",
       "         0.02, -0.2 ,  1.05,  0.11, -0.01,  0.82,  0.14,  0.11,  0.94,\n",
       "         0.08,  0.1 ,  1.08,  0.04, -0.02,  0.96,  0.04, -0.07,  1.  ,\n",
       "         0.07,  0.  ,  1.01,  0.06,  0.01,  1.  ,  0.08,  0.02,  0.98,\n",
       "         0.05, -0.02,  0.97,  0.08,  0.03,  0.95],\n",
       "       [ 0.04, -0.06,  0.99,  0.02, -0.06,  0.99,  0.09,  0.13,  1.08,\n",
       "         0.11, -0.04,  1.14,  0.14,  0.02,  0.6 ,  0.09,  0.04,  0.92,\n",
       "         0.03,  0.19,  1.13, -0.02, -0.09,  1.01, -0.01, -0.04,  0.97,\n",
       "         0.06,  0.06,  0.97,  0.02,  0.02,  0.99,  0.01,  0.02,  0.94,\n",
       "         0.02,  0.04,  0.99,  0.01,  0.03,  0.99],\n",
       "       [-0.04, -0.1 ,  0.99, -0.05, -0.12,  0.99, -0.04, -0.29,  1.05,\n",
       "         0.02,  0.02,  1.08,  0.09,  0.14,  0.78,  0.14,  0.05,  0.83,\n",
       "         0.14, -0.08,  0.82,  0.01, -0.28,  0.95,  0.01, -0.07,  1.08,\n",
       "        -0.03,  0.02,  1.05,  0.02,  0.12,  0.96, -0.02,  0.03,  0.99,\n",
       "         0.03, -0.06,  0.93, -0.  , -0.09,  0.98],\n",
       "       [ 0.05, -0.01,  0.96,  0.08,  0.1 ,  0.95,  0.07,  0.02,  1.04,\n",
       "         0.1 , -0.04,  1.  ,  0.15,  0.05,  0.77,  0.14,  0.09,  0.96,\n",
       "         0.12,  0.15,  1.04,  0.12,  0.04,  1.1 ,  0.13,  0.04,  0.9 ,\n",
       "         0.14,  0.04,  0.88,  0.15,  0.14,  1.02,  0.11,  0.08,  0.99,\n",
       "         0.06, -0.05,  0.99,  0.08,  0.  ,  0.97],\n",
       "       [ 0.1 , -0.08,  0.97,  0.11, -0.07,  0.95,  0.1 ,  0.04,  1.01,\n",
       "         0.1 , -0.12,  1.06,  0.12, -0.12,  0.96,  0.19, -0.02,  0.81,\n",
       "         0.18,  0.02,  0.9 ,  0.13,  0.07,  1.07,  0.11,  0.01,  1.07,\n",
       "         0.1 , -0.08,  1.  ,  0.16, -0.07,  0.87,  0.2 , -0.02,  0.91,\n",
       "         0.15,  0.04,  0.93,  0.11, -0.  ,  1.08],\n",
       "       [ 0.1 , -0.04,  0.98,  0.09, -0.02,  1.  ,  0.1 ,  0.05,  1.07,\n",
       "         0.11, -0.08,  1.02,  0.12, -0.16,  0.91,  0.13,  0.05,  0.8 ,\n",
       "         0.17,  0.22,  1.01,  0.11,  0.08,  1.04,  0.06, -0.02,  0.96,\n",
       "         0.09, -0.02,  1.03,  0.09,  0.01,  0.98,  0.09, -0.  ,  0.96,\n",
       "         0.12,  0.05,  0.98,  0.1 ,  0.02,  0.97],\n",
       "       [ 0.1 , -0.04,  0.95,  0.09,  0.  ,  0.97,  0.08, -0.01,  1.04,\n",
       "         0.14, -0.03,  1.12,  0.15, -0.1 ,  0.87,  0.15,  0.05,  0.79,\n",
       "         0.14,  0.13,  0.93,  0.12,  0.13,  1.07,  0.06,  0.03,  1.01,\n",
       "         0.05, -0.04,  0.99,  0.1 ,  0.05,  0.99,  0.1 ,  0.09,  1.01,\n",
       "         0.09,  0.06,  0.95,  0.09,  0.02,  0.95],\n",
       "       [-0.  , -0.07,  0.97,  0.02,  0.08,  1.  ,  0.02,  0.04,  1.08,\n",
       "         0.05, -0.14,  1.15,  0.08, -0.18,  0.85,  0.18,  0.22,  0.81,\n",
       "         0.08,  0.2 ,  1.07,  0.09,  0.14,  0.98,  0.04, -0.02,  1.  ,\n",
       "         0.03, -0.02,  0.97,  0.03,  0.01,  0.99,  0.06,  0.07,  1.  ,\n",
       "         0.02,  0.  ,  1.01,  0.05,  0.05,  1.  ],\n",
       "       [ 0.08, -0.03,  0.97,  0.07, -0.04,  0.99,  0.14,  0.14,  1.05,\n",
       "         0.09, -0.04,  1.1 ,  0.14, -0.02,  0.8 ,  0.1 ,  0.01,  0.86,\n",
       "         0.05,  0.14,  1.08, -0.  ,  0.01,  1.12,  0.02, -0.03,  0.93,\n",
       "         0.08, -0.02,  0.85,  0.05,  0.  ,  0.92,  0.01,  0.17,  1.08,\n",
       "        -0.04,  0.01,  1.02, -0.06, -0.09,  0.97],\n",
       "       [ 0.1 , -0.07,  1.  ,  0.12, -0.01,  0.95,  0.12,  0.03,  1.03,\n",
       "         0.15, -0.08,  1.1 ,  0.17, -0.06,  0.8 ,  0.2 ,  0.05,  0.82,\n",
       "         0.17,  0.14,  1.09,  0.12,  0.02,  1.07,  0.14, -0.05,  0.92,\n",
       "         0.09, -0.04,  1.  ,  0.12,  0.01,  0.96,  0.14,  0.05,  1.01,\n",
       "         0.09, -0.04,  0.97,  0.13,  0.02,  0.95],\n",
       "       [ 0.08,  0.03,  1.03,  0.05, -0.02,  0.98,  0.13,  0.35,  1.02,\n",
       "         0.1 , -0.07,  1.15,  0.1 , -0.18,  1.01,  0.15,  0.07,  0.7 ,\n",
       "         0.26,  0.2 ,  0.73,  0.15,  0.2 ,  0.93,  0.08,  0.21,  1.13,\n",
       "        -0.  , -0.06,  1.  ,  0.04,  0.02,  1.04,  0.07, -0.03,  0.96,\n",
       "         0.07,  0.01,  1.01,  0.07, -0.05,  0.91],\n",
       "       [ 0.01, -0.07,  1.12,  0.03, -0.17,  0.93,  0.  ,  0.  ,  0.75,\n",
       "        -0.04,  0.15,  1.01, -0.07,  0.12,  1.08, -0.06, -0.17,  1.13,\n",
       "        -0.02, -0.04,  0.81, -0.03, -0.  ,  0.92, -0.05,  0.16,  1.06,\n",
       "        -0.09, -0.  ,  0.98, -0.1 , -0.09,  0.97, -0.08, -0.01,  1.  ,\n",
       "        -0.06, -0.01,  0.94, -0.07,  0.  ,  1.  ],\n",
       "       [ 0.18, -0.  ,  0.93,  0.13,  0.02,  0.99,  0.19,  0.04,  1.03,\n",
       "         0.19, -0.13,  1.06,  0.19, -0.02,  0.73,  0.22,  0.11,  0.94,\n",
       "         0.17,  0.13,  1.12,  0.17, -0.03,  1.04,  0.2 ,  0.02,  0.82,\n",
       "         0.21,  0.08,  0.87,  0.18,  0.17,  1.03,  0.15, -0.01,  0.99,\n",
       "         0.14, -0.07,  0.95,  0.16,  0.  ,  0.97],\n",
       "       [ 0.13, -0.01,  0.99,  0.16,  0.01,  0.99,  0.16,  0.14,  1.03,\n",
       "         0.18, -0.05,  1.1 ,  0.18, -0.07,  0.88,  0.24,  0.16,  0.78,\n",
       "         0.2 ,  0.21,  1.03,  0.16,  0.12,  1.02,  0.12,  0.03,  0.96,\n",
       "         0.13, -0.  ,  0.98,  0.13,  0.02,  0.95,  0.14,  0.04,  0.98,\n",
       "         0.13,  0.  ,  0.93,  0.15,  0.04,  0.95],\n",
       "       [ 0.12, -0.03,  0.98,  0.1 , -0.02,  0.98,  0.14,  0.06,  1.06,\n",
       "         0.12, -0.1 ,  1.01,  0.13, -0.02,  0.79,  0.17,  0.2 ,  0.97,\n",
       "         0.1 ,  0.13,  1.05,  0.12,  0.1 ,  0.98,  0.07, -0.08,  0.96,\n",
       "         0.11,  0.06,  1.02,  0.09,  0.03,  0.98,  0.1 ,  0.05,  1.  ,\n",
       "         0.1 ,  0.  ,  0.98,  0.11,  0.02,  1.  ],\n",
       "       [ 0.  , -0.01,  0.97,  0.01,  0.06,  1.  , -0.13,  0.02,  0.94,\n",
       "         0.01, -0.27,  1.24,  0.08, -0.16,  0.84,  0.17,  0.08,  0.76,\n",
       "         0.18,  0.2 ,  0.85,  0.03,  0.1 ,  1.06, -0.02,  0.07,  1.04,\n",
       "        -0.07,  0.02,  1.06, -0.09, -0.01,  1.02, -0.06,  0.02,  0.97,\n",
       "        -0.06, -0.01,  0.98, -0.1 , -0.07,  0.98],\n",
       "       [ 0.09, -0.05,  0.96,  0.11, -0.02,  0.96,  0.11,  0.07,  1.03,\n",
       "         0.14, -0.13,  1.08,  0.15, -0.08,  0.86,  0.2 ,  0.19,  0.84,\n",
       "         0.16,  0.15,  1.05,  0.13,  0.06,  1.01,  0.12,  0.02,  1.  ,\n",
       "         0.11, -0.07,  0.97,  0.1 , -0.02,  0.99,  0.12, -0.01,  0.99,\n",
       "         0.14,  0.02,  0.97,  0.15,  0.04,  0.94],\n",
       "       [ 0.08, -0.1 ,  1.  ,  0.12, -0.02,  0.93,  0.09,  0.01,  0.97,\n",
       "         0.07, -0.13,  1.15,  0.14, -0.1 ,  0.97,  0.22,  0.  ,  0.73,\n",
       "         0.14, -0.02,  0.95,  0.13,  0.14,  1.11,  0.08,  0.06,  1.03,\n",
       "         0.01, -0.15,  0.98,  0.07, -0.02,  1.01,  0.05, -0.02,  0.97,\n",
       "         0.04, -0.02,  1.03,  0.06, -0.02,  0.98],\n",
       "       [ 0.04,  0.03,  0.95,  0.09,  0.18,  0.88,  0.13,  0.18,  1.12,\n",
       "         0.09, -0.18,  0.97,  0.15,  0.01,  0.76,  0.19,  0.27,  0.75,\n",
       "         0.14,  0.32,  1.05,  0.05,  0.22,  1.03, -0.01,  0.1 ,  1.  ,\n",
       "        -0.01,  0.09,  1.  ,  0.  ,  0.08,  0.98,  0.  ,  0.1 ,  0.96,\n",
       "         0.  ,  0.11,  0.96,  0.06,  0.13,  0.96],\n",
       "       [ 0.05, -0.05,  0.99,  0.08, -0.01,  1.02,  0.06, -0.28,  0.96,\n",
       "         0.1 ,  0.07,  0.69,  0.11,  0.4 ,  0.98, -0.03,  0.2 ,  1.25,\n",
       "        -0.04, -0.06,  1.08,  0.02, -0.04,  0.84,  0.07,  0.  ,  0.81,\n",
       "         0.05,  0.21,  1.08, -0.07,  0.04,  1.12, -0.07, -0.04,  0.97,\n",
       "        -0.05, -0.02,  0.98, -0.04,  0.01,  0.99],\n",
       "       [ 0.11, -0.  ,  0.96,  0.06,  0.04,  0.95,  0.11,  0.01,  1.09,\n",
       "         0.12, -0.07,  1.02,  0.21,  0.02,  0.84,  0.17, -0.03,  0.81,\n",
       "         0.16,  0.08,  0.99,  0.06,  0.06,  1.02,  0.06,  0.02,  1.02,\n",
       "         0.  , -0.  ,  1.03,  0.08,  0.04,  0.97,  0.07,  0.02,  0.98,\n",
       "         0.05,  0.  ,  1.  ,  0.06,  0.01,  1.  ],\n",
       "       [ 0.03, -0.04,  1.02,  0.03, -0.02,  1.  ,  0.06,  0.08,  1.1 ,\n",
       "         0.03, -0.14,  1.04,  0.1 , -0.13,  0.92,  0.18,  0.03,  0.84,\n",
       "         0.18,  0.12,  0.96,  0.1 ,  0.14,  1.03,  0.04,  0.03,  1.03,\n",
       "         0.04,  0.01,  0.99,  0.03, -0.04,  0.99,  0.05,  0.03,  0.97,\n",
       "         0.04,  0.02,  0.99,  0.03,  0.  ,  0.99],\n",
       "       [ 0.06, -0.08,  0.9 ,  0.12, -0.04,  1.02,  0.13, -0.12,  0.93,\n",
       "         0.15,  0.  ,  0.77,  0.13,  0.16,  0.95,  0.12,  0.14,  1.06,\n",
       "         0.07, -0.06,  1.06,  0.11, -0.02,  0.92,  0.17, -0.02,  0.88,\n",
       "         0.12,  0.03,  0.96,  0.06,  0.02,  1.08,  0.04, -0.11,  1.  ,\n",
       "         0.06, -0.09,  0.98,  0.06, -0.07,  0.98],\n",
       "       [ 0.15, -0.04,  1.  ,  0.16, -0.09,  0.89,  0.1 ,  0.05,  1.08,\n",
       "         0.15, -0.13,  1.06,  0.16,  0.02,  0.65,  0.11,  0.16,  1.07,\n",
       "         0.05,  0.01,  1.15,  0.09,  0.02,  0.97,  0.13,  0.05,  0.78,\n",
       "         0.07,  0.19,  1.1 ,  0.04,  0.02,  1.02,  0.04, -0.09,  0.98,\n",
       "         0.06, -0.04,  0.96,  0.04, -0.06,  0.98],\n",
       "       [ 0.04,  0.  ,  0.99,  0.06,  0.04,  0.97,  0.05,  0.08,  1.1 ,\n",
       "         0.05, -0.07,  1.08,  0.12, -0.03,  0.8 ,  0.13,  0.02,  0.87,\n",
       "         0.11,  0.13,  1.04,  0.08,  0.1 ,  1.08,  0.05, -0.03,  1.05,\n",
       "         0.11, -0.02,  0.83,  0.11,  0.05,  0.94,  0.05,  0.1 ,  1.07,\n",
       "         0.01, -0.01,  0.98,  0.  , -0.09,  0.97],\n",
       "       [ 0.06, -0.02,  0.98,  0.06,  0.05,  0.92,  0.07,  0.01,  1.08,\n",
       "         0.07, -0.07,  1.01,  0.13,  0.01,  0.83,  0.12,  0.05,  0.91,\n",
       "         0.07,  0.11,  1.09,  0.08,  0.01,  1.04,  0.08, -0.03,  0.96,\n",
       "         0.12,  0.02,  0.87,  0.12,  0.11,  0.95,  0.04,  0.06,  1.06,\n",
       "         0.05, -0.  ,  0.98,  0.05, -0.05,  0.98],\n",
       "       [ 0.07, -0.06,  0.99,  0.06, -0.07,  0.95,  0.08, -0.06,  1.1 ,\n",
       "         0.13, -0.09,  0.94,  0.14, -0.05,  0.79,  0.15,  0.07,  1.02,\n",
       "         0.1 , -0.01,  1.1 ,  0.11, -0.08,  0.99,  0.19, -0.01,  0.81,\n",
       "         0.16,  0.01,  0.89,  0.08,  0.04,  1.09,  0.02, -0.16,  1.  ,\n",
       "         0.06, -0.08,  0.97,  0.07, -0.07,  0.97],\n",
       "       [-0.06,  0.03,  0.97, -0.04,  0.07,  0.95, -0.05,  0.19,  1.01,\n",
       "        -0.06, -0.16,  1.16, -0.03, -0.15,  1.13,  0.09, -0.07,  0.75,\n",
       "         0.17,  0.2 ,  0.76,  0.09,  0.21,  0.85,  0.03,  0.21,  0.99,\n",
       "        -0.09,  0.1 ,  1.06, -0.14, -0.01,  1.01, -0.13,  0.03,  0.98,\n",
       "        -0.11,  0.05,  0.97, -0.11,  0.  ,  0.99],\n",
       "       [ 0.04, -0.03,  0.99,  0.04, -0.04,  0.93,  0.02,  0.05,  1.01,\n",
       "         0.04, -0.07,  1.2 ,  0.09,  0.02,  0.71,  0.11,  0.09,  0.93,\n",
       "         0.01,  0.14,  1.08, -0.  , -0.07,  1.15,  0.05,  0.  ,  0.88,\n",
       "         0.09,  0.04,  0.84,  0.07,  0.13,  0.97, -0.  ,  0.1 ,  1.08,\n",
       "        -0.04, -0.04,  1.  , -0.05, -0.01,  0.99],\n",
       "       [ 0.07, -0.05,  0.96,  0.08,  0.01,  0.93,  0.06,  0.01,  1.03,\n",
       "         0.07, -0.14,  1.03,  0.15, -0.02,  0.85,  0.2 , -0.06,  0.76,\n",
       "         0.18,  0.11,  1.01,  0.08,  0.12,  1.08,  0.01, -0.  ,  1.06,\n",
       "         0.01, -0.1 ,  0.96,  0.04,  0.01,  1.  ,  0.04,  0.02,  0.98,\n",
       "         0.05,  0.03,  0.99,  0.01, -0.01,  1.01],\n",
       "       [ 0.04,  0.  ,  0.97,  0.04, -0.  ,  1.  ,  0.04, -0.03,  1.34,\n",
       "         0.1 , -0.05,  0.76,  0.11,  0.19,  0.88, -0.  ,  0.14,  1.14,\n",
       "        -0.01, -0.13,  1.09,  0.04, -0.09,  0.98,  0.11, -0.02,  0.8 ,\n",
       "         0.1 ,  0.03,  0.91,  0.02,  0.01,  1.08,  0.04, -0.02,  0.98,\n",
       "         0.  , -0.12,  0.99,  0.03, -0.02,  1.03],\n",
       "       [ 0.06, -0.06,  1.01,  0.06, -0.03,  1.  ,  0.07,  0.02,  1.05,\n",
       "         0.02, -0.16,  1.18,  0.09, -0.06,  0.89,  0.14,  0.02,  0.89,\n",
       "         0.15,  0.11,  1.07,  0.1 ,  0.14,  1.04, -0.03, -0.04,  1.04,\n",
       "         0.04, -0.  ,  0.89,  0.06,  0.  ,  1.  ,  0.05, -0.02,  1.  ,\n",
       "         0.09,  0.05,  0.97,  0.03, -0.01,  1.  ],\n",
       "       [ 0.11, -0.06,  0.93,  0.12,  0.12,  1.02,  0.11, -0.09,  1.12,\n",
       "         0.1 , -0.18,  1.03,  0.15, -0.11,  0.84,  0.21,  0.09,  0.88,\n",
       "         0.16,  0.11,  1.02,  0.1 ,  0.09,  1.02,  0.07, -0.03,  0.91,\n",
       "         0.07, -0.05,  1.01,  0.12,  0.05,  1.01,  0.09, -0.  ,  0.94,\n",
       "         0.08, -0.01,  0.97,  0.12,  0.03,  0.96],\n",
       "       [ 0.08,  0.03,  0.99,  0.07,  0.07,  0.98,  0.07,  0.14,  1.1 ,\n",
       "         0.15, -0.05,  1.08,  0.11, -0.17,  0.91,  0.18,  0.05,  0.83,\n",
       "         0.21,  0.18,  0.83,  0.16,  0.13,  0.96,  0.1 ,  0.16,  1.05,\n",
       "         0.05,  0.11,  1.  , -0.03, -0.03,  0.99,  0.07,  0.05,  0.98,\n",
       "         0.03,  0.02,  1.  ,  0.04,  0.04,  0.99],\n",
       "       [ 0.09, -0.03,  0.97,  0.12, -0.02,  1.05,  0.11, -0.17,  0.97,\n",
       "         0.18,  0.05,  0.8 ,  0.18,  0.2 ,  0.9 ,  0.11,  0.16,  1.07,\n",
       "         0.05,  0.02,  1.1 ,  0.08, -0.05,  1.02,  0.06, -0.08,  0.89,\n",
       "         0.07, -0.02,  0.91,  0.07,  0.04,  1.  ,  0.04, -0.05,  1.02,\n",
       "         0.05, -0.05,  0.98,  0.04, -0.07,  0.98],\n",
       "       [ 0.08,  0.05,  0.97,  0.07,  0.14,  0.94,  0.11, -0.03,  1.16,\n",
       "         0.15, -0.09,  0.95,  0.19,  0.11,  0.78,  0.26,  0.32,  0.87,\n",
       "         0.18,  0.21,  0.99,  0.13,  0.15,  1.02,  0.03,  0.02,  1.04,\n",
       "         0.01, -0.02,  0.97,  0.04,  0.05,  1.  ,  0.07,  0.06,  0.98,\n",
       "         0.07,  0.05,  0.94,  0.08,  0.04,  0.96],\n",
       "       [ 0.  ,  0.  ,  0.  ,  0.27,  0.1 ,  1.17,  0.2 ,  0.29,  1.13,\n",
       "         0.01, -0.14,  1.1 ,  0.11, -0.08,  0.98,  0.24,  0.08,  0.6 ,\n",
       "         0.12,  0.01,  0.87,  0.01,  0.21,  1.11, -0.04, -0.07,  1.06,\n",
       "         0.02, -0.03,  1.03,  0.04, -0.04,  0.96,  0.03, -0.02,  1.  ,\n",
       "         0.05, -0.01,  0.96,  0.05, -0.03,  0.97],\n",
       "       [ 0.06, -0.04,  0.99,  0.07, -0.04,  0.93,  0.05, -0.06,  1.03,\n",
       "         0.1 , -0.08,  1.06,  0.17, -0.01,  0.78,  0.15,  0.01,  0.87,\n",
       "         0.11,  0.11,  1.15,  0.07, -0.11,  1.09,  0.14, -0.04,  0.88,\n",
       "         0.15, -0.03,  0.88,  0.15,  0.07,  0.92,  0.01, -0.03,  1.09,\n",
       "         0.04, -0.08,  0.99,  0.06, -0.04,  0.95],\n",
       "       [ 0.07, -0.07,  1.  ,  0.04, -0.1 ,  0.98,  0.07,  0.05,  1.06,\n",
       "         0.11, -0.17,  1.05,  0.13, -0.07,  0.7 ,  0.19,  0.04,  0.93,\n",
       "         0.12,  0.16,  1.11,  0.09,  0.02,  1.01,  0.03, -0.1 ,  0.98,\n",
       "         0.06,  0.  ,  0.98,  0.05, -0.03,  0.99,  0.07,  0.01,  0.98,\n",
       "         0.04, -0.03,  1.  ,  0.08, -0.  ,  0.96],\n",
       "       [ 0.08, -0.14,  1.09,  0.16, -0.18,  1.04,  0.13, -0.01,  0.74,\n",
       "         0.17,  0.19,  0.94,  0.06,  0.07,  1.09,  0.07, -0.07,  1.11,\n",
       "         0.08, -0.11,  0.97,  0.13, -0.03,  0.84,  0.15,  0.01,  0.91,\n",
       "         0.1 ,  0.06,  1.05,  0.07, -0.05,  1.01,  0.08, -0.1 ,  0.97,\n",
       "         0.08, -0.07,  1.03,  0.06, -0.13,  0.96],\n",
       "       [ 0.07,  0.01,  0.96,  0.07,  0.09,  0.96,  0.08,  0.01,  1.14,\n",
       "         0.08, -0.02,  0.95,  0.15,  0.09,  0.77,  0.14,  0.16,  0.99,\n",
       "         0.1 ,  0.12,  1.07,  0.11,  0.01,  1.03,  0.11,  0.03,  0.88,\n",
       "         0.16,  0.15,  0.88,  0.1 ,  0.14,  0.99,  0.08,  0.11,  1.  ,\n",
       "         0.04, -0.03,  1.  ,  0.09,  0.05,  0.96],\n",
       "       [ 0.05, -0.05,  0.99,  0.08,  0.  ,  0.97,  0.11, -0.16,  1.29,\n",
       "         0.08, -0.13,  0.66,  0.2 ,  0.3 ,  0.75,  0.04,  0.29,  1.1 ,\n",
       "         0.01, -0.02,  1.13,  0.03, -0.21,  1.02,  0.13, -0.1 ,  0.85,\n",
       "         0.18,  0.13,  0.83,  0.12,  0.05,  0.94,  0.05,  0.01,  1.09,\n",
       "         0.05, -0.11,  0.99,  0.05, -0.07,  0.94],\n",
       "       [ 0.02, -0.07,  1.  ,  0.04,  0.05,  0.97, -0.  , -0.  ,  1.07,\n",
       "         0.06, -0.22,  1.12,  0.08, -0.19,  0.69,  0.2 ,  0.19,  0.79,\n",
       "         0.12,  0.21,  1.06,  0.04,  0.05,  1.03,  0.05,  0.  ,  1.  ,\n",
       "         0.06,  0.  ,  0.97,  0.06,  0.01,  1.  ,  0.07,  0.01,  0.96,\n",
       "         0.07,  0.  ,  0.97,  0.05,  0.01,  0.98],\n",
       "       [ 0.08, -0.03,  1.01,  0.11,  0.13,  1.06,  0.12, -0.02,  1.09,\n",
       "         0.12, -0.12,  1.01,  0.13, -0.03,  0.74,  0.19,  0.19,  0.93,\n",
       "         0.1 ,  0.14,  1.05,  0.05,  0.03,  0.99,  0.04, -0.03,  1.02,\n",
       "         0.07,  0.  ,  1.01,  0.08,  0.03,  1.  ,  0.09,  0.06,  0.97,\n",
       "         0.1 ,  0.06,  0.99,  0.08,  0.02,  0.97],\n",
       "       [ 0.12, -0.03,  0.99,  0.2 , -0.05,  1.2 ,  0.14, -0.1 ,  0.84,\n",
       "         0.2 ,  0.21,  0.75,  0.16,  0.22,  1.05,  0.09,  0.02,  1.08,\n",
       "         0.09, -0.09,  1.02,  0.15, -0.03,  0.91,  0.18, -0.03,  0.84,\n",
       "         0.19,  0.11,  1.01,  0.12,  0.03,  1.05,  0.08, -0.08,  0.97,\n",
       "         0.09, -0.07,  0.92,  0.12, -0.03,  0.97],\n",
       "       [ 0.02, -0.01,  0.99,  0.01, -0.04,  1.03, -0.02, -0.28,  1.18,\n",
       "         0.03,  0.3 ,  1.18,  0.12,  0.15,  0.66,  0.14, -0.07,  0.8 ,\n",
       "         0.03, -0.1 ,  0.99, -0.03,  0.07,  1.12,  0.  ,  0.23,  1.  ,\n",
       "        -0.07,  0.15,  0.96, -0.  ,  0.19,  1.  ,  0.01,  0.07,  0.97,\n",
       "         0.01,  0.05,  1.  , -0.01,  0.05,  0.99],\n",
       "       [ 0.09, -0.03,  0.96,  0.14, -0.04,  1.03,  0.08, -0.18,  0.78,\n",
       "         0.16,  0.15,  0.83,  0.1 ,  0.18,  1.02,  0.03,  0.04,  1.07,\n",
       "         0.05, -0.05,  1.02,  0.12, -0.01,  0.85,  0.16,  0.02,  0.91,\n",
       "         0.06,  0.1 ,  1.03,  0.01, -0.01,  1.04,  0.04, -0.04,  1.  ,\n",
       "         0.04, -0.04,  0.99,  0.03, -0.06,  0.95],\n",
       "       [ 0.08, -0.09,  0.95,  0.07, -0.05,  0.94,  0.04, -0.05,  1.03,\n",
       "         0.09, -0.18,  1.08,  0.17, -0.07,  0.93,  0.23, -0.04,  0.81,\n",
       "         0.23,  0.02,  0.88,  0.16,  0.08,  1.1 ,  0.09,  0.02,  1.05,\n",
       "         0.03, -0.1 ,  1.02,  0.08, -0.1 ,  0.96,  0.05, -0.09,  0.97,\n",
       "         0.12, -0.  ,  0.97,  0.08, -0.04,  0.96],\n",
       "       [ 0.13, -0.  ,  0.97,  0.11, -0.06,  1.03,  0.14, -0.1 ,  0.96,\n",
       "         0.16,  0.06,  0.79,  0.11,  0.13,  0.97,  0.07,  0.08,  1.07,\n",
       "         0.07, -0.11,  1.06,  0.07, -0.08,  0.93,  0.16,  0.01,  0.82,\n",
       "         0.11,  0.03,  0.98,  0.09,  0.05,  1.02,  0.04, -0.1 ,  1.  ,\n",
       "         0.06, -0.11,  0.97,  0.08, -0.04,  0.99],\n",
       "       [ 0.12, -0.03,  0.95,  0.09,  0.01,  0.97,  0.12,  0.03,  1.01,\n",
       "         0.14, -0.09,  1.07,  0.17,  0.  ,  0.85,  0.19, -0.03,  0.82,\n",
       "         0.17,  0.07,  1.  ,  0.16,  0.1 ,  1.04,  0.15,  0.08,  1.01,\n",
       "         0.08, -0.05,  1.02,  0.11, -0.01,  1.  ,  0.11,  0.01,  0.95,\n",
       "         0.08, -0.04,  1.02,  0.08, -0.03,  0.98],\n",
       "       [ 0.07,  0.02,  0.98,  0.03, -0.  ,  0.96,  0.07,  0.08,  1.09,\n",
       "         0.08, -0.08,  1.01,  0.12, -0.02,  0.74,  0.08,  0.13,  0.99,\n",
       "         0.06,  0.01,  1.13,  0.04, -0.07,  1.02,  0.08, -0.03,  0.81,\n",
       "         0.09,  0.08,  0.99,  0.05,  0.17,  1.1 , -0.01, -0.02,  0.99,\n",
       "        -0.05, -0.15,  0.98, -0.01, -0.01,  0.99],\n",
       "       [ 0.15, -0.05,  0.96,  0.16,  0.  ,  0.93,  0.12,  0.03,  0.99,\n",
       "         0.12, -0.12,  1.1 ,  0.15, -0.08,  0.87,  0.21,  0.01,  0.83,\n",
       "         0.2 ,  0.09,  0.97,  0.13,  0.02,  1.09,  0.14, -0.09,  1.02,\n",
       "         0.17, -0.03,  0.83,  0.18, -0.03,  0.91,  0.18,  0.09,  0.97,\n",
       "         0.1 ,  0.01,  1.05,  0.07, -0.07,  0.98],\n",
       "       [ 0.09, -0.  ,  0.97,  0.12,  0.02,  0.95,  0.07, -0.19,  0.91,\n",
       "         0.14,  0.03,  0.76,  0.13,  0.29,  0.93,  0.06,  0.21,  1.11,\n",
       "         0.01,  0.01,  1.14,  0.06, -0.  ,  0.83,  0.1 ,  0.03,  0.8 ,\n",
       "         0.06,  0.16,  1.04,  0.03,  0.07,  1.02,  0.03, -0.  ,  0.96,\n",
       "         0.05,  0.07,  0.95,  0.05,  0.09,  0.98],\n",
       "       [ 0.1 , -0.03,  0.97,  0.1 , -0.01,  1.02,  0.05, -0.3 ,  1.06,\n",
       "         0.12, -0.  ,  0.64,  0.12,  0.27,  0.88,  0.08,  0.13,  1.1 ,\n",
       "         0.06, -0.15,  1.11,  0.13,  0.01,  0.83,  0.16,  0.02,  0.8 ,\n",
       "         0.12,  0.09,  1.02,  0.07,  0.03,  1.07,  0.04, -0.09,  1.  ,\n",
       "         0.06, -0.01,  1.  ,  0.06, -0.01,  0.98],\n",
       "       [-0.03, -0.02,  0.98, -0.03, -0.03,  0.99,  0.05, -0.01,  1.13,\n",
       "         0.04,  0.15,  1.08,  0.13,  0.09,  0.74,  0.22, -0.09,  0.63,\n",
       "         0.16, -0.19,  0.86, -0.03, -0.25,  1.03, -0.12, -0.17,  1.14,\n",
       "        -0.06, -0.01,  0.95, -0.1 , -0.08,  1.1 , -0.09, -0.05,  0.91,\n",
       "        -0.05,  0.01,  1.07, -0.06, -0.05,  1.02],\n",
       "       [ 0.1 , -0.02,  0.98,  0.08, -0.04,  0.97,  0.14,  0.18,  1.03,\n",
       "         0.11, -0.11,  1.26,  0.21,  0.05,  0.67,  0.18,  0.04,  0.87,\n",
       "         0.13,  0.25,  1.07,  0.06,  0.03,  1.01,  0.08,  0.06,  0.96,\n",
       "         0.08,  0.09,  0.96,  0.06,  0.05,  0.96,  0.07,  0.05,  0.98,\n",
       "         0.06,  0.05,  1.03,  0.06,  0.06,  1.01],\n",
       "       [-0.01,  0.01,  1.  ,  0.01,  0.  ,  0.96, -0.02, -0.09,  1.  ,\n",
       "        -0.05, -0.04,  1.15,  0.08,  0.12,  0.96,  0.16,  0.22,  0.92,\n",
       "         0.21, -0.  ,  0.74,  0.15, -0.15,  0.81,  0.05, -0.21,  0.96,\n",
       "        -0.06, -0.11,  1.16, -0.05,  0.1 ,  1.09, -0.05,  0.12,  1.06,\n",
       "        -0.06,  0.04,  1.  , -0.05, -0.02,  1.  ],\n",
       "       [-0.02, -0.02,  0.98, -0.02,  0.11,  0.97, -0.02,  0.01,  1.21,\n",
       "         0.  , -0.24,  1.03,  0.09, -0.04,  0.82,  0.19,  0.26,  0.82,\n",
       "         0.13,  0.25,  0.95,  0.03,  0.18,  1.04, -0.07,  0.05,  1.05,\n",
       "        -0.14, -0.07,  1.14, -0.05,  0.07,  1.  , -0.03,  0.03,  0.92,\n",
       "        -0.05,  0.04,  0.99, -0.03,  0.02,  0.96],\n",
       "       [ 0.05, -0.13,  0.97,  0.13, -0.11,  1.08,  0.08, -0.2 ,  0.86,\n",
       "         0.15,  0.12,  0.72,  0.09,  0.24,  1.09,  0.04, -0.04,  1.29,\n",
       "         0.02, -0.11,  0.79,  0.05, -0.04,  0.79,  0.09,  0.21,  1.11,\n",
       "        -0.02, -0.02,  1.  , -0.02, -0.1 ,  0.97, -0.01,  0.03,  0.98,\n",
       "         0.01,  0.01,  1.  ,  0.01, -0.  ,  0.95],\n",
       "       [ 0.09,  0.02,  0.94,  0.07, -0.08,  0.96,  0.03, -0.05,  1.04,\n",
       "         0.12,  0.07,  1.07,  0.08, -0.09,  0.72,  0.11, -0.12,  0.88,\n",
       "         0.09, -0.23,  1.06,  0.1 , -0.03,  0.96,  0.08, -0.09,  0.98,\n",
       "         0.08, -0.13,  0.98,  0.07, -0.15,  0.96,  0.11, -0.15,  0.96,\n",
       "         0.07, -0.12,  1.01,  0.04, -0.27,  0.95],\n",
       "       [ 0.03, -0.01,  0.98,  0.01, -0.07,  0.96,  0.06, -0.03,  1.11,\n",
       "         0.12,  0.09,  1.09,  0.09,  0.02,  0.84,  0.07, -0.11,  0.87,\n",
       "         0.04, -0.12,  0.96,  0.03, -0.16,  1.06,  0.04,  0.05,  0.95,\n",
       "         0.05, -0.04,  1.  ,  0.06, -0.05,  0.97,  0.04, -0.06,  0.95,\n",
       "         0.05, -0.08,  0.98,  0.01, -0.08,  1.  ],\n",
       "       [ 0.  ,  0.  ,  0.  ,  0.02,  0.1 ,  0.95,  0.04,  0.23,  0.9 ,\n",
       "         0.02,  0.14,  1.08,  0.06, -0.21,  1.03,  0.14,  0.03,  0.75,\n",
       "         0.22,  0.26,  0.71,  0.17,  0.33,  1.  ,  0.07,  0.17,  1.08,\n",
       "         0.04, -0.08,  1.01,  0.12,  0.11,  0.97,  0.08, -0.  ,  0.99,\n",
       "         0.11,  0.03,  0.94,  0.13,  0.04,  0.98],\n",
       "       [ 0.04, -0.18,  0.99,  0.05, -0.13,  0.97,  0.08,  0.04,  0.97,\n",
       "         0.06,  0.01,  0.97,  0.1 ,  0.12,  1.02,  0.06, -0.03,  1.07,\n",
       "         0.09, -0.2 ,  1.05,  0.19,  0.04,  0.66,  0.13,  0.15,  1.  ,\n",
       "         0.08,  0.  ,  1.11,  0.09, -0.05,  1.01,  0.1 ,  0.03,  0.96,\n",
       "         0.07,  0.  ,  0.98,  0.11,  0.07,  0.98],\n",
       "       [ 0.11, -0.09,  0.99,  0.14, -0.12,  1.05,  0.11, -0.19,  0.88,\n",
       "         0.21,  0.02,  0.77,  0.14,  0.14,  0.97,  0.03,  0.05,  1.18,\n",
       "         0.05, -0.11,  1.1 ,  0.1 ,  0.  ,  0.83,  0.1 ,  0.02,  0.86,\n",
       "         0.02,  0.06,  1.05, -0.04,  0.04,  1.05, -0.01,  0.03,  1.01,\n",
       "        -0.03,  0.04,  0.99, -0.01,  0.05,  0.99],\n",
       "       [-0.03, -0.03,  1.04,  0.01,  0.09,  0.99,  0.07,  0.05,  1.11,\n",
       "         0.1 , -0.11,  1.05,  0.13, -0.04,  0.79,  0.18,  0.14,  0.8 ,\n",
       "         0.22,  0.26,  0.88,  0.07,  0.15,  1.04,  0.05,  0.15,  1.02,\n",
       "         0.  ,  0.02,  1.03, -0.01,  0.  ,  0.98,  0.03,  0.06,  0.98,\n",
       "         0.02,  0.08,  1.  ,  0.02,  0.03,  0.99],\n",
       "       [ 0.04, -0.05,  0.96,  0.03, -0.11,  0.94,  0.09, -0.09,  1.02,\n",
       "         0.1 ,  0.11,  1.08,  0.1 , -0.08,  0.71,  0.16,  0.02,  0.89,\n",
       "         0.13, -0.01,  1.07,  0.06, -0.05,  1.03,  0.05,  0.  ,  0.96,\n",
       "         0.06, -0.05,  1.  ,  0.05, -0.11,  0.95,  0.07, -0.11,  0.99,\n",
       "         0.07, -0.14,  0.92,  0.06, -0.14,  0.99],\n",
       "       [ 0.09, -0.03,  0.97,  0.05, -0.06,  0.98,  0.04,  0.03,  0.88,\n",
       "         0.05,  0.  ,  1.14,  0.1 , -0.02,  0.88,  0.06,  0.01,  0.71,\n",
       "         0.09,  0.24,  1.07,  0.07,  0.04,  1.19,  0.08,  0.02,  0.74,\n",
       "         0.09,  0.07,  0.83,  0.09,  0.17,  1.06,  0.05,  0.04,  1.  ,\n",
       "         0.05, -0.03,  0.99,  0.04,  0.  ,  0.96],\n",
       "       [ 0.08, -0.11,  0.99,  0.11,  0.  ,  0.95,  0.14,  0.06,  1.06,\n",
       "         0.13, -0.08,  1.03,  0.17, -0.05,  0.85,  0.25,  0.01,  0.82,\n",
       "         0.18,  0.  ,  1.  ,  0.14,  0.07,  1.09,  0.11,  0.01,  0.96,\n",
       "         0.07, -0.12,  0.96,  0.09, -0.06,  0.96,  0.07, -0.06,  0.99,\n",
       "         0.09, -0.05,  0.97,  0.08, -0.05,  1.11],\n",
       "       [ 0.08, -0.01,  1.  ,  0.05, -0.02,  0.99,  0.07,  0.16,  1.1 ,\n",
       "         0.09, -0.15,  1.03,  0.13, -0.09,  0.99,  0.18, -0.07,  0.84,\n",
       "         0.24,  0.16,  0.73,  0.26,  0.3 ,  0.92,  0.11,  0.16,  1.02,\n",
       "         0.08,  0.14,  1.02,  0.06,  0.05,  0.96,  0.04,  0.04,  0.98,\n",
       "         0.05,  0.06,  0.99,  0.05,  0.06,  0.98],\n",
       "       [ 0.08, -0.05,  0.96,  0.09,  0.02,  0.91,  0.04, -0.01,  1.02,\n",
       "         0.13, -0.14,  1.08,  0.14, -0.  ,  0.8 ,  0.15,  0.07,  0.97,\n",
       "         0.11,  0.11,  1.12,  0.13, -0.03,  1.03,  0.14,  0.06,  0.81,\n",
       "         0.16,  0.06,  0.9 ,  0.13,  0.15,  1.01,  0.1 , -0.  ,  1.03,\n",
       "         0.03, -0.19,  0.97,  0.09, -0.08,  0.96],\n",
       "       [ 0.06, -0.09,  0.97,  0.08, -0.04,  0.94,  0.07,  0.13,  1.13,\n",
       "         0.  , -0.07,  1.16,  0.08,  0.1 ,  0.77,  0.07,  0.1 ,  0.83,\n",
       "         0.04,  0.3 ,  1.14, -0.02,  0.  ,  1.11,  0.05,  0.01,  0.8 ,\n",
       "         0.08,  0.04,  0.8 ,  0.04,  0.29,  1.07, -0.06,  0.06,  1.  ,\n",
       "        -0.03,  0.01,  0.97, -0.  ,  0.07,  0.98],\n",
       "       [ 0.07,  0.02,  0.96,  0.07,  0.05,  0.98,  0.05, -0.01,  1.15,\n",
       "         0.15, -0.13,  1.03,  0.24,  0.03,  0.76,  0.23,  0.24,  0.85,\n",
       "         0.18,  0.21,  1.01,  0.14,  0.18,  1.1 ,  0.1 ,  0.05,  1.01,\n",
       "         0.07,  0.02,  0.99,  0.1 ,  0.07,  0.98,  0.09,  0.03,  0.93,\n",
       "         0.08,  0.06,  0.97,  0.08,  0.04,  0.96],\n",
       "       [ 0.08, -0.04,  1.  ,  0.15, -0.07,  1.11,  0.11, -0.17,  0.86,\n",
       "         0.1 ,  0.01,  0.74,  0.11,  0.28,  1.02, -0.02,  0.02,  1.1 ,\n",
       "         0.01, -0.09,  1.04,  0.11,  0.01,  0.82,  0.14,  0.07,  0.87,\n",
       "         0.08,  0.15,  1.03,  0.02,  0.  ,  1.07,  0.03,  0.03,  1.  ,\n",
       "         0.05,  0.04,  0.99,  0.04,  0.02,  0.96],\n",
       "       [ 0.07, -0.03,  0.98,  0.07, -0.  ,  0.96,  0.05, -0.11,  1.02,\n",
       "         0.09, -0.07,  0.84,  0.11, -0.01,  0.78,  0.15,  0.18,  1.01,\n",
       "         0.09,  0.  ,  1.18,  0.1 ,  0.01,  0.9 ,  0.12,  0.06,  0.82,\n",
       "         0.09,  0.12,  0.99,  0.09,  0.1 ,  0.98,  0.06, -0.12,  0.99,\n",
       "         0.09,  0.01,  0.98,  0.08,  0.01,  0.96],\n",
       "       [ 0.03, -0.1 ,  0.95,  0.07,  0.  ,  1.05,  0.08,  0.09,  1.11,\n",
       "         0.1 , -0.09,  1.08,  0.08, -0.1 ,  0.86,  0.14,  0.15,  0.81,\n",
       "         0.09,  0.12,  1.  ,  0.03,  0.1 ,  1.06,  0.07,  0.08,  0.97,\n",
       "         0.01, -0.04,  0.99,  0.04,  0.07,  0.98,  0.06,  0.08,  1.04,\n",
       "         0.06,  0.09,  0.99,  0.04,  0.04,  0.96],\n",
       "       [ 0.03, -0.05,  0.97,  0.02, -0.03,  1.01,  0.03,  0.04,  0.91,\n",
       "        -0.  , -0.18,  1.04,  0.07, -0.12,  0.91,  0.11, -0.  ,  0.85,\n",
       "         0.11,  0.08,  0.99,  0.05,  0.01,  1.01,  0.06,  0.02,  0.96,\n",
       "         0.03, -0.06,  1.  ,  0.03, -0.07,  0.96,  0.03, -0.05,  1.02,\n",
       "         0.05, -0.03,  0.97,  0.04, -0.04,  0.97],\n",
       "       [ 0.06, -0.  ,  0.97,  0.01,  0.02,  0.99,  0.09,  0.08,  1.01,\n",
       "         0.08, -0.06,  1.01,  0.08, -0.18,  0.96,  0.18,  0.01,  0.84,\n",
       "         0.14,  0.08,  0.92,  0.11,  0.15,  1.09,  0.05,  0.04,  1.04,\n",
       "         0.04, -0.03,  0.96,  0.01, -0.07,  0.98,  0.05,  0.01,  1.02,\n",
       "         0.05,  0.  ,  0.97,  0.03, -0.02,  0.99],\n",
       "       [ 0.04,  0.01,  1.01,  0.05, -0.01,  0.97,  0.06, -0.18,  0.98,\n",
       "         0.13, -0.  ,  0.69,  0.15,  0.32,  0.87,  0.02,  0.2 ,  1.1 ,\n",
       "        -0.02, -0.12,  1.15,  0.01, -0.06,  0.84,  0.08,  0.08,  0.84,\n",
       "        -0.02,  0.1 ,  1.05, -0.08,  0.01,  1.04, -0.08, -0.09,  0.97,\n",
       "        -0.03,  0.05,  0.97, -0.04,  0.01,  0.97],\n",
       "       [ 0.06, -0.03,  0.98,  0.03, -0.08,  1.01,  0.07, -0.11,  1.01,\n",
       "         0.08,  0.01,  0.79,  0.04,  0.12,  0.88, -0.03,  0.13,  1.12,\n",
       "        -0.02, -0.08,  1.09,  0.04, -0.01,  0.89,  0.05,  0.02,  0.85,\n",
       "         0.01,  0.14,  1.07, -0.04,  0.03,  1.05, -0.06, -0.09,  0.98,\n",
       "        -0.04, -0.03,  0.99, -0.02, -0.03,  1.01],\n",
       "       [ 0.15, -0.04,  0.96,  0.15,  0.04,  0.91,  0.15,  0.03,  1.08,\n",
       "         0.13, -0.15,  1.08,  0.17, -0.02,  0.67,  0.21,  0.04,  0.83,\n",
       "         0.21,  0.26,  1.11,  0.12,  0.05,  1.01,  0.09, -0.05,  0.97,\n",
       "         0.15,  0.08,  0.97,  0.12,  0.05,  1.  ,  0.13,  0.05,  1.  ,\n",
       "         0.14,  0.05,  0.97,  0.13,  0.04,  0.98],\n",
       "       [ 0.05, -0.01,  0.97,  0.08,  0.14,  0.99,  0.03, -0.08,  1.04,\n",
       "         0.08, -0.17,  0.98,  0.11, -0.02,  0.78,  0.17,  0.2 ,  0.94,\n",
       "         0.07,  0.13,  1.06, -0.01,  0.03,  1.02,  0.02, -0.01,  0.98,\n",
       "         0.01,  0.04,  1.  ,  0.01,  0.04,  1.  ,  0.03,  0.06,  0.97,\n",
       "         0.03,  0.06,  1.  ,  0.02,  0.03,  0.98],\n",
       "       [ 0.07, -0.09,  0.99,  0.06, -0.12,  0.93,  0.07,  0.03,  1.07,\n",
       "         0.09, -0.07,  1.04,  0.1 , -0.05,  0.68,  0.09,  0.14,  0.95,\n",
       "         0.05,  0.07,  1.24,  0.08, -0.04,  0.98,  0.13,  0.02,  0.76,\n",
       "         0.08,  0.06,  0.95,  0.06,  0.11,  1.11,  0.04, -0.05,  0.98,\n",
       "         0.04, -0.03,  1.  ,  0.02, -0.04,  1.01],\n",
       "       [-0.03, -0.01,  1.  , -0.02, -0.02,  0.99,  0.02, -0.01,  1.04,\n",
       "         0.07,  0.06,  1.12,  0.07,  0.11,  0.98,  0.19,  0.12,  0.89,\n",
       "         0.25,  0.1 ,  0.89,  0.17, -0.08,  0.88,  0.08, -0.16,  0.95,\n",
       "        -0.  , -0.08,  1.04,  0.03,  0.14,  1.03,  0.05,  0.16,  1.02,\n",
       "         0.02,  0.14,  0.93,  0.03,  0.12,  1.  ],\n",
       "       [-0.04, -0.02,  0.98, -0.01, -0.06,  0.97, -0.03, -0.1 ,  1.27,\n",
       "         0.04,  0.14,  0.89,  0.19,  0.12,  0.81,  0.24, -0.01,  0.78,\n",
       "         0.24, -0.04,  0.82, -0.01, -0.16,  0.95, -0.09, -0.12,  1.09,\n",
       "        -0.05,  0.14,  0.99, -0.04,  0.05,  0.98, -0.04,  0.01,  0.94,\n",
       "        -0.06, -0.03,  0.97, -0.03, -0.01,  0.99],\n",
       "       [ 0.05, -0.09,  1.  ,  0.07, -0.11,  1.06,  0.07, -0.18,  0.85,\n",
       "         0.15,  0.11,  0.79,  0.07,  0.16,  1.06,  0.01, -0.09,  1.08,\n",
       "         0.01, -0.11,  0.97,  0.06, -0.01,  0.78,  0.02,  0.01,  1.01,\n",
       "        -0.02,  0.01,  1.08, -0.04, -0.07,  0.99, -0.03, -0.06,  0.96,\n",
       "        -0.03, -0.05,  0.99, -0.04, -0.05,  1.01],\n",
       "       [ 0.07, -0.06,  0.99,  0.05, -0.04,  0.94,  0.07,  0.08,  1.09,\n",
       "         0.05, -0.11,  1.14,  0.13,  0.09,  0.68,  0.09, -0.02,  0.79,\n",
       "         0.05,  0.23,  1.21,  0.04, -0.05,  1.14,  0.07,  0.02,  0.87,\n",
       "         0.11,  0.03,  0.84,  0.08,  0.11,  1.01,  0.06,  0.1 ,  1.03,\n",
       "         0.02, -0.11,  0.97,  0.05, -0.05,  0.98],\n",
       "       [ 0.05, -0.01,  0.98,  0.06,  0.05,  0.95,  0.08,  0.05,  1.11,\n",
       "         0.07, -0.08,  0.98,  0.12, -0.  ,  0.77,  0.1 ,  0.06,  0.97,\n",
       "         0.09,  0.1 ,  1.09,  0.06, -0.05,  1.1 ,  0.11,  0.01,  0.78,\n",
       "         0.11,  0.06,  0.96,  0.06,  0.1 ,  1.07,  0.03, -0.04,  1.01,\n",
       "         0.05, -0.02,  0.98,  0.06,  0.03,  1.  ],\n",
       "       [ 0.02, -0.03,  0.99,  0.03,  0.14,  1.02,  0.02, -0.12,  1.23,\n",
       "         0.06, -0.2 ,  0.87,  0.15,  0.01,  0.72,  0.16,  0.13,  0.8 ,\n",
       "         0.11,  0.22,  1.05,  0.06,  0.12,  0.99,  0.01, -0.03,  0.96,\n",
       "         0.03,  0.02,  0.97,  0.01,  0.01,  1.  ,  0.03,  0.  ,  0.95,\n",
       "         0.03,  0.04,  1.  ,  0.04,  0.02,  0.98],\n",
       "       [ 0.07, -0.05,  0.97,  0.06, -0.02,  0.99,  0.07,  0.08,  1.02,\n",
       "         0.11, -0.06,  1.11,  0.13, -0.08,  0.97,  0.12, -0.06,  0.77,\n",
       "         0.1 ,  0.11,  0.89,  0.14,  0.09,  1.07,  0.1 ,  0.05,  0.96,\n",
       "         0.04, -0.09,  0.98,  0.06, -0.02,  0.98,  0.07,  0.  ,  0.93,\n",
       "         0.11,  0.04,  1.02,  0.1 ,  0.03,  0.97],\n",
       "       [ 0.05, -0.05,  0.98,  0.03,  0.01,  1.02,  0.05,  0.03,  0.98,\n",
       "         0.06, -0.09,  1.1 ,  0.15,  0.01,  0.84,  0.17,  0.03,  0.83,\n",
       "         0.11, -0.01,  0.94,  0.13,  0.14,  0.96,  0.11,  0.13,  1.05,\n",
       "         0.01, -0.03,  1.02,  0.09,  0.06,  1.  ,  0.08,  0.06,  0.99,\n",
       "         0.05,  0.03,  0.96,  0.07,  0.05,  1.01],\n",
       "       [ 0.07, -0.09,  1.  ,  0.1 , -0.01,  0.99,  0.09, -0.01,  0.99,\n",
       "         0.07, -0.15,  1.06,  0.12, -0.1 ,  0.89,  0.16,  0.13,  0.86,\n",
       "         0.16,  0.17,  1.02,  0.11,  0.08,  0.96,  0.08, -0.02,  0.95,\n",
       "         0.09, -0.01,  0.98,  0.11,  0.07,  1.01,  0.07, -0.01,  0.98,\n",
       "         0.11,  0.04,  0.97,  0.07, -0.  ,  0.99],\n",
       "       [ 0.02, -0.02,  1.01,  0.06,  0.07,  0.88,  0.06,  0.19,  1.1 ,\n",
       "         0.08, -0.21,  1.05,  0.14, -0.04,  0.8 ,  0.1 , -0.02,  0.69,\n",
       "         0.19,  0.32,  1.02,  0.09,  0.15,  1.05, -0.03, -0.01,  1.11,\n",
       "        -0.02,  0.03,  1.01, -0.05, -0.05,  0.94, -0.  ,  0.03,  1.01,\n",
       "        -0.01,  0.01,  1.03, -0.  ,  0.  ,  1.  ],\n",
       "       [ 0.04, -0.11,  0.98,  0.06, -0.02,  0.98,  0.05,  0.04,  1.01,\n",
       "         0.14, -0.06,  1.02,  0.13, -0.04,  0.88,  0.14, -0.02,  0.84,\n",
       "         0.12, -0.01,  0.89,  0.09,  0.1 ,  1.09,  0.03, -0.  ,  1.02,\n",
       "         0.07, -0.  ,  0.95,  0.01, -0.13,  1.  ,  0.09,  0.02,  0.99,\n",
       "         0.05, -0.03,  1.  ,  0.09,  0.02,  1.01],\n",
       "       [ 0.01, -0.08,  0.99,  0.01, -0.02,  0.96,  0.06,  0.  ,  1.1 ,\n",
       "         0.07, -0.07,  1.  ,  0.14, -0.02,  0.65,  0.13,  0.04,  0.99,\n",
       "         0.13,  0.22,  1.07, -0.01,  0.16,  1.08,  0.  , -0.02,  0.96,\n",
       "         0.01,  0.06,  1.02,  0.01,  0.06,  0.98,  0.  ,  0.05,  0.99,\n",
       "         0.  ,  0.04,  0.98,  0.03,  0.06,  0.98]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 3, 2, 0, 0, 3, 1, 2, 3, 4, 4, 1, 1, 1, 4, 1, 3, 0, 4, 1, 1, 3,\n",
       "       1, 2, 3, 0, 2, 1, 0, 4, 4, 4, 4, 3, 4, 2, 0, 2, 1, 3, 0, 3, 2, 4,\n",
       "       2, 0, 4, 0, 1, 1, 0, 3, 0, 2, 0, 2, 4, 4, 0, 0, 3, 2, 3, 3, 0, 2,\n",
       "       2, 3, 1, 0, 3, 2, 4, 2, 3, 4, 4, 3, 0, 4, 1, 1, 1, 0, 0, 2, 1, 4,\n",
       "       3, 3, 0, 4, 4, 1, 1, 2, 1, 3, 2, 2])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Spotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test options and evaluation metric\n",
    "num_folds = 5\n",
    "seed = 42\n",
    "scoring = 'f1_macro'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spot-Check Algorithms\n",
    "models = []\n",
    "\n",
    "#models.append(('XGB', XGBClassifier(random_state=seed)))\n",
    "models.append(('GNB', GaussianNB(var_smoothing=2e-9)))\n",
    "models.append(('LR', LogisticRegression(random_state=seed)))\n",
    "models.append(('CART' , DecisionTreeClassifier(random_state=seed)))\n",
    "models.append(('SVC' , SVC(gamma=0.99, random_state=seed)))\n",
    "models.append(('RF', RandomForestClassifier(random_state=RANDOM_SEED, n_estimators=100, \n",
    "                                                           max_features=5, criterion='gini', max_depth=None,\n",
    "                                                           min_samples_split=4, min_samples_leaf=1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GNB - 0,85 0,05\n",
      "LR - 0,89 0,02\n",
      "CART - 0,77 0,08\n",
      "SVC - 0,93 0,03\n",
      "RF - 0,89 0,03\n"
     ]
    }
   ],
   "source": [
    "# Cross Validation\n",
    "results = []\n",
    "names = []\n",
    "for name, model in models:\n",
    "    # Dividere dati in n = num_folds\n",
    "    kf = StratifiedKFold(n_splits=num_folds, random_state=seed, shuffle=True)\n",
    "    cv_results = np.array([])\n",
    "    for train_idx, test_idx, in kf.split(X_train, y_train):\n",
    "        X_cross_train, y_cross_train = X_train[train_idx], y_train[train_idx]\n",
    "        X_cross_test, y_cross_test = X_train[test_idx], y_train[test_idx]\n",
    "        model.fit(X_cross_train, y_cross_train)  \n",
    "        y_pred = model.predict(X_cross_test)\n",
    "        f1s = f1_score(y_cross_test, y_pred, average=\"weighted\")\n",
    "        cv_results = np.append(cv_results, [f1s])\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    #msg = \"%s - %f - %f\" % (name, cv_results.mean(), cv_results.std())\n",
    "    msg = \"{} - {:.2f} {:.2f}\".format(name, cv_results.mean(), cv_results.std()).replace('.', ',')\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlkAAAFTCAYAAAAKixm8AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAfmUlEQVR4nO3df7RdZ13n8feH9JdYWm9pLNI2bcGCKRGK3CkiVVqgUH+M5ccMJqK2rGhHtJ0l4g+YoA1lMsCMiqNWoU46gEJC1YUrjrgK2tQSBc2NtJW0FNKU0qRUUhKoQEvT8J0/zr5wenuTe5Oe55x7b96vtc7K2Xs/++zvPjvn5pNnP+e5qSokSZI0WI8bdQGSJEkLkSFLkiSpAUOWJElSA4YsSZKkBgxZkiRJDRiyJEmSGjBkSQtMkncn+e+NXvvVST58gO3nJdnR4tgLVZIlSb6SZNGoa5E0WIYsaZ5KckOSPUmOHtYxq+p9VfWSvhoqyXcP6/gHkuScJB9K8qUku5P8c5LXjLqumVTV56rq2KraN+paJA2WIUuah5KcDvwgUMCPD+mYRwzjOIciyfOA64G/B74beCLwWuCHR1nXTObyeyrpsTNkSfPTzwAfB94NXHyghkl+Lcnnk9yT5Gf7e5+SHJ/kvUl2JbkryZuSPK7bdkmSf0jyjiRfBFZ36zZ122/sDnFzd7vrJ/qO+fokX+iO+5q+9e9O8odJ/qbb5x+SPCnJ73a9cp9K8uy+9r+eZGeSf09ye5IX7ec0/xfwnqp6e1XdVz1bqupVfa/1c0m2db1cG5I8uW9bJfmFJJ/pjvWWJE9N8o9J7k9ybZKjurbnJdmR5L8luS/JZ5O8uu+1fjTJJ7r97k6yum/b6d2xVib5HHB937oj+t737V0dd06+dpLHddfnru69fW+S46e87sVJPtfVtepAfy8ktWfIkuannwHe1z1emuSk6RoluRD4ZeDF9Hp4zpvS5PeB44GnAC/oXrf/Fttzge3AScCa/h2r6oe6p8/qbnd9oFt+UveaJwMrgauSjPXt+irgTcCJwNeBjwH/0i3/OfA7Xe1PBy4D/kNVPQF4KfDZac7x8cDzun2nleSFwFu7Y38XcBewfkqzlwLPAb4f+DXgauCngFOBZcCKvrZP6uo9mV7IvbqrF+Cr9N7H7wB+FHhtkpdNOdYLgKXdMfvr/Hbg94Af7s75B4Cbus2XdI/z6V2vY4E/mPK65wJPB14E/GaSpdO/I5KGwZAlzTNJzgVOA66tqi3AHcBP7qf5q4D/W1Vbq+prwOq+11kELAfeWFX/XlWfBX4b+Om+/e+pqt+vqoer6oFZlrgXuLKq9lbVh4Cv0PuHf9IHu16mB4EPAg9W1Xu7MUkfACZ7svYBRwNnJTmyqj5bVXdMc7wxej/LPn+Aml4NXFNV/1JVXwfeCDyvu+066X9W1f1VtRX4JPDhqtpeVV8G/qavrkm/UVVfr6q/B/6a3ntNVd1QVf9aVd+oqluAdfRCVb/VVfXV/byn3wCWJfm2qvp8V8/kOfxOV9NXunNYPuWW45ur6oGquhm4GXjWAd4TSY0ZsqT552J6AeC+bvn97P+W4ZOBu/uW+5+fCBxJr1dn0l30ememaz9bX6yqh/uWv0av12XSv/U9f2Ca5WMBqmob8Ev0guEXkqzvv8XXZw+9YPJdB6jpyfSdZxdSvsgjz3VWdU0es6q+2rd8V3cMkjw3ycbuFuyXgZ+n9173m/Z97V7zJ7p9Pp/kr5N8z3Tn0D0/gl4v46R7+55Pfd8lDZkhS5pHknwbvR6TFyS5N8m9wOuAZyWZrtfi88Apfcun9j2/j16v02l965YAO/uWayCFH6Kqen9VTfbcFfD2adp8jd4tx1ce4KXuoe88u9tyT+SR53owxrrXmLSkOwb0Qu8G4NSqOh54J5CpZe/vhavquqq6gF5o/BTwx9OdQ3fMh3lkGJQ0hxiypPnlZfRuo50FnN09lgIfpTcOaKprgdckWdqNXfqNyQ3d7blrgTVJnpDkNHrjt/70IOr5N3rjgwYuydOTvDC9KSoepNeb9I39NP814JIkv5rkid3+z0oyOe5qHb334ezu9f4H8E/dLdJD9eYkRyX5QeDHgD/r1j8B2F1VDyY5h/3fyn2UJCcluagLcF+nd6t18pzXAa9LckaSY7tz+MCUXkNJc4ghS5pfLqY3xupzVXXv5IPeAOhXTxmfQ1X9Db2B1BuBbfS+kQi9f8ABLqc3UHs7sIleL8w1B1HPauA96c1N9aqZGh+ko4G30etxuxf4TnrjkB6lqv4ReGH32J5kN72B6x/qtv8tvYD5F/R6955KbzzaobqX3m3Ke+h9+eDnq+pT3bZfAK5M8u/Ab9ILsrP1OHpB9x5gN72xXK/ttl0D/AlwI3AnveB5+WM4B0mNpWqkdwMkDVH3bbNPAkfbA3JokpwH/GlVnTJDU0mHOXuypAUuycuTHN1No/B24K8MWJLUniFLWvj+C/AFelM97ONbt58kSQ15u1CSJKkBe7IkSZIaMGRJkiQ1YMiSJElqwJAlSZLUgCFLkiSpAUOWJElSA4YsSZKkBgxZkiRJDRiyJEmSGjBkSZIkNWDIkiRJasCQJUmS1IAhS5IkqQFDliRJUgOGLEmSpAYMWZIkSQ0YsiRJkhowZEmSJDVgyJIkSWrAkCVJktSAIUuSJKkBQ5YkSVIDR4y6gKlOPPHEOv3000ddhiRJ0oy2bNlyX1Utnm7bnAtZp59+OhMTE6MuQ5IkaUZJ7trfNm8XSpIkNWDIkiRJasCQJUmS1IAhS5IkqQFDliRJUgOGLEmSpAYMWZIkSQ0YsiRJkhowZEmSJDVgyJIkSWpgzv1aHUnSwpVk6MesqqEfUwJDliRpiA418CQxLGne8XahJElSA4YsSZKkBgxZkiRJDRiyJEmSGjBkSZIkNTCrkJXkwiS3J9mW5A3TbD8tyd8luSXJDUlO6du2L8lN3WPDIIuXJEmaq2acwiHJIuAq4AJgB7A5yYaqurWv2W8B762q9yR5IfBW4Ke7bQ9U1dmDLVuSJGlum01P1jnAtqraXlUPAeuBi6a0OQu4vnu+cZrtkiRJh5XZhKyTgbv7lnd06/rdDLyie/5y4AlJntgtH5NkIsnHk7zssRQrSZobTjjhBJIM7QEM9XgnnHDCiN9hLQSDmvH9V4A/SHIJcCOwE9jXbTutqnYmeQpwfZJ/rao7+ndOcilwKcCSJUsGVJIkqZU9e/Ys6BnYR/Hrf7TwzKYnaydwat/yKd26b6qqe6rqFVX1bGBVt+5L3Z87uz+3AzcAz556gKq6uqrGq2p88eLFh3AakiRJc8tsQtZm4MwkZyQ5ClgOPOJbgklOTDL5Wm8ErunWjyU5erIN8Hygf8C8JEnSgjRjyKqqh4HLgOuA24Brq2prkiuT/HjX7Dzg9iSfBk4C1nTrlwITSW6mNyD+bVO+lShJkrQgZa7dUx8fH6+JiYlRlyFJOoAkC35M1kI+Pw1Oki1VNT7dNmd8lyRJasCQJUmS1IAhS5IkqQFDliRJUgOGLEmSpAYMWZIkSQ0YsiRJkhowZEmSJDVgyJIkSWrAkCVJktSAIUuSJKkBQ5YkSVIDhixJkqQGDFmSJEkNHDHqAiRJ809dcRysPn7UZTRTVxw36hK0ABiyJEkHLW++n6oadRnNJKFWj7qKuSfJ0I85n/+eGbIkSdKsHGrgSTKvw9KhckyWJElSA4YsSZKkBgxZkiRJDRiyJEmSGjBkSZIkNWDIkiRJasApHCRJh2QUcyYNy9jY2KhL0AJgyJIkHbRhz3l0uM6z1MoJJ5zAnj17hnrMYYbysbExdu/ePbTj7Y8h6xA5660kab7as2fPgv43Za70shqyDpGz3kqSpANx4LskSVIDhixJkqQGDFmSJEkNzCpkJbkwye1JtiV5wzTbT0vyd0luSXJDklP6tl2c5DPd4+JBFi9JkjRXzRiykiwCrgJ+GDgLWJHkrCnNfgt4b1U9E7gSeGu37wnAFcBzgXOAK5I4+YgkSVrwZtOTdQ6wraq2V9VDwHrgoiltzgKu755v7Nv+UuAjVbW7qvYAHwEufOxlS5IkzW2zmcLhZODuvuUd9Hqm+t0MvAL438DLgSckeeJ+9j35kKuVJEmPWV1xHKw+ftRlNFNXHDfqEoDBzZP1K8AfJLkEuBHYCeyb7c5JLgUuBViyZMmAStLhYBSzFg/TXJm1WNLCkjffv6DnbExCrR51FbMLWTuBU/uWT+nWfVNV3UOvJ4skxwKvrKovJdkJnDdl3xumHqCqrgauBhgfH1+4V10D56zFkqS5ajZjsjYDZyY5I8lRwHJgQ3+DJCcmmXytNwLXdM+vA16SZKwb8P6Sbp0kSdKCNmPIqqqHgcvohaPbgGuramuSK5P8eNfsPOD2JJ8GTgLWdPvuBt5CL6htBq7s1kmSJC1omWu3WsbHx2tiYmLUZTTj7y4crIX+fi7085Nmy8/CYC3093OY55dkS1WNT7fNGd8lSZIaMGRJkiQ1YMiSJElqwJAlSZLUgCFLkiSpgUHN+D5vjWLG8GFOMOmM4ZIkjcZhH7KcMXx+8/dvSdKhWcj/PoyNjY26BMCQpflu9ZdHXYEkzTsLuXNhLnFMliRJUgOGLEmSpAYMWZIkSQ0YsiRJkhowZEmSJDVgyJIkSWrAkCVJktSAIUuSJKkBJyOVJA3NY5ll/FD3deJNjYohS5I0NAYeHU68XShJktSAIUuSJKkBQ5YkSVIDhixJkqQGDFmSJEkNGLIkSZIaMGRJkiQ1YMiSZmHdunUsW7aMRYsWsWzZMtatWzfqkiRJc5yTkUozWLduHatWrWLt2rWce+65bNq0iZUrVwKwYsWKEVcnSZqr7MmSZrBmzRrWrl3L+eefz5FHHsn555/P2rVrWbNmzahLkyTNYZlrv+JgfHy8JiYmhna8JAv61zws9PMbhkWLFvHggw9y5JFHfnPd3r17OeaYY9i3b98IKzt8PZbff3co/AxJ2p8kW6pqfLpt9mRJM1i6dCmbNm16xLpNmzaxdOnSEVWkqjrox6HuZ8CSdKhmFbKSXJjk9iTbkrxhmu1LkmxM8okktyT5kW796UkeSHJT93jnoE9Aam3VqlWsXLmSjRs3snfvXjZu3MjKlStZtWrVqEuTJM1hMw58T7IIuAq4ANgBbE6yoapu7Wv2JuDaqvqjJGcBHwJO77bdUVVnD7RqaYgmB7dffvnl3HbbbSxdupQ1a9Y46F2SdECz+XbhOcC2qtoOkGQ9cBHQH7IKOK57fjxwzyCLlEZtxYoVhipJ0kGZTcg6Gbi7b3kH8NwpbVYDH05yOfDtwIv7tp2R5BPA/cCbquqjh17u4NUVx8Hq40ddRjN1xXEzN5IkSQM3qHmyVgDvrqrfTvI84E+SLAM+Dyypqi8meQ7wl0meUVX39++c5FLgUoAlS5YMqKTZyZvvX9ADW5NQq0ddhSRJh5/ZDHzfCZzat3xKt67fSuBagKr6GHAMcGJVfb2qvtit3wLcATxt6gGq6uqqGq+q8cWLFx/8WUiSJM0xswlZm4Ezk5yR5ChgObBhSpvPAS8CSLKUXsjalWRxN3CeJE8BzgS2D6p4SZKkuWrG24VV9XCSy4DrgEXANVW1NcmVwERVbQBeD/xxktfRGwR/SVVVkh8CrkyyF/gG8PNVtbvZ2UiSJM0Rzvi+wGdEX+jnJ82WnwVJLTjjuyRJ0pAZsiRJkhowZEmSJDVgyJIkSWrAkCVJktSAIUuSJKkBQ5YkSWpi3bp1LFu2jEWLFrFs2TLWrVs36pKGalC/u1CSJOmb1q1bx6pVq1i7di3nnnsumzZtYuXKlQCsWLFixNUNhz1ZkiRp4NasWcPatWs5//zzOfLIIzn//PNZu3Yta9asGXVpQ+OM7wt8FuiFfn7SbPlZkIZr0aJFPPjggxx55JHfXLd3716OOeYY9u3bN8LKBssZ3yVJ0lAtXbqUTZs2PWLdpk2bWLp06YgqGj5DliRJGrhVq1axcuVKNm7cyN69e9m4cSMrV65k1apVoy5taBz4LkmSBm5ycPvll1/ObbfdxtKlS1mzZs1hM+gdHJO14MdpLPTzk2bLz4KkFhyTJUmSNGTeLpQ0MieccAJ79uwZ2vGSDO1YY2Nj7N69e2jHkzT3GLIY7g/eYRsbGxt1CdJ+7dmzZ8HewlvIP1ckzc5hH7KG/QPecSGSJB0eHJMlSZLUgCFLkiSpAUOWJElSA4YsSZKkBgxZkiRJDRiyJEmSGjBkSZIkNWDIkiRJasCQJUmS1IAhS5IkqQFDliRJUgOGLEmSpAZmFbKSXJjk9iTbkrxhmu1LkmxM8okktyT5kb5tb+z2uz3JSwdZvCRJ0lx1xEwNkiwCrgIuAHYAm5NsqKpb+5q9Cbi2qv4oyVnAh4DTu+fLgWcATwb+NsnTqmrfoE9EkiRpLplNT9Y5wLaq2l5VDwHrgYumtCnguO758cA93fOLgPVV9fWquhPY1r2eJEnSgjabkHUycHff8o5uXb/VwE8l2UGvF+vyg9hXkiRpwRnUwPcVwLur6hTgR4A/STLr105yaZKJJBO7du0aUEmSJEmjM5sgtBM4tW/5lG5dv5XAtQBV9THgGODEWe5LVV1dVeNVNb548eLZVy9JkjRHzSZkbQbOTHJGkqPoDWTfMKXN54AXASRZSi9k7eraLU9ydJIzgDOBfx5U8ZIkSXPVjN8urKqHk1wGXAcsAq6pqq1JrgQmqmoD8Hrgj5O8jt4g+EuqqoCtSa4FbgUeBn7RbxZKkqTDQXpZaO4YHx+viYmJUZfRTBLm2nsujcpC/jws5HOT9C1JtlTV+HTbnPFdkiSpAUOWJElSAzOOyZKkVuqK42D18aMuo4m64riZG0la0AxZkkYmb75/wY5bSkKtHnUVkkbJ24WSJEkNGLIkSZIaMGRJkiQ1YMiSJElqwIHvhyjJ0PddqAOEJUlaiAxZh8jAI0mSDsTbhZIkSQ0YsiRJkhowZEmSJDVgyJIkSWrAkCVJktSAIUuSJKkBQ5YkSVIDhixJkqQGDFmSJEkNGLIkSZIaMGRJkiQ1YMiSJElqwJAlSZLUgCFLkiSpAUOWJElSA4YsSZKkBgxZkiRJDRiyJEmSGjBkSZIkNWDIkiRJasCQJUmS1MCsQlaSC5PcnmRbkjdMs/0dSW7qHp9O8qW+bfv6tm0YYO2SJElz1hEzNUiyCLgKuADYAWxOsqGqbp1sU1Wv62t/OfDsvpd4oKrOHljFkiRJ88BserLOAbZV1faqeghYD1x0gPYrgHWDKE6SJGm+mk3IOhm4u295R7fuUZKcBpwBXN+3+pgkE0k+nuRl+9nv0q7NxK5du2ZXuSRJ0hw26IHvy4E/r6p9fetOq6px4CeB303y1Kk7VdXVVTVeVeOLFy8ecEmSJEnDN5uQtRM4tW/5lG7ddJYz5VZhVe3s/twO3MAjx2tJkiQtSLMJWZuBM5OckeQoekHqUd8STPI9wBjwsb51Y0mO7p6fCDwfuHXqvpIkSQvNjN8urKqHk1wGXAcsAq6pqq1JrgQmqmoycC0H1ldV9e2+FHhXkm/QC3Rv6/9WoiRJ0kKVR2ai0RsfH6+JiYlRlyFpCJIw134GDcpCPjdJ35JkSzf2/FGc8V2SJKkBQ5YkSVIDhixJkqQGDFmSJEkNGLIkSZIaMGRJkiQ1YMiSJElqwJAlSZLUgCFLkiSpAUOWJElSA4YsSZKkBgxZkiRJDRiyJEmSGjBkSZIkNWDIkiRJasCQJUmS1IAhS5IkqQFDliRJUgOGLEmSpAYMWZIkSQ0YsiRJkhowZEmSJDVgyJIkSWrgiFEXIOnwlmTUJTQxNjY26hIkjZghS9LIVNXQjpVkqMeTJG8XSpIkNWDIkiRJasCQJUmS1IAhS5IkqQFDliRJUgOzCllJLkxye5JtSd4wzfZ3JLmpe3w6yZf6tl2c5DPd4+IB1i5JkjRnzTiFQ5JFwFXABcAOYHOSDVV162SbqnpdX/vLgWd3z08ArgDGgQK2dPvuGehZSJIkzTGz6ck6B9hWVdur6iFgPXDRAdqvANZ1z18KfKSqdnfB6iPAhY+lYEmSpPlgNiHrZODuvuUd3bpHSXIacAZw/cHuK0mStJAMeuD7cuDPq2rfweyU5NIkE0kmdu3aNeCSJEmShm82IWsncGrf8induuks51u3Cme9b1VdXVXjVTW+ePHiWZQkSZI0t80mZG0GzkxyRpKj6AWpDVMbJfkeYAz4WN/q64CXJBlLMga8pFsnSZK0oM347cKqejjJZfTC0SLgmqramuRKYKKqJgPXcmB99f0G1qraneQt9IIawJVVtXuwpyBJkjT3ZK79Vvrx8fGamJgYdRmSFpgkzLWfd5LmvyRbqmp8um3O+C5JktSAIUuSJKkBQ5YkSVIDhixJkqQGDFmSJEkNGLIkSZIaMGRJkiQ1YMiSJElqwJAlSZLUgCFLkiSpAUOWJElSA4YsSZKkBgxZkiRJDRiyJEmSGjBkSZIkNWDIkiRJasCQJUmS1IAhS5IkqQFDliRJUgOGLEmSpAYMWZIkSQ0YsiRJkhowZEmSJDVgyJIkSWrAkCVJktSAIUuSJKkBQ5YkSVIDhixJkqQGDFmSJEkNGLIkSZIamFXISnJhktuTbEvyhv20eVWSW5NsTfL+vvX7ktzUPTYMqnBJkqS57IiZGiRZBFwFXADsADYn2VBVt/a1ORN4I/D8qtqT5Dv7XuKBqjp7sGVLkiTNbbPpyToH2FZV26vqIWA9cNGUNj8HXFVVewCq6guDLVOSJGl+mU3IOhm4u295R7eu39OApyX5hyQfT3Jh37Zjkkx061/22MqVJEmaH2a8XXgQr3MmcB5wCnBjku+tqi8Bp1XVziRPAa5P8q9VdUf/zkkuBS4FWLJkyYBKkiRJGp3Z9GTtBE7tWz6lW9dvB7ChqvZW1Z3Ap+mFLqpqZ/fnduAG4NlTD1BVV1fVeFWNL168+KBPQtLhJclBPw51v8l9JelgzSZkbQbOTHJGkqOA5cDUbwn+Jb1eLJKcSO/24fYkY0mO7lv/fOBWJOkxqKqhPiTpUMx4u7CqHk5yGXAdsAi4pqq2JrkSmKiqDd22lyS5FdgH/GpVfTHJDwDvSvINeoHubf3fSpQkSVqoMtf+lzY+Pl4TExOjLkOSJGlGSbZU1fh025zxXZIkqQFDliRJUgOGLEmSpAYMWZIkSQ0YsiRJkhowZEmSJDVgyJIkSWrAkCVJktSAIUuSJKmBOTfje5JdwF2jrqOhE4H7Rl2EDpnXb/7y2s1vXr/5bSFfv9OqavF0G+ZcyFrokkzsb/p9zX1ev/nLaze/ef3mt8P1+nm7UJIkqQFDliRJUgOGrOG7etQF6DHx+s1fXrv5zes3vx2W188xWZIkSQ3YkyVJktSAIWuAkpyU5P1JtifZkuRjSV6e5LwkleQ/9rX9f0nO657fkOT2JDcluS3JpaM6B31Lkq9Ms251kp3dtbo1yYpR1KaeJE9Ksj7JHd1n7kNJntZt+6UkDyY5vq/9eUm+3F2/TyX5rSTf2y3flGR3kju75387ujM7/CRZlWRrklu69/+KJG+d0ubsJLd1z49N8q6+a39DkueOpnpNSrKvu36fTPJXSb6jW396kgf6Pms3JTlqxOU2Z8gakCQB/hK4saqeUlXPAZYDp3RNdgCrDvASr66qs4HnA28/HP7yzWPv6K7VRcC7khw54noOS91n7oPADVX11O4z90bgpK7JCmAz8Iopu360u37PBn4MOK6qzu7WbQB+tVt+8RBOQ0CS59G7Ft9XVc8EXgxsBH5iStPlwLru+f8BdgNndtf+NfTmYtJoPdB9fpbRuz6/2LftjsnPWvd4aEQ1Do0ha3BeCDxUVe+cXFFVd1XV73eLNwNfTnLBDK9zLPBVYF+bMjUoVfUZ4GvA2KhrOUydD+yd8pm7uao+muSp9D5Lb6IXth6lqh4AbgJOHkKtOrDvAu6rqq8DVNV9VXUjsGdK79SrgHXd9X0u8Kaq+ka3z51V9dfDLlwH9DEO88+XIWtwngH8ywxt1tD7oT+d9yW5BbgdeEtVGbLmuCTfB3ymqr4w6loOU8uALfvZthxYD3wUeHqSk6Y2SDIGnAnc2KxCzdaHgVOTfDrJHyZ5Qbd+Hb1rSZLvB3Z3/7l5BnCTPyfnriSLgBfR6x2e9NS+W4VXjai0oTJkNZLkqiQ3J9k8ua77nxlJzp1ml1d33eRLgF9JctqQStXBe12SrcA/0QvOmntWAOu7Xo6/AP5z37YfTHIzsBO4rqruHUWB+paq+grwHOBSYBfwgSSXAB8A/lOSx/HIW4Wau74tyU3AvfRu3X+kb1v/7cJfnHbvBcaQNThbge+bXOj+Ar0ImPr7jA7Um0VV7aLXI+YAzrnrHVX1DOCVwNokx4y6oMPUVnr/MD9Cku+l10P1kSSfpfePc/8tw49W1bPo9YasTHJ2+1I1k6raV1U3VNUVwGXAK6vqbuBO4AX0Pm8f6JpvBZ7V9ZZobnmgG994GhAeOSbrsGPIGpzrgWOSvLZv3eOnNqqqD9Mbw/PM6V4kyePpDci9o0WRGpyq2gBMABePupbD1PXA0f3fxk3yTOD3gNVVdXr3eDLw5Km9w1V1J/A24NeHWbQeLcnTk5zZt+ps4K7u+TrgHcD2qtoBUFV30Pvsvbn7AsTkt9d+dHhV60Cq6mvAfwVen+SIUdczKoasAanerK4vA17QfQX8n4H3MP0P8DXAqVPWva/rYt0CvLuq9jfWRMPz+CQ7+h6/PE2bK4Ff7m5naIi6z9zLgRd3X+PfCrwVOI/etw77fZBubM8U7wR+KMnpDUvVzI4F3tNNi3ILcBawutv2Z/R6HafeKvxZerejtiX5JPBuwPGRc0hVfQK4hf18+eRw4IzvkiRJDfi/b0mSpAYMWZIkSQ0YsiRJkhowZEmSJDVgyJIkSWrAkCVJktSAIUuSJKkBQ5YkSVID/x+Dw6qQAokD6QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compare Algorithms\n",
    "fig = plt.figure(figsize=(10,5))\n",
    "fig.suptitle('Algorithms Comparison')\n",
    "ax = fig.add_subplot(111)\n",
    "plt.boxplot(results)\n",
    "ax.set_xticklabels(names)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Valutazione dei migliori algoritmi su test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Valutazione modelli sul Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model GNB: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.95      0.95        20\n",
      "           1       0.68      0.75      0.71        20\n",
      "           2       0.80      0.80      0.80        20\n",
      "           3       1.00      0.80      0.89        20\n",
      "           4       0.86      0.95      0.90        20\n",
      "\n",
      "    accuracy                           0.85       100\n",
      "   macro avg       0.86      0.85      0.85       100\n",
      "weighted avg       0.86      0.85      0.85       100\n",
      "\n",
      "-------------------------------------------------------------\n",
      "Model LR: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.95      0.95        20\n",
      "           1       0.94      0.80      0.86        20\n",
      "           2       0.74      0.85      0.79        20\n",
      "           3       0.89      0.80      0.84        20\n",
      "           4       0.86      0.95      0.90        20\n",
      "\n",
      "    accuracy                           0.87       100\n",
      "   macro avg       0.88      0.87      0.87       100\n",
      "weighted avg       0.88      0.87      0.87       100\n",
      "\n",
      "-------------------------------------------------------------\n",
      "Model CART: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.95      0.95        20\n",
      "           1       0.71      0.75      0.73        20\n",
      "           2       0.65      0.85      0.74        20\n",
      "           3       0.92      0.60      0.73        20\n",
      "           4       0.85      0.85      0.85        20\n",
      "\n",
      "    accuracy                           0.80       100\n",
      "   macro avg       0.82      0.80      0.80       100\n",
      "weighted avg       0.82      0.80      0.80       100\n",
      "\n",
      "-------------------------------------------------------------\n",
      "Model SVC: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.98        20\n",
      "           1       0.89      0.85      0.87        20\n",
      "           2       0.85      0.85      0.85        20\n",
      "           3       0.95      1.00      0.98        20\n",
      "           4       1.00      0.95      0.97        20\n",
      "\n",
      "    accuracy                           0.93       100\n",
      "   macro avg       0.93      0.93      0.93       100\n",
      "weighted avg       0.93      0.93      0.93       100\n",
      "\n",
      "-------------------------------------------------------------\n",
      "Model RF: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.98        20\n",
      "           1       0.89      0.85      0.87        20\n",
      "           2       0.89      0.85      0.87        20\n",
      "           3       0.95      1.00      0.98        20\n",
      "           4       0.95      0.95      0.95        20\n",
      "\n",
      "    accuracy                           0.93       100\n",
      "   macro avg       0.93      0.93      0.93       100\n",
      "weighted avg       0.93      0.93      0.93       100\n",
      "\n",
      "-------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def classification_report_csv(report, model_name):\n",
    "    report_data = []\n",
    "    lines = report.split('\\n')\n",
    "    index = 0\n",
    "    row = lines[-4].split('    ')\n",
    "    accuracy = row[-2] if taskIndex > 1 else row[-3]\n",
    "    for line in lines[2:-5]:\n",
    "        row = {}\n",
    "        row_data = line.split('      ')\n",
    "        row['class'] = labels[index]\n",
    "        row['precision'] = float(row_data[2]) \n",
    "        row['recall'] = float(row_data[3]) \n",
    "        row['f1_score'] = float(row_data[4])\n",
    "        row['accuracy'] = accuracy\n",
    "        report_data.append(row)\n",
    "        index += 1\n",
    "    dataframe = pd.DataFrame.from_dict(report_data)\n",
    "    dataframe.to_csv(tasks[taskIndex] + \"/classificationReports/\" +'report' + model_name +  '.csv', index = False)\n",
    "    \n",
    "for name, model in models:\n",
    "    model.fit(X_train,  y_train)\n",
    "    pred_train = model.predict(X_train)\n",
    "    pred_test = model.predict(X_test)\n",
    "    print(f\"Model {name}: \")\n",
    "    report = classification_report(y_test, pred_test)\n",
    "    print(report)\n",
    "    classification_report_csv(report, name)\n",
    "    print(\"-------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Hyperparameters of NN\n",
    "EPOCHS = 500 \n",
    "BATCH_SIZE = 7\n",
    "learn_rate = 0.001\n",
    "nodes = 256\n",
    "def getNetwork():\n",
    "    model = Sequential(name=\"Sequential-NN\")\n",
    "    model.add(layers.Dense(X.shape[1], activation='relu', input_shape=(X.shape[1],)))\n",
    "    model.add(layers.Dropout(0.25))    \n",
    "    model.add(layers.Dense(nodes, activation='relu'))\n",
    "    model.add(layers.Dropout(0.25))\n",
    "    model.add(layers.Dense(np.unique(y).size, activation='softmax'))\n",
    "    opt = Adam(learning_rate=learn_rate)\n",
    "    # SGB\n",
    "    model.compile(optimizer=opt, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Sequential-NN\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 42)                1806      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 42)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               11008     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 5)                 1285      \n",
      "=================================================================\n",
      "Total params: 14,099\n",
      "Trainable params: 14,099\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/500\n",
      "46/46 [==============================] - 0s 438us/step - loss: 1.5987 - accuracy: 0.2656\n",
      "Epoch 2/500\n",
      "46/46 [==============================] - 0s 399us/step - loss: 1.4567 - accuracy: 0.4094\n",
      "Epoch 3/500\n",
      "46/46 [==============================] - 0s 396us/step - loss: 1.2548 - accuracy: 0.4812\n",
      "Epoch 4/500\n",
      "46/46 [==============================] - 0s 428us/step - loss: 1.0786 - accuracy: 0.5969\n",
      "Epoch 5/500\n",
      "46/46 [==============================] - 0s 407us/step - loss: 0.9896 - accuracy: 0.5938\n",
      "Epoch 6/500\n",
      "46/46 [==============================] - 0s 406us/step - loss: 0.8862 - accuracy: 0.6000\n",
      "Epoch 7/500\n",
      "46/46 [==============================] - 0s 438us/step - loss: 0.8365 - accuracy: 0.6406\n",
      "Epoch 8/500\n",
      "46/46 [==============================] - 0s 429us/step - loss: 0.7605 - accuracy: 0.7063\n",
      "Epoch 9/500\n",
      "46/46 [==============================] - 0s 420us/step - loss: 0.7160 - accuracy: 0.7063\n",
      "Epoch 10/500\n",
      "46/46 [==============================] - 0s 404us/step - loss: 0.6881 - accuracy: 0.7156\n",
      "Epoch 11/500\n",
      "46/46 [==============================] - 0s 404us/step - loss: 0.6152 - accuracy: 0.7563\n",
      "Epoch 12/500\n",
      "46/46 [==============================] - 0s 428us/step - loss: 0.6175 - accuracy: 0.7688\n",
      "Epoch 13/500\n",
      "46/46 [==============================] - 0s 416us/step - loss: 0.5727 - accuracy: 0.7688\n",
      "Epoch 14/500\n",
      "46/46 [==============================] - 0s 422us/step - loss: 0.5411 - accuracy: 0.7812\n",
      "Epoch 15/500\n",
      "46/46 [==============================] - 0s 391us/step - loss: 0.5476 - accuracy: 0.8031\n",
      "Epoch 16/500\n",
      "46/46 [==============================] - 0s 432us/step - loss: 0.4888 - accuracy: 0.8000\n",
      "Epoch 17/500\n",
      "46/46 [==============================] - 0s 417us/step - loss: 0.4781 - accuracy: 0.8125\n",
      "Epoch 18/500\n",
      "46/46 [==============================] - 0s 455us/step - loss: 0.4457 - accuracy: 0.7812\n",
      "Epoch 19/500\n",
      "46/46 [==============================] - 0s 417us/step - loss: 0.4679 - accuracy: 0.7844\n",
      "Epoch 20/500\n",
      "46/46 [==============================] - 0s 393us/step - loss: 0.4941 - accuracy: 0.7750\n",
      "Epoch 21/500\n",
      "46/46 [==============================] - 0s 406us/step - loss: 0.4553 - accuracy: 0.8344\n",
      "Epoch 22/500\n",
      "46/46 [==============================] - 0s 409us/step - loss: 0.4517 - accuracy: 0.7937\n",
      "Epoch 23/500\n",
      "46/46 [==============================] - 0s 413us/step - loss: 0.4131 - accuracy: 0.8281\n",
      "Epoch 24/500\n",
      "46/46 [==============================] - 0s 438us/step - loss: 0.4153 - accuracy: 0.8250\n",
      "Epoch 25/500\n",
      "46/46 [==============================] - 0s 409us/step - loss: 0.3965 - accuracy: 0.8375\n",
      "Epoch 26/500\n",
      "46/46 [==============================] - 0s 409us/step - loss: 0.3875 - accuracy: 0.8438\n",
      "Epoch 27/500\n",
      "46/46 [==============================] - 0s 389us/step - loss: 0.4035 - accuracy: 0.8344\n",
      "Epoch 28/500\n",
      "46/46 [==============================] - 0s 433us/step - loss: 0.3463 - accuracy: 0.8750\n",
      "Epoch 29/500\n",
      "46/46 [==============================] - 0s 401us/step - loss: 0.3662 - accuracy: 0.8531\n",
      "Epoch 30/500\n",
      "46/46 [==============================] - 0s 407us/step - loss: 0.3078 - accuracy: 0.8656\n",
      "Epoch 31/500\n",
      "46/46 [==============================] - 0s 401us/step - loss: 0.3159 - accuracy: 0.8594\n",
      "Epoch 32/500\n",
      "46/46 [==============================] - 0s 416us/step - loss: 0.3465 - accuracy: 0.8625\n",
      "Epoch 33/500\n",
      "46/46 [==============================] - 0s 406us/step - loss: 0.3520 - accuracy: 0.8781\n",
      "Epoch 34/500\n",
      "46/46 [==============================] - 0s 408us/step - loss: 0.3227 - accuracy: 0.8875\n",
      "Epoch 35/500\n",
      "46/46 [==============================] - 0s 410us/step - loss: 0.3556 - accuracy: 0.8687\n",
      "Epoch 36/500\n",
      "46/46 [==============================] - 0s 438us/step - loss: 0.2769 - accuracy: 0.8938\n",
      "Epoch 37/500\n",
      "46/46 [==============================] - 0s 403us/step - loss: 0.2958 - accuracy: 0.8813\n",
      "Epoch 38/500\n",
      "46/46 [==============================] - 0s 428us/step - loss: 0.2748 - accuracy: 0.8719\n",
      "Epoch 39/500\n",
      "46/46 [==============================] - 0s 404us/step - loss: 0.2784 - accuracy: 0.8938\n",
      "Epoch 40/500\n",
      "46/46 [==============================] - 0s 398us/step - loss: 0.2653 - accuracy: 0.8906\n",
      "Epoch 41/500\n",
      "46/46 [==============================] - 0s 412us/step - loss: 0.2888 - accuracy: 0.8969\n",
      "Epoch 42/500\n",
      "46/46 [==============================] - 0s 416us/step - loss: 0.2640 - accuracy: 0.9281\n",
      "Epoch 43/500\n",
      "46/46 [==============================] - 0s 400us/step - loss: 0.2762 - accuracy: 0.9031\n",
      "Epoch 44/500\n",
      "46/46 [==============================] - 0s 400us/step - loss: 0.2677 - accuracy: 0.8844\n",
      "Epoch 45/500\n",
      "46/46 [==============================] - 0s 438us/step - loss: 0.2559 - accuracy: 0.8938\n",
      "Epoch 46/500\n",
      "46/46 [==============================] - 0s 399us/step - loss: 0.2420 - accuracy: 0.8969\n",
      "Epoch 47/500\n",
      "46/46 [==============================] - 0s 394us/step - loss: 0.2648 - accuracy: 0.9062\n",
      "Epoch 48/500\n",
      "46/46 [==============================] - 0s 399us/step - loss: 0.2282 - accuracy: 0.9250\n",
      "Epoch 49/500\n",
      "46/46 [==============================] - 0s 401us/step - loss: 0.2179 - accuracy: 0.9250\n",
      "Epoch 50/500\n",
      "46/46 [==============================] - 0s 393us/step - loss: 0.2296 - accuracy: 0.9250\n",
      "Epoch 51/500\n",
      "46/46 [==============================] - 0s 391us/step - loss: 0.2097 - accuracy: 0.9281\n",
      "Epoch 52/500\n",
      "46/46 [==============================] - 0s 395us/step - loss: 0.2334 - accuracy: 0.9094\n",
      "Epoch 53/500\n",
      "46/46 [==============================] - 0s 399us/step - loss: 0.2413 - accuracy: 0.9125\n",
      "Epoch 54/500\n",
      "46/46 [==============================] - 0s 401us/step - loss: 0.2465 - accuracy: 0.9062\n",
      "Epoch 55/500\n",
      "46/46 [==============================] - 0s 395us/step - loss: 0.2564 - accuracy: 0.8781\n",
      "Epoch 56/500\n",
      "46/46 [==============================] - 0s 403us/step - loss: 0.1994 - accuracy: 0.9094\n",
      "Epoch 57/500\n",
      "46/46 [==============================] - 0s 397us/step - loss: 0.2228 - accuracy: 0.9187\n",
      "Epoch 58/500\n",
      "46/46 [==============================] - 0s 399us/step - loss: 0.2129 - accuracy: 0.9156\n",
      "Epoch 59/500\n",
      "46/46 [==============================] - 0s 416us/step - loss: 0.1842 - accuracy: 0.9312\n",
      "Epoch 60/500\n",
      "46/46 [==============================] - 0s 409us/step - loss: 0.1985 - accuracy: 0.9312\n",
      "Epoch 61/500\n",
      "46/46 [==============================] - 0s 428us/step - loss: 0.1841 - accuracy: 0.9312\n",
      "Epoch 62/500\n",
      "46/46 [==============================] - 0s 397us/step - loss: 0.1928 - accuracy: 0.9281\n",
      "Epoch 63/500\n",
      "46/46 [==============================] - 0s 413us/step - loss: 0.1722 - accuracy: 0.9438\n",
      "Epoch 64/500\n",
      "46/46 [==============================] - 0s 385us/step - loss: 0.1762 - accuracy: 0.9312\n",
      "Epoch 65/500\n",
      "46/46 [==============================] - 0s 410us/step - loss: 0.1768 - accuracy: 0.9250\n",
      "Epoch 66/500\n",
      "46/46 [==============================] - 0s 392us/step - loss: 0.1880 - accuracy: 0.9281\n",
      "Epoch 67/500\n",
      "46/46 [==============================] - 0s 406us/step - loss: 0.1926 - accuracy: 0.9219\n",
      "Epoch 68/500\n",
      "46/46 [==============================] - 0s 391us/step - loss: 0.1481 - accuracy: 0.9375\n",
      "Epoch 69/500\n",
      "46/46 [==============================] - 0s 414us/step - loss: 0.1684 - accuracy: 0.9438\n",
      "Epoch 70/500\n",
      "46/46 [==============================] - 0s 411us/step - loss: 0.1659 - accuracy: 0.9375\n",
      "Epoch 71/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 400us/step - loss: 0.1588 - accuracy: 0.9219\n",
      "Epoch 72/500\n",
      "46/46 [==============================] - 0s 406us/step - loss: 0.1897 - accuracy: 0.9187\n",
      "Epoch 73/500\n",
      "46/46 [==============================] - 0s 398us/step - loss: 0.1634 - accuracy: 0.9406\n",
      "Epoch 74/500\n",
      "46/46 [==============================] - 0s 382us/step - loss: 0.1654 - accuracy: 0.9406\n",
      "Epoch 75/500\n",
      "46/46 [==============================] - 0s 413us/step - loss: 0.1368 - accuracy: 0.9469\n",
      "Epoch 76/500\n",
      "46/46 [==============================] - 0s 405us/step - loss: 0.1329 - accuracy: 0.9406\n",
      "Epoch 77/500\n",
      "46/46 [==============================] - 0s 387us/step - loss: 0.1408 - accuracy: 0.9500\n",
      "Epoch 78/500\n",
      "46/46 [==============================] - 0s 403us/step - loss: 0.1595 - accuracy: 0.9469\n",
      "Epoch 79/500\n",
      "46/46 [==============================] - 0s 400us/step - loss: 0.1825 - accuracy: 0.9281\n",
      "Epoch 80/500\n",
      "46/46 [==============================] - 0s 412us/step - loss: 0.1235 - accuracy: 0.9563\n",
      "Epoch 81/500\n",
      "46/46 [==============================] - 0s 406us/step - loss: 0.1469 - accuracy: 0.9625\n",
      "Epoch 82/500\n",
      "46/46 [==============================] - 0s 398us/step - loss: 0.1541 - accuracy: 0.9469\n",
      "Epoch 83/500\n",
      "46/46 [==============================] - 0s 385us/step - loss: 0.1434 - accuracy: 0.9375\n",
      "Epoch 84/500\n",
      "46/46 [==============================] - 0s 401us/step - loss: 0.1266 - accuracy: 0.9563\n",
      "Epoch 85/500\n",
      "46/46 [==============================] - 0s 404us/step - loss: 0.1554 - accuracy: 0.9312\n",
      "Epoch 86/500\n",
      "46/46 [==============================] - 0s 396us/step - loss: 0.1254 - accuracy: 0.9563\n",
      "Epoch 87/500\n",
      "46/46 [==============================] - 0s 429us/step - loss: 0.1270 - accuracy: 0.9406\n",
      "Epoch 88/500\n",
      "46/46 [==============================] - 0s 419us/step - loss: 0.1292 - accuracy: 0.9469\n",
      "Epoch 89/500\n",
      "46/46 [==============================] - 0s 396us/step - loss: 0.1263 - accuracy: 0.9469\n",
      "Epoch 90/500\n",
      "46/46 [==============================] - 0s 407us/step - loss: 0.1248 - accuracy: 0.9531\n",
      "Epoch 91/500\n",
      "46/46 [==============================] - 0s 403us/step - loss: 0.1279 - accuracy: 0.9563\n",
      "Epoch 92/500\n",
      "46/46 [==============================] - 0s 406us/step - loss: 0.1620 - accuracy: 0.9469\n",
      "Epoch 93/500\n",
      "46/46 [==============================] - 0s 404us/step - loss: 0.1409 - accuracy: 0.9469\n",
      "Epoch 94/500\n",
      "46/46 [==============================] - 0s 397us/step - loss: 0.1372 - accuracy: 0.9531\n",
      "Epoch 95/500\n",
      "46/46 [==============================] - 0s 402us/step - loss: 0.1244 - accuracy: 0.9563\n",
      "Epoch 96/500\n",
      "46/46 [==============================] - 0s 397us/step - loss: 0.1107 - accuracy: 0.9563\n",
      "Epoch 97/500\n",
      "46/46 [==============================] - 0s 410us/step - loss: 0.1413 - accuracy: 0.9406\n",
      "Epoch 98/500\n",
      "46/46 [==============================] - 0s 404us/step - loss: 0.1074 - accuracy: 0.9594\n",
      "Epoch 99/500\n",
      "46/46 [==============================] - 0s 407us/step - loss: 0.1051 - accuracy: 0.9563\n",
      "Epoch 100/500\n",
      "46/46 [==============================] - 0s 402us/step - loss: 0.1412 - accuracy: 0.9469\n",
      "Epoch 101/500\n",
      "46/46 [==============================] - 0s 408us/step - loss: 0.1532 - accuracy: 0.9469\n",
      "Epoch 102/500\n",
      "46/46 [==============================] - 0s 412us/step - loss: 0.1299 - accuracy: 0.9563\n",
      "Epoch 103/500\n",
      "46/46 [==============================] - 0s 402us/step - loss: 0.1249 - accuracy: 0.9625\n",
      "Epoch 104/500\n",
      "46/46 [==============================] - 0s 404us/step - loss: 0.1113 - accuracy: 0.9563\n",
      "Epoch 105/500\n",
      "46/46 [==============================] - 0s 396us/step - loss: 0.1035 - accuracy: 0.9719\n",
      "Epoch 106/500\n",
      "46/46 [==============================] - 0s 404us/step - loss: 0.0927 - accuracy: 0.9750\n",
      "Epoch 107/500\n",
      "46/46 [==============================] - 0s 407us/step - loss: 0.1146 - accuracy: 0.9625\n",
      "Epoch 108/500\n",
      "46/46 [==============================] - 0s 391us/step - loss: 0.0987 - accuracy: 0.9688\n",
      "Epoch 109/500\n",
      "46/46 [==============================] - 0s 405us/step - loss: 0.1334 - accuracy: 0.9469\n",
      "Epoch 110/500\n",
      "46/46 [==============================] - 0s 413us/step - loss: 0.0874 - accuracy: 0.9656\n",
      "Epoch 111/500\n",
      "46/46 [==============================] - 0s 406us/step - loss: 0.0973 - accuracy: 0.9656\n",
      "Epoch 112/500\n",
      "46/46 [==============================] - 0s 402us/step - loss: 0.0835 - accuracy: 0.9656\n",
      "Epoch 113/500\n",
      "46/46 [==============================] - 0s 405us/step - loss: 0.1115 - accuracy: 0.9531\n",
      "Epoch 114/500\n",
      "46/46 [==============================] - 0s 412us/step - loss: 0.1107 - accuracy: 0.9563\n",
      "Epoch 115/500\n",
      "46/46 [==============================] - 0s 407us/step - loss: 0.1183 - accuracy: 0.9563\n",
      "Epoch 116/500\n",
      "46/46 [==============================] - 0s 387us/step - loss: 0.1003 - accuracy: 0.9500\n",
      "Epoch 117/500\n",
      "46/46 [==============================] - 0s 397us/step - loss: 0.1055 - accuracy: 0.9656\n",
      "Epoch 118/500\n",
      "46/46 [==============================] - 0s 387us/step - loss: 0.0903 - accuracy: 0.9719\n",
      "Epoch 119/500\n",
      "46/46 [==============================] - 0s 394us/step - loss: 0.0726 - accuracy: 0.9812\n",
      "Epoch 120/500\n",
      "46/46 [==============================] - 0s 459us/step - loss: 0.0692 - accuracy: 0.9750\n",
      "Epoch 121/500\n",
      "46/46 [==============================] - 0s 396us/step - loss: 0.0689 - accuracy: 0.9781\n",
      "Epoch 122/500\n",
      "46/46 [==============================] - 0s 395us/step - loss: 0.0874 - accuracy: 0.9719\n",
      "Epoch 123/500\n",
      "46/46 [==============================] - 0s 405us/step - loss: 0.1523 - accuracy: 0.9344\n",
      "Epoch 124/500\n",
      "46/46 [==============================] - 0s 407us/step - loss: 0.0975 - accuracy: 0.9656\n",
      "Epoch 125/500\n",
      "46/46 [==============================] - 0s 390us/step - loss: 0.1227 - accuracy: 0.9344\n",
      "Epoch 126/500\n",
      "46/46 [==============================] - 0s 404us/step - loss: 0.1061 - accuracy: 0.9688\n",
      "Epoch 127/500\n",
      "46/46 [==============================] - 0s 404us/step - loss: 0.0961 - accuracy: 0.9625\n",
      "Epoch 128/500\n",
      "46/46 [==============================] - 0s 398us/step - loss: 0.1035 - accuracy: 0.9719\n",
      "Epoch 129/500\n",
      "46/46 [==============================] - 0s 418us/step - loss: 0.0972 - accuracy: 0.9688\n",
      "Epoch 130/500\n",
      "46/46 [==============================] - 0s 388us/step - loss: 0.0778 - accuracy: 0.9750\n",
      "Epoch 131/500\n",
      "46/46 [==============================] - 0s 402us/step - loss: 0.1153 - accuracy: 0.9500\n",
      "Epoch 132/500\n",
      "46/46 [==============================] - 0s 403us/step - loss: 0.0840 - accuracy: 0.9812\n",
      "Epoch 133/500\n",
      "46/46 [==============================] - 0s 389us/step - loss: 0.1177 - accuracy: 0.9625\n",
      "Epoch 134/500\n",
      "46/46 [==============================] - 0s 406us/step - loss: 0.0943 - accuracy: 0.9563\n",
      "Epoch 135/500\n",
      "46/46 [==============================] - 0s 389us/step - loss: 0.1079 - accuracy: 0.9594\n",
      "Epoch 136/500\n",
      "46/46 [==============================] - 0s 412us/step - loss: 0.0808 - accuracy: 0.9656\n",
      "Epoch 137/500\n",
      "46/46 [==============================] - 0s 403us/step - loss: 0.1197 - accuracy: 0.9531\n",
      "Epoch 138/500\n",
      "46/46 [==============================] - 0s 408us/step - loss: 0.0791 - accuracy: 0.9656\n",
      "Epoch 139/500\n",
      "46/46 [==============================] - 0s 434us/step - loss: 0.1158 - accuracy: 0.9563\n",
      "Epoch 140/500\n",
      "46/46 [==============================] - 0s 396us/step - loss: 0.0738 - accuracy: 0.9812\n",
      "Epoch 141/500\n",
      "46/46 [==============================] - 0s 387us/step - loss: 0.0642 - accuracy: 0.9781\n",
      "Epoch 142/500\n",
      "46/46 [==============================] - 0s 402us/step - loss: 0.0807 - accuracy: 0.9656\n",
      "Epoch 143/500\n",
      "46/46 [==============================] - 0s 401us/step - loss: 0.0909 - accuracy: 0.9625\n",
      "Epoch 144/500\n",
      "46/46 [==============================] - 0s 404us/step - loss: 0.0757 - accuracy: 0.9719\n",
      "Epoch 145/500\n",
      "46/46 [==============================] - 0s 405us/step - loss: 0.0696 - accuracy: 0.9719\n",
      "Epoch 146/500\n",
      "46/46 [==============================] - 0s 415us/step - loss: 0.0984 - accuracy: 0.9688\n",
      "Epoch 147/500\n",
      "46/46 [==============================] - 0s 400us/step - loss: 0.0866 - accuracy: 0.9594\n",
      "Epoch 148/500\n",
      "46/46 [==============================] - 0s 391us/step - loss: 0.0696 - accuracy: 0.9750\n",
      "Epoch 149/500\n",
      "46/46 [==============================] - 0s 402us/step - loss: 0.1227 - accuracy: 0.9594\n",
      "Epoch 150/500\n",
      "46/46 [==============================] - 0s 407us/step - loss: 0.0757 - accuracy: 0.9812\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 151/500\n",
      "46/46 [==============================] - 0s 404us/step - loss: 0.0843 - accuracy: 0.9688\n",
      "Epoch 152/500\n",
      "46/46 [==============================] - 0s 408us/step - loss: 0.0828 - accuracy: 0.9656\n",
      "Epoch 153/500\n",
      "46/46 [==============================] - 0s 391us/step - loss: 0.0899 - accuracy: 0.9688\n",
      "Epoch 154/500\n",
      "46/46 [==============================] - 0s 404us/step - loss: 0.1199 - accuracy: 0.9500\n",
      "Epoch 155/500\n",
      "46/46 [==============================] - 0s 406us/step - loss: 0.0802 - accuracy: 0.9750\n",
      "Epoch 156/500\n",
      "46/46 [==============================] - 0s 397us/step - loss: 0.0697 - accuracy: 0.9656\n",
      "Epoch 157/500\n",
      "46/46 [==============================] - 0s 412us/step - loss: 0.0587 - accuracy: 0.9812\n",
      "Epoch 158/500\n",
      "46/46 [==============================] - 0s 386us/step - loss: 0.0733 - accuracy: 0.9812\n",
      "Epoch 159/500\n",
      "46/46 [==============================] - 0s 403us/step - loss: 0.1061 - accuracy: 0.9688\n",
      "Epoch 160/500\n",
      "46/46 [==============================] - 0s 409us/step - loss: 0.0821 - accuracy: 0.9688\n",
      "Epoch 161/500\n",
      "46/46 [==============================] - 0s 399us/step - loss: 0.1159 - accuracy: 0.9625\n",
      "Epoch 162/500\n",
      "46/46 [==============================] - 0s 411us/step - loss: 0.0735 - accuracy: 0.9750\n",
      "Epoch 163/500\n",
      "46/46 [==============================] - 0s 411us/step - loss: 0.0601 - accuracy: 0.9812\n",
      "Epoch 164/500\n",
      "46/46 [==============================] - 0s 404us/step - loss: 0.0436 - accuracy: 0.9875\n",
      "Epoch 165/500\n",
      "46/46 [==============================] - 0s 399us/step - loss: 0.0762 - accuracy: 0.9625\n",
      "Epoch 166/500\n",
      "46/46 [==============================] - 0s 395us/step - loss: 0.0621 - accuracy: 0.9750\n",
      "Epoch 167/500\n",
      "46/46 [==============================] - 0s 401us/step - loss: 0.0737 - accuracy: 0.9656\n",
      "Epoch 168/500\n",
      "46/46 [==============================] - 0s 407us/step - loss: 0.0699 - accuracy: 0.9750\n",
      "Epoch 169/500\n",
      "46/46 [==============================] - 0s 391us/step - loss: 0.0618 - accuracy: 0.9781\n",
      "Epoch 170/500\n",
      "46/46 [==============================] - 0s 394us/step - loss: 0.0626 - accuracy: 0.9719\n",
      "Epoch 171/500\n",
      "46/46 [==============================] - 0s 408us/step - loss: 0.1030 - accuracy: 0.9625\n",
      "Epoch 172/500\n",
      "46/46 [==============================] - 0s 420us/step - loss: 0.0606 - accuracy: 0.9812\n",
      "Epoch 173/500\n",
      "46/46 [==============================] - 0s 390us/step - loss: 0.0628 - accuracy: 0.9750\n",
      "Epoch 174/500\n",
      "46/46 [==============================] - 0s 402us/step - loss: 0.0454 - accuracy: 0.9875\n",
      "Epoch 175/500\n",
      "46/46 [==============================] - 0s 399us/step - loss: 0.0556 - accuracy: 0.9812\n",
      "Epoch 176/500\n",
      "46/46 [==============================] - 0s 394us/step - loss: 0.0651 - accuracy: 0.9781\n",
      "Epoch 177/500\n",
      "46/46 [==============================] - 0s 426us/step - loss: 0.0843 - accuracy: 0.9625\n",
      "Epoch 178/500\n",
      "46/46 [==============================] - 0s 399us/step - loss: 0.0963 - accuracy: 0.9594\n",
      "Epoch 179/500\n",
      "46/46 [==============================] - 0s 403us/step - loss: 0.0606 - accuracy: 0.9781\n",
      "Epoch 180/500\n",
      "46/46 [==============================] - 0s 392us/step - loss: 0.0616 - accuracy: 0.9875\n",
      "Epoch 181/500\n",
      "46/46 [==============================] - 0s 412us/step - loss: 0.0648 - accuracy: 0.9781\n",
      "Epoch 182/500\n",
      "46/46 [==============================] - 0s 397us/step - loss: 0.0499 - accuracy: 0.9844\n",
      "Epoch 183/500\n",
      "46/46 [==============================] - 0s 398us/step - loss: 0.0481 - accuracy: 0.9875\n",
      "Epoch 184/500\n",
      "46/46 [==============================] - 0s 391us/step - loss: 0.0412 - accuracy: 0.9875\n",
      "Epoch 185/500\n",
      "46/46 [==============================] - 0s 406us/step - loss: 0.0670 - accuracy: 0.9750\n",
      "Epoch 186/500\n",
      "46/46 [==============================] - 0s 408us/step - loss: 0.0754 - accuracy: 0.9688\n",
      "Epoch 187/500\n",
      "46/46 [==============================] - 0s 393us/step - loss: 0.0683 - accuracy: 0.9688\n",
      "Epoch 188/500\n",
      "46/46 [==============================] - 0s 394us/step - loss: 0.0813 - accuracy: 0.9625\n",
      "Epoch 189/500\n",
      "46/46 [==============================] - 0s 436us/step - loss: 0.0611 - accuracy: 0.9656\n",
      "Epoch 190/500\n",
      "46/46 [==============================] - 0s 397us/step - loss: 0.0828 - accuracy: 0.9594\n",
      "Epoch 191/500\n",
      "46/46 [==============================] - 0s 415us/step - loss: 0.0685 - accuracy: 0.9750\n",
      "Epoch 192/500\n",
      "46/46 [==============================] - 0s 393us/step - loss: 0.0684 - accuracy: 0.9781\n",
      "Epoch 193/500\n",
      "46/46 [==============================] - 0s 405us/step - loss: 0.0664 - accuracy: 0.9688\n",
      "Epoch 194/500\n",
      "46/46 [==============================] - 0s 406us/step - loss: 0.0673 - accuracy: 0.9750\n",
      "Epoch 195/500\n",
      "46/46 [==============================] - 0s 393us/step - loss: 0.0839 - accuracy: 0.9688\n",
      "Epoch 196/500\n",
      "46/46 [==============================] - 0s 419us/step - loss: 0.0902 - accuracy: 0.9688\n",
      "Epoch 197/500\n",
      "46/46 [==============================] - 0s 398us/step - loss: 0.0627 - accuracy: 0.9750\n",
      "Epoch 198/500\n",
      "46/46 [==============================] - 0s 401us/step - loss: 0.0465 - accuracy: 0.9875\n",
      "Epoch 199/500\n",
      "46/46 [==============================] - 0s 417us/step - loss: 0.0595 - accuracy: 0.9750\n",
      "Epoch 200/500\n",
      "46/46 [==============================] - 0s 411us/step - loss: 0.0380 - accuracy: 0.9844\n",
      "Epoch 201/500\n",
      "46/46 [==============================] - 0s 403us/step - loss: 0.0293 - accuracy: 0.9937\n",
      "Epoch 202/500\n",
      "46/46 [==============================] - 0s 400us/step - loss: 0.0361 - accuracy: 0.9969\n",
      "Epoch 203/500\n",
      "46/46 [==============================] - 0s 400us/step - loss: 0.0782 - accuracy: 0.9625\n",
      "Epoch 204/500\n",
      "46/46 [==============================] - 0s 404us/step - loss: 0.0654 - accuracy: 0.9875\n",
      "Epoch 205/500\n",
      "46/46 [==============================] - 0s 388us/step - loss: 0.0675 - accuracy: 0.9719\n",
      "Epoch 206/500\n",
      "46/46 [==============================] - 0s 403us/step - loss: 0.0550 - accuracy: 0.9750\n",
      "Epoch 207/500\n",
      "46/46 [==============================] - 0s 398us/step - loss: 0.0358 - accuracy: 0.9844\n",
      "Epoch 208/500\n",
      "46/46 [==============================] - 0s 412us/step - loss: 0.0630 - accuracy: 0.9812\n",
      "Epoch 209/500\n",
      "46/46 [==============================] - 0s 422us/step - loss: 0.0479 - accuracy: 0.9781\n",
      "Epoch 210/500\n",
      "46/46 [==============================] - 0s 404us/step - loss: 0.0438 - accuracy: 0.9906\n",
      "Epoch 211/500\n",
      "46/46 [==============================] - 0s 422us/step - loss: 0.0300 - accuracy: 0.9906\n",
      "Epoch 212/500\n",
      "46/46 [==============================] - 0s 399us/step - loss: 0.0606 - accuracy: 0.9688\n",
      "Epoch 213/500\n",
      "46/46 [==============================] - 0s 427us/step - loss: 0.0886 - accuracy: 0.9719\n",
      "Epoch 214/500\n",
      "46/46 [==============================] - 0s 398us/step - loss: 0.0861 - accuracy: 0.9688\n",
      "Epoch 215/500\n",
      "46/46 [==============================] - 0s 413us/step - loss: 0.0813 - accuracy: 0.9719\n",
      "Epoch 216/500\n",
      "46/46 [==============================] - 0s 402us/step - loss: 0.0405 - accuracy: 0.9844\n",
      "Epoch 217/500\n",
      "46/46 [==============================] - 0s 407us/step - loss: 0.0664 - accuracy: 0.9781\n",
      "Epoch 218/500\n",
      "46/46 [==============================] - 0s 440us/step - loss: 0.1351 - accuracy: 0.9563\n",
      "Epoch 219/500\n",
      "46/46 [==============================] - 0s 400us/step - loss: 0.1275 - accuracy: 0.9500\n",
      "Epoch 220/500\n",
      "46/46 [==============================] - 0s 415us/step - loss: 0.0605 - accuracy: 0.9781\n",
      "Epoch 221/500\n",
      "46/46 [==============================] - 0s 411us/step - loss: 0.0474 - accuracy: 0.9875\n",
      "Epoch 222/500\n",
      "46/46 [==============================] - 0s 405us/step - loss: 0.0647 - accuracy: 0.9750\n",
      "Epoch 223/500\n",
      "46/46 [==============================] - 0s 417us/step - loss: 0.0849 - accuracy: 0.9719\n",
      "Epoch 224/500\n",
      "46/46 [==============================] - 0s 405us/step - loss: 0.0693 - accuracy: 0.9750\n",
      "Epoch 225/500\n",
      "46/46 [==============================] - 0s 410us/step - loss: 0.0728 - accuracy: 0.9750\n",
      "Epoch 226/500\n",
      "46/46 [==============================] - 0s 412us/step - loss: 0.0595 - accuracy: 0.9750\n",
      "Epoch 227/500\n",
      "46/46 [==============================] - 0s 408us/step - loss: 0.0618 - accuracy: 0.9781\n",
      "Epoch 228/500\n",
      "46/46 [==============================] - 0s 413us/step - loss: 0.0526 - accuracy: 0.9812\n",
      "Epoch 229/500\n",
      "46/46 [==============================] - 0s 410us/step - loss: 0.0493 - accuracy: 0.9875\n",
      "Epoch 230/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 433us/step - loss: 0.0374 - accuracy: 0.9844\n",
      "Epoch 231/500\n",
      "46/46 [==============================] - 0s 416us/step - loss: 0.0899 - accuracy: 0.9688\n",
      "Epoch 232/500\n",
      "46/46 [==============================] - 0s 408us/step - loss: 0.0535 - accuracy: 0.9844\n",
      "Epoch 233/500\n",
      "46/46 [==============================] - 0s 401us/step - loss: 0.0576 - accuracy: 0.9812\n",
      "Epoch 234/500\n",
      "46/46 [==============================] - 0s 396us/step - loss: 0.0523 - accuracy: 0.9875\n",
      "Epoch 235/500\n",
      "46/46 [==============================] - 0s 408us/step - loss: 0.0571 - accuracy: 0.9781\n",
      "Epoch 236/500\n",
      "46/46 [==============================] - 0s 398us/step - loss: 0.0368 - accuracy: 0.9875\n",
      "Epoch 237/500\n",
      "46/46 [==============================] - 0s 403us/step - loss: 0.0554 - accuracy: 0.9781\n",
      "Epoch 238/500\n",
      "46/46 [==============================] - 0s 408us/step - loss: 0.0807 - accuracy: 0.9688\n",
      "Epoch 239/500\n",
      "46/46 [==============================] - 0s 449us/step - loss: 0.0508 - accuracy: 0.9844\n",
      "Epoch 240/500\n",
      "46/46 [==============================] - 0s 405us/step - loss: 0.0671 - accuracy: 0.9812\n",
      "Epoch 241/500\n",
      "46/46 [==============================] - 0s 396us/step - loss: 0.0454 - accuracy: 0.9812\n",
      "Epoch 242/500\n",
      "46/46 [==============================] - 0s 403us/step - loss: 0.0529 - accuracy: 0.9844\n",
      "Epoch 243/500\n",
      "46/46 [==============================] - 0s 407us/step - loss: 0.0282 - accuracy: 0.9906\n",
      "Epoch 244/500\n",
      "46/46 [==============================] - 0s 414us/step - loss: 0.0480 - accuracy: 0.9844\n",
      "Epoch 245/500\n",
      "46/46 [==============================] - 0s 408us/step - loss: 0.0779 - accuracy: 0.9781\n",
      "Epoch 246/500\n",
      "46/46 [==============================] - 0s 406us/step - loss: 0.0879 - accuracy: 0.9781\n",
      "Epoch 247/500\n",
      "46/46 [==============================] - 0s 407us/step - loss: 0.0537 - accuracy: 0.9812\n",
      "Epoch 248/500\n",
      "46/46 [==============================] - 0s 378us/step - loss: 0.0807 - accuracy: 0.9656\n",
      "Epoch 249/500\n",
      "46/46 [==============================] - 0s 393us/step - loss: 0.0544 - accuracy: 0.9812\n",
      "Epoch 250/500\n",
      "46/46 [==============================] - 0s 419us/step - loss: 0.0536 - accuracy: 0.9812\n",
      "Epoch 251/500\n",
      "46/46 [==============================] - 0s 395us/step - loss: 0.0822 - accuracy: 0.9719\n",
      "Epoch 252/500\n",
      "46/46 [==============================] - 0s 412us/step - loss: 0.0559 - accuracy: 0.9844\n",
      "Epoch 253/500\n",
      "46/46 [==============================] - 0s 392us/step - loss: 0.0580 - accuracy: 0.9750\n",
      "Epoch 254/500\n",
      "46/46 [==============================] - 0s 398us/step - loss: 0.0643 - accuracy: 0.9781\n",
      "Epoch 255/500\n",
      "46/46 [==============================] - 0s 403us/step - loss: 0.0603 - accuracy: 0.9750\n",
      "Epoch 256/500\n",
      "46/46 [==============================] - 0s 407us/step - loss: 0.0855 - accuracy: 0.9719\n",
      "Epoch 257/500\n",
      "46/46 [==============================] - 0s 411us/step - loss: 0.0604 - accuracy: 0.9719\n",
      "Epoch 258/500\n",
      "46/46 [==============================] - 0s 400us/step - loss: 0.1549 - accuracy: 0.9406\n",
      "Epoch 259/500\n",
      "46/46 [==============================] - 0s 409us/step - loss: 0.0570 - accuracy: 0.9875\n",
      "Epoch 260/500\n",
      "46/46 [==============================] - 0s 414us/step - loss: 0.0500 - accuracy: 0.9812\n",
      "Epoch 261/500\n",
      "46/46 [==============================] - 0s 582us/step - loss: 0.0400 - accuracy: 0.9875\n",
      "Epoch 262/500\n",
      "46/46 [==============================] - 0s 413us/step - loss: 0.0684 - accuracy: 0.9656\n",
      "Epoch 263/500\n",
      "46/46 [==============================] - 0s 577us/step - loss: 0.0594 - accuracy: 0.9844\n",
      "Epoch 264/500\n",
      "46/46 [==============================] - 0s 432us/step - loss: 0.0389 - accuracy: 0.9906\n",
      "Epoch 265/500\n",
      "46/46 [==============================] - 0s 396us/step - loss: 0.0430 - accuracy: 0.9875\n",
      "Epoch 266/500\n",
      "46/46 [==============================] - 0s 410us/step - loss: 0.0554 - accuracy: 0.9844\n",
      "Epoch 267/500\n",
      "46/46 [==============================] - 0s 390us/step - loss: 0.0397 - accuracy: 0.9844\n",
      "Epoch 268/500\n",
      "46/46 [==============================] - 0s 397us/step - loss: 0.0376 - accuracy: 0.9875\n",
      "Epoch 269/500\n",
      "46/46 [==============================] - 0s 402us/step - loss: 0.0471 - accuracy: 0.9875\n",
      "Epoch 270/500\n",
      "46/46 [==============================] - 0s 393us/step - loss: 0.0676 - accuracy: 0.9750\n",
      "Epoch 271/500\n",
      "46/46 [==============================] - 0s 402us/step - loss: 0.0493 - accuracy: 0.9781\n",
      "Epoch 272/500\n",
      "46/46 [==============================] - 0s 392us/step - loss: 0.0367 - accuracy: 0.9906\n",
      "Epoch 273/500\n",
      "46/46 [==============================] - 0s 400us/step - loss: 0.0515 - accuracy: 0.9781\n",
      "Epoch 274/500\n",
      "46/46 [==============================] - 0s 408us/step - loss: 0.0471 - accuracy: 0.9844\n",
      "Epoch 275/500\n",
      "46/46 [==============================] - 0s 392us/step - loss: 0.0321 - accuracy: 0.9875\n",
      "Epoch 276/500\n",
      "46/46 [==============================] - 0s 404us/step - loss: 0.0339 - accuracy: 0.9875\n",
      "Epoch 277/500\n",
      "46/46 [==============================] - 0s 401us/step - loss: 0.0590 - accuracy: 0.9844\n",
      "Epoch 278/500\n",
      "46/46 [==============================] - 0s 393us/step - loss: 0.0444 - accuracy: 0.9750\n",
      "Epoch 279/500\n",
      "46/46 [==============================] - 0s 388us/step - loss: 0.0742 - accuracy: 0.9719\n",
      "Epoch 280/500\n",
      "46/46 [==============================] - 0s 400us/step - loss: 0.0471 - accuracy: 0.9750\n",
      "Epoch 281/500\n",
      "46/46 [==============================] - 0s 414us/step - loss: 0.0527 - accuracy: 0.9750\n",
      "Epoch 282/500\n",
      "46/46 [==============================] - 0s 404us/step - loss: 0.0280 - accuracy: 0.9969\n",
      "Epoch 283/500\n",
      "46/46 [==============================] - 0s 413us/step - loss: 0.0524 - accuracy: 0.9750\n",
      "Epoch 284/500\n",
      "46/46 [==============================] - 0s 405us/step - loss: 0.0272 - accuracy: 0.9937\n",
      "Epoch 285/500\n",
      "46/46 [==============================] - 0s 389us/step - loss: 0.0504 - accuracy: 0.9781\n",
      "Epoch 286/500\n",
      "46/46 [==============================] - 0s 398us/step - loss: 0.0433 - accuracy: 0.9812\n",
      "Epoch 287/500\n",
      "46/46 [==============================] - 0s 401us/step - loss: 0.0878 - accuracy: 0.9656\n",
      "Epoch 288/500\n",
      "46/46 [==============================] - 0s 440us/step - loss: 0.0965 - accuracy: 0.9656\n",
      "Epoch 289/500\n",
      "46/46 [==============================] - 0s 406us/step - loss: 0.0663 - accuracy: 0.9781\n",
      "Epoch 290/500\n",
      "46/46 [==============================] - 0s 410us/step - loss: 0.0312 - accuracy: 0.9875\n",
      "Epoch 291/500\n",
      "46/46 [==============================] - 0s 407us/step - loss: 0.0188 - accuracy: 0.9969\n",
      "Epoch 292/500\n",
      "46/46 [==============================] - 0s 401us/step - loss: 0.0471 - accuracy: 0.9844\n",
      "Epoch 293/500\n",
      "46/46 [==============================] - 0s 404us/step - loss: 0.0488 - accuracy: 0.9875\n",
      "Epoch 294/500\n",
      "46/46 [==============================] - 0s 413us/step - loss: 0.0207 - accuracy: 0.9937\n",
      "Epoch 295/500\n",
      "46/46 [==============================] - 0s 402us/step - loss: 0.0483 - accuracy: 0.9844\n",
      "Epoch 296/500\n",
      "46/46 [==============================] - 0s 403us/step - loss: 0.0208 - accuracy: 0.9937\n",
      "Epoch 297/500\n",
      "46/46 [==============================] - 0s 394us/step - loss: 0.0315 - accuracy: 0.9875\n",
      "Epoch 298/500\n",
      "46/46 [==============================] - 0s 403us/step - loss: 0.0227 - accuracy: 0.9906\n",
      "Epoch 299/500\n",
      "46/46 [==============================] - 0s 420us/step - loss: 0.0565 - accuracy: 0.9781\n",
      "Epoch 300/500\n",
      "46/46 [==============================] - 0s 410us/step - loss: 0.0777 - accuracy: 0.9688\n",
      "Epoch 301/500\n",
      "46/46 [==============================] - 0s 407us/step - loss: 0.0583 - accuracy: 0.9750\n",
      "Epoch 302/500\n",
      "46/46 [==============================] - 0s 406us/step - loss: 0.0396 - accuracy: 0.9812\n",
      "Epoch 303/500\n",
      "46/46 [==============================] - 0s 416us/step - loss: 0.0675 - accuracy: 0.9781\n",
      "Epoch 304/500\n",
      "46/46 [==============================] - 0s 406us/step - loss: 0.0632 - accuracy: 0.9906\n",
      "Epoch 305/500\n",
      "46/46 [==============================] - 0s 409us/step - loss: 0.0337 - accuracy: 0.9844\n",
      "Epoch 306/500\n",
      "46/46 [==============================] - 0s 395us/step - loss: 0.0157 - accuracy: 1.0000\n",
      "Epoch 307/500\n",
      "46/46 [==============================] - 0s 392us/step - loss: 0.0293 - accuracy: 0.9906\n",
      "Epoch 308/500\n",
      "46/46 [==============================] - 0s 405us/step - loss: 0.0697 - accuracy: 0.9688\n",
      "Epoch 309/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 407us/step - loss: 0.0337 - accuracy: 0.9844\n",
      "Epoch 310/500\n",
      "46/46 [==============================] - 0s 427us/step - loss: 0.0565 - accuracy: 0.9719\n",
      "Epoch 311/500\n",
      "46/46 [==============================] - 0s 420us/step - loss: 0.0583 - accuracy: 0.9781\n",
      "Epoch 312/500\n",
      "46/46 [==============================] - 0s 418us/step - loss: 0.0418 - accuracy: 0.9844\n",
      "Epoch 313/500\n",
      "46/46 [==============================] - 0s 412us/step - loss: 0.0612 - accuracy: 0.9812\n",
      "Epoch 314/500\n",
      "46/46 [==============================] - 0s 393us/step - loss: 0.0196 - accuracy: 0.9937\n",
      "Epoch 315/500\n",
      "46/46 [==============================] - 0s 396us/step - loss: 0.0733 - accuracy: 0.9719\n",
      "Epoch 316/500\n",
      "46/46 [==============================] - 0s 402us/step - loss: 0.0850 - accuracy: 0.9625\n",
      "Epoch 317/500\n",
      "46/46 [==============================] - 0s 407us/step - loss: 0.0261 - accuracy: 1.0000\n",
      "Epoch 318/500\n",
      "46/46 [==============================] - 0s 405us/step - loss: 0.0919 - accuracy: 0.9500\n",
      "Epoch 319/500\n",
      "46/46 [==============================] - 0s 395us/step - loss: 0.1101 - accuracy: 0.9625\n",
      "Epoch 320/500\n",
      "46/46 [==============================] - 0s 411us/step - loss: 0.1863 - accuracy: 0.9406\n",
      "Epoch 321/500\n",
      "46/46 [==============================] - 0s 407us/step - loss: 0.0716 - accuracy: 0.9844\n",
      "Epoch 322/500\n",
      "46/46 [==============================] - 0s 406us/step - loss: 0.0324 - accuracy: 0.9844\n",
      "Epoch 323/500\n",
      "46/46 [==============================] - 0s 392us/step - loss: 0.0229 - accuracy: 0.9969\n",
      "Epoch 324/500\n",
      "46/46 [==============================] - 0s 393us/step - loss: 0.0135 - accuracy: 1.0000\n",
      "Epoch 325/500\n",
      "46/46 [==============================] - 0s 402us/step - loss: 0.0483 - accuracy: 0.9781\n",
      "Epoch 326/500\n",
      "46/46 [==============================] - 0s 395us/step - loss: 0.0276 - accuracy: 0.9937\n",
      "Epoch 327/500\n",
      "46/46 [==============================] - 0s 396us/step - loss: 0.0546 - accuracy: 0.9750\n",
      "Epoch 328/500\n",
      "46/46 [==============================] - 0s 395us/step - loss: 0.0734 - accuracy: 0.9750\n",
      "Epoch 329/500\n",
      "46/46 [==============================] - 0s 438us/step - loss: 0.0526 - accuracy: 0.9812\n",
      "Epoch 330/500\n",
      "46/46 [==============================] - 0s 419us/step - loss: 0.0688 - accuracy: 0.9781\n",
      "Epoch 331/500\n",
      "46/46 [==============================] - 0s 396us/step - loss: 0.0211 - accuracy: 0.9969\n",
      "Epoch 332/500\n",
      "46/46 [==============================] - 0s 408us/step - loss: 0.0262 - accuracy: 0.9906\n",
      "Epoch 333/500\n",
      "46/46 [==============================] - 0s 413us/step - loss: 0.0335 - accuracy: 0.9969\n",
      "Epoch 334/500\n",
      "46/46 [==============================] - 0s 398us/step - loss: 0.0281 - accuracy: 0.9937\n",
      "Epoch 335/500\n",
      "46/46 [==============================] - 0s 400us/step - loss: 0.0225 - accuracy: 0.9937\n",
      "Epoch 336/500\n",
      "46/46 [==============================] - 0s 401us/step - loss: 0.0342 - accuracy: 0.9812\n",
      "Epoch 337/500\n",
      "46/46 [==============================] - 0s 400us/step - loss: 0.0829 - accuracy: 0.9719\n",
      "Epoch 338/500\n",
      "46/46 [==============================] - 0s 410us/step - loss: 0.0204 - accuracy: 0.9906\n",
      "Epoch 339/500\n",
      "46/46 [==============================] - 0s 422us/step - loss: 0.0470 - accuracy: 0.9750\n",
      "Epoch 340/500\n",
      "46/46 [==============================] - 0s 412us/step - loss: 0.0154 - accuracy: 0.9969\n",
      "Epoch 341/500\n",
      "46/46 [==============================] - 0s 398us/step - loss: 0.0579 - accuracy: 0.9875\n",
      "Epoch 342/500\n",
      "46/46 [==============================] - 0s 399us/step - loss: 0.0660 - accuracy: 0.9844\n",
      "Epoch 343/500\n",
      "46/46 [==============================] - 0s 400us/step - loss: 0.0098 - accuracy: 1.0000\n",
      "Epoch 344/500\n",
      "46/46 [==============================] - 0s 386us/step - loss: 0.0273 - accuracy: 0.9906\n",
      "Epoch 345/500\n",
      "46/46 [==============================] - 0s 407us/step - loss: 0.0381 - accuracy: 0.9844\n",
      "Epoch 346/500\n",
      "46/46 [==============================] - 0s 402us/step - loss: 0.0216 - accuracy: 0.9906\n",
      "Epoch 347/500\n",
      "46/46 [==============================] - 0s 392us/step - loss: 0.0337 - accuracy: 0.9937\n",
      "Epoch 348/500\n",
      "46/46 [==============================] - 0s 400us/step - loss: 0.0196 - accuracy: 0.9969\n",
      "Epoch 349/500\n",
      "46/46 [==============================] - 0s 443us/step - loss: 0.0562 - accuracy: 0.9906\n",
      "Epoch 350/500\n",
      "46/46 [==============================] - 0s 393us/step - loss: 0.0536 - accuracy: 0.9781\n",
      "Epoch 351/500\n",
      "46/46 [==============================] - 0s 409us/step - loss: 0.0495 - accuracy: 0.9688\n",
      "Epoch 352/500\n",
      "46/46 [==============================] - 0s 393us/step - loss: 0.0288 - accuracy: 0.9906\n",
      "Epoch 353/500\n",
      "46/46 [==============================] - 0s 395us/step - loss: 0.0349 - accuracy: 0.9875\n",
      "Epoch 354/500\n",
      "46/46 [==============================] - 0s 409us/step - loss: 0.0388 - accuracy: 0.9844\n",
      "Epoch 355/500\n",
      "46/46 [==============================] - 0s 403us/step - loss: 0.0340 - accuracy: 0.9875\n",
      "Epoch 356/500\n",
      "46/46 [==============================] - 0s 400us/step - loss: 0.0171 - accuracy: 0.9969\n",
      "Epoch 357/500\n",
      "46/46 [==============================] - 0s 436us/step - loss: 0.0250 - accuracy: 0.9906\n",
      "Epoch 358/500\n",
      "46/46 [==============================] - 0s 433us/step - loss: 0.0389 - accuracy: 0.9781\n",
      "Epoch 359/500\n",
      "46/46 [==============================] - 0s 405us/step - loss: 0.0602 - accuracy: 0.9812\n",
      "Epoch 360/500\n",
      "46/46 [==============================] - 0s 416us/step - loss: 0.0635 - accuracy: 0.9750\n",
      "Epoch 361/500\n",
      "46/46 [==============================] - 0s 415us/step - loss: 0.0431 - accuracy: 0.9875\n",
      "Epoch 362/500\n",
      "46/46 [==============================] - 0s 435us/step - loss: 0.0718 - accuracy: 0.9750\n",
      "Epoch 363/500\n",
      "46/46 [==============================] - 0s 391us/step - loss: 0.0726 - accuracy: 0.9688\n",
      "Epoch 364/500\n",
      "46/46 [==============================] - 0s 408us/step - loss: 0.0871 - accuracy: 0.9719\n",
      "Epoch 365/500\n",
      "46/46 [==============================] - 0s 398us/step - loss: 0.0494 - accuracy: 0.9812\n",
      "Epoch 366/500\n",
      "46/46 [==============================] - 0s 391us/step - loss: 0.0440 - accuracy: 0.9750\n",
      "Epoch 367/500\n",
      "46/46 [==============================] - 0s 405us/step - loss: 0.0561 - accuracy: 0.9812\n",
      "Epoch 368/500\n",
      "46/46 [==============================] - 0s 390us/step - loss: 0.0655 - accuracy: 0.9750\n",
      "Epoch 369/500\n",
      "46/46 [==============================] - 0s 409us/step - loss: 0.0643 - accuracy: 0.9781\n",
      "Epoch 370/500\n",
      "46/46 [==============================] - 0s 409us/step - loss: 0.0481 - accuracy: 0.9875\n",
      "Epoch 371/500\n",
      "46/46 [==============================] - 0s 401us/step - loss: 0.0155 - accuracy: 0.9937\n",
      "Epoch 372/500\n",
      "46/46 [==============================] - 0s 401us/step - loss: 0.0312 - accuracy: 0.9937\n",
      "Epoch 373/500\n",
      "46/46 [==============================] - 0s 396us/step - loss: 0.0326 - accuracy: 0.9781\n",
      "Epoch 374/500\n",
      "46/46 [==============================] - 0s 420us/step - loss: 0.0676 - accuracy: 0.9750\n",
      "Epoch 375/500\n",
      "46/46 [==============================] - 0s 410us/step - loss: 0.0841 - accuracy: 0.9750\n",
      "Epoch 376/500\n",
      "46/46 [==============================] - 0s 400us/step - loss: 0.0717 - accuracy: 0.9750\n",
      "Epoch 377/500\n",
      "46/46 [==============================] - 0s 416us/step - loss: 0.0346 - accuracy: 0.9906\n",
      "Epoch 378/500\n",
      "46/46 [==============================] - 0s 401us/step - loss: 0.0377 - accuracy: 0.9875\n",
      "Epoch 379/500\n",
      "46/46 [==============================] - 0s 396us/step - loss: 0.0354 - accuracy: 0.9844\n",
      "Epoch 380/500\n",
      "46/46 [==============================] - 0s 400us/step - loss: 0.0557 - accuracy: 0.9875\n",
      "Epoch 381/500\n",
      "46/46 [==============================] - 0s 420us/step - loss: 0.0324 - accuracy: 0.9906\n",
      "Epoch 382/500\n",
      "46/46 [==============================] - 0s 402us/step - loss: 0.0324 - accuracy: 0.9875\n",
      "Epoch 383/500\n",
      "46/46 [==============================] - 0s 400us/step - loss: 0.0624 - accuracy: 0.9781\n",
      "Epoch 384/500\n",
      "46/46 [==============================] - 0s 394us/step - loss: 0.0662 - accuracy: 0.9750\n",
      "Epoch 385/500\n",
      "46/46 [==============================] - 0s 394us/step - loss: 0.0611 - accuracy: 0.9719\n",
      "Epoch 386/500\n",
      "46/46 [==============================] - 0s 386us/step - loss: 0.0412 - accuracy: 0.9844\n",
      "Epoch 387/500\n",
      "46/46 [==============================] - 0s 403us/step - loss: 0.0790 - accuracy: 0.9781\n",
      "Epoch 388/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 396us/step - loss: 0.0897 - accuracy: 0.9719\n",
      "Epoch 389/500\n",
      "46/46 [==============================] - 0s 442us/step - loss: 0.0256 - accuracy: 0.9875\n",
      "Epoch 390/500\n",
      "46/46 [==============================] - 0s 430us/step - loss: 0.0638 - accuracy: 0.9781\n",
      "Epoch 391/500\n",
      "46/46 [==============================] - 0s 399us/step - loss: 0.0536 - accuracy: 0.9781\n",
      "Epoch 392/500\n",
      "46/46 [==============================] - 0s 412us/step - loss: 0.0345 - accuracy: 0.9844\n",
      "Epoch 393/500\n",
      "46/46 [==============================] - 0s 400us/step - loss: 0.0311 - accuracy: 0.9937\n",
      "Epoch 394/500\n",
      "46/46 [==============================] - 0s 393us/step - loss: 0.0146 - accuracy: 0.9969\n",
      "Epoch 395/500\n",
      "46/46 [==============================] - 0s 389us/step - loss: 0.0492 - accuracy: 0.9875\n",
      "Epoch 396/500\n",
      "46/46 [==============================] - 0s 402us/step - loss: 0.0549 - accuracy: 0.9812\n",
      "Epoch 397/500\n",
      "46/46 [==============================] - 0s 405us/step - loss: 0.0481 - accuracy: 0.9781\n",
      "Epoch 398/500\n",
      "46/46 [==============================] - 0s 402us/step - loss: 0.0579 - accuracy: 0.9719\n",
      "Epoch 399/500\n",
      "46/46 [==============================] - 0s 413us/step - loss: 0.0374 - accuracy: 0.9812\n",
      "Epoch 400/500\n",
      "46/46 [==============================] - 0s 381us/step - loss: 0.0435 - accuracy: 0.9844\n",
      "Epoch 401/500\n",
      "46/46 [==============================] - 0s 415us/step - loss: 0.0790 - accuracy: 0.9781\n",
      "Epoch 402/500\n",
      "46/46 [==============================] - 0s 402us/step - loss: 0.0773 - accuracy: 0.9719\n",
      "Epoch 403/500\n",
      "46/46 [==============================] - 0s 401us/step - loss: 0.0471 - accuracy: 0.9812\n",
      "Epoch 404/500\n",
      "46/46 [==============================] - 0s 416us/step - loss: 0.1087 - accuracy: 0.9688\n",
      "Epoch 405/500\n",
      "46/46 [==============================] - 0s 398us/step - loss: 0.0678 - accuracy: 0.9750\n",
      "Epoch 406/500\n",
      "46/46 [==============================] - 0s 395us/step - loss: 0.0705 - accuracy: 0.9594\n",
      "Epoch 407/500\n",
      "46/46 [==============================] - 0s 398us/step - loss: 0.0294 - accuracy: 0.9906\n",
      "Epoch 408/500\n",
      "46/46 [==============================] - 0s 399us/step - loss: 0.0327 - accuracy: 0.9937\n",
      "Epoch 409/500\n",
      "46/46 [==============================] - 0s 402us/step - loss: 0.0550 - accuracy: 0.9875\n",
      "Epoch 410/500\n",
      "46/46 [==============================] - 0s 398us/step - loss: 0.0175 - accuracy: 1.0000\n",
      "Epoch 411/500\n",
      "46/46 [==============================] - 0s 389us/step - loss: 0.0142 - accuracy: 0.9937\n",
      "Epoch 412/500\n",
      "46/46 [==============================] - 0s 397us/step - loss: 0.0506 - accuracy: 0.9781\n",
      "Epoch 413/500\n",
      "46/46 [==============================] - 0s 400us/step - loss: 0.0612 - accuracy: 0.9781\n",
      "Epoch 414/500\n",
      "46/46 [==============================] - 0s 417us/step - loss: 0.0561 - accuracy: 0.9781\n",
      "Epoch 415/500\n",
      "46/46 [==============================] - 0s 405us/step - loss: 0.0300 - accuracy: 0.9906\n",
      "Epoch 416/500\n",
      "46/46 [==============================] - 0s 410us/step - loss: 0.0382 - accuracy: 0.9875\n",
      "Epoch 417/500\n",
      "46/46 [==============================] - 0s 424us/step - loss: 0.0507 - accuracy: 0.9812\n",
      "Epoch 418/500\n",
      "46/46 [==============================] - 0s 396us/step - loss: 0.0305 - accuracy: 0.9812\n",
      "Epoch 419/500\n",
      "46/46 [==============================] - 0s 416us/step - loss: 0.0337 - accuracy: 0.9906\n",
      "Epoch 420/500\n",
      "46/46 [==============================] - 0s 404us/step - loss: 0.0164 - accuracy: 0.9969\n",
      "Epoch 421/500\n",
      "46/46 [==============================] - 0s 413us/step - loss: 0.0212 - accuracy: 0.9906\n",
      "Epoch 422/500\n",
      "46/46 [==============================] - 0s 397us/step - loss: 0.0478 - accuracy: 0.9875\n",
      "Epoch 423/500\n",
      "46/46 [==============================] - 0s 391us/step - loss: 0.0108 - accuracy: 1.0000\n",
      "Epoch 424/500\n",
      "46/46 [==============================] - 0s 427us/step - loss: 0.0258 - accuracy: 0.9812\n",
      "Epoch 425/500\n",
      "46/46 [==============================] - 0s 401us/step - loss: 0.0316 - accuracy: 0.9906\n",
      "Epoch 426/500\n",
      "46/46 [==============================] - 0s 393us/step - loss: 0.0165 - accuracy: 0.9937\n",
      "Epoch 427/500\n",
      "46/46 [==============================] - 0s 390us/step - loss: 0.0313 - accuracy: 0.9906\n",
      "Epoch 428/500\n",
      "46/46 [==============================] - 0s 411us/step - loss: 0.0524 - accuracy: 0.9844\n",
      "Epoch 429/500\n",
      "46/46 [==============================] - 0s 407us/step - loss: 0.0185 - accuracy: 0.9937\n",
      "Epoch 430/500\n",
      "46/46 [==============================] - 0s 406us/step - loss: 0.0647 - accuracy: 0.9594\n",
      "Epoch 431/500\n",
      "46/46 [==============================] - 0s 391us/step - loss: 0.0222 - accuracy: 0.9937\n",
      "Epoch 432/500\n",
      "46/46 [==============================] - 0s 425us/step - loss: 0.0138 - accuracy: 0.9937\n",
      "Epoch 433/500\n",
      "46/46 [==============================] - 0s 405us/step - loss: 0.0459 - accuracy: 0.9844\n",
      "Epoch 434/500\n",
      "46/46 [==============================] - 0s 415us/step - loss: 0.0175 - accuracy: 0.9937\n",
      "Epoch 435/500\n",
      "46/46 [==============================] - 0s 397us/step - loss: 0.0118 - accuracy: 0.9969\n",
      "Epoch 436/500\n",
      "46/46 [==============================] - 0s 421us/step - loss: 0.0265 - accuracy: 0.9906\n",
      "Epoch 437/500\n",
      "46/46 [==============================] - 0s 397us/step - loss: 0.0254 - accuracy: 0.9906\n",
      "Epoch 438/500\n",
      "46/46 [==============================] - 0s 406us/step - loss: 0.0328 - accuracy: 0.9844\n",
      "Epoch 439/500\n",
      "46/46 [==============================] - 0s 463us/step - loss: 0.0253 - accuracy: 0.9844\n",
      "Epoch 440/500\n",
      "46/46 [==============================] - 0s 411us/step - loss: 0.0424 - accuracy: 0.9781\n",
      "Epoch 441/500\n",
      "46/46 [==============================] - 0s 425us/step - loss: 0.0079 - accuracy: 1.0000\n",
      "Epoch 442/500\n",
      "46/46 [==============================] - 0s 399us/step - loss: 0.0159 - accuracy: 0.9937\n",
      "Epoch 443/500\n",
      "46/46 [==============================] - 0s 402us/step - loss: 0.0174 - accuracy: 0.9906\n",
      "Epoch 444/500\n",
      "46/46 [==============================] - 0s 422us/step - loss: 0.0324 - accuracy: 0.9812\n",
      "Epoch 445/500\n",
      "46/46 [==============================] - 0s 410us/step - loss: 0.0165 - accuracy: 0.9969\n",
      "Epoch 446/500\n",
      "46/46 [==============================] - 0s 410us/step - loss: 0.0146 - accuracy: 0.9937\n",
      "Epoch 447/500\n",
      "46/46 [==============================] - 0s 413us/step - loss: 0.0628 - accuracy: 0.9844\n",
      "Epoch 448/500\n",
      "46/46 [==============================] - 0s 406us/step - loss: 0.0740 - accuracy: 0.9688\n",
      "Epoch 449/500\n",
      "46/46 [==============================] - 0s 407us/step - loss: 0.0501 - accuracy: 0.9812\n",
      "Epoch 450/500\n",
      "46/46 [==============================] - 0s 409us/step - loss: 0.0160 - accuracy: 0.9937\n",
      "Epoch 451/500\n",
      "46/46 [==============================] - 0s 409us/step - loss: 0.0082 - accuracy: 0.9969\n",
      "Epoch 452/500\n",
      "46/46 [==============================] - 0s 409us/step - loss: 0.0299 - accuracy: 0.9875\n",
      "Epoch 453/500\n",
      "46/46 [==============================] - 0s 420us/step - loss: 0.0677 - accuracy: 0.9719\n",
      "Epoch 454/500\n",
      "46/46 [==============================] - 0s 418us/step - loss: 0.0752 - accuracy: 0.9781\n",
      "Epoch 455/500\n",
      "46/46 [==============================] - 0s 415us/step - loss: 0.0455 - accuracy: 0.9844\n",
      "Epoch 456/500\n",
      "46/46 [==============================] - 0s 407us/step - loss: 0.0745 - accuracy: 0.9688\n",
      "Epoch 457/500\n",
      "46/46 [==============================] - 0s 403us/step - loss: 0.0350 - accuracy: 0.9875\n",
      "Epoch 458/500\n",
      "46/46 [==============================] - 0s 406us/step - loss: 0.0331 - accuracy: 0.9906\n",
      "Epoch 459/500\n",
      "46/46 [==============================] - 0s 423us/step - loss: 0.0167 - accuracy: 0.9937\n",
      "Epoch 460/500\n",
      "46/46 [==============================] - 0s 416us/step - loss: 0.0264 - accuracy: 0.9875\n",
      "Epoch 461/500\n",
      "46/46 [==============================] - 0s 433us/step - loss: 0.0106 - accuracy: 0.9969\n",
      "Epoch 462/500\n",
      "46/46 [==============================] - 0s 413us/step - loss: 0.0405 - accuracy: 0.9812\n",
      "Epoch 463/500\n",
      "46/46 [==============================] - 0s 424us/step - loss: 0.0335 - accuracy: 0.9875\n",
      "Epoch 464/500\n",
      "46/46 [==============================] - 0s 430us/step - loss: 0.0209 - accuracy: 0.9969\n",
      "Epoch 465/500\n",
      "46/46 [==============================] - 0s 444us/step - loss: 0.0510 - accuracy: 0.9781\n",
      "Epoch 466/500\n",
      "46/46 [==============================] - 0s 402us/step - loss: 0.0294 - accuracy: 0.9906\n",
      "Epoch 467/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 411us/step - loss: 0.0764 - accuracy: 0.9719\n",
      "Epoch 468/500\n",
      "46/46 [==============================] - 0s 424us/step - loss: 0.0425 - accuracy: 0.9844\n",
      "Epoch 469/500\n",
      "46/46 [==============================] - 0s 410us/step - loss: 0.0308 - accuracy: 0.9875\n",
      "Epoch 470/500\n",
      "46/46 [==============================] - 0s 416us/step - loss: 0.0316 - accuracy: 0.9906\n",
      "Epoch 471/500\n",
      "46/46 [==============================] - 0s 409us/step - loss: 0.0365 - accuracy: 0.9812\n",
      "Epoch 472/500\n",
      "46/46 [==============================] - 0s 405us/step - loss: 0.0319 - accuracy: 0.9906\n",
      "Epoch 473/500\n",
      "46/46 [==============================] - 0s 397us/step - loss: 0.0323 - accuracy: 0.9875\n",
      "Epoch 474/500\n",
      "46/46 [==============================] - 0s 406us/step - loss: 0.0274 - accuracy: 0.9906\n",
      "Epoch 475/500\n",
      "46/46 [==============================] - 0s 399us/step - loss: 0.0315 - accuracy: 0.9875\n",
      "Epoch 476/500\n",
      "46/46 [==============================] - 0s 406us/step - loss: 0.0244 - accuracy: 0.9844\n",
      "Epoch 477/500\n",
      "46/46 [==============================] - 0s 410us/step - loss: 0.0522 - accuracy: 0.9844\n",
      "Epoch 478/500\n",
      "46/46 [==============================] - 0s 399us/step - loss: 0.0362 - accuracy: 0.9844\n",
      "Epoch 479/500\n",
      "46/46 [==============================] - 0s 406us/step - loss: 0.0818 - accuracy: 0.9719\n",
      "Epoch 480/500\n",
      "46/46 [==============================] - 0s 397us/step - loss: 0.0544 - accuracy: 0.9812\n",
      "Epoch 481/500\n",
      "46/46 [==============================] - 0s 398us/step - loss: 0.0492 - accuracy: 0.9812\n",
      "Epoch 482/500\n",
      "46/46 [==============================] - 0s 432us/step - loss: 0.0368 - accuracy: 0.9812\n",
      "Epoch 483/500\n",
      "46/46 [==============================] - 0s 413us/step - loss: 0.0301 - accuracy: 0.9906\n",
      "Epoch 484/500\n",
      "46/46 [==============================] - 0s 403us/step - loss: 0.0179 - accuracy: 0.9937\n",
      "Epoch 485/500\n",
      "46/46 [==============================] - 0s 412us/step - loss: 0.0875 - accuracy: 0.9688\n",
      "Epoch 486/500\n",
      "46/46 [==============================] - 0s 428us/step - loss: 0.0372 - accuracy: 0.9812\n",
      "Epoch 487/500\n",
      "46/46 [==============================] - 0s 414us/step - loss: 0.0344 - accuracy: 0.9937\n",
      "Epoch 488/500\n",
      "46/46 [==============================] - 0s 427us/step - loss: 0.0150 - accuracy: 0.9969\n",
      "Epoch 489/500\n",
      "46/46 [==============================] - 0s 407us/step - loss: 0.0364 - accuracy: 0.9875\n",
      "Epoch 490/500\n",
      "46/46 [==============================] - 0s 404us/step - loss: 0.0579 - accuracy: 0.9844\n",
      "Epoch 491/500\n",
      "46/46 [==============================] - 0s 395us/step - loss: 0.0678 - accuracy: 0.9812\n",
      "Epoch 492/500\n",
      "46/46 [==============================] - 0s 409us/step - loss: 0.0120 - accuracy: 0.9969\n",
      "Epoch 493/500\n",
      "46/46 [==============================] - 0s 407us/step - loss: 0.0188 - accuracy: 0.9906\n",
      "Epoch 494/500\n",
      "46/46 [==============================] - 0s 412us/step - loss: 0.0238 - accuracy: 0.9906\n",
      "Epoch 495/500\n",
      "46/46 [==============================] - 0s 402us/step - loss: 0.0235 - accuracy: 0.9875\n",
      "Epoch 496/500\n",
      "46/46 [==============================] - 0s 401us/step - loss: 0.0451 - accuracy: 0.9844\n",
      "Epoch 497/500\n",
      "46/46 [==============================] - 0s 409us/step - loss: 0.0361 - accuracy: 0.9875\n",
      "Epoch 498/500\n",
      "46/46 [==============================] - 0s 409us/step - loss: 0.0696 - accuracy: 0.9812\n",
      "Epoch 499/500\n",
      "46/46 [==============================] - 0s 412us/step - loss: 0.0163 - accuracy: 0.9937\n",
      "Epoch 500/500\n",
      "46/46 [==============================] - 0s 413us/step - loss: 0.0824 - accuracy: 0.9750\n",
      "Model: \"Sequential-NN\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 42)                1806      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 42)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 256)               11008     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 5)                 1285      \n",
      "=================================================================\n",
      "Total params: 14,099\n",
      "Trainable params: 14,099\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/500\n",
      "46/46 [==============================] - 0s 446us/step - loss: 1.6124 - accuracy: 0.2188\n",
      "Epoch 2/500\n",
      "46/46 [==============================] - 0s 422us/step - loss: 1.4578 - accuracy: 0.4094\n",
      "Epoch 3/500\n",
      "46/46 [==============================] - 0s 399us/step - loss: 1.2639 - accuracy: 0.5063\n",
      "Epoch 4/500\n",
      "46/46 [==============================] - 0s 406us/step - loss: 1.0662 - accuracy: 0.6125\n",
      "Epoch 5/500\n",
      "46/46 [==============================] - 0s 396us/step - loss: 0.9296 - accuracy: 0.6500\n",
      "Epoch 6/500\n",
      "46/46 [==============================] - 0s 414us/step - loss: 0.8575 - accuracy: 0.6938\n",
      "Epoch 7/500\n",
      "46/46 [==============================] - 0s 403us/step - loss: 0.7808 - accuracy: 0.6781\n",
      "Epoch 8/500\n",
      "46/46 [==============================] - 0s 406us/step - loss: 0.7153 - accuracy: 0.7312\n",
      "Epoch 9/500\n",
      "46/46 [==============================] - 0s 396us/step - loss: 0.6500 - accuracy: 0.7656\n",
      "Epoch 10/500\n",
      "46/46 [==============================] - 0s 403us/step - loss: 0.6405 - accuracy: 0.7406\n",
      "Epoch 11/500\n",
      "46/46 [==============================] - 0s 409us/step - loss: 0.5603 - accuracy: 0.7812\n",
      "Epoch 12/500\n",
      "46/46 [==============================] - 0s 391us/step - loss: 0.5947 - accuracy: 0.7719\n",
      "Epoch 13/500\n",
      "46/46 [==============================] - 0s 397us/step - loss: 0.5187 - accuracy: 0.7875\n",
      "Epoch 14/500\n",
      "46/46 [==============================] - 0s 397us/step - loss: 0.5120 - accuracy: 0.7812\n",
      "Epoch 15/500\n",
      "46/46 [==============================] - 0s 434us/step - loss: 0.5305 - accuracy: 0.7906\n",
      "Epoch 16/500\n",
      "46/46 [==============================] - 0s 400us/step - loss: 0.4614 - accuracy: 0.8156\n",
      "Epoch 17/500\n",
      "46/46 [==============================] - 0s 394us/step - loss: 0.4953 - accuracy: 0.8250\n",
      "Epoch 18/500\n",
      "46/46 [==============================] - 0s 411us/step - loss: 0.4413 - accuracy: 0.8375\n",
      "Epoch 19/500\n",
      "46/46 [==============================] - 0s 404us/step - loss: 0.4022 - accuracy: 0.8594\n",
      "Epoch 20/500\n",
      "46/46 [==============================] - 0s 394us/step - loss: 0.4271 - accuracy: 0.8406\n",
      "Epoch 21/500\n",
      "46/46 [==============================] - 0s 409us/step - loss: 0.3936 - accuracy: 0.8375\n",
      "Epoch 22/500\n",
      "46/46 [==============================] - 0s 407us/step - loss: 0.3599 - accuracy: 0.8562\n",
      "Epoch 23/500\n",
      "46/46 [==============================] - 0s 414us/step - loss: 0.3656 - accuracy: 0.8406\n",
      "Epoch 24/500\n",
      "46/46 [==============================] - 0s 422us/step - loss: 0.3641 - accuracy: 0.8750\n",
      "Epoch 25/500\n",
      "46/46 [==============================] - 0s 417us/step - loss: 0.3393 - accuracy: 0.8625\n",
      "Epoch 26/500\n",
      "46/46 [==============================] - 0s 441us/step - loss: 0.3906 - accuracy: 0.8594\n",
      "Epoch 27/500\n",
      "46/46 [==============================] - 0s 393us/step - loss: 0.3815 - accuracy: 0.8438\n",
      "Epoch 28/500\n",
      "46/46 [==============================] - 0s 418us/step - loss: 0.2894 - accuracy: 0.9094\n",
      "Epoch 29/500\n",
      "46/46 [==============================] - 0s 400us/step - loss: 0.3267 - accuracy: 0.8813\n",
      "Epoch 30/500\n",
      "46/46 [==============================] - 0s 409us/step - loss: 0.3245 - accuracy: 0.8687\n",
      "Epoch 31/500\n",
      "46/46 [==============================] - 0s 404us/step - loss: 0.3441 - accuracy: 0.8844\n",
      "Epoch 32/500\n",
      "46/46 [==============================] - 0s 397us/step - loss: 0.2967 - accuracy: 0.8906\n",
      "Epoch 33/500\n",
      "46/46 [==============================] - 0s 407us/step - loss: 0.2563 - accuracy: 0.9031\n",
      "Epoch 34/500\n",
      "46/46 [==============================] - 0s 411us/step - loss: 0.3086 - accuracy: 0.8844\n",
      "Epoch 35/500\n",
      "46/46 [==============================] - 0s 399us/step - loss: 0.2565 - accuracy: 0.8938\n",
      "Epoch 36/500\n",
      "46/46 [==============================] - 0s 412us/step - loss: 0.2379 - accuracy: 0.9156\n",
      "Epoch 37/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 400us/step - loss: 0.2656 - accuracy: 0.8813\n",
      "Epoch 38/500\n",
      "46/46 [==============================] - 0s 405us/step - loss: 0.2391 - accuracy: 0.9156\n",
      "Epoch 39/500\n",
      "46/46 [==============================] - 0s 398us/step - loss: 0.2688 - accuracy: 0.8969\n",
      "Epoch 40/500\n",
      "46/46 [==============================] - 0s 397us/step - loss: 0.2583 - accuracy: 0.9000\n",
      "Epoch 41/500\n",
      "46/46 [==============================] - 0s 409us/step - loss: 0.2678 - accuracy: 0.9125\n",
      "Epoch 42/500\n",
      "46/46 [==============================] - 0s 446us/step - loss: 0.2172 - accuracy: 0.9219\n",
      "Epoch 43/500\n",
      "46/46 [==============================] - 0s 412us/step - loss: 0.2358 - accuracy: 0.9281\n",
      "Epoch 44/500\n",
      "46/46 [==============================] - 0s 398us/step - loss: 0.2170 - accuracy: 0.9312\n",
      "Epoch 45/500\n",
      "46/46 [==============================] - 0s 397us/step - loss: 0.2111 - accuracy: 0.9156\n",
      "Epoch 46/500\n",
      "46/46 [==============================] - 0s 424us/step - loss: 0.2128 - accuracy: 0.9156\n",
      "Epoch 47/500\n",
      "46/46 [==============================] - 0s 391us/step - loss: 0.2223 - accuracy: 0.9094\n",
      "Epoch 48/500\n",
      "46/46 [==============================] - 0s 410us/step - loss: 0.2137 - accuracy: 0.9094\n",
      "Epoch 49/500\n",
      "46/46 [==============================] - 0s 406us/step - loss: 0.1944 - accuracy: 0.9250\n",
      "Epoch 50/500\n",
      "46/46 [==============================] - 0s 404us/step - loss: 0.1834 - accuracy: 0.9219\n",
      "Epoch 51/500\n",
      "46/46 [==============================] - 0s 437us/step - loss: 0.2008 - accuracy: 0.9156\n",
      "Epoch 52/500\n",
      "46/46 [==============================] - 0s 470us/step - loss: 0.2105 - accuracy: 0.8969\n",
      "Epoch 53/500\n",
      "46/46 [==============================] - 0s 488us/step - loss: 0.1904 - accuracy: 0.9250\n",
      "Epoch 54/500\n",
      "46/46 [==============================] - 0s 442us/step - loss: 0.2072 - accuracy: 0.9156\n",
      "Epoch 55/500\n",
      "46/46 [==============================] - 0s 450us/step - loss: 0.1983 - accuracy: 0.9281\n",
      "Epoch 56/500\n",
      "46/46 [==============================] - 0s 467us/step - loss: 0.1827 - accuracy: 0.9375\n",
      "Epoch 57/500\n",
      "46/46 [==============================] - 0s 465us/step - loss: 0.1728 - accuracy: 0.9469\n",
      "Epoch 58/500\n",
      "46/46 [==============================] - 0s 454us/step - loss: 0.1697 - accuracy: 0.9375\n",
      "Epoch 59/500\n",
      "46/46 [==============================] - 0s 411us/step - loss: 0.1712 - accuracy: 0.9344\n",
      "Epoch 60/500\n",
      "46/46 [==============================] - 0s 389us/step - loss: 0.1582 - accuracy: 0.9438\n",
      "Epoch 61/500\n",
      "46/46 [==============================] - 0s 459us/step - loss: 0.2012 - accuracy: 0.9344\n",
      "Epoch 62/500\n",
      "46/46 [==============================] - 0s 433us/step - loss: 0.1363 - accuracy: 0.9563\n",
      "Epoch 63/500\n",
      "46/46 [==============================] - 0s 458us/step - loss: 0.1190 - accuracy: 0.9625\n",
      "Epoch 64/500\n",
      "46/46 [==============================] - 0s 431us/step - loss: 0.1402 - accuracy: 0.9438\n",
      "Epoch 65/500\n",
      "46/46 [==============================] - 0s 424us/step - loss: 0.1406 - accuracy: 0.9594\n",
      "Epoch 66/500\n",
      "46/46 [==============================] - 0s 414us/step - loss: 0.1599 - accuracy: 0.9531\n",
      "Epoch 67/500\n",
      "46/46 [==============================] - 0s 394us/step - loss: 0.1435 - accuracy: 0.9594\n",
      "Epoch 68/500\n",
      "46/46 [==============================] - 0s 397us/step - loss: 0.1448 - accuracy: 0.9563\n",
      "Epoch 69/500\n",
      "46/46 [==============================] - 0s 390us/step - loss: 0.1684 - accuracy: 0.9344\n",
      "Epoch 70/500\n",
      "46/46 [==============================] - 0s 394us/step - loss: 0.1479 - accuracy: 0.9563\n",
      "Epoch 71/500\n",
      "46/46 [==============================] - 0s 409us/step - loss: 0.1322 - accuracy: 0.9563\n",
      "Epoch 72/500\n",
      "46/46 [==============================] - 0s 399us/step - loss: 0.1341 - accuracy: 0.9563\n",
      "Epoch 73/500\n",
      "46/46 [==============================] - 0s 402us/step - loss: 0.1395 - accuracy: 0.9500\n",
      "Epoch 74/500\n",
      "46/46 [==============================] - 0s 460us/step - loss: 0.1404 - accuracy: 0.9594\n",
      "Epoch 75/500\n",
      "46/46 [==============================] - 0s 428us/step - loss: 0.1491 - accuracy: 0.9469\n",
      "Epoch 76/500\n",
      "46/46 [==============================] - 0s 470us/step - loss: 0.1226 - accuracy: 0.9500\n",
      "Epoch 77/500\n",
      "46/46 [==============================] - 0s 443us/step - loss: 0.1431 - accuracy: 0.9594\n",
      "Epoch 78/500\n",
      "46/46 [==============================] - 0s 431us/step - loss: 0.1503 - accuracy: 0.9563\n",
      "Epoch 79/500\n",
      "46/46 [==============================] - 0s 440us/step - loss: 0.1310 - accuracy: 0.9500\n",
      "Epoch 80/500\n",
      "46/46 [==============================] - 0s 447us/step - loss: 0.0993 - accuracy: 0.9594\n",
      "Epoch 81/500\n",
      "46/46 [==============================] - 0s 431us/step - loss: 0.1356 - accuracy: 0.9469\n",
      "Epoch 82/500\n",
      "46/46 [==============================] - 0s 465us/step - loss: 0.1552 - accuracy: 0.9438\n",
      "Epoch 83/500\n",
      "46/46 [==============================] - 0s 483us/step - loss: 0.1129 - accuracy: 0.9594\n",
      "Epoch 84/500\n",
      "46/46 [==============================] - 0s 453us/step - loss: 0.1631 - accuracy: 0.9375\n",
      "Epoch 85/500\n",
      "46/46 [==============================] - 0s 457us/step - loss: 0.1622 - accuracy: 0.9187\n",
      "Epoch 86/500\n",
      "46/46 [==============================] - 0s 429us/step - loss: 0.1023 - accuracy: 0.9688\n",
      "Epoch 87/500\n",
      "46/46 [==============================] - 0s 456us/step - loss: 0.0933 - accuracy: 0.9656\n",
      "Epoch 88/500\n",
      "46/46 [==============================] - 0s 444us/step - loss: 0.1060 - accuracy: 0.9531\n",
      "Epoch 89/500\n",
      "46/46 [==============================] - 0s 429us/step - loss: 0.0965 - accuracy: 0.9688\n",
      "Epoch 90/500\n",
      "46/46 [==============================] - 0s 402us/step - loss: 0.1196 - accuracy: 0.9625\n",
      "Epoch 91/500\n",
      "46/46 [==============================] - 0s 423us/step - loss: 0.1433 - accuracy: 0.9438\n",
      "Epoch 92/500\n",
      "46/46 [==============================] - 0s 388us/step - loss: 0.1172 - accuracy: 0.9406\n",
      "Epoch 93/500\n",
      "46/46 [==============================] - 0s 407us/step - loss: 0.0941 - accuracy: 0.9594\n",
      "Epoch 94/500\n",
      "46/46 [==============================] - 0s 415us/step - loss: 0.1121 - accuracy: 0.9656\n",
      "Epoch 95/500\n",
      "46/46 [==============================] - 0s 393us/step - loss: 0.0819 - accuracy: 0.9688\n",
      "Epoch 96/500\n",
      "46/46 [==============================] - 0s 404us/step - loss: 0.1264 - accuracy: 0.9531\n",
      "Epoch 97/500\n",
      "46/46 [==============================] - 0s 403us/step - loss: 0.0988 - accuracy: 0.9563\n",
      "Epoch 98/500\n",
      "46/46 [==============================] - 0s 410us/step - loss: 0.1165 - accuracy: 0.9688\n",
      "Epoch 99/500\n",
      "46/46 [==============================] - 0s 419us/step - loss: 0.1074 - accuracy: 0.9688\n",
      "Epoch 100/500\n",
      "46/46 [==============================] - 0s 394us/step - loss: 0.0901 - accuracy: 0.9688\n",
      "Epoch 101/500\n",
      "46/46 [==============================] - 0s 394us/step - loss: 0.0966 - accuracy: 0.9625\n",
      "Epoch 102/500\n",
      "46/46 [==============================] - 0s 403us/step - loss: 0.0755 - accuracy: 0.9719\n",
      "Epoch 103/500\n",
      "46/46 [==============================] - 0s 385us/step - loss: 0.1036 - accuracy: 0.9656\n",
      "Epoch 104/500\n",
      "46/46 [==============================] - 0s 392us/step - loss: 0.1167 - accuracy: 0.9563\n",
      "Epoch 105/500\n",
      "46/46 [==============================] - 0s 387us/step - loss: 0.1014 - accuracy: 0.9625\n",
      "Epoch 106/500\n",
      "46/46 [==============================] - 0s 395us/step - loss: 0.1009 - accuracy: 0.9656\n",
      "Epoch 107/500\n",
      "46/46 [==============================] - 0s 397us/step - loss: 0.1026 - accuracy: 0.9625\n",
      "Epoch 108/500\n",
      "46/46 [==============================] - 0s 411us/step - loss: 0.0737 - accuracy: 0.9844\n",
      "Epoch 109/500\n",
      "46/46 [==============================] - 0s 402us/step - loss: 0.0687 - accuracy: 0.9781\n",
      "Epoch 110/500\n",
      "46/46 [==============================] - 0s 405us/step - loss: 0.0736 - accuracy: 0.9719\n",
      "Epoch 111/500\n",
      "46/46 [==============================] - 0s 420us/step - loss: 0.1022 - accuracy: 0.9500\n",
      "Epoch 112/500\n",
      "46/46 [==============================] - 0s 396us/step - loss: 0.0987 - accuracy: 0.9656\n",
      "Epoch 113/500\n",
      "46/46 [==============================] - 0s 402us/step - loss: 0.0913 - accuracy: 0.9594\n",
      "Epoch 114/500\n",
      "46/46 [==============================] - 0s 401us/step - loss: 0.0841 - accuracy: 0.9688\n",
      "Epoch 115/500\n",
      "46/46 [==============================] - 0s 401us/step - loss: 0.0834 - accuracy: 0.9781\n",
      "Epoch 116/500\n",
      "46/46 [==============================] - 0s 410us/step - loss: 0.0779 - accuracy: 0.9688\n",
      "Epoch 117/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 404us/step - loss: 0.0974 - accuracy: 0.9594\n",
      "Epoch 118/500\n",
      "46/46 [==============================] - 0s 417us/step - loss: 0.1392 - accuracy: 0.9469\n",
      "Epoch 119/500\n",
      "46/46 [==============================] - 0s 408us/step - loss: 0.1031 - accuracy: 0.9688\n",
      "Epoch 120/500\n",
      "46/46 [==============================] - 0s 395us/step - loss: 0.0702 - accuracy: 0.9812\n",
      "Epoch 121/500\n",
      "46/46 [==============================] - 0s 407us/step - loss: 0.0606 - accuracy: 0.9719\n",
      "Epoch 122/500\n",
      "46/46 [==============================] - 0s 415us/step - loss: 0.0830 - accuracy: 0.9688\n",
      "Epoch 123/500\n",
      "46/46 [==============================] - 0s 447us/step - loss: 0.1259 - accuracy: 0.9563\n",
      "Epoch 124/500\n",
      "46/46 [==============================] - 0s 397us/step - loss: 0.0806 - accuracy: 0.9781\n",
      "Epoch 125/500\n",
      "46/46 [==============================] - 0s 396us/step - loss: 0.0812 - accuracy: 0.9656\n",
      "Epoch 126/500\n",
      "46/46 [==============================] - 0s 404us/step - loss: 0.0952 - accuracy: 0.9719\n",
      "Epoch 127/500\n",
      "46/46 [==============================] - 0s 404us/step - loss: 0.0823 - accuracy: 0.9719\n",
      "Epoch 128/500\n",
      "46/46 [==============================] - 0s 530us/step - loss: 0.0771 - accuracy: 0.9688\n",
      "Epoch 129/500\n",
      "46/46 [==============================] - 0s 420us/step - loss: 0.0536 - accuracy: 0.9844\n",
      "Epoch 130/500\n",
      "46/46 [==============================] - 0s 424us/step - loss: 0.0677 - accuracy: 0.9719\n",
      "Epoch 131/500\n",
      "46/46 [==============================] - 0s 412us/step - loss: 0.0752 - accuracy: 0.9719\n",
      "Epoch 132/500\n",
      "46/46 [==============================] - 0s 422us/step - loss: 0.0466 - accuracy: 0.9844\n",
      "Epoch 133/500\n",
      "46/46 [==============================] - 0s 417us/step - loss: 0.0792 - accuracy: 0.9594\n",
      "Epoch 134/500\n",
      "46/46 [==============================] - 0s 410us/step - loss: 0.0885 - accuracy: 0.9688\n",
      "Epoch 135/500\n",
      "46/46 [==============================] - 0s 443us/step - loss: 0.0821 - accuracy: 0.9719\n",
      "Epoch 136/500\n",
      "46/46 [==============================] - 0s 419us/step - loss: 0.0927 - accuracy: 0.9750\n",
      "Epoch 137/500\n",
      "46/46 [==============================] - 0s 416us/step - loss: 0.0418 - accuracy: 0.9875\n",
      "Epoch 138/500\n",
      "46/46 [==============================] - 0s 423us/step - loss: 0.0785 - accuracy: 0.9656\n",
      "Epoch 139/500\n",
      "46/46 [==============================] - 0s 406us/step - loss: 0.0907 - accuracy: 0.9719\n",
      "Epoch 140/500\n",
      "46/46 [==============================] - 0s 412us/step - loss: 0.0655 - accuracy: 0.9781\n",
      "Epoch 141/500\n",
      "46/46 [==============================] - 0s 402us/step - loss: 0.0599 - accuracy: 0.9750\n",
      "Epoch 142/500\n",
      "46/46 [==============================] - 0s 394us/step - loss: 0.0618 - accuracy: 0.9750\n",
      "Epoch 143/500\n",
      "46/46 [==============================] - 0s 422us/step - loss: 0.0661 - accuracy: 0.9844\n",
      "Epoch 144/500\n",
      "46/46 [==============================] - 0s 398us/step - loss: 0.0859 - accuracy: 0.9719\n",
      "Epoch 145/500\n",
      "46/46 [==============================] - 0s 404us/step - loss: 0.0539 - accuracy: 0.9844\n",
      "Epoch 146/500\n",
      "46/46 [==============================] - 0s 396us/step - loss: 0.0470 - accuracy: 0.9844\n",
      "Epoch 147/500\n",
      "46/46 [==============================] - 0s 401us/step - loss: 0.0674 - accuracy: 0.9719\n",
      "Epoch 148/500\n",
      "46/46 [==============================] - 0s 391us/step - loss: 0.0637 - accuracy: 0.9750\n",
      "Epoch 149/500\n",
      "46/46 [==============================] - 0s 384us/step - loss: 0.0840 - accuracy: 0.9719\n",
      "Epoch 150/500\n",
      "46/46 [==============================] - 0s 403us/step - loss: 0.0813 - accuracy: 0.9688\n",
      "Epoch 151/500\n",
      "46/46 [==============================] - 0s 405us/step - loss: 0.0809 - accuracy: 0.9719\n",
      "Epoch 152/500\n",
      "46/46 [==============================] - 0s 390us/step - loss: 0.0446 - accuracy: 0.9875\n",
      "Epoch 153/500\n",
      "46/46 [==============================] - 0s 421us/step - loss: 0.0607 - accuracy: 0.9719\n",
      "Epoch 154/500\n",
      "46/46 [==============================] - 0s 393us/step - loss: 0.0705 - accuracy: 0.9688\n",
      "Epoch 155/500\n",
      "46/46 [==============================] - 0s 406us/step - loss: 0.1075 - accuracy: 0.9625\n",
      "Epoch 156/500\n",
      "46/46 [==============================] - 0s 390us/step - loss: 0.0622 - accuracy: 0.9812\n",
      "Epoch 157/500\n",
      "46/46 [==============================] - 0s 387us/step - loss: 0.0634 - accuracy: 0.9781\n",
      "Epoch 158/500\n",
      "46/46 [==============================] - 0s 405us/step - loss: 0.0632 - accuracy: 0.9844\n",
      "Epoch 159/500\n",
      "46/46 [==============================] - 0s 410us/step - loss: 0.0519 - accuracy: 0.9812\n",
      "Epoch 160/500\n",
      "46/46 [==============================] - 0s 404us/step - loss: 0.0737 - accuracy: 0.9719\n",
      "Epoch 161/500\n",
      "46/46 [==============================] - 0s 390us/step - loss: 0.0591 - accuracy: 0.9750\n",
      "Epoch 162/500\n",
      "46/46 [==============================] - 0s 398us/step - loss: 0.0758 - accuracy: 0.9781\n",
      "Epoch 163/500\n",
      "46/46 [==============================] - 0s 415us/step - loss: 0.0453 - accuracy: 0.9812\n",
      "Epoch 164/500\n",
      "46/46 [==============================] - 0s 400us/step - loss: 0.0610 - accuracy: 0.9688\n",
      "Epoch 165/500\n",
      "46/46 [==============================] - 0s 410us/step - loss: 0.1065 - accuracy: 0.9594\n",
      "Epoch 166/500\n",
      "46/46 [==============================] - 0s 404us/step - loss: 0.0596 - accuracy: 0.9812\n",
      "Epoch 167/500\n",
      "46/46 [==============================] - 0s 426us/step - loss: 0.0489 - accuracy: 0.9844\n",
      "Epoch 168/500\n",
      "46/46 [==============================] - 0s 421us/step - loss: 0.0871 - accuracy: 0.9688\n",
      "Epoch 169/500\n",
      "46/46 [==============================] - 0s 417us/step - loss: 0.0546 - accuracy: 0.9844\n",
      "Epoch 170/500\n",
      "46/46 [==============================] - 0s 412us/step - loss: 0.0341 - accuracy: 0.9937\n",
      "Epoch 171/500\n",
      "46/46 [==============================] - 0s 422us/step - loss: 0.0961 - accuracy: 0.9594\n",
      "Epoch 172/500\n",
      "46/46 [==============================] - 0s 447us/step - loss: 0.0824 - accuracy: 0.9688\n",
      "Epoch 173/500\n",
      "46/46 [==============================] - 0s 405us/step - loss: 0.0674 - accuracy: 0.9750\n",
      "Epoch 174/500\n",
      "46/46 [==============================] - 0s 414us/step - loss: 0.0791 - accuracy: 0.9781\n",
      "Epoch 175/500\n",
      "46/46 [==============================] - 0s 435us/step - loss: 0.0428 - accuracy: 0.9937\n",
      "Epoch 176/500\n",
      "46/46 [==============================] - 0s 410us/step - loss: 0.0470 - accuracy: 0.9812\n",
      "Epoch 177/500\n",
      "46/46 [==============================] - 0s 416us/step - loss: 0.0439 - accuracy: 0.9812\n",
      "Epoch 178/500\n",
      "46/46 [==============================] - 0s 406us/step - loss: 0.0761 - accuracy: 0.9688\n",
      "Epoch 179/500\n",
      "46/46 [==============================] - 0s 425us/step - loss: 0.0457 - accuracy: 0.9844\n",
      "Epoch 180/500\n",
      "46/46 [==============================] - 0s 396us/step - loss: 0.0609 - accuracy: 0.9781\n",
      "Epoch 181/500\n",
      "46/46 [==============================] - 0s 416us/step - loss: 0.0547 - accuracy: 0.9844\n",
      "Epoch 182/500\n",
      "46/46 [==============================] - 0s 402us/step - loss: 0.0582 - accuracy: 0.9844\n",
      "Epoch 183/500\n",
      "46/46 [==============================] - 0s 424us/step - loss: 0.0453 - accuracy: 0.9812\n",
      "Epoch 184/500\n",
      "46/46 [==============================] - 0s 419us/step - loss: 0.0602 - accuracy: 0.9719\n",
      "Epoch 185/500\n",
      "46/46 [==============================] - 0s 399us/step - loss: 0.0484 - accuracy: 0.9875\n",
      "Epoch 186/500\n",
      "46/46 [==============================] - 0s 400us/step - loss: 0.0331 - accuracy: 0.9875\n",
      "Epoch 187/500\n",
      "46/46 [==============================] - 0s 429us/step - loss: 0.0590 - accuracy: 0.9812\n",
      "Epoch 188/500\n",
      "46/46 [==============================] - 0s 413us/step - loss: 0.0415 - accuracy: 0.9844\n",
      "Epoch 189/500\n",
      "46/46 [==============================] - 0s 420us/step - loss: 0.0434 - accuracy: 0.9812\n",
      "Epoch 190/500\n",
      "46/46 [==============================] - 0s 394us/step - loss: 0.0749 - accuracy: 0.9688\n",
      "Epoch 191/500\n",
      "46/46 [==============================] - 0s 421us/step - loss: 0.0624 - accuracy: 0.9812\n",
      "Epoch 192/500\n",
      "46/46 [==============================] - 0s 394us/step - loss: 0.0239 - accuracy: 0.9906\n",
      "Epoch 193/500\n",
      "46/46 [==============================] - 0s 393us/step - loss: 0.0333 - accuracy: 0.9937\n",
      "Epoch 194/500\n",
      "46/46 [==============================] - 0s 419us/step - loss: 0.0278 - accuracy: 0.9937\n",
      "Epoch 195/500\n",
      "46/46 [==============================] - 0s 390us/step - loss: 0.0800 - accuracy: 0.9688\n",
      "Epoch 196/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 405us/step - loss: 0.0785 - accuracy: 0.9531\n",
      "Epoch 197/500\n",
      "46/46 [==============================] - 0s 390us/step - loss: 0.0582 - accuracy: 0.9781\n",
      "Epoch 198/500\n",
      "46/46 [==============================] - 0s 392us/step - loss: 0.0509 - accuracy: 0.9906\n",
      "Epoch 199/500\n",
      "46/46 [==============================] - 0s 409us/step - loss: 0.0522 - accuracy: 0.9781\n",
      "Epoch 200/500\n",
      "46/46 [==============================] - 0s 397us/step - loss: 0.0583 - accuracy: 0.9781\n",
      "Epoch 201/500\n",
      "46/46 [==============================] - 0s 421us/step - loss: 0.0640 - accuracy: 0.9812\n",
      "Epoch 202/500\n",
      "46/46 [==============================] - 0s 396us/step - loss: 0.0389 - accuracy: 0.9906\n",
      "Epoch 203/500\n",
      "46/46 [==============================] - 0s 399us/step - loss: 0.0778 - accuracy: 0.9688\n",
      "Epoch 204/500\n",
      "46/46 [==============================] - 0s 399us/step - loss: 0.0596 - accuracy: 0.9781\n",
      "Epoch 205/500\n",
      "46/46 [==============================] - 0s 399us/step - loss: 0.0406 - accuracy: 0.9937\n",
      "Epoch 206/500\n",
      "46/46 [==============================] - 0s 419us/step - loss: 0.0341 - accuracy: 0.9906\n",
      "Epoch 207/500\n",
      "46/46 [==============================] - 0s 399us/step - loss: 0.0453 - accuracy: 0.9812\n",
      "Epoch 208/500\n",
      "46/46 [==============================] - 0s 396us/step - loss: 0.0135 - accuracy: 0.9969\n",
      "Epoch 209/500\n",
      "46/46 [==============================] - 0s 411us/step - loss: 0.0558 - accuracy: 0.9688\n",
      "Epoch 210/500\n",
      "46/46 [==============================] - 0s 422us/step - loss: 0.0555 - accuracy: 0.9844\n",
      "Epoch 211/500\n",
      "46/46 [==============================] - 0s 416us/step - loss: 0.0783 - accuracy: 0.9656\n",
      "Epoch 212/500\n",
      "46/46 [==============================] - 0s 400us/step - loss: 0.0902 - accuracy: 0.9688\n",
      "Epoch 213/500\n",
      "46/46 [==============================] - 0s 400us/step - loss: 0.0510 - accuracy: 0.9812\n",
      "Epoch 214/500\n",
      "46/46 [==============================] - 0s 399us/step - loss: 0.0401 - accuracy: 0.9937\n",
      "Epoch 215/500\n",
      "46/46 [==============================] - 0s 405us/step - loss: 0.0334 - accuracy: 0.9906\n",
      "Epoch 216/500\n",
      "46/46 [==============================] - 0s 403us/step - loss: 0.0239 - accuracy: 0.9937\n",
      "Epoch 217/500\n",
      "46/46 [==============================] - 0s 395us/step - loss: 0.0431 - accuracy: 0.9781\n",
      "Epoch 218/500\n",
      "46/46 [==============================] - 0s 403us/step - loss: 0.0563 - accuracy: 0.9781\n",
      "Epoch 219/500\n",
      "46/46 [==============================] - 0s 436us/step - loss: 0.0269 - accuracy: 0.9906\n",
      "Epoch 220/500\n",
      "46/46 [==============================] - 0s 410us/step - loss: 0.0873 - accuracy: 0.9625\n",
      "Epoch 221/500\n",
      "46/46 [==============================] - 0s 404us/step - loss: 0.0674 - accuracy: 0.9750\n",
      "Epoch 222/500\n",
      "46/46 [==============================] - 0s 428us/step - loss: 0.0416 - accuracy: 0.9875\n",
      "Epoch 223/500\n",
      "46/46 [==============================] - 0s 397us/step - loss: 0.0520 - accuracy: 0.9812\n",
      "Epoch 224/500\n",
      "46/46 [==============================] - 0s 403us/step - loss: 0.0332 - accuracy: 0.9937\n",
      "Epoch 225/500\n",
      "46/46 [==============================] - 0s 412us/step - loss: 0.0448 - accuracy: 0.9875\n",
      "Epoch 226/500\n",
      "46/46 [==============================] - 0s 409us/step - loss: 0.0841 - accuracy: 0.9656\n",
      "Epoch 227/500\n",
      "46/46 [==============================] - 0s 408us/step - loss: 0.0534 - accuracy: 0.9844\n",
      "Epoch 228/500\n",
      "46/46 [==============================] - 0s 411us/step - loss: 0.0472 - accuracy: 0.9750\n",
      "Epoch 229/500\n",
      "46/46 [==============================] - 0s 387us/step - loss: 0.0462 - accuracy: 0.9812\n",
      "Epoch 230/500\n",
      "46/46 [==============================] - 0s 398us/step - loss: 0.0467 - accuracy: 0.9781\n",
      "Epoch 231/500\n",
      "46/46 [==============================] - 0s 410us/step - loss: 0.0765 - accuracy: 0.9781\n",
      "Epoch 232/500\n",
      "46/46 [==============================] - 0s 393us/step - loss: 0.0499 - accuracy: 0.9812\n",
      "Epoch 233/500\n",
      "46/46 [==============================] - 0s 425us/step - loss: 0.0384 - accuracy: 0.9906\n",
      "Epoch 234/500\n",
      "46/46 [==============================] - 0s 416us/step - loss: 0.0232 - accuracy: 0.9906\n",
      "Epoch 235/500\n",
      "46/46 [==============================] - 0s 405us/step - loss: 0.0320 - accuracy: 0.9875\n",
      "Epoch 236/500\n",
      "46/46 [==============================] - 0s 399us/step - loss: 0.0231 - accuracy: 0.9969\n",
      "Epoch 237/500\n",
      "46/46 [==============================] - 0s 578us/step - loss: 0.0288 - accuracy: 0.9875\n",
      "Epoch 238/500\n",
      "46/46 [==============================] - 0s 438us/step - loss: 0.0626 - accuracy: 0.9719\n",
      "Epoch 239/500\n",
      "46/46 [==============================] - 0s 448us/step - loss: 0.0618 - accuracy: 0.9719\n",
      "Epoch 240/500\n",
      "46/46 [==============================] - 0s 400us/step - loss: 0.0402 - accuracy: 0.9875\n",
      "Epoch 241/500\n",
      "46/46 [==============================] - 0s 412us/step - loss: 0.0348 - accuracy: 0.9875\n",
      "Epoch 242/500\n",
      "46/46 [==============================] - 0s 416us/step - loss: 0.0352 - accuracy: 0.9906\n",
      "Epoch 243/500\n",
      "46/46 [==============================] - 0s 415us/step - loss: 0.0282 - accuracy: 0.9906\n",
      "Epoch 244/500\n",
      "46/46 [==============================] - 0s 410us/step - loss: 0.0401 - accuracy: 0.9875\n",
      "Epoch 245/500\n",
      "46/46 [==============================] - 0s 400us/step - loss: 0.0515 - accuracy: 0.9781\n",
      "Epoch 246/500\n",
      "46/46 [==============================] - 0s 395us/step - loss: 0.0348 - accuracy: 0.9844\n",
      "Epoch 247/500\n",
      "46/46 [==============================] - 0s 400us/step - loss: 0.0573 - accuracy: 0.9750\n",
      "Epoch 248/500\n",
      "46/46 [==============================] - 0s 398us/step - loss: 0.1111 - accuracy: 0.9594\n",
      "Epoch 249/500\n",
      "46/46 [==============================] - 0s 400us/step - loss: 0.0487 - accuracy: 0.9844\n",
      "Epoch 250/500\n",
      "46/46 [==============================] - 0s 414us/step - loss: 0.0256 - accuracy: 0.9937\n",
      "Epoch 251/500\n",
      "46/46 [==============================] - 0s 404us/step - loss: 0.0349 - accuracy: 0.9844\n",
      "Epoch 252/500\n",
      "46/46 [==============================] - 0s 407us/step - loss: 0.0694 - accuracy: 0.9688\n",
      "Epoch 253/500\n",
      "46/46 [==============================] - 0s 409us/step - loss: 0.0422 - accuracy: 0.9844\n",
      "Epoch 254/500\n",
      "46/46 [==============================] - 0s 416us/step - loss: 0.0472 - accuracy: 0.9750\n",
      "Epoch 255/500\n",
      "46/46 [==============================] - 0s 412us/step - loss: 0.0451 - accuracy: 0.9812\n",
      "Epoch 256/500\n",
      "46/46 [==============================] - 0s 389us/step - loss: 0.0622 - accuracy: 0.9688\n",
      "Epoch 257/500\n",
      "46/46 [==============================] - 0s 398us/step - loss: 0.0300 - accuracy: 0.9937\n",
      "Epoch 258/500\n",
      "46/46 [==============================] - 0s 416us/step - loss: 0.0329 - accuracy: 0.9875\n",
      "Epoch 259/500\n",
      "46/46 [==============================] - 0s 415us/step - loss: 0.0636 - accuracy: 0.9719\n",
      "Epoch 260/500\n",
      "46/46 [==============================] - 0s 420us/step - loss: 0.0665 - accuracy: 0.9750\n",
      "Epoch 261/500\n",
      "46/46 [==============================] - 0s 415us/step - loss: 0.0382 - accuracy: 0.9844\n",
      "Epoch 262/500\n",
      "46/46 [==============================] - 0s 416us/step - loss: 0.0358 - accuracy: 0.9875\n",
      "Epoch 263/500\n",
      "46/46 [==============================] - 0s 395us/step - loss: 0.0497 - accuracy: 0.9875\n",
      "Epoch 264/500\n",
      "46/46 [==============================] - 0s 422us/step - loss: 0.0516 - accuracy: 0.9844\n",
      "Epoch 265/500\n",
      "46/46 [==============================] - 0s 409us/step - loss: 0.0650 - accuracy: 0.9656\n",
      "Epoch 266/500\n",
      "46/46 [==============================] - 0s 398us/step - loss: 0.0290 - accuracy: 0.9937\n",
      "Epoch 267/500\n",
      "46/46 [==============================] - 0s 406us/step - loss: 0.0496 - accuracy: 0.9844\n",
      "Epoch 268/500\n",
      "46/46 [==============================] - 0s 401us/step - loss: 0.0694 - accuracy: 0.9750\n",
      "Epoch 269/500\n",
      "46/46 [==============================] - 0s 403us/step - loss: 0.0379 - accuracy: 0.9844\n",
      "Epoch 270/500\n",
      "46/46 [==============================] - 0s 403us/step - loss: 0.0931 - accuracy: 0.9781\n",
      "Epoch 271/500\n",
      "46/46 [==============================] - 0s 418us/step - loss: 0.0384 - accuracy: 0.9937\n",
      "Epoch 272/500\n",
      "46/46 [==============================] - 0s 462us/step - loss: 0.0455 - accuracy: 0.9844\n",
      "Epoch 273/500\n",
      "46/46 [==============================] - 0s 400us/step - loss: 0.0439 - accuracy: 0.9719\n",
      "Epoch 274/500\n",
      "46/46 [==============================] - 0s 416us/step - loss: 0.0395 - accuracy: 0.9844\n",
      "Epoch 275/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 394us/step - loss: 0.0301 - accuracy: 0.9875\n",
      "Epoch 276/500\n",
      "46/46 [==============================] - 0s 404us/step - loss: 0.0420 - accuracy: 0.9875\n",
      "Epoch 277/500\n",
      "46/46 [==============================] - 0s 428us/step - loss: 0.0141 - accuracy: 1.0000\n",
      "Epoch 278/500\n",
      "46/46 [==============================] - 0s 408us/step - loss: 0.0188 - accuracy: 0.9937\n",
      "Epoch 279/500\n",
      "46/46 [==============================] - 0s 410us/step - loss: 0.0216 - accuracy: 0.9969\n",
      "Epoch 280/500\n",
      "46/46 [==============================] - 0s 409us/step - loss: 0.0390 - accuracy: 0.9812\n",
      "Epoch 281/500\n",
      "46/46 [==============================] - 0s 408us/step - loss: 0.0575 - accuracy: 0.9875\n",
      "Epoch 282/500\n",
      "46/46 [==============================] - 0s 401us/step - loss: 0.0647 - accuracy: 0.9781\n",
      "Epoch 283/500\n",
      "46/46 [==============================] - 0s 394us/step - loss: 0.0701 - accuracy: 0.9750\n",
      "Epoch 284/500\n",
      "46/46 [==============================] - 0s 401us/step - loss: 0.0290 - accuracy: 0.9906\n",
      "Epoch 285/500\n",
      "46/46 [==============================] - 0s 427us/step - loss: 0.0406 - accuracy: 0.9844\n",
      "Epoch 286/500\n",
      "46/46 [==============================] - 0s 486us/step - loss: 0.0262 - accuracy: 0.9969\n",
      "Epoch 287/500\n",
      "46/46 [==============================] - 0s 406us/step - loss: 0.0261 - accuracy: 0.9969\n",
      "Epoch 288/500\n",
      "46/46 [==============================] - 0s 400us/step - loss: 0.1055 - accuracy: 0.9719\n",
      "Epoch 289/500\n",
      "46/46 [==============================] - 0s 401us/step - loss: 0.0560 - accuracy: 0.9812\n",
      "Epoch 290/500\n",
      "46/46 [==============================] - 0s 385us/step - loss: 0.0231 - accuracy: 0.9937\n",
      "Epoch 291/500\n",
      "46/46 [==============================] - 0s 412us/step - loss: 0.0326 - accuracy: 0.9969\n",
      "Epoch 292/500\n",
      "46/46 [==============================] - 0s 398us/step - loss: 0.0286 - accuracy: 0.9875\n",
      "Epoch 293/500\n",
      "46/46 [==============================] - 0s 395us/step - loss: 0.0202 - accuracy: 0.9906\n",
      "Epoch 294/500\n",
      "46/46 [==============================] - 0s 404us/step - loss: 0.0188 - accuracy: 0.9906\n",
      "Epoch 295/500\n",
      "46/46 [==============================] - 0s 383us/step - loss: 0.0523 - accuracy: 0.9781\n",
      "Epoch 296/500\n",
      "46/46 [==============================] - 0s 407us/step - loss: 0.0330 - accuracy: 0.9844\n",
      "Epoch 297/500\n",
      "46/46 [==============================] - 0s 394us/step - loss: 0.0283 - accuracy: 0.9906\n",
      "Epoch 298/500\n",
      "46/46 [==============================] - 0s 415us/step - loss: 0.0381 - accuracy: 0.9844\n",
      "Epoch 299/500\n",
      "46/46 [==============================] - 0s 402us/step - loss: 0.0313 - accuracy: 0.9906\n",
      "Epoch 300/500\n",
      "46/46 [==============================] - 0s 411us/step - loss: 0.0564 - accuracy: 0.9781\n",
      "Epoch 301/500\n",
      "46/46 [==============================] - 0s 400us/step - loss: 0.0276 - accuracy: 0.9937\n",
      "Epoch 302/500\n",
      "46/46 [==============================] - 0s 400us/step - loss: 0.0686 - accuracy: 0.9750\n",
      "Epoch 303/500\n",
      "46/46 [==============================] - 0s 400us/step - loss: 0.0602 - accuracy: 0.9750\n",
      "Epoch 304/500\n",
      "46/46 [==============================] - 0s 422us/step - loss: 0.0391 - accuracy: 0.9750\n",
      "Epoch 305/500\n",
      "46/46 [==============================] - 0s 419us/step - loss: 0.0428 - accuracy: 0.9844\n",
      "Epoch 306/500\n",
      "46/46 [==============================] - 0s 412us/step - loss: 0.0365 - accuracy: 0.9844\n",
      "Epoch 307/500\n",
      "46/46 [==============================] - 0s 399us/step - loss: 0.0200 - accuracy: 0.9969\n",
      "Epoch 308/500\n",
      "46/46 [==============================] - 0s 406us/step - loss: 0.0273 - accuracy: 0.9906\n",
      "Epoch 309/500\n",
      "46/46 [==============================] - 0s 399us/step - loss: 0.0489 - accuracy: 0.9844\n",
      "Epoch 310/500\n",
      "46/46 [==============================] - 0s 403us/step - loss: 0.0327 - accuracy: 0.9906\n",
      "Epoch 311/500\n",
      "46/46 [==============================] - 0s 416us/step - loss: 0.0250 - accuracy: 0.9906\n",
      "Epoch 312/500\n",
      "46/46 [==============================] - 0s 399us/step - loss: 0.0500 - accuracy: 0.9812\n",
      "Epoch 313/500\n",
      "46/46 [==============================] - 0s 446us/step - loss: 0.0548 - accuracy: 0.9719\n",
      "Epoch 314/500\n",
      "46/46 [==============================] - 0s 413us/step - loss: 0.0422 - accuracy: 0.9812\n",
      "Epoch 315/500\n",
      "46/46 [==============================] - 0s 416us/step - loss: 0.0364 - accuracy: 0.9875\n",
      "Epoch 316/500\n",
      "46/46 [==============================] - 0s 422us/step - loss: 0.0597 - accuracy: 0.9875\n",
      "Epoch 317/500\n",
      "46/46 [==============================] - 0s 427us/step - loss: 0.0382 - accuracy: 0.9844\n",
      "Epoch 318/500\n",
      "46/46 [==============================] - 0s 422us/step - loss: 0.0315 - accuracy: 0.9844\n",
      "Epoch 319/500\n",
      "46/46 [==============================] - 0s 413us/step - loss: 0.0143 - accuracy: 0.9969\n",
      "Epoch 320/500\n",
      "46/46 [==============================] - 0s 476us/step - loss: 0.0133 - accuracy: 0.9969\n",
      "Epoch 321/500\n",
      "46/46 [==============================] - 0s 399us/step - loss: 0.0071 - accuracy: 1.0000\n",
      "Epoch 322/500\n",
      "46/46 [==============================] - 0s 405us/step - loss: 0.0266 - accuracy: 0.9906\n",
      "Epoch 323/500\n",
      "46/46 [==============================] - 0s 404us/step - loss: 0.0272 - accuracy: 0.9875\n",
      "Epoch 324/500\n",
      "46/46 [==============================] - 0s 408us/step - loss: 0.0248 - accuracy: 0.9906\n",
      "Epoch 325/500\n",
      "46/46 [==============================] - 0s 400us/step - loss: 0.0143 - accuracy: 0.9969\n",
      "Epoch 326/500\n",
      "46/46 [==============================] - 0s 407us/step - loss: 0.0237 - accuracy: 0.9906\n",
      "Epoch 327/500\n",
      "46/46 [==============================] - 0s 406us/step - loss: 0.0563 - accuracy: 0.9812\n",
      "Epoch 328/500\n",
      "46/46 [==============================] - 0s 399us/step - loss: 0.0656 - accuracy: 0.9688\n",
      "Epoch 329/500\n",
      "46/46 [==============================] - 0s 410us/step - loss: 0.0244 - accuracy: 0.9937\n",
      "Epoch 330/500\n",
      "46/46 [==============================] - 0s 408us/step - loss: 0.0141 - accuracy: 0.9937\n",
      "Epoch 331/500\n",
      "46/46 [==============================] - 0s 401us/step - loss: 0.0167 - accuracy: 0.9937\n",
      "Epoch 332/500\n",
      "46/46 [==============================] - 0s 399us/step - loss: 0.0510 - accuracy: 0.9844\n",
      "Epoch 333/500\n",
      "46/46 [==============================] - 0s 401us/step - loss: 0.0240 - accuracy: 0.9906\n",
      "Epoch 334/500\n",
      "46/46 [==============================] - 0s 438us/step - loss: 0.0306 - accuracy: 0.9875\n",
      "Epoch 335/500\n",
      "46/46 [==============================] - 0s 429us/step - loss: 0.0716 - accuracy: 0.9781\n",
      "Epoch 336/500\n",
      "46/46 [==============================] - 0s 409us/step - loss: 0.0363 - accuracy: 0.9875\n",
      "Epoch 337/500\n",
      "46/46 [==============================] - 0s 430us/step - loss: 0.0633 - accuracy: 0.9750\n",
      "Epoch 338/500\n",
      "46/46 [==============================] - 0s 416us/step - loss: 0.0363 - accuracy: 0.9875\n",
      "Epoch 339/500\n",
      "46/46 [==============================] - 0s 407us/step - loss: 0.0171 - accuracy: 0.9937\n",
      "Epoch 340/500\n",
      "46/46 [==============================] - 0s 408us/step - loss: 0.0287 - accuracy: 0.9906\n",
      "Epoch 341/500\n",
      "46/46 [==============================] - 0s 417us/step - loss: 0.0365 - accuracy: 0.9844\n",
      "Epoch 342/500\n",
      "46/46 [==============================] - 0s 428us/step - loss: 0.0557 - accuracy: 0.9750\n",
      "Epoch 343/500\n",
      "46/46 [==============================] - 0s 409us/step - loss: 0.0418 - accuracy: 0.9844\n",
      "Epoch 344/500\n",
      "46/46 [==============================] - 0s 400us/step - loss: 0.0348 - accuracy: 0.9844\n",
      "Epoch 345/500\n",
      "46/46 [==============================] - 0s 430us/step - loss: 0.0298 - accuracy: 0.9937\n",
      "Epoch 346/500\n",
      "46/46 [==============================] - 0s 425us/step - loss: 0.0121 - accuracy: 1.0000\n",
      "Epoch 347/500\n",
      "46/46 [==============================] - 0s 404us/step - loss: 0.0365 - accuracy: 0.9844\n",
      "Epoch 348/500\n",
      "46/46 [==============================] - 0s 412us/step - loss: 0.0216 - accuracy: 0.9906\n",
      "Epoch 349/500\n",
      "46/46 [==============================] - 0s 409us/step - loss: 0.0227 - accuracy: 0.9906\n",
      "Epoch 350/500\n",
      "46/46 [==============================] - 0s 410us/step - loss: 0.0167 - accuracy: 0.9969\n",
      "Epoch 351/500\n",
      "46/46 [==============================] - 0s 404us/step - loss: 0.0069 - accuracy: 1.0000\n",
      "Epoch 352/500\n",
      "46/46 [==============================] - 0s 421us/step - loss: 0.0165 - accuracy: 0.9937\n",
      "Epoch 353/500\n",
      "46/46 [==============================] - 0s 400us/step - loss: 0.0359 - accuracy: 0.9906\n",
      "Epoch 354/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 435us/step - loss: 0.0308 - accuracy: 0.9906\n",
      "Epoch 355/500\n",
      "46/46 [==============================] - 0s 402us/step - loss: 0.0447 - accuracy: 0.9844\n",
      "Epoch 356/500\n",
      "46/46 [==============================] - 0s 407us/step - loss: 0.0167 - accuracy: 0.9969\n",
      "Epoch 357/500\n",
      "46/46 [==============================] - 0s 421us/step - loss: 0.0093 - accuracy: 0.9969\n",
      "Epoch 358/500\n",
      "46/46 [==============================] - 0s 399us/step - loss: 0.0493 - accuracy: 0.9750\n",
      "Epoch 359/500\n",
      "46/46 [==============================] - 0s 411us/step - loss: 0.0163 - accuracy: 0.9969\n",
      "Epoch 360/500\n",
      "46/46 [==============================] - 0s 400us/step - loss: 0.0261 - accuracy: 0.9906\n",
      "Epoch 361/500\n",
      "46/46 [==============================] - 0s 397us/step - loss: 0.0194 - accuracy: 0.9937\n",
      "Epoch 362/500\n",
      "46/46 [==============================] - 0s 395us/step - loss: 0.0173 - accuracy: 0.9937\n",
      "Epoch 363/500\n",
      "46/46 [==============================] - 0s 397us/step - loss: 0.0394 - accuracy: 0.9781\n",
      "Epoch 364/500\n",
      "46/46 [==============================] - 0s 418us/step - loss: 0.0299 - accuracy: 0.9937\n",
      "Epoch 365/500\n",
      "46/46 [==============================] - 0s 394us/step - loss: 0.0456 - accuracy: 0.9875\n",
      "Epoch 366/500\n",
      "46/46 [==============================] - 0s 398us/step - loss: 0.0821 - accuracy: 0.9812\n",
      "Epoch 367/500\n",
      "46/46 [==============================] - 0s 402us/step - loss: 0.0605 - accuracy: 0.9656\n",
      "Epoch 368/500\n",
      "46/46 [==============================] - 0s 401us/step - loss: 0.0974 - accuracy: 0.9594\n",
      "Epoch 369/500\n",
      "46/46 [==============================] - 0s 409us/step - loss: 0.0633 - accuracy: 0.9781\n",
      "Epoch 370/500\n",
      "46/46 [==============================] - 0s 407us/step - loss: 0.0849 - accuracy: 0.9625\n",
      "Epoch 371/500\n",
      "46/46 [==============================] - 0s 415us/step - loss: 0.0154 - accuracy: 1.0000\n",
      "Epoch 372/500\n",
      "46/46 [==============================] - 0s 376us/step - loss: 0.0237 - accuracy: 0.9906\n",
      "Epoch 373/500\n",
      "46/46 [==============================] - 0s 407us/step - loss: 0.0155 - accuracy: 0.9937\n",
      "Epoch 374/500\n",
      "46/46 [==============================] - 0s 402us/step - loss: 0.0571 - accuracy: 0.9781\n",
      "Epoch 375/500\n",
      "46/46 [==============================] - 0s 406us/step - loss: 0.0641 - accuracy: 0.9781\n",
      "Epoch 376/500\n",
      "46/46 [==============================] - 0s 419us/step - loss: 0.0185 - accuracy: 0.9937\n",
      "Epoch 377/500\n",
      "46/46 [==============================] - 0s 403us/step - loss: 0.0765 - accuracy: 0.9719\n",
      "Epoch 378/500\n",
      "46/46 [==============================] - 0s 407us/step - loss: 0.0406 - accuracy: 0.9906\n",
      "Epoch 379/500\n",
      "46/46 [==============================] - 0s 409us/step - loss: 0.0577 - accuracy: 0.9719\n",
      "Epoch 380/500\n",
      "46/46 [==============================] - 0s 403us/step - loss: 0.0668 - accuracy: 0.9750\n",
      "Epoch 381/500\n",
      "46/46 [==============================] - 0s 410us/step - loss: 0.0554 - accuracy: 0.9781\n",
      "Epoch 382/500\n",
      "46/46 [==============================] - 0s 403us/step - loss: 0.0120 - accuracy: 1.0000\n",
      "Epoch 383/500\n",
      "46/46 [==============================] - 0s 401us/step - loss: 0.0049 - accuracy: 1.0000\n",
      "Epoch 384/500\n",
      "46/46 [==============================] - 0s 398us/step - loss: 0.0130 - accuracy: 1.0000\n",
      "Epoch 385/500\n",
      "46/46 [==============================] - 0s 402us/step - loss: 0.0132 - accuracy: 0.9969\n",
      "Epoch 386/500\n",
      "46/46 [==============================] - 0s 396us/step - loss: 0.0264 - accuracy: 0.9906\n",
      "Epoch 387/500\n",
      "46/46 [==============================] - 0s 399us/step - loss: 0.0249 - accuracy: 0.9906\n",
      "Epoch 388/500\n",
      "46/46 [==============================] - 0s 406us/step - loss: 0.0485 - accuracy: 0.9750\n",
      "Epoch 389/500\n",
      "46/46 [==============================] - 0s 402us/step - loss: 0.0503 - accuracy: 0.9844\n",
      "Epoch 390/500\n",
      "46/46 [==============================] - 0s 435us/step - loss: 0.0542 - accuracy: 0.9844\n",
      "Epoch 391/500\n",
      "46/46 [==============================] - 0s 412us/step - loss: 0.0276 - accuracy: 0.9844\n",
      "Epoch 392/500\n",
      "46/46 [==============================] - 0s 409us/step - loss: 0.0194 - accuracy: 0.9969\n",
      "Epoch 393/500\n",
      "46/46 [==============================] - 0s 411us/step - loss: 0.0210 - accuracy: 0.9937\n",
      "Epoch 394/500\n",
      "46/46 [==============================] - 0s 441us/step - loss: 0.0129 - accuracy: 0.9969\n",
      "Epoch 395/500\n",
      "46/46 [==============================] - 0s 409us/step - loss: 0.0137 - accuracy: 0.9937\n",
      "Epoch 396/500\n",
      "46/46 [==============================] - 0s 403us/step - loss: 0.0240 - accuracy: 0.9906\n",
      "Epoch 397/500\n",
      "46/46 [==============================] - 0s 418us/step - loss: 0.0166 - accuracy: 0.9937\n",
      "Epoch 398/500\n",
      "46/46 [==============================] - 0s 417us/step - loss: 0.0142 - accuracy: 0.9969\n",
      "Epoch 399/500\n",
      "46/46 [==============================] - 0s 404us/step - loss: 0.0081 - accuracy: 1.0000\n",
      "Epoch 400/500\n",
      "46/46 [==============================] - 0s 419us/step - loss: 0.0412 - accuracy: 0.9844\n",
      "Epoch 401/500\n",
      "46/46 [==============================] - 0s 410us/step - loss: 0.0108 - accuracy: 0.9969\n",
      "Epoch 402/500\n",
      "46/46 [==============================] - 0s 415us/step - loss: 0.0217 - accuracy: 0.9906\n",
      "Epoch 403/500\n",
      "46/46 [==============================] - 0s 418us/step - loss: 0.0175 - accuracy: 0.9937\n",
      "Epoch 404/500\n",
      "46/46 [==============================] - 0s 404us/step - loss: 0.0416 - accuracy: 0.9906\n",
      "Epoch 405/500\n",
      "46/46 [==============================] - 0s 403us/step - loss: 0.0282 - accuracy: 0.9875\n",
      "Epoch 406/500\n",
      "46/46 [==============================] - 0s 412us/step - loss: 0.1062 - accuracy: 0.9594\n",
      "Epoch 407/500\n",
      "46/46 [==============================] - 0s 426us/step - loss: 0.0604 - accuracy: 0.9812\n",
      "Epoch 408/500\n",
      "46/46 [==============================] - 0s 421us/step - loss: 0.0415 - accuracy: 0.9875\n",
      "Epoch 409/500\n",
      "46/46 [==============================] - 0s 402us/step - loss: 0.0257 - accuracy: 0.9906\n",
      "Epoch 410/500\n",
      "46/46 [==============================] - 0s 399us/step - loss: 0.0459 - accuracy: 0.9844\n",
      "Epoch 411/500\n",
      "46/46 [==============================] - 0s 421us/step - loss: 0.0131 - accuracy: 0.9937\n",
      "Epoch 412/500\n",
      "46/46 [==============================] - 0s 409us/step - loss: 0.0518 - accuracy: 0.9781\n",
      "Epoch 413/500\n",
      "46/46 [==============================] - 0s 404us/step - loss: 0.0351 - accuracy: 0.9781\n",
      "Epoch 414/500\n",
      "46/46 [==============================] - 0s 387us/step - loss: 0.0203 - accuracy: 0.9937\n",
      "Epoch 415/500\n",
      "46/46 [==============================] - 0s 408us/step - loss: 0.0530 - accuracy: 0.9812\n",
      "Epoch 416/500\n",
      "46/46 [==============================] - 0s 396us/step - loss: 0.0399 - accuracy: 0.9844\n",
      "Epoch 417/500\n",
      "46/46 [==============================] - 0s 404us/step - loss: 0.0581 - accuracy: 0.9812\n",
      "Epoch 418/500\n",
      "46/46 [==============================] - 0s 407us/step - loss: 0.0315 - accuracy: 0.9969\n",
      "Epoch 419/500\n",
      "46/46 [==============================] - 0s 396us/step - loss: 0.0128 - accuracy: 0.9969\n",
      "Epoch 420/500\n",
      "46/46 [==============================] - 0s 427us/step - loss: 0.0232 - accuracy: 0.9906\n",
      "Epoch 421/500\n",
      "46/46 [==============================] - 0s 394us/step - loss: 0.0275 - accuracy: 0.9906\n",
      "Epoch 422/500\n",
      "46/46 [==============================] - 0s 411us/step - loss: 0.0131 - accuracy: 0.9937\n",
      "Epoch 423/500\n",
      "46/46 [==============================] - 0s 408us/step - loss: 0.0111 - accuracy: 0.9969\n",
      "Epoch 424/500\n",
      "46/46 [==============================] - 0s 418us/step - loss: 0.0161 - accuracy: 0.9937\n",
      "Epoch 425/500\n",
      "46/46 [==============================] - 0s 419us/step - loss: 0.0327 - accuracy: 0.9906\n",
      "Epoch 426/500\n",
      "46/46 [==============================] - 0s 392us/step - loss: 0.0025 - accuracy: 1.0000\n",
      "Epoch 427/500\n",
      "46/46 [==============================] - 0s 400us/step - loss: 0.0216 - accuracy: 0.9937\n",
      "Epoch 428/500\n",
      "46/46 [==============================] - 0s 417us/step - loss: 0.0211 - accuracy: 0.9937\n",
      "Epoch 429/500\n",
      "46/46 [==============================] - 0s 418us/step - loss: 0.0345 - accuracy: 0.9875\n",
      "Epoch 430/500\n",
      "46/46 [==============================] - 0s 422us/step - loss: 0.0511 - accuracy: 0.9812\n",
      "Epoch 431/500\n",
      "46/46 [==============================] - 0s 400us/step - loss: 0.0155 - accuracy: 0.9969\n",
      "Epoch 432/500\n",
      "46/46 [==============================] - 0s 404us/step - loss: 0.0629 - accuracy: 0.9812\n",
      "Epoch 433/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 400us/step - loss: 0.0488 - accuracy: 0.9906\n",
      "Epoch 434/500\n",
      "46/46 [==============================] - 0s 384us/step - loss: 0.0613 - accuracy: 0.9812\n",
      "Epoch 435/500\n",
      "46/46 [==============================] - 0s 411us/step - loss: 0.0411 - accuracy: 0.9906\n",
      "Epoch 436/500\n",
      "46/46 [==============================] - 0s 397us/step - loss: 0.0529 - accuracy: 0.9812\n",
      "Epoch 437/500\n",
      "46/46 [==============================] - 0s 392us/step - loss: 0.0215 - accuracy: 0.9937\n",
      "Epoch 438/500\n",
      "46/46 [==============================] - 0s 409us/step - loss: 0.0222 - accuracy: 0.9875\n",
      "Epoch 439/500\n",
      "46/46 [==============================] - 0s 397us/step - loss: 0.0181 - accuracy: 0.9906\n",
      "Epoch 440/500\n",
      "46/46 [==============================] - 0s 398us/step - loss: 0.0182 - accuracy: 0.9937\n",
      "Epoch 441/500\n",
      "46/46 [==============================] - 0s 390us/step - loss: 0.0243 - accuracy: 0.9937\n",
      "Epoch 442/500\n",
      "46/46 [==============================] - 0s 393us/step - loss: 0.0221 - accuracy: 0.9906\n",
      "Epoch 443/500\n",
      "46/46 [==============================] - 0s 400us/step - loss: 0.0091 - accuracy: 0.9969\n",
      "Epoch 444/500\n",
      "46/46 [==============================] - 0s 397us/step - loss: 0.0122 - accuracy: 0.9969\n",
      "Epoch 445/500\n",
      "46/46 [==============================] - 0s 396us/step - loss: 0.0205 - accuracy: 0.9937\n",
      "Epoch 446/500\n",
      "46/46 [==============================] - 0s 397us/step - loss: 0.0191 - accuracy: 0.9937\n",
      "Epoch 447/500\n",
      "46/46 [==============================] - 0s 451us/step - loss: 0.0155 - accuracy: 0.9969\n",
      "Epoch 448/500\n",
      "46/46 [==============================] - 0s 413us/step - loss: 0.0220 - accuracy: 0.9906\n",
      "Epoch 449/500\n",
      "46/46 [==============================] - 0s 425us/step - loss: 0.0308 - accuracy: 0.9875\n",
      "Epoch 450/500\n",
      "46/46 [==============================] - 0s 405us/step - loss: 0.0266 - accuracy: 0.9875\n",
      "Epoch 451/500\n",
      "46/46 [==============================] - 0s 406us/step - loss: 0.0590 - accuracy: 0.9750\n",
      "Epoch 452/500\n",
      "46/46 [==============================] - 0s 406us/step - loss: 0.0467 - accuracy: 0.9844\n",
      "Epoch 453/500\n",
      "46/46 [==============================] - 0s 408us/step - loss: 0.1097 - accuracy: 0.9594\n",
      "Epoch 454/500\n",
      "46/46 [==============================] - 0s 409us/step - loss: 0.0466 - accuracy: 0.9781\n",
      "Epoch 455/500\n",
      "46/46 [==============================] - 0s 415us/step - loss: 0.0365 - accuracy: 0.9844\n",
      "Epoch 456/500\n",
      "46/46 [==============================] - 0s 408us/step - loss: 0.0389 - accuracy: 0.9906\n",
      "Epoch 457/500\n",
      "46/46 [==============================] - 0s 412us/step - loss: 0.0154 - accuracy: 0.9969\n",
      "Epoch 458/500\n",
      "46/46 [==============================] - 0s 399us/step - loss: 0.0159 - accuracy: 0.9937\n",
      "Epoch 459/500\n",
      "46/46 [==============================] - 0s 402us/step - loss: 0.0430 - accuracy: 0.9844\n",
      "Epoch 460/500\n",
      "46/46 [==============================] - 0s 426us/step - loss: 0.0365 - accuracy: 0.9812\n",
      "Epoch 461/500\n",
      "46/46 [==============================] - 0s 406us/step - loss: 0.0369 - accuracy: 0.9875\n",
      "Epoch 462/500\n",
      "46/46 [==============================] - 0s 417us/step - loss: 0.0250 - accuracy: 0.9937\n",
      "Epoch 463/500\n",
      "46/46 [==============================] - 0s 398us/step - loss: 0.0145 - accuracy: 0.9969\n",
      "Epoch 464/500\n",
      "46/46 [==============================] - 0s 413us/step - loss: 0.0192 - accuracy: 0.9937\n",
      "Epoch 465/500\n",
      "46/46 [==============================] - 0s 392us/step - loss: 0.0656 - accuracy: 0.9844\n",
      "Epoch 466/500\n",
      "46/46 [==============================] - 0s 406us/step - loss: 0.0208 - accuracy: 0.9937\n",
      "Epoch 467/500\n",
      "46/46 [==============================] - 0s 411us/step - loss: 0.0274 - accuracy: 0.9906\n",
      "Epoch 468/500\n",
      "46/46 [==============================] - 0s 390us/step - loss: 0.0262 - accuracy: 0.9875\n",
      "Epoch 469/500\n",
      "46/46 [==============================] - 0s 424us/step - loss: 0.0594 - accuracy: 0.9844\n",
      "Epoch 470/500\n",
      "46/46 [==============================] - 0s 419us/step - loss: 0.0401 - accuracy: 0.9844\n",
      "Epoch 471/500\n",
      "46/46 [==============================] - 0s 397us/step - loss: 0.0205 - accuracy: 0.9937\n",
      "Epoch 472/500\n",
      "46/46 [==============================] - 0s 409us/step - loss: 0.0215 - accuracy: 0.9969\n",
      "Epoch 473/500\n",
      "46/46 [==============================] - 0s 388us/step - loss: 0.0499 - accuracy: 0.9812\n",
      "Epoch 474/500\n",
      "46/46 [==============================] - 0s 396us/step - loss: 0.1047 - accuracy: 0.9594\n",
      "Epoch 475/500\n",
      "46/46 [==============================] - 0s 382us/step - loss: 0.0688 - accuracy: 0.9719\n",
      "Epoch 476/500\n",
      "46/46 [==============================] - 0s 407us/step - loss: 0.0398 - accuracy: 0.9812\n",
      "Epoch 477/500\n",
      "46/46 [==============================] - 0s 410us/step - loss: 0.0367 - accuracy: 0.9844\n",
      "Epoch 478/500\n",
      "46/46 [==============================] - 0s 401us/step - loss: 0.0440 - accuracy: 0.9812\n",
      "Epoch 479/500\n",
      "46/46 [==============================] - 0s 413us/step - loss: 0.0349 - accuracy: 0.9906\n",
      "Epoch 480/500\n",
      "46/46 [==============================] - 0s 438us/step - loss: 0.0309 - accuracy: 0.9812\n",
      "Epoch 481/500\n",
      "46/46 [==============================] - 0s 449us/step - loss: 0.0351 - accuracy: 0.9875\n",
      "Epoch 482/500\n",
      "46/46 [==============================] - 0s 430us/step - loss: 0.0260 - accuracy: 0.9906\n",
      "Epoch 483/500\n",
      "46/46 [==============================] - 0s 416us/step - loss: 0.0116 - accuracy: 0.9969\n",
      "Epoch 484/500\n",
      "46/46 [==============================] - 0s 406us/step - loss: 0.0343 - accuracy: 0.9875\n",
      "Epoch 485/500\n",
      "46/46 [==============================] - 0s 404us/step - loss: 0.0357 - accuracy: 0.9906\n",
      "Epoch 486/500\n",
      "46/46 [==============================] - 0s 426us/step - loss: 0.0284 - accuracy: 0.9906\n",
      "Epoch 487/500\n",
      "46/46 [==============================] - 0s 410us/step - loss: 0.0326 - accuracy: 0.9844\n",
      "Epoch 488/500\n",
      "46/46 [==============================] - 0s 458us/step - loss: 0.0313 - accuracy: 0.9906\n",
      "Epoch 489/500\n",
      "46/46 [==============================] - 0s 418us/step - loss: 0.0741 - accuracy: 0.9719\n",
      "Epoch 490/500\n",
      "46/46 [==============================] - 0s 403us/step - loss: 0.0385 - accuracy: 0.9906\n",
      "Epoch 491/500\n",
      "46/46 [==============================] - 0s 399us/step - loss: 0.0216 - accuracy: 0.9937\n",
      "Epoch 492/500\n",
      "46/46 [==============================] - 0s 409us/step - loss: 0.0061 - accuracy: 1.0000\n",
      "Epoch 493/500\n",
      "46/46 [==============================] - 0s 406us/step - loss: 0.0105 - accuracy: 0.9937\n",
      "Epoch 494/500\n",
      "46/46 [==============================] - 0s 431us/step - loss: 0.0145 - accuracy: 0.9937\n",
      "Epoch 495/500\n",
      "46/46 [==============================] - 0s 402us/step - loss: 0.0620 - accuracy: 0.9812\n",
      "Epoch 496/500\n",
      "46/46 [==============================] - 0s 409us/step - loss: 0.0201 - accuracy: 0.9937\n",
      "Epoch 497/500\n",
      "46/46 [==============================] - 0s 414us/step - loss: 0.0084 - accuracy: 0.9969\n",
      "Epoch 498/500\n",
      "46/46 [==============================] - 0s 400us/step - loss: 0.0171 - accuracy: 0.9906\n",
      "Epoch 499/500\n",
      "46/46 [==============================] - 0s 388us/step - loss: 0.0270 - accuracy: 0.9906\n",
      "Epoch 500/500\n",
      "46/46 [==============================] - 0s 393us/step - loss: 0.0177 - accuracy: 0.9969\n",
      "Model: \"Sequential-NN\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_6 (Dense)              (None, 42)                1806      \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 42)                0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 256)               11008     \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 5)                 1285      \n",
      "=================================================================\n",
      "Total params: 14,099\n",
      "Trainable params: 14,099\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/500\n",
      "46/46 [==============================] - 0s 397us/step - loss: 1.6079 - accuracy: 0.2469\n",
      "Epoch 2/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 427us/step - loss: 1.4614 - accuracy: 0.4000\n",
      "Epoch 3/500\n",
      "46/46 [==============================] - 0s 409us/step - loss: 1.2879 - accuracy: 0.4750\n",
      "Epoch 4/500\n",
      "46/46 [==============================] - 0s 410us/step - loss: 1.1065 - accuracy: 0.5594\n",
      "Epoch 5/500\n",
      "46/46 [==============================] - 0s 396us/step - loss: 0.9593 - accuracy: 0.6594\n",
      "Epoch 6/500\n",
      "46/46 [==============================] - 0s 381us/step - loss: 0.9619 - accuracy: 0.5719\n",
      "Epoch 7/500\n",
      "46/46 [==============================] - 0s 404us/step - loss: 0.8492 - accuracy: 0.6313\n",
      "Epoch 8/500\n",
      "46/46 [==============================] - 0s 411us/step - loss: 0.7723 - accuracy: 0.7188\n",
      "Epoch 9/500\n",
      "46/46 [==============================] - 0s 426us/step - loss: 0.7057 - accuracy: 0.7250\n",
      "Epoch 10/500\n",
      "46/46 [==============================] - 0s 431us/step - loss: 0.6609 - accuracy: 0.7437\n",
      "Epoch 11/500\n",
      "46/46 [==============================] - 0s 396us/step - loss: 0.6274 - accuracy: 0.7625\n",
      "Epoch 12/500\n",
      "46/46 [==============================] - 0s 424us/step - loss: 0.6062 - accuracy: 0.7219\n",
      "Epoch 13/500\n",
      "46/46 [==============================] - 0s 400us/step - loss: 0.5450 - accuracy: 0.7781\n",
      "Epoch 14/500\n",
      "46/46 [==============================] - 0s 466us/step - loss: 0.5297 - accuracy: 0.7937\n",
      "Epoch 15/500\n",
      "46/46 [==============================] - 0s 388us/step - loss: 0.5049 - accuracy: 0.8031\n",
      "Epoch 16/500\n",
      "46/46 [==============================] - 0s 408us/step - loss: 0.5309 - accuracy: 0.7875\n",
      "Epoch 17/500\n",
      "46/46 [==============================] - 0s 416us/step - loss: 0.4769 - accuracy: 0.8156\n",
      "Epoch 18/500\n",
      "46/46 [==============================] - 0s 411us/step - loss: 0.4541 - accuracy: 0.8125\n",
      "Epoch 19/500\n",
      "46/46 [==============================] - 0s 436us/step - loss: 0.4242 - accuracy: 0.8281\n",
      "Epoch 20/500\n",
      "46/46 [==============================] - 0s 407us/step - loss: 0.4394 - accuracy: 0.8281\n",
      "Epoch 21/500\n",
      "46/46 [==============================] - 0s 417us/step - loss: 0.4130 - accuracy: 0.8250\n",
      "Epoch 22/500\n",
      "46/46 [==============================] - 0s 427us/step - loss: 0.3901 - accuracy: 0.8438\n",
      "Epoch 23/500\n",
      "46/46 [==============================] - 0s 415us/step - loss: 0.3778 - accuracy: 0.8438\n",
      "Epoch 24/500\n",
      "46/46 [==============================] - 0s 407us/step - loss: 0.3608 - accuracy: 0.8656\n",
      "Epoch 25/500\n",
      "46/46 [==============================] - 0s 398us/step - loss: 0.3943 - accuracy: 0.8313\n",
      "Epoch 26/500\n",
      "46/46 [==============================] - 0s 418us/step - loss: 0.3546 - accuracy: 0.8562\n",
      "Epoch 27/500\n",
      "46/46 [==============================] - 0s 413us/step - loss: 0.3678 - accuracy: 0.8344\n",
      "Epoch 28/500\n",
      "46/46 [==============================] - 0s 433us/step - loss: 0.3693 - accuracy: 0.8438\n",
      "Epoch 29/500\n",
      "46/46 [==============================] - 0s 408us/step - loss: 0.3591 - accuracy: 0.8438\n",
      "Epoch 30/500\n",
      "46/46 [==============================] - 0s 417us/step - loss: 0.3448 - accuracy: 0.8562\n",
      "Epoch 31/500\n",
      "46/46 [==============================] - 0s 432us/step - loss: 0.3147 - accuracy: 0.8906\n",
      "Epoch 32/500\n",
      "46/46 [==============================] - 0s 397us/step - loss: 0.3166 - accuracy: 0.8938\n",
      "Epoch 33/500\n",
      "46/46 [==============================] - 0s 402us/step - loss: 0.3145 - accuracy: 0.8906\n",
      "Epoch 34/500\n",
      "46/46 [==============================] - 0s 438us/step - loss: 0.2869 - accuracy: 0.8687\n",
      "Epoch 35/500\n",
      "46/46 [==============================] - 0s 406us/step - loss: 0.2573 - accuracy: 0.8969\n",
      "Epoch 36/500\n",
      "46/46 [==============================] - 0s 413us/step - loss: 0.2777 - accuracy: 0.8969\n",
      "Epoch 37/500\n",
      "46/46 [==============================] - 0s 415us/step - loss: 0.3130 - accuracy: 0.8750\n",
      "Epoch 38/500\n",
      "46/46 [==============================] - 0s 412us/step - loss: 0.2633 - accuracy: 0.9156\n",
      "Epoch 39/500\n",
      "46/46 [==============================] - 0s 399us/step - loss: 0.2630 - accuracy: 0.8906\n",
      "Epoch 40/500\n",
      "46/46 [==============================] - 0s 404us/step - loss: 0.2567 - accuracy: 0.9000\n",
      "Epoch 41/500\n",
      "46/46 [==============================] - 0s 404us/step - loss: 0.2405 - accuracy: 0.8969\n",
      "Epoch 42/500\n",
      "46/46 [==============================] - 0s 399us/step - loss: 0.2179 - accuracy: 0.9187\n",
      "Epoch 43/500\n",
      "46/46 [==============================] - 0s 417us/step - loss: 0.2302 - accuracy: 0.9281\n",
      "Epoch 44/500\n",
      "46/46 [==============================] - 0s 408us/step - loss: 0.2142 - accuracy: 0.9156\n",
      "Epoch 45/500\n",
      "46/46 [==============================] - 0s 393us/step - loss: 0.2465 - accuracy: 0.9156\n",
      "Epoch 46/500\n",
      "46/46 [==============================] - 0s 403us/step - loss: 0.2340 - accuracy: 0.9062\n",
      "Epoch 47/500\n",
      "46/46 [==============================] - 0s 392us/step - loss: 0.2291 - accuracy: 0.9156\n",
      "Epoch 48/500\n",
      "46/46 [==============================] - 0s 405us/step - loss: 0.2307 - accuracy: 0.9000\n",
      "Epoch 49/500\n",
      "46/46 [==============================] - 0s 394us/step - loss: 0.2420 - accuracy: 0.9094\n",
      "Epoch 50/500\n",
      "46/46 [==============================] - 0s 402us/step - loss: 0.2263 - accuracy: 0.9000\n",
      "Epoch 51/500\n",
      "46/46 [==============================] - 0s 407us/step - loss: 0.2148 - accuracy: 0.9187\n",
      "Epoch 52/500\n",
      "46/46 [==============================] - 0s 396us/step - loss: 0.1841 - accuracy: 0.9375\n",
      "Epoch 53/500\n",
      "46/46 [==============================] - 0s 447us/step - loss: 0.1859 - accuracy: 0.9312\n",
      "Epoch 54/500\n",
      "46/46 [==============================] - 0s 403us/step - loss: 0.2297 - accuracy: 0.9250\n",
      "Epoch 55/500\n",
      "46/46 [==============================] - 0s 410us/step - loss: 0.2258 - accuracy: 0.9062\n",
      "Epoch 56/500\n",
      "46/46 [==============================] - 0s 402us/step - loss: 0.2086 - accuracy: 0.9094\n",
      "Epoch 57/500\n",
      "46/46 [==============================] - 0s 401us/step - loss: 0.2172 - accuracy: 0.9031\n",
      "Epoch 58/500\n",
      "46/46 [==============================] - 0s 419us/step - loss: 0.1803 - accuracy: 0.9312\n",
      "Epoch 59/500\n",
      "46/46 [==============================] - 0s 403us/step - loss: 0.1827 - accuracy: 0.9344\n",
      "Epoch 60/500\n",
      "46/46 [==============================] - 0s 406us/step - loss: 0.1893 - accuracy: 0.9281\n",
      "Epoch 61/500\n",
      "46/46 [==============================] - 0s 401us/step - loss: 0.1538 - accuracy: 0.9469\n",
      "Epoch 62/500\n",
      "46/46 [==============================] - 0s 396us/step - loss: 0.1751 - accuracy: 0.9281\n",
      "Epoch 63/500\n",
      "46/46 [==============================] - 0s 412us/step - loss: 0.1767 - accuracy: 0.9312\n",
      "Epoch 64/500\n",
      "46/46 [==============================] - 0s 401us/step - loss: 0.1337 - accuracy: 0.9469\n",
      "Epoch 65/500\n",
      "46/46 [==============================] - 0s 398us/step - loss: 0.1582 - accuracy: 0.9438\n",
      "Epoch 66/500\n",
      "46/46 [==============================] - 0s 425us/step - loss: 0.1429 - accuracy: 0.9594\n",
      "Epoch 67/500\n",
      "46/46 [==============================] - 0s 425us/step - loss: 0.1371 - accuracy: 0.9438\n",
      "Epoch 68/500\n",
      "46/46 [==============================] - 0s 427us/step - loss: 0.1496 - accuracy: 0.9438\n",
      "Epoch 69/500\n",
      "46/46 [==============================] - 0s 411us/step - loss: 0.1460 - accuracy: 0.9469\n",
      "Epoch 70/500\n",
      "46/46 [==============================] - 0s 407us/step - loss: 0.1439 - accuracy: 0.9594\n",
      "Epoch 71/500\n",
      "46/46 [==============================] - 0s 398us/step - loss: 0.1641 - accuracy: 0.9375\n",
      "Epoch 72/500\n",
      "46/46 [==============================] - 0s 399us/step - loss: 0.1199 - accuracy: 0.9531\n",
      "Epoch 73/500\n",
      "46/46 [==============================] - 0s 404us/step - loss: 0.1413 - accuracy: 0.9406\n",
      "Epoch 74/500\n",
      "46/46 [==============================] - 0s 405us/step - loss: 0.1285 - accuracy: 0.9563\n",
      "Epoch 75/500\n",
      "46/46 [==============================] - 0s 423us/step - loss: 0.1292 - accuracy: 0.9625\n",
      "Epoch 76/500\n",
      "46/46 [==============================] - 0s 413us/step - loss: 0.1391 - accuracy: 0.9375\n",
      "Epoch 77/500\n",
      "46/46 [==============================] - 0s 402us/step - loss: 0.1485 - accuracy: 0.9406\n",
      "Epoch 78/500\n",
      "46/46 [==============================] - 0s 417us/step - loss: 0.1483 - accuracy: 0.9438\n",
      "Epoch 79/500\n",
      "46/46 [==============================] - 0s 424us/step - loss: 0.1292 - accuracy: 0.9625\n",
      "Epoch 80/500\n",
      "46/46 [==============================] - 0s 419us/step - loss: 0.1197 - accuracy: 0.9500\n",
      "Epoch 81/500\n",
      "46/46 [==============================] - 0s 405us/step - loss: 0.1215 - accuracy: 0.9469\n",
      "Epoch 82/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 396us/step - loss: 0.1082 - accuracy: 0.9625\n",
      "Epoch 83/500\n",
      "46/46 [==============================] - 0s 445us/step - loss: 0.1116 - accuracy: 0.9594\n",
      "Epoch 84/500\n",
      "46/46 [==============================] - 0s 411us/step - loss: 0.1339 - accuracy: 0.9500\n",
      "Epoch 85/500\n",
      "46/46 [==============================] - 0s 403us/step - loss: 0.1034 - accuracy: 0.9656\n",
      "Epoch 86/500\n",
      "46/46 [==============================] - 0s 401us/step - loss: 0.0936 - accuracy: 0.9656\n",
      "Epoch 87/500\n",
      "46/46 [==============================] - 0s 419us/step - loss: 0.1270 - accuracy: 0.9531\n",
      "Epoch 88/500\n",
      "46/46 [==============================] - 0s 395us/step - loss: 0.1312 - accuracy: 0.9500\n",
      "Epoch 89/500\n",
      "46/46 [==============================] - 0s 417us/step - loss: 0.0992 - accuracy: 0.9594\n",
      "Epoch 90/500\n",
      "46/46 [==============================] - 0s 409us/step - loss: 0.1014 - accuracy: 0.9625\n",
      "Epoch 91/500\n",
      "46/46 [==============================] - 0s 408us/step - loss: 0.1106 - accuracy: 0.9625\n",
      "Epoch 92/500\n",
      "46/46 [==============================] - 0s 400us/step - loss: 0.1039 - accuracy: 0.9625\n",
      "Epoch 93/500\n",
      "46/46 [==============================] - 0s 408us/step - loss: 0.1125 - accuracy: 0.9563\n",
      "Epoch 94/500\n",
      "46/46 [==============================] - 0s 422us/step - loss: 0.1286 - accuracy: 0.9281\n",
      "Epoch 95/500\n",
      "46/46 [==============================] - 0s 439us/step - loss: 0.1108 - accuracy: 0.9656\n",
      "Epoch 96/500\n",
      "46/46 [==============================] - 0s 407us/step - loss: 0.1037 - accuracy: 0.9531\n",
      "Epoch 97/500\n",
      "46/46 [==============================] - 0s 402us/step - loss: 0.0858 - accuracy: 0.9625\n",
      "Epoch 98/500\n",
      "46/46 [==============================] - 0s 404us/step - loss: 0.1142 - accuracy: 0.9563\n",
      "Epoch 99/500\n",
      "46/46 [==============================] - 0s 413us/step - loss: 0.1195 - accuracy: 0.9563\n",
      "Epoch 100/500\n",
      "46/46 [==============================] - 0s 409us/step - loss: 0.1114 - accuracy: 0.9594\n",
      "Epoch 101/500\n",
      "46/46 [==============================] - 0s 436us/step - loss: 0.0831 - accuracy: 0.9656\n",
      "Epoch 102/500\n",
      "46/46 [==============================] - 0s 404us/step - loss: 0.1114 - accuracy: 0.9625\n",
      "Epoch 103/500\n",
      "46/46 [==============================] - 0s 396us/step - loss: 0.0780 - accuracy: 0.9719\n",
      "Epoch 104/500\n",
      "46/46 [==============================] - 0s 403us/step - loss: 0.0872 - accuracy: 0.9656\n",
      "Epoch 105/500\n",
      "46/46 [==============================] - 0s 439us/step - loss: 0.0755 - accuracy: 0.9719\n",
      "Epoch 106/500\n",
      "46/46 [==============================] - 0s 505us/step - loss: 0.0918 - accuracy: 0.9688\n",
      "Epoch 107/500\n",
      "46/46 [==============================] - 0s 440us/step - loss: 0.1218 - accuracy: 0.9531\n",
      "Epoch 108/500\n",
      "46/46 [==============================] - 0s 431us/step - loss: 0.1012 - accuracy: 0.9625\n",
      "Epoch 109/500\n",
      "46/46 [==============================] - 0s 425us/step - loss: 0.0978 - accuracy: 0.9688\n",
      "Epoch 110/500\n",
      "46/46 [==============================] - 0s 411us/step - loss: 0.1136 - accuracy: 0.9594\n",
      "Epoch 111/500\n",
      "46/46 [==============================] - 0s 443us/step - loss: 0.0647 - accuracy: 0.9781\n",
      "Epoch 112/500\n",
      "46/46 [==============================] - 0s 461us/step - loss: 0.0968 - accuracy: 0.9563\n",
      "Epoch 113/500\n",
      "46/46 [==============================] - 0s 417us/step - loss: 0.0855 - accuracy: 0.9688\n",
      "Epoch 114/500\n",
      "46/46 [==============================] - 0s 418us/step - loss: 0.0896 - accuracy: 0.9688\n",
      "Epoch 115/500\n",
      "46/46 [==============================] - 0s 418us/step - loss: 0.0835 - accuracy: 0.9781\n",
      "Epoch 116/500\n",
      "46/46 [==============================] - 0s 409us/step - loss: 0.0943 - accuracy: 0.9625\n",
      "Epoch 117/500\n",
      "46/46 [==============================] - 0s 394us/step - loss: 0.1002 - accuracy: 0.9500\n",
      "Epoch 118/500\n",
      "46/46 [==============================] - 0s 413us/step - loss: 0.0682 - accuracy: 0.9812\n",
      "Epoch 119/500\n",
      "46/46 [==============================] - 0s 401us/step - loss: 0.0920 - accuracy: 0.9625\n",
      "Epoch 120/500\n",
      "46/46 [==============================] - 0s 391us/step - loss: 0.0641 - accuracy: 0.9781\n",
      "Epoch 121/500\n",
      "46/46 [==============================] - 0s 408us/step - loss: 0.0663 - accuracy: 0.9719\n",
      "Epoch 122/500\n",
      "46/46 [==============================] - 0s 386us/step - loss: 0.0814 - accuracy: 0.9688\n",
      "Epoch 123/500\n",
      "46/46 [==============================] - 0s 410us/step - loss: 0.0884 - accuracy: 0.9656\n",
      "Epoch 124/500\n",
      "46/46 [==============================] - 0s 403us/step - loss: 0.0914 - accuracy: 0.9688\n",
      "Epoch 125/500\n",
      "46/46 [==============================] - 0s 414us/step - loss: 0.0714 - accuracy: 0.9719\n",
      "Epoch 126/500\n",
      "46/46 [==============================] - 0s 412us/step - loss: 0.0994 - accuracy: 0.9688\n",
      "Epoch 127/500\n",
      "46/46 [==============================] - 0s 391us/step - loss: 0.0648 - accuracy: 0.9781\n",
      "Epoch 128/500\n",
      "46/46 [==============================] - 0s 429us/step - loss: 0.0758 - accuracy: 0.9688\n",
      "Epoch 129/500\n",
      "46/46 [==============================] - 0s 387us/step - loss: 0.0834 - accuracy: 0.9719\n",
      "Epoch 130/500\n",
      "46/46 [==============================] - 0s 403us/step - loss: 0.0697 - accuracy: 0.9719\n",
      "Epoch 131/500\n",
      "46/46 [==============================] - 0s 400us/step - loss: 0.1064 - accuracy: 0.9531\n",
      "Epoch 132/500\n",
      "46/46 [==============================] - 0s 391us/step - loss: 0.0754 - accuracy: 0.9719\n",
      "Epoch 133/500\n",
      "46/46 [==============================] - 0s 418us/step - loss: 0.0889 - accuracy: 0.9719\n",
      "Epoch 134/500\n",
      "46/46 [==============================] - 0s 385us/step - loss: 0.0933 - accuracy: 0.9625\n",
      "Epoch 135/500\n",
      "46/46 [==============================] - 0s 400us/step - loss: 0.0692 - accuracy: 0.9688\n",
      "Epoch 136/500\n",
      "46/46 [==============================] - 0s 399us/step - loss: 0.0716 - accuracy: 0.9844\n",
      "Epoch 137/500\n",
      "46/46 [==============================] - 0s 413us/step - loss: 0.0543 - accuracy: 0.9844\n",
      "Epoch 138/500\n",
      "46/46 [==============================] - 0s 428us/step - loss: 0.0647 - accuracy: 0.9812\n",
      "Epoch 139/500\n",
      "46/46 [==============================] - 0s 399us/step - loss: 0.0487 - accuracy: 0.9937\n",
      "Epoch 140/500\n",
      "46/46 [==============================] - 0s 399us/step - loss: 0.0717 - accuracy: 0.9781\n",
      "Epoch 141/500\n",
      "46/46 [==============================] - 0s 407us/step - loss: 0.0684 - accuracy: 0.9781\n",
      "Epoch 142/500\n",
      "46/46 [==============================] - 0s 425us/step - loss: 0.0651 - accuracy: 0.9812\n",
      "Epoch 143/500\n",
      "46/46 [==============================] - 0s 432us/step - loss: 0.0530 - accuracy: 0.9750\n",
      "Epoch 144/500\n",
      "46/46 [==============================] - 0s 420us/step - loss: 0.0459 - accuracy: 0.9844\n",
      "Epoch 145/500\n",
      "46/46 [==============================] - 0s 432us/step - loss: 0.0389 - accuracy: 0.9906\n",
      "Epoch 146/500\n",
      "46/46 [==============================] - 0s 420us/step - loss: 0.0497 - accuracy: 0.9812\n",
      "Epoch 147/500\n",
      "46/46 [==============================] - 0s 414us/step - loss: 0.0623 - accuracy: 0.9750\n",
      "Epoch 148/500\n",
      "46/46 [==============================] - 0s 406us/step - loss: 0.0442 - accuracy: 0.9844\n",
      "Epoch 149/500\n",
      "46/46 [==============================] - 0s 455us/step - loss: 0.0772 - accuracy: 0.9750\n",
      "Epoch 150/500\n",
      "46/46 [==============================] - 0s 431us/step - loss: 0.0607 - accuracy: 0.9750\n",
      "Epoch 151/500\n",
      "46/46 [==============================] - 0s 416us/step - loss: 0.0669 - accuracy: 0.9781\n",
      "Epoch 152/500\n",
      "46/46 [==============================] - 0s 429us/step - loss: 0.0768 - accuracy: 0.9750\n",
      "Epoch 153/500\n",
      "46/46 [==============================] - 0s 444us/step - loss: 0.0642 - accuracy: 0.9812\n",
      "Epoch 154/500\n",
      "46/46 [==============================] - 0s 427us/step - loss: 0.0609 - accuracy: 0.9812\n",
      "Epoch 155/500\n",
      "46/46 [==============================] - 0s 414us/step - loss: 0.0828 - accuracy: 0.9656\n",
      "Epoch 156/500\n",
      "46/46 [==============================] - 0s 442us/step - loss: 0.0532 - accuracy: 0.9812\n",
      "Epoch 157/500\n",
      "46/46 [==============================] - 0s 450us/step - loss: 0.0767 - accuracy: 0.9688\n",
      "Epoch 158/500\n",
      "46/46 [==============================] - 0s 428us/step - loss: 0.0391 - accuracy: 0.9875\n",
      "Epoch 159/500\n",
      "46/46 [==============================] - 0s 424us/step - loss: 0.0397 - accuracy: 0.9906\n",
      "Epoch 160/500\n",
      "46/46 [==============================] - 0s 409us/step - loss: 0.1279 - accuracy: 0.9531\n",
      "Epoch 161/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 401us/step - loss: 0.0866 - accuracy: 0.9688\n",
      "Epoch 162/500\n",
      "46/46 [==============================] - 0s 400us/step - loss: 0.0607 - accuracy: 0.9844\n",
      "Epoch 163/500\n",
      "46/46 [==============================] - 0s 382us/step - loss: 0.0347 - accuracy: 0.9906\n",
      "Epoch 164/500\n",
      "46/46 [==============================] - 0s 393us/step - loss: 0.0543 - accuracy: 0.9781\n",
      "Epoch 165/500\n",
      "46/46 [==============================] - 0s 422us/step - loss: 0.1201 - accuracy: 0.9594\n",
      "Epoch 166/500\n",
      "46/46 [==============================] - 0s 440us/step - loss: 0.1009 - accuracy: 0.9625\n",
      "Epoch 167/500\n",
      "46/46 [==============================] - 0s 399us/step - loss: 0.0437 - accuracy: 0.9875\n",
      "Epoch 168/500\n",
      "46/46 [==============================] - 0s 405us/step - loss: 0.0863 - accuracy: 0.9750\n",
      "Epoch 169/500\n",
      "46/46 [==============================] - 0s 409us/step - loss: 0.0411 - accuracy: 0.9875\n",
      "Epoch 170/500\n",
      "46/46 [==============================] - 0s 405us/step - loss: 0.0682 - accuracy: 0.9688\n",
      "Epoch 171/500\n",
      "46/46 [==============================] - 0s 408us/step - loss: 0.0847 - accuracy: 0.9625\n",
      "Epoch 172/500\n",
      "46/46 [==============================] - 0s 440us/step - loss: 0.0657 - accuracy: 0.9812\n",
      "Epoch 173/500\n",
      "46/46 [==============================] - 0s 431us/step - loss: 0.0448 - accuracy: 0.9875\n",
      "Epoch 174/500\n",
      "46/46 [==============================] - 0s 415us/step - loss: 0.0550 - accuracy: 0.9812\n",
      "Epoch 175/500\n",
      "46/46 [==============================] - 0s 395us/step - loss: 0.0804 - accuracy: 0.9750\n",
      "Epoch 176/500\n",
      "46/46 [==============================] - 0s 401us/step - loss: 0.0639 - accuracy: 0.9719\n",
      "Epoch 177/500\n",
      "46/46 [==============================] - 0s 421us/step - loss: 0.0796 - accuracy: 0.9750\n",
      "Epoch 178/500\n",
      "46/46 [==============================] - 0s 409us/step - loss: 0.0761 - accuracy: 0.9719\n",
      "Epoch 179/500\n",
      "46/46 [==============================] - 0s 395us/step - loss: 0.0733 - accuracy: 0.9750\n",
      "Epoch 180/500\n",
      "46/46 [==============================] - 0s 395us/step - loss: 0.0622 - accuracy: 0.9750\n",
      "Epoch 181/500\n",
      "46/46 [==============================] - 0s 410us/step - loss: 0.0297 - accuracy: 0.9937\n",
      "Epoch 182/500\n",
      "46/46 [==============================] - 0s 406us/step - loss: 0.0490 - accuracy: 0.9875\n",
      "Epoch 183/500\n",
      "46/46 [==============================] - 0s 405us/step - loss: 0.0312 - accuracy: 0.9875\n",
      "Epoch 184/500\n",
      "46/46 [==============================] - 0s 396us/step - loss: 0.0324 - accuracy: 0.9875\n",
      "Epoch 185/500\n",
      "46/46 [==============================] - 0s 404us/step - loss: 0.0647 - accuracy: 0.9625\n",
      "Epoch 186/500\n",
      "46/46 [==============================] - 0s 426us/step - loss: 0.0510 - accuracy: 0.9781\n",
      "Epoch 187/500\n",
      "46/46 [==============================] - 0s 419us/step - loss: 0.0311 - accuracy: 0.9937\n",
      "Epoch 188/500\n",
      "46/46 [==============================] - 0s 405us/step - loss: 0.0692 - accuracy: 0.9656\n",
      "Epoch 189/500\n",
      "46/46 [==============================] - 0s 412us/step - loss: 0.0465 - accuracy: 0.9812\n",
      "Epoch 190/500\n",
      "46/46 [==============================] - 0s 416us/step - loss: 0.0436 - accuracy: 0.9844\n",
      "Epoch 191/500\n",
      "46/46 [==============================] - 0s 422us/step - loss: 0.0447 - accuracy: 0.9781\n",
      "Epoch 192/500\n",
      "46/46 [==============================] - 0s 403us/step - loss: 0.0757 - accuracy: 0.9656\n",
      "Epoch 193/500\n",
      "46/46 [==============================] - 0s 417us/step - loss: 0.0426 - accuracy: 0.9844\n",
      "Epoch 194/500\n",
      "46/46 [==============================] - 0s 394us/step - loss: 0.0622 - accuracy: 0.9844\n",
      "Epoch 195/500\n",
      "46/46 [==============================] - 0s 402us/step - loss: 0.0751 - accuracy: 0.9812\n",
      "Epoch 196/500\n",
      "46/46 [==============================] - 0s 404us/step - loss: 0.0911 - accuracy: 0.9688\n",
      "Epoch 197/500\n",
      "46/46 [==============================] - 0s 413us/step - loss: 0.1043 - accuracy: 0.9563\n",
      "Epoch 198/500\n",
      "46/46 [==============================] - 0s 386us/step - loss: 0.0821 - accuracy: 0.9594\n",
      "Epoch 199/500\n",
      "46/46 [==============================] - 0s 400us/step - loss: 0.0275 - accuracy: 0.9937\n",
      "Epoch 200/500\n",
      "46/46 [==============================] - 0s 407us/step - loss: 0.0385 - accuracy: 0.9875\n",
      "Epoch 201/500\n",
      "46/46 [==============================] - 0s 397us/step - loss: 0.0439 - accuracy: 0.9844\n",
      "Epoch 202/500\n",
      "46/46 [==============================] - 0s 403us/step - loss: 0.0548 - accuracy: 0.9750\n",
      "Epoch 203/500\n",
      "46/46 [==============================] - 0s 401us/step - loss: 0.0585 - accuracy: 0.9812\n",
      "Epoch 204/500\n",
      "46/46 [==============================] - 0s 398us/step - loss: 0.0292 - accuracy: 0.9969\n",
      "Epoch 205/500\n",
      "46/46 [==============================] - 0s 404us/step - loss: 0.0334 - accuracy: 0.9906\n",
      "Epoch 206/500\n",
      "46/46 [==============================] - 0s 387us/step - loss: 0.0322 - accuracy: 0.9906\n",
      "Epoch 207/500\n",
      "46/46 [==============================] - 0s 398us/step - loss: 0.0496 - accuracy: 0.9812\n",
      "Epoch 208/500\n",
      "46/46 [==============================] - 0s 408us/step - loss: 0.0460 - accuracy: 0.9875\n",
      "Epoch 209/500\n",
      "46/46 [==============================] - 0s 398us/step - loss: 0.0811 - accuracy: 0.9594\n",
      "Epoch 210/500\n",
      "46/46 [==============================] - 0s 586us/step - loss: 0.0697 - accuracy: 0.9750\n",
      "Epoch 211/500\n",
      "46/46 [==============================] - 0s 556us/step - loss: 0.0257 - accuracy: 0.9937\n",
      "Epoch 212/500\n",
      "46/46 [==============================] - 0s 538us/step - loss: 0.0272 - accuracy: 0.9937\n",
      "Epoch 213/500\n",
      "46/46 [==============================] - 0s 465us/step - loss: 0.0494 - accuracy: 0.9812\n",
      "Epoch 214/500\n",
      "46/46 [==============================] - 0s 699us/step - loss: 0.0775 - accuracy: 0.9750\n",
      "Epoch 215/500\n",
      "46/46 [==============================] - 0s 531us/step - loss: 0.0630 - accuracy: 0.9812\n",
      "Epoch 216/500\n",
      "46/46 [==============================] - 0s 515us/step - loss: 0.0328 - accuracy: 0.9844\n",
      "Epoch 217/500\n",
      "46/46 [==============================] - 0s 602us/step - loss: 0.0584 - accuracy: 0.9688\n",
      "Epoch 218/500\n",
      "46/46 [==============================] - 0s 609us/step - loss: 0.0357 - accuracy: 0.9844\n",
      "Epoch 219/500\n",
      "46/46 [==============================] - 0s 472us/step - loss: 0.0190 - accuracy: 0.9937\n",
      "Epoch 220/500\n",
      "46/46 [==============================] - 0s 467us/step - loss: 0.0447 - accuracy: 0.9875\n",
      "Epoch 221/500\n",
      "46/46 [==============================] - 0s 482us/step - loss: 0.0845 - accuracy: 0.9719\n",
      "Epoch 222/500\n",
      "46/46 [==============================] - 0s 468us/step - loss: 0.0465 - accuracy: 0.9750\n",
      "Epoch 223/500\n",
      "46/46 [==============================] - 0s 419us/step - loss: 0.0411 - accuracy: 0.9875\n",
      "Epoch 224/500\n",
      "46/46 [==============================] - 0s 425us/step - loss: 0.0334 - accuracy: 0.9969\n",
      "Epoch 225/500\n",
      "46/46 [==============================] - 0s 508us/step - loss: 0.0113 - accuracy: 1.0000\n",
      "Epoch 226/500\n",
      "46/46 [==============================] - 0s 483us/step - loss: 0.0271 - accuracy: 0.9906\n",
      "Epoch 227/500\n",
      "46/46 [==============================] - 0s 547us/step - loss: 0.0464 - accuracy: 0.9844\n",
      "Epoch 228/500\n",
      "46/46 [==============================] - 0s 459us/step - loss: 0.0269 - accuracy: 0.9906\n",
      "Epoch 229/500\n",
      "46/46 [==============================] - 0s 412us/step - loss: 0.0291 - accuracy: 0.9906\n",
      "Epoch 230/500\n",
      "46/46 [==============================] - 0s 427us/step - loss: 0.0249 - accuracy: 0.9906\n",
      "Epoch 231/500\n",
      "46/46 [==============================] - 0s 391us/step - loss: 0.0275 - accuracy: 0.9906\n",
      "Epoch 232/500\n",
      "46/46 [==============================] - 0s 404us/step - loss: 0.0137 - accuracy: 0.9969\n",
      "Epoch 233/500\n",
      "46/46 [==============================] - 0s 408us/step - loss: 0.0461 - accuracy: 0.9781\n",
      "Epoch 234/500\n",
      "46/46 [==============================] - 0s 402us/step - loss: 0.0422 - accuracy: 0.9750\n",
      "Epoch 235/500\n",
      "46/46 [==============================] - 0s 468us/step - loss: 0.0592 - accuracy: 0.9750\n",
      "Epoch 236/500\n",
      "46/46 [==============================] - 0s 447us/step - loss: 0.0390 - accuracy: 0.9844\n",
      "Epoch 237/500\n",
      "46/46 [==============================] - 0s 432us/step - loss: 0.0231 - accuracy: 0.9937\n",
      "Epoch 238/500\n",
      "46/46 [==============================] - 0s 440us/step - loss: 0.0487 - accuracy: 0.9750\n",
      "Epoch 239/500\n",
      "46/46 [==============================] - 0s 425us/step - loss: 0.0746 - accuracy: 0.9719\n",
      "Epoch 240/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 445us/step - loss: 0.0532 - accuracy: 0.9875\n",
      "Epoch 241/500\n",
      "46/46 [==============================] - 0s 418us/step - loss: 0.0337 - accuracy: 0.9844\n",
      "Epoch 242/500\n",
      "46/46 [==============================] - 0s 419us/step - loss: 0.0608 - accuracy: 0.9812\n",
      "Epoch 243/500\n",
      "46/46 [==============================] - 0s 420us/step - loss: 0.0401 - accuracy: 0.9812\n",
      "Epoch 244/500\n",
      "46/46 [==============================] - 0s 415us/step - loss: 0.0539 - accuracy: 0.9719\n",
      "Epoch 245/500\n",
      "46/46 [==============================] - 0s 409us/step - loss: 0.0462 - accuracy: 0.9812\n",
      "Epoch 246/500\n",
      "46/46 [==============================] - 0s 398us/step - loss: 0.0672 - accuracy: 0.9656\n",
      "Epoch 247/500\n",
      "46/46 [==============================] - 0s 406us/step - loss: 0.0361 - accuracy: 0.9812\n",
      "Epoch 248/500\n",
      "46/46 [==============================] - 0s 415us/step - loss: 0.1035 - accuracy: 0.9625\n",
      "Epoch 249/500\n",
      "46/46 [==============================] - 0s 413us/step - loss: 0.1091 - accuracy: 0.9688\n",
      "Epoch 250/500\n",
      "46/46 [==============================] - 0s 418us/step - loss: 0.0452 - accuracy: 0.9844\n",
      "Epoch 251/500\n",
      "46/46 [==============================] - 0s 428us/step - loss: 0.0220 - accuracy: 0.9937\n",
      "Epoch 252/500\n",
      "46/46 [==============================] - 0s 429us/step - loss: 0.0227 - accuracy: 0.9906\n",
      "Epoch 253/500\n",
      "46/46 [==============================] - 0s 418us/step - loss: 0.0352 - accuracy: 0.9875\n",
      "Epoch 254/500\n",
      "46/46 [==============================] - 0s 404us/step - loss: 0.0307 - accuracy: 0.9906\n",
      "Epoch 255/500\n",
      "46/46 [==============================] - 0s 404us/step - loss: 0.0506 - accuracy: 0.9781\n",
      "Epoch 256/500\n",
      "46/46 [==============================] - 0s 436us/step - loss: 0.0418 - accuracy: 0.9812\n",
      "Epoch 257/500\n",
      "46/46 [==============================] - 0s 406us/step - loss: 0.0421 - accuracy: 0.9906\n",
      "Epoch 258/500\n",
      "46/46 [==============================] - 0s 429us/step - loss: 0.0378 - accuracy: 0.9875\n",
      "Epoch 259/500\n",
      "46/46 [==============================] - 0s 456us/step - loss: 0.0697 - accuracy: 0.9781\n",
      "Epoch 260/500\n",
      "46/46 [==============================] - 0s 415us/step - loss: 0.0697 - accuracy: 0.9719\n",
      "Epoch 261/500\n",
      "46/46 [==============================] - 0s 413us/step - loss: 0.0656 - accuracy: 0.9750\n",
      "Epoch 262/500\n",
      "46/46 [==============================] - 0s 409us/step - loss: 0.0834 - accuracy: 0.9781\n",
      "Epoch 263/500\n",
      "46/46 [==============================] - 0s 423us/step - loss: 0.0480 - accuracy: 0.9719\n",
      "Epoch 264/500\n",
      "46/46 [==============================] - 0s 421us/step - loss: 0.0698 - accuracy: 0.9750\n",
      "Epoch 265/500\n",
      "46/46 [==============================] - 0s 402us/step - loss: 0.0528 - accuracy: 0.9844\n",
      "Epoch 266/500\n",
      "46/46 [==============================] - 0s 408us/step - loss: 0.0337 - accuracy: 0.9906\n",
      "Epoch 267/500\n",
      "46/46 [==============================] - 0s 471us/step - loss: 0.0213 - accuracy: 0.9906\n",
      "Epoch 268/500\n",
      "46/46 [==============================] - 0s 418us/step - loss: 0.0409 - accuracy: 0.9844\n",
      "Epoch 269/500\n",
      "46/46 [==============================] - 0s 407us/step - loss: 0.0994 - accuracy: 0.9781\n",
      "Epoch 270/500\n",
      "46/46 [==============================] - 0s 408us/step - loss: 0.0255 - accuracy: 0.9937\n",
      "Epoch 271/500\n",
      "46/46 [==============================] - 0s 424us/step - loss: 0.0434 - accuracy: 0.9875\n",
      "Epoch 272/500\n",
      "46/46 [==============================] - 0s 417us/step - loss: 0.0464 - accuracy: 0.9750\n",
      "Epoch 273/500\n",
      "46/46 [==============================] - 0s 460us/step - loss: 0.0282 - accuracy: 0.9906\n",
      "Epoch 274/500\n",
      "46/46 [==============================] - 0s 427us/step - loss: 0.0357 - accuracy: 0.9844\n",
      "Epoch 275/500\n",
      "46/46 [==============================] - 0s 431us/step - loss: 0.0218 - accuracy: 0.9875\n",
      "Epoch 276/500\n",
      "46/46 [==============================] - 0s 413us/step - loss: 0.0259 - accuracy: 0.9906\n",
      "Epoch 277/500\n",
      "46/46 [==============================] - 0s 404us/step - loss: 0.0310 - accuracy: 0.9844\n",
      "Epoch 278/500\n",
      "46/46 [==============================] - 0s 420us/step - loss: 0.0193 - accuracy: 0.9937\n",
      "Epoch 279/500\n",
      "46/46 [==============================] - 0s 412us/step - loss: 0.0422 - accuracy: 0.9812\n",
      "Epoch 280/500\n",
      "46/46 [==============================] - 0s 414us/step - loss: 0.0311 - accuracy: 0.9875\n",
      "Epoch 281/500\n",
      "46/46 [==============================] - 0s 430us/step - loss: 0.0424 - accuracy: 0.9844\n",
      "Epoch 282/500\n",
      "46/46 [==============================] - 0s 466us/step - loss: 0.0315 - accuracy: 0.9906\n",
      "Epoch 283/500\n",
      "46/46 [==============================] - 0s 423us/step - loss: 0.0250 - accuracy: 0.9906\n",
      "Epoch 284/500\n",
      "46/46 [==============================] - 0s 436us/step - loss: 0.0903 - accuracy: 0.9719\n",
      "Epoch 285/500\n",
      "46/46 [==============================] - 0s 438us/step - loss: 0.0199 - accuracy: 0.9937\n",
      "Epoch 286/500\n",
      "46/46 [==============================] - 0s 437us/step - loss: 0.0239 - accuracy: 0.9906\n",
      "Epoch 287/500\n",
      "46/46 [==============================] - 0s 421us/step - loss: 0.0308 - accuracy: 0.9875\n",
      "Epoch 288/500\n",
      "46/46 [==============================] - 0s 416us/step - loss: 0.0210 - accuracy: 0.9906\n",
      "Epoch 289/500\n",
      "46/46 [==============================] - 0s 454us/step - loss: 0.0164 - accuracy: 0.9969\n",
      "Epoch 290/500\n",
      "46/46 [==============================] - 0s 396us/step - loss: 0.0480 - accuracy: 0.9812\n",
      "Epoch 291/500\n",
      "46/46 [==============================] - 0s 406us/step - loss: 0.0523 - accuracy: 0.9844\n",
      "Epoch 292/500\n",
      "46/46 [==============================] - 0s 418us/step - loss: 0.0505 - accuracy: 0.9750\n",
      "Epoch 293/500\n",
      "46/46 [==============================] - 0s 414us/step - loss: 0.0944 - accuracy: 0.9656\n",
      "Epoch 294/500\n",
      "46/46 [==============================] - 0s 422us/step - loss: 0.0610 - accuracy: 0.9844\n",
      "Epoch 295/500\n",
      "46/46 [==============================] - 0s 443us/step - loss: 0.0247 - accuracy: 0.9906\n",
      "Epoch 296/500\n",
      "46/46 [==============================] - 0s 444us/step - loss: 0.0389 - accuracy: 0.9812\n",
      "Epoch 297/500\n",
      "46/46 [==============================] - 0s 434us/step - loss: 0.0593 - accuracy: 0.9812\n",
      "Epoch 298/500\n",
      "46/46 [==============================] - 0s 448us/step - loss: 0.0297 - accuracy: 0.9937\n",
      "Epoch 299/500\n",
      "46/46 [==============================] - 0s 465us/step - loss: 0.0190 - accuracy: 0.9969\n",
      "Epoch 300/500\n",
      "46/46 [==============================] - 0s 428us/step - loss: 0.0184 - accuracy: 0.9969\n",
      "Epoch 301/500\n",
      "46/46 [==============================] - 0s 403us/step - loss: 0.0197 - accuracy: 0.9937\n",
      "Epoch 302/500\n",
      "46/46 [==============================] - 0s 446us/step - loss: 0.0191 - accuracy: 0.9937\n",
      "Epoch 303/500\n",
      "46/46 [==============================] - 0s 427us/step - loss: 0.0538 - accuracy: 0.9812\n",
      "Epoch 304/500\n",
      "46/46 [==============================] - 0s 404us/step - loss: 0.0435 - accuracy: 0.9750\n",
      "Epoch 305/500\n",
      "46/46 [==============================] - 0s 411us/step - loss: 0.0655 - accuracy: 0.9844\n",
      "Epoch 306/500\n",
      "46/46 [==============================] - 0s 429us/step - loss: 0.0221 - accuracy: 0.9937\n",
      "Epoch 307/500\n",
      "46/46 [==============================] - 0s 415us/step - loss: 0.0219 - accuracy: 0.9937\n",
      "Epoch 308/500\n",
      "46/46 [==============================] - 0s 420us/step - loss: 0.0338 - accuracy: 0.9906\n",
      "Epoch 309/500\n",
      "46/46 [==============================] - 0s 414us/step - loss: 0.0331 - accuracy: 0.9844\n",
      "Epoch 310/500\n",
      "46/46 [==============================] - 0s 429us/step - loss: 0.0274 - accuracy: 0.9969\n",
      "Epoch 311/500\n",
      "46/46 [==============================] - 0s 401us/step - loss: 0.0112 - accuracy: 0.9969\n",
      "Epoch 312/500\n",
      "46/46 [==============================] - 0s 417us/step - loss: 0.0229 - accuracy: 0.9969\n",
      "Epoch 313/500\n",
      "46/46 [==============================] - 0s 411us/step - loss: 0.0438 - accuracy: 0.9812\n",
      "Epoch 314/500\n",
      "46/46 [==============================] - 0s 424us/step - loss: 0.0468 - accuracy: 0.9812\n",
      "Epoch 315/500\n",
      "46/46 [==============================] - 0s 421us/step - loss: 0.0572 - accuracy: 0.9719\n",
      "Epoch 316/500\n",
      "46/46 [==============================] - 0s 402us/step - loss: 0.0992 - accuracy: 0.9625\n",
      "Epoch 317/500\n",
      "46/46 [==============================] - 0s 407us/step - loss: 0.0508 - accuracy: 0.9844\n",
      "Epoch 318/500\n",
      "46/46 [==============================] - 0s 402us/step - loss: 0.0545 - accuracy: 0.9750\n",
      "Epoch 319/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 431us/step - loss: 0.0354 - accuracy: 0.9844\n",
      "Epoch 320/500\n",
      "46/46 [==============================] - 0s 437us/step - loss: 0.0247 - accuracy: 0.9937\n",
      "Epoch 321/500\n",
      "46/46 [==============================] - 0s 405us/step - loss: 0.0191 - accuracy: 0.9937\n",
      "Epoch 322/500\n",
      "46/46 [==============================] - 0s 428us/step - loss: 0.0408 - accuracy: 0.9875\n",
      "Epoch 323/500\n",
      "46/46 [==============================] - 0s 458us/step - loss: 0.0458 - accuracy: 0.9812\n",
      "Epoch 324/500\n",
      "46/46 [==============================] - 0s 422us/step - loss: 0.0388 - accuracy: 0.9844\n",
      "Epoch 325/500\n",
      "46/46 [==============================] - 0s 417us/step - loss: 0.0335 - accuracy: 0.9844\n",
      "Epoch 326/500\n",
      "46/46 [==============================] - 0s 431us/step - loss: 0.0385 - accuracy: 0.9875\n",
      "Epoch 327/500\n",
      "46/46 [==============================] - 0s 418us/step - loss: 0.0122 - accuracy: 0.9969\n",
      "Epoch 328/500\n",
      "46/46 [==============================] - 0s 403us/step - loss: 0.0223 - accuracy: 0.9906\n",
      "Epoch 329/500\n",
      "46/46 [==============================] - 0s 416us/step - loss: 0.0212 - accuracy: 0.9937\n",
      "Epoch 330/500\n",
      "46/46 [==============================] - 0s 413us/step - loss: 0.0918 - accuracy: 0.9688\n",
      "Epoch 331/500\n",
      "46/46 [==============================] - 0s 421us/step - loss: 0.0663 - accuracy: 0.9750\n",
      "Epoch 332/500\n",
      "46/46 [==============================] - 0s 414us/step - loss: 0.0700 - accuracy: 0.9625\n",
      "Epoch 333/500\n",
      "46/46 [==============================] - 0s 425us/step - loss: 0.0332 - accuracy: 0.9875\n",
      "Epoch 334/500\n",
      "46/46 [==============================] - 0s 421us/step - loss: 0.0752 - accuracy: 0.9688\n",
      "Epoch 335/500\n",
      "46/46 [==============================] - 0s 405us/step - loss: 0.0251 - accuracy: 0.9937\n",
      "Epoch 336/500\n",
      "46/46 [==============================] - 0s 401us/step - loss: 0.0342 - accuracy: 0.9875\n",
      "Epoch 337/500\n",
      "46/46 [==============================] - 0s 397us/step - loss: 0.0346 - accuracy: 0.9844\n",
      "Epoch 338/500\n",
      "46/46 [==============================] - 0s 408us/step - loss: 0.0192 - accuracy: 0.9937\n",
      "Epoch 339/500\n",
      "46/46 [==============================] - 0s 398us/step - loss: 0.0401 - accuracy: 0.9937\n",
      "Epoch 340/500\n",
      "46/46 [==============================] - 0s 379us/step - loss: 0.0232 - accuracy: 0.9937\n",
      "Epoch 341/500\n",
      "46/46 [==============================] - 0s 395us/step - loss: 0.0344 - accuracy: 0.9906\n",
      "Epoch 342/500\n",
      "46/46 [==============================] - 0s 407us/step - loss: 0.0374 - accuracy: 0.9812\n",
      "Epoch 343/500\n",
      "46/46 [==============================] - 0s 493us/step - loss: 0.0251 - accuracy: 0.9906\n",
      "Epoch 344/500\n",
      "46/46 [==============================] - 0s 398us/step - loss: 0.0334 - accuracy: 0.9906\n",
      "Epoch 345/500\n",
      "46/46 [==============================] - 0s 385us/step - loss: 0.0329 - accuracy: 0.9812\n",
      "Epoch 346/500\n",
      "46/46 [==============================] - 0s 396us/step - loss: 0.0199 - accuracy: 0.9937\n",
      "Epoch 347/500\n",
      "46/46 [==============================] - 0s 410us/step - loss: 0.0090 - accuracy: 1.0000\n",
      "Epoch 348/500\n",
      "46/46 [==============================] - 0s 437us/step - loss: 0.0054 - accuracy: 1.0000\n",
      "Epoch 349/500\n",
      "46/46 [==============================] - 0s 442us/step - loss: 0.0067 - accuracy: 0.9969\n",
      "Epoch 350/500\n",
      "46/46 [==============================] - 0s 418us/step - loss: 0.0073 - accuracy: 0.9969\n",
      "Epoch 351/500\n",
      "46/46 [==============================] - 0s 419us/step - loss: 0.0113 - accuracy: 0.9906\n",
      "Epoch 352/500\n",
      "46/46 [==============================] - 0s 420us/step - loss: 0.0326 - accuracy: 0.9875\n",
      "Epoch 353/500\n",
      "46/46 [==============================] - 0s 404us/step - loss: 0.0037 - accuracy: 1.0000\n",
      "Epoch 354/500\n",
      "46/46 [==============================] - 0s 429us/step - loss: 0.0233 - accuracy: 0.9906\n",
      "Epoch 355/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.0662 - accuracy: 0.9750\n",
      "Epoch 356/500\n",
      "46/46 [==============================] - 0s 577us/step - loss: 0.0675 - accuracy: 0.9781\n",
      "Epoch 357/500\n",
      "46/46 [==============================] - 0s 443us/step - loss: 0.0296 - accuracy: 0.9844\n",
      "Epoch 358/500\n",
      "46/46 [==============================] - 0s 435us/step - loss: 0.0241 - accuracy: 0.9875\n",
      "Epoch 359/500\n",
      "46/46 [==============================] - 0s 396us/step - loss: 0.0100 - accuracy: 0.9969\n",
      "Epoch 360/500\n",
      "46/46 [==============================] - 0s 397us/step - loss: 0.0376 - accuracy: 0.9937\n",
      "Epoch 361/500\n",
      "46/46 [==============================] - 0s 397us/step - loss: 0.0180 - accuracy: 0.9969\n",
      "Epoch 362/500\n",
      "46/46 [==============================] - 0s 422us/step - loss: 0.0108 - accuracy: 0.9969\n",
      "Epoch 363/500\n",
      "46/46 [==============================] - 0s 387us/step - loss: 0.0189 - accuracy: 0.9937\n",
      "Epoch 364/500\n",
      "46/46 [==============================] - 0s 403us/step - loss: 0.0228 - accuracy: 0.9906\n",
      "Epoch 365/500\n",
      "46/46 [==============================] - 0s 392us/step - loss: 0.0328 - accuracy: 0.9906\n",
      "Epoch 366/500\n",
      "46/46 [==============================] - 0s 391us/step - loss: 0.0174 - accuracy: 0.9906\n",
      "Epoch 367/500\n",
      "46/46 [==============================] - 0s 385us/step - loss: 0.0952 - accuracy: 0.9750\n",
      "Epoch 368/500\n",
      "46/46 [==============================] - 0s 398us/step - loss: 0.0969 - accuracy: 0.9688\n",
      "Epoch 369/500\n",
      "46/46 [==============================] - 0s 385us/step - loss: 0.0479 - accuracy: 0.9750\n",
      "Epoch 370/500\n",
      "46/46 [==============================] - 0s 394us/step - loss: 0.0577 - accuracy: 0.9781\n",
      "Epoch 371/500\n",
      "46/46 [==============================] - 0s 377us/step - loss: 0.0425 - accuracy: 0.9812\n",
      "Epoch 372/500\n",
      "46/46 [==============================] - 0s 418us/step - loss: 0.0345 - accuracy: 0.9844\n",
      "Epoch 373/500\n",
      "46/46 [==============================] - 0s 400us/step - loss: 0.0495 - accuracy: 0.9812\n",
      "Epoch 374/500\n",
      "46/46 [==============================] - 0s 399us/step - loss: 0.0636 - accuracy: 0.9688\n",
      "Epoch 375/500\n",
      "46/46 [==============================] - 0s 391us/step - loss: 0.0183 - accuracy: 0.9937\n",
      "Epoch 376/500\n",
      "46/46 [==============================] - 0s 400us/step - loss: 0.0276 - accuracy: 0.9875\n",
      "Epoch 377/500\n",
      "46/46 [==============================] - 0s 401us/step - loss: 0.0402 - accuracy: 0.9781\n",
      "Epoch 378/500\n",
      "46/46 [==============================] - 0s 402us/step - loss: 0.0363 - accuracy: 0.9844\n",
      "Epoch 379/500\n",
      "46/46 [==============================] - 0s 407us/step - loss: 0.0554 - accuracy: 0.9812\n",
      "Epoch 380/500\n",
      "46/46 [==============================] - 0s 401us/step - loss: 0.0481 - accuracy: 0.9781\n",
      "Epoch 381/500\n",
      "46/46 [==============================] - 0s 425us/step - loss: 0.0530 - accuracy: 0.9812\n",
      "Epoch 382/500\n",
      "46/46 [==============================] - 0s 424us/step - loss: 0.0200 - accuracy: 0.9937\n",
      "Epoch 383/500\n",
      "46/46 [==============================] - 0s 391us/step - loss: 0.0362 - accuracy: 0.9844\n",
      "Epoch 384/500\n",
      "46/46 [==============================] - 0s 387us/step - loss: 0.0348 - accuracy: 0.9844\n",
      "Epoch 385/500\n",
      "46/46 [==============================] - 0s 398us/step - loss: 0.0412 - accuracy: 0.9750\n",
      "Epoch 386/500\n",
      "46/46 [==============================] - 0s 391us/step - loss: 0.0141 - accuracy: 0.9906\n",
      "Epoch 387/500\n",
      "46/46 [==============================] - 0s 390us/step - loss: 0.0359 - accuracy: 0.9844\n",
      "Epoch 388/500\n",
      "46/46 [==============================] - 0s 400us/step - loss: 0.0411 - accuracy: 0.9875\n",
      "Epoch 389/500\n",
      "46/46 [==============================] - 0s 401us/step - loss: 0.0450 - accuracy: 0.9844\n",
      "Epoch 390/500\n",
      "46/46 [==============================] - 0s 410us/step - loss: 0.0360 - accuracy: 0.9906\n",
      "Epoch 391/500\n",
      "46/46 [==============================] - 0s 393us/step - loss: 0.0136 - accuracy: 1.0000\n",
      "Epoch 392/500\n",
      "46/46 [==============================] - 0s 415us/step - loss: 0.0228 - accuracy: 0.9844\n",
      "Epoch 393/500\n",
      "46/46 [==============================] - 0s 400us/step - loss: 0.0295 - accuracy: 0.9906\n",
      "Epoch 394/500\n",
      "46/46 [==============================] - 0s 394us/step - loss: 0.0384 - accuracy: 0.9875\n",
      "Epoch 395/500\n",
      "46/46 [==============================] - 0s 434us/step - loss: 0.0478 - accuracy: 0.9781\n",
      "Epoch 396/500\n",
      "46/46 [==============================] - 0s 396us/step - loss: 0.0310 - accuracy: 0.9906\n",
      "Epoch 397/500\n",
      "46/46 [==============================] - 0s 434us/step - loss: 0.0278 - accuracy: 0.9844\n",
      "Epoch 398/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 438us/step - loss: 0.0377 - accuracy: 0.9875\n",
      "Epoch 399/500\n",
      "46/46 [==============================] - 0s 445us/step - loss: 0.0320 - accuracy: 0.9812\n",
      "Epoch 400/500\n",
      "46/46 [==============================] - 0s 450us/step - loss: 0.0249 - accuracy: 0.9937\n",
      "Epoch 401/500\n",
      "46/46 [==============================] - 0s 577us/step - loss: 0.0361 - accuracy: 0.9875\n",
      "Epoch 402/500\n",
      "46/46 [==============================] - 0s 642us/step - loss: 0.0594 - accuracy: 0.9844\n",
      "Epoch 403/500\n",
      "46/46 [==============================] - 0s 473us/step - loss: 0.0238 - accuracy: 0.9937\n",
      "Epoch 404/500\n",
      "46/46 [==============================] - 0s 421us/step - loss: 0.0191 - accuracy: 0.9906\n",
      "Epoch 405/500\n",
      "46/46 [==============================] - 0s 416us/step - loss: 0.0196 - accuracy: 0.9906\n",
      "Epoch 406/500\n",
      "46/46 [==============================] - 0s 414us/step - loss: 0.0614 - accuracy: 0.9719\n",
      "Epoch 407/500\n",
      "46/46 [==============================] - 0s 460us/step - loss: 0.0169 - accuracy: 0.9969\n",
      "Epoch 408/500\n",
      "46/46 [==============================] - 0s 474us/step - loss: 0.0633 - accuracy: 0.9812\n",
      "Epoch 409/500\n",
      "46/46 [==============================] - 0s 496us/step - loss: 0.0273 - accuracy: 0.9937\n",
      "Epoch 410/500\n",
      "46/46 [==============================] - 0s 497us/step - loss: 0.0307 - accuracy: 0.9844\n",
      "Epoch 411/500\n",
      "46/46 [==============================] - 0s 458us/step - loss: 0.0623 - accuracy: 0.9875\n",
      "Epoch 412/500\n",
      "46/46 [==============================] - 0s 465us/step - loss: 0.0494 - accuracy: 0.9812\n",
      "Epoch 413/500\n",
      "46/46 [==============================] - 0s 401us/step - loss: 0.0214 - accuracy: 0.9937\n",
      "Epoch 414/500\n",
      "46/46 [==============================] - 0s 455us/step - loss: 0.0207 - accuracy: 0.9906\n",
      "Epoch 415/500\n",
      "46/46 [==============================] - 0s 459us/step - loss: 0.0408 - accuracy: 0.9844\n",
      "Epoch 416/500\n",
      "46/46 [==============================] - 0s 456us/step - loss: 0.0264 - accuracy: 0.9906\n",
      "Epoch 417/500\n",
      "46/46 [==============================] - 0s 414us/step - loss: 0.0438 - accuracy: 0.9844\n",
      "Epoch 418/500\n",
      "46/46 [==============================] - 0s 428us/step - loss: 0.0280 - accuracy: 0.9844\n",
      "Epoch 419/500\n",
      "46/46 [==============================] - 0s 448us/step - loss: 0.0608 - accuracy: 0.9906\n",
      "Epoch 420/500\n",
      "46/46 [==============================] - 0s 417us/step - loss: 0.0179 - accuracy: 0.9906\n",
      "Epoch 421/500\n",
      "46/46 [==============================] - 0s 427us/step - loss: 0.0206 - accuracy: 0.9937\n",
      "Epoch 422/500\n",
      "46/46 [==============================] - 0s 406us/step - loss: 0.0421 - accuracy: 0.9875\n",
      "Epoch 423/500\n",
      "46/46 [==============================] - 0s 470us/step - loss: 0.0369 - accuracy: 0.9906\n",
      "Epoch 424/500\n",
      "46/46 [==============================] - 0s 477us/step - loss: 0.0224 - accuracy: 0.9844\n",
      "Epoch 425/500\n",
      "46/46 [==============================] - 0s 440us/step - loss: 0.0416 - accuracy: 0.9781\n",
      "Epoch 426/500\n",
      "46/46 [==============================] - 0s 454us/step - loss: 0.0378 - accuracy: 0.9781\n",
      "Epoch 427/500\n",
      "46/46 [==============================] - 0s 447us/step - loss: 0.0370 - accuracy: 0.9906\n",
      "Epoch 428/500\n",
      "46/46 [==============================] - 0s 435us/step - loss: 0.0539 - accuracy: 0.9844\n",
      "Epoch 429/500\n",
      "46/46 [==============================] - 0s 464us/step - loss: 0.0908 - accuracy: 0.9750\n",
      "Epoch 430/500\n",
      "46/46 [==============================] - 0s 438us/step - loss: 0.0579 - accuracy: 0.9844\n",
      "Epoch 431/500\n",
      "46/46 [==============================] - 0s 437us/step - loss: 0.0427 - accuracy: 0.9844\n",
      "Epoch 432/500\n",
      "46/46 [==============================] - 0s 440us/step - loss: 0.0279 - accuracy: 0.9875\n",
      "Epoch 433/500\n",
      "46/46 [==============================] - 0s 428us/step - loss: 0.0134 - accuracy: 1.0000\n",
      "Epoch 434/500\n",
      "46/46 [==============================] - 0s 402us/step - loss: 0.0485 - accuracy: 0.9969\n",
      "Epoch 435/500\n",
      "46/46 [==============================] - 0s 420us/step - loss: 0.0686 - accuracy: 0.9844\n",
      "Epoch 436/500\n",
      "46/46 [==============================] - 0s 424us/step - loss: 0.0476 - accuracy: 0.9750\n",
      "Epoch 437/500\n",
      "46/46 [==============================] - 0s 446us/step - loss: 0.0592 - accuracy: 0.9750\n",
      "Epoch 438/500\n",
      "46/46 [==============================] - 0s 438us/step - loss: 0.0396 - accuracy: 0.9750\n",
      "Epoch 439/500\n",
      "46/46 [==============================] - 0s 437us/step - loss: 0.0328 - accuracy: 0.9906\n",
      "Epoch 440/500\n",
      "46/46 [==============================] - 0s 446us/step - loss: 0.0109 - accuracy: 1.0000\n",
      "Epoch 441/500\n",
      "46/46 [==============================] - 0s 429us/step - loss: 0.0097 - accuracy: 0.9969\n",
      "Epoch 442/500\n",
      "46/46 [==============================] - 0s 406us/step - loss: 0.0202 - accuracy: 0.9875\n",
      "Epoch 443/500\n",
      "46/46 [==============================] - 0s 417us/step - loss: 0.0183 - accuracy: 0.9906\n",
      "Epoch 444/500\n",
      "46/46 [==============================] - 0s 429us/step - loss: 0.0148 - accuracy: 0.9969\n",
      "Epoch 445/500\n",
      "46/46 [==============================] - 0s 476us/step - loss: 0.0153 - accuracy: 0.9937\n",
      "Epoch 446/500\n",
      "46/46 [==============================] - 0s 463us/step - loss: 0.0115 - accuracy: 0.9969\n",
      "Epoch 447/500\n",
      "46/46 [==============================] - 0s 518us/step - loss: 0.0282 - accuracy: 0.9875\n",
      "Epoch 448/500\n",
      "46/46 [==============================] - 0s 425us/step - loss: 0.0207 - accuracy: 0.9906\n",
      "Epoch 449/500\n",
      "46/46 [==============================] - 0s 428us/step - loss: 0.0216 - accuracy: 0.9969\n",
      "Epoch 450/500\n",
      "46/46 [==============================] - 0s 431us/step - loss: 0.0274 - accuracy: 0.9875\n",
      "Epoch 451/500\n",
      "46/46 [==============================] - 0s 447us/step - loss: 0.0082 - accuracy: 0.9969\n",
      "Epoch 452/500\n",
      "46/46 [==============================] - 0s 433us/step - loss: 0.0177 - accuracy: 0.9937\n",
      "Epoch 453/500\n",
      "46/46 [==============================] - 0s 422us/step - loss: 0.0362 - accuracy: 0.9844\n",
      "Epoch 454/500\n",
      "46/46 [==============================] - 0s 468us/step - loss: 0.0119 - accuracy: 0.9969\n",
      "Epoch 455/500\n",
      "46/46 [==============================] - 0s 436us/step - loss: 0.0251 - accuracy: 0.9969\n",
      "Epoch 456/500\n",
      "46/46 [==============================] - 0s 440us/step - loss: 0.0554 - accuracy: 0.9906\n",
      "Epoch 457/500\n",
      "46/46 [==============================] - 0s 441us/step - loss: 0.0142 - accuracy: 0.9969\n",
      "Epoch 458/500\n",
      "46/46 [==============================] - 0s 470us/step - loss: 0.0313 - accuracy: 0.9875\n",
      "Epoch 459/500\n",
      "46/46 [==============================] - 0s 432us/step - loss: 0.0134 - accuracy: 0.9937\n",
      "Epoch 460/500\n",
      "46/46 [==============================] - 0s 450us/step - loss: 0.0280 - accuracy: 0.9906\n",
      "Epoch 461/500\n",
      "46/46 [==============================] - 0s 436us/step - loss: 0.0324 - accuracy: 0.9875\n",
      "Epoch 462/500\n",
      "46/46 [==============================] - 0s 442us/step - loss: 0.0418 - accuracy: 0.9875\n",
      "Epoch 463/500\n",
      "46/46 [==============================] - 0s 448us/step - loss: 0.0161 - accuracy: 0.9969\n",
      "Epoch 464/500\n",
      "46/46 [==============================] - 0s 417us/step - loss: 0.0224 - accuracy: 0.9875\n",
      "Epoch 465/500\n",
      "46/46 [==============================] - 0s 413us/step - loss: 0.0278 - accuracy: 0.9906\n",
      "Epoch 466/500\n",
      "46/46 [==============================] - 0s 418us/step - loss: 0.0411 - accuracy: 0.9875\n",
      "Epoch 467/500\n",
      "46/46 [==============================] - 0s 418us/step - loss: 0.0638 - accuracy: 0.9844\n",
      "Epoch 468/500\n",
      "46/46 [==============================] - 0s 435us/step - loss: 0.0137 - accuracy: 0.9969\n",
      "Epoch 469/500\n",
      "46/46 [==============================] - 0s 440us/step - loss: 0.0250 - accuracy: 0.9906\n",
      "Epoch 470/500\n",
      "46/46 [==============================] - 0s 508us/step - loss: 0.0311 - accuracy: 0.9906\n",
      "Epoch 471/500\n",
      "46/46 [==============================] - 0s 486us/step - loss: 0.0233 - accuracy: 0.9875\n",
      "Epoch 472/500\n",
      "46/46 [==============================] - 0s 449us/step - loss: 0.0104 - accuracy: 0.9969\n",
      "Epoch 473/500\n",
      "46/46 [==============================] - 0s 441us/step - loss: 0.0433 - accuracy: 0.9844\n",
      "Epoch 474/500\n",
      "46/46 [==============================] - 0s 443us/step - loss: 0.0587 - accuracy: 0.9750\n",
      "Epoch 475/500\n",
      "46/46 [==============================] - 0s 440us/step - loss: 0.0417 - accuracy: 0.9812\n",
      "Epoch 476/500\n",
      "46/46 [==============================] - 0s 424us/step - loss: 0.0076 - accuracy: 1.0000\n",
      "Epoch 477/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 405us/step - loss: 0.0537 - accuracy: 0.9812\n",
      "Epoch 478/500\n",
      "46/46 [==============================] - 0s 468us/step - loss: 0.0351 - accuracy: 0.9812\n",
      "Epoch 479/500\n",
      "46/46 [==============================] - 0s 437us/step - loss: 0.0268 - accuracy: 0.9906\n",
      "Epoch 480/500\n",
      "46/46 [==============================] - 0s 448us/step - loss: 0.0255 - accuracy: 0.9906\n",
      "Epoch 481/500\n",
      "46/46 [==============================] - 0s 461us/step - loss: 0.0757 - accuracy: 0.9812\n",
      "Epoch 482/500\n",
      "46/46 [==============================] - 0s 482us/step - loss: 0.0502 - accuracy: 0.9750\n",
      "Epoch 483/500\n",
      "46/46 [==============================] - 0s 468us/step - loss: 0.0193 - accuracy: 0.9937\n",
      "Epoch 484/500\n",
      "46/46 [==============================] - 0s 427us/step - loss: 0.0232 - accuracy: 0.9937\n",
      "Epoch 485/500\n",
      "46/46 [==============================] - 0s 433us/step - loss: 0.0094 - accuracy: 1.0000\n",
      "Epoch 486/500\n",
      "46/46 [==============================] - 0s 465us/step - loss: 0.0141 - accuracy: 0.9937\n",
      "Epoch 487/500\n",
      "46/46 [==============================] - 0s 419us/step - loss: 0.0519 - accuracy: 0.9812\n",
      "Epoch 488/500\n",
      "46/46 [==============================] - 0s 449us/step - loss: 0.0680 - accuracy: 0.9781\n",
      "Epoch 489/500\n",
      "46/46 [==============================] - 0s 504us/step - loss: 0.0265 - accuracy: 0.9906\n",
      "Epoch 490/500\n",
      "46/46 [==============================] - 0s 453us/step - loss: 0.0442 - accuracy: 0.9844\n",
      "Epoch 491/500\n",
      "46/46 [==============================] - 0s 430us/step - loss: 0.0321 - accuracy: 0.9875\n",
      "Epoch 492/500\n",
      "46/46 [==============================] - 0s 447us/step - loss: 0.0158 - accuracy: 0.9906\n",
      "Epoch 493/500\n",
      "46/46 [==============================] - 0s 430us/step - loss: 0.0469 - accuracy: 0.9844\n",
      "Epoch 494/500\n",
      "46/46 [==============================] - 0s 434us/step - loss: 0.0210 - accuracy: 0.9937\n",
      "Epoch 495/500\n",
      "46/46 [==============================] - 0s 453us/step - loss: 0.0374 - accuracy: 0.9906\n",
      "Epoch 496/500\n",
      "46/46 [==============================] - 0s 440us/step - loss: 0.0273 - accuracy: 0.9906\n",
      "Epoch 497/500\n",
      "46/46 [==============================] - 0s 435us/step - loss: 0.0236 - accuracy: 0.9875\n",
      "Epoch 498/500\n",
      "46/46 [==============================] - 0s 452us/step - loss: 0.0127 - accuracy: 0.9937\n",
      "Epoch 499/500\n",
      "46/46 [==============================] - 0s 444us/step - loss: 0.0150 - accuracy: 0.9937\n",
      "Epoch 500/500\n",
      "46/46 [==============================] - 0s 404us/step - loss: 0.0121 - accuracy: 0.9969\n",
      "Model: \"Sequential-NN\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_9 (Dense)              (None, 42)                1806      \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 42)                0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 256)               11008     \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 5)                 1285      \n",
      "=================================================================\n",
      "Total params: 14,099\n",
      "Trainable params: 14,099\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/500\n",
      "46/46 [==============================] - 0s 427us/step - loss: 1.5805 - accuracy: 0.2531\n",
      "Epoch 2/500\n",
      "46/46 [==============================] - 0s 404us/step - loss: 1.4374 - accuracy: 0.4625\n",
      "Epoch 3/500\n",
      "46/46 [==============================] - 0s 442us/step - loss: 1.2512 - accuracy: 0.5000\n",
      "Epoch 4/500\n",
      "46/46 [==============================] - 0s 496us/step - loss: 1.1082 - accuracy: 0.5688\n",
      "Epoch 5/500\n",
      "46/46 [==============================] - 0s 653us/step - loss: 1.0060 - accuracy: 0.5875\n",
      "Epoch 6/500\n",
      "46/46 [==============================] - 0s 656us/step - loss: 0.9865 - accuracy: 0.5906\n",
      "Epoch 7/500\n",
      "46/46 [==============================] - 0s 470us/step - loss: 0.8792 - accuracy: 0.6406\n",
      "Epoch 8/500\n",
      "46/46 [==============================] - 0s 471us/step - loss: 0.8294 - accuracy: 0.6875\n",
      "Epoch 9/500\n",
      "46/46 [==============================] - 0s 469us/step - loss: 0.7613 - accuracy: 0.6844\n",
      "Epoch 10/500\n",
      "46/46 [==============================] - 0s 456us/step - loss: 0.7231 - accuracy: 0.7031\n",
      "Epoch 11/500\n",
      "46/46 [==============================] - 0s 466us/step - loss: 0.7460 - accuracy: 0.6906\n",
      "Epoch 12/500\n",
      "46/46 [==============================] - 0s 447us/step - loss: 0.6908 - accuracy: 0.7281\n",
      "Epoch 13/500\n",
      "46/46 [==============================] - 0s 469us/step - loss: 0.6481 - accuracy: 0.7469\n",
      "Epoch 14/500\n",
      "46/46 [==============================] - 0s 562us/step - loss: 0.6082 - accuracy: 0.7750\n",
      "Epoch 15/500\n",
      "46/46 [==============================] - 0s 612us/step - loss: 0.6384 - accuracy: 0.7344\n",
      "Epoch 16/500\n",
      "46/46 [==============================] - 0s 470us/step - loss: 0.5725 - accuracy: 0.7531\n",
      "Epoch 17/500\n",
      "46/46 [==============================] - 0s 440us/step - loss: 0.5510 - accuracy: 0.7781\n",
      "Epoch 18/500\n",
      "46/46 [==============================] - 0s 413us/step - loss: 0.6268 - accuracy: 0.7406\n",
      "Epoch 19/500\n",
      "46/46 [==============================] - 0s 443us/step - loss: 0.5377 - accuracy: 0.7875\n",
      "Epoch 20/500\n",
      "46/46 [==============================] - 0s 415us/step - loss: 0.5078 - accuracy: 0.8000\n",
      "Epoch 21/500\n",
      "46/46 [==============================] - 0s 413us/step - loss: 0.4979 - accuracy: 0.8000\n",
      "Epoch 22/500\n",
      "46/46 [==============================] - 0s 432us/step - loss: 0.4502 - accuracy: 0.8281\n",
      "Epoch 23/500\n",
      "46/46 [==============================] - 0s 405us/step - loss: 0.4580 - accuracy: 0.8219\n",
      "Epoch 24/500\n",
      "46/46 [==============================] - 0s 407us/step - loss: 0.4414 - accuracy: 0.8219\n",
      "Epoch 25/500\n",
      "46/46 [==============================] - 0s 405us/step - loss: 0.4675 - accuracy: 0.7937\n",
      "Epoch 26/500\n",
      "46/46 [==============================] - 0s 490us/step - loss: 0.4845 - accuracy: 0.8000\n",
      "Epoch 27/500\n",
      "46/46 [==============================] - 0s 425us/step - loss: 0.4216 - accuracy: 0.8344\n",
      "Epoch 28/500\n",
      "46/46 [==============================] - 0s 446us/step - loss: 0.3973 - accuracy: 0.8500\n",
      "Epoch 29/500\n",
      "46/46 [==============================] - 0s 466us/step - loss: 0.4028 - accuracy: 0.8531\n",
      "Epoch 30/500\n",
      "46/46 [==============================] - 0s 419us/step - loss: 0.4136 - accuracy: 0.8406\n",
      "Epoch 31/500\n",
      "46/46 [==============================] - 0s 414us/step - loss: 0.3931 - accuracy: 0.8344\n",
      "Epoch 32/500\n",
      "46/46 [==============================] - 0s 510us/step - loss: 0.3700 - accuracy: 0.8562\n",
      "Epoch 33/500\n",
      "46/46 [==============================] - 0s 458us/step - loss: 0.3622 - accuracy: 0.8656\n",
      "Epoch 34/500\n",
      "46/46 [==============================] - 0s 426us/step - loss: 0.3668 - accuracy: 0.8469\n",
      "Epoch 35/500\n",
      "46/46 [==============================] - 0s 447us/step - loss: 0.3644 - accuracy: 0.8438\n",
      "Epoch 36/500\n",
      "46/46 [==============================] - 0s 418us/step - loss: 0.3675 - accuracy: 0.8562\n",
      "Epoch 37/500\n",
      "46/46 [==============================] - 0s 416us/step - loss: 0.3640 - accuracy: 0.8531\n",
      "Epoch 38/500\n",
      "46/46 [==============================] - 0s 406us/step - loss: 0.3452 - accuracy: 0.8656\n",
      "Epoch 39/500\n",
      "46/46 [==============================] - 0s 425us/step - loss: 0.3456 - accuracy: 0.8562\n",
      "Epoch 40/500\n",
      "46/46 [==============================] - 0s 413us/step - loss: 0.3682 - accuracy: 0.8594\n",
      "Epoch 41/500\n",
      "46/46 [==============================] - 0s 412us/step - loss: 0.3303 - accuracy: 0.8625\n",
      "Epoch 42/500\n",
      "46/46 [==============================] - 0s 438us/step - loss: 0.3195 - accuracy: 0.8813\n",
      "Epoch 43/500\n",
      "46/46 [==============================] - 0s 418us/step - loss: 0.3532 - accuracy: 0.8375\n",
      "Epoch 44/500\n",
      "46/46 [==============================] - 0s 419us/step - loss: 0.3014 - accuracy: 0.8906\n",
      "Epoch 45/500\n",
      "46/46 [==============================] - 0s 412us/step - loss: 0.3134 - accuracy: 0.8750\n",
      "Epoch 46/500\n",
      "46/46 [==============================] - 0s 397us/step - loss: 0.2903 - accuracy: 0.8844\n",
      "Epoch 47/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 406us/step - loss: 0.3134 - accuracy: 0.8687\n",
      "Epoch 48/500\n",
      "46/46 [==============================] - 0s 402us/step - loss: 0.3047 - accuracy: 0.8844\n",
      "Epoch 49/500\n",
      "46/46 [==============================] - 0s 399us/step - loss: 0.2888 - accuracy: 0.8938\n",
      "Epoch 50/500\n",
      "46/46 [==============================] - 0s 395us/step - loss: 0.3023 - accuracy: 0.8656\n",
      "Epoch 51/500\n",
      "46/46 [==============================] - 0s 404us/step - loss: 0.3040 - accuracy: 0.8719\n",
      "Epoch 52/500\n",
      "46/46 [==============================] - 0s 409us/step - loss: 0.2692 - accuracy: 0.8906\n",
      "Epoch 53/500\n",
      "46/46 [==============================] - 0s 397us/step - loss: 0.3087 - accuracy: 0.8781\n",
      "Epoch 54/500\n",
      "46/46 [==============================] - 0s 410us/step - loss: 0.2813 - accuracy: 0.8938\n",
      "Epoch 55/500\n",
      "46/46 [==============================] - 0s 419us/step - loss: 0.2844 - accuracy: 0.8781\n",
      "Epoch 56/500\n",
      "46/46 [==============================] - 0s 401us/step - loss: 0.2823 - accuracy: 0.8750\n",
      "Epoch 57/500\n",
      "46/46 [==============================] - 0s 406us/step - loss: 0.2539 - accuracy: 0.8938\n",
      "Epoch 58/500\n",
      "46/46 [==============================] - 0s 406us/step - loss: 0.2355 - accuracy: 0.9000\n",
      "Epoch 59/500\n",
      "46/46 [==============================] - 0s 415us/step - loss: 0.2370 - accuracy: 0.9062\n",
      "Epoch 60/500\n",
      "46/46 [==============================] - 0s 405us/step - loss: 0.2275 - accuracy: 0.9125\n",
      "Epoch 61/500\n",
      "46/46 [==============================] - 0s 402us/step - loss: 0.2287 - accuracy: 0.9062\n",
      "Epoch 62/500\n",
      "46/46 [==============================] - 0s 409us/step - loss: 0.2447 - accuracy: 0.9031\n",
      "Epoch 63/500\n",
      "46/46 [==============================] - 0s 419us/step - loss: 0.2060 - accuracy: 0.9312\n",
      "Epoch 64/500\n",
      "46/46 [==============================] - 0s 423us/step - loss: 0.2500 - accuracy: 0.8906\n",
      "Epoch 65/500\n",
      "46/46 [==============================] - 0s 389us/step - loss: 0.2212 - accuracy: 0.9156\n",
      "Epoch 66/500\n",
      "46/46 [==============================] - 0s 406us/step - loss: 0.2417 - accuracy: 0.9000\n",
      "Epoch 67/500\n",
      "46/46 [==============================] - 0s 388us/step - loss: 0.2259 - accuracy: 0.9312\n",
      "Epoch 68/500\n",
      "46/46 [==============================] - 0s 423us/step - loss: 0.2108 - accuracy: 0.9250\n",
      "Epoch 69/500\n",
      "46/46 [==============================] - 0s 417us/step - loss: 0.2669 - accuracy: 0.8938\n",
      "Epoch 70/500\n",
      "46/46 [==============================] - 0s 426us/step - loss: 0.2084 - accuracy: 0.9187\n",
      "Epoch 71/500\n",
      "46/46 [==============================] - 0s 403us/step - loss: 0.2485 - accuracy: 0.9031\n",
      "Epoch 72/500\n",
      "46/46 [==============================] - 0s 466us/step - loss: 0.1830 - accuracy: 0.9344\n",
      "Epoch 73/500\n",
      "46/46 [==============================] - 0s 400us/step - loss: 0.2014 - accuracy: 0.9344\n",
      "Epoch 74/500\n",
      "46/46 [==============================] - 0s 399us/step - loss: 0.2016 - accuracy: 0.9250\n",
      "Epoch 75/500\n",
      "46/46 [==============================] - 0s 389us/step - loss: 0.2573 - accuracy: 0.8938\n",
      "Epoch 76/500\n",
      "46/46 [==============================] - 0s 394us/step - loss: 0.2084 - accuracy: 0.9312\n",
      "Epoch 77/500\n",
      "46/46 [==============================] - 0s 406us/step - loss: 0.1833 - accuracy: 0.9312\n",
      "Epoch 78/500\n",
      "46/46 [==============================] - 0s 414us/step - loss: 0.1779 - accuracy: 0.9406\n",
      "Epoch 79/500\n",
      "46/46 [==============================] - 0s 398us/step - loss: 0.1945 - accuracy: 0.9125\n",
      "Epoch 80/500\n",
      "46/46 [==============================] - 0s 397us/step - loss: 0.2097 - accuracy: 0.9031\n",
      "Epoch 81/500\n",
      "46/46 [==============================] - 0s 402us/step - loss: 0.2088 - accuracy: 0.9219\n",
      "Epoch 82/500\n",
      "46/46 [==============================] - 0s 411us/step - loss: 0.1890 - accuracy: 0.9344\n",
      "Epoch 83/500\n",
      "46/46 [==============================] - 0s 404us/step - loss: 0.2064 - accuracy: 0.9187\n",
      "Epoch 84/500\n",
      "46/46 [==============================] - 0s 392us/step - loss: 0.1880 - accuracy: 0.9344\n",
      "Epoch 85/500\n",
      "46/46 [==============================] - 0s 391us/step - loss: 0.1818 - accuracy: 0.9219\n",
      "Epoch 86/500\n",
      "46/46 [==============================] - 0s 398us/step - loss: 0.1637 - accuracy: 0.9375\n",
      "Epoch 87/500\n",
      "46/46 [==============================] - 0s 400us/step - loss: 0.1649 - accuracy: 0.9406\n",
      "Epoch 88/500\n",
      "46/46 [==============================] - 0s 402us/step - loss: 0.1676 - accuracy: 0.9375\n",
      "Epoch 89/500\n",
      "46/46 [==============================] - 0s 461us/step - loss: 0.1982 - accuracy: 0.9406\n",
      "Epoch 90/500\n",
      "46/46 [==============================] - 0s 430us/step - loss: 0.1703 - accuracy: 0.9406\n",
      "Epoch 91/500\n",
      "46/46 [==============================] - 0s 512us/step - loss: 0.1654 - accuracy: 0.9344\n",
      "Epoch 92/500\n",
      "46/46 [==============================] - 0s 410us/step - loss: 0.1651 - accuracy: 0.9281\n",
      "Epoch 93/500\n",
      "46/46 [==============================] - 0s 401us/step - loss: 0.1356 - accuracy: 0.9625\n",
      "Epoch 94/500\n",
      "46/46 [==============================] - 0s 403us/step - loss: 0.1693 - accuracy: 0.9344\n",
      "Epoch 95/500\n",
      "46/46 [==============================] - 0s 390us/step - loss: 0.1655 - accuracy: 0.9312\n",
      "Epoch 96/500\n",
      "46/46 [==============================] - 0s 404us/step - loss: 0.1335 - accuracy: 0.9563\n",
      "Epoch 97/500\n",
      "46/46 [==============================] - 0s 393us/step - loss: 0.1948 - accuracy: 0.9281\n",
      "Epoch 98/500\n",
      "46/46 [==============================] - 0s 389us/step - loss: 0.1599 - accuracy: 0.9375\n",
      "Epoch 99/500\n",
      "46/46 [==============================] - 0s 414us/step - loss: 0.1682 - accuracy: 0.9281\n",
      "Epoch 100/500\n",
      "46/46 [==============================] - 0s 399us/step - loss: 0.1295 - accuracy: 0.9656\n",
      "Epoch 101/500\n",
      "46/46 [==============================] - 0s 404us/step - loss: 0.1517 - accuracy: 0.9563\n",
      "Epoch 102/500\n",
      "46/46 [==============================] - 0s 408us/step - loss: 0.1751 - accuracy: 0.9250\n",
      "Epoch 103/500\n",
      "46/46 [==============================] - 0s 402us/step - loss: 0.1814 - accuracy: 0.9344\n",
      "Epoch 104/500\n",
      "46/46 [==============================] - 0s 396us/step - loss: 0.1634 - accuracy: 0.9281\n",
      "Epoch 105/500\n",
      "46/46 [==============================] - 0s 397us/step - loss: 0.1493 - accuracy: 0.9438\n",
      "Epoch 106/500\n",
      "46/46 [==============================] - 0s 400us/step - loss: 0.1457 - accuracy: 0.9406\n",
      "Epoch 107/500\n",
      "46/46 [==============================] - 0s 408us/step - loss: 0.1516 - accuracy: 0.9469\n",
      "Epoch 108/500\n",
      "46/46 [==============================] - 0s 396us/step - loss: 0.1642 - accuracy: 0.9312\n",
      "Epoch 109/500\n",
      "46/46 [==============================] - 0s 397us/step - loss: 0.1508 - accuracy: 0.9500\n",
      "Epoch 110/500\n",
      "46/46 [==============================] - 0s 447us/step - loss: 0.1214 - accuracy: 0.9594\n",
      "Epoch 111/500\n",
      "46/46 [==============================] - 0s 427us/step - loss: 0.1354 - accuracy: 0.9594\n",
      "Epoch 112/500\n",
      "46/46 [==============================] - 0s 407us/step - loss: 0.1257 - accuracy: 0.9500\n",
      "Epoch 113/500\n",
      "46/46 [==============================] - 0s 412us/step - loss: 0.1397 - accuracy: 0.9531\n",
      "Epoch 114/500\n",
      "46/46 [==============================] - 0s 421us/step - loss: 0.1342 - accuracy: 0.9375\n",
      "Epoch 115/500\n",
      "46/46 [==============================] - 0s 428us/step - loss: 0.1646 - accuracy: 0.9344\n",
      "Epoch 116/500\n",
      "46/46 [==============================] - 0s 442us/step - loss: 0.1476 - accuracy: 0.9469\n",
      "Epoch 117/500\n",
      "46/46 [==============================] - 0s 472us/step - loss: 0.1428 - accuracy: 0.9594\n",
      "Epoch 118/500\n",
      "46/46 [==============================] - 0s 486us/step - loss: 0.1223 - accuracy: 0.9500\n",
      "Epoch 119/500\n",
      "46/46 [==============================] - 0s 477us/step - loss: 0.1136 - accuracy: 0.9531\n",
      "Epoch 120/500\n",
      "46/46 [==============================] - 0s 484us/step - loss: 0.1301 - accuracy: 0.9500\n",
      "Epoch 121/500\n",
      "46/46 [==============================] - 0s 430us/step - loss: 0.1468 - accuracy: 0.9312\n",
      "Epoch 122/500\n",
      "46/46 [==============================] - 0s 413us/step - loss: 0.1497 - accuracy: 0.9438\n",
      "Epoch 123/500\n",
      "46/46 [==============================] - 0s 398us/step - loss: 0.1224 - accuracy: 0.9531\n",
      "Epoch 124/500\n",
      "46/46 [==============================] - 0s 407us/step - loss: 0.1251 - accuracy: 0.9594\n",
      "Epoch 125/500\n",
      "46/46 [==============================] - 0s 391us/step - loss: 0.0978 - accuracy: 0.9688\n",
      "Epoch 126/500\n",
      "46/46 [==============================] - 0s 398us/step - loss: 0.1494 - accuracy: 0.9312\n",
      "Epoch 127/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 412us/step - loss: 0.1699 - accuracy: 0.9375\n",
      "Epoch 128/500\n",
      "46/46 [==============================] - 0s 396us/step - loss: 0.1344 - accuracy: 0.9438\n",
      "Epoch 129/500\n",
      "46/46 [==============================] - 0s 415us/step - loss: 0.1254 - accuracy: 0.9344\n",
      "Epoch 130/500\n",
      "46/46 [==============================] - 0s 391us/step - loss: 0.1247 - accuracy: 0.9563\n",
      "Epoch 131/500\n",
      "46/46 [==============================] - 0s 415us/step - loss: 0.1322 - accuracy: 0.9531\n",
      "Epoch 132/500\n",
      "46/46 [==============================] - 0s 419us/step - loss: 0.0879 - accuracy: 0.9719\n",
      "Epoch 133/500\n",
      "46/46 [==============================] - 0s 380us/step - loss: 0.1401 - accuracy: 0.9438\n",
      "Epoch 134/500\n",
      "46/46 [==============================] - 0s 402us/step - loss: 0.0971 - accuracy: 0.9750\n",
      "Epoch 135/500\n",
      "46/46 [==============================] - 0s 394us/step - loss: 0.1134 - accuracy: 0.9625\n",
      "Epoch 136/500\n",
      "46/46 [==============================] - 0s 395us/step - loss: 0.1390 - accuracy: 0.9438\n",
      "Epoch 137/500\n",
      "46/46 [==============================] - 0s 402us/step - loss: 0.1092 - accuracy: 0.9563\n",
      "Epoch 138/500\n",
      "46/46 [==============================] - 0s 391us/step - loss: 0.1035 - accuracy: 0.9656\n",
      "Epoch 139/500\n",
      "46/46 [==============================] - 0s 417us/step - loss: 0.1174 - accuracy: 0.9656\n",
      "Epoch 140/500\n",
      "46/46 [==============================] - 0s 390us/step - loss: 0.1298 - accuracy: 0.9500\n",
      "Epoch 141/500\n",
      "46/46 [==============================] - 0s 402us/step - loss: 0.1087 - accuracy: 0.9719\n",
      "Epoch 142/500\n",
      "46/46 [==============================] - 0s 402us/step - loss: 0.0947 - accuracy: 0.9563\n",
      "Epoch 143/500\n",
      "46/46 [==============================] - 0s 388us/step - loss: 0.1257 - accuracy: 0.9563\n",
      "Epoch 144/500\n",
      "46/46 [==============================] - 0s 412us/step - loss: 0.1004 - accuracy: 0.9719\n",
      "Epoch 145/500\n",
      "46/46 [==============================] - 0s 426us/step - loss: 0.1159 - accuracy: 0.9656\n",
      "Epoch 146/500\n",
      "46/46 [==============================] - 0s 405us/step - loss: 0.1061 - accuracy: 0.9594\n",
      "Epoch 147/500\n",
      "46/46 [==============================] - 0s 418us/step - loss: 0.1161 - accuracy: 0.9563\n",
      "Epoch 148/500\n",
      "46/46 [==============================] - 0s 410us/step - loss: 0.1100 - accuracy: 0.9563\n",
      "Epoch 149/500\n",
      "46/46 [==============================] - 0s 415us/step - loss: 0.1184 - accuracy: 0.9563\n",
      "Epoch 150/500\n",
      "46/46 [==============================] - 0s 389us/step - loss: 0.1190 - accuracy: 0.9563\n",
      "Epoch 151/500\n",
      "46/46 [==============================] - 0s 400us/step - loss: 0.1219 - accuracy: 0.9594\n",
      "Epoch 152/500\n",
      "46/46 [==============================] - 0s 391us/step - loss: 0.1149 - accuracy: 0.9531\n",
      "Epoch 153/500\n",
      "46/46 [==============================] - 0s 406us/step - loss: 0.1154 - accuracy: 0.9563\n",
      "Epoch 154/500\n",
      "46/46 [==============================] - 0s 413us/step - loss: 0.0951 - accuracy: 0.9656\n",
      "Epoch 155/500\n",
      "46/46 [==============================] - 0s 403us/step - loss: 0.1290 - accuracy: 0.9438\n",
      "Epoch 156/500\n",
      "46/46 [==============================] - 0s 459us/step - loss: 0.1412 - accuracy: 0.9281\n",
      "Epoch 157/500\n",
      "46/46 [==============================] - 0s 403us/step - loss: 0.1307 - accuracy: 0.9625\n",
      "Epoch 158/500\n",
      "46/46 [==============================] - 0s 424us/step - loss: 0.0995 - accuracy: 0.9656\n",
      "Epoch 159/500\n",
      "46/46 [==============================] - 0s 427us/step - loss: 0.0798 - accuracy: 0.9719\n",
      "Epoch 160/500\n",
      "46/46 [==============================] - 0s 404us/step - loss: 0.0975 - accuracy: 0.9781\n",
      "Epoch 161/500\n",
      "46/46 [==============================] - 0s 438us/step - loss: 0.1148 - accuracy: 0.9625\n",
      "Epoch 162/500\n",
      "46/46 [==============================] - 0s 485us/step - loss: 0.0897 - accuracy: 0.9656\n",
      "Epoch 163/500\n",
      "46/46 [==============================] - 0s 448us/step - loss: 0.1290 - accuracy: 0.9531\n",
      "Epoch 164/500\n",
      "46/46 [==============================] - 0s 406us/step - loss: 0.1205 - accuracy: 0.9563\n",
      "Epoch 165/500\n",
      "46/46 [==============================] - 0s 402us/step - loss: 0.1092 - accuracy: 0.9625\n",
      "Epoch 166/500\n",
      "46/46 [==============================] - 0s 418us/step - loss: 0.1035 - accuracy: 0.9656\n",
      "Epoch 167/500\n",
      "46/46 [==============================] - 0s 415us/step - loss: 0.1254 - accuracy: 0.9563\n",
      "Epoch 168/500\n",
      "46/46 [==============================] - 0s 504us/step - loss: 0.0920 - accuracy: 0.9656\n",
      "Epoch 169/500\n",
      "46/46 [==============================] - 0s 565us/step - loss: 0.1014 - accuracy: 0.9688\n",
      "Epoch 170/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.0968 - accuracy: 0.9656\n",
      "Epoch 171/500\n",
      "46/46 [==============================] - 0s 485us/step - loss: 0.1322 - accuracy: 0.9500\n",
      "Epoch 172/500\n",
      "46/46 [==============================] - 0s 428us/step - loss: 0.1196 - accuracy: 0.9594\n",
      "Epoch 173/500\n",
      "46/46 [==============================] - 0s 406us/step - loss: 0.0949 - accuracy: 0.9688\n",
      "Epoch 174/500\n",
      "46/46 [==============================] - 0s 408us/step - loss: 0.0787 - accuracy: 0.9844\n",
      "Epoch 175/500\n",
      "46/46 [==============================] - 0s 399us/step - loss: 0.0891 - accuracy: 0.9625\n",
      "Epoch 176/500\n",
      "46/46 [==============================] - 0s 403us/step - loss: 0.0948 - accuracy: 0.9563\n",
      "Epoch 177/500\n",
      "46/46 [==============================] - 0s 408us/step - loss: 0.0822 - accuracy: 0.9719\n",
      "Epoch 178/500\n",
      "46/46 [==============================] - 0s 392us/step - loss: 0.1142 - accuracy: 0.9500\n",
      "Epoch 179/500\n",
      "46/46 [==============================] - 0s 394us/step - loss: 0.0605 - accuracy: 0.9781\n",
      "Epoch 180/500\n",
      "46/46 [==============================] - 0s 424us/step - loss: 0.1024 - accuracy: 0.9688\n",
      "Epoch 181/500\n",
      "46/46 [==============================] - 0s 402us/step - loss: 0.0714 - accuracy: 0.9750\n",
      "Epoch 182/500\n",
      "46/46 [==============================] - 0s 407us/step - loss: 0.1188 - accuracy: 0.9594\n",
      "Epoch 183/500\n",
      "46/46 [==============================] - 0s 394us/step - loss: 0.1006 - accuracy: 0.9625\n",
      "Epoch 184/500\n",
      "46/46 [==============================] - 0s 409us/step - loss: 0.0665 - accuracy: 0.9781\n",
      "Epoch 185/500\n",
      "46/46 [==============================] - 0s 405us/step - loss: 0.0781 - accuracy: 0.9781\n",
      "Epoch 186/500\n",
      "46/46 [==============================] - 0s 394us/step - loss: 0.0611 - accuracy: 0.9781\n",
      "Epoch 187/500\n",
      "46/46 [==============================] - 0s 405us/step - loss: 0.1161 - accuracy: 0.9688\n",
      "Epoch 188/500\n",
      "46/46 [==============================] - 0s 394us/step - loss: 0.1261 - accuracy: 0.9656\n",
      "Epoch 189/500\n",
      "46/46 [==============================] - 0s 402us/step - loss: 0.0732 - accuracy: 0.9844\n",
      "Epoch 190/500\n",
      "46/46 [==============================] - 0s 406us/step - loss: 0.1091 - accuracy: 0.9563\n",
      "Epoch 191/500\n",
      "46/46 [==============================] - 0s 412us/step - loss: 0.0783 - accuracy: 0.9594\n",
      "Epoch 192/500\n",
      "46/46 [==============================] - 0s 408us/step - loss: 0.1106 - accuracy: 0.9563\n",
      "Epoch 193/500\n",
      "46/46 [==============================] - 0s 388us/step - loss: 0.1099 - accuracy: 0.9656\n",
      "Epoch 194/500\n",
      "46/46 [==============================] - 0s 398us/step - loss: 0.0715 - accuracy: 0.9812\n",
      "Epoch 195/500\n",
      "46/46 [==============================] - 0s 407us/step - loss: 0.1300 - accuracy: 0.9438\n",
      "Epoch 196/500\n",
      "46/46 [==============================] - 0s 399us/step - loss: 0.1120 - accuracy: 0.9625\n",
      "Epoch 197/500\n",
      "46/46 [==============================] - 0s 405us/step - loss: 0.0547 - accuracy: 0.9875\n",
      "Epoch 198/500\n",
      "46/46 [==============================] - 0s 391us/step - loss: 0.0637 - accuracy: 0.9719\n",
      "Epoch 199/500\n",
      "46/46 [==============================] - 0s 405us/step - loss: 0.0946 - accuracy: 0.9750\n",
      "Epoch 200/500\n",
      "46/46 [==============================] - 0s 390us/step - loss: 0.0859 - accuracy: 0.9656\n",
      "Epoch 201/500\n",
      "46/46 [==============================] - 0s 388us/step - loss: 0.0922 - accuracy: 0.9594\n",
      "Epoch 202/500\n",
      "46/46 [==============================] - 0s 411us/step - loss: 0.0911 - accuracy: 0.9719\n",
      "Epoch 203/500\n",
      "46/46 [==============================] - 0s 392us/step - loss: 0.0888 - accuracy: 0.9594\n",
      "Epoch 204/500\n",
      "46/46 [==============================] - 0s 421us/step - loss: 0.1288 - accuracy: 0.9625\n",
      "Epoch 205/500\n",
      "46/46 [==============================] - 0s 406us/step - loss: 0.0669 - accuracy: 0.9750\n",
      "Epoch 206/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 408us/step - loss: 0.0639 - accuracy: 0.9719\n",
      "Epoch 207/500\n",
      "46/46 [==============================] - 0s 417us/step - loss: 0.1041 - accuracy: 0.9563\n",
      "Epoch 208/500\n",
      "46/46 [==============================] - 0s 386us/step - loss: 0.0761 - accuracy: 0.9656\n",
      "Epoch 209/500\n",
      "46/46 [==============================] - 0s 415us/step - loss: 0.1062 - accuracy: 0.9625\n",
      "Epoch 210/500\n",
      "46/46 [==============================] - 0s 404us/step - loss: 0.0695 - accuracy: 0.9812\n",
      "Epoch 211/500\n",
      "46/46 [==============================] - 0s 421us/step - loss: 0.0964 - accuracy: 0.9719\n",
      "Epoch 212/500\n",
      "46/46 [==============================] - 0s 413us/step - loss: 0.0837 - accuracy: 0.9656\n",
      "Epoch 213/500\n",
      "46/46 [==============================] - 0s 403us/step - loss: 0.0816 - accuracy: 0.9750\n",
      "Epoch 214/500\n",
      "46/46 [==============================] - 0s 457us/step - loss: 0.0628 - accuracy: 0.9844\n",
      "Epoch 215/500\n",
      "46/46 [==============================] - 0s 413us/step - loss: 0.0947 - accuracy: 0.9688\n",
      "Epoch 216/500\n",
      "46/46 [==============================] - 0s 456us/step - loss: 0.0973 - accuracy: 0.9656\n",
      "Epoch 217/500\n",
      "46/46 [==============================] - 0s 406us/step - loss: 0.0690 - accuracy: 0.9812\n",
      "Epoch 218/500\n",
      "46/46 [==============================] - 0s 416us/step - loss: 0.0713 - accuracy: 0.9719\n",
      "Epoch 219/500\n",
      "46/46 [==============================] - 0s 406us/step - loss: 0.0876 - accuracy: 0.9594\n",
      "Epoch 220/500\n",
      "46/46 [==============================] - 0s 406us/step - loss: 0.1104 - accuracy: 0.9531\n",
      "Epoch 221/500\n",
      "46/46 [==============================] - 0s 428us/step - loss: 0.0757 - accuracy: 0.9781\n",
      "Epoch 222/500\n",
      "46/46 [==============================] - 0s 403us/step - loss: 0.0822 - accuracy: 0.9688\n",
      "Epoch 223/500\n",
      "46/46 [==============================] - 0s 404us/step - loss: 0.0481 - accuracy: 0.9812\n",
      "Epoch 224/500\n",
      "46/46 [==============================] - 0s 417us/step - loss: 0.1302 - accuracy: 0.9531\n",
      "Epoch 225/500\n",
      "46/46 [==============================] - 0s 432us/step - loss: 0.0792 - accuracy: 0.9750\n",
      "Epoch 226/500\n",
      "46/46 [==============================] - 0s 430us/step - loss: 0.0766 - accuracy: 0.9719\n",
      "Epoch 227/500\n",
      "46/46 [==============================] - 0s 406us/step - loss: 0.0876 - accuracy: 0.9719\n",
      "Epoch 228/500\n",
      "46/46 [==============================] - 0s 428us/step - loss: 0.0731 - accuracy: 0.9750\n",
      "Epoch 229/500\n",
      "46/46 [==============================] - 0s 407us/step - loss: 0.0587 - accuracy: 0.9812\n",
      "Epoch 230/500\n",
      "46/46 [==============================] - 0s 408us/step - loss: 0.0721 - accuracy: 0.9688\n",
      "Epoch 231/500\n",
      "46/46 [==============================] - 0s 420us/step - loss: 0.1536 - accuracy: 0.9438\n",
      "Epoch 232/500\n",
      "46/46 [==============================] - 0s 392us/step - loss: 0.0650 - accuracy: 0.9844\n",
      "Epoch 233/500\n",
      "46/46 [==============================] - 0s 427us/step - loss: 0.0759 - accuracy: 0.9719\n",
      "Epoch 234/500\n",
      "46/46 [==============================] - 0s 390us/step - loss: 0.0569 - accuracy: 0.9781\n",
      "Epoch 235/500\n",
      "46/46 [==============================] - 0s 397us/step - loss: 0.0627 - accuracy: 0.9844\n",
      "Epoch 236/500\n",
      "46/46 [==============================] - 0s 413us/step - loss: 0.0709 - accuracy: 0.9656\n",
      "Epoch 237/500\n",
      "46/46 [==============================] - 0s 401us/step - loss: 0.0979 - accuracy: 0.9594\n",
      "Epoch 238/500\n",
      "46/46 [==============================] - 0s 420us/step - loss: 0.0860 - accuracy: 0.9625\n",
      "Epoch 239/500\n",
      "46/46 [==============================] - 0s 393us/step - loss: 0.0850 - accuracy: 0.9688\n",
      "Epoch 240/500\n",
      "46/46 [==============================] - 0s 409us/step - loss: 0.0921 - accuracy: 0.9719\n",
      "Epoch 241/500\n",
      "46/46 [==============================] - 0s 426us/step - loss: 0.0704 - accuracy: 0.9812\n",
      "Epoch 242/500\n",
      "46/46 [==============================] - 0s 410us/step - loss: 0.0638 - accuracy: 0.9812\n",
      "Epoch 243/500\n",
      "46/46 [==============================] - 0s 423us/step - loss: 0.0807 - accuracy: 0.9656\n",
      "Epoch 244/500\n",
      "46/46 [==============================] - 0s 417us/step - loss: 0.0546 - accuracy: 0.9812\n",
      "Epoch 245/500\n",
      "46/46 [==============================] - 0s 513us/step - loss: 0.0386 - accuracy: 0.9875\n",
      "Epoch 246/500\n",
      "46/46 [==============================] - 0s 430us/step - loss: 0.0648 - accuracy: 0.9781\n",
      "Epoch 247/500\n",
      "46/46 [==============================] - 0s 397us/step - loss: 0.0698 - accuracy: 0.9750\n",
      "Epoch 248/500\n",
      "46/46 [==============================] - 0s 457us/step - loss: 0.0572 - accuracy: 0.9781\n",
      "Epoch 249/500\n",
      "46/46 [==============================] - 0s 390us/step - loss: 0.0709 - accuracy: 0.9688\n",
      "Epoch 250/500\n",
      "46/46 [==============================] - 0s 412us/step - loss: 0.0377 - accuracy: 0.9875\n",
      "Epoch 251/500\n",
      "46/46 [==============================] - 0s 388us/step - loss: 0.0780 - accuracy: 0.9750\n",
      "Epoch 252/500\n",
      "46/46 [==============================] - 0s 398us/step - loss: 0.0549 - accuracy: 0.9781\n",
      "Epoch 253/500\n",
      "46/46 [==============================] - 0s 397us/step - loss: 0.0784 - accuracy: 0.9750\n",
      "Epoch 254/500\n",
      "46/46 [==============================] - 0s 387us/step - loss: 0.0537 - accuracy: 0.9750\n",
      "Epoch 255/500\n",
      "46/46 [==============================] - 0s 392us/step - loss: 0.0791 - accuracy: 0.9625\n",
      "Epoch 256/500\n",
      "46/46 [==============================] - 0s 398us/step - loss: 0.0601 - accuracy: 0.9812\n",
      "Epoch 257/500\n",
      "46/46 [==============================] - 0s 422us/step - loss: 0.0945 - accuracy: 0.9688\n",
      "Epoch 258/500\n",
      "46/46 [==============================] - 0s 448us/step - loss: 0.1284 - accuracy: 0.9531\n",
      "Epoch 259/500\n",
      "46/46 [==============================] - 0s 430us/step - loss: 0.1273 - accuracy: 0.9438\n",
      "Epoch 260/500\n",
      "46/46 [==============================] - 0s 418us/step - loss: 0.0538 - accuracy: 0.9844\n",
      "Epoch 261/500\n",
      "46/46 [==============================] - 0s 409us/step - loss: 0.0693 - accuracy: 0.9750\n",
      "Epoch 262/500\n",
      "46/46 [==============================] - 0s 415us/step - loss: 0.0833 - accuracy: 0.9656\n",
      "Epoch 263/500\n",
      "46/46 [==============================] - 0s 413us/step - loss: 0.0888 - accuracy: 0.9719\n",
      "Epoch 264/500\n",
      "46/46 [==============================] - 0s 411us/step - loss: 0.0310 - accuracy: 0.9969\n",
      "Epoch 265/500\n",
      "46/46 [==============================] - 0s 401us/step - loss: 0.0653 - accuracy: 0.9812\n",
      "Epoch 266/500\n",
      "46/46 [==============================] - 0s 394us/step - loss: 0.0381 - accuracy: 0.9906\n",
      "Epoch 267/500\n",
      "46/46 [==============================] - 0s 411us/step - loss: 0.0760 - accuracy: 0.9656\n",
      "Epoch 268/500\n",
      "46/46 [==============================] - 0s 408us/step - loss: 0.0780 - accuracy: 0.9750\n",
      "Epoch 269/500\n",
      "46/46 [==============================] - 0s 410us/step - loss: 0.0446 - accuracy: 0.9875\n",
      "Epoch 270/500\n",
      "46/46 [==============================] - 0s 449us/step - loss: 0.0697 - accuracy: 0.9750\n",
      "Epoch 271/500\n",
      "46/46 [==============================] - 0s 408us/step - loss: 0.0521 - accuracy: 0.9875\n",
      "Epoch 272/500\n",
      "46/46 [==============================] - 0s 406us/step - loss: 0.0749 - accuracy: 0.9781\n",
      "Epoch 273/500\n",
      "46/46 [==============================] - 0s 389us/step - loss: 0.0717 - accuracy: 0.9750\n",
      "Epoch 274/500\n",
      "46/46 [==============================] - 0s 431us/step - loss: 0.0797 - accuracy: 0.9625\n",
      "Epoch 275/500\n",
      "46/46 [==============================] - 0s 418us/step - loss: 0.0701 - accuracy: 0.9781\n",
      "Epoch 276/500\n",
      "46/46 [==============================] - 0s 405us/step - loss: 0.0873 - accuracy: 0.9625\n",
      "Epoch 277/500\n",
      "46/46 [==============================] - 0s 401us/step - loss: 0.0489 - accuracy: 0.9812\n",
      "Epoch 278/500\n",
      "46/46 [==============================] - 0s 406us/step - loss: 0.0767 - accuracy: 0.9781\n",
      "Epoch 279/500\n",
      "46/46 [==============================] - 0s 416us/step - loss: 0.0464 - accuracy: 0.9844\n",
      "Epoch 280/500\n",
      "46/46 [==============================] - 0s 393us/step - loss: 0.0390 - accuracy: 0.9875\n",
      "Epoch 281/500\n",
      "46/46 [==============================] - 0s 397us/step - loss: 0.0482 - accuracy: 0.9875\n",
      "Epoch 282/500\n",
      "46/46 [==============================] - 0s 411us/step - loss: 0.0618 - accuracy: 0.9750\n",
      "Epoch 283/500\n",
      "46/46 [==============================] - 0s 390us/step - loss: 0.0571 - accuracy: 0.9781\n",
      "Epoch 284/500\n",
      "46/46 [==============================] - 0s 479us/step - loss: 0.0736 - accuracy: 0.9750\n",
      "Epoch 285/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 419us/step - loss: 0.0644 - accuracy: 0.9844\n",
      "Epoch 286/500\n",
      "46/46 [==============================] - 0s 409us/step - loss: 0.0494 - accuracy: 0.9781\n",
      "Epoch 287/500\n",
      "46/46 [==============================] - 0s 430us/step - loss: 0.0488 - accuracy: 0.9781\n",
      "Epoch 288/500\n",
      "46/46 [==============================] - 0s 409us/step - loss: 0.0707 - accuracy: 0.9812\n",
      "Epoch 289/500\n",
      "46/46 [==============================] - 0s 413us/step - loss: 0.0691 - accuracy: 0.9781\n",
      "Epoch 290/500\n",
      "46/46 [==============================] - 0s 391us/step - loss: 0.0375 - accuracy: 0.9875\n",
      "Epoch 291/500\n",
      "46/46 [==============================] - 0s 415us/step - loss: 0.1038 - accuracy: 0.9594\n",
      "Epoch 292/500\n",
      "46/46 [==============================] - 0s 400us/step - loss: 0.0524 - accuracy: 0.9812\n",
      "Epoch 293/500\n",
      "46/46 [==============================] - 0s 396us/step - loss: 0.0705 - accuracy: 0.9781\n",
      "Epoch 294/500\n",
      "46/46 [==============================] - 0s 438us/step - loss: 0.0710 - accuracy: 0.9781\n",
      "Epoch 295/500\n",
      "46/46 [==============================] - 0s 445us/step - loss: 0.0602 - accuracy: 0.9844\n",
      "Epoch 296/500\n",
      "46/46 [==============================] - 0s 485us/step - loss: 0.0558 - accuracy: 0.9812\n",
      "Epoch 297/500\n",
      "46/46 [==============================] - 0s 432us/step - loss: 0.0412 - accuracy: 0.9875\n",
      "Epoch 298/500\n",
      "46/46 [==============================] - 0s 414us/step - loss: 0.0723 - accuracy: 0.9688\n",
      "Epoch 299/500\n",
      "46/46 [==============================] - 0s 403us/step - loss: 0.0704 - accuracy: 0.9688\n",
      "Epoch 300/500\n",
      "46/46 [==============================] - 0s 412us/step - loss: 0.0873 - accuracy: 0.9625\n",
      "Epoch 301/500\n",
      "46/46 [==============================] - 0s 413us/step - loss: 0.1047 - accuracy: 0.9594\n",
      "Epoch 302/500\n",
      "46/46 [==============================] - 0s 400us/step - loss: 0.0531 - accuracy: 0.9812\n",
      "Epoch 303/500\n",
      "46/46 [==============================] - 0s 420us/step - loss: 0.0444 - accuracy: 0.9844\n",
      "Epoch 304/500\n",
      "46/46 [==============================] - 0s 410us/step - loss: 0.0819 - accuracy: 0.9625\n",
      "Epoch 305/500\n",
      "46/46 [==============================] - 0s 448us/step - loss: 0.0788 - accuracy: 0.9750\n",
      "Epoch 306/500\n",
      "46/46 [==============================] - 0s 424us/step - loss: 0.0538 - accuracy: 0.9844\n",
      "Epoch 307/500\n",
      "46/46 [==============================] - 0s 402us/step - loss: 0.0862 - accuracy: 0.9625\n",
      "Epoch 308/500\n",
      "46/46 [==============================] - 0s 419us/step - loss: 0.0457 - accuracy: 0.9812\n",
      "Epoch 309/500\n",
      "46/46 [==============================] - 0s 471us/step - loss: 0.0199 - accuracy: 0.9937\n",
      "Epoch 310/500\n",
      "46/46 [==============================] - 0s 486us/step - loss: 0.0715 - accuracy: 0.9812\n",
      "Epoch 311/500\n",
      "46/46 [==============================] - 0s 409us/step - loss: 0.0623 - accuracy: 0.9781\n",
      "Epoch 312/500\n",
      "46/46 [==============================] - 0s 451us/step - loss: 0.0549 - accuracy: 0.9875\n",
      "Epoch 313/500\n",
      "46/46 [==============================] - 0s 407us/step - loss: 0.0554 - accuracy: 0.9844\n",
      "Epoch 314/500\n",
      "46/46 [==============================] - 0s 413us/step - loss: 0.0473 - accuracy: 0.9812\n",
      "Epoch 315/500\n",
      "46/46 [==============================] - 0s 396us/step - loss: 0.0600 - accuracy: 0.9719\n",
      "Epoch 316/500\n",
      "46/46 [==============================] - 0s 399us/step - loss: 0.0445 - accuracy: 0.9875\n",
      "Epoch 317/500\n",
      "46/46 [==============================] - 0s 430us/step - loss: 0.0328 - accuracy: 0.9875\n",
      "Epoch 318/500\n",
      "46/46 [==============================] - 0s 400us/step - loss: 0.0654 - accuracy: 0.9781\n",
      "Epoch 319/500\n",
      "46/46 [==============================] - 0s 402us/step - loss: 0.0644 - accuracy: 0.9812\n",
      "Epoch 320/500\n",
      "46/46 [==============================] - 0s 418us/step - loss: 0.0521 - accuracy: 0.9719\n",
      "Epoch 321/500\n",
      "46/46 [==============================] - 0s 428us/step - loss: 0.0230 - accuracy: 0.9937\n",
      "Epoch 322/500\n",
      "46/46 [==============================] - 0s 413us/step - loss: 0.0324 - accuracy: 0.9875\n",
      "Epoch 323/500\n",
      "46/46 [==============================] - 0s 425us/step - loss: 0.0193 - accuracy: 0.9937\n",
      "Epoch 324/500\n",
      "46/46 [==============================] - 0s 435us/step - loss: 0.0431 - accuracy: 0.9875\n",
      "Epoch 325/500\n",
      "46/46 [==============================] - 0s 414us/step - loss: 0.0499 - accuracy: 0.9844\n",
      "Epoch 326/500\n",
      "46/46 [==============================] - 0s 414us/step - loss: 0.0624 - accuracy: 0.9750\n",
      "Epoch 327/500\n",
      "46/46 [==============================] - 0s 423us/step - loss: 0.0657 - accuracy: 0.9844\n",
      "Epoch 328/500\n",
      "46/46 [==============================] - 0s 389us/step - loss: 0.0256 - accuracy: 0.9906\n",
      "Epoch 329/500\n",
      "46/46 [==============================] - 0s 434us/step - loss: 0.0591 - accuracy: 0.9688\n",
      "Epoch 330/500\n",
      "46/46 [==============================] - 0s 404us/step - loss: 0.0773 - accuracy: 0.9719\n",
      "Epoch 331/500\n",
      "46/46 [==============================] - 0s 416us/step - loss: 0.0763 - accuracy: 0.9688\n",
      "Epoch 332/500\n",
      "46/46 [==============================] - 0s 461us/step - loss: 0.0623 - accuracy: 0.9750\n",
      "Epoch 333/500\n",
      "46/46 [==============================] - 0s 440us/step - loss: 0.0855 - accuracy: 0.9688\n",
      "Epoch 334/500\n",
      "46/46 [==============================] - 0s 414us/step - loss: 0.1743 - accuracy: 0.9375\n",
      "Epoch 335/500\n",
      "46/46 [==============================] - 0s 391us/step - loss: 0.0994 - accuracy: 0.9594\n",
      "Epoch 336/500\n",
      "46/46 [==============================] - 0s 407us/step - loss: 0.0626 - accuracy: 0.9812\n",
      "Epoch 337/500\n",
      "46/46 [==============================] - 0s 399us/step - loss: 0.0641 - accuracy: 0.9875\n",
      "Epoch 338/500\n",
      "46/46 [==============================] - 0s 396us/step - loss: 0.0413 - accuracy: 0.9875\n",
      "Epoch 339/500\n",
      "46/46 [==============================] - 0s 418us/step - loss: 0.0397 - accuracy: 0.9844\n",
      "Epoch 340/500\n",
      "46/46 [==============================] - 0s 404us/step - loss: 0.0331 - accuracy: 0.9906\n",
      "Epoch 341/500\n",
      "46/46 [==============================] - 0s 420us/step - loss: 0.0489 - accuracy: 0.9906\n",
      "Epoch 342/500\n",
      "46/46 [==============================] - 0s 415us/step - loss: 0.0514 - accuracy: 0.9781\n",
      "Epoch 343/500\n",
      "46/46 [==============================] - 0s 408us/step - loss: 0.0300 - accuracy: 0.9906\n",
      "Epoch 344/500\n",
      "46/46 [==============================] - 0s 417us/step - loss: 0.0328 - accuracy: 0.9937\n",
      "Epoch 345/500\n",
      "46/46 [==============================] - 0s 409us/step - loss: 0.0352 - accuracy: 0.9906\n",
      "Epoch 346/500\n",
      "46/46 [==============================] - 0s 409us/step - loss: 0.0816 - accuracy: 0.9844\n",
      "Epoch 347/500\n",
      "46/46 [==============================] - 0s 389us/step - loss: 0.0531 - accuracy: 0.9781\n",
      "Epoch 348/500\n",
      "46/46 [==============================] - 0s 403us/step - loss: 0.0277 - accuracy: 0.9906\n",
      "Epoch 349/500\n",
      "46/46 [==============================] - 0s 416us/step - loss: 0.0367 - accuracy: 0.9875\n",
      "Epoch 350/500\n",
      "46/46 [==============================] - 0s 476us/step - loss: 0.0220 - accuracy: 0.9969\n",
      "Epoch 351/500\n",
      "46/46 [==============================] - 0s 411us/step - loss: 0.0389 - accuracy: 0.9906\n",
      "Epoch 352/500\n",
      "46/46 [==============================] - 0s 385us/step - loss: 0.0369 - accuracy: 0.9844\n",
      "Epoch 353/500\n",
      "46/46 [==============================] - 0s 426us/step - loss: 0.0441 - accuracy: 0.9875\n",
      "Epoch 354/500\n",
      "46/46 [==============================] - 0s 420us/step - loss: 0.0945 - accuracy: 0.9781\n",
      "Epoch 355/500\n",
      "46/46 [==============================] - 0s 437us/step - loss: 0.0854 - accuracy: 0.9719\n",
      "Epoch 356/500\n",
      "46/46 [==============================] - 0s 409us/step - loss: 0.0551 - accuracy: 0.9844\n",
      "Epoch 357/500\n",
      "46/46 [==============================] - 0s 404us/step - loss: 0.0475 - accuracy: 0.9906\n",
      "Epoch 358/500\n",
      "46/46 [==============================] - 0s 408us/step - loss: 0.0314 - accuracy: 0.9906\n",
      "Epoch 359/500\n",
      "46/46 [==============================] - 0s 461us/step - loss: 0.0613 - accuracy: 0.9875\n",
      "Epoch 360/500\n",
      "46/46 [==============================] - 0s 429us/step - loss: 0.0895 - accuracy: 0.9656\n",
      "Epoch 361/500\n",
      "46/46 [==============================] - 0s 409us/step - loss: 0.0676 - accuracy: 0.9750\n",
      "Epoch 362/500\n",
      "46/46 [==============================] - 0s 408us/step - loss: 0.0461 - accuracy: 0.9781\n",
      "Epoch 363/500\n",
      "46/46 [==============================] - 0s 432us/step - loss: 0.0306 - accuracy: 0.9844\n",
      "Epoch 364/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 426us/step - loss: 0.0702 - accuracy: 0.9844\n",
      "Epoch 365/500\n",
      "46/46 [==============================] - 0s 429us/step - loss: 0.0492 - accuracy: 0.9812\n",
      "Epoch 366/500\n",
      "46/46 [==============================] - 0s 413us/step - loss: 0.0381 - accuracy: 0.9937\n",
      "Epoch 367/500\n",
      "46/46 [==============================] - 0s 419us/step - loss: 0.0443 - accuracy: 0.9844\n",
      "Epoch 368/500\n",
      "46/46 [==============================] - 0s 423us/step - loss: 0.0506 - accuracy: 0.9875\n",
      "Epoch 369/500\n",
      "46/46 [==============================] - 0s 434us/step - loss: 0.0668 - accuracy: 0.9719\n",
      "Epoch 370/500\n",
      "46/46 [==============================] - 0s 414us/step - loss: 0.0833 - accuracy: 0.9750\n",
      "Epoch 371/500\n",
      "46/46 [==============================] - 0s 443us/step - loss: 0.0621 - accuracy: 0.9781\n",
      "Epoch 372/500\n",
      "46/46 [==============================] - 0s 428us/step - loss: 0.1123 - accuracy: 0.9688\n",
      "Epoch 373/500\n",
      "46/46 [==============================] - 0s 413us/step - loss: 0.0367 - accuracy: 0.9844\n",
      "Epoch 374/500\n",
      "46/46 [==============================] - 0s 432us/step - loss: 0.0551 - accuracy: 0.9812\n",
      "Epoch 375/500\n",
      "46/46 [==============================] - 0s 417us/step - loss: 0.0407 - accuracy: 0.9875\n",
      "Epoch 376/500\n",
      "46/46 [==============================] - 0s 404us/step - loss: 0.0393 - accuracy: 0.9812\n",
      "Epoch 377/500\n",
      "46/46 [==============================] - 0s 400us/step - loss: 0.0438 - accuracy: 0.9875\n",
      "Epoch 378/500\n",
      "46/46 [==============================] - 0s 424us/step - loss: 0.0624 - accuracy: 0.9750\n",
      "Epoch 379/500\n",
      "46/46 [==============================] - 0s 399us/step - loss: 0.0701 - accuracy: 0.9750\n",
      "Epoch 380/500\n",
      "46/46 [==============================] - 0s 414us/step - loss: 0.0368 - accuracy: 0.9875\n",
      "Epoch 381/500\n",
      "46/46 [==============================] - 0s 402us/step - loss: 0.0711 - accuracy: 0.9781\n",
      "Epoch 382/500\n",
      "46/46 [==============================] - 0s 406us/step - loss: 0.0135 - accuracy: 1.0000\n",
      "Epoch 383/500\n",
      "46/46 [==============================] - 0s 410us/step - loss: 0.0422 - accuracy: 0.9906\n",
      "Epoch 384/500\n",
      "46/46 [==============================] - 0s 401us/step - loss: 0.0285 - accuracy: 0.9906\n",
      "Epoch 385/500\n",
      "46/46 [==============================] - 0s 398us/step - loss: 0.0368 - accuracy: 0.9844\n",
      "Epoch 386/500\n",
      "46/46 [==============================] - 0s 400us/step - loss: 0.0363 - accuracy: 0.9875\n",
      "Epoch 387/500\n",
      "46/46 [==============================] - 0s 408us/step - loss: 0.0332 - accuracy: 0.9906\n",
      "Epoch 388/500\n",
      "46/46 [==============================] - 0s 409us/step - loss: 0.0177 - accuracy: 0.9937\n",
      "Epoch 389/500\n",
      "46/46 [==============================] - 0s 407us/step - loss: 0.0202 - accuracy: 0.9906\n",
      "Epoch 390/500\n",
      "46/46 [==============================] - 0s 399us/step - loss: 0.0529 - accuracy: 0.9781\n",
      "Epoch 391/500\n",
      "46/46 [==============================] - 0s 402us/step - loss: 0.0910 - accuracy: 0.9844\n",
      "Epoch 392/500\n",
      "46/46 [==============================] - 0s 398us/step - loss: 0.0807 - accuracy: 0.9656\n",
      "Epoch 393/500\n",
      "46/46 [==============================] - 0s 399us/step - loss: 0.1108 - accuracy: 0.9563\n",
      "Epoch 394/500\n",
      "46/46 [==============================] - 0s 407us/step - loss: 0.0543 - accuracy: 0.9875\n",
      "Epoch 395/500\n",
      "46/46 [==============================] - 0s 399us/step - loss: 0.0595 - accuracy: 0.9750\n",
      "Epoch 396/500\n",
      "46/46 [==============================] - 0s 417us/step - loss: 0.0423 - accuracy: 0.9875\n",
      "Epoch 397/500\n",
      "46/46 [==============================] - 0s 408us/step - loss: 0.0573 - accuracy: 0.9781\n",
      "Epoch 398/500\n",
      "46/46 [==============================] - 0s 401us/step - loss: 0.0860 - accuracy: 0.9625\n",
      "Epoch 399/500\n",
      "46/46 [==============================] - 0s 395us/step - loss: 0.0970 - accuracy: 0.9625\n",
      "Epoch 400/500\n",
      "46/46 [==============================] - 0s 503us/step - loss: 0.0770 - accuracy: 0.9781\n",
      "Epoch 401/500\n",
      "46/46 [==============================] - 0s 412us/step - loss: 0.0510 - accuracy: 0.9844\n",
      "Epoch 402/500\n",
      "46/46 [==============================] - 0s 415us/step - loss: 0.0898 - accuracy: 0.9719\n",
      "Epoch 403/500\n",
      "46/46 [==============================] - 0s 400us/step - loss: 0.0490 - accuracy: 0.9844\n",
      "Epoch 404/500\n",
      "46/46 [==============================] - 0s 419us/step - loss: 0.0776 - accuracy: 0.9812\n",
      "Epoch 405/500\n",
      "46/46 [==============================] - 0s 406us/step - loss: 0.0836 - accuracy: 0.9750\n",
      "Epoch 406/500\n",
      "46/46 [==============================] - 0s 417us/step - loss: 0.0720 - accuracy: 0.9781\n",
      "Epoch 407/500\n",
      "46/46 [==============================] - 0s 425us/step - loss: 0.0863 - accuracy: 0.9531\n",
      "Epoch 408/500\n",
      "46/46 [==============================] - 0s 418us/step - loss: 0.0573 - accuracy: 0.9688\n",
      "Epoch 409/500\n",
      "46/46 [==============================] - 0s 407us/step - loss: 0.0578 - accuracy: 0.9781\n",
      "Epoch 410/500\n",
      "46/46 [==============================] - 0s 426us/step - loss: 0.0523 - accuracy: 0.9875\n",
      "Epoch 411/500\n",
      "46/46 [==============================] - 0s 395us/step - loss: 0.0559 - accuracy: 0.9750\n",
      "Epoch 412/500\n",
      "46/46 [==============================] - 0s 401us/step - loss: 0.0365 - accuracy: 0.9906\n",
      "Epoch 413/500\n",
      "46/46 [==============================] - 0s 419us/step - loss: 0.0682 - accuracy: 0.9844\n",
      "Epoch 414/500\n",
      "46/46 [==============================] - 0s 400us/step - loss: 0.0490 - accuracy: 0.9844\n",
      "Epoch 415/500\n",
      "46/46 [==============================] - 0s 390us/step - loss: 0.0390 - accuracy: 0.9906\n",
      "Epoch 416/500\n",
      "46/46 [==============================] - 0s 391us/step - loss: 0.0429 - accuracy: 0.9844\n",
      "Epoch 417/500\n",
      "46/46 [==============================] - 0s 402us/step - loss: 0.0225 - accuracy: 0.9937\n",
      "Epoch 418/500\n",
      "46/46 [==============================] - 0s 410us/step - loss: 0.0380 - accuracy: 0.9906\n",
      "Epoch 419/500\n",
      "46/46 [==============================] - 0s 394us/step - loss: 0.0183 - accuracy: 0.9969\n",
      "Epoch 420/500\n",
      "46/46 [==============================] - 0s 394us/step - loss: 0.0166 - accuracy: 0.9937\n",
      "Epoch 421/500\n",
      "46/46 [==============================] - 0s 397us/step - loss: 0.0304 - accuracy: 0.9906\n",
      "Epoch 422/500\n",
      "46/46 [==============================] - 0s 380us/step - loss: 0.0415 - accuracy: 0.9875\n",
      "Epoch 423/500\n",
      "46/46 [==============================] - 0s 406us/step - loss: 0.0672 - accuracy: 0.9656\n",
      "Epoch 424/500\n",
      "46/46 [==============================] - 0s 402us/step - loss: 0.0525 - accuracy: 0.9750\n",
      "Epoch 425/500\n",
      "46/46 [==============================] - 0s 392us/step - loss: 0.0618 - accuracy: 0.9781\n",
      "Epoch 426/500\n",
      "46/46 [==============================] - 0s 408us/step - loss: 0.0377 - accuracy: 0.9875\n",
      "Epoch 427/500\n",
      "46/46 [==============================] - 0s 395us/step - loss: 0.0406 - accuracy: 0.9844\n",
      "Epoch 428/500\n",
      "46/46 [==============================] - 0s 403us/step - loss: 0.0316 - accuracy: 0.9844\n",
      "Epoch 429/500\n",
      "46/46 [==============================] - 0s 381us/step - loss: 0.0284 - accuracy: 0.9875\n",
      "Epoch 430/500\n",
      "46/46 [==============================] - 0s 400us/step - loss: 0.0542 - accuracy: 0.9844\n",
      "Epoch 431/500\n",
      "46/46 [==============================] - 0s 405us/step - loss: 0.0530 - accuracy: 0.9875\n",
      "Epoch 432/500\n",
      "46/46 [==============================] - 0s 426us/step - loss: 0.0926 - accuracy: 0.9719\n",
      "Epoch 433/500\n",
      "46/46 [==============================] - 0s 410us/step - loss: 0.0853 - accuracy: 0.9594\n",
      "Epoch 434/500\n",
      "46/46 [==============================] - 0s 389us/step - loss: 0.0652 - accuracy: 0.9781\n",
      "Epoch 435/500\n",
      "46/46 [==============================] - 0s 404us/step - loss: 0.0422 - accuracy: 0.9875\n",
      "Epoch 436/500\n",
      "46/46 [==============================] - 0s 415us/step - loss: 0.0332 - accuracy: 0.9906\n",
      "Epoch 437/500\n",
      "46/46 [==============================] - 0s 399us/step - loss: 0.0280 - accuracy: 0.9906\n",
      "Epoch 438/500\n",
      "46/46 [==============================] - 0s 421us/step - loss: 0.0652 - accuracy: 0.9781\n",
      "Epoch 439/500\n",
      "46/46 [==============================] - 0s 402us/step - loss: 0.0803 - accuracy: 0.9688\n",
      "Epoch 440/500\n",
      "46/46 [==============================] - 0s 397us/step - loss: 0.0240 - accuracy: 0.9875\n",
      "Epoch 441/500\n",
      "46/46 [==============================] - 0s 400us/step - loss: 0.0475 - accuracy: 0.9844\n",
      "Epoch 442/500\n",
      "46/46 [==============================] - 0s 392us/step - loss: 0.0617 - accuracy: 0.9750\n",
      "Epoch 443/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 404us/step - loss: 0.0444 - accuracy: 0.9906\n",
      "Epoch 444/500\n",
      "46/46 [==============================] - 0s 402us/step - loss: 0.0354 - accuracy: 0.9844\n",
      "Epoch 445/500\n",
      "46/46 [==============================] - 0s 406us/step - loss: 0.0957 - accuracy: 0.9719\n",
      "Epoch 446/500\n",
      "46/46 [==============================] - 0s 383us/step - loss: 0.0492 - accuracy: 0.9875\n",
      "Epoch 447/500\n",
      "46/46 [==============================] - 0s 394us/step - loss: 0.0537 - accuracy: 0.9781\n",
      "Epoch 448/500\n",
      "46/46 [==============================] - 0s 402us/step - loss: 0.0434 - accuracy: 0.9844\n",
      "Epoch 449/500\n",
      "46/46 [==============================] - 0s 395us/step - loss: 0.0724 - accuracy: 0.9688\n",
      "Epoch 450/500\n",
      "46/46 [==============================] - 0s 407us/step - loss: 0.0693 - accuracy: 0.9781\n",
      "Epoch 451/500\n",
      "46/46 [==============================] - 0s 392us/step - loss: 0.0429 - accuracy: 0.9844\n",
      "Epoch 452/500\n",
      "46/46 [==============================] - 0s 382us/step - loss: 0.0695 - accuracy: 0.9781\n",
      "Epoch 453/500\n",
      "46/46 [==============================] - 0s 402us/step - loss: 0.0450 - accuracy: 0.9750\n",
      "Epoch 454/500\n",
      "46/46 [==============================] - 0s 400us/step - loss: 0.0659 - accuracy: 0.9719\n",
      "Epoch 455/500\n",
      "46/46 [==============================] - 0s 415us/step - loss: 0.0337 - accuracy: 0.9844\n",
      "Epoch 456/500\n",
      "46/46 [==============================] - 0s 458us/step - loss: 0.0146 - accuracy: 0.9969\n",
      "Epoch 457/500\n",
      "46/46 [==============================] - 0s 430us/step - loss: 0.0292 - accuracy: 0.9875\n",
      "Epoch 458/500\n",
      "46/46 [==============================] - 0s 430us/step - loss: 0.0171 - accuracy: 0.9937\n",
      "Epoch 459/500\n",
      "46/46 [==============================] - 0s 441us/step - loss: 0.0670 - accuracy: 0.9750\n",
      "Epoch 460/500\n",
      "46/46 [==============================] - 0s 445us/step - loss: 0.0632 - accuracy: 0.9781\n",
      "Epoch 461/500\n",
      "46/46 [==============================] - 0s 435us/step - loss: 0.0255 - accuracy: 0.9937\n",
      "Epoch 462/500\n",
      "46/46 [==============================] - 0s 428us/step - loss: 0.0419 - accuracy: 0.9781\n",
      "Epoch 463/500\n",
      "46/46 [==============================] - 0s 410us/step - loss: 0.0308 - accuracy: 0.9906\n",
      "Epoch 464/500\n",
      "46/46 [==============================] - 0s 445us/step - loss: 0.0421 - accuracy: 0.9875\n",
      "Epoch 465/500\n",
      "46/46 [==============================] - 0s 440us/step - loss: 0.0324 - accuracy: 0.9937\n",
      "Epoch 466/500\n",
      "46/46 [==============================] - 0s 427us/step - loss: 0.0296 - accuracy: 0.9906\n",
      "Epoch 467/500\n",
      "46/46 [==============================] - 0s 428us/step - loss: 0.0344 - accuracy: 0.9875\n",
      "Epoch 468/500\n",
      "46/46 [==============================] - 0s 415us/step - loss: 0.0174 - accuracy: 0.9969\n",
      "Epoch 469/500\n",
      "46/46 [==============================] - 0s 435us/step - loss: 0.0211 - accuracy: 0.9875\n",
      "Epoch 470/500\n",
      "46/46 [==============================] - 0s 417us/step - loss: 0.0155 - accuracy: 0.9969\n",
      "Epoch 471/500\n",
      "46/46 [==============================] - 0s 409us/step - loss: 0.0432 - accuracy: 0.9844\n",
      "Epoch 472/500\n",
      "46/46 [==============================] - 0s 415us/step - loss: 0.0521 - accuracy: 0.9875\n",
      "Epoch 473/500\n",
      "46/46 [==============================] - 0s 403us/step - loss: 0.1131 - accuracy: 0.9812\n",
      "Epoch 474/500\n",
      "46/46 [==============================] - 0s 426us/step - loss: 0.0457 - accuracy: 0.9844\n",
      "Epoch 475/500\n",
      "46/46 [==============================] - 0s 405us/step - loss: 0.0320 - accuracy: 0.9906\n",
      "Epoch 476/500\n",
      "46/46 [==============================] - 0s 409us/step - loss: 0.0431 - accuracy: 0.9844\n",
      "Epoch 477/500\n",
      "46/46 [==============================] - 0s 387us/step - loss: 0.0497 - accuracy: 0.9781\n",
      "Epoch 478/500\n",
      "46/46 [==============================] - 0s 397us/step - loss: 0.0320 - accuracy: 0.9844\n",
      "Epoch 479/500\n",
      "46/46 [==============================] - 0s 407us/step - loss: 0.0766 - accuracy: 0.9719\n",
      "Epoch 480/500\n",
      "46/46 [==============================] - 0s 399us/step - loss: 0.0562 - accuracy: 0.9781\n",
      "Epoch 481/500\n",
      "46/46 [==============================] - 0s 411us/step - loss: 0.0483 - accuracy: 0.9812\n",
      "Epoch 482/500\n",
      "46/46 [==============================] - 0s 383us/step - loss: 0.0310 - accuracy: 0.9844\n",
      "Epoch 483/500\n",
      "46/46 [==============================] - 0s 409us/step - loss: 0.0512 - accuracy: 0.9906\n",
      "Epoch 484/500\n",
      "46/46 [==============================] - 0s 450us/step - loss: 0.0388 - accuracy: 0.9875\n",
      "Epoch 485/500\n",
      "46/46 [==============================] - 0s 401us/step - loss: 0.0609 - accuracy: 0.9844\n",
      "Epoch 486/500\n",
      "46/46 [==============================] - 0s 409us/step - loss: 0.0535 - accuracy: 0.9844\n",
      "Epoch 487/500\n",
      "46/46 [==============================] - 0s 393us/step - loss: 0.0442 - accuracy: 0.9875\n",
      "Epoch 488/500\n",
      "46/46 [==============================] - 0s 401us/step - loss: 0.0202 - accuracy: 0.9937\n",
      "Epoch 489/500\n",
      "46/46 [==============================] - 0s 409us/step - loss: 0.0697 - accuracy: 0.9656\n",
      "Epoch 490/500\n",
      "46/46 [==============================] - 0s 397us/step - loss: 0.0435 - accuracy: 0.9812\n",
      "Epoch 491/500\n",
      "46/46 [==============================] - 0s 416us/step - loss: 0.0479 - accuracy: 0.9812\n",
      "Epoch 492/500\n",
      "46/46 [==============================] - 0s 398us/step - loss: 0.0510 - accuracy: 0.9781\n",
      "Epoch 493/500\n",
      "46/46 [==============================] - 0s 408us/step - loss: 0.0573 - accuracy: 0.9781\n",
      "Epoch 494/500\n",
      "46/46 [==============================] - 0s 421us/step - loss: 0.0620 - accuracy: 0.9719\n",
      "Epoch 495/500\n",
      "46/46 [==============================] - 0s 398us/step - loss: 0.0400 - accuracy: 0.9844\n",
      "Epoch 496/500\n",
      "46/46 [==============================] - 0s 424us/step - loss: 0.0833 - accuracy: 0.9688\n",
      "Epoch 497/500\n",
      "46/46 [==============================] - 0s 399us/step - loss: 0.0494 - accuracy: 0.9781\n",
      "Epoch 498/500\n",
      "46/46 [==============================] - 0s 422us/step - loss: 0.0164 - accuracy: 0.9969\n",
      "Epoch 499/500\n",
      "46/46 [==============================] - 0s 409us/step - loss: 0.0240 - accuracy: 0.9937\n",
      "Epoch 500/500\n",
      "46/46 [==============================] - 0s 415us/step - loss: 0.0124 - accuracy: 0.9969\n",
      "Model: \"Sequential-NN\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_12 (Dense)             (None, 42)                1806      \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 42)                0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 256)               11008     \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 5)                 1285      \n",
      "=================================================================\n",
      "Total params: 14,099\n",
      "Trainable params: 14,099\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/500\n",
      "46/46 [==============================] - 0s 417us/step - loss: 1.6059 - accuracy: 0.2875\n",
      "Epoch 2/500\n",
      "46/46 [==============================] - 0s 417us/step - loss: 1.4791 - accuracy: 0.4437\n",
      "Epoch 3/500\n",
      "46/46 [==============================] - 0s 400us/step - loss: 1.3299 - accuracy: 0.4625\n",
      "Epoch 4/500\n",
      "46/46 [==============================] - 0s 418us/step - loss: 1.1450 - accuracy: 0.5781\n",
      "Epoch 5/500\n",
      "46/46 [==============================] - 0s 422us/step - loss: 1.0041 - accuracy: 0.5875\n",
      "Epoch 6/500\n",
      "46/46 [==============================] - 0s 425us/step - loss: 0.9384 - accuracy: 0.6125\n",
      "Epoch 7/500\n",
      "46/46 [==============================] - 0s 487us/step - loss: 0.8305 - accuracy: 0.6219\n",
      "Epoch 8/500\n",
      "46/46 [==============================] - 0s 426us/step - loss: 0.7668 - accuracy: 0.7125\n",
      "Epoch 9/500\n",
      "46/46 [==============================] - 0s 416us/step - loss: 0.7491 - accuracy: 0.6625\n",
      "Epoch 10/500\n",
      "46/46 [==============================] - 0s 422us/step - loss: 0.6806 - accuracy: 0.7375\n",
      "Epoch 11/500\n",
      "46/46 [==============================] - 0s 418us/step - loss: 0.6464 - accuracy: 0.7469\n",
      "Epoch 12/500\n",
      "46/46 [==============================] - 0s 424us/step - loss: 0.6068 - accuracy: 0.7844\n",
      "Epoch 13/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 423us/step - loss: 0.5967 - accuracy: 0.7594\n",
      "Epoch 14/500\n",
      "46/46 [==============================] - 0s 423us/step - loss: 0.5034 - accuracy: 0.8156\n",
      "Epoch 15/500\n",
      "46/46 [==============================] - 0s 436us/step - loss: 0.4845 - accuracy: 0.8094\n",
      "Epoch 16/500\n",
      "46/46 [==============================] - 0s 420us/step - loss: 0.4898 - accuracy: 0.8031\n",
      "Epoch 17/500\n",
      "46/46 [==============================] - 0s 448us/step - loss: 0.4723 - accuracy: 0.8062\n",
      "Epoch 18/500\n",
      "46/46 [==============================] - 0s 423us/step - loss: 0.4644 - accuracy: 0.8000\n",
      "Epoch 19/500\n",
      "46/46 [==============================] - 0s 434us/step - loss: 0.4550 - accuracy: 0.8250\n",
      "Epoch 20/500\n",
      "46/46 [==============================] - 0s 421us/step - loss: 0.4275 - accuracy: 0.8344\n",
      "Epoch 21/500\n",
      "46/46 [==============================] - 0s 435us/step - loss: 0.3712 - accuracy: 0.8406\n",
      "Epoch 22/500\n",
      "46/46 [==============================] - 0s 418us/step - loss: 0.4348 - accuracy: 0.8406\n",
      "Epoch 23/500\n",
      "46/46 [==============================] - 0s 416us/step - loss: 0.3648 - accuracy: 0.8500\n",
      "Epoch 24/500\n",
      "46/46 [==============================] - 0s 443us/step - loss: 0.3355 - accuracy: 0.8750\n",
      "Epoch 25/500\n",
      "46/46 [==============================] - 0s 452us/step - loss: 0.3717 - accuracy: 0.8562\n",
      "Epoch 26/500\n",
      "46/46 [==============================] - 0s 437us/step - loss: 0.3705 - accuracy: 0.8687\n",
      "Epoch 27/500\n",
      "46/46 [==============================] - 0s 443us/step - loss: 0.3451 - accuracy: 0.8750\n",
      "Epoch 28/500\n",
      "46/46 [==============================] - 0s 440us/step - loss: 0.3381 - accuracy: 0.8719\n",
      "Epoch 29/500\n",
      "46/46 [==============================] - 0s 427us/step - loss: 0.3436 - accuracy: 0.8750\n",
      "Epoch 30/500\n",
      "46/46 [==============================] - 0s 437us/step - loss: 0.3448 - accuracy: 0.8844\n",
      "Epoch 31/500\n",
      "46/46 [==============================] - 0s 420us/step - loss: 0.2913 - accuracy: 0.8906\n",
      "Epoch 32/500\n",
      "46/46 [==============================] - 0s 421us/step - loss: 0.3046 - accuracy: 0.8844\n",
      "Epoch 33/500\n",
      "46/46 [==============================] - 0s 438us/step - loss: 0.2960 - accuracy: 0.8781\n",
      "Epoch 34/500\n",
      "46/46 [==============================] - 0s 438us/step - loss: 0.3345 - accuracy: 0.8656\n",
      "Epoch 35/500\n",
      "46/46 [==============================] - 0s 433us/step - loss: 0.2667 - accuracy: 0.8938\n",
      "Epoch 36/500\n",
      "46/46 [==============================] - 0s 431us/step - loss: 0.2878 - accuracy: 0.8969\n",
      "Epoch 37/500\n",
      "46/46 [==============================] - 0s 472us/step - loss: 0.2874 - accuracy: 0.8906\n",
      "Epoch 38/500\n",
      "46/46 [==============================] - 0s 427us/step - loss: 0.2824 - accuracy: 0.9000\n",
      "Epoch 39/500\n",
      "46/46 [==============================] - 0s 424us/step - loss: 0.2831 - accuracy: 0.8906\n",
      "Epoch 40/500\n",
      "46/46 [==============================] - 0s 464us/step - loss: 0.2530 - accuracy: 0.9062\n",
      "Epoch 41/500\n",
      "46/46 [==============================] - 0s 432us/step - loss: 0.2623 - accuracy: 0.8906\n",
      "Epoch 42/500\n",
      "46/46 [==============================] - 0s 426us/step - loss: 0.2541 - accuracy: 0.9031\n",
      "Epoch 43/500\n",
      "46/46 [==============================] - 0s 464us/step - loss: 0.2405 - accuracy: 0.8969\n",
      "Epoch 44/500\n",
      "46/46 [==============================] - 0s 421us/step - loss: 0.2357 - accuracy: 0.9031\n",
      "Epoch 45/500\n",
      "46/46 [==============================] - 0s 439us/step - loss: 0.2448 - accuracy: 0.9125\n",
      "Epoch 46/500\n",
      "46/46 [==============================] - 0s 434us/step - loss: 0.2270 - accuracy: 0.9187\n",
      "Epoch 47/500\n",
      "46/46 [==============================] - 0s 422us/step - loss: 0.2419 - accuracy: 0.9031\n",
      "Epoch 48/500\n",
      "46/46 [==============================] - 0s 420us/step - loss: 0.2167 - accuracy: 0.9312\n",
      "Epoch 49/500\n",
      "46/46 [==============================] - 0s 427us/step - loss: 0.2086 - accuracy: 0.9281\n",
      "Epoch 50/500\n",
      "46/46 [==============================] - 0s 436us/step - loss: 0.2238 - accuracy: 0.9219\n",
      "Epoch 51/500\n",
      "46/46 [==============================] - 0s 432us/step - loss: 0.2164 - accuracy: 0.9281\n",
      "Epoch 52/500\n",
      "46/46 [==============================] - 0s 437us/step - loss: 0.2015 - accuracy: 0.9094\n",
      "Epoch 53/500\n",
      "46/46 [==============================] - 0s 431us/step - loss: 0.2023 - accuracy: 0.9156\n",
      "Epoch 54/500\n",
      "46/46 [==============================] - 0s 470us/step - loss: 0.1955 - accuracy: 0.9344\n",
      "Epoch 55/500\n",
      "46/46 [==============================] - 0s 417us/step - loss: 0.1893 - accuracy: 0.9406\n",
      "Epoch 56/500\n",
      "46/46 [==============================] - 0s 458us/step - loss: 0.1774 - accuracy: 0.9531\n",
      "Epoch 57/500\n",
      "46/46 [==============================] - 0s 426us/step - loss: 0.1939 - accuracy: 0.9375\n",
      "Epoch 58/500\n",
      "46/46 [==============================] - 0s 416us/step - loss: 0.2039 - accuracy: 0.9281\n",
      "Epoch 59/500\n",
      "46/46 [==============================] - 0s 436us/step - loss: 0.1837 - accuracy: 0.9344\n",
      "Epoch 60/500\n",
      "46/46 [==============================] - 0s 421us/step - loss: 0.1771 - accuracy: 0.9438\n",
      "Epoch 61/500\n",
      "46/46 [==============================] - 0s 502us/step - loss: 0.1551 - accuracy: 0.9531\n",
      "Epoch 62/500\n",
      "46/46 [==============================] - 0s 439us/step - loss: 0.1834 - accuracy: 0.9375\n",
      "Epoch 63/500\n",
      "46/46 [==============================] - 0s 476us/step - loss: 0.1691 - accuracy: 0.9438\n",
      "Epoch 64/500\n",
      "46/46 [==============================] - 0s 429us/step - loss: 0.1661 - accuracy: 0.9469\n",
      "Epoch 65/500\n",
      "46/46 [==============================] - 0s 405us/step - loss: 0.1779 - accuracy: 0.9250\n",
      "Epoch 66/500\n",
      "46/46 [==============================] - 0s 473us/step - loss: 0.1574 - accuracy: 0.9438\n",
      "Epoch 67/500\n",
      "46/46 [==============================] - 0s 409us/step - loss: 0.1664 - accuracy: 0.9438\n",
      "Epoch 68/500\n",
      "46/46 [==============================] - 0s 413us/step - loss: 0.2026 - accuracy: 0.9156\n",
      "Epoch 69/500\n",
      "46/46 [==============================] - 0s 425us/step - loss: 0.1808 - accuracy: 0.9375\n",
      "Epoch 70/500\n",
      "46/46 [==============================] - 0s 418us/step - loss: 0.1700 - accuracy: 0.9406\n",
      "Epoch 71/500\n",
      "46/46 [==============================] - 0s 466us/step - loss: 0.1669 - accuracy: 0.9312\n",
      "Epoch 72/500\n",
      "46/46 [==============================] - 0s 501us/step - loss: 0.1851 - accuracy: 0.9250\n",
      "Epoch 73/500\n",
      "46/46 [==============================] - 0s 413us/step - loss: 0.1310 - accuracy: 0.9500\n",
      "Epoch 74/500\n",
      "46/46 [==============================] - 0s 453us/step - loss: 0.1304 - accuracy: 0.9500\n",
      "Epoch 75/500\n",
      "46/46 [==============================] - 0s 415us/step - loss: 0.1527 - accuracy: 0.9438\n",
      "Epoch 76/500\n",
      "46/46 [==============================] - 0s 423us/step - loss: 0.1575 - accuracy: 0.9531\n",
      "Epoch 77/500\n",
      "46/46 [==============================] - 0s 425us/step - loss: 0.1441 - accuracy: 0.9531\n",
      "Epoch 78/500\n",
      "46/46 [==============================] - 0s 427us/step - loss: 0.1517 - accuracy: 0.9500\n",
      "Epoch 79/500\n",
      "46/46 [==============================] - 0s 403us/step - loss: 0.1188 - accuracy: 0.9625\n",
      "Epoch 80/500\n",
      "46/46 [==============================] - 0s 394us/step - loss: 0.1426 - accuracy: 0.9500\n",
      "Epoch 81/500\n",
      "46/46 [==============================] - 0s 396us/step - loss: 0.1092 - accuracy: 0.9750\n",
      "Epoch 82/500\n",
      "46/46 [==============================] - 0s 409us/step - loss: 0.1552 - accuracy: 0.9469\n",
      "Epoch 83/500\n",
      "46/46 [==============================] - 0s 386us/step - loss: 0.1226 - accuracy: 0.9688\n",
      "Epoch 84/500\n",
      "46/46 [==============================] - 0s 410us/step - loss: 0.1380 - accuracy: 0.9563\n",
      "Epoch 85/500\n",
      "46/46 [==============================] - 0s 454us/step - loss: 0.1461 - accuracy: 0.9469\n",
      "Epoch 86/500\n",
      "46/46 [==============================] - 0s 418us/step - loss: 0.1218 - accuracy: 0.9594\n",
      "Epoch 87/500\n",
      "46/46 [==============================] - 0s 395us/step - loss: 0.1196 - accuracy: 0.9656\n",
      "Epoch 88/500\n",
      "46/46 [==============================] - 0s 412us/step - loss: 0.1195 - accuracy: 0.9625\n",
      "Epoch 89/500\n",
      "46/46 [==============================] - 0s 419us/step - loss: 0.1500 - accuracy: 0.9531\n",
      "Epoch 90/500\n",
      "46/46 [==============================] - 0s 419us/step - loss: 0.1210 - accuracy: 0.9500\n",
      "Epoch 91/500\n",
      "46/46 [==============================] - 0s 448us/step - loss: 0.1142 - accuracy: 0.9656\n",
      "Epoch 92/500\n",
      "46/46 [==============================] - 0s 418us/step - loss: 0.1352 - accuracy: 0.9531\n",
      "Epoch 93/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 428us/step - loss: 0.1189 - accuracy: 0.9625\n",
      "Epoch 94/500\n",
      "46/46 [==============================] - 0s 439us/step - loss: 0.1097 - accuracy: 0.9563\n",
      "Epoch 95/500\n",
      "46/46 [==============================] - 0s 395us/step - loss: 0.1223 - accuracy: 0.9563\n",
      "Epoch 96/500\n",
      "46/46 [==============================] - 0s 418us/step - loss: 0.0920 - accuracy: 0.9719\n",
      "Epoch 97/500\n",
      "46/46 [==============================] - 0s 408us/step - loss: 0.1263 - accuracy: 0.9531\n",
      "Epoch 98/500\n",
      "46/46 [==============================] - 0s 392us/step - loss: 0.1280 - accuracy: 0.9469\n",
      "Epoch 99/500\n",
      "46/46 [==============================] - 0s 400us/step - loss: 0.1052 - accuracy: 0.9625\n",
      "Epoch 100/500\n",
      "46/46 [==============================] - 0s 395us/step - loss: 0.1270 - accuracy: 0.9563\n",
      "Epoch 101/500\n",
      "46/46 [==============================] - 0s 403us/step - loss: 0.1198 - accuracy: 0.9594\n",
      "Epoch 102/500\n",
      "46/46 [==============================] - 0s 410us/step - loss: 0.1258 - accuracy: 0.9594\n",
      "Epoch 103/500\n",
      "46/46 [==============================] - 0s 402us/step - loss: 0.1647 - accuracy: 0.9406\n",
      "Epoch 104/500\n",
      "46/46 [==============================] - 0s 386us/step - loss: 0.1122 - accuracy: 0.9594\n",
      "Epoch 105/500\n",
      "46/46 [==============================] - 0s 397us/step - loss: 0.1031 - accuracy: 0.9625\n",
      "Epoch 106/500\n",
      "46/46 [==============================] - 0s 401us/step - loss: 0.0957 - accuracy: 0.9719\n",
      "Epoch 107/500\n",
      "46/46 [==============================] - 0s 393us/step - loss: 0.1155 - accuracy: 0.9531\n",
      "Epoch 108/500\n",
      "46/46 [==============================] - 0s 386us/step - loss: 0.0645 - accuracy: 0.9812\n",
      "Epoch 109/500\n",
      "46/46 [==============================] - 0s 392us/step - loss: 0.1279 - accuracy: 0.9469\n",
      "Epoch 110/500\n",
      "46/46 [==============================] - 0s 401us/step - loss: 0.1124 - accuracy: 0.9594\n",
      "Epoch 111/500\n",
      "46/46 [==============================] - 0s 431us/step - loss: 0.1100 - accuracy: 0.9625\n",
      "Epoch 112/500\n",
      "46/46 [==============================] - 0s 397us/step - loss: 0.0862 - accuracy: 0.9719\n",
      "Epoch 113/500\n",
      "46/46 [==============================] - 0s 394us/step - loss: 0.1180 - accuracy: 0.9500\n",
      "Epoch 114/500\n",
      "46/46 [==============================] - 0s 389us/step - loss: 0.0919 - accuracy: 0.9750\n",
      "Epoch 115/500\n",
      "46/46 [==============================] - 0s 387us/step - loss: 0.1304 - accuracy: 0.9563\n",
      "Epoch 116/500\n",
      "46/46 [==============================] - 0s 379us/step - loss: 0.1228 - accuracy: 0.9563\n",
      "Epoch 117/500\n",
      "46/46 [==============================] - 0s 410us/step - loss: 0.0798 - accuracy: 0.9719\n",
      "Epoch 118/500\n",
      "46/46 [==============================] - 0s 386us/step - loss: 0.1016 - accuracy: 0.9719\n",
      "Epoch 119/500\n",
      "46/46 [==============================] - 0s 398us/step - loss: 0.1160 - accuracy: 0.9531\n",
      "Epoch 120/500\n",
      "46/46 [==============================] - 0s 386us/step - loss: 0.0692 - accuracy: 0.9781\n",
      "Epoch 121/500\n",
      "46/46 [==============================] - 0s 429us/step - loss: 0.1119 - accuracy: 0.9688\n",
      "Epoch 122/500\n",
      "46/46 [==============================] - 0s 389us/step - loss: 0.0784 - accuracy: 0.9781\n",
      "Epoch 123/500\n",
      "46/46 [==============================] - 0s 395us/step - loss: 0.1163 - accuracy: 0.9563\n",
      "Epoch 124/500\n",
      "46/46 [==============================] - 0s 397us/step - loss: 0.1063 - accuracy: 0.9500\n",
      "Epoch 125/500\n",
      "46/46 [==============================] - 0s 386us/step - loss: 0.0772 - accuracy: 0.9656\n",
      "Epoch 126/500\n",
      "46/46 [==============================] - 0s 404us/step - loss: 0.0942 - accuracy: 0.9563\n",
      "Epoch 127/500\n",
      "46/46 [==============================] - 0s 394us/step - loss: 0.0485 - accuracy: 0.9844\n",
      "Epoch 128/500\n",
      "46/46 [==============================] - 0s 490us/step - loss: 0.1059 - accuracy: 0.9563\n",
      "Epoch 129/500\n",
      "46/46 [==============================] - 0s 386us/step - loss: 0.0924 - accuracy: 0.9688\n",
      "Epoch 130/500\n",
      "46/46 [==============================] - 0s 389us/step - loss: 0.0941 - accuracy: 0.9688\n",
      "Epoch 131/500\n",
      "46/46 [==============================] - 0s 406us/step - loss: 0.0950 - accuracy: 0.9625\n",
      "Epoch 132/500\n",
      "46/46 [==============================] - 0s 401us/step - loss: 0.0912 - accuracy: 0.9688\n",
      "Epoch 133/500\n",
      "46/46 [==============================] - 0s 382us/step - loss: 0.0928 - accuracy: 0.9688\n",
      "Epoch 134/500\n",
      "46/46 [==============================] - 0s 392us/step - loss: 0.1013 - accuracy: 0.9688\n",
      "Epoch 135/500\n",
      "46/46 [==============================] - 0s 397us/step - loss: 0.1075 - accuracy: 0.9500\n",
      "Epoch 136/500\n",
      "46/46 [==============================] - 0s 388us/step - loss: 0.0876 - accuracy: 0.9625\n",
      "Epoch 137/500\n",
      "46/46 [==============================] - 0s 405us/step - loss: 0.0961 - accuracy: 0.9594\n",
      "Epoch 138/500\n",
      "46/46 [==============================] - 0s 529us/step - loss: 0.1033 - accuracy: 0.9688\n",
      "Epoch 139/500\n",
      "46/46 [==============================] - 0s 457us/step - loss: 0.0677 - accuracy: 0.9750\n",
      "Epoch 140/500\n",
      "46/46 [==============================] - 0s 494us/step - loss: 0.0650 - accuracy: 0.9812\n",
      "Epoch 141/500\n",
      "46/46 [==============================] - 0s 461us/step - loss: 0.0767 - accuracy: 0.9750\n",
      "Epoch 142/500\n",
      "46/46 [==============================] - 0s 510us/step - loss: 0.0594 - accuracy: 0.9844\n",
      "Epoch 143/500\n",
      "46/46 [==============================] - 0s 466us/step - loss: 0.1182 - accuracy: 0.9563\n",
      "Epoch 144/500\n",
      "46/46 [==============================] - 0s 463us/step - loss: 0.1091 - accuracy: 0.9625\n",
      "Epoch 145/500\n",
      "46/46 [==============================] - 0s 461us/step - loss: 0.0591 - accuracy: 0.9812\n",
      "Epoch 146/500\n",
      "46/46 [==============================] - 0s 407us/step - loss: 0.0580 - accuracy: 0.9812\n",
      "Epoch 147/500\n",
      "46/46 [==============================] - 0s 427us/step - loss: 0.0797 - accuracy: 0.9750\n",
      "Epoch 148/500\n",
      "46/46 [==============================] - 0s 410us/step - loss: 0.0714 - accuracy: 0.9719\n",
      "Epoch 149/500\n",
      "46/46 [==============================] - 0s 490us/step - loss: 0.0723 - accuracy: 0.9688\n",
      "Epoch 150/500\n",
      "46/46 [==============================] - 0s 422us/step - loss: 0.0921 - accuracy: 0.9656\n",
      "Epoch 151/500\n",
      "46/46 [==============================] - 0s 399us/step - loss: 0.0658 - accuracy: 0.9781\n",
      "Epoch 152/500\n",
      "46/46 [==============================] - 0s 394us/step - loss: 0.0606 - accuracy: 0.9781\n",
      "Epoch 153/500\n",
      "46/46 [==============================] - 0s 405us/step - loss: 0.0761 - accuracy: 0.9812\n",
      "Epoch 154/500\n",
      "46/46 [==============================] - 0s 397us/step - loss: 0.0704 - accuracy: 0.9781\n",
      "Epoch 155/500\n",
      "46/46 [==============================] - 0s 409us/step - loss: 0.0898 - accuracy: 0.9563\n",
      "Epoch 156/500\n",
      "46/46 [==============================] - 0s 416us/step - loss: 0.0956 - accuracy: 0.9656\n",
      "Epoch 157/500\n",
      "46/46 [==============================] - 0s 392us/step - loss: 0.0902 - accuracy: 0.9719\n",
      "Epoch 158/500\n",
      "46/46 [==============================] - 0s 413us/step - loss: 0.0740 - accuracy: 0.9625\n",
      "Epoch 159/500\n",
      "46/46 [==============================] - 0s 422us/step - loss: 0.0864 - accuracy: 0.9656\n",
      "Epoch 160/500\n",
      "46/46 [==============================] - 0s 405us/step - loss: 0.0904 - accuracy: 0.9688\n",
      "Epoch 161/500\n",
      "46/46 [==============================] - 0s 429us/step - loss: 0.0892 - accuracy: 0.9688\n",
      "Epoch 162/500\n",
      "46/46 [==============================] - 0s 434us/step - loss: 0.0884 - accuracy: 0.9625\n",
      "Epoch 163/500\n",
      "46/46 [==============================] - 0s 425us/step - loss: 0.0950 - accuracy: 0.9563\n",
      "Epoch 164/500\n",
      "46/46 [==============================] - 0s 421us/step - loss: 0.0687 - accuracy: 0.9688\n",
      "Epoch 165/500\n",
      "46/46 [==============================] - 0s 434us/step - loss: 0.0698 - accuracy: 0.9688\n",
      "Epoch 166/500\n",
      "46/46 [==============================] - 0s 406us/step - loss: 0.0752 - accuracy: 0.9719\n",
      "Epoch 167/500\n",
      "46/46 [==============================] - 0s 422us/step - loss: 0.0716 - accuracy: 0.9750\n",
      "Epoch 168/500\n",
      "46/46 [==============================] - 0s 431us/step - loss: 0.0980 - accuracy: 0.9625\n",
      "Epoch 169/500\n",
      "46/46 [==============================] - 0s 410us/step - loss: 0.0683 - accuracy: 0.9844\n",
      "Epoch 170/500\n",
      "46/46 [==============================] - 0s 421us/step - loss: 0.0526 - accuracy: 0.9812\n",
      "Epoch 171/500\n",
      "46/46 [==============================] - 0s 414us/step - loss: 0.0688 - accuracy: 0.9719\n",
      "Epoch 172/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 416us/step - loss: 0.0992 - accuracy: 0.9563\n",
      "Epoch 173/500\n",
      "46/46 [==============================] - 0s 410us/step - loss: 0.0833 - accuracy: 0.9750\n",
      "Epoch 174/500\n",
      "46/46 [==============================] - 0s 437us/step - loss: 0.0519 - accuracy: 0.9875\n",
      "Epoch 175/500\n",
      "46/46 [==============================] - 0s 420us/step - loss: 0.0673 - accuracy: 0.9781\n",
      "Epoch 176/500\n",
      "46/46 [==============================] - 0s 415us/step - loss: 0.0722 - accuracy: 0.9719\n",
      "Epoch 177/500\n",
      "46/46 [==============================] - 0s 418us/step - loss: 0.0827 - accuracy: 0.9625\n",
      "Epoch 178/500\n",
      "46/46 [==============================] - 0s 423us/step - loss: 0.0695 - accuracy: 0.9750\n",
      "Epoch 179/500\n",
      "46/46 [==============================] - 0s 427us/step - loss: 0.0544 - accuracy: 0.9750\n",
      "Epoch 180/500\n",
      "46/46 [==============================] - 0s 412us/step - loss: 0.0786 - accuracy: 0.9812\n",
      "Epoch 181/500\n",
      "46/46 [==============================] - 0s 403us/step - loss: 0.1018 - accuracy: 0.9656\n",
      "Epoch 182/500\n",
      "46/46 [==============================] - 0s 432us/step - loss: 0.0849 - accuracy: 0.9625\n",
      "Epoch 183/500\n",
      "46/46 [==============================] - 0s 393us/step - loss: 0.0477 - accuracy: 0.9812\n",
      "Epoch 184/500\n",
      "46/46 [==============================] - 0s 419us/step - loss: 0.1035 - accuracy: 0.9656\n",
      "Epoch 185/500\n",
      "46/46 [==============================] - 0s 422us/step - loss: 0.0774 - accuracy: 0.9688\n",
      "Epoch 186/500\n",
      "46/46 [==============================] - 0s 431us/step - loss: 0.0805 - accuracy: 0.9688\n",
      "Epoch 187/500\n",
      "46/46 [==============================] - 0s 446us/step - loss: 0.0760 - accuracy: 0.9688\n",
      "Epoch 188/500\n",
      "46/46 [==============================] - 0s 448us/step - loss: 0.1180 - accuracy: 0.9563\n",
      "Epoch 189/500\n",
      "46/46 [==============================] - 0s 435us/step - loss: 0.1042 - accuracy: 0.9500\n",
      "Epoch 190/500\n",
      "46/46 [==============================] - 0s 423us/step - loss: 0.0702 - accuracy: 0.9719\n",
      "Epoch 191/500\n",
      "46/46 [==============================] - 0s 412us/step - loss: 0.0552 - accuracy: 0.9875\n",
      "Epoch 192/500\n",
      "46/46 [==============================] - 0s 461us/step - loss: 0.0410 - accuracy: 0.9844\n",
      "Epoch 193/500\n",
      "46/46 [==============================] - 0s 433us/step - loss: 0.0619 - accuracy: 0.9750\n",
      "Epoch 194/500\n",
      "46/46 [==============================] - 0s 465us/step - loss: 0.0591 - accuracy: 0.9781\n",
      "Epoch 195/500\n",
      "46/46 [==============================] - 0s 485us/step - loss: 0.0687 - accuracy: 0.9750\n",
      "Epoch 196/500\n",
      "46/46 [==============================] - 0s 432us/step - loss: 0.0543 - accuracy: 0.9688\n",
      "Epoch 197/500\n",
      "46/46 [==============================] - 0s 440us/step - loss: 0.0776 - accuracy: 0.9688\n",
      "Epoch 198/500\n",
      "46/46 [==============================] - 0s 430us/step - loss: 0.0770 - accuracy: 0.9688\n",
      "Epoch 199/500\n",
      "46/46 [==============================] - 0s 440us/step - loss: 0.0564 - accuracy: 0.9781\n",
      "Epoch 200/500\n",
      "46/46 [==============================] - 0s 430us/step - loss: 0.0819 - accuracy: 0.9688\n",
      "Epoch 201/500\n",
      "46/46 [==============================] - 0s 416us/step - loss: 0.0923 - accuracy: 0.9656\n",
      "Epoch 202/500\n",
      "46/46 [==============================] - 0s 407us/step - loss: 0.0814 - accuracy: 0.9688\n",
      "Epoch 203/500\n",
      "46/46 [==============================] - 0s 408us/step - loss: 0.0816 - accuracy: 0.9563\n",
      "Epoch 204/500\n",
      "46/46 [==============================] - 0s 417us/step - loss: 0.0736 - accuracy: 0.9656\n",
      "Epoch 205/500\n",
      "46/46 [==============================] - 0s 391us/step - loss: 0.0628 - accuracy: 0.9625\n",
      "Epoch 206/500\n",
      "46/46 [==============================] - 0s 387us/step - loss: 0.0513 - accuracy: 0.9812\n",
      "Epoch 207/500\n",
      "46/46 [==============================] - 0s 387us/step - loss: 0.0475 - accuracy: 0.9844\n",
      "Epoch 208/500\n",
      "46/46 [==============================] - 0s 402us/step - loss: 0.0681 - accuracy: 0.9781\n",
      "Epoch 209/500\n",
      "46/46 [==============================] - 0s 394us/step - loss: 0.1372 - accuracy: 0.9469\n",
      "Epoch 210/500\n",
      "46/46 [==============================] - 0s 382us/step - loss: 0.0866 - accuracy: 0.9625\n",
      "Epoch 211/500\n",
      "46/46 [==============================] - 0s 382us/step - loss: 0.0765 - accuracy: 0.9625\n",
      "Epoch 212/500\n",
      "46/46 [==============================] - 0s 386us/step - loss: 0.0454 - accuracy: 0.9906\n",
      "Epoch 213/500\n",
      "46/46 [==============================] - 0s 458us/step - loss: 0.0462 - accuracy: 0.9844\n",
      "Epoch 214/500\n",
      "46/46 [==============================] - 0s 452us/step - loss: 0.1206 - accuracy: 0.9594\n",
      "Epoch 215/500\n",
      "46/46 [==============================] - 0s 457us/step - loss: 0.1323 - accuracy: 0.9406\n",
      "Epoch 216/500\n",
      "46/46 [==============================] - 0s 431us/step - loss: 0.0793 - accuracy: 0.9688\n",
      "Epoch 217/500\n",
      "46/46 [==============================] - 0s 403us/step - loss: 0.0630 - accuracy: 0.9656\n",
      "Epoch 218/500\n",
      "46/46 [==============================] - 0s 399us/step - loss: 0.0733 - accuracy: 0.9625\n",
      "Epoch 219/500\n",
      "46/46 [==============================] - 0s 381us/step - loss: 0.0302 - accuracy: 0.9937\n",
      "Epoch 220/500\n",
      "46/46 [==============================] - 0s 381us/step - loss: 0.0360 - accuracy: 0.9875\n",
      "Epoch 221/500\n",
      "46/46 [==============================] - 0s 386us/step - loss: 0.0569 - accuracy: 0.9812\n",
      "Epoch 222/500\n",
      "46/46 [==============================] - 0s 414us/step - loss: 0.0572 - accuracy: 0.9781\n",
      "Epoch 223/500\n",
      "46/46 [==============================] - 0s 420us/step - loss: 0.0818 - accuracy: 0.9625\n",
      "Epoch 224/500\n",
      "46/46 [==============================] - 0s 396us/step - loss: 0.0769 - accuracy: 0.9625\n",
      "Epoch 225/500\n",
      "46/46 [==============================] - 0s 397us/step - loss: 0.0557 - accuracy: 0.9812\n",
      "Epoch 226/500\n",
      "46/46 [==============================] - 0s 394us/step - loss: 0.0814 - accuracy: 0.9656\n",
      "Epoch 227/500\n",
      "46/46 [==============================] - 0s 405us/step - loss: 0.0725 - accuracy: 0.9656\n",
      "Epoch 228/500\n",
      "46/46 [==============================] - 0s 406us/step - loss: 0.0387 - accuracy: 0.9875\n",
      "Epoch 229/500\n",
      "46/46 [==============================] - 0s 443us/step - loss: 0.0551 - accuracy: 0.9719\n",
      "Epoch 230/500\n",
      "46/46 [==============================] - 0s 412us/step - loss: 0.1137 - accuracy: 0.9531\n",
      "Epoch 231/500\n",
      "46/46 [==============================] - 0s 413us/step - loss: 0.0585 - accuracy: 0.9812\n",
      "Epoch 232/500\n",
      "46/46 [==============================] - 0s 425us/step - loss: 0.0995 - accuracy: 0.9594\n",
      "Epoch 233/500\n",
      "46/46 [==============================] - 0s 399us/step - loss: 0.0865 - accuracy: 0.9625\n",
      "Epoch 234/500\n",
      "46/46 [==============================] - 0s 415us/step - loss: 0.0648 - accuracy: 0.9875\n",
      "Epoch 235/500\n",
      "46/46 [==============================] - 0s 398us/step - loss: 0.0619 - accuracy: 0.9719\n",
      "Epoch 236/500\n",
      "46/46 [==============================] - 0s 407us/step - loss: 0.0525 - accuracy: 0.9844\n",
      "Epoch 237/500\n",
      "46/46 [==============================] - 0s 444us/step - loss: 0.0421 - accuracy: 0.9844\n",
      "Epoch 238/500\n",
      "46/46 [==============================] - 0s 432us/step - loss: 0.0695 - accuracy: 0.9719\n",
      "Epoch 239/500\n",
      "46/46 [==============================] - 0s 481us/step - loss: 0.0668 - accuracy: 0.9719\n",
      "Epoch 240/500\n",
      "46/46 [==============================] - 0s 420us/step - loss: 0.0417 - accuracy: 0.9812\n",
      "Epoch 241/500\n",
      "46/46 [==============================] - 0s 418us/step - loss: 0.0248 - accuracy: 0.9937\n",
      "Epoch 242/500\n",
      "46/46 [==============================] - 0s 447us/step - loss: 0.0283 - accuracy: 0.9906\n",
      "Epoch 243/500\n",
      "46/46 [==============================] - 0s 461us/step - loss: 0.0691 - accuracy: 0.9719\n",
      "Epoch 244/500\n",
      "46/46 [==============================] - 0s 431us/step - loss: 0.0809 - accuracy: 0.9781\n",
      "Epoch 245/500\n",
      "46/46 [==============================] - 0s 410us/step - loss: 0.0446 - accuracy: 0.9781\n",
      "Epoch 246/500\n",
      "46/46 [==============================] - 0s 411us/step - loss: 0.0652 - accuracy: 0.9688\n",
      "Epoch 247/500\n",
      "46/46 [==============================] - 0s 389us/step - loss: 0.0769 - accuracy: 0.9688\n",
      "Epoch 248/500\n",
      "46/46 [==============================] - 0s 392us/step - loss: 0.1151 - accuracy: 0.9531\n",
      "Epoch 249/500\n",
      "46/46 [==============================] - 0s 386us/step - loss: 0.0946 - accuracy: 0.9688\n",
      "Epoch 250/500\n",
      "46/46 [==============================] - 0s 384us/step - loss: 0.0527 - accuracy: 0.9781\n",
      "Epoch 251/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 391us/step - loss: 0.0401 - accuracy: 0.9844\n",
      "Epoch 252/500\n",
      "46/46 [==============================] - 0s 407us/step - loss: 0.0438 - accuracy: 0.9812\n",
      "Epoch 253/500\n",
      "46/46 [==============================] - 0s 407us/step - loss: 0.0429 - accuracy: 0.9844\n",
      "Epoch 254/500\n",
      "46/46 [==============================] - 0s 390us/step - loss: 0.0818 - accuracy: 0.9781\n",
      "Epoch 255/500\n",
      "46/46 [==============================] - 0s 385us/step - loss: 0.0401 - accuracy: 0.9812\n",
      "Epoch 256/500\n",
      "46/46 [==============================] - 0s 394us/step - loss: 0.0667 - accuracy: 0.9781\n",
      "Epoch 257/500\n",
      "46/46 [==============================] - 0s 406us/step - loss: 0.0896 - accuracy: 0.9688\n",
      "Epoch 258/500\n",
      "46/46 [==============================] - 0s 402us/step - loss: 0.0839 - accuracy: 0.9656\n",
      "Epoch 259/500\n",
      "46/46 [==============================] - 0s 393us/step - loss: 0.0659 - accuracy: 0.9781\n",
      "Epoch 260/500\n",
      "46/46 [==============================] - 0s 398us/step - loss: 0.0564 - accuracy: 0.9781\n",
      "Epoch 261/500\n",
      "46/46 [==============================] - 0s 396us/step - loss: 0.0476 - accuracy: 0.9781\n",
      "Epoch 262/500\n",
      "46/46 [==============================] - 0s 390us/step - loss: 0.0634 - accuracy: 0.9719\n",
      "Epoch 263/500\n",
      "46/46 [==============================] - 0s 396us/step - loss: 0.0492 - accuracy: 0.9750\n",
      "Epoch 264/500\n",
      "46/46 [==============================] - 0s 414us/step - loss: 0.0618 - accuracy: 0.9781\n",
      "Epoch 265/500\n",
      "46/46 [==============================] - 0s 402us/step - loss: 0.0374 - accuracy: 0.9875\n",
      "Epoch 266/500\n",
      "46/46 [==============================] - 0s 387us/step - loss: 0.0504 - accuracy: 0.9844\n",
      "Epoch 267/500\n",
      "46/46 [==============================] - 0s 386us/step - loss: 0.0227 - accuracy: 0.9969\n",
      "Epoch 268/500\n",
      "46/46 [==============================] - 0s 393us/step - loss: 0.0238 - accuracy: 0.9875\n",
      "Epoch 269/500\n",
      "46/46 [==============================] - 0s 385us/step - loss: 0.0499 - accuracy: 0.9875\n",
      "Epoch 270/500\n",
      "46/46 [==============================] - 0s 387us/step - loss: 0.0622 - accuracy: 0.9812\n",
      "Epoch 271/500\n",
      "46/46 [==============================] - 0s 386us/step - loss: 0.0482 - accuracy: 0.9844\n",
      "Epoch 272/500\n",
      "46/46 [==============================] - 0s 401us/step - loss: 0.0822 - accuracy: 0.9594\n",
      "Epoch 273/500\n",
      "46/46 [==============================] - 0s 396us/step - loss: 0.0517 - accuracy: 0.9812\n",
      "Epoch 274/500\n",
      "46/46 [==============================] - 0s 408us/step - loss: 0.0428 - accuracy: 0.9812\n",
      "Epoch 275/500\n",
      "46/46 [==============================] - 0s 414us/step - loss: 0.0455 - accuracy: 0.9781\n",
      "Epoch 276/500\n",
      "46/46 [==============================] - 0s 415us/step - loss: 0.0541 - accuracy: 0.9781\n",
      "Epoch 277/500\n",
      "46/46 [==============================] - 0s 393us/step - loss: 0.0345 - accuracy: 0.9875\n",
      "Epoch 278/500\n",
      "46/46 [==============================] - 0s 427us/step - loss: 0.0621 - accuracy: 0.9844\n",
      "Epoch 279/500\n",
      "46/46 [==============================] - 0s 410us/step - loss: 0.0512 - accuracy: 0.9875\n",
      "Epoch 280/500\n",
      "46/46 [==============================] - 0s 392us/step - loss: 0.0307 - accuracy: 0.9906\n",
      "Epoch 281/500\n",
      "46/46 [==============================] - 0s 382us/step - loss: 0.0499 - accuracy: 0.9781\n",
      "Epoch 282/500\n",
      "46/46 [==============================] - 0s 384us/step - loss: 0.0784 - accuracy: 0.9750\n",
      "Epoch 283/500\n",
      "46/46 [==============================] - 0s 398us/step - loss: 0.0574 - accuracy: 0.9719\n",
      "Epoch 284/500\n",
      "46/46 [==============================] - 0s 401us/step - loss: 0.0489 - accuracy: 0.9844\n",
      "Epoch 285/500\n",
      "46/46 [==============================] - 0s 527us/step - loss: 0.0343 - accuracy: 0.9875\n",
      "Epoch 286/500\n",
      "46/46 [==============================] - 0s 379us/step - loss: 0.0467 - accuracy: 0.9844\n",
      "Epoch 287/500\n",
      "46/46 [==============================] - 0s 390us/step - loss: 0.0659 - accuracy: 0.9656\n",
      "Epoch 288/500\n",
      "46/46 [==============================] - 0s 409us/step - loss: 0.0671 - accuracy: 0.9812\n",
      "Epoch 289/500\n",
      "46/46 [==============================] - 0s 417us/step - loss: 0.0449 - accuracy: 0.9844\n",
      "Epoch 290/500\n",
      "46/46 [==============================] - 0s 438us/step - loss: 0.0876 - accuracy: 0.9688\n",
      "Epoch 291/500\n",
      "46/46 [==============================] - 0s 449us/step - loss: 0.0566 - accuracy: 0.9781\n",
      "Epoch 292/500\n",
      "46/46 [==============================] - 0s 449us/step - loss: 0.0486 - accuracy: 0.9906\n",
      "Epoch 293/500\n",
      "46/46 [==============================] - 0s 540us/step - loss: 0.0510 - accuracy: 0.9750\n",
      "Epoch 294/500\n",
      "46/46 [==============================] - 0s 442us/step - loss: 0.0396 - accuracy: 0.9875\n",
      "Epoch 295/500\n",
      "46/46 [==============================] - 0s 443us/step - loss: 0.0446 - accuracy: 0.9781\n",
      "Epoch 296/500\n",
      "46/46 [==============================] - 0s 430us/step - loss: 0.0882 - accuracy: 0.9719\n",
      "Epoch 297/500\n",
      "46/46 [==============================] - 0s 420us/step - loss: 0.0978 - accuracy: 0.9625\n",
      "Epoch 298/500\n",
      "46/46 [==============================] - 0s 500us/step - loss: 0.0554 - accuracy: 0.9812\n",
      "Epoch 299/500\n",
      "46/46 [==============================] - 0s 442us/step - loss: 0.0743 - accuracy: 0.9625\n",
      "Epoch 300/500\n",
      "46/46 [==============================] - 0s 470us/step - loss: 0.0546 - accuracy: 0.9750\n",
      "Epoch 301/500\n",
      "46/46 [==============================] - 0s 463us/step - loss: 0.0341 - accuracy: 0.9875\n",
      "Epoch 302/500\n",
      "46/46 [==============================] - 0s 489us/step - loss: 0.0409 - accuracy: 0.9906\n",
      "Epoch 303/500\n",
      "46/46 [==============================] - 0s 424us/step - loss: 0.0846 - accuracy: 0.9688\n",
      "Epoch 304/500\n",
      "46/46 [==============================] - 0s 424us/step - loss: 0.0636 - accuracy: 0.9750\n",
      "Epoch 305/500\n",
      "46/46 [==============================] - 0s 450us/step - loss: 0.0383 - accuracy: 0.9906\n",
      "Epoch 306/500\n",
      "46/46 [==============================] - 0s 440us/step - loss: 0.0450 - accuracy: 0.9750\n",
      "Epoch 307/500\n",
      "46/46 [==============================] - 0s 426us/step - loss: 0.0437 - accuracy: 0.9844\n",
      "Epoch 308/500\n",
      "46/46 [==============================] - 0s 434us/step - loss: 0.0251 - accuracy: 0.9906\n",
      "Epoch 309/500\n",
      "46/46 [==============================] - 0s 478us/step - loss: 0.0367 - accuracy: 0.9875\n",
      "Epoch 310/500\n",
      "46/46 [==============================] - 0s 464us/step - loss: 0.0643 - accuracy: 0.9719\n",
      "Epoch 311/500\n",
      "46/46 [==============================] - 0s 442us/step - loss: 0.0467 - accuracy: 0.9844\n",
      "Epoch 312/500\n",
      "46/46 [==============================] - 0s 459us/step - loss: 0.0364 - accuracy: 0.9875\n",
      "Epoch 313/500\n",
      "46/46 [==============================] - 0s 442us/step - loss: 0.0511 - accuracy: 0.9906\n",
      "Epoch 314/500\n",
      "46/46 [==============================] - 0s 442us/step - loss: 0.0320 - accuracy: 0.9937\n",
      "Epoch 315/500\n",
      "46/46 [==============================] - 0s 469us/step - loss: 0.1211 - accuracy: 0.9500\n",
      "Epoch 316/500\n",
      "46/46 [==============================] - 0s 423us/step - loss: 0.0670 - accuracy: 0.9750\n",
      "Epoch 317/500\n",
      "46/46 [==============================] - 0s 430us/step - loss: 0.0593 - accuracy: 0.9719\n",
      "Epoch 318/500\n",
      "46/46 [==============================] - 0s 482us/step - loss: 0.0782 - accuracy: 0.9719\n",
      "Epoch 319/500\n",
      "46/46 [==============================] - 0s 427us/step - loss: 0.0765 - accuracy: 0.9688\n",
      "Epoch 320/500\n",
      "46/46 [==============================] - 0s 462us/step - loss: 0.0870 - accuracy: 0.9688\n",
      "Epoch 321/500\n",
      "46/46 [==============================] - 0s 445us/step - loss: 0.0525 - accuracy: 0.9781\n",
      "Epoch 322/500\n",
      "46/46 [==============================] - 0s 426us/step - loss: 0.0262 - accuracy: 0.9875\n",
      "Epoch 323/500\n",
      "46/46 [==============================] - 0s 415us/step - loss: 0.0352 - accuracy: 0.9812\n",
      "Epoch 324/500\n",
      "46/46 [==============================] - 0s 448us/step - loss: 0.0287 - accuracy: 0.9875\n",
      "Epoch 325/500\n",
      "46/46 [==============================] - 0s 461us/step - loss: 0.0305 - accuracy: 0.9906\n",
      "Epoch 326/500\n",
      "46/46 [==============================] - 0s 434us/step - loss: 0.0439 - accuracy: 0.9812\n",
      "Epoch 327/500\n",
      "46/46 [==============================] - 0s 449us/step - loss: 0.0470 - accuracy: 0.9812\n",
      "Epoch 328/500\n",
      "46/46 [==============================] - 0s 425us/step - loss: 0.0546 - accuracy: 0.9781\n",
      "Epoch 329/500\n",
      "46/46 [==============================] - 0s 436us/step - loss: 0.0304 - accuracy: 0.9875\n",
      "Epoch 330/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 438us/step - loss: 0.0531 - accuracy: 0.9781\n",
      "Epoch 331/500\n",
      "46/46 [==============================] - 0s 427us/step - loss: 0.0699 - accuracy: 0.9719\n",
      "Epoch 332/500\n",
      "46/46 [==============================] - 0s 442us/step - loss: 0.0494 - accuracy: 0.9812\n",
      "Epoch 333/500\n",
      "46/46 [==============================] - 0s 425us/step - loss: 0.0457 - accuracy: 0.9719\n",
      "Epoch 334/500\n",
      "46/46 [==============================] - 0s 420us/step - loss: 0.0379 - accuracy: 0.9812\n",
      "Epoch 335/500\n",
      "46/46 [==============================] - 0s 430us/step - loss: 0.0638 - accuracy: 0.9719\n",
      "Epoch 336/500\n",
      "46/46 [==============================] - 0s 415us/step - loss: 0.0543 - accuracy: 0.9750\n",
      "Epoch 337/500\n",
      "46/46 [==============================] - 0s 441us/step - loss: 0.0741 - accuracy: 0.9875\n",
      "Epoch 338/500\n",
      "46/46 [==============================] - 0s 416us/step - loss: 0.0648 - accuracy: 0.9781\n",
      "Epoch 339/500\n",
      "46/46 [==============================] - 0s 423us/step - loss: 0.0668 - accuracy: 0.9688\n",
      "Epoch 340/500\n",
      "46/46 [==============================] - 0s 430us/step - loss: 0.0524 - accuracy: 0.9812\n",
      "Epoch 341/500\n",
      "46/46 [==============================] - 0s 431us/step - loss: 0.0354 - accuracy: 0.9844\n",
      "Epoch 342/500\n",
      "46/46 [==============================] - 0s 429us/step - loss: 0.0295 - accuracy: 0.9875\n",
      "Epoch 343/500\n",
      "46/46 [==============================] - 0s 443us/step - loss: 0.0339 - accuracy: 0.9875\n",
      "Epoch 344/500\n",
      "46/46 [==============================] - 0s 465us/step - loss: 0.0522 - accuracy: 0.9812\n",
      "Epoch 345/500\n",
      "46/46 [==============================] - 0s 447us/step - loss: 0.0757 - accuracy: 0.9719\n",
      "Epoch 346/500\n",
      "46/46 [==============================] - 0s 484us/step - loss: 0.0684 - accuracy: 0.9719\n",
      "Epoch 347/500\n",
      "46/46 [==============================] - 0s 418us/step - loss: 0.0468 - accuracy: 0.9719\n",
      "Epoch 348/500\n",
      "46/46 [==============================] - 0s 409us/step - loss: 0.0519 - accuracy: 0.9719\n",
      "Epoch 349/500\n",
      "46/46 [==============================] - 0s 379us/step - loss: 0.0543 - accuracy: 0.9781\n",
      "Epoch 350/500\n",
      "46/46 [==============================] - 0s 390us/step - loss: 0.0939 - accuracy: 0.9656\n",
      "Epoch 351/500\n",
      "46/46 [==============================] - 0s 382us/step - loss: 0.0497 - accuracy: 0.9812\n",
      "Epoch 352/500\n",
      "46/46 [==============================] - 0s 388us/step - loss: 0.0381 - accuracy: 0.9812\n",
      "Epoch 353/500\n",
      "46/46 [==============================] - 0s 406us/step - loss: 0.0666 - accuracy: 0.9750\n",
      "Epoch 354/500\n",
      "46/46 [==============================] - 0s 389us/step - loss: 0.0478 - accuracy: 0.9844\n",
      "Epoch 355/500\n",
      "46/46 [==============================] - 0s 405us/step - loss: 0.0230 - accuracy: 0.9906\n",
      "Epoch 356/500\n",
      "46/46 [==============================] - 0s 465us/step - loss: 0.0226 - accuracy: 0.9937\n",
      "Epoch 357/500\n",
      "46/46 [==============================] - 0s 407us/step - loss: 0.0491 - accuracy: 0.9750\n",
      "Epoch 358/500\n",
      "46/46 [==============================] - 0s 396us/step - loss: 0.0635 - accuracy: 0.9781\n",
      "Epoch 359/500\n",
      "46/46 [==============================] - 0s 468us/step - loss: 0.0447 - accuracy: 0.9875\n",
      "Epoch 360/500\n",
      "46/46 [==============================] - 0s 420us/step - loss: 0.0376 - accuracy: 0.9750\n",
      "Epoch 361/500\n",
      "46/46 [==============================] - 0s 467us/step - loss: 0.0671 - accuracy: 0.9781\n",
      "Epoch 362/500\n",
      "46/46 [==============================] - 0s 452us/step - loss: 0.0694 - accuracy: 0.9781\n",
      "Epoch 363/500\n",
      "46/46 [==============================] - 0s 430us/step - loss: 0.0560 - accuracy: 0.9750\n",
      "Epoch 364/500\n",
      "46/46 [==============================] - 0s 526us/step - loss: 0.0252 - accuracy: 0.9844\n",
      "Epoch 365/500\n",
      "46/46 [==============================] - 0s 414us/step - loss: 0.0487 - accuracy: 0.9812\n",
      "Epoch 366/500\n",
      "46/46 [==============================] - 0s 423us/step - loss: 0.0271 - accuracy: 0.9875\n",
      "Epoch 367/500\n",
      "46/46 [==============================] - 0s 391us/step - loss: 0.0399 - accuracy: 0.9844\n",
      "Epoch 368/500\n",
      "46/46 [==============================] - 0s 430us/step - loss: 0.0290 - accuracy: 0.9875\n",
      "Epoch 369/500\n",
      "46/46 [==============================] - 0s 390us/step - loss: 0.0309 - accuracy: 0.9937\n",
      "Epoch 370/500\n",
      "46/46 [==============================] - 0s 396us/step - loss: 0.0346 - accuracy: 0.9906\n",
      "Epoch 371/500\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.0285 - accuracy: 0.9937\n",
      "Epoch 372/500\n",
      "46/46 [==============================] - 0s 545us/step - loss: 0.0338 - accuracy: 0.9906\n",
      "Epoch 373/500\n",
      "46/46 [==============================] - 0s 396us/step - loss: 0.0352 - accuracy: 0.9875\n",
      "Epoch 374/500\n",
      "46/46 [==============================] - 0s 401us/step - loss: 0.0511 - accuracy: 0.9844\n",
      "Epoch 375/500\n",
      "46/46 [==============================] - 0s 384us/step - loss: 0.0560 - accuracy: 0.9781\n",
      "Epoch 376/500\n",
      "46/46 [==============================] - 0s 387us/step - loss: 0.0301 - accuracy: 0.9844\n",
      "Epoch 377/500\n",
      "46/46 [==============================] - 0s 392us/step - loss: 0.0556 - accuracy: 0.9812\n",
      "Epoch 378/500\n",
      "46/46 [==============================] - 0s 387us/step - loss: 0.0653 - accuracy: 0.9844\n",
      "Epoch 379/500\n",
      "46/46 [==============================] - 0s 385us/step - loss: 0.0273 - accuracy: 0.9906\n",
      "Epoch 380/500\n",
      "46/46 [==============================] - 0s 393us/step - loss: 0.0540 - accuracy: 0.9750\n",
      "Epoch 381/500\n",
      "46/46 [==============================] - 0s 423us/step - loss: 0.0365 - accuracy: 0.9844\n",
      "Epoch 382/500\n",
      "46/46 [==============================] - 0s 409us/step - loss: 0.0605 - accuracy: 0.9750\n",
      "Epoch 383/500\n",
      "46/46 [==============================] - 0s 414us/step - loss: 0.0571 - accuracy: 0.9781\n",
      "Epoch 384/500\n",
      "46/46 [==============================] - 0s 458us/step - loss: 0.0497 - accuracy: 0.9781\n",
      "Epoch 385/500\n",
      "46/46 [==============================] - 0s 416us/step - loss: 0.0690 - accuracy: 0.9719\n",
      "Epoch 386/500\n",
      "46/46 [==============================] - 0s 392us/step - loss: 0.0567 - accuracy: 0.9750\n",
      "Epoch 387/500\n",
      "46/46 [==============================] - 0s 404us/step - loss: 0.0668 - accuracy: 0.9844\n",
      "Epoch 388/500\n",
      "46/46 [==============================] - 0s 391us/step - loss: 0.0768 - accuracy: 0.9625\n",
      "Epoch 389/500\n",
      "46/46 [==============================] - 0s 463us/step - loss: 0.0631 - accuracy: 0.9781\n",
      "Epoch 390/500\n",
      "46/46 [==============================] - 0s 388us/step - loss: 0.0355 - accuracy: 0.9844\n",
      "Epoch 391/500\n",
      "46/46 [==============================] - 0s 373us/step - loss: 0.0337 - accuracy: 0.9906\n",
      "Epoch 392/500\n",
      "46/46 [==============================] - 0s 384us/step - loss: 0.0725 - accuracy: 0.9750\n",
      "Epoch 393/500\n",
      "46/46 [==============================] - 0s 390us/step - loss: 0.0437 - accuracy: 0.9844\n",
      "Epoch 394/500\n",
      "46/46 [==============================] - 0s 390us/step - loss: 0.0325 - accuracy: 0.9875\n",
      "Epoch 395/500\n",
      "46/46 [==============================] - 0s 385us/step - loss: 0.0369 - accuracy: 0.9812\n",
      "Epoch 396/500\n",
      "46/46 [==============================] - 0s 390us/step - loss: 0.0547 - accuracy: 0.9781\n",
      "Epoch 397/500\n",
      "46/46 [==============================] - 0s 414us/step - loss: 0.0591 - accuracy: 0.9812\n",
      "Epoch 398/500\n",
      "46/46 [==============================] - 0s 392us/step - loss: 0.0310 - accuracy: 0.9875\n",
      "Epoch 399/500\n",
      "46/46 [==============================] - 0s 392us/step - loss: 0.0384 - accuracy: 0.9875\n",
      "Epoch 400/500\n",
      "46/46 [==============================] - 0s 397us/step - loss: 0.0286 - accuracy: 0.9875\n",
      "Epoch 401/500\n",
      "46/46 [==============================] - 0s 409us/step - loss: 0.0465 - accuracy: 0.9781\n",
      "Epoch 402/500\n",
      "46/46 [==============================] - 0s 390us/step - loss: 0.0138 - accuracy: 0.9969\n",
      "Epoch 403/500\n",
      "46/46 [==============================] - 0s 390us/step - loss: 0.0202 - accuracy: 0.9937\n",
      "Epoch 404/500\n",
      "46/46 [==============================] - 0s 391us/step - loss: 0.0213 - accuracy: 0.9937\n",
      "Epoch 405/500\n",
      "46/46 [==============================] - 0s 395us/step - loss: 0.0290 - accuracy: 0.9969\n",
      "Epoch 406/500\n",
      "46/46 [==============================] - 0s 374us/step - loss: 0.0214 - accuracy: 0.9969\n",
      "Epoch 407/500\n",
      "46/46 [==============================] - 0s 389us/step - loss: 0.0278 - accuracy: 0.9906\n",
      "Epoch 408/500\n",
      "46/46 [==============================] - 0s 401us/step - loss: 0.0531 - accuracy: 0.9719\n",
      "Epoch 409/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 404us/step - loss: 0.0708 - accuracy: 0.9594\n",
      "Epoch 410/500\n",
      "46/46 [==============================] - 0s 412us/step - loss: 0.0292 - accuracy: 0.9875\n",
      "Epoch 411/500\n",
      "46/46 [==============================] - 0s 386us/step - loss: 0.0315 - accuracy: 0.9906\n",
      "Epoch 412/500\n",
      "46/46 [==============================] - 0s 404us/step - loss: 0.0286 - accuracy: 0.9844\n",
      "Epoch 413/500\n",
      "46/46 [==============================] - 0s 390us/step - loss: 0.0602 - accuracy: 0.9844\n",
      "Epoch 414/500\n",
      "46/46 [==============================] - 0s 406us/step - loss: 0.0317 - accuracy: 0.9875\n",
      "Epoch 415/500\n",
      "46/46 [==============================] - 0s 393us/step - loss: 0.0192 - accuracy: 0.9969\n",
      "Epoch 416/500\n",
      "46/46 [==============================] - 0s 386us/step - loss: 0.0459 - accuracy: 0.9812\n",
      "Epoch 417/500\n",
      "46/46 [==============================] - 0s 385us/step - loss: 0.1022 - accuracy: 0.9625\n",
      "Epoch 418/500\n",
      "46/46 [==============================] - 0s 388us/step - loss: 0.1125 - accuracy: 0.9625\n",
      "Epoch 419/500\n",
      "46/46 [==============================] - 0s 392us/step - loss: 0.0332 - accuracy: 0.9875\n",
      "Epoch 420/500\n",
      "46/46 [==============================] - 0s 388us/step - loss: 0.0480 - accuracy: 0.9812\n",
      "Epoch 421/500\n",
      "46/46 [==============================] - 0s 402us/step - loss: 0.0252 - accuracy: 0.9906\n",
      "Epoch 422/500\n",
      "46/46 [==============================] - 0s 406us/step - loss: 0.0438 - accuracy: 0.9875\n",
      "Epoch 423/500\n",
      "46/46 [==============================] - 0s 464us/step - loss: 0.0159 - accuracy: 0.9937\n",
      "Epoch 424/500\n",
      "46/46 [==============================] - 0s 531us/step - loss: 0.0241 - accuracy: 0.9906\n",
      "Epoch 425/500\n",
      "46/46 [==============================] - 0s 495us/step - loss: 0.0252 - accuracy: 0.9875\n",
      "Epoch 426/500\n",
      "46/46 [==============================] - 0s 476us/step - loss: 0.0211 - accuracy: 0.9937\n",
      "Epoch 427/500\n",
      "46/46 [==============================] - 0s 480us/step - loss: 0.0522 - accuracy: 0.9812\n",
      "Epoch 428/500\n",
      "46/46 [==============================] - 0s 512us/step - loss: 0.0529 - accuracy: 0.9812\n",
      "Epoch 429/500\n",
      "46/46 [==============================] - 0s 450us/step - loss: 0.0421 - accuracy: 0.9812\n",
      "Epoch 430/500\n",
      "46/46 [==============================] - 0s 469us/step - loss: 0.0349 - accuracy: 0.9844\n",
      "Epoch 431/500\n",
      "46/46 [==============================] - 0s 485us/step - loss: 0.0251 - accuracy: 0.9906\n",
      "Epoch 432/500\n",
      "46/46 [==============================] - 0s 479us/step - loss: 0.0369 - accuracy: 0.9812\n",
      "Epoch 433/500\n",
      "46/46 [==============================] - 0s 444us/step - loss: 0.0418 - accuracy: 0.9812\n",
      "Epoch 434/500\n",
      "46/46 [==============================] - 0s 476us/step - loss: 0.0643 - accuracy: 0.9719\n",
      "Epoch 435/500\n",
      "46/46 [==============================] - 0s 414us/step - loss: 0.0233 - accuracy: 0.9906\n",
      "Epoch 436/500\n",
      "46/46 [==============================] - 0s 410us/step - loss: 0.0515 - accuracy: 0.9781\n",
      "Epoch 437/500\n",
      "46/46 [==============================] - 0s 407us/step - loss: 0.0606 - accuracy: 0.9781\n",
      "Epoch 438/500\n",
      "46/46 [==============================] - 0s 409us/step - loss: 0.0472 - accuracy: 0.9812\n",
      "Epoch 439/500\n",
      "46/46 [==============================] - 0s 391us/step - loss: 0.0228 - accuracy: 0.9875\n",
      "Epoch 440/500\n",
      "46/46 [==============================] - 0s 389us/step - loss: 0.0437 - accuracy: 0.9812\n",
      "Epoch 441/500\n",
      "46/46 [==============================] - 0s 394us/step - loss: 0.0550 - accuracy: 0.9812\n",
      "Epoch 442/500\n",
      "46/46 [==============================] - 0s 383us/step - loss: 0.0306 - accuracy: 0.9906\n",
      "Epoch 443/500\n",
      "46/46 [==============================] - 0s 400us/step - loss: 0.0322 - accuracy: 0.9844\n",
      "Epoch 444/500\n",
      "46/46 [==============================] - 0s 404us/step - loss: 0.0290 - accuracy: 0.9844\n",
      "Epoch 445/500\n",
      "46/46 [==============================] - 0s 414us/step - loss: 0.0313 - accuracy: 0.9937\n",
      "Epoch 446/500\n",
      "46/46 [==============================] - 0s 433us/step - loss: 0.0519 - accuracy: 0.9781\n",
      "Epoch 447/500\n",
      "46/46 [==============================] - 0s 405us/step - loss: 0.0480 - accuracy: 0.9781\n",
      "Epoch 448/500\n",
      "46/46 [==============================] - 0s 391us/step - loss: 0.0813 - accuracy: 0.9688\n",
      "Epoch 449/500\n",
      "46/46 [==============================] - 0s 398us/step - loss: 0.0235 - accuracy: 0.9969\n",
      "Epoch 450/500\n",
      "46/46 [==============================] - 0s 393us/step - loss: 0.0322 - accuracy: 0.9875\n",
      "Epoch 451/500\n",
      "46/46 [==============================] - 0s 381us/step - loss: 0.0786 - accuracy: 0.9781\n",
      "Epoch 452/500\n",
      "46/46 [==============================] - 0s 387us/step - loss: 0.0370 - accuracy: 0.9781\n",
      "Epoch 453/500\n",
      "46/46 [==============================] - 0s 402us/step - loss: 0.0159 - accuracy: 0.9937\n",
      "Epoch 454/500\n",
      "46/46 [==============================] - 0s 413us/step - loss: 0.0240 - accuracy: 0.9844\n",
      "Epoch 455/500\n",
      "46/46 [==============================] - 0s 393us/step - loss: 0.0261 - accuracy: 0.9906\n",
      "Epoch 456/500\n",
      "46/46 [==============================] - 0s 392us/step - loss: 0.0334 - accuracy: 0.9875\n",
      "Epoch 457/500\n",
      "46/46 [==============================] - 0s 403us/step - loss: 0.0361 - accuracy: 0.9875\n",
      "Epoch 458/500\n",
      "46/46 [==============================] - 0s 398us/step - loss: 0.0370 - accuracy: 0.9875\n",
      "Epoch 459/500\n",
      "46/46 [==============================] - 0s 392us/step - loss: 0.0245 - accuracy: 0.9937\n",
      "Epoch 460/500\n",
      "46/46 [==============================] - 0s 394us/step - loss: 0.0142 - accuracy: 1.0000\n",
      "Epoch 461/500\n",
      "46/46 [==============================] - 0s 416us/step - loss: 0.0332 - accuracy: 0.9812\n",
      "Epoch 462/500\n",
      "46/46 [==============================] - 0s 397us/step - loss: 0.0450 - accuracy: 0.9812\n",
      "Epoch 463/500\n",
      "46/46 [==============================] - 0s 380us/step - loss: 0.0575 - accuracy: 0.9781\n",
      "Epoch 464/500\n",
      "46/46 [==============================] - 0s 402us/step - loss: 0.0712 - accuracy: 0.9781\n",
      "Epoch 465/500\n",
      "46/46 [==============================] - 0s 389us/step - loss: 0.0159 - accuracy: 0.9969\n",
      "Epoch 466/500\n",
      "46/46 [==============================] - 0s 402us/step - loss: 0.0205 - accuracy: 0.9937\n",
      "Epoch 467/500\n",
      "46/46 [==============================] - 0s 396us/step - loss: 0.0306 - accuracy: 0.9844\n",
      "Epoch 468/500\n",
      "46/46 [==============================] - 0s 386us/step - loss: 0.0140 - accuracy: 1.0000\n",
      "Epoch 469/500\n",
      "46/46 [==============================] - 0s 384us/step - loss: 0.0134 - accuracy: 0.9969\n",
      "Epoch 470/500\n",
      "46/46 [==============================] - 0s 432us/step - loss: 0.0293 - accuracy: 0.9906\n",
      "Epoch 471/500\n",
      "46/46 [==============================] - 0s 434us/step - loss: 0.0390 - accuracy: 0.9844\n",
      "Epoch 472/500\n",
      "46/46 [==============================] - 0s 393us/step - loss: 0.0118 - accuracy: 0.9969\n",
      "Epoch 473/500\n",
      "46/46 [==============================] - 0s 423us/step - loss: 0.0181 - accuracy: 0.9969\n",
      "Epoch 474/500\n",
      "46/46 [==============================] - 0s 393us/step - loss: 0.0490 - accuracy: 0.9812\n",
      "Epoch 475/500\n",
      "46/46 [==============================] - 0s 393us/step - loss: 0.0218 - accuracy: 0.9937\n",
      "Epoch 476/500\n",
      "46/46 [==============================] - 0s 381us/step - loss: 0.0470 - accuracy: 0.9875\n",
      "Epoch 477/500\n",
      "46/46 [==============================] - 0s 389us/step - loss: 0.0240 - accuracy: 0.9906\n",
      "Epoch 478/500\n",
      "46/46 [==============================] - 0s 379us/step - loss: 0.0294 - accuracy: 0.9906\n",
      "Epoch 479/500\n",
      "46/46 [==============================] - 0s 396us/step - loss: 0.0425 - accuracy: 0.9844\n",
      "Epoch 480/500\n",
      "46/46 [==============================] - 0s 392us/step - loss: 0.0104 - accuracy: 0.9969\n",
      "Epoch 481/500\n",
      "46/46 [==============================] - 0s 429us/step - loss: 0.0269 - accuracy: 0.9844\n",
      "Epoch 482/500\n",
      "46/46 [==============================] - 0s 390us/step - loss: 0.0352 - accuracy: 0.9875\n",
      "Epoch 483/500\n",
      "46/46 [==============================] - 0s 417us/step - loss: 0.0885 - accuracy: 0.9781\n",
      "Epoch 484/500\n",
      "46/46 [==============================] - 0s 410us/step - loss: 0.0477 - accuracy: 0.9781\n",
      "Epoch 485/500\n",
      "46/46 [==============================] - 0s 378us/step - loss: 0.0447 - accuracy: 0.9750\n",
      "Epoch 486/500\n",
      "46/46 [==============================] - 0s 413us/step - loss: 0.0543 - accuracy: 0.9812\n",
      "Epoch 487/500\n",
      "46/46 [==============================] - 0s 401us/step - loss: 0.0242 - accuracy: 0.9875\n",
      "Epoch 488/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 387us/step - loss: 0.0690 - accuracy: 0.9812\n",
      "Epoch 489/500\n",
      "46/46 [==============================] - 0s 390us/step - loss: 0.0320 - accuracy: 0.9875\n",
      "Epoch 490/500\n",
      "46/46 [==============================] - 0s 382us/step - loss: 0.0130 - accuracy: 0.9969\n",
      "Epoch 491/500\n",
      "46/46 [==============================] - 0s 387us/step - loss: 0.0492 - accuracy: 0.9844\n",
      "Epoch 492/500\n",
      "46/46 [==============================] - 0s 397us/step - loss: 0.0694 - accuracy: 0.9844\n",
      "Epoch 493/500\n",
      "46/46 [==============================] - 0s 526us/step - loss: 0.0511 - accuracy: 0.9844\n",
      "Epoch 494/500\n",
      "46/46 [==============================] - 0s 415us/step - loss: 0.0546 - accuracy: 0.9844\n",
      "Epoch 495/500\n",
      "46/46 [==============================] - 0s 424us/step - loss: 0.0297 - accuracy: 0.9937\n",
      "Epoch 496/500\n",
      "46/46 [==============================] - 0s 417us/step - loss: 0.0489 - accuracy: 0.9750\n",
      "Epoch 497/500\n",
      "46/46 [==============================] - 0s 414us/step - loss: 0.0451 - accuracy: 0.9781\n",
      "Epoch 498/500\n",
      "46/46 [==============================] - 0s 434us/step - loss: 0.0552 - accuracy: 0.9812\n",
      "Epoch 499/500\n",
      "46/46 [==============================] - 0s 450us/step - loss: 0.0710 - accuracy: 0.9625\n",
      "Epoch 500/500\n",
      "46/46 [==============================] - 0s 428us/step - loss: 0.0209 - accuracy: 0.9937\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f51764ae950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Average score of Cross Validation: 0.9320130269521096\n"
     ]
    }
   ],
   "source": [
    "num_folds = 5\n",
    "\n",
    "kf = StratifiedKFold(n_splits=num_folds, random_state=seed, shuffle=True)\n",
    "cv_results = np.array([])\n",
    "for train_idx, test_idx, in kf.split(X_train, y_train):\n",
    "    X_cross_train, y_cross_train = X_train[train_idx], y_train[train_idx]\n",
    "    X_cross_test, y_cross_test = X_train[test_idx], y_train[test_idx]\n",
    "    model = getNetwork()\n",
    "    model.fit(X_cross_train, y_cross_train, epochs=EPOCHS, batch_size=BATCH_SIZE)  \n",
    "    y_pred = model.predict(X_cross_test)\n",
    "    predictions_categorical = np.argmax(y_pred, axis=1)\n",
    "    f1s = f1_score(y_cross_test, predictions_categorical, average=\"weighted\")\n",
    "    cv_results = np.append(cv_results, [f1s])\n",
    "\n",
    "print(f'Average score of Cross Validation: {cv_results.mean()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Sequential-NN\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_15 (Dense)             (None, 42)                1806      \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 42)                0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 256)               11008     \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 5)                 1285      \n",
      "=================================================================\n",
      "Total params: 14,099\n",
      "Trainable params: 14,099\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.5904 - accuracy: 0.2767 - val_loss: 1.5312 - val_accuracy: 0.3600\n",
      "Epoch 2/500\n",
      "43/43 [==============================] - 0s 673us/step - loss: 1.4438 - accuracy: 0.4433 - val_loss: 1.3463 - val_accuracy: 0.4300\n",
      "Epoch 3/500\n",
      "43/43 [==============================] - 0s 700us/step - loss: 1.2551 - accuracy: 0.5367 - val_loss: 1.1172 - val_accuracy: 0.5700\n",
      "Epoch 4/500\n",
      "43/43 [==============================] - 0s 692us/step - loss: 1.0918 - accuracy: 0.5600 - val_loss: 1.0212 - val_accuracy: 0.5000\n",
      "Epoch 5/500\n",
      "43/43 [==============================] - 0s 646us/step - loss: 1.0369 - accuracy: 0.5967 - val_loss: 0.9224 - val_accuracy: 0.6200\n",
      "Epoch 6/500\n",
      "43/43 [==============================] - 0s 632us/step - loss: 0.9249 - accuracy: 0.6267 - val_loss: 0.8472 - val_accuracy: 0.6900\n",
      "Epoch 7/500\n",
      "43/43 [==============================] - 0s 661us/step - loss: 0.8353 - accuracy: 0.6733 - val_loss: 0.8027 - val_accuracy: 0.6700\n",
      "Epoch 8/500\n",
      "43/43 [==============================] - 0s 686us/step - loss: 0.8109 - accuracy: 0.6600 - val_loss: 0.7489 - val_accuracy: 0.7400\n",
      "Epoch 9/500\n",
      "43/43 [==============================] - 0s 676us/step - loss: 0.7236 - accuracy: 0.7067 - val_loss: 0.7095 - val_accuracy: 0.7400\n",
      "Epoch 10/500\n",
      "43/43 [==============================] - 0s 679us/step - loss: 0.6626 - accuracy: 0.7367 - val_loss: 0.7021 - val_accuracy: 0.6600\n",
      "Epoch 11/500\n",
      "43/43 [==============================] - 0s 678us/step - loss: 0.6616 - accuracy: 0.7333 - val_loss: 0.6818 - val_accuracy: 0.6900\n",
      "Epoch 12/500\n",
      "43/43 [==============================] - 0s 674us/step - loss: 0.6161 - accuracy: 0.7333 - val_loss: 0.6371 - val_accuracy: 0.7500\n",
      "Epoch 13/500\n",
      "43/43 [==============================] - 0s 718us/step - loss: 0.5777 - accuracy: 0.7967 - val_loss: 0.5998 - val_accuracy: 0.7300\n",
      "Epoch 14/500\n",
      "43/43 [==============================] - 0s 641us/step - loss: 0.5785 - accuracy: 0.7667 - val_loss: 0.5757 - val_accuracy: 0.7900\n",
      "Epoch 15/500\n",
      "43/43 [==============================] - 0s 667us/step - loss: 0.5522 - accuracy: 0.7867 - val_loss: 0.5592 - val_accuracy: 0.7400\n",
      "Epoch 16/500\n",
      "43/43 [==============================] - 0s 676us/step - loss: 0.5703 - accuracy: 0.7767 - val_loss: 0.5895 - val_accuracy: 0.7400\n",
      "Epoch 17/500\n",
      "43/43 [==============================] - 0s 682us/step - loss: 0.5330 - accuracy: 0.7700 - val_loss: 0.5247 - val_accuracy: 0.8200\n",
      "Epoch 18/500\n",
      "43/43 [==============================] - 0s 644us/step - loss: 0.5087 - accuracy: 0.7867 - val_loss: 0.5477 - val_accuracy: 0.8200\n",
      "Epoch 19/500\n",
      "43/43 [==============================] - 0s 647us/step - loss: 0.4589 - accuracy: 0.8233 - val_loss: 0.5611 - val_accuracy: 0.7500\n",
      "Epoch 20/500\n",
      "43/43 [==============================] - 0s 664us/step - loss: 0.4781 - accuracy: 0.8033 - val_loss: 0.5043 - val_accuracy: 0.8100\n",
      "Epoch 21/500\n",
      "43/43 [==============================] - 0s 676us/step - loss: 0.4806 - accuracy: 0.8233 - val_loss: 0.5271 - val_accuracy: 0.7600\n",
      "Epoch 22/500\n",
      "43/43 [==============================] - 0s 651us/step - loss: 0.4321 - accuracy: 0.8000 - val_loss: 0.5219 - val_accuracy: 0.8200\n",
      "Epoch 23/500\n",
      "43/43 [==============================] - 0s 642us/step - loss: 0.4672 - accuracy: 0.8167 - val_loss: 0.4964 - val_accuracy: 0.8200\n",
      "Epoch 24/500\n",
      "43/43 [==============================] - 0s 658us/step - loss: 0.4193 - accuracy: 0.8167 - val_loss: 0.5414 - val_accuracy: 0.7900\n",
      "Epoch 25/500\n",
      "43/43 [==============================] - 0s 660us/step - loss: 0.4170 - accuracy: 0.8167 - val_loss: 0.5082 - val_accuracy: 0.8100\n",
      "Epoch 26/500\n",
      "43/43 [==============================] - 0s 666us/step - loss: 0.4061 - accuracy: 0.8333 - val_loss: 0.4758 - val_accuracy: 0.8300\n",
      "Epoch 27/500\n",
      "43/43 [==============================] - 0s 647us/step - loss: 0.3955 - accuracy: 0.8567 - val_loss: 0.4572 - val_accuracy: 0.8500\n",
      "Epoch 28/500\n",
      "43/43 [==============================] - 0s 653us/step - loss: 0.4046 - accuracy: 0.8400 - val_loss: 0.4914 - val_accuracy: 0.8100\n",
      "Epoch 29/500\n",
      "43/43 [==============================] - 0s 644us/step - loss: 0.3998 - accuracy: 0.8400 - val_loss: 0.5182 - val_accuracy: 0.8000\n",
      "Epoch 30/500\n",
      "43/43 [==============================] - 0s 669us/step - loss: 0.3991 - accuracy: 0.8400 - val_loss: 0.4241 - val_accuracy: 0.8500\n",
      "Epoch 31/500\n",
      "43/43 [==============================] - 0s 660us/step - loss: 0.3639 - accuracy: 0.8700 - val_loss: 0.4664 - val_accuracy: 0.8600\n",
      "Epoch 32/500\n",
      "43/43 [==============================] - 0s 658us/step - loss: 0.3863 - accuracy: 0.8633 - val_loss: 0.4849 - val_accuracy: 0.8300\n",
      "Epoch 33/500\n",
      "43/43 [==============================] - 0s 657us/step - loss: 0.3780 - accuracy: 0.8500 - val_loss: 0.5106 - val_accuracy: 0.8300\n",
      "Epoch 34/500\n",
      "43/43 [==============================] - 0s 623us/step - loss: 0.3736 - accuracy: 0.8533 - val_loss: 0.4851 - val_accuracy: 0.8000\n",
      "Epoch 35/500\n",
      "43/43 [==============================] - 0s 689us/step - loss: 0.3286 - accuracy: 0.8800 - val_loss: 0.4337 - val_accuracy: 0.7700\n",
      "Epoch 36/500\n",
      "43/43 [==============================] - 0s 678us/step - loss: 0.3759 - accuracy: 0.8567 - val_loss: 0.4170 - val_accuracy: 0.8800\n",
      "Epoch 37/500\n",
      "43/43 [==============================] - 0s 647us/step - loss: 0.3130 - accuracy: 0.8800 - val_loss: 0.4352 - val_accuracy: 0.8600\n",
      "Epoch 38/500\n",
      "43/43 [==============================] - 0s 633us/step - loss: 0.3135 - accuracy: 0.8733 - val_loss: 0.4010 - val_accuracy: 0.8800\n",
      "Epoch 39/500\n",
      "43/43 [==============================] - 0s 645us/step - loss: 0.3281 - accuracy: 0.8700 - val_loss: 0.4728 - val_accuracy: 0.8300\n",
      "Epoch 40/500\n",
      "43/43 [==============================] - 0s 638us/step - loss: 0.3444 - accuracy: 0.8667 - val_loss: 0.3947 - val_accuracy: 0.9200\n",
      "Epoch 41/500\n",
      "43/43 [==============================] - 0s 617us/step - loss: 0.3321 - accuracy: 0.8767 - val_loss: 0.3981 - val_accuracy: 0.8400\n",
      "Epoch 42/500\n",
      "43/43 [==============================] - 0s 613us/step - loss: 0.3252 - accuracy: 0.8633 - val_loss: 0.3616 - val_accuracy: 0.8800\n",
      "Epoch 43/500\n",
      "43/43 [==============================] - 0s 642us/step - loss: 0.3069 - accuracy: 0.8833 - val_loss: 0.4123 - val_accuracy: 0.9000\n",
      "Epoch 44/500\n",
      "43/43 [==============================] - 0s 661us/step - loss: 0.2808 - accuracy: 0.8967 - val_loss: 0.4216 - val_accuracy: 0.8600\n",
      "Epoch 45/500\n",
      "43/43 [==============================] - 0s 660us/step - loss: 0.2650 - accuracy: 0.9000 - val_loss: 0.3800 - val_accuracy: 0.8900\n",
      "Epoch 46/500\n",
      "43/43 [==============================] - 0s 625us/step - loss: 0.2332 - accuracy: 0.9367 - val_loss: 0.3458 - val_accuracy: 0.9000\n",
      "Epoch 47/500\n",
      "43/43 [==============================] - 0s 629us/step - loss: 0.3216 - accuracy: 0.8833 - val_loss: 0.4070 - val_accuracy: 0.8700\n",
      "Epoch 48/500\n",
      "43/43 [==============================] - 0s 643us/step - loss: 0.2912 - accuracy: 0.8900 - val_loss: 0.3903 - val_accuracy: 0.8300\n",
      "Epoch 49/500\n",
      "43/43 [==============================] - 0s 599us/step - loss: 0.2600 - accuracy: 0.9167 - val_loss: 0.3613 - val_accuracy: 0.8600\n",
      "Epoch 50/500\n",
      "43/43 [==============================] - 0s 602us/step - loss: 0.2731 - accuracy: 0.8833 - val_loss: 0.4268 - val_accuracy: 0.8600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51/500\n",
      "43/43 [==============================] - 0s 641us/step - loss: 0.2244 - accuracy: 0.9133 - val_loss: 0.3547 - val_accuracy: 0.8900\n",
      "Epoch 52/500\n",
      "43/43 [==============================] - 0s 631us/step - loss: 0.2574 - accuracy: 0.9033 - val_loss: 0.4570 - val_accuracy: 0.8400\n",
      "Epoch 53/500\n",
      "43/43 [==============================] - 0s 619us/step - loss: 0.2376 - accuracy: 0.9200 - val_loss: 0.3910 - val_accuracy: 0.9100\n",
      "Epoch 54/500\n",
      "43/43 [==============================] - 0s 648us/step - loss: 0.2576 - accuracy: 0.9133 - val_loss: 0.3649 - val_accuracy: 0.9200\n",
      "Epoch 55/500\n",
      "43/43 [==============================] - 0s 652us/step - loss: 0.2316 - accuracy: 0.9200 - val_loss: 0.3922 - val_accuracy: 0.9000\n",
      "Epoch 56/500\n",
      "43/43 [==============================] - 0s 610us/step - loss: 0.2665 - accuracy: 0.8933 - val_loss: 0.4719 - val_accuracy: 0.8600\n",
      "Epoch 57/500\n",
      "43/43 [==============================] - 0s 619us/step - loss: 0.2517 - accuracy: 0.9133 - val_loss: 0.3987 - val_accuracy: 0.9000\n",
      "Epoch 58/500\n",
      "43/43 [==============================] - 0s 627us/step - loss: 0.2323 - accuracy: 0.9033 - val_loss: 0.3874 - val_accuracy: 0.9300\n",
      "Epoch 59/500\n",
      "43/43 [==============================] - 0s 623us/step - loss: 0.2454 - accuracy: 0.9133 - val_loss: 0.3734 - val_accuracy: 0.9200\n",
      "Epoch 60/500\n",
      "43/43 [==============================] - 0s 609us/step - loss: 0.2420 - accuracy: 0.9033 - val_loss: 0.3842 - val_accuracy: 0.9200\n",
      "Epoch 61/500\n",
      "43/43 [==============================] - 0s 654us/step - loss: 0.2427 - accuracy: 0.9133 - val_loss: 0.3586 - val_accuracy: 0.9400\n",
      "Epoch 62/500\n",
      "43/43 [==============================] - 0s 706us/step - loss: 0.2120 - accuracy: 0.9300 - val_loss: 0.4177 - val_accuracy: 0.8800\n",
      "Epoch 63/500\n",
      "43/43 [==============================] - 0s 647us/step - loss: 0.2287 - accuracy: 0.9133 - val_loss: 0.4340 - val_accuracy: 0.8900\n",
      "Epoch 64/500\n",
      "43/43 [==============================] - 0s 629us/step - loss: 0.2293 - accuracy: 0.9167 - val_loss: 0.3525 - val_accuracy: 0.9200\n",
      "Epoch 65/500\n",
      "43/43 [==============================] - 0s 611us/step - loss: 0.2057 - accuracy: 0.9167 - val_loss: 0.4076 - val_accuracy: 0.9200\n",
      "Epoch 66/500\n",
      "43/43 [==============================] - 0s 654us/step - loss: 0.2249 - accuracy: 0.9233 - val_loss: 0.3744 - val_accuracy: 0.9200\n",
      "Epoch 67/500\n",
      "43/43 [==============================] - 0s 636us/step - loss: 0.2252 - accuracy: 0.9100 - val_loss: 0.3765 - val_accuracy: 0.9300\n",
      "Epoch 68/500\n",
      "43/43 [==============================] - 0s 624us/step - loss: 0.1842 - accuracy: 0.9433 - val_loss: 0.3481 - val_accuracy: 0.9300\n",
      "Epoch 69/500\n",
      "43/43 [==============================] - 0s 632us/step - loss: 0.2043 - accuracy: 0.9300 - val_loss: 0.3434 - val_accuracy: 0.9100\n",
      "Epoch 70/500\n",
      "43/43 [==============================] - 0s 637us/step - loss: 0.2017 - accuracy: 0.9200 - val_loss: 0.3732 - val_accuracy: 0.9000\n",
      "Epoch 71/500\n",
      "43/43 [==============================] - 0s 664us/step - loss: 0.2283 - accuracy: 0.9133 - val_loss: 0.3824 - val_accuracy: 0.9100\n",
      "Epoch 72/500\n",
      "43/43 [==============================] - 0s 660us/step - loss: 0.1733 - accuracy: 0.9400 - val_loss: 0.3907 - val_accuracy: 0.9200\n",
      "Epoch 73/500\n",
      "43/43 [==============================] - 0s 642us/step - loss: 0.1871 - accuracy: 0.9333 - val_loss: 0.3675 - val_accuracy: 0.9200\n",
      "Epoch 74/500\n",
      "43/43 [==============================] - 0s 657us/step - loss: 0.1667 - accuracy: 0.9567 - val_loss: 0.3914 - val_accuracy: 0.9100\n",
      "Epoch 75/500\n",
      "43/43 [==============================] - 0s 653us/step - loss: 0.1619 - accuracy: 0.9433 - val_loss: 0.4350 - val_accuracy: 0.9000\n",
      "Epoch 76/500\n",
      "43/43 [==============================] - 0s 648us/step - loss: 0.1766 - accuracy: 0.9400 - val_loss: 0.3660 - val_accuracy: 0.9300\n",
      "Epoch 77/500\n",
      "43/43 [==============================] - 0s 629us/step - loss: 0.1757 - accuracy: 0.9433 - val_loss: 0.3436 - val_accuracy: 0.9200\n",
      "Epoch 78/500\n",
      "43/43 [==============================] - 0s 628us/step - loss: 0.1880 - accuracy: 0.9367 - val_loss: 0.4084 - val_accuracy: 0.8800\n",
      "Epoch 79/500\n",
      "43/43 [==============================] - 0s 663us/step - loss: 0.1723 - accuracy: 0.9100 - val_loss: 0.3814 - val_accuracy: 0.9100\n",
      "Epoch 80/500\n",
      "43/43 [==============================] - 0s 653us/step - loss: 0.1627 - accuracy: 0.9400 - val_loss: 0.3760 - val_accuracy: 0.9300\n",
      "Epoch 81/500\n",
      "43/43 [==============================] - 0s 634us/step - loss: 0.1691 - accuracy: 0.9467 - val_loss: 0.3965 - val_accuracy: 0.9100\n",
      "Epoch 82/500\n",
      "43/43 [==============================] - 0s 643us/step - loss: 0.1744 - accuracy: 0.9467 - val_loss: 0.3447 - val_accuracy: 0.9300\n",
      "Epoch 83/500\n",
      "43/43 [==============================] - 0s 665us/step - loss: 0.1390 - accuracy: 0.9500 - val_loss: 0.3654 - val_accuracy: 0.9200\n",
      "Epoch 84/500\n",
      "43/43 [==============================] - 0s 652us/step - loss: 0.1635 - accuracy: 0.9400 - val_loss: 0.3997 - val_accuracy: 0.9300\n",
      "Epoch 85/500\n",
      "43/43 [==============================] - 0s 626us/step - loss: 0.1876 - accuracy: 0.9367 - val_loss: 0.4272 - val_accuracy: 0.9200\n",
      "Epoch 86/500\n",
      "43/43 [==============================] - 0s 641us/step - loss: 0.1471 - accuracy: 0.9600 - val_loss: 0.3974 - val_accuracy: 0.9300\n",
      "Epoch 87/500\n",
      "43/43 [==============================] - 0s 706us/step - loss: 0.1735 - accuracy: 0.9200 - val_loss: 0.4265 - val_accuracy: 0.9300\n",
      "Epoch 88/500\n",
      "43/43 [==============================] - 0s 647us/step - loss: 0.1661 - accuracy: 0.9267 - val_loss: 0.4923 - val_accuracy: 0.8600\n",
      "Epoch 89/500\n",
      "43/43 [==============================] - 0s 630us/step - loss: 0.1615 - accuracy: 0.9500 - val_loss: 0.4085 - val_accuracy: 0.9200\n",
      "Epoch 90/500\n",
      "43/43 [==============================] - 0s 613us/step - loss: 0.1407 - accuracy: 0.9467 - val_loss: 0.3672 - val_accuracy: 0.9300\n",
      "Epoch 91/500\n",
      "43/43 [==============================] - 0s 682us/step - loss: 0.1681 - accuracy: 0.9400 - val_loss: 0.3992 - val_accuracy: 0.9000\n",
      "Epoch 92/500\n",
      "43/43 [==============================] - 0s 719us/step - loss: 0.1694 - accuracy: 0.9400 - val_loss: 0.3721 - val_accuracy: 0.9400\n",
      "Epoch 93/500\n",
      "43/43 [==============================] - 0s 642us/step - loss: 0.1916 - accuracy: 0.9233 - val_loss: 0.3688 - val_accuracy: 0.9400\n",
      "Epoch 94/500\n",
      "43/43 [==============================] - 0s 628us/step - loss: 0.1523 - accuracy: 0.9533 - val_loss: 0.3913 - val_accuracy: 0.9200\n",
      "Epoch 95/500\n",
      "43/43 [==============================] - 0s 678us/step - loss: 0.1481 - accuracy: 0.9467 - val_loss: 0.3841 - val_accuracy: 0.9300\n",
      "Epoch 96/500\n",
      "43/43 [==============================] - 0s 626us/step - loss: 0.1629 - accuracy: 0.9367 - val_loss: 0.3641 - val_accuracy: 0.9400\n",
      "Epoch 97/500\n",
      "43/43 [==============================] - 0s 648us/step - loss: 0.1416 - accuracy: 0.9400 - val_loss: 0.3377 - val_accuracy: 0.9300\n",
      "Epoch 98/500\n",
      "43/43 [==============================] - 0s 659us/step - loss: 0.1295 - accuracy: 0.9633 - val_loss: 0.3577 - val_accuracy: 0.9200\n",
      "Epoch 99/500\n",
      "43/43 [==============================] - 0s 662us/step - loss: 0.1414 - accuracy: 0.9567 - val_loss: 0.3593 - val_accuracy: 0.9300\n",
      "Epoch 100/500\n",
      "43/43 [==============================] - 0s 621us/step - loss: 0.1212 - accuracy: 0.9667 - val_loss: 0.4128 - val_accuracy: 0.9300\n",
      "Epoch 101/500\n",
      "43/43 [==============================] - 0s 692us/step - loss: 0.1547 - accuracy: 0.9267 - val_loss: 0.4405 - val_accuracy: 0.9100\n",
      "Epoch 102/500\n",
      "43/43 [==============================] - 0s 708us/step - loss: 0.1375 - accuracy: 0.9467 - val_loss: 0.3997 - val_accuracy: 0.9300\n",
      "Epoch 103/500\n",
      "43/43 [==============================] - 0s 646us/step - loss: 0.1132 - accuracy: 0.9600 - val_loss: 0.3945 - val_accuracy: 0.9300\n",
      "Epoch 104/500\n",
      "43/43 [==============================] - 0s 622us/step - loss: 0.1452 - accuracy: 0.9333 - val_loss: 0.4150 - val_accuracy: 0.9300\n",
      "Epoch 105/500\n",
      "43/43 [==============================] - 0s 605us/step - loss: 0.1392 - accuracy: 0.9633 - val_loss: 0.4287 - val_accuracy: 0.9200\n",
      "Epoch 106/500\n",
      "43/43 [==============================] - 0s 653us/step - loss: 0.1416 - accuracy: 0.9533 - val_loss: 0.3932 - val_accuracy: 0.9300\n",
      "Epoch 107/500\n",
      "43/43 [==============================] - 0s 655us/step - loss: 0.1117 - accuracy: 0.9667 - val_loss: 0.3856 - val_accuracy: 0.9400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 108/500\n",
      "43/43 [==============================] - 0s 645us/step - loss: 0.1397 - accuracy: 0.9533 - val_loss: 0.4010 - val_accuracy: 0.9400\n",
      "Epoch 109/500\n",
      "43/43 [==============================] - 0s 621us/step - loss: 0.1351 - accuracy: 0.9567 - val_loss: 0.3966 - val_accuracy: 0.9300\n",
      "Epoch 110/500\n",
      "43/43 [==============================] - 0s 639us/step - loss: 0.1297 - accuracy: 0.9500 - val_loss: 0.4436 - val_accuracy: 0.9100\n",
      "Epoch 111/500\n",
      "43/43 [==============================] - 0s 627us/step - loss: 0.1664 - accuracy: 0.9533 - val_loss: 0.3956 - val_accuracy: 0.9300\n",
      "Epoch 112/500\n",
      "43/43 [==============================] - 0s 628us/step - loss: 0.1205 - accuracy: 0.9500 - val_loss: 0.4169 - val_accuracy: 0.9400\n",
      "Epoch 113/500\n",
      "43/43 [==============================] - 0s 647us/step - loss: 0.1235 - accuracy: 0.9667 - val_loss: 0.4179 - val_accuracy: 0.9400\n",
      "Epoch 114/500\n",
      "43/43 [==============================] - 0s 675us/step - loss: 0.1197 - accuracy: 0.9600 - val_loss: 0.4009 - val_accuracy: 0.9300\n",
      "Epoch 115/500\n",
      "43/43 [==============================] - 0s 668us/step - loss: 0.1067 - accuracy: 0.9667 - val_loss: 0.4134 - val_accuracy: 0.9200\n",
      "Epoch 116/500\n",
      "43/43 [==============================] - 0s 624us/step - loss: 0.1105 - accuracy: 0.9700 - val_loss: 0.4031 - val_accuracy: 0.9300\n",
      "Epoch 117/500\n",
      "43/43 [==============================] - 0s 632us/step - loss: 0.1212 - accuracy: 0.9600 - val_loss: 0.3650 - val_accuracy: 0.9200\n",
      "Epoch 118/500\n",
      "43/43 [==============================] - 0s 658us/step - loss: 0.1224 - accuracy: 0.9600 - val_loss: 0.4238 - val_accuracy: 0.9300\n",
      "Epoch 119/500\n",
      "43/43 [==============================] - 0s 625us/step - loss: 0.0995 - accuracy: 0.9567 - val_loss: 0.4211 - val_accuracy: 0.9400\n",
      "Epoch 120/500\n",
      "43/43 [==============================] - 0s 623us/step - loss: 0.1148 - accuracy: 0.9633 - val_loss: 0.4026 - val_accuracy: 0.9400\n",
      "Epoch 121/500\n",
      "43/43 [==============================] - 0s 622us/step - loss: 0.1195 - accuracy: 0.9567 - val_loss: 0.4066 - val_accuracy: 0.9100\n",
      "Epoch 122/500\n",
      "43/43 [==============================] - 0s 691us/step - loss: 0.1222 - accuracy: 0.9633 - val_loss: 0.3961 - val_accuracy: 0.9400\n",
      "Epoch 123/500\n",
      "43/43 [==============================] - 0s 833us/step - loss: 0.1318 - accuracy: 0.9733 - val_loss: 0.3606 - val_accuracy: 0.9400\n",
      "Epoch 124/500\n",
      "43/43 [==============================] - 0s 769us/step - loss: 0.1151 - accuracy: 0.9767 - val_loss: 0.4024 - val_accuracy: 0.9400\n",
      "Epoch 125/500\n",
      "43/43 [==============================] - 0s 843us/step - loss: 0.1194 - accuracy: 0.9433 - val_loss: 0.4536 - val_accuracy: 0.9300\n",
      "Epoch 126/500\n",
      "43/43 [==============================] - 0s 817us/step - loss: 0.1378 - accuracy: 0.9400 - val_loss: 0.3636 - val_accuracy: 0.9200\n",
      "Epoch 127/500\n",
      "43/43 [==============================] - 0s 747us/step - loss: 0.1414 - accuracy: 0.9467 - val_loss: 0.4697 - val_accuracy: 0.9300\n",
      "Epoch 128/500\n",
      "43/43 [==============================] - 0s 777us/step - loss: 0.1429 - accuracy: 0.9433 - val_loss: 0.4749 - val_accuracy: 0.9200\n",
      "Epoch 129/500\n",
      "43/43 [==============================] - 0s 689us/step - loss: 0.1204 - accuracy: 0.9467 - val_loss: 0.4715 - val_accuracy: 0.9000\n",
      "Epoch 130/500\n",
      "43/43 [==============================] - 0s 672us/step - loss: 0.0941 - accuracy: 0.9667 - val_loss: 0.4139 - val_accuracy: 0.9300\n",
      "Epoch 131/500\n",
      "43/43 [==============================] - 0s 683us/step - loss: 0.1057 - accuracy: 0.9700 - val_loss: 0.4060 - val_accuracy: 0.9400\n",
      "Epoch 132/500\n",
      "43/43 [==============================] - 0s 659us/step - loss: 0.0955 - accuracy: 0.9633 - val_loss: 0.3833 - val_accuracy: 0.9400\n",
      "Epoch 133/500\n",
      "43/43 [==============================] - 0s 658us/step - loss: 0.1548 - accuracy: 0.9533 - val_loss: 0.3941 - val_accuracy: 0.9400\n",
      "Epoch 134/500\n",
      "43/43 [==============================] - 0s 678us/step - loss: 0.1148 - accuracy: 0.9600 - val_loss: 0.4536 - val_accuracy: 0.9400\n",
      "Epoch 135/500\n",
      "43/43 [==============================] - 0s 689us/step - loss: 0.1435 - accuracy: 0.9500 - val_loss: 0.4423 - val_accuracy: 0.9300\n",
      "Epoch 136/500\n",
      "43/43 [==============================] - 0s 684us/step - loss: 0.1173 - accuracy: 0.9567 - val_loss: 0.4395 - val_accuracy: 0.9400\n",
      "Epoch 137/500\n",
      "43/43 [==============================] - 0s 708us/step - loss: 0.1046 - accuracy: 0.9600 - val_loss: 0.4137 - val_accuracy: 0.9200\n",
      "Epoch 138/500\n",
      "43/43 [==============================] - 0s 629us/step - loss: 0.1094 - accuracy: 0.9600 - val_loss: 0.4281 - val_accuracy: 0.9400\n",
      "Epoch 139/500\n",
      "43/43 [==============================] - 0s 612us/step - loss: 0.0742 - accuracy: 0.9700 - val_loss: 0.3300 - val_accuracy: 0.9100\n",
      "Epoch 140/500\n",
      "43/43 [==============================] - 0s 639us/step - loss: 0.1268 - accuracy: 0.9433 - val_loss: 0.4200 - val_accuracy: 0.9400\n",
      "Epoch 141/500\n",
      "43/43 [==============================] - 0s 706us/step - loss: 0.1061 - accuracy: 0.9667 - val_loss: 0.4049 - val_accuracy: 0.9400\n",
      "Epoch 142/500\n",
      "43/43 [==============================] - 0s 623us/step - loss: 0.0855 - accuracy: 0.9733 - val_loss: 0.4358 - val_accuracy: 0.9400\n",
      "Epoch 143/500\n",
      "43/43 [==============================] - 0s 611us/step - loss: 0.0822 - accuracy: 0.9700 - val_loss: 0.4797 - val_accuracy: 0.9300\n",
      "Epoch 144/500\n",
      "43/43 [==============================] - 0s 661us/step - loss: 0.1328 - accuracy: 0.9500 - val_loss: 0.5383 - val_accuracy: 0.9200\n",
      "Epoch 145/500\n",
      "43/43 [==============================] - 0s 660us/step - loss: 0.1145 - accuracy: 0.9667 - val_loss: 0.4562 - val_accuracy: 0.9400\n",
      "Epoch 146/500\n",
      "43/43 [==============================] - 0s 656us/step - loss: 0.1079 - accuracy: 0.9467 - val_loss: 0.4402 - val_accuracy: 0.9300\n",
      "Epoch 147/500\n",
      "43/43 [==============================] - 0s 683us/step - loss: 0.0966 - accuracy: 0.9700 - val_loss: 0.4323 - val_accuracy: 0.9300\n",
      "Epoch 148/500\n",
      "43/43 [==============================] - 0s 701us/step - loss: 0.1264 - accuracy: 0.9533 - val_loss: 0.4846 - val_accuracy: 0.9300\n",
      "Epoch 149/500\n",
      "43/43 [==============================] - 0s 664us/step - loss: 0.1069 - accuracy: 0.9533 - val_loss: 0.4821 - val_accuracy: 0.9200\n",
      "Epoch 150/500\n",
      "43/43 [==============================] - 0s 699us/step - loss: 0.1095 - accuracy: 0.9633 - val_loss: 0.4378 - val_accuracy: 0.9400\n",
      "Epoch 151/500\n",
      "43/43 [==============================] - 0s 675us/step - loss: 0.0931 - accuracy: 0.9767 - val_loss: 0.4399 - val_accuracy: 0.9400\n",
      "Epoch 152/500\n",
      "43/43 [==============================] - 0s 612us/step - loss: 0.1219 - accuracy: 0.9500 - val_loss: 0.4114 - val_accuracy: 0.9400\n",
      "Epoch 153/500\n",
      "43/43 [==============================] - 0s 613us/step - loss: 0.1374 - accuracy: 0.9533 - val_loss: 0.4327 - val_accuracy: 0.9400\n",
      "Epoch 154/500\n",
      "43/43 [==============================] - 0s 695us/step - loss: 0.0892 - accuracy: 0.9700 - val_loss: 0.4227 - val_accuracy: 0.9300\n",
      "Epoch 155/500\n",
      "43/43 [==============================] - 0s 672us/step - loss: 0.0839 - accuracy: 0.9700 - val_loss: 0.4182 - val_accuracy: 0.9400\n",
      "Epoch 156/500\n",
      "43/43 [==============================] - 0s 646us/step - loss: 0.0699 - accuracy: 0.9767 - val_loss: 0.4286 - val_accuracy: 0.9300\n",
      "Epoch 157/500\n",
      "43/43 [==============================] - 0s 639us/step - loss: 0.1027 - accuracy: 0.9500 - val_loss: 0.4176 - val_accuracy: 0.9400\n",
      "Epoch 158/500\n",
      "43/43 [==============================] - 0s 619us/step - loss: 0.1214 - accuracy: 0.9400 - val_loss: 0.4177 - val_accuracy: 0.9500\n",
      "Epoch 159/500\n",
      "43/43 [==============================] - 0s 671us/step - loss: 0.0894 - accuracy: 0.9700 - val_loss: 0.4169 - val_accuracy: 0.9400\n",
      "Epoch 160/500\n",
      "43/43 [==============================] - 0s 634us/step - loss: 0.0804 - accuracy: 0.9733 - val_loss: 0.3905 - val_accuracy: 0.9400\n",
      "Epoch 161/500\n",
      "43/43 [==============================] - 0s 623us/step - loss: 0.0887 - accuracy: 0.9667 - val_loss: 0.4547 - val_accuracy: 0.9200\n",
      "Epoch 162/500\n",
      "43/43 [==============================] - 0s 650us/step - loss: 0.0907 - accuracy: 0.9700 - val_loss: 0.3822 - val_accuracy: 0.9300\n",
      "Epoch 163/500\n",
      "43/43 [==============================] - 0s 658us/step - loss: 0.1307 - accuracy: 0.9533 - val_loss: 0.4090 - val_accuracy: 0.9200\n",
      "Epoch 164/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - 0s 657us/step - loss: 0.0607 - accuracy: 0.9733 - val_loss: 0.4312 - val_accuracy: 0.9400\n",
      "Epoch 165/500\n",
      "43/43 [==============================] - 0s 631us/step - loss: 0.0806 - accuracy: 0.9800 - val_loss: 0.4070 - val_accuracy: 0.9400\n",
      "Epoch 166/500\n",
      "43/43 [==============================] - 0s 624us/step - loss: 0.0738 - accuracy: 0.9733 - val_loss: 0.4570 - val_accuracy: 0.9400\n",
      "Epoch 167/500\n",
      "43/43 [==============================] - 0s 636us/step - loss: 0.0953 - accuracy: 0.9633 - val_loss: 0.4006 - val_accuracy: 0.9400\n",
      "Epoch 168/500\n",
      "43/43 [==============================] - 0s 709us/step - loss: 0.0766 - accuracy: 0.9733 - val_loss: 0.5496 - val_accuracy: 0.9200\n",
      "Epoch 169/500\n",
      "43/43 [==============================] - 0s 626us/step - loss: 0.1023 - accuracy: 0.9567 - val_loss: 0.4783 - val_accuracy: 0.9400\n",
      "Epoch 170/500\n",
      "43/43 [==============================] - 0s 622us/step - loss: 0.0879 - accuracy: 0.9667 - val_loss: 0.4709 - val_accuracy: 0.9300\n",
      "Epoch 171/500\n",
      "43/43 [==============================] - 0s 603us/step - loss: 0.0875 - accuracy: 0.9667 - val_loss: 0.5050 - val_accuracy: 0.9400\n",
      "Epoch 172/500\n",
      "43/43 [==============================] - 0s 640us/step - loss: 0.0946 - accuracy: 0.9667 - val_loss: 0.4754 - val_accuracy: 0.9400\n",
      "Epoch 173/500\n",
      "43/43 [==============================] - 0s 620us/step - loss: 0.1026 - accuracy: 0.9533 - val_loss: 0.4805 - val_accuracy: 0.9400\n",
      "Epoch 174/500\n",
      "43/43 [==============================] - 0s 603us/step - loss: 0.1020 - accuracy: 0.9533 - val_loss: 0.4237 - val_accuracy: 0.9400\n",
      "Epoch 175/500\n",
      "43/43 [==============================] - 0s 638us/step - loss: 0.0767 - accuracy: 0.9667 - val_loss: 0.4815 - val_accuracy: 0.9400\n",
      "Epoch 176/500\n",
      "43/43 [==============================] - 0s 617us/step - loss: 0.0948 - accuracy: 0.9600 - val_loss: 0.4066 - val_accuracy: 0.9500\n",
      "Epoch 177/500\n",
      "43/43 [==============================] - 0s 619us/step - loss: 0.1089 - accuracy: 0.9600 - val_loss: 0.4338 - val_accuracy: 0.9400\n",
      "Epoch 178/500\n",
      "43/43 [==============================] - 0s 650us/step - loss: 0.0982 - accuracy: 0.9700 - val_loss: 0.4372 - val_accuracy: 0.9300\n",
      "Epoch 179/500\n",
      "43/43 [==============================] - 0s 654us/step - loss: 0.0945 - accuracy: 0.9600 - val_loss: 0.4226 - val_accuracy: 0.9300\n",
      "Epoch 180/500\n",
      "43/43 [==============================] - 0s 633us/step - loss: 0.0918 - accuracy: 0.9667 - val_loss: 0.5183 - val_accuracy: 0.9400\n",
      "Epoch 181/500\n",
      "43/43 [==============================] - 0s 624us/step - loss: 0.0943 - accuracy: 0.9667 - val_loss: 0.4936 - val_accuracy: 0.9300\n",
      "Epoch 182/500\n",
      "43/43 [==============================] - 0s 641us/step - loss: 0.0913 - accuracy: 0.9667 - val_loss: 0.4534 - val_accuracy: 0.9300\n",
      "Epoch 183/500\n",
      "43/43 [==============================] - 0s 697us/step - loss: 0.0690 - accuracy: 0.9700 - val_loss: 0.5243 - val_accuracy: 0.9400\n",
      "Epoch 184/500\n",
      "43/43 [==============================] - 0s 638us/step - loss: 0.0972 - accuracy: 0.9533 - val_loss: 0.4795 - val_accuracy: 0.9300\n",
      "Epoch 185/500\n",
      "43/43 [==============================] - 0s 643us/step - loss: 0.0841 - accuracy: 0.9767 - val_loss: 0.5083 - val_accuracy: 0.9400\n",
      "Epoch 186/500\n",
      "43/43 [==============================] - 0s 634us/step - loss: 0.0729 - accuracy: 0.9800 - val_loss: 0.4960 - val_accuracy: 0.9400\n",
      "Epoch 187/500\n",
      "43/43 [==============================] - 0s 642us/step - loss: 0.0805 - accuracy: 0.9667 - val_loss: 0.4813 - val_accuracy: 0.9300\n",
      "Epoch 188/500\n",
      "43/43 [==============================] - 0s 611us/step - loss: 0.1004 - accuracy: 0.9667 - val_loss: 0.5170 - val_accuracy: 0.9400\n",
      "Epoch 189/500\n",
      "43/43 [==============================] - 0s 634us/step - loss: 0.0778 - accuracy: 0.9700 - val_loss: 0.4902 - val_accuracy: 0.9500\n",
      "Epoch 190/500\n",
      "43/43 [==============================] - 0s 620us/step - loss: 0.0475 - accuracy: 0.9800 - val_loss: 0.5177 - val_accuracy: 0.9400\n",
      "Epoch 191/500\n",
      "43/43 [==============================] - 0s 645us/step - loss: 0.0908 - accuracy: 0.9667 - val_loss: 0.5649 - val_accuracy: 0.9100\n",
      "Epoch 192/500\n",
      "43/43 [==============================] - 0s 721us/step - loss: 0.0816 - accuracy: 0.9767 - val_loss: 0.4744 - val_accuracy: 0.9300\n",
      "Epoch 193/500\n",
      "43/43 [==============================] - 0s 656us/step - loss: 0.0456 - accuracy: 0.9833 - val_loss: 0.4444 - val_accuracy: 0.9400\n",
      "Epoch 194/500\n",
      "43/43 [==============================] - 0s 635us/step - loss: 0.0580 - accuracy: 0.9733 - val_loss: 0.4660 - val_accuracy: 0.9400\n",
      "Epoch 195/500\n",
      "43/43 [==============================] - 0s 676us/step - loss: 0.0773 - accuracy: 0.9667 - val_loss: 0.4630 - val_accuracy: 0.9500\n",
      "Epoch 196/500\n",
      "43/43 [==============================] - 0s 652us/step - loss: 0.0862 - accuracy: 0.9667 - val_loss: 0.5225 - val_accuracy: 0.9500\n",
      "Epoch 197/500\n",
      "43/43 [==============================] - 0s 663us/step - loss: 0.0857 - accuracy: 0.9733 - val_loss: 0.5240 - val_accuracy: 0.9400\n",
      "Epoch 198/500\n",
      "43/43 [==============================] - 0s 666us/step - loss: 0.0790 - accuracy: 0.9733 - val_loss: 0.4600 - val_accuracy: 0.9400\n",
      "Epoch 199/500\n",
      "43/43 [==============================] - 0s 644us/step - loss: 0.0734 - accuracy: 0.9733 - val_loss: 0.5498 - val_accuracy: 0.9400\n",
      "Epoch 200/500\n",
      "43/43 [==============================] - 0s 626us/step - loss: 0.1154 - accuracy: 0.9567 - val_loss: 0.5094 - val_accuracy: 0.9500\n",
      "Epoch 201/500\n",
      "43/43 [==============================] - 0s 625us/step - loss: 0.0595 - accuracy: 0.9800 - val_loss: 0.4853 - val_accuracy: 0.9500\n",
      "Epoch 202/500\n",
      "43/43 [==============================] - 0s 605us/step - loss: 0.0742 - accuracy: 0.9667 - val_loss: 0.5112 - val_accuracy: 0.9200\n",
      "Epoch 203/500\n",
      "43/43 [==============================] - 0s 610us/step - loss: 0.1199 - accuracy: 0.9400 - val_loss: 0.4724 - val_accuracy: 0.9100\n",
      "Epoch 204/500\n",
      "43/43 [==============================] - 0s 648us/step - loss: 0.1083 - accuracy: 0.9667 - val_loss: 0.4521 - val_accuracy: 0.9300\n",
      "Epoch 205/500\n",
      "43/43 [==============================] - 0s 618us/step - loss: 0.0719 - accuracy: 0.9733 - val_loss: 0.4344 - val_accuracy: 0.9400\n",
      "Epoch 206/500\n",
      "43/43 [==============================] - 0s 623us/step - loss: 0.0696 - accuracy: 0.9733 - val_loss: 0.5366 - val_accuracy: 0.9400\n",
      "Epoch 207/500\n",
      "43/43 [==============================] - 0s 637us/step - loss: 0.1258 - accuracy: 0.9367 - val_loss: 0.4241 - val_accuracy: 0.9400\n",
      "Epoch 208/500\n",
      "43/43 [==============================] - 0s 639us/step - loss: 0.1074 - accuracy: 0.9467 - val_loss: 0.4271 - val_accuracy: 0.9500\n",
      "Epoch 209/500\n",
      "43/43 [==============================] - 0s 633us/step - loss: 0.0732 - accuracy: 0.9833 - val_loss: 0.5525 - val_accuracy: 0.9400\n",
      "Epoch 210/500\n",
      "43/43 [==============================] - 0s 604us/step - loss: 0.1026 - accuracy: 0.9467 - val_loss: 0.4734 - val_accuracy: 0.9300\n",
      "Epoch 211/500\n",
      "43/43 [==============================] - 0s 640us/step - loss: 0.0827 - accuracy: 0.9600 - val_loss: 0.4533 - val_accuracy: 0.9500\n",
      "Epoch 212/500\n",
      "43/43 [==============================] - 0s 633us/step - loss: 0.0970 - accuracy: 0.9500 - val_loss: 0.5244 - val_accuracy: 0.9400\n",
      "Epoch 213/500\n",
      "43/43 [==============================] - 0s 614us/step - loss: 0.0809 - accuracy: 0.9733 - val_loss: 0.4359 - val_accuracy: 0.9400\n",
      "Epoch 214/500\n",
      "43/43 [==============================] - 0s 628us/step - loss: 0.0693 - accuracy: 0.9767 - val_loss: 0.4459 - val_accuracy: 0.9300\n",
      "Epoch 215/500\n",
      "43/43 [==============================] - 0s 646us/step - loss: 0.0984 - accuracy: 0.9633 - val_loss: 0.4404 - val_accuracy: 0.9400\n",
      "Epoch 216/500\n",
      "43/43 [==============================] - 0s 626us/step - loss: 0.0337 - accuracy: 0.9900 - val_loss: 0.3948 - val_accuracy: 0.9400\n",
      "Epoch 217/500\n",
      "43/43 [==============================] - 0s 621us/step - loss: 0.0841 - accuracy: 0.9633 - val_loss: 0.4310 - val_accuracy: 0.9400\n",
      "Epoch 218/500\n",
      "43/43 [==============================] - 0s 697us/step - loss: 0.0605 - accuracy: 0.9800 - val_loss: 0.5098 - val_accuracy: 0.9500\n",
      "Epoch 219/500\n",
      "43/43 [==============================] - 0s 675us/step - loss: 0.0768 - accuracy: 0.9767 - val_loss: 0.4513 - val_accuracy: 0.9400\n",
      "Epoch 220/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - 0s 644us/step - loss: 0.0564 - accuracy: 0.9800 - val_loss: 0.5215 - val_accuracy: 0.9300\n",
      "Epoch 221/500\n",
      "43/43 [==============================] - 0s 615us/step - loss: 0.0558 - accuracy: 0.9800 - val_loss: 0.4612 - val_accuracy: 0.9200\n",
      "Epoch 222/500\n",
      "43/43 [==============================] - 0s 611us/step - loss: 0.0865 - accuracy: 0.9667 - val_loss: 0.4927 - val_accuracy: 0.9400\n",
      "Epoch 223/500\n",
      "43/43 [==============================] - 0s 637us/step - loss: 0.0404 - accuracy: 0.9867 - val_loss: 0.4836 - val_accuracy: 0.9300\n",
      "Epoch 224/500\n",
      "43/43 [==============================] - 0s 639us/step - loss: 0.0659 - accuracy: 0.9733 - val_loss: 0.4609 - val_accuracy: 0.9400\n",
      "Epoch 225/500\n",
      "43/43 [==============================] - 0s 611us/step - loss: 0.0959 - accuracy: 0.9667 - val_loss: 0.4579 - val_accuracy: 0.9400\n",
      "Epoch 226/500\n",
      "43/43 [==============================] - 0s 628us/step - loss: 0.0679 - accuracy: 0.9767 - val_loss: 0.5007 - val_accuracy: 0.9500\n",
      "Epoch 227/500\n",
      "43/43 [==============================] - 0s 645us/step - loss: 0.0399 - accuracy: 0.9900 - val_loss: 0.4582 - val_accuracy: 0.9400\n",
      "Epoch 228/500\n",
      "43/43 [==============================] - 0s 618us/step - loss: 0.0433 - accuracy: 0.9833 - val_loss: 0.5412 - val_accuracy: 0.9500\n",
      "Epoch 229/500\n",
      "43/43 [==============================] - 0s 617us/step - loss: 0.0746 - accuracy: 0.9767 - val_loss: 0.5444 - val_accuracy: 0.9400\n",
      "Epoch 230/500\n",
      "43/43 [==============================] - 0s 652us/step - loss: 0.0718 - accuracy: 0.9700 - val_loss: 0.4799 - val_accuracy: 0.9500\n",
      "Epoch 231/500\n",
      "43/43 [==============================] - 0s 669us/step - loss: 0.0792 - accuracy: 0.9733 - val_loss: 0.4639 - val_accuracy: 0.9500\n",
      "Epoch 232/500\n",
      "43/43 [==============================] - 0s 637us/step - loss: 0.0538 - accuracy: 0.9833 - val_loss: 0.5124 - val_accuracy: 0.9400\n",
      "Epoch 233/500\n",
      "43/43 [==============================] - 0s 693us/step - loss: 0.0878 - accuracy: 0.9633 - val_loss: 0.5670 - val_accuracy: 0.9300\n",
      "Epoch 234/500\n",
      "43/43 [==============================] - 0s 679us/step - loss: 0.0463 - accuracy: 0.9833 - val_loss: 0.5068 - val_accuracy: 0.9400\n",
      "Epoch 235/500\n",
      "43/43 [==============================] - 0s 648us/step - loss: 0.0500 - accuracy: 0.9800 - val_loss: 0.5621 - val_accuracy: 0.9400\n",
      "Epoch 236/500\n",
      "43/43 [==============================] - 0s 659us/step - loss: 0.0913 - accuracy: 0.9733 - val_loss: 0.4948 - val_accuracy: 0.9500\n",
      "Epoch 237/500\n",
      "43/43 [==============================] - 0s 640us/step - loss: 0.0799 - accuracy: 0.9700 - val_loss: 0.4401 - val_accuracy: 0.9400\n",
      "Epoch 238/500\n",
      "43/43 [==============================] - 0s 616us/step - loss: 0.0495 - accuracy: 0.9833 - val_loss: 0.4639 - val_accuracy: 0.9500\n",
      "Epoch 239/500\n",
      "43/43 [==============================] - 0s 658us/step - loss: 0.0600 - accuracy: 0.9833 - val_loss: 0.5443 - val_accuracy: 0.9300\n",
      "Epoch 240/500\n",
      "43/43 [==============================] - 0s 659us/step - loss: 0.0630 - accuracy: 0.9733 - val_loss: 0.4878 - val_accuracy: 0.9400\n",
      "Epoch 241/500\n",
      "43/43 [==============================] - 0s 633us/step - loss: 0.0944 - accuracy: 0.9567 - val_loss: 0.5138 - val_accuracy: 0.9400\n",
      "Epoch 242/500\n",
      "43/43 [==============================] - 0s 615us/step - loss: 0.0600 - accuracy: 0.9733 - val_loss: 0.4955 - val_accuracy: 0.9500\n",
      "Epoch 243/500\n",
      "43/43 [==============================] - 0s 621us/step - loss: 0.0351 - accuracy: 0.9867 - val_loss: 0.5005 - val_accuracy: 0.9400\n",
      "Epoch 244/500\n",
      "43/43 [==============================] - 0s 625us/step - loss: 0.0541 - accuracy: 0.9767 - val_loss: 0.5740 - val_accuracy: 0.9400\n",
      "Epoch 245/500\n",
      "43/43 [==============================] - 0s 624us/step - loss: 0.0984 - accuracy: 0.9567 - val_loss: 0.5681 - val_accuracy: 0.9400\n",
      "Epoch 246/500\n",
      "43/43 [==============================] - 0s 613us/step - loss: 0.0487 - accuracy: 0.9767 - val_loss: 0.4463 - val_accuracy: 0.9400\n",
      "Epoch 247/500\n",
      "43/43 [==============================] - 0s 650us/step - loss: 0.0706 - accuracy: 0.9767 - val_loss: 0.5855 - val_accuracy: 0.9400\n",
      "Epoch 248/500\n",
      "43/43 [==============================] - 0s 696us/step - loss: 0.0791 - accuracy: 0.9700 - val_loss: 0.4474 - val_accuracy: 0.9500\n",
      "Epoch 249/500\n",
      "43/43 [==============================] - 0s 637us/step - loss: 0.0862 - accuracy: 0.9700 - val_loss: 0.5601 - val_accuracy: 0.9300\n",
      "Epoch 250/500\n",
      "43/43 [==============================] - 0s 639us/step - loss: 0.0612 - accuracy: 0.9867 - val_loss: 0.4418 - val_accuracy: 0.9400\n",
      "Epoch 251/500\n",
      "43/43 [==============================] - 0s 661us/step - loss: 0.0530 - accuracy: 0.9867 - val_loss: 0.3961 - val_accuracy: 0.9400\n",
      "Epoch 252/500\n",
      "43/43 [==============================] - 0s 642us/step - loss: 0.0560 - accuracy: 0.9700 - val_loss: 0.4060 - val_accuracy: 0.9400\n",
      "Epoch 253/500\n",
      "43/43 [==============================] - 0s 651us/step - loss: 0.0672 - accuracy: 0.9633 - val_loss: 0.4460 - val_accuracy: 0.9500\n",
      "Epoch 254/500\n",
      "43/43 [==============================] - 0s 615us/step - loss: 0.0530 - accuracy: 0.9800 - val_loss: 0.5754 - val_accuracy: 0.9300\n",
      "Epoch 255/500\n",
      "43/43 [==============================] - 0s 625us/step - loss: 0.0389 - accuracy: 0.9767 - val_loss: 0.5163 - val_accuracy: 0.9400\n",
      "Epoch 256/500\n",
      "43/43 [==============================] - 0s 628us/step - loss: 0.0950 - accuracy: 0.9633 - val_loss: 0.5229 - val_accuracy: 0.9400\n",
      "Epoch 257/500\n",
      "43/43 [==============================] - 0s 601us/step - loss: 0.0645 - accuracy: 0.9733 - val_loss: 0.5683 - val_accuracy: 0.9400\n",
      "Epoch 258/500\n",
      "43/43 [==============================] - 0s 619us/step - loss: 0.0974 - accuracy: 0.9700 - val_loss: 0.3747 - val_accuracy: 0.9400\n",
      "Epoch 259/500\n",
      "43/43 [==============================] - 0s 647us/step - loss: 0.0595 - accuracy: 0.9800 - val_loss: 0.4355 - val_accuracy: 0.9400\n",
      "Epoch 260/500\n",
      "43/43 [==============================] - 0s 650us/step - loss: 0.0424 - accuracy: 0.9867 - val_loss: 0.4251 - val_accuracy: 0.9400\n",
      "Epoch 261/500\n",
      "43/43 [==============================] - 0s 610us/step - loss: 0.0596 - accuracy: 0.9733 - val_loss: 0.5068 - val_accuracy: 0.9300\n",
      "Epoch 262/500\n",
      "43/43 [==============================] - 0s 658us/step - loss: 0.0552 - accuracy: 0.9833 - val_loss: 0.3971 - val_accuracy: 0.9400\n",
      "Epoch 263/500\n",
      "43/43 [==============================] - 0s 636us/step - loss: 0.0995 - accuracy: 0.9633 - val_loss: 0.4770 - val_accuracy: 0.9400\n",
      "Epoch 264/500\n",
      "43/43 [==============================] - 0s 634us/step - loss: 0.0521 - accuracy: 0.9867 - val_loss: 0.4645 - val_accuracy: 0.9300\n",
      "Epoch 265/500\n",
      "43/43 [==============================] - 0s 616us/step - loss: 0.0780 - accuracy: 0.9733 - val_loss: 0.4751 - val_accuracy: 0.9400\n",
      "Epoch 266/500\n",
      "43/43 [==============================] - 0s 649us/step - loss: 0.0669 - accuracy: 0.9700 - val_loss: 0.5148 - val_accuracy: 0.9500\n",
      "Epoch 267/500\n",
      "43/43 [==============================] - 0s 646us/step - loss: 0.0631 - accuracy: 0.9800 - val_loss: 0.5490 - val_accuracy: 0.9500\n",
      "Epoch 268/500\n",
      "43/43 [==============================] - 0s 672us/step - loss: 0.0611 - accuracy: 0.9733 - val_loss: 0.4256 - val_accuracy: 0.9300\n",
      "Epoch 269/500\n",
      "43/43 [==============================] - 0s 611us/step - loss: 0.0516 - accuracy: 0.9867 - val_loss: 0.4227 - val_accuracy: 0.9300\n",
      "Epoch 270/500\n",
      "43/43 [==============================] - 0s 637us/step - loss: 0.0661 - accuracy: 0.9700 - val_loss: 0.5199 - val_accuracy: 0.9400\n",
      "Epoch 271/500\n",
      "43/43 [==============================] - 0s 643us/step - loss: 0.0334 - accuracy: 0.9900 - val_loss: 0.4887 - val_accuracy: 0.9400\n",
      "Epoch 272/500\n",
      "43/43 [==============================] - 0s 603us/step - loss: 0.0367 - accuracy: 0.9833 - val_loss: 0.4626 - val_accuracy: 0.9300\n",
      "Epoch 273/500\n",
      "43/43 [==============================] - 0s 626us/step - loss: 0.0526 - accuracy: 0.9833 - val_loss: 0.5515 - val_accuracy: 0.9400\n",
      "Epoch 274/500\n",
      "43/43 [==============================] - 0s 640us/step - loss: 0.0601 - accuracy: 0.9767 - val_loss: 0.4896 - val_accuracy: 0.9400\n",
      "Epoch 275/500\n",
      "43/43 [==============================] - 0s 631us/step - loss: 0.0542 - accuracy: 0.9867 - val_loss: 0.5597 - val_accuracy: 0.9300\n",
      "Epoch 276/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - 0s 638us/step - loss: 0.0597 - accuracy: 0.9800 - val_loss: 0.5263 - val_accuracy: 0.9200\n",
      "Epoch 277/500\n",
      "43/43 [==============================] - 0s 621us/step - loss: 0.0735 - accuracy: 0.9633 - val_loss: 0.5892 - val_accuracy: 0.9400\n",
      "Epoch 278/500\n",
      "43/43 [==============================] - 0s 653us/step - loss: 0.0368 - accuracy: 0.9933 - val_loss: 0.5804 - val_accuracy: 0.9400\n",
      "Epoch 279/500\n",
      "43/43 [==============================] - 0s 612us/step - loss: 0.0511 - accuracy: 0.9767 - val_loss: 0.5683 - val_accuracy: 0.9400\n",
      "Epoch 280/500\n",
      "43/43 [==============================] - 0s 607us/step - loss: 0.0817 - accuracy: 0.9733 - val_loss: 0.4935 - val_accuracy: 0.9400\n",
      "Epoch 281/500\n",
      "43/43 [==============================] - 0s 665us/step - loss: 0.0717 - accuracy: 0.9767 - val_loss: 0.5020 - val_accuracy: 0.9300\n",
      "Epoch 282/500\n",
      "43/43 [==============================] - 0s 633us/step - loss: 0.0435 - accuracy: 0.9767 - val_loss: 0.5723 - val_accuracy: 0.9400\n",
      "Epoch 283/500\n",
      "43/43 [==============================] - 0s 611us/step - loss: 0.0316 - accuracy: 0.9900 - val_loss: 0.5784 - val_accuracy: 0.9400\n",
      "Epoch 284/500\n",
      "43/43 [==============================] - 0s 613us/step - loss: 0.0609 - accuracy: 0.9700 - val_loss: 0.5333 - val_accuracy: 0.9500\n",
      "Epoch 285/500\n",
      "43/43 [==============================] - 0s 645us/step - loss: 0.0975 - accuracy: 0.9667 - val_loss: 0.6130 - val_accuracy: 0.9300\n",
      "Epoch 286/500\n",
      "43/43 [==============================] - 0s 614us/step - loss: 0.0677 - accuracy: 0.9700 - val_loss: 0.5115 - val_accuracy: 0.9500\n",
      "Epoch 287/500\n",
      "43/43 [==============================] - 0s 608us/step - loss: 0.0403 - accuracy: 0.9833 - val_loss: 0.5566 - val_accuracy: 0.9400\n",
      "Epoch 288/500\n",
      "43/43 [==============================] - 0s 673us/step - loss: 0.0346 - accuracy: 0.9867 - val_loss: 0.5477 - val_accuracy: 0.9500\n",
      "Epoch 289/500\n",
      "43/43 [==============================] - 0s 646us/step - loss: 0.0504 - accuracy: 0.9833 - val_loss: 0.5043 - val_accuracy: 0.9400\n",
      "Epoch 290/500\n",
      "43/43 [==============================] - 0s 659us/step - loss: 0.0606 - accuracy: 0.9733 - val_loss: 0.6279 - val_accuracy: 0.9300\n",
      "Epoch 291/500\n",
      "43/43 [==============================] - 0s 659us/step - loss: 0.0675 - accuracy: 0.9700 - val_loss: 0.5871 - val_accuracy: 0.9400\n",
      "Epoch 292/500\n",
      "43/43 [==============================] - 0s 662us/step - loss: 0.0506 - accuracy: 0.9767 - val_loss: 0.5814 - val_accuracy: 0.9400\n",
      "Epoch 293/500\n",
      "43/43 [==============================] - 0s 732us/step - loss: 0.0423 - accuracy: 0.9833 - val_loss: 0.4410 - val_accuracy: 0.9500\n",
      "Epoch 294/500\n",
      "43/43 [==============================] - 0s 685us/step - loss: 0.0923 - accuracy: 0.9700 - val_loss: 0.6186 - val_accuracy: 0.9400\n",
      "Epoch 295/500\n",
      "43/43 [==============================] - 0s 666us/step - loss: 0.0430 - accuracy: 0.9767 - val_loss: 0.5474 - val_accuracy: 0.9500\n",
      "Epoch 296/500\n",
      "43/43 [==============================] - 0s 632us/step - loss: 0.0619 - accuracy: 0.9733 - val_loss: 0.5560 - val_accuracy: 0.9500\n",
      "Epoch 297/500\n",
      "43/43 [==============================] - 0s 633us/step - loss: 0.0220 - accuracy: 1.0000 - val_loss: 0.5422 - val_accuracy: 0.9500\n",
      "Epoch 298/500\n",
      "43/43 [==============================] - 0s 657us/step - loss: 0.0230 - accuracy: 0.9900 - val_loss: 0.5233 - val_accuracy: 0.9300\n",
      "Epoch 299/500\n",
      "43/43 [==============================] - 0s 638us/step - loss: 0.0248 - accuracy: 0.9900 - val_loss: 0.5340 - val_accuracy: 0.9300\n",
      "Epoch 300/500\n",
      "43/43 [==============================] - 0s 623us/step - loss: 0.0342 - accuracy: 0.9900 - val_loss: 0.6273 - val_accuracy: 0.9300\n",
      "Epoch 301/500\n",
      "43/43 [==============================] - 0s 636us/step - loss: 0.0431 - accuracy: 0.9800 - val_loss: 0.4392 - val_accuracy: 0.9400\n",
      "Epoch 302/500\n",
      "43/43 [==============================] - 0s 665us/step - loss: 0.0660 - accuracy: 0.9667 - val_loss: 0.5820 - val_accuracy: 0.9400\n",
      "Epoch 303/500\n",
      "43/43 [==============================] - 0s 654us/step - loss: 0.0508 - accuracy: 0.9733 - val_loss: 0.5291 - val_accuracy: 0.9500\n",
      "Epoch 304/500\n",
      "43/43 [==============================] - 0s 662us/step - loss: 0.0303 - accuracy: 0.9933 - val_loss: 0.6018 - val_accuracy: 0.9400\n",
      "Epoch 305/500\n",
      "43/43 [==============================] - 0s 613us/step - loss: 0.0911 - accuracy: 0.9667 - val_loss: 0.5799 - val_accuracy: 0.9000\n",
      "Epoch 306/500\n",
      "43/43 [==============================] - 0s 623us/step - loss: 0.0682 - accuracy: 0.9700 - val_loss: 0.5387 - val_accuracy: 0.9400\n",
      "Epoch 307/500\n",
      "43/43 [==============================] - 0s 653us/step - loss: 0.0615 - accuracy: 0.9767 - val_loss: 0.6016 - val_accuracy: 0.9400\n",
      "Epoch 308/500\n",
      "43/43 [==============================] - 0s 626us/step - loss: 0.0621 - accuracy: 0.9800 - val_loss: 0.5729 - val_accuracy: 0.9400\n",
      "Epoch 309/500\n",
      "43/43 [==============================] - 0s 627us/step - loss: 0.0430 - accuracy: 0.9833 - val_loss: 0.5257 - val_accuracy: 0.9400\n",
      "Epoch 310/500\n",
      "43/43 [==============================] - 0s 664us/step - loss: 0.0328 - accuracy: 0.9867 - val_loss: 0.5477 - val_accuracy: 0.9400\n",
      "Epoch 311/500\n",
      "43/43 [==============================] - 0s 715us/step - loss: 0.0228 - accuracy: 0.9900 - val_loss: 0.5254 - val_accuracy: 0.9300\n",
      "Epoch 312/500\n",
      "43/43 [==============================] - 0s 649us/step - loss: 0.0564 - accuracy: 0.9767 - val_loss: 0.4878 - val_accuracy: 0.9500\n",
      "Epoch 313/500\n",
      "43/43 [==============================] - 0s 638us/step - loss: 0.0356 - accuracy: 0.9900 - val_loss: 0.5075 - val_accuracy: 0.9400\n",
      "Epoch 314/500\n",
      "43/43 [==============================] - 0s 645us/step - loss: 0.0462 - accuracy: 0.9833 - val_loss: 0.6022 - val_accuracy: 0.9400\n",
      "Epoch 315/500\n",
      "43/43 [==============================] - 0s 659us/step - loss: 0.0485 - accuracy: 0.9767 - val_loss: 0.5993 - val_accuracy: 0.9200\n",
      "Epoch 316/500\n",
      "43/43 [==============================] - 0s 669us/step - loss: 0.0870 - accuracy: 0.9700 - val_loss: 0.6930 - val_accuracy: 0.9200\n",
      "Epoch 317/500\n",
      "43/43 [==============================] - 0s 661us/step - loss: 0.0654 - accuracy: 0.9700 - val_loss: 0.7285 - val_accuracy: 0.9300\n",
      "Epoch 318/500\n",
      "43/43 [==============================] - 0s 608us/step - loss: 0.0788 - accuracy: 0.9700 - val_loss: 0.5661 - val_accuracy: 0.9400\n",
      "Epoch 319/500\n",
      "43/43 [==============================] - 0s 660us/step - loss: 0.0413 - accuracy: 0.9867 - val_loss: 0.5713 - val_accuracy: 0.9500\n",
      "Epoch 320/500\n",
      "43/43 [==============================] - 0s 667us/step - loss: 0.0714 - accuracy: 0.9733 - val_loss: 0.5642 - val_accuracy: 0.9400\n",
      "Epoch 321/500\n",
      "43/43 [==============================] - 0s 660us/step - loss: 0.0816 - accuracy: 0.9733 - val_loss: 0.6031 - val_accuracy: 0.9500\n",
      "Epoch 322/500\n",
      "43/43 [==============================] - 0s 640us/step - loss: 0.0614 - accuracy: 0.9700 - val_loss: 0.5213 - val_accuracy: 0.9400\n",
      "Epoch 323/500\n",
      "43/43 [==============================] - 0s 633us/step - loss: 0.0549 - accuracy: 0.9800 - val_loss: 0.5475 - val_accuracy: 0.9400\n",
      "Epoch 324/500\n",
      "43/43 [==============================] - 0s 640us/step - loss: 0.0271 - accuracy: 0.9833 - val_loss: 0.5064 - val_accuracy: 0.9400\n",
      "Epoch 325/500\n",
      "43/43 [==============================] - 0s 676us/step - loss: 0.0381 - accuracy: 0.9833 - val_loss: 0.5204 - val_accuracy: 0.9400\n",
      "Epoch 326/500\n",
      "43/43 [==============================] - 0s 673us/step - loss: 0.0367 - accuracy: 0.9800 - val_loss: 0.5179 - val_accuracy: 0.9500\n",
      "Epoch 327/500\n",
      "43/43 [==============================] - 0s 646us/step - loss: 0.0434 - accuracy: 0.9767 - val_loss: 0.5612 - val_accuracy: 0.9400\n",
      "Epoch 328/500\n",
      "43/43 [==============================] - 0s 623us/step - loss: 0.0232 - accuracy: 0.9967 - val_loss: 0.5306 - val_accuracy: 0.9400\n",
      "Epoch 329/500\n",
      "43/43 [==============================] - 0s 661us/step - loss: 0.0228 - accuracy: 0.9933 - val_loss: 0.5284 - val_accuracy: 0.9400\n",
      "Epoch 330/500\n",
      "43/43 [==============================] - 0s 638us/step - loss: 0.0436 - accuracy: 0.9800 - val_loss: 0.4828 - val_accuracy: 0.9400\n",
      "Epoch 331/500\n",
      "43/43 [==============================] - 0s 632us/step - loss: 0.0636 - accuracy: 0.9767 - val_loss: 0.6174 - val_accuracy: 0.9300\n",
      "Epoch 332/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - 0s 639us/step - loss: 0.0294 - accuracy: 0.9800 - val_loss: 0.5109 - val_accuracy: 0.9400\n",
      "Epoch 333/500\n",
      "43/43 [==============================] - 0s 668us/step - loss: 0.0348 - accuracy: 0.9933 - val_loss: 0.5397 - val_accuracy: 0.9500\n",
      "Epoch 334/500\n",
      "43/43 [==============================] - 0s 656us/step - loss: 0.0528 - accuracy: 0.9800 - val_loss: 0.6627 - val_accuracy: 0.9300\n",
      "Epoch 335/500\n",
      "43/43 [==============================] - 0s 628us/step - loss: 0.0312 - accuracy: 0.9900 - val_loss: 0.5536 - val_accuracy: 0.9400\n",
      "Epoch 336/500\n",
      "43/43 [==============================] - 0s 742us/step - loss: 0.0383 - accuracy: 0.9833 - val_loss: 0.6166 - val_accuracy: 0.9500\n",
      "Epoch 337/500\n",
      "43/43 [==============================] - 0s 628us/step - loss: 0.0308 - accuracy: 0.9900 - val_loss: 0.6413 - val_accuracy: 0.9500\n",
      "Epoch 338/500\n",
      "43/43 [==============================] - 0s 622us/step - loss: 0.0308 - accuracy: 0.9867 - val_loss: 0.5849 - val_accuracy: 0.9500\n",
      "Epoch 339/500\n",
      "43/43 [==============================] - 0s 632us/step - loss: 0.0409 - accuracy: 0.9867 - val_loss: 0.5493 - val_accuracy: 0.9300\n",
      "Epoch 340/500\n",
      "43/43 [==============================] - 0s 690us/step - loss: 0.0244 - accuracy: 1.0000 - val_loss: 0.5515 - val_accuracy: 0.9400\n",
      "Epoch 341/500\n",
      "43/43 [==============================] - 0s 768us/step - loss: 0.0305 - accuracy: 0.9867 - val_loss: 0.5614 - val_accuracy: 0.9400\n",
      "Epoch 342/500\n",
      "43/43 [==============================] - 0s 659us/step - loss: 0.0631 - accuracy: 0.9733 - val_loss: 0.5199 - val_accuracy: 0.9400\n",
      "Epoch 343/500\n",
      "43/43 [==============================] - 0s 687us/step - loss: 0.0666 - accuracy: 0.9800 - val_loss: 0.5443 - val_accuracy: 0.9400\n",
      "Epoch 344/500\n",
      "43/43 [==============================] - 0s 721us/step - loss: 0.0394 - accuracy: 0.9867 - val_loss: 0.5582 - val_accuracy: 0.9500\n",
      "Epoch 345/500\n",
      "43/43 [==============================] - 0s 717us/step - loss: 0.0477 - accuracy: 0.9900 - val_loss: 0.5267 - val_accuracy: 0.9400\n",
      "Epoch 346/500\n",
      "43/43 [==============================] - 0s 726us/step - loss: 0.0229 - accuracy: 0.9967 - val_loss: 0.6218 - val_accuracy: 0.9400\n",
      "Epoch 347/500\n",
      "43/43 [==============================] - 0s 727us/step - loss: 0.0658 - accuracy: 0.9733 - val_loss: 0.5740 - val_accuracy: 0.9500\n",
      "Epoch 348/500\n",
      "43/43 [==============================] - 0s 750us/step - loss: 0.0179 - accuracy: 0.9967 - val_loss: 0.5763 - val_accuracy: 0.9400\n",
      "Epoch 349/500\n",
      "43/43 [==============================] - 0s 771us/step - loss: 0.0482 - accuracy: 0.9800 - val_loss: 0.5609 - val_accuracy: 0.9400\n",
      "Epoch 350/500\n",
      "43/43 [==============================] - 0s 811us/step - loss: 0.0579 - accuracy: 0.9833 - val_loss: 0.5946 - val_accuracy: 0.9400\n",
      "Epoch 351/500\n",
      "43/43 [==============================] - 0s 672us/step - loss: 0.0144 - accuracy: 0.9967 - val_loss: 0.5398 - val_accuracy: 0.9400\n",
      "Epoch 352/500\n",
      "43/43 [==============================] - 0s 638us/step - loss: 0.0187 - accuracy: 0.9933 - val_loss: 0.5617 - val_accuracy: 0.9400\n",
      "Epoch 353/500\n",
      "43/43 [==============================] - 0s 648us/step - loss: 0.0262 - accuracy: 0.9900 - val_loss: 0.8477 - val_accuracy: 0.9100\n",
      "Epoch 354/500\n",
      "43/43 [==============================] - 0s 669us/step - loss: 0.0552 - accuracy: 0.9633 - val_loss: 0.5052 - val_accuracy: 0.9400\n",
      "Epoch 355/500\n",
      "43/43 [==============================] - 0s 685us/step - loss: 0.0664 - accuracy: 0.9767 - val_loss: 0.4721 - val_accuracy: 0.9300\n",
      "Epoch 356/500\n",
      "43/43 [==============================] - 0s 662us/step - loss: 0.0297 - accuracy: 0.9867 - val_loss: 0.4722 - val_accuracy: 0.9500\n",
      "Epoch 357/500\n",
      "43/43 [==============================] - 0s 641us/step - loss: 0.0932 - accuracy: 0.9633 - val_loss: 0.5302 - val_accuracy: 0.9500\n",
      "Epoch 358/500\n",
      "43/43 [==============================] - 0s 626us/step - loss: 0.0696 - accuracy: 0.9767 - val_loss: 0.5501 - val_accuracy: 0.9300\n",
      "Epoch 359/500\n",
      "43/43 [==============================] - 0s 681us/step - loss: 0.0314 - accuracy: 0.9867 - val_loss: 0.5110 - val_accuracy: 0.9400\n",
      "Epoch 360/500\n",
      "43/43 [==============================] - 0s 691us/step - loss: 0.0367 - accuracy: 0.9833 - val_loss: 0.5712 - val_accuracy: 0.9500\n",
      "Epoch 361/500\n",
      "43/43 [==============================] - 0s 796us/step - loss: 0.0422 - accuracy: 0.9867 - val_loss: 0.4928 - val_accuracy: 0.9400\n",
      "Epoch 362/500\n",
      "43/43 [==============================] - 0s 684us/step - loss: 0.0431 - accuracy: 0.9833 - val_loss: 0.6351 - val_accuracy: 0.9400\n",
      "Epoch 363/500\n",
      "43/43 [==============================] - 0s 694us/step - loss: 0.0624 - accuracy: 0.9667 - val_loss: 0.6679 - val_accuracy: 0.9300\n",
      "Epoch 364/500\n",
      "43/43 [==============================] - 0s 710us/step - loss: 0.0990 - accuracy: 0.9700 - val_loss: 0.5274 - val_accuracy: 0.9500\n",
      "Epoch 365/500\n",
      "43/43 [==============================] - 0s 642us/step - loss: 0.0760 - accuracy: 0.9733 - val_loss: 0.5993 - val_accuracy: 0.9500\n",
      "Epoch 366/500\n",
      "43/43 [==============================] - 0s 633us/step - loss: 0.0639 - accuracy: 0.9867 - val_loss: 0.5736 - val_accuracy: 0.9300\n",
      "Epoch 367/500\n",
      "43/43 [==============================] - 0s 653us/step - loss: 0.1006 - accuracy: 0.9667 - val_loss: 0.4561 - val_accuracy: 0.9500\n",
      "Epoch 368/500\n",
      "43/43 [==============================] - 0s 668us/step - loss: 0.0798 - accuracy: 0.9600 - val_loss: 0.5629 - val_accuracy: 0.9400\n",
      "Epoch 369/500\n",
      "43/43 [==============================] - 0s 645us/step - loss: 0.0402 - accuracy: 0.9833 - val_loss: 0.5707 - val_accuracy: 0.9500\n",
      "Epoch 370/500\n",
      "43/43 [==============================] - 0s 620us/step - loss: 0.0715 - accuracy: 0.9833 - val_loss: 0.6230 - val_accuracy: 0.9500\n",
      "Epoch 371/500\n",
      "43/43 [==============================] - 0s 666us/step - loss: 0.0421 - accuracy: 0.9833 - val_loss: 0.5401 - val_accuracy: 0.9500\n",
      "Epoch 372/500\n",
      "43/43 [==============================] - 0s 692us/step - loss: 0.0491 - accuracy: 0.9767 - val_loss: 0.5138 - val_accuracy: 0.9300\n",
      "Epoch 373/500\n",
      "43/43 [==============================] - 0s 673us/step - loss: 0.0419 - accuracy: 0.9867 - val_loss: 0.6285 - val_accuracy: 0.9300\n",
      "Epoch 374/500\n",
      "43/43 [==============================] - 0s 636us/step - loss: 0.0215 - accuracy: 0.9900 - val_loss: 0.5414 - val_accuracy: 0.9600\n",
      "Epoch 375/500\n",
      "43/43 [==============================] - 0s 630us/step - loss: 0.0403 - accuracy: 0.9867 - val_loss: 0.5908 - val_accuracy: 0.9500\n",
      "Epoch 376/500\n",
      "43/43 [==============================] - 0s 639us/step - loss: 0.0432 - accuracy: 0.9800 - val_loss: 0.5739 - val_accuracy: 0.9500\n",
      "Epoch 377/500\n",
      "43/43 [==============================] - 0s 659us/step - loss: 0.0354 - accuracy: 0.9833 - val_loss: 0.5720 - val_accuracy: 0.9300\n",
      "Epoch 378/500\n",
      "43/43 [==============================] - 0s 650us/step - loss: 0.0524 - accuracy: 0.9833 - val_loss: 0.5824 - val_accuracy: 0.9500\n",
      "Epoch 379/500\n",
      "43/43 [==============================] - 0s 620us/step - loss: 0.0521 - accuracy: 0.9800 - val_loss: 0.6196 - val_accuracy: 0.9500\n",
      "Epoch 380/500\n",
      "43/43 [==============================] - 0s 656us/step - loss: 0.0461 - accuracy: 0.9767 - val_loss: 0.5619 - val_accuracy: 0.9400\n",
      "Epoch 381/500\n",
      "43/43 [==============================] - 0s 691us/step - loss: 0.0324 - accuracy: 0.9867 - val_loss: 0.5029 - val_accuracy: 0.9400\n",
      "Epoch 382/500\n",
      "43/43 [==============================] - 0s 645us/step - loss: 0.0716 - accuracy: 0.9767 - val_loss: 0.6132 - val_accuracy: 0.9400\n",
      "Epoch 383/500\n",
      "43/43 [==============================] - 0s 635us/step - loss: 0.0347 - accuracy: 0.9833 - val_loss: 0.6081 - val_accuracy: 0.9400\n",
      "Epoch 384/500\n",
      "43/43 [==============================] - 0s 639us/step - loss: 0.0399 - accuracy: 0.9900 - val_loss: 0.6343 - val_accuracy: 0.9300\n",
      "Epoch 385/500\n",
      "43/43 [==============================] - 0s 652us/step - loss: 0.0628 - accuracy: 0.9767 - val_loss: 0.5352 - val_accuracy: 0.9400\n",
      "Epoch 386/500\n",
      "43/43 [==============================] - 0s 672us/step - loss: 0.0495 - accuracy: 0.9700 - val_loss: 0.6293 - val_accuracy: 0.9300\n",
      "Epoch 387/500\n",
      "43/43 [==============================] - 0s 645us/step - loss: 0.0317 - accuracy: 0.9900 - val_loss: 0.6926 - val_accuracy: 0.9400\n",
      "Epoch 388/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - 0s 615us/step - loss: 0.0367 - accuracy: 0.9867 - val_loss: 0.6475 - val_accuracy: 0.9500\n",
      "Epoch 389/500\n",
      "43/43 [==============================] - 0s 644us/step - loss: 0.0425 - accuracy: 0.9900 - val_loss: 0.7385 - val_accuracy: 0.9300\n",
      "Epoch 390/500\n",
      "43/43 [==============================] - 0s 676us/step - loss: 0.0834 - accuracy: 0.9767 - val_loss: 0.7239 - val_accuracy: 0.9300\n",
      "Epoch 391/500\n",
      "43/43 [==============================] - 0s 616us/step - loss: 0.0406 - accuracy: 0.9867 - val_loss: 0.6350 - val_accuracy: 0.9500\n",
      "Epoch 392/500\n",
      "43/43 [==============================] - 0s 629us/step - loss: 0.0458 - accuracy: 0.9800 - val_loss: 0.5183 - val_accuracy: 0.9300\n",
      "Epoch 393/500\n",
      "43/43 [==============================] - 0s 630us/step - loss: 0.0629 - accuracy: 0.9800 - val_loss: 0.5384 - val_accuracy: 0.9400\n",
      "Epoch 394/500\n",
      "43/43 [==============================] - 0s 666us/step - loss: 0.0558 - accuracy: 0.9800 - val_loss: 0.5782 - val_accuracy: 0.9400\n",
      "Epoch 395/500\n",
      "43/43 [==============================] - 0s 625us/step - loss: 0.0451 - accuracy: 0.9833 - val_loss: 0.5736 - val_accuracy: 0.9500\n",
      "Epoch 396/500\n",
      "43/43 [==============================] - 0s 613us/step - loss: 0.0373 - accuracy: 0.9867 - val_loss: 0.5635 - val_accuracy: 0.9500\n",
      "Epoch 397/500\n",
      "43/43 [==============================] - 0s 614us/step - loss: 0.0331 - accuracy: 0.9800 - val_loss: 0.5605 - val_accuracy: 0.9500\n",
      "Epoch 398/500\n",
      "43/43 [==============================] - 0s 688us/step - loss: 0.0376 - accuracy: 0.9867 - val_loss: 0.4498 - val_accuracy: 0.9500\n",
      "Epoch 399/500\n",
      "43/43 [==============================] - 0s 692us/step - loss: 0.0348 - accuracy: 0.9767 - val_loss: 0.5455 - val_accuracy: 0.9500\n",
      "Epoch 400/500\n",
      "43/43 [==============================] - 0s 678us/step - loss: 0.0219 - accuracy: 0.9933 - val_loss: 0.5958 - val_accuracy: 0.9500\n",
      "Epoch 401/500\n",
      "43/43 [==============================] - 0s 666us/step - loss: 0.0168 - accuracy: 0.9967 - val_loss: 0.5917 - val_accuracy: 0.9400\n",
      "Epoch 402/500\n",
      "43/43 [==============================] - 0s 654us/step - loss: 0.0712 - accuracy: 0.9800 - val_loss: 0.8063 - val_accuracy: 0.9100\n",
      "Epoch 403/500\n",
      "43/43 [==============================] - 0s 665us/step - loss: 0.0856 - accuracy: 0.9633 - val_loss: 0.5555 - val_accuracy: 0.9300\n",
      "Epoch 404/500\n",
      "43/43 [==============================] - 0s 672us/step - loss: 0.0641 - accuracy: 0.9767 - val_loss: 0.5759 - val_accuracy: 0.9400\n",
      "Epoch 405/500\n",
      "43/43 [==============================] - 0s 677us/step - loss: 0.0340 - accuracy: 0.9933 - val_loss: 0.5677 - val_accuracy: 0.9400\n",
      "Epoch 406/500\n",
      "43/43 [==============================] - 0s 672us/step - loss: 0.0574 - accuracy: 0.9800 - val_loss: 0.6104 - val_accuracy: 0.9500\n",
      "Epoch 407/500\n",
      "43/43 [==============================] - 0s 636us/step - loss: 0.0262 - accuracy: 0.9900 - val_loss: 0.5835 - val_accuracy: 0.9500\n",
      "Epoch 408/500\n",
      "43/43 [==============================] - 0s 646us/step - loss: 0.0209 - accuracy: 0.9967 - val_loss: 0.6076 - val_accuracy: 0.9500\n",
      "Epoch 409/500\n",
      "43/43 [==============================] - 0s 647us/step - loss: 0.0493 - accuracy: 0.9800 - val_loss: 0.6562 - val_accuracy: 0.9500\n",
      "Epoch 410/500\n",
      "43/43 [==============================] - 0s 624us/step - loss: 0.0246 - accuracy: 0.9933 - val_loss: 0.6077 - val_accuracy: 0.9500\n",
      "Epoch 411/500\n",
      "43/43 [==============================] - 0s 614us/step - loss: 0.0429 - accuracy: 0.9900 - val_loss: 0.6112 - val_accuracy: 0.9500\n",
      "Epoch 412/500\n",
      "43/43 [==============================] - 0s 686us/step - loss: 0.0256 - accuracy: 0.9933 - val_loss: 0.6835 - val_accuracy: 0.9500\n",
      "Epoch 413/500\n",
      "43/43 [==============================] - 0s 663us/step - loss: 0.0902 - accuracy: 0.9867 - val_loss: 0.5958 - val_accuracy: 0.9500\n",
      "Epoch 414/500\n",
      "43/43 [==============================] - 0s 643us/step - loss: 0.0345 - accuracy: 0.9900 - val_loss: 0.6168 - val_accuracy: 0.9500\n",
      "Epoch 415/500\n",
      "43/43 [==============================] - 0s 710us/step - loss: 0.0326 - accuracy: 0.9833 - val_loss: 0.5746 - val_accuracy: 0.9500\n",
      "Epoch 416/500\n",
      "43/43 [==============================] - 0s 638us/step - loss: 0.0274 - accuracy: 0.9900 - val_loss: 0.6908 - val_accuracy: 0.9400\n",
      "Epoch 417/500\n",
      "43/43 [==============================] - 0s 628us/step - loss: 0.0500 - accuracy: 0.9833 - val_loss: 0.6990 - val_accuracy: 0.9500\n",
      "Epoch 418/500\n",
      "43/43 [==============================] - 0s 658us/step - loss: 0.0382 - accuracy: 0.9867 - val_loss: 0.6458 - val_accuracy: 0.9300\n",
      "Epoch 419/500\n",
      "43/43 [==============================] - 0s 689us/step - loss: 0.0292 - accuracy: 0.9867 - val_loss: 0.6446 - val_accuracy: 0.9500\n",
      "Epoch 420/500\n",
      "43/43 [==============================] - 0s 638us/step - loss: 0.0209 - accuracy: 0.9933 - val_loss: 0.6790 - val_accuracy: 0.9500\n",
      "Epoch 421/500\n",
      "43/43 [==============================] - 0s 632us/step - loss: 0.0788 - accuracy: 0.9633 - val_loss: 0.5789 - val_accuracy: 0.9300\n",
      "Epoch 422/500\n",
      "43/43 [==============================] - 0s 666us/step - loss: 0.0271 - accuracy: 0.9900 - val_loss: 0.6545 - val_accuracy: 0.9400\n",
      "Epoch 423/500\n",
      "43/43 [==============================] - 0s 659us/step - loss: 0.0271 - accuracy: 0.9900 - val_loss: 0.6784 - val_accuracy: 0.9500\n",
      "Epoch 424/500\n",
      "43/43 [==============================] - 0s 669us/step - loss: 0.0240 - accuracy: 0.9867 - val_loss: 0.7420 - val_accuracy: 0.9400\n",
      "Epoch 425/500\n",
      "43/43 [==============================] - 0s 646us/step - loss: 0.0815 - accuracy: 0.9767 - val_loss: 0.7256 - val_accuracy: 0.9400\n",
      "Epoch 426/500\n",
      "43/43 [==============================] - 0s 642us/step - loss: 0.0583 - accuracy: 0.9833 - val_loss: 0.6096 - val_accuracy: 0.9400\n",
      "Epoch 427/500\n",
      "43/43 [==============================] - 0s 655us/step - loss: 0.0353 - accuracy: 0.9800 - val_loss: 0.5752 - val_accuracy: 0.9400\n",
      "Epoch 428/500\n",
      "43/43 [==============================] - 0s 670us/step - loss: 0.0477 - accuracy: 0.9733 - val_loss: 0.4814 - val_accuracy: 0.9400\n",
      "Epoch 429/500\n",
      "43/43 [==============================] - 0s 650us/step - loss: 0.0491 - accuracy: 0.9833 - val_loss: 0.6057 - val_accuracy: 0.9500\n",
      "Epoch 430/500\n",
      "43/43 [==============================] - 0s 614us/step - loss: 0.0406 - accuracy: 0.9867 - val_loss: 0.5736 - val_accuracy: 0.9400\n",
      "Epoch 431/500\n",
      "43/43 [==============================] - 0s 632us/step - loss: 0.0464 - accuracy: 0.9833 - val_loss: 0.6008 - val_accuracy: 0.9400\n",
      "Epoch 432/500\n",
      "43/43 [==============================] - 0s 688us/step - loss: 0.0634 - accuracy: 0.9700 - val_loss: 0.6155 - val_accuracy: 0.9500\n",
      "Epoch 433/500\n",
      "43/43 [==============================] - 0s 659us/step - loss: 0.0850 - accuracy: 0.9667 - val_loss: 0.6211 - val_accuracy: 0.9500\n",
      "Epoch 434/500\n",
      "43/43 [==============================] - 0s 643us/step - loss: 0.0305 - accuracy: 0.9867 - val_loss: 0.6217 - val_accuracy: 0.9400\n",
      "Epoch 435/500\n",
      "43/43 [==============================] - 0s 614us/step - loss: 0.0546 - accuracy: 0.9800 - val_loss: 0.5204 - val_accuracy: 0.9400\n",
      "Epoch 436/500\n",
      "43/43 [==============================] - 0s 643us/step - loss: 0.0448 - accuracy: 0.9900 - val_loss: 0.4700 - val_accuracy: 0.9500\n",
      "Epoch 437/500\n",
      "43/43 [==============================] - 0s 625us/step - loss: 0.0484 - accuracy: 0.9833 - val_loss: 0.5312 - val_accuracy: 0.9500\n",
      "Epoch 438/500\n",
      "43/43 [==============================] - 0s 610us/step - loss: 0.0245 - accuracy: 0.9900 - val_loss: 0.5778 - val_accuracy: 0.9500\n",
      "Epoch 439/500\n",
      "43/43 [==============================] - 0s 641us/step - loss: 0.0565 - accuracy: 0.9800 - val_loss: 0.6019 - val_accuracy: 0.9500\n",
      "Epoch 440/500\n",
      "43/43 [==============================] - 0s 619us/step - loss: 0.0230 - accuracy: 0.9933 - val_loss: 0.5975 - val_accuracy: 0.9500\n",
      "Epoch 441/500\n",
      "43/43 [==============================] - 0s 631us/step - loss: 0.0408 - accuracy: 0.9867 - val_loss: 0.5527 - val_accuracy: 0.9500\n",
      "Epoch 442/500\n",
      "43/43 [==============================] - 0s 606us/step - loss: 0.0204 - accuracy: 0.9933 - val_loss: 0.5768 - val_accuracy: 0.9500\n",
      "Epoch 443/500\n",
      "43/43 [==============================] - 0s 644us/step - loss: 0.0388 - accuracy: 0.9867 - val_loss: 0.5137 - val_accuracy: 0.9400\n",
      "Epoch 444/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - 0s 623us/step - loss: 0.0378 - accuracy: 0.9867 - val_loss: 0.5598 - val_accuracy: 0.9500\n",
      "Epoch 445/500\n",
      "43/43 [==============================] - 0s 623us/step - loss: 0.0416 - accuracy: 0.9867 - val_loss: 0.5595 - val_accuracy: 0.9300\n",
      "Epoch 446/500\n",
      "43/43 [==============================] - 0s 635us/step - loss: 0.0547 - accuracy: 0.9800 - val_loss: 0.5516 - val_accuracy: 0.9500\n",
      "Epoch 447/500\n",
      "43/43 [==============================] - 0s 642us/step - loss: 0.0529 - accuracy: 0.9767 - val_loss: 0.6285 - val_accuracy: 0.9400\n",
      "Epoch 448/500\n",
      "43/43 [==============================] - 0s 618us/step - loss: 0.0494 - accuracy: 0.9833 - val_loss: 0.6016 - val_accuracy: 0.9500\n",
      "Epoch 449/500\n",
      "43/43 [==============================] - 0s 631us/step - loss: 0.0675 - accuracy: 0.9733 - val_loss: 0.6964 - val_accuracy: 0.9500\n",
      "Epoch 450/500\n",
      "43/43 [==============================] - 0s 646us/step - loss: 0.0307 - accuracy: 0.9867 - val_loss: 0.7046 - val_accuracy: 0.9500\n",
      "Epoch 451/500\n",
      "43/43 [==============================] - 0s 628us/step - loss: 0.0463 - accuracy: 0.9800 - val_loss: 0.6746 - val_accuracy: 0.9500\n",
      "Epoch 452/500\n",
      "43/43 [==============================] - 0s 630us/step - loss: 0.0212 - accuracy: 0.9933 - val_loss: 0.6994 - val_accuracy: 0.9500\n",
      "Epoch 453/500\n",
      "43/43 [==============================] - 0s 604us/step - loss: 0.0426 - accuracy: 0.9833 - val_loss: 0.6167 - val_accuracy: 0.9500\n",
      "Epoch 454/500\n",
      "43/43 [==============================] - 0s 634us/step - loss: 0.0667 - accuracy: 0.9800 - val_loss: 0.6637 - val_accuracy: 0.9500\n",
      "Epoch 455/500\n",
      "43/43 [==============================] - 0s 614us/step - loss: 0.0552 - accuracy: 0.9767 - val_loss: 0.6760 - val_accuracy: 0.9300\n",
      "Epoch 456/500\n",
      "43/43 [==============================] - 0s 604us/step - loss: 0.0246 - accuracy: 0.9967 - val_loss: 0.6281 - val_accuracy: 0.9500\n",
      "Epoch 457/500\n",
      "43/43 [==============================] - 0s 649us/step - loss: 0.0321 - accuracy: 0.9833 - val_loss: 0.6450 - val_accuracy: 0.9400\n",
      "Epoch 458/500\n",
      "43/43 [==============================] - 0s 662us/step - loss: 0.0493 - accuracy: 0.9767 - val_loss: 0.5394 - val_accuracy: 0.9300\n",
      "Epoch 459/500\n",
      "43/43 [==============================] - 0s 661us/step - loss: 0.0521 - accuracy: 0.9767 - val_loss: 0.6890 - val_accuracy: 0.9400\n",
      "Epoch 460/500\n",
      "43/43 [==============================] - 0s 614us/step - loss: 0.0726 - accuracy: 0.9667 - val_loss: 0.6804 - val_accuracy: 0.9400\n",
      "Epoch 461/500\n",
      "43/43 [==============================] - 0s 646us/step - loss: 0.0296 - accuracy: 0.9933 - val_loss: 0.6281 - val_accuracy: 0.9500\n",
      "Epoch 462/500\n",
      "43/43 [==============================] - 0s 638us/step - loss: 0.0480 - accuracy: 0.9833 - val_loss: 0.6539 - val_accuracy: 0.9300\n",
      "Epoch 463/500\n",
      "43/43 [==============================] - 0s 593us/step - loss: 0.0463 - accuracy: 0.9833 - val_loss: 0.6336 - val_accuracy: 0.9200\n",
      "Epoch 464/500\n",
      "43/43 [==============================] - 0s 629us/step - loss: 0.1057 - accuracy: 0.9633 - val_loss: 0.7643 - val_accuracy: 0.9000\n",
      "Epoch 465/500\n",
      "43/43 [==============================] - 0s 643us/step - loss: 0.0587 - accuracy: 0.9700 - val_loss: 0.5669 - val_accuracy: 0.9500\n",
      "Epoch 466/500\n",
      "43/43 [==============================] - 0s 631us/step - loss: 0.0596 - accuracy: 0.9767 - val_loss: 0.6558 - val_accuracy: 0.9400\n",
      "Epoch 467/500\n",
      "43/43 [==============================] - 0s 666us/step - loss: 0.0407 - accuracy: 0.9833 - val_loss: 0.5973 - val_accuracy: 0.9500\n",
      "Epoch 468/500\n",
      "43/43 [==============================] - 0s 615us/step - loss: 0.0321 - accuracy: 0.9900 - val_loss: 0.6083 - val_accuracy: 0.9500\n",
      "Epoch 469/500\n",
      "43/43 [==============================] - 0s 643us/step - loss: 0.0575 - accuracy: 0.9733 - val_loss: 0.6588 - val_accuracy: 0.9400\n",
      "Epoch 470/500\n",
      "43/43 [==============================] - 0s 613us/step - loss: 0.0683 - accuracy: 0.9700 - val_loss: 0.5829 - val_accuracy: 0.9500\n",
      "Epoch 471/500\n",
      "43/43 [==============================] - 0s 636us/step - loss: 0.0674 - accuracy: 0.9733 - val_loss: 0.6459 - val_accuracy: 0.9500\n",
      "Epoch 472/500\n",
      "43/43 [==============================] - 0s 633us/step - loss: 0.0537 - accuracy: 0.9800 - val_loss: 0.4793 - val_accuracy: 0.9300\n",
      "Epoch 473/500\n",
      "43/43 [==============================] - 0s 634us/step - loss: 0.0652 - accuracy: 0.9733 - val_loss: 0.6547 - val_accuracy: 0.9500\n",
      "Epoch 474/500\n",
      "43/43 [==============================] - 0s 625us/step - loss: 0.0244 - accuracy: 0.9900 - val_loss: 0.5423 - val_accuracy: 0.9400\n",
      "Epoch 475/500\n",
      "43/43 [==============================] - 0s 615us/step - loss: 0.0144 - accuracy: 0.9967 - val_loss: 0.5533 - val_accuracy: 0.9500\n",
      "Epoch 476/500\n",
      "43/43 [==============================] - 0s 660us/step - loss: 0.0345 - accuracy: 0.9900 - val_loss: 0.5840 - val_accuracy: 0.9400\n",
      "Epoch 477/500\n",
      "43/43 [==============================] - 0s 652us/step - loss: 0.0338 - accuracy: 0.9867 - val_loss: 0.5487 - val_accuracy: 0.9400\n",
      "Epoch 478/500\n",
      "43/43 [==============================] - 0s 607us/step - loss: 0.0574 - accuracy: 0.9833 - val_loss: 0.5675 - val_accuracy: 0.9400\n",
      "Epoch 479/500\n",
      "43/43 [==============================] - 0s 609us/step - loss: 0.0560 - accuracy: 0.9767 - val_loss: 0.6165 - val_accuracy: 0.9500\n",
      "Epoch 480/500\n",
      "43/43 [==============================] - 0s 647us/step - loss: 0.0316 - accuracy: 0.9867 - val_loss: 0.5954 - val_accuracy: 0.9500\n",
      "Epoch 481/500\n",
      "43/43 [==============================] - 0s 623us/step - loss: 0.0464 - accuracy: 0.9900 - val_loss: 0.5412 - val_accuracy: 0.9400\n",
      "Epoch 482/500\n",
      "43/43 [==============================] - 0s 609us/step - loss: 0.0288 - accuracy: 0.9867 - val_loss: 0.5359 - val_accuracy: 0.9500\n",
      "Epoch 483/500\n",
      "43/43 [==============================] - 0s 651us/step - loss: 0.0467 - accuracy: 0.9800 - val_loss: 0.6051 - val_accuracy: 0.9500\n",
      "Epoch 484/500\n",
      "43/43 [==============================] - 0s 636us/step - loss: 0.0235 - accuracy: 0.9933 - val_loss: 0.7067 - val_accuracy: 0.9500\n",
      "Epoch 485/500\n",
      "43/43 [==============================] - 0s 635us/step - loss: 0.0599 - accuracy: 0.9767 - val_loss: 0.5195 - val_accuracy: 0.9300\n",
      "Epoch 486/500\n",
      "43/43 [==============================] - 0s 635us/step - loss: 0.0339 - accuracy: 0.9833 - val_loss: 0.6371 - val_accuracy: 0.9500\n",
      "Epoch 487/500\n",
      "43/43 [==============================] - 0s 633us/step - loss: 0.0444 - accuracy: 0.9800 - val_loss: 0.6436 - val_accuracy: 0.9500\n",
      "Epoch 488/500\n",
      "43/43 [==============================] - 0s 640us/step - loss: 0.0461 - accuracy: 0.9867 - val_loss: 0.6351 - val_accuracy: 0.9500\n",
      "Epoch 489/500\n",
      "43/43 [==============================] - 0s 608us/step - loss: 0.0528 - accuracy: 0.9867 - val_loss: 0.6669 - val_accuracy: 0.9500\n",
      "Epoch 490/500\n",
      "43/43 [==============================] - 0s 615us/step - loss: 0.0517 - accuracy: 0.9800 - val_loss: 0.7154 - val_accuracy: 0.9300\n",
      "Epoch 491/500\n",
      "43/43 [==============================] - 0s 652us/step - loss: 0.0221 - accuracy: 0.9900 - val_loss: 0.5849 - val_accuracy: 0.9400\n",
      "Epoch 492/500\n",
      "43/43 [==============================] - 0s 625us/step - loss: 0.0281 - accuracy: 0.9933 - val_loss: 0.6092 - val_accuracy: 0.9400\n",
      "Epoch 493/500\n",
      "43/43 [==============================] - 0s 618us/step - loss: 0.0329 - accuracy: 0.9933 - val_loss: 0.6326 - val_accuracy: 0.9500\n",
      "Epoch 494/500\n",
      "43/43 [==============================] - 0s 651us/step - loss: 0.0407 - accuracy: 0.9867 - val_loss: 0.6282 - val_accuracy: 0.9400\n",
      "Epoch 495/500\n",
      "43/43 [==============================] - 0s 680us/step - loss: 0.0589 - accuracy: 0.9767 - val_loss: 0.6688 - val_accuracy: 0.9300\n",
      "Epoch 496/500\n",
      "43/43 [==============================] - 0s 633us/step - loss: 0.0846 - accuracy: 0.9700 - val_loss: 0.4929 - val_accuracy: 0.9400\n",
      "Epoch 497/500\n",
      "43/43 [==============================] - 0s 627us/step - loss: 0.0289 - accuracy: 0.9900 - val_loss: 0.6260 - val_accuracy: 0.9500\n",
      "Epoch 498/500\n",
      "43/43 [==============================] - 0s 645us/step - loss: 0.0229 - accuracy: 0.9933 - val_loss: 0.5499 - val_accuracy: 0.9500\n",
      "Epoch 499/500\n",
      "43/43 [==============================] - 0s 658us/step - loss: 0.0367 - accuracy: 0.9833 - val_loss: 0.6266 - val_accuracy: 0.9500\n",
      "Epoch 500/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1/43 [..............................] - ETA: 0s - loss: 0.0011 - accuracy: 1.0000\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "43/43 [==============================] - 0s 641us/step - loss: 0.0279 - accuracy: 0.9867 - val_loss: 0.5546 - val_accuracy: 0.9500\n"
     ]
    }
   ],
   "source": [
    "model = getNetwork()\n",
    "history = model.fit(X_train, y_train, epochs=EPOCHS, batch_size=BATCH_SIZE, validation_split=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f517810bea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.98        20\n",
      "           1       0.85      0.85      0.85        20\n",
      "           2       0.90      0.95      0.93        20\n",
      "           3       1.00      0.95      0.97        20\n",
      "           4       1.00      0.95      0.97        20\n",
      "\n",
      "    accuracy                           0.94       100\n",
      "   macro avg       0.94      0.94      0.94       100\n",
      "weighted avg       0.94      0.94      0.94       100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred_test = model.predict(X_test)\n",
    "predictions_categorical = np.argmax(pred_test, axis=1)\n",
    "report = classification_report(y_test, predictions_categorical)\n",
    "print(report)\n",
    "classification_report_csv(report, \"NN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export Models in C code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/sakka/anaconda3/envs/ts/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From /home/sakka/anaconda3/envs/ts/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "INFO:tensorflow:Assets written to: /tmp/tmplcchr3r_/assets\n"
     ]
    }
   ],
   "source": [
    "# Neural network with TinyMLGen\n",
    "with open(tasks[taskIndex] + '/exportedModels/NNmodel.h', 'w') as f:\n",
    "    f.write(tiny.port(model, optimize=False))\n",
    "\n",
    "# Classifiers with MicroMLGen\n",
    "for name, model in models:\n",
    "    prepath = tasks[taskIndex] + '/exportedModels/'\n",
    "    path = prepath + name + '.h'\n",
    "    x = port(model, optimize=True)\n",
    "    with open(path, 'w') as f:\n",
    "        f.write(port(model, optimize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inferance Rate medio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "csv = read_csv(\"InfTimeReport.csv\")\n",
    "g = sbs.barplot(x=csv['Algoritmo'], y=csv['inf5'])\n",
    "g.set_yscale(\"log\")\n",
    "plt.ylabel(\"Inference Time in millisecondi\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Memoria Occupata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZcAAAEGCAYAAACpXNjrAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAb60lEQVR4nO3dfbhVdZ338fcnzKd8QiE0RY9jjHOjFimjODpp6Rja7YBmjWRKjkbXCKWTzZXmNJDlld7d6p2lNszICI6J3pnJFEr4rDUqh0QQzOH4lDA+HEUBIyXxO3+s38nFYZ99Frj22mcfPq/r2tdZ67uevus6cL57/dZv/ZYiAjMzszK9p9kJmJlZ/+PiYmZmpXNxMTOz0rm4mJlZ6VxczMysdFs0O4G+YtCgQdHW1tbsNMzMWsr8+fNfjojB3eMuLklbWxvt7e3NTsPMrKVIerZW3M1iZmZWOhcXMzMrnYuLmZmVzsXFzMxK5+JiZmalc3ExM7PSubiYmVnpXFzMzKx0Li5mZlY6P6FvZtYEF33upGansFEu+Pcfb9T6DbtykTRU0t2SlkhaLOnsFJ8iabmkBelzXG6b8yV1SHpC0idy8dEp1iHpvFx8b0kPpfiNkrZM8a3SfEda3tao8zQzsw01slnsLeDciBgOjAImShqell0eESPSZzZAWnYysB8wGrhK0gBJA4ArgWOB4cC43H4uSfv6IPAqcEaKnwG8muKXp/XMzKwiDSsuEfF8RPw6Ta8GHgd2r7PJGGBmRLwZEU8DHcDB6dMREU9FxFpgJjBGkoCPA13XatOBsbl9TU/TPwaOSuubmVkFKrmhn5qlPgI8lEKTJC2UNE3SwBTbHXgut9myFOspvgvwWkS81S2+3r7S8pVp/e55TZDULqm9s7Pz3Z2kmZn9UcOLi6TtgJuBcyJiFXA1sA8wAngeuLTROfQkIqZGxMiIGDl48AavIzAzs03U0OIi6b1kheX6iPgJQES8GBHrIuJt4F/Imr0AlgNDc5vvkWI9xV8BdpK0Rbf4evtKy3dM65uZWQUa2VtMwDXA4xFxWS6+W261E4DH0vQs4OTU02tvYBjwMDAPGJZ6hm1JdtN/VkQEcDfQ1Z9vPHBrbl/j0/RJwF1pfTMzq0Ajn3M5DDgVWCRpQYp9nay31wgggGeALwJExGJJNwFLyHqaTYyIdQCSJgFzgAHAtIhYnPb3NWCmpG8Dj5AVM9LP6yR1ACvICpKZmVWkYcUlIh4AavXQml1nm4uAi2rEZ9faLiKe4p1mtXz8DeDTG5OvmZmVx8O/mJlZ6VxczMysdC4uZmZWOhcXMzMrnYuLmZmVzsXFzMxK5+JiZmalc3ExM7PSubiYmVnpXFzMzKx0Li5mZlY6FxczMyudi4uZmZXOxcXMzErn4mJmZqVzcTEzs9K5uJiZWelcXMzMrHQuLmZmVrotmp2AmW2aez96RLNT2GhH3Hdvs1OwivjKxczMSufiYmZmpXNxMTOz0vmeSy8O+ocZzU5ho8z/7mnNTsHMzFcuZmZWPhcXMzMrnYuLmZmVzsXFzMxK5+JiZmalc3ExM7PSubiYmVnpXFzMzKx0DSsukoZKulvSEkmLJZ2d4jtLmitpafo5MMUl6QpJHZIWSjowt6/xaf2lksbn4gdJWpS2uUKS6h3DzMyq0cgrl7eAcyNiODAKmChpOHAecGdEDAPuTPMAxwLD0mcCcDVkhQKYDBwCHAxMzhWLq4Ev5LYbneI9HcPMzCrQsOISEc9HxK/T9GrgcWB3YAwwPa02HRibpscAMyLzILCTpN2ATwBzI2JFRLwKzAVGp2U7RMSDERHAjG77qnUMMzOrQK/FJTVXfU7SP6X5PSUdvDEHkdQGfAR4CBgSEc+nRS8AQ9L07sBzuc2WpVi9+LIaceoco3teEyS1S2rv7OzcmFMyM7M6ily5XAUcCoxL86uBK4seQNJ2wM3AORGxKr8sXXFE0X1tinrHiIipETEyIkYOHjy4kWmYmW1WihSXQyJiIvAGQGqa2rLIziW9l6ywXB8RP0nhF1OTFunnSym+HBia23yPFKsX36NGvN4xzMysAkWKyx8kDSB9+5c0GHi7t41Sz61rgMcj4rLcollAV4+v8cCtufhpqRluFLAyNW3NAY6RNDDdyD8GmJOWrZI0Kh3rtG77qnUMMzOrQJH3uVwB3AK8X9JFwEnANwpsdxhwKrBI0oIU+zpwMXCTpDOAZ4HPpGWzgeOADmANcDpARKyQ9C1gXlrvwohYkabPAq4FtgFuSx/qHMPMzCrQa3GJiOslzQeOAgSMjYjHC2z3QFq/lqNqrB/AxB72NQ2YViPeDuxfI/5KrWOYmVk1ei0ukq6LiFOB39SImZmZbaDIPZf98jPp/stBjUnHzMz6gx6Li6TzJa0GPiRpVfqsJut55RvkZmbWox6LS0R8JyK2B74bETukz/YRsUtEnF9hjmZm1mKKNIvtK+k4SR5B2czMCin6hP4pwFJJF0vat8E5mZlZi+u1uETEHRFxCnAg8Axwh6RfSTo9PYFvZma2nkJNXZJ2AT4PnAk8AnyPrNjMbVhmZmbWsoo853ILsC9wHXB8brThGyW1NzI5MzNrTYWGf4mIu2stiIiRJedjZmb9QN3iImkvYFGaHgUcDjwZEbdUkJuZmbWoHouLpG+Q3WcJSTOBo4F7gE9KOiIizqkiQTMzaz31rlzGAf8L2Bb4LbBrRKyRtAWwoILczMysRdUrLm9ExFpgraQnI2INQES8JWltNemZmVkrqldcdpJ0Itmw+TukadL8jg3PzMzMWla94nIvcHyavi833TVvZmZWU4/FJSJOrzIRMzPrPzwYpZmZlc7FxczMSufiYmZmpSsy/AuS/gJoy68fETMalJOZmbW4IgNXXgfsQ/bg5LoUDsDFxczMaipy5TISGB4R0ehkzMysfyhyz+UxYNdGJ2JmZv1HkSuXQcASSQ8Db3YFI+KvG5aVmZm1tCLFZUqjkzAzs/6l1+ISEfdWkYiZmfUf9d7n8kBEHC5pNVnvsD8uAiIidmh4dmZm1pLqjS12ePq5fXXpmJlZf+An9M3MrHQuLmZmVrqGFRdJ0yS9JOmxXGyKpOWSFqTPcbll50vqkPSEpE/k4qNTrEPSebn43pIeSvEbJW2Z4lul+Y60vK1R52hmZrU18srlWmB0jfjlETEifWYDSBoOnAzsl7a5StIASQOAK4FjgeHAuLQuwCVpXx8EXgXOSPEzgFdT/PK0npmZVajX4iJplKR5kl6XtFbSOkmretsuIu4DVhTMYwwwMyLejIingQ7g4PTpiIinImItMBMYI0nAx4Efp+2nA2Nz+5qepn8MHJXWNzOzihS5cvkBMA5YCmwDnEl2NbGpJklamJrNBqbY7sBzuXWWpVhP8V2A1yLirW7x9faVlq9M629A0gRJ7ZLaOzs738UpmZlZXqFmsYjoAAZExLqI+DdqN3cVcTXZCMsjgOeBSzdxP6WIiKkRMTIiRg4ePLiZqZiZ9StFhn9Zk26WL5D0f8iKwibdq4mIF7umJf0L8LM0uxwYmlt1jxSjh/grwE6StkhXJ/n1u/a1TNIWwI5pfTMzq0iRInFqWm8S8DuyP9wnbsrBJO2Wmz2BbMRlgFnAyamn197AMOBhYB4wLPUM25Lspv+sNPz/3cBJafvxwK25fY1P0ycBd/l1AWZm1Spy5TI2Ir4HvAF8E0DS2cD36m0k6QbgSGCQpGXAZOBISSPIhpN5BvgiQEQslnQTsAR4C5gYEevSfiYBc4ABwLSIWJwO8TVgpqRvA48A16T4NcB1kjrIOhScXOAczcysREWKy3g2LCSfrxFbT0SMqxG+pkasa/2LgItqxGcDs2vEnyLrTdY9/gbw6Xq5mZlZY9UbuHIc8Flgb0mzcou2p3gXYzMz2wzVu3L5FdnN+0Gs36trNbCwkUmZmVlrqzcq8rPAs8Ch1aVjZmb9QcOe0Dczs81XM57QNzOzfq7qJ/TNzGwzUOkT+mZmtnnY1Cf0P9XIpMzMrLX1euUSEc+mK5c24CfAE2n4ezMzs5p6LS6SPgn8EHgSENlDlV+MiNsanZyZmbWmIvdcLgU+lm7qI2kf4OeAi4uZmdVU5J7L6q7CkjxF9pS+mZlZTUWuXNolzQZuIhvN+NPAPEknAkTETxqYn5mZtaAixWVr4EXgiDTfSfYw5fFkxcbFxczM1lOkt9jpVSRiZmb9R5HeYv9GdoWynoj424ZkZGZmLa9Is9jPctNbk72e+L8bk46ZmfUHRZrFbs7Pp9cXP9CwjMzMrOVtyhhhw4D3l52ImZn1H0Xuuaxm/XsuLwBfa1hGZmbW8oo0i21fRSJmZtZ/FHkT5QmSdszN7yRpbEOzMjOzllbknsvkiFjZNRMRrwGTG5aRmZm1vCLFpdY6Rbowm5nZZqpIcWmXdJmkfdLnMmB+oxMzM7PWVaS4fAlYC9wIzATeACY2MikzM2ttRXqL/Q44r4JczMysnyjSW2yupJ1y8wMlzWloVmZm1tKKNIsNSj3EAIiIV/ET+mZmVkeR4vK2pD27ZiTtRY1Rks3MzLoU6VJ8AfCApHsBAX8JTGhoVmZm1tKK3NC/XdKBwKgUOiciXm5sWmbv3mHfP6zZKWy0X37pl81Ooc/4wbn/0ewUNsqkS49vdgp9St1mMUlbSjqdrLfYkcBgYHWRHUuaJuklSY/lYjunDgJL08+BKS5JV0jqkLQwFbOubcan9ZdKGp+LHyRpUdrmCkmqdwwzM6tOj8VF0nBgCVlR+W36HAksTst6cy0wulvsPODOiBgG3Mk7XZyPJRvKfxhZk9vVKYedyYaaOQQ4GJicKxZXA1/IbTe6l2OYmVlF6jWLfR/4u4iYmw9KOhq4EvhYvR1HxH2S2rqFx5AVKIDpwD1kw/ePAWZERAAPpsExd0vrzo2IFenYc4HRku4BdoiIB1N8BjAWuK3OMayb3154QLNT2Gh7/tOiZqdgZgXUaxbbvXthAYiIO4BdN/F4QyLi+TT9AjCk61jAc7n1lqVYvfiyGvF6x9iApAmS2iW1d3Z2bsLpmJlZLfWKy3skbdU9KGlrShi4Ml2lNLRLc2/HiIipETEyIkYOHjy4kamYmW1W6hWXGcDN6bkWAFIz103AdZt4vBdTcxfp50spvhwYmltvjxSrF9+jRrzeMczMrCI9FpeI+DZwO3C/pJclvQLcS3YP5MJNPN4soKvH13jg1lz8tNRrbBSwMjVtzQGOSUPODASOAeakZaskjUq9xE7rtq9axzAzs4rUbd6KiB8AP5C0fZov1A0ZQNINZDfWB0laRtbr62LgJklnAM8Cn0mrzwaOAzqANcDp6XgrJH0LmJfWu7Dr5j5wFlmPtG3IbuTfluI9HcPMzCrS672TNGjlaUCbpD+uHxFfrrddRIzrYdFRNdYNehjGPyKmAdNqxNuB/WvEX6l1DDMzq06RG/OzgQeBRcDbjU3HzMz6gyLFZeuI+ErDMzEzs36jyKjI10n6gqTd0tAqO6cn583MzGoqcuWyFvgu2ejIXc+MBPAnjUrKzMxaW5Hici7wQY+EbGZmRRVpFuvqHmxmZlZIkSuX3wELJN0NvNkV7K0rspmZbb6KFJefpo+ZmVkhRd5EOV3SNsCeEfFEBTmZmVmL6/Wei6TjgQVk44whaYSkWQ3Oy8zMWliRG/pTyN4C+RpARCzA3ZDNzKyOIsXlDxGxslvMw8CYmVmPitzQXyzps8AAScOALwO/amxaZmbWyopcuXwJ2I+sG/INwCrgnAbmZGZmLa5Ib7E1ZEO/XND4dMzMrD/osbj01iMsIv66/HTMzKw/qHflcijwHFlT2EOAKsnIzMxaXr3isivwV8A44LPAz4EbImJxFYmZmVnr6vGGfkSsi4jbI2I8MIpsAMt7JE2qLDszM2tJdW/oS9oK+CTZ1UsbcAVwS+PTMjOzVlbvhv4MYH9gNvDNiHissqzMzKyl1bty+RzZcPtnA1+W/ng/X0BExA4Nzs3MzFpUj8UlIoo8YGlmZrYBFxAzMyudi4uZmZXOxcXMzErn4mJmZqVzcTEzs9K5uJiZWelcXMzMrHQuLmZmVrqmFBdJz0haJGmBpPYU21nSXElL08+BKS5JV0jqkLRQ0oG5/YxP6y+VND4XPyjtvyNt69cFmJlVqJlXLh+LiBERMTLNnwfcGRHDgDvTPMCxwLD0mQBcDVkxAiYDhwAHA5O7ClJa5wu57UY3/nTMzKxLX2oWGwNMT9PTgbG5+IzIPAjsJGk34BPA3IhYERGvAnOB0WnZDhHxYEQEMCO3LzMzq0CziksAv5A0X9KEFBsSEc+n6ReAIWl6d7I3YnZZlmL14stqxDcgaYKkdkntnZ2d7+Z8zMwsp+77XBro8IhYLun9wFxJv8kvjIiQFI1OIiKmAlMBRo4c2fDjmZltLppy5RIRy9PPl8hePnYw8GJq0iL9fCmtvhwYmtt8jxSrF9+jRtzMzCpSeXGR9D5J23dNA8cAjwGzgK4eX+OBW9P0LOC01GtsFLAyNZ/NAY6RNDDdyD8GmJOWrZI0KvUSOy23LzMzq0AzmsWGALek3sFbAD+KiNslzQNuknQG8CzwmbT+bOA4oANYA5wOEBErJH0LmJfWuzAiVqTps4BrgW2A29LHzMwqUnlxiYingA/XiL8CHFUjHsDEHvY1DZhWI95O9opmMzNrgr7UFdnMzPoJFxczMyudi4uZmZXOxcXMzErn4mJmZqVzcTEzs9K5uJiZWelcXMzMrHQuLmZmVjoXFzMzK52Li5mZlc7FxczMSufiYmZmpXNxMTOz0rm4mJlZ6VxczMysdC4uZmZWOhcXMzMrnYuLmZmVzsXFzMxK5+JiZmalc3ExM7PSubiYmVnpXFzMzKx0Li5mZlY6FxczMyudi4uZmZXOxcXMzErn4mJmZqVzcTEzs9K5uJiZWelcXMzMrHT9trhIGi3pCUkdks5rdj5mZpuTfllcJA0ArgSOBYYD4yQNb25WZmabj35ZXICDgY6IeCoi1gIzgTFNzsnMbLOhiGh2DqWTdBIwOiLOTPOnAodExKRu600AJqTZfYEnKkxzEPByhcerWn8+v/58buDza3VVn99eETG4e3CLChPocyJiKjC1GceW1B4RI5tx7Cr05/Prz+cGPr9W11fOr782iy0Hhubm90gxMzOrQH8tLvOAYZL2lrQlcDIwq8k5mZltNvpls1hEvCVpEjAHGABMi4jFTU6ru6Y0x1WoP59ffz438Pm1uj5xfv3yhr6ZmTVXf20WMzOzJnJxMTOz0rm4VEDSOkkLJD0m6T8k7ZTibZJ+n5Z1fbZscro1SdpV0kxJT0qaL2m2pD9Ny86R9IakHXPrHylpZTqn30j6v5IOyJ3nCklPp+k7mndm9Ul6vUZsiqTlKfclksY1I7dNJekCSYslLUznMFnSd7qtM0LS42l6O0n/nPvd3yPpkOZk3zNJQyT9SNJTKc//lHRC+rcYko7PrfszSUem6XvSUFELJD2enn/r09L5XJqb/6qkKWl6iqQ1kt6fW77Bv+NGc3Gpxu8jYkRE7A+sACbmlj2ZlnV91jYpxx5JEnALcE9E7BMRBwHnA0PSKuPIeuid2G3T+yNiBPAR4H8DO3SdJ1nvvX9I80dXcBpluzydxxjgnyW9t8n5FCLpULLfxYER8SHgaOBu4G+6rXoycEOa/leyf7fD0u/+dLIH9fqM9G/0p8B9EfEnKc+TyR5DAFgGXFBnF6ek3+dhwCV99UtezpvAiZJ6+j28DJxbYT4bcHGp3n8Cuzc7iY30MeAPEfHDrkBEPBoR90vaB9gO+EeyIrOBiPg9sIDWO+9eRcRSYA0wsNm5FLQb8HJEvAkQES9HxH3Aq92uRj4D3JB+v4cA/xgRb6dtno6In1edeC8+Dqzt9m/02Yj4fpp9FFgp6a962c92wO+AdY1JszRvkfUK+/selk8D/kbSztWltD4XlwqlATWPYv1nbvbJNRVd2aTUerM/ML+HZSeTjd12P7CvpCHdV5A0EBgG3NewDJtE0oHA0oh4qdm5FPQLYKik/5J0laQjUvwGst8lkkYBK1Lh3A9YEBF9/Y/tfsCve1nnIrIvQbVcL2kh2RBQ32qB84VscN5T8s3ROa+TFZizq03pHS4u1dhG0gLgBbKmpLm5ZflmsYk1t+7bxgEz07fam4FP55b9paRHyUZHmBMRLzQjwQb5e0mLgYfI/mi1hIh4HTiIbEy9TuBGSZ8HbgROkvQe1m8Sa0mSrpT0qKR5XbF0hYakw2tsckpqJtwT+KqkvSpKdZNFxCpgBvDlHla5AhgvafvqsnqHi0s1fp/ac/cCxPr3XFrBYrI/SOuRdADZFclcSc+Q/VHKN43dHxEfJvtWeYakEY1PtTKXR8R+wKeAayRt3eyEioqIdRFxT0RMBiYBn4qI54CngSPIzunGtPpi4MPpqrsvWwwc2DWTvqgdBXQfULHe1QsR0Ul2BdTnOiz04P8BZwDv674gIl4DfkST/t64uFQoItaQfcs4V1IrjY5wF7BVvheNpA+RfTOaEhFt6fMB4APdv/VFxNPAxcDXqky6ChExC2gHxjc7lyIk7StpWC40Ang2Td8AXA48FRHLACLiSbLz+2a6ad7Vy/GT1WVdyF3A1pL+LhfbtvtKEfELsvtjH6q1E0nbknVAebIRSZYtIlYAN5EVmFouA75IE0ZjcXGpWEQ8Aiykh5vffVFkwzicAByduqMuBr4DHEnWiyzvFlLbfTc/BD4qqa2BqTbCtpKW5T5fqbHOhcBXUpNSX7cdMD11oV5I9jK9KWnZ/ye7yuzeJHYmWXNuh6THgGuBPnWPKf0bHQsckbq4PwxMp/YXmotYf2BbyO65LCC7t3htRPR0j7EvupQeeu9FxMtk/ye3qjQjPPyLmZk1QCt80zIzsxbj4mJmZqVzcTEzs9K5uJiZWelcXMzMrHQuLmYlkTQ2jVb7Z2m+LXXdLWv//yppeJr+eln7NWsEFxez8owDHqABzzBJGhARZ0bEkhRycbE+zcXFrASStgMOJ3tSeoOHSCVtK+mm9PDiLZIekjQyLRsnaZGy9/1cktvmdUmXpvHZDk3vHRkp6WLSeHWSrk9XSL+RdG0akPJ6SUdL+qWkpZIOTvvbWdJPlb3H5cE0yoJZQ7i4mJVjDHB7RPwX8Iqk7mOxnQW8GhHDgW+QxmqT9AHgErIh40cAfy5pbNrmfcBDEfHhiHiga0cRcR7vvCPolBT+INmT2n+WPp8lK3Zf5Z2rnG8Cj6QBGr9ONuihWUO4uJiVYxzZqwdIP7s3jR3etTwiHiMbAgjgz8lewtYZEW8B1wMfTcvWkY00XcTTEbEojU69GLgzDYmyCGjL5XBdyuEuYBdJOxQ+Q7ON0EqDJ5r1SemFTB8HDpAUwAAgyN638W68sRHvFXkzN/12bv5t/P/cmsBXLmbv3knAdRGxVxodeijZ8PX5wRF/SfZ2R1KPrwNS/GGywRYHpWHtxwH3FjjmHzbh1cr3A6ekHI4keyPlqo3ch1khLi5m7944Nhwd+mbg/Nz8VcBgSUuAb5M1Xa2MiOeB88jeY/8oMD8ibi1wzKnAQknXb0SeU4CD0mjIF9Mirwmw1uRRkc0qkK5K3hsRb6T30t8B7BsRa5ucmllDuC3WrBrbAnenpiwBZ7mwWH/mKxczMyud77mYmVnpXFzMzKx0Li5mZlY6FxczMyudi4uZmZXufwD3bbV0csTBBAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "csv = read_csv(\"MemOccupationReport.csv\")\n",
    "sbs.barplot(x=csv['Algoritmo'], y=csv['Mem5'])\n",
    "plt.ylabel(\"MemOccupata in Byte\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

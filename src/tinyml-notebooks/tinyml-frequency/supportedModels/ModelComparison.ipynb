{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models Comparison for TinyML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "import numpy as np\n",
    "from numpy import arange\n",
    "import pickle\n",
    "\n",
    "#\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#\n",
    "import pandas as pd\n",
    "from pandas import read_csv\n",
    "\n",
    "from sklearn.metrics import confusion_matrix,  classification_report, f1_score\n",
    "from sklearn.model_selection import train_test_split, KFold,StratifiedKFold, cross_val_score, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from keras.models import Sequential, Model \n",
    "from keras.layers import Dense, Input, concatenate, Activation, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import tensorflow\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from micromlgen import port\n",
    "import tinymlgen as tiny\n",
    "\n",
    "import warnings\n",
    "import sys\n",
    "import seaborn as sbs\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "tensorflow.random.set_seed(RANDOM_SEED)\n",
    "np.set_printoptions(threshold=sys.maxsize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change 'chosenIndex' to change the chosen Test (s/s3/s6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataXPath = ['../data/X.pkl', '../data/XS3.pkl', '../data/XS6.pkl']\n",
    "dataYPath = ['../data/y.pkl', '../data/yS3.pkl', '../data/yS6.pkl']\n",
    "choosenIndex = 1\n",
    "\n",
    "with open(dataXPath[choosenIndex], 'rb') as f:\n",
    "    X = pickle.load(f)\n",
    "\n",
    "with open(dataYPath[choosenIndex], 'rb') as f:\n",
    "    y = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2000 2200 2400 2600 2800 3000]\n",
      "['2000', '2200', '2400', '2600', '2800', '3000']\n"
     ]
    }
   ],
   "source": [
    "print(np.unique(y))\n",
    "labels = [str(el) for el in list(np.unique(y))]\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
      " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
      " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4\n",
      " 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n",
      " 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n",
      " 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5\n",
      " 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5\n",
      " 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5\n",
      " 5 5 5 5 5 5 5 5]\n"
     ]
    }
   ],
   "source": [
    "# Convert the labels in values like 0...n for the NN tests\n",
    "\n",
    "labels = []\n",
    "uniques = list(np.unique(y))\n",
    "\n",
    "[labels.append(uniques.index(el)) for el in y]\n",
    "\n",
    "y = np.array(labels)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4222.48 4241.73 4213.88 4238.89 4219.92 4236.06 4219.77 4250.12 4222.62\n",
      "  4242.72 4232.34 4247.06 4223.43 4259.11 4228.34 4237.99 4238.51 4241.86\n",
      "  4222.75 4250.35 4231.15 4238.69 4240.34 4250.1  4237.81 4264.28 4240.01\n",
      "  4252.29 4245.64 4255.56 4227.65 4258.17]\n",
      " [5285.42 5275.73 5272.9  5272.49 5269.17 5265.02 5265.12 5264.83 5265.61\n",
      "  5284.38 5268.85 5262.72 5256.22 5273.67 5264.37 5257.94 5265.68 5261.77\n",
      "  5262.4  5270.34 5270.68 5263.   5266.57 5265.01 5252.83 5257.91 5274.09\n",
      "  5259.18 5270.39 5264.49 5256.22 5263.44]\n",
      " [3525.27 3498.38 3523.3  3506.97 3516.33 3503.27 3519.36 3510.73 3511.36\n",
      "  3508.88 3509.36 3493.99 3527.7  3502.72 3513.33 3513.13 3511.27 3513.54\n",
      "  3519.03 3506.67 3508.41 3509.28 3512.73 3498.74 3515.28 3507.89 3510.81\n",
      "  3501.01 3514.17 3498.34 3512.63 3507.36]\n",
      " [4903.88 4923.48 4937.63 4902.6  4916.25 4919.49 4913.59 4914.64 4918.55\n",
      "  4904.83 4906.45 4913.39 4899.71 4903.37 4913.03 4907.08 4895.24 4911.73\n",
      "  4896.33 4896.33 4907.86 4902.48 4895.   4907.6  4900.49 4896.49 4908.78\n",
      "  4910.77 4890.43 4907.51 4903.97 4895.71]\n",
      " [3303.68 3310.17 3310.28 3301.02 3315.07 3311.85 3307.93 3311.25 3326.73\n",
      "  3312.69 3319.16 3320.53 3309.19 3308.51 3325.86 3308.72 3322.22 3327.87\n",
      "  3317.07 3306.53 3325.56 3321.1  3319.51 3326.97 3328.2  3330.24 3330.08\n",
      "  3320.12 3322.2  3318.79 3324.37 3328.44]\n",
      " [4891.45 4918.65 4906.43 4923.82 4892.1  4942.66 4891.02 4912.84 4904.58\n",
      "  4919.92 4886.78 4920.15 4891.74 4899.09 4897.08 4920.65 4893.4  4916.6\n",
      "  4900.84 4909.56 4896.12 4926.23 4890.93 4917.97 4910.71 4921.37 4890.05\n",
      "  4925.81 4889.76 4911.18 4900.84 4917.81]\n",
      " [4285.36 4270.92 4281.68 4288.23 4281.75 4275.15 4292.69 4275.46 4281.2\n",
      "  4288.46 4282.53 4278.77 4285.87 4280.38 4277.01 4286.29 4275.82 4275.86\n",
      "  4281.16 4286.46 4273.12 4283.71 4285.84 4273.23 4278.85 4283.3  4273.49\n",
      "  4283.7  4284.74 4275.73 4275.81 4281.48]\n",
      " [5435.4  5438.37 5409.93 5430.47 5425.53 5422.12 5437.21 5438.07 5422.12\n",
      "  5431.9  5439.23 5428.37 5444.85 5459.24 5450.55 5479.66 5524.44 5537.02\n",
      "  5562.33 5610.96 5631.19 5646.87 5694.24 5703.27 5706.77 5734.06 5739.2\n",
      "  5757.95 5773.43 5774.14 5765.5  5792.62]\n",
      " [4864.5  4853.11 4875.55 4849.75 4872.49 4871.65 4867.13 4856.23 4884.71\n",
      "  4854.97 4874.72 4873.71 4881.16 4864.61 4881.91 4868.98 4871.18 4871.86\n",
      "  4877.2  4858.07 4883.71 4871.31 4872.31 4866.53 4880.92 4858.47 4877.36\n",
      "  4879.4  4870.98 4876.92 4885.49 4874.09]\n",
      " [4642.99 4690.88 4726.46 4728.45 4745.58 4784.89 4870.06 4942.17 4981.11\n",
      "  5032.07 5065.86 5057.06 5093.56 5104.52 5088.74 5068.96 5069.02 5025.39\n",
      "  4993.56 4929.02 4878.43 4788.36 4764.3  4634.29 4577.71 4518.35 4526.14\n",
      "  4539.94 4612.74 4667.48 4684.11 4685.66]\n",
      " [5056.58 5049.88 5052.44 5053.41 5053.56 5062.73 5070.57 5053.18 5051.63\n",
      "  5050.71 5050.86 5054.37 5063.   5054.92 5062.96 5061.79 5058.56 5054.25\n",
      "  5051.11 5055.4  5044.81 5061.99 5058.34 5055.76 5062.95 5057.35 5055.37\n",
      "  5067.8  5058.56 5048.28 5048.15 5054.13]\n",
      " [3460.55 3402.48 3419.44 3414.36 3432.75 3396.18 3435.3  3402.53 3414.7\n",
      "  3402.88 3421.66 3404.98 3438.13 3417.81 3408.11 3388.25 3437.44 3394.42\n",
      "  3412.27 3394.28 3431.64 3408.52 3405.34 3414.73 3399.17 3394.74 3411.81\n",
      "  3397.07 3449.97 3416.14 3443.13 3415.76]\n",
      " [4268.64 4265.56 4272.02 4265.16 4259.95 4274.35 4266.7  4263.6  4272.7\n",
      "  4273.71 4258.63 4280.07 4273.4  4263.98 4276.01 4305.24 4265.18 4273.15\n",
      "  4275.98 4277.87 4270.35 4275.91 4270.48 4268.44 4279.17 4286.69 4283.28\n",
      "  4274.37 4275.47 4272.82 4273.17 4268.03]\n",
      " [5128.22 5143.69 5140.29 5142.76 5132.79 5139.35 5148.   5131.37 5129.81\n",
      "  5133.77 5130.36 5138.93 5127.57 5130.27 5136.39 5132.32 5143.97 5129.24\n",
      "  5129.71 5124.27 5130.38 5134.49 5122.66 5134.49 5135.34 5119.86 5126.16\n",
      "  5123.72 5116.72 5119.32 5125.35 5116.37]\n",
      " [5040.49 5045.96 5041.51 5038.33 5048.6  5048.7  5040.41 5042.02 5050.52\n",
      "  5042.66 5043.47 5050.19 5041.57 5044.43 5044.25 5041.49 5050.82 5054.41\n",
      "  5046.53 5041.33 5051.77 5045.46 5048.48 5058.36 5052.07 5050.51 5048.95\n",
      "  5049.41 5047.04 5048.04 5058.45 5050.77]\n",
      " [5056.57 5051.67 5040.78 5057.55 5058.84 5049.01 5051.58 5051.64 5048.4\n",
      "  5045.4  5053.68 5052.53 5045.63 5062.16 5052.76 5060.16 5064.71 5058.56\n",
      "  5062.03 5062.02 5063.84 5053.03 5063.94 5068.94 5065.45 5071.56 5078.56\n",
      "  5060.79 5064.6  5063.24 5061.5  5068.01]\n",
      " [4842.89 4864.61 4829.56 4850.78 4848.52 4848.49 4811.83 4848.24 4821.37\n",
      "  4847.02 4847.79 4879.42 4863.11 4905.89 4877.78 4900.4  4884.26 4921.51\n",
      "  4891.5  4931.95 4916.41 4932.72 4897.19 4881.88 4817.22 4821.55 4784.83\n",
      "  4826.62 4825.34 4894.   4883.36 4911.05]\n",
      " [3303.59 3285.86 3302.59 3325.64 3293.87 3291.52 3304.21 3302.7  3293.49\n",
      "  3288.85 3299.57 3286.99 3298.39 3296.55 3286.57 3297.27 3296.94 3286.59\n",
      "  3300.63 3291.18 3290.45 3282.8  3300.58 3280.82 3293.21 3294.12 3288.26\n",
      "  3291.95 3307.6  3286.84 3295.1  3288.66]\n",
      " [2574.09 2533.29 2420.61 2368.92 2289.64 2286.81 2280.04 2286.47 2299.32\n",
      "  2317.59 2333.07 2338.92 2343.94 2359.82 2386.46 2408.65 2421.22 2450.29\n",
      "  2448.22 2455.52 2410.83 2409.89 2377.86 2402.3  2374.03 2380.39 2351.69\n",
      "  2351.81 2318.29 2312.78 2303.7  2284.74]\n",
      " [4816.95 4849.47 4825.91 4871.79 4873.69 4908.61 4912.25 4939.21 4914.82\n",
      "  4958.75 4931.53 4949.57 4940.78 4972.17 4946.82 4963.9  4954.48 4950.29\n",
      "  4934.36 4955.15 4942.05 4954.07 4943.49 4985.83 4966.31 5015.73 5002.16\n",
      "  5008.4  4993.4  5034.58 4992.37 5021.02]\n",
      " [5288.63 5267.06 5279.85 5276.35 5270.69 5275.4  5273.45 5275.84 5274.57\n",
      "  5273.59 5266.87 5266.33 5280.13 5266.83 5269.55 5267.33 5268.06 5263.86\n",
      "  5273.33 5273.2  5268.4  5276.75 5278.94 5271.7  5277.89 5276.15 5256.58\n",
      "  5255.68 5238.11 5228.89 5229.15 5214.09]\n",
      " [4256.77 4277.91 4268.7  4276.32 4258.11 4290.02 4255.18 4271.25 4265.12\n",
      "  4274.23 4250.49 4278.17 4257.35 4268.9  4258.95 4279.06 4252.58 4276.53\n",
      "  4260.77 4268.83 4255.82 4276.12 4256.18 4267.78 4259.77 4267.07 4252.33\n",
      "  4272.39 4251.21 4263.82 4256.11 4265.77]\n",
      " [5697.4  5689.89 5673.03 5693.91 5675.22 5656.85 5674.08 5675.83 5641.7\n",
      "  5659.37 5677.73 5647.45 5669.75 5662.2  5633.1  5643.8  5654.55 5639.9\n",
      "  5637.9  5646.3  5626.33 5616.92 5638.17 5613.96 5601.28 5620.46 5604.99\n",
      "  5590.43 5609.45 5606.54 5590.67 5599.51]\n",
      " [4820.95 4846.59 4823.85 4828.95 4829.46 4865.67 4833.22 4836.79 4824.75\n",
      "  4829.84 4811.38 4844.14 4818.35 4826.16 4817.9  4821.58 4794.78 4844.86\n",
      "  4802.98 4813.09 4795.76 4804.03 4771.69 4819.59 4804.73 4821.09 4792.81\n",
      "  4801.99 4774.03 4828.24 4790.19 4790.21]\n",
      " [3881.19 3865.44 3854.3  3882.01 3873.39 3881.68 3865.73 3864.32 3868.49\n",
      "  3863.43 3842.99 3858.23 3860.78 3846.88 3834.7  3863.54 3816.17 3827.79\n",
      "  3826.45 3832.62 3807.56 3847.35 3814.91 3826.27 3811.18 3819.19 3792.48\n",
      "  3817.85 3793.06 3795.19 3787.37 3783.58]\n",
      " [5680.96 5661.46 5676.04 5674.86 5658.15 5656.77 5668.65 5664.19 5653.\n",
      "  5682.08 5656.91 5654.22 5668.59 5646.53 5641.05 5657.17 5641.4  5644.91\n",
      "  5660.84 5650.45 5629.22 5648.49 5640.85 5630.97 5646.97 5647.59 5622.02\n",
      "  5629.61 5639.37 5618.25 5629.73 5639.49]\n",
      " [5708.56 5715.65 5691.21 5706.83 5712.7  5691.29 5696.36 5711.04 5692.45\n",
      "  5698.85 5710.64 5695.95 5688.57 5715.42 5696.87 5692.34 5708.63 5697.18\n",
      "  5685.66 5695.26 5697.39 5672.92 5685.89 5700.99 5672.85 5687.37 5694.42\n",
      "  5678.5  5677.67 5694.74 5667.72 5681.69]\n",
      " [1873.76 1841.32 1818.62 1805.36 1800.9  1773.02 1772.14 1755.01 1723.84\n",
      "  1700.34 1672.84 1638.87 1629.97 1625.07 1614.55 1640.52 1659.92 1679.87\n",
      "  1730.6  1757.57 1787.98 1806.77 1864.31 1895.57 1910.28 1931.31 1975.04\n",
      "  1976.95 1995.11 2043.34 2010.19 1966.98]\n",
      " [4242.85 4243.28 4257.71 4252.49 4253.84 4254.7  4250.72 4251.43 4273.82\n",
      "  4250.42 4250.14 4253.92 4259.31 4243.71 4261.59 4259.32 4249.46 4260.57\n",
      "  4260.4  4250.47 4262.26 4257.14 4256.82 4254.92 4266.34 4251.58 4263.74\n",
      "  4261.53 4270.88 4252.24 4271.54 4255.43]\n",
      " [3502.46 3524.59 3496.79 3513.72 3508.97 3526.32 3503.69 3519.54 3495.73\n",
      "  3511.96 3506.67 3515.61 3496.35 3517.9  3499.39 3517.81 3505.43 3523.44\n",
      "  3494.85 3528.61 3505.86 3514.41 3513.24 3527.77 3507.51 3519.04 3518.47\n",
      "  3520.67 3504.39 3526.38 3503.37 3523.94]\n",
      " [4793.53 4780.94 4782.58 4772.73 4798.61 4768.26 4792.8  4782.02 4779.78\n",
      "  4763.78 4792.28 4772.37 4778.39 4777.06 4784.69 4761.68 4789.98 4777.98\n",
      "  4776.28 4769.56 4784.07 4757.1  4783.85 4776.58 4771.52 4765.09 4781.33\n",
      "  4756.93 4767.34 4769.01 4768.39 4760.32]\n",
      " [3085.43 3102.79 3107.52 3108.37 3084.92 3122.81 3126.85 3107.32 3121.26\n",
      "  3155.05 3101.05 3124.76 3136.75 3132.93 3104.15 3152.88 3120.94 3127.49\n",
      "  3107.35 3132.51 3098.52 3123.47 3137.59 3131.82 3114.21 3114.08 3109.5\n",
      "  3123.8  3123.84 3123.43 3147.74 3176.69]\n",
      " [4817.65 4844.41 4835.84 4826.35 4847.31 4843.55 4823.14 4846.4  4881.08\n",
      "  4834.39 4831.12 4839.15 4822.67 4846.01 4839.54 4825.23 4822.67 4847.52\n",
      "  4818.67 4822.45 4843.62 4825.78 4814.88 4846.89 4839.13 4828.6  4826.4\n",
      "  4824.55 4807.23 4835.97 4818.75 4814.33]\n",
      " [3053.09 3051.24 3069.81 3066.86 3061.07 3055.35 3051.29 3045.18 3062.13\n",
      "  3042.4  3061.62 3053.66 3054.45 3046.52 3082.59 3062.41 3075.17 3072.37\n",
      "  3078.65 3070.47 3087.14 3069.21 3077.39 3088.28 3107.78 3075.28 3090.99\n",
      "  3085.54 3075.17 3067.15 3097.1  3072.6 ]\n",
      " [4873.45 4915.49 4922.5  4900.6  4882.67 4896.78 4871.17 4876.22 4878.56\n",
      "  4881.95 4885.59 4899.8  4872.62 4871.97 4878.75 4890.08 4874.79 4888.23\n",
      "  4878.84 4886.25 4888.48 4889.32 4861.32 4877.78 4878.08 4873.08 4882.77\n",
      "  4882.78 4864.32 4913.73 4874.83 4877.59]\n",
      " [3139.69 3128.55 3109.99 3106.34 3105.05 3108.04 3135.16 3204.43 3146.52\n",
      "  3125.99 3182.29 3146.32 3105.14 3133.95 3161.06 3130.52 3096.82 3113.95\n",
      "  3112.16 3119.32 3100.84 3118.67 3121.87 3115.01 3109.66 3125.08 3107.17\n",
      "  3134.52 3109.98 3131.71 3112.64 3127.55]\n",
      " [4767.96 4775.95 4760.27 4790.06 4755.4  4773.66 4772.31 4785.88 4757.62\n",
      "  4801.27 4767.33 4781.13 4772.59 4795.02 4765.31 4796.9  4775.04 4798.29\n",
      "  4781.99 4806.68 4768.17 4800.08 4786.7  4798.61 4778.46 4813.82 4770.06\n",
      "  4799.29 4792.29 4805.6  4780.96 4823.41]\n",
      " [5720.97 5733.96 5721.12 5714.52 5743.56 5735.42 5724.45 5744.41 5747.4\n",
      "  5725.32 5754.18 5770.52 5745.4  5749.27 5765.32 5739.88 5756.16 5770.84\n",
      "  5746.97 5754.94 5772.41 5753.3  5752.51 5765.67 5751.96 5739.96 5764.91\n",
      "  5749.77 5741.38 5755.72 5745.46 5728.17]\n",
      " [3554.92 3579.13 3561.17 3584.17 3561.66 3572.76 3560.12 3582.91 3564.46\n",
      "  3572.13 3558.75 3580.39 3553.44 3581.75 3563.93 3580.25 3556.16 3583.08\n",
      "  3559.38 3572.69 3558.94 3567.18 3558.85 3571.88 3551.95 3560.16 3553.96\n",
      "  3565.34 3543.88 3560.13 3547.62 3548.34]\n",
      " [4176.51 4189.86 4177.07 4199.75 4164.92 4195.15 4182.64 4189.93 4178.05\n",
      "  4198.73 4175.85 4193.66 4183.48 4195.32 4185.21 4199.28 4170.19 4190.14\n",
      "  4182.81 4184.57 4169.67 4194.24 4175.85 4185.55 4177.5  4187.65 4163.65\n",
      "  4198.54 4176.87 4186.61 4181.64 4207.39]\n",
      " [3384.85 3395.52 3383.15 3405.46 3404.85 3389.05 3396.96 3398.09 3389.18\n",
      "  3392.47 3399.87 3406.83 3418.61 3399.02 3397.82 3392.58 3402.28 3396.78\n",
      "  3405.21 3418.4  3397.38 3392.26 3404.79 3401.45 3400.49 3400.32 3399.92\n",
      "  3397.48 3399.91 3409.02 3401.07 3402.84]\n",
      " [5059.11 5066.32 5061.52 5064.53 5068.28 5064.89 5064.4  5071.81 5072.97\n",
      "  5065.43 5070.23 5067.39 5067.97 5072.23 5072.91 5068.2  5079.89 5073.73\n",
      "  5061.48 5074.16 5068.54 5063.15 5068.46 5070.63 5073.11 5070.4  5074.58\n",
      "  5064.92 5067.65 5073.18 5064.93 5068.52]\n",
      " [4253.97 4204.8  4221.72 4191.76 4228.9  4203.38 4213.8  4198.28 4224.5\n",
      "  4187.46 4211.41 4212.79 4216.88 4194.8  4239.49 4188.15 4211.81 4201.38\n",
      "  4210.92 4196.59 4213.09 4204.98 4224.73 4185.32 4225.21 4195.98 4209.69\n",
      "  4187.29 4207.12 4186.07 4212.12 4181.26]\n",
      " [3129.15 3134.14 3185.74 3190.32 3146.38 3142.01 3187.21 3211.35 3130.58\n",
      "  3136.25 3270.98 3164.86 3191.32 3131.16 3194.32 3192.05 3166.2  3212.68\n",
      "  3158.86 3176.24 3253.16 3173.09 3136.14 3116.22 3120.5  3143.37 3116.24\n",
      "  3214.22 3147.28 3133.31 3163.39 3343.83]\n",
      " [5419.28 5434.43 5439.35 5402.06 5408.59 5429.85 5405.58 5406.22 5415.08\n",
      "  5388.85 5390.15 5406.02 5391.01 5382.43 5416.49 5379.46 5369.86 5393.57\n",
      "  5385.07 5366.04 5384.53 5378.09 5367.89 5380.24 5380.52 5371.86 5387.91\n",
      "  5388.87 5371.5  5383.78 5401.19 5389.83]\n",
      " [5156.97 5157.4  5149.32 5156.51 5149.38 5152.61 5164.84 5152.38 5166.28\n",
      "  5148.36 5154.09 5149.79 5146.77 5149.49 5141.57 5147.22 5149.8  5149.26\n",
      "  5145.97 5149.48 5142.2  5135.93 5142.4  5145.84 5137.72 5143.82 5144.09\n",
      "  5144.45 5146.81 5149.62 5143.45 5130.97]\n",
      " [5151.62 5156.69 5167.8  5161.4  5150.35 5170.52 5204.44 5201.75 5177.67\n",
      "  5188.54 5166.26 5159.91 5166.67 5168.59 5167.89 5219.96 5210.9  5172.26\n",
      "  5194.32 5207.51 5210.27 5176.43 5184.66 5180.27 5167.53 5167.11 5169.68\n",
      "  5161.77 5176.35 5166.98 5185.47 5181.32]\n",
      " [5092.71 5093.19 5097.91 5085.48 5096.08 5083.45 5089.   5093.   5084.15\n",
      "  5092.05 5091.49 5089.48 5094.16 5087.56 5080.   5081.63 5089.67 5086.03\n",
      "  5082.21 5090.11 5078.66 5079.09 5103.7  5103.41 5086.57 5085.82 5078.51\n",
      "  5080.35 5092.14 5083.38 5071.34 5072.54]\n",
      " [5551.89 5580.89 5542.28 5535.85 5577.36 5546.44 5544.64 5564.64 5526.7\n",
      "  5533.89 5556.43 5533.19 5531.74 5568.15 5574.12 5533.75 5565.35 5586.22\n",
      "  5552.05 5566.22 5557.47 5565.98 5570.53 5578.5  5577.49 5603.88 5580.43\n",
      "  5561.37 5584.05 5585.45 5632.42 5623.06]\n",
      " [3492.41 3519.72 3502.3  3517.16 3520.69 3543.44 3513.96 3527.09 3507.71\n",
      "  3524.73 3505.34 3523.36 3499.05 3526.74 3513.85 3520.98 3516.71 3544.24\n",
      "  3528.89 3532.77 3521.97 3526.35 3514.06 3543.53 3520.69 3530.35 3530.66\n",
      "  3542.58 3525.65 3543.13 3526.92 3536.6 ]\n",
      " [4259.32 4269.93 4254.81 4265.11 4264.18 4258.41 4259.56 4277.3  4261.71\n",
      "  4273.56 4266.29 4269.22 4257.97 4279.99 4266.6  4280.57 4269.95 4273.65\n",
      "  4255.38 4276.92 4267.28 4263.06 4269.88 4270.41 4254.1  4275.82 4268.19\n",
      "  4262.36 4263.91 4273.54 4258.14 4269.45]\n",
      " [3145.09 3150.93 3146.66 3145.27 3148.63 3137.05 3154.78 3165.89 3144.6\n",
      "  3137.12 3172.   3150.18 3143.88 3145.12 3167.8  3168.69 3151.86 3155.69\n",
      "  3145.54 3162.98 3157.2  3146.36 3148.11 3156.5  3151.97 3141.76 3151.85\n",
      "  3145.58 3145.04 3149.64 3151.89 3149.83]\n",
      " [4343.36 4291.46 4336.02 4292.51 4331.58 4281.02 4314.5  4316.59 4312.5\n",
      "  4283.4  4310.11 4306.17 4300.69 4313.53 4300.46 4326.65 4300.55 4284.05\n",
      "  4310.77 4308.82 4297.63 4287.64 4302.58 4274.95 4318.6  4284.71 4299.03\n",
      "  4284.63 4301.51 4282.47 4293.63 4299.14]\n",
      " [3381.57 3383.32 3388.49 3366.92 3378.65 3371.38 3378.51 3357.16 3369.76\n",
      "  3352.   3358.33 3349.04 3370.91 3346.81 3352.96 3343.04 3369.35 3363.83\n",
      "  3353.6  3341.39 3352.04 3343.06 3343.52 3336.44 3344.75 3321.39 3328.98\n",
      "  3328.13 3343.86 3320.47 3337.16 3319.52]\n",
      " [3549.74 3540.82 3556.3  3537.96 3541.27 3535.8  3547.34 3529.19 3545.21\n",
      "  3533.37 3539.33 3545.53 3552.86 3521.71 3542.42 3532.32 3536.56 3528.73\n",
      "  3543.39 3518.7  3536.64 3532.11 3546.57 3534.77 3545.84 3520.55 3543.87\n",
      "  3548.55 3542.88 3516.89 3540.01 3529.75]\n",
      " [5557.75 5575.61 5555.11 5562.95 5594.14 5573.98 5587.52 5602.45 5587.45\n",
      "  5585.26 5606.52 5610.96 5592.75 5613.47 5605.2  5598.24 5625.75 5626.47\n",
      "  5610.01 5623.34 5627.09 5615.1  5628.53 5642.45 5620.29 5631.26 5644.83\n",
      "  5633.3  5669.72 5654.47 5637.94 5653.84]\n",
      " [4810.81 4809.11 4805.93 4821.87 4797.21 4809.34 4808.31 4806.78 4811.89\n",
      "  4815.81 4792.35 4801.46 4809.6  4805.12 4795.56 4815.54 4797.23 4796.77\n",
      "  4808.92 4806.5  4789.43 4814.45 4804.3  4802.98 4806.49 4820.33 4792.1\n",
      "  4812.3  4802.93 4812.63 4804.51 4825.6 ]\n",
      " [4955.45 4946.74 4971.5  4937.36 4972.2  4943.03 4960.86 4947.58 4973.88\n",
      "  4933.49 4974.71 4946.38 4955.24 4941.3  4973.55 4939.33 4966.28 4952.96\n",
      "  4960.65 4938.18 4977.97 4936.92 4968.11 4953.07 4967.73 4933.2  4976.75\n",
      "  4935.36 4949.62 4948.55 4963.95 4927.33]\n",
      " [4253.97 4235.18 4260.92 4244.41 4251.88 4247.78 4261.33 4241.15 4263.73\n",
      "  4256.08 4258.79 4252.49 4264.97 4242.23 4265.53 4258.01 4256.74 4242.36\n",
      "  4276.22 4251.04 4261.98 4258.37 4266.33 4250.63 4269.03 4250.75 4258.95\n",
      "  4250.95 4267.29 4241.8  4268.85 4255.19]\n",
      " [5059.28 5065.8  5059.77 5056.45 5066.25 5060.69 5065.1  5068.55 5064.48\n",
      "  5062.71 5060.5  5066.45 5051.17 5059.61 5073.14 5065.83 5066.44 5067.94\n",
      "  5066.93 5069.23 5063.56 5054.87 5062.54 5070.77 5062.93 5058.87 5067.32\n",
      "  5064.36 5064.17 5068.95 5066.1  5055.38]\n",
      " [3537.75 3515.77 3522.67 3530.85 3532.27 3520.67 3529.71 3523.07 3521.74\n",
      "  3529.36 3528.89 3524.04 3532.32 3531.03 3519.72 3532.47 3532.43 3518.52\n",
      "  3530.78 3544.21 3522.7  3526.89 3532.48 3520.94 3536.3  3539.75 3523.5\n",
      "  3528.72 3534.5  3534.58 3524.35 3532.22]\n",
      " [4293.21 4292.76 4300.71 4304.34 4289.29 4301.61 4295.38 4291.79 4309.64\n",
      "  4303.05 4287.61 4305.06 4299.86 4293.77 4301.75 4300.64 4289.57 4292.54\n",
      "  4341.9  4302.7  4287.74 4303.51 4286.68 4288.1  4309.28 4307.55 4288.81\n",
      "  4298.55 4292.8  4289.42 4301.32 4298.11]\n",
      " [4231.9  4198.84 4238.05 4224.09 4235.09 4199.92 4237.21 4216.44 4217.79\n",
      "  4195.87 4263.42 4186.26 4217.38 4204.05 4256.18 4228.52 4227.07 4200.57\n",
      "  4269.03 4218.35 4226.88 4201.61 4233.95 4207.12 4227.37 4228.86 4259.03\n",
      "  4237.72 4258.39 4252.27 4260.15 4263.6 ]\n",
      " [5751.62 5735.76 5763.58 5761.59 5745.01 5761.95 5765.17 5756.62 5772.11\n",
      "  5786.86 5753.12 5790.91 5792.62 5775.14 5785.29 5792.62 5781.29 5782.27\n",
      "  5792.62 5792.62 5788.07 5792.62 5791.81 5778.68 5792.62 5792.62 5780.35\n",
      "  5792.62 5789.15 5776.78 5792.62 5792.62]\n",
      " [3356.5  3367.   3350.26 3359.39 3359.92 3352.23 3358.87 3367.66 3358.39\n",
      "  3371.49 3382.74 3364.78 3347.38 3368.72 3357.9  3357.76 3357.78 3379.57\n",
      "  3356.64 3357.01 3351.7  3349.96 3353.06 3361.28 3347.41 3359.11 3357.92\n",
      "  3357.24 3356.23 3370.39 3347.21 3360.42]\n",
      " [5156.36 5159.82 5160.07 5172.52 5168.95 5159.84 5166.79 5170.16 5160.36\n",
      "  5174.32 5169.32 5169.   5179.75 5173.62 5163.05 5168.06 5172.7  5174.05\n",
      "  5176.93 5179.69 5186.39 5175.04 5186.57 5170.77 5176.78 5177.01 5174.65\n",
      "  5179.49 5174.78 5184.11 5180.   5181.32]\n",
      " [4914.46 4900.73 4924.58 4884.83 4912.56 4898.3  4907.04 4887.7  4922.43\n",
      "  4881.51 4904.78 4895.95 4905.05 4874.   4913.3  4875.74 4898.83 4887.54\n",
      "  4908.83 4873.97 4909.35 4878.75 4894.53 4884.59 4910.54 4877.07 4905.84\n",
      "  4888.82 4900.26 4894.53 4931.94 4888.16]\n",
      " [4271.2  4290.98 4261.34 4291.74 4261.9  4281.45 4263.78 4280.05 4256.88\n",
      "  4286.27 4257.9  4277.58 4266.95 4274.26 4250.9  4278.84 4258.57 4274.77\n",
      "  4254.27 4272.4  4240.62 4278.94 4258.08 4266.84 4246.25 4268.01 4242.7\n",
      "  4271.4  4248.22 4257.4  4240.2  4266.32]\n",
      " [3505.59 3495.79 3490.55 3509.03 3501.85 3507.55 3499.84 3506.2  3500.24\n",
      "  3513.02 3501.74 3500.49 3499.31 3512.53 3500.39 3523.67 3507.34 3507.84\n",
      "  3500.89 3513.34 3499.61 3514.42 3506.84 3502.91 3506.37 3515.67 3500.71\n",
      "  3503.58 3508.64 3512.03 3497.43 3519.81]\n",
      " [3810.41 3778.89 3791.52 3784.63 3803.75 3775.74 3791.47 3781.4  3782.72\n",
      "  3777.11 3795.45 3767.6  3791.79 3782.42 3782.62 3772.41 3786.98 3760.77\n",
      "  3778.04 3769.87 3781.49 3763.52 3778.06 3763.79 3771.17 3771.48 3783.92\n",
      "  3759.44 3777.41 3768.91 3768.77 3772.58]\n",
      " [3273.55 3288.8  3286.19 3262.36 3270.97 3271.56 3276.45 3274.43 3275.57\n",
      "  3259.08 3265.7  3280.65 3273.28 3270.95 3275.11 3277.52 3270.27 3279.86\n",
      "  3276.02 3276.18 3286.62 3280.69 3280.71 3300.6  3284.07 3276.06 3286.85\n",
      "  3287.4  3280.84 3297.39 3295.11 3289.68]\n",
      " [4241.62 4228.04 4231.69 4197.34 4255.6  4216.52 4219.97 4209.15 4247.92\n",
      "  4199.18 4236.8  4211.82 4244.45 4216.77 4234.99 4208.16 4227.55 4213.63\n",
      "  4221.87 4214.26 4247.34 4218.1  4218.43 4208.72 4229.71 4204.13 4231.16\n",
      "  4212.22 4222.53 4212.77 4241.25 4190.78]\n",
      " [4196.45 4226.46 4207.97 4217.25 4203.3  4227.06 4210.68 4217.38 4212.96\n",
      "  4218.39 4223.6  4235.54 4207.95 4228.07 4219.89 4227.5  4211.71 4235.11\n",
      "  4217.06 4228.58 4223.98 4237.43 4213.47 4235.27 4222.46 4232.68 4221.41\n",
      "  4247.41 4219.83 4237.16 4222.33 4241.64]\n",
      " [5631.45 5638.89 5642.61 5635.23 5625.61 5645.63 5633.53 5623.86 5647.13\n",
      "  5625.96 5619.38 5642.31 5632.74 5614.32 5633.69 5639.05 5620.4  5638.09\n",
      "  5642.05 5622.24 5627.74 5637.3  5623.85 5634.7  5646.07 5625.01 5627.68\n",
      "  5649.35 5642.56 5639.03 5654.4  5650.1 ]\n",
      " [3433.31 3443.08 3423.61 3429.35 3436.04 3428.59 3436.43 3436.79 3428.99\n",
      "  3431.49 3435.61 3432.08 3448.1  3435.3  3438.15 3435.07 3438.75 3430.82\n",
      "  3444.39 3437.2  3449.3  3431.36 3446.95 3438.05 3436.38 3440.52 3458.11\n",
      "  3454.45 3444.46 3444.72 3487.48 3471.85]\n",
      " [5048.21 5064.53 4994.25 4900.09 4683.34 4547.27 4307.77 4206.77 4159.16\n",
      "  4149.02 4184.12 4332.37 4539.29 4624.8  4643.04 4701.64 4720.67 4773.58\n",
      "  4820.4  4834.45 4795.33 4816.14 4789.2  4812.05 4828.78 4850.86 4831.17\n",
      "  4847.39 4783.33 4768.03 4731.53 4742.69]\n",
      " [5094.19 5082.99 5081.45 5086.32 5085.07 5106.41 5090.18 5079.33 5082.08\n",
      "  5090.48 5083.94 5085.94 5081.88 5082.74 5086.73 5085.74 5091.27 5080.99\n",
      "  5085.   5090.18 5078.64 5086.31 5083.7  5080.56 5086.45 5088.57 5079.9\n",
      "  5082.86 5088.29 5082.68 5077.99 5085.53]\n",
      " [5585.51 5539.94 5504.63 5509.07 5484.38 5468.92 5468.17 5461.49 5447.17\n",
      "  5472.62 5466.37 5450.81 5466.16 5471.31 5456.23 5472.78 5486.9  5465.16\n",
      "  5482.17 5488.79 5474.72 5480.4  5498.54 5494.83 5488.97 5499.22 5490.89\n",
      "  5490.6  5514.71 5510.39 5497.97 5526.95]\n",
      " [5585.41 5576.35 5557.66 5575.37 5570.63 5558.67 5584.43 5574.55 5550.25\n",
      "  5564.5  5572.44 5558.25 5569.67 5584.08 5565.52 5554.8  5574.06 5556.46\n",
      "  5555.77 5580.13 5554.11 5541.44 5561.81 5557.15 5544.   5565.36 5546.62\n",
      "  5540.68 5566.28 5558.08 5539.28 5560.31]\n",
      " [4328.47 4284.89 4326.51 4281.03 4300.24 4287.85 4297.58 4298.51 4341.58\n",
      "  4286.96 4313.88 4293.94 4317.71 4279.11 4325.66 4269.1  4296.35 4316.78\n",
      "  4295.5  4276.71 4296.8  4259.64 4298.15 4278.57 4287.41 4274.93 4299.69\n",
      "  4265.44 4296.99 4277.42 4281.85 4268.07]\n",
      " [3411.62 3423.4  3402.51 3415.66 3412.42 3427.5  3409.08 3417.94 3408.21\n",
      "  3426.   3416.89 3426.88 3421.11 3419.41 3420.03 3424.3  3416.12 3426.38\n",
      "  3407.71 3421.87 3420.24 3418.72 3416.45 3423.87 3414.37 3415.94 3412.69\n",
      "  3419.74 3407.01 3437.52 3428.89 3420.13]\n",
      " [3494.44 3513.21 3507.72 3503.46 3499.52 3527.28 3495.87 3502.84 3504.36\n",
      "  3503.88 3498.38 3511.25 3501.73 3498.3  3506.42 3506.96 3491.07 3505.38\n",
      "  3491.78 3488.02 3498.2  3507.57 3510.62 3502.   3497.95 3493.11 3517.02\n",
      "  3504.54 3493.28 3497.05 3505.63 3499.76]\n",
      " [1855.12 1838.01 1837.49 1824.05 1827.73 1796.45 1805.57 1806.76 1799.94\n",
      "  1807.67 1798.49 1797.06 1803.71 1788.78 1765.72 1748.04 1760.48 1753.31\n",
      "  1750.67 1759.32 1776.87 1813.82 1835.16 1806.94 1781.71 1812.69 1782.56\n",
      "  1767.77 1781.05 1754.29 1771.93 1777.33]\n",
      " [4251.73 4235.67 4233.8  4226.06 4256.71 4227.98 4240.54 4228.28 4230.84\n",
      "  4220.13 4246.88 4218.76 4233.2  4230.88 4232.61 4219.03 4236.14 4216.27\n",
      "  4230.39 4222.27 4233.84 4216.44 4248.1  4221.54 4228.3  4228.06 4241.71\n",
      "  4219.93 4233.37 4224.08 4232.08 4237.53]\n",
      " [5203.25 5208.43 5184.36 5181.54 5206.4  5199.76 5195.85 5197.2  5205.36\n",
      "  5210.1  5187.11 5191.2  5195.4  5199.71 5193.34 5182.41 5207.4  5206.15\n",
      "  5183.81 5191.41 5190.94 5186.17 5188.27 5187.87 5192.89 5179.49 5195.81\n",
      "  5200.85 5187.79 5202.12 5188.91 5183.  ]\n",
      " [3365.21 3384.52 3375.68 3381.27 3370.56 3386.64 3370.6  3380.02 3378.14\n",
      "  3381.91 3378.98 3399.42 3392.97 3397.11 3382.36 3379.19 3387.95 3390.58\n",
      "  3376.65 3383.1  3381.27 3400.57 3374.3  3397.36 3384.57 3386.77 3375.19\n",
      "  3392.7  3375.38 3384.86 3380.66 3391.35]\n",
      " [5607.43 5583.66 5589.93 5609.46 5581.36 5579.07 5603.28 5585.05 5574.32\n",
      "  5591.58 5583.96 5569.3  5592.16 5589.25 5565.6  5576.54 5582.08 5565.05\n",
      "  5591.05 5589.35 5566.48 5573.3  5585.32 5569.44 5577.17 5594.45 5574.63\n",
      "  5561.54 5585.12 5569.68 5564.05 5587.38]\n",
      " [3440.12 3453.45 3458.39 3446.9  3416.92 3449.78 3428.48 3438.46 3425.69\n",
      "  3438.2  3432.72 3442.54 3428.17 3443.84 3415.52 3457.19 3443.15 3437.62\n",
      "  3418.97 3439.76 3420.55 3442.25 3413.7  3451.06 3427.93 3436.35 3417.72\n",
      "  3444.77 3417.2  3435.36 3428.67 3437.71]\n",
      " [5148.31 5142.44 5132.53 5138.81 5131.41 5121.84 5108.71 5106.58 5119.96\n",
      "  5102.94 5102.74 5106.44 5101.41 5106.5  5094.56 5088.94 5077.08 5089.74\n",
      "  5073.92 5076.35 5090.39 5079.76 5085.72 5092.27 5088.96 5090.17 5091.15\n",
      "  5087.36 5094.35 5102.38 5105.15 5090.69]\n",
      " [3567.71 3587.6  3566.92 3576.55 3565.52 3583.69 3555.31 3588.99 3564.4\n",
      "  3586.33 3560.77 3584.9  3552.85 3577.91 3564.08 3575.18 3556.9  3578.49\n",
      "  3551.2  3573.35 3566.39 3572.13 3554.97 3587.92 3558.06 3572.68 3563.93\n",
      "  3574.93 3548.69 3578.01 3562.26 3568.04]\n",
      " [3245.51 3272.2  3250.64 3265.49 3254.72 3269.5  3254.26 3271.96 3257.43\n",
      "  3269.91 3259.13 3270.77 3247.76 3277.98 3263.53 3267.61 3259.32 3278.66\n",
      "  3253.78 3277.78 3272.15 3276.58 3258.27 3283.56 3275.6  3273.36 3276.55\n",
      "  3286.24 3271.29 3284.87 3271.32 3280.31]\n",
      " [5631.32 5636.13 5667.8  5642.13 5642.19 5666.62 5653.21 5645.55 5675.74\n",
      "  5657.79 5648.87 5674.37 5673.47 5657.66 5674.39 5672.2  5652.41 5682.75\n",
      "  5688.85 5655.29 5665.95 5688.56 5659.21 5677.8  5681.5  5654.42 5670.38\n",
      "  5681.32 5655.78 5656.67 5660.77 5644.21]\n",
      " [4255.82 4265.05 4268.69 4257.39 4263.32 4263.35 4255.71 4253.67 4260.69\n",
      "  4259.51 4277.99 4264.07 4258.62 4247.73 4266.34 4246.39 4246.3  4268.24\n",
      "  4266.92 4253.73 4269.06 4256.64 4254.01 4262.57 4266.14 4251.46 4258.74\n",
      "  4269.8  4259.77 4253.87 4269.33 4247.99]\n",
      " [4215.44 4219.09 4214.97 4208.15 4197.07 4218.76 4220.23 4221.17 4236.58\n",
      "  4239.29 4227.71 4243.35 4234.87 4237.99 4237.56 4240.92 4229.41 4251.97\n",
      "  4248.27 4249.54 4251.64 4271.92 4240.31 4249.39 4242.21 4231.39 4216.26\n",
      "  4241.18 4227.36 4243.65 4252.78 4261.97]\n",
      " [4824.22 4802.43 4814.08 4816.53 4814.97 4800.45 4820.52 4801.81 4811.61\n",
      "  4825.32 4839.07 4795.88 4821.97 4810.32 4806.29 4804.52 4823.2  4798.55\n",
      "  4813.49 4812.17 4812.39 4804.6  4826.63 4803.67 4817.26 4811.56 4813.79\n",
      "  4798.35 4819.15 4804.32 4808.03 4816.84]\n",
      " [3243.54 3250.37 3237.48 3257.98 3239.82 3249.21 3246.26 3260.1  3236.67\n",
      "  3251.33 3239.36 3252.52 3240.86 3250.11 3243.66 3248.25 3235.25 3247.04\n",
      "  3231.13 3247.63 3227.97 3251.57 3242.4  3252.03 3233.43 3253.13 3241.29\n",
      "  3236.57 3247.72 3277.08 3236.89 3267.17]\n",
      " [5067.27 5063.74 5057.72 5064.03 5053.16 5063.61 5062.28 5059.21 5061.46\n",
      "  5066.91 5064.65 5057.24 5063.95 5069.05 5068.73 5060.87 5063.42 5060.96\n",
      "  5073.82 5062.61 5056.54 5058.5  5076.38 5064.92 5065.59 5065.97 5058.33\n",
      "  5058.83 5065.98 5057.46 5058.98 5068.25]\n",
      " [5613.23 5621.46 5603.74 5617.62 5632.02 5601.1  5597.25 5611.1  5590.44\n",
      "  5583.39 5599.76 5569.71 5563.95 5584.41 5570.37 5554.35 5572.88 5567.01\n",
      "  5536.66 5558.71 5554.47 5532.37 5537.34 5537.38 5521.9  5547.11 5541.36\n",
      "  5508.93 5533.32 5530.62 5503.67 5523.32]\n",
      " [5074.   5072.39 5076.57 5086.81 5076.38 5072.66 5071.96 5072.48 5077.91\n",
      "  5077.92 5075.03 5080.93 5069.53 5067.38 5076.26 5068.13 5067.89 5072.49\n",
      "  5065.28 5067.1  5071.25 5073.88 5067.31 5074.2  5075.6  5070.09 5070.44\n",
      "  5069.19 5061.07 5070.82 5071.47 5065.3 ]\n",
      " [4271.71 4265.13 4277.89 4256.93 4283.51 4254.18 4266.47 4260.7  4285.19\n",
      "  4253.36 4281.18 4273.35 4271.25 4261.51 4278.08 4257.22 4282.71 4263.84\n",
      "  4271.65 4267.71 4286.24 4257.3  4276.03 4268.17 4278.22 4261.11 4291.6\n",
      "  4268.42 4283.26 4271.36 4291.05 4264.4 ]\n",
      " [4874.98 4909.03 4861.19 4890.1  4861.89 4880.26 4870.22 4890.8  4855.7\n",
      "  4888.6  4871.14 4882.22 4870.15 4899.   4865.69 4890.18 4876.75 4887.72\n",
      "  4876.11 4902.45 4860.59 4889.49 4881.96 4886.23 4865.46 4892.96 4873.01\n",
      "  4880.18 4870.06 4886.22 4856.91 4889.17]\n",
      " [4251.16 4275.71 4256.34 4281.94 4261.19 4292.31 4245.01 4266.09 4247.99\n",
      "  4268.79 4253.03 4295.76 4242.66 4272.4  4246.28 4279.41 4233.2  4265.54\n",
      "  4233.97 4252.71 4237.8  4273.42 4236.03 4251.85 4230.05 4245.13 4229.62\n",
      "  4251.09 4215.31 4238.54 4225.27 4242.72]\n",
      " [3117.77 3109.6  3130.85 3112.01 3121.13 3101.84 3121.35 3114.63 3127.81\n",
      "  3106.18 3135.52 3124.21 3119.86 3114.98 3142.42 3136.84 3138.12 3115.57\n",
      "  3131.94 3130.63 3125.95 3109.57 3132.51 3135.81 3123.16 3117.5  3128.9\n",
      "  3119.36 3126.34 3112.91 3119.49 3116.71]\n",
      " [3543.99 3518.17 3548.41 3525.44 3520.64 3517.92 3515.82 3496.   3505.7\n",
      "  3494.41 3496.79 3491.91 3514.44 3489.01 3489.55 3487.11 3472.92 3457.41\n",
      "  3490.48 3482.62 3466.62 3453.91 3470.89 3461.88 3482.07 3461.66 3449.64\n",
      "  3456.28 3450.34 3425.09 3443.23 3427.94]\n",
      " [5076.85 5079.36 5069.74 5071.65 5066.7  5064.88 5061.62 5069.03 5075.81\n",
      "  5068.76 5072.13 5068.24 5066.09 5077.02 5071.43 5063.22 5075.57 5064.23\n",
      "  5070.27 5079.45 5080.6  5071.03 5076.1  5073.79 5057.44 5065.6  5074.94\n",
      "  5070.29 5084.09 5082.29 5083.58 5079.97]\n",
      " [3101.81 3111.   3093.52 3117.13 3102.88 3102.93 3095.94 3114.07 3091.66\n",
      "  3113.93 3108.74 3102.52 3086.53 3108.94 3090.56 3102.78 3094.39 3102.72\n",
      "  3088.83 3110.24 3106.67 3106.15 3092.19 3106.19 3076.89 3106.53 3090.47\n",
      "  3098.37 3088.27 3103.34 3078.8  3103.01]\n",
      " [5665.64 5664.25 5717.83 5674.91 5661.71 5682.85 5666.09 5660.23 5684.93\n",
      "  5674.79 5664.06 5668.08 5680.54 5646.12 5685.27 5687.7  5646.07 5652.71\n",
      "  5669.11 5646.68 5661.58 5667.04 5666.91 5647.13 5674.67 5654.3  5682.04\n",
      "  5676.68 5644.87 5641.12 5668.01 5657.67]\n",
      " [3523.2  3522.62 3520.42 3517.38 3514.28 3523.51 3507.26 3515.53 3513.77\n",
      "  3507.54 3506.28 3511.46 3497.91 3501.32 3507.08 3508.25 3498.35 3505.83\n",
      "  3498.44 3498.3  3518.01 3505.53 3495.92 3506.39 3510.59 3504.77 3503.97\n",
      "  3513.63 3533.61 3515.65 3511.07 3498.65]\n",
      " [5053.29 5043.36 5057.12 5046.37 5045.03 5037.64 5045.01 5043.32 5041.91\n",
      "  5053.27 5051.84 5044.97 5050.62 5050.82 5048.88 5047.29 5052.89 5046.06\n",
      "  5056.86 5064.37 5057.17 5059.09 5058.19 5058.62 5062.3  5062.34 5058.96\n",
      "  5054.29 5067.67 5067.   5063.14 5068.46]\n",
      " [5080.12 5078.81 5082.13 5090.23 5086.89 5084.5  5082.12 5079.25 5082.09\n",
      "  5093.96 5084.02 5100.22 5094.09 5094.71 5093.53 5091.18 5077.67 5082.73\n",
      "  5086.59 5101.06 5081.43 5094.75 5092.93 5084.14 5101.17 5092.17 5080.31\n",
      "  5087.77 5087.33 5091.41 5092.54 5103.5 ]\n",
      " [3275.89 3283.27 3269.83 3292.8  3272.26 3285.54 3279.25 3292.15 3268.97\n",
      "  3290.73 3273.   3285.09 3275.49 3294.92 3277.17 3282.23 3278.75 3280.51\n",
      "  3270.4  3289.76 3269.37 3279.85 3276.57 3283.77 3265.68 3290.49 3276.54\n",
      "  3275.05 3275.16 3289.56 3265.33 3283.69]\n",
      " [5612.83 5631.71 5628.19 5613.4  5620.01 5629.88 5614.45 5612.07 5617.47\n",
      "  5610.53 5615.08 5608.   5583.43 5599.88 5609.4  5582.25 5581.28 5601.51\n",
      "  5581.59 5575.41 5595.87 5591.48 5574.98 5600.36 5594.39 5575.86 5601.08\n",
      "  5603.24 5589.82 5608.4  5626.95 5616.6 ]\n",
      " [4228.14 4237.04 4225.15 4239.8  4213.5  4230.56 4224.5  4226.36 4221.05\n",
      "  4242.92 4214.78 4226.78 4223.29 4226.73 4211.09 4237.73 4222.82 4225.41\n",
      "  4219.05 4226.47 4196.95 4229.09 4205.4  4205.46 4214.69 4216.49 4206.06\n",
      "  4209.16 4193.2  4202.67 4187.72 4218.78]\n",
      " [3090.9  3106.18 3090.2  3090.91 3090.21 3096.77 3092.47 3093.67 3095.32\n",
      "  3097.36 3096.76 3101.87 3087.9  3091.15 3111.42 3084.66 3088.02 3092.69\n",
      "  3083.17 3090.09 3096.88 3087.25 3090.04 3098.58 3092.1  3092.76 3100.82\n",
      "  3102.23 3098.81 3108.28 3102.43 3090.88]\n",
      " [5781.35 5792.62 5792.62 5780.02 5792.62 5792.62 5790.43 5792.62 5792.62\n",
      "  5792.62 5792.62 5792.62 5792.62 5792.62 5792.62 5789.08 5792.62 5792.62\n",
      "  5792.62 5778.1  5792.62 5792.62 5783.22 5792.62 5792.62 5771.31 5790.72\n",
      "  5788.98 5769.81 5782.4  5792.62 5776.46]\n",
      " [3130.82 3100.26 3114.59 3101.13 3134.19 3104.68 3124.23 3103.9  3122.86\n",
      "  3097.64 3125.11 3109.25 3115.61 3108.4  3128.83 3101.65 3127.48 3105.06\n",
      "  3120.31 3114.98 3133.58 3115.31 3126.06 3114.58 3124.87 3116.22 3129.66\n",
      "  3116.13 3141.38 3116.8  3133.66 3110.76]\n",
      " [5570.32 5543.28 5557.   5562.57 5528.27 5546.45 5557.   5537.68 5550.76\n",
      "  5559.   5535.57 5536.3  5571.9  5551.91 5549.35 5568.72 5542.42 5529.8\n",
      "  5563.36 5551.16 5549.27 5555.29 5570.1  5535.96 5554.1  5588.17 5568.71\n",
      "  5550.23 5571.38 5552.17 5572.2  5577.9 ]\n",
      " [5582.9  5580.   5558.44 5578.11 5584.63 5577.51 5588.44 5600.09 5576.4\n",
      "  5596.88 5613.35 5595.57 5604.77 5636.47 5611.56 5611.16 5635.66 5649.04\n",
      "  5638.65 5652.31 5652.02 5653.17 5681.05 5669.34 5662.8  5714.05 5690.53\n",
      "  5668.83 5689.78 5701.34 5669.14 5712.99]\n",
      " [4970.13 4923.16 4951.85 4910.3  4905.55 4859.46 4865.26 4819.93 4828.32\n",
      "  4825.1  4842.36 4850.58 4882.8  4890.28 4922.55 4921.89 4934.21 4923.23\n",
      "  4967.9  4963.35 4969.1  4960.52 4933.75 4867.99 4868.06 4798.54 4784.56\n",
      "  4776.43 4780.49 4771.4  4800.26 4835.82]\n",
      " [3439.43 3413.13 3438.84 3420.37 3455.36 3411.61 3445.6  3411.19 3436.64\n",
      "  3427.21 3450.28 3410.44 3436.88 3398.75 3432.16 3415.54 3429.04 3413.06\n",
      "  3477.73 3407.22 3435.77 3429.49 3456.14 3421.51 3437.02 3420.4  3430.57\n",
      "  3434.55 3451.67 3412.43 3436.52 3425.17]]\n"
     ]
    }
   ],
   "source": [
    "print(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Spotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test options and evaluation metric\n",
    "num_folds = 10\n",
    "seed = 42\n",
    "scoring = 'f1_macro'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spot-Check Algorithms\n",
    "models = []\n",
    "\n",
    "#models.append(('XGB', XGBClassifier(random_state=seed)))\n",
    "models.append(('GNB', GaussianNB(var_smoothing=2e-9)))\n",
    "models.append(('LR', LogisticRegression(random_state=seed)))\n",
    "models.append(('CART' , DecisionTreeClassifier(random_state=seed)))\n",
    "models.append(('SVC' , SVC(gamma=0.05, random_state=seed)))\n",
    "models.append(('RF', RandomForestClassifier(random_state=seed, n_estimators = 50)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GNB - 0,87 0,05\n",
      "LR - 0,21 0,04\n",
      "CART - 0,96 0,03\n",
      "SVC - 0,24 0,03\n",
      "RF - 0,97 0,02\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "names = []\n",
    "for name, model in models:\n",
    "    # Dividere dati in n = num_folds\n",
    "    kf = StratifiedKFold(n_splits=num_folds, random_state=seed, shuffle=True)\n",
    "    cv_results = np.array([])\n",
    "    for train_idx, test_idx, in kf.split(X_train, y_train):\n",
    "        X_cross_train, y_cross_train = X_train[train_idx], y_train[train_idx]\n",
    "        X_cross_test, y_cross_test = X_train[test_idx], y_train[test_idx]\n",
    "        model.fit(X_cross_train, y_cross_train)  \n",
    "        y_pred = model.predict(X_cross_test)\n",
    "        f1s = f1_score(y_cross_test, y_pred, average=\"weighted\")\n",
    "        cv_results = np.append(cv_results, [f1s])\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    #msg = \"%s - %f - %f\" % (name, cv_results.mean(), cv_results.std())\n",
    "    msg = \"{} - {:.2f} {:.2f}\".format(name, cv_results.mean(), cv_results.std()).replace('.', ',')\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compare Algorithms\n",
    "fig = plt.figure(figsize=(10,5))\n",
    "fig.suptitle('Algorithms Comparison')\n",
    "ax = fig.add_subplot(111)\n",
    "plt.boxplot(results)\n",
    "ax.set_yscale('log')\n",
    "ax.set_xticklabels(names)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Valutazione dei modelli sul Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model GNB: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        20\n",
      "           1       0.71      0.60      0.65        20\n",
      "           2       0.91      1.00      0.95        20\n",
      "           3       0.65      0.75      0.70        20\n",
      "           4       1.00      0.90      0.95        20\n",
      "           5       1.00      1.00      1.00        20\n",
      "\n",
      "    accuracy                           0.88       120\n",
      "   macro avg       0.88      0.88      0.87       120\n",
      "weighted avg       0.88      0.88      0.87       120\n",
      "\n",
      "-------------------------------------------------------------\n",
      "Model LR: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.09      0.15      0.11        20\n",
      "           1       0.18      0.10      0.13        20\n",
      "           2       0.25      0.15      0.19        20\n",
      "           3       0.50      0.15      0.23        20\n",
      "           4       0.21      0.20      0.21        20\n",
      "           5       0.33      0.65      0.44        20\n",
      "\n",
      "    accuracy                           0.23       120\n",
      "   macro avg       0.26      0.23      0.22       120\n",
      "weighted avg       0.26      0.23      0.22       120\n",
      "\n",
      "-------------------------------------------------------------\n",
      "Model CART: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        20\n",
      "           1       0.95      0.95      0.95        20\n",
      "           2       0.90      0.95      0.93        20\n",
      "           3       0.95      0.95      0.95        20\n",
      "           4       0.95      0.90      0.92        20\n",
      "           5       1.00      1.00      1.00        20\n",
      "\n",
      "    accuracy                           0.96       120\n",
      "   macro avg       0.96      0.96      0.96       120\n",
      "weighted avg       0.96      0.96      0.96       120\n",
      "\n",
      "-------------------------------------------------------------\n",
      "Model SVC: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        20\n",
      "           1       0.94      0.75      0.83        20\n",
      "           2       1.00      0.05      0.10        20\n",
      "           3       0.00      0.00      0.00        20\n",
      "           4       0.19      1.00      0.33        20\n",
      "           5       0.00      0.00      0.00        20\n",
      "\n",
      "    accuracy                           0.30       120\n",
      "   macro avg       0.36      0.30      0.21       120\n",
      "weighted avg       0.36      0.30      0.21       120\n",
      "\n",
      "-------------------------------------------------------------\n",
      "Model RF: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        20\n",
      "           1       1.00      1.00      1.00        20\n",
      "           2       0.91      1.00      0.95        20\n",
      "           3       1.00      1.00      1.00        20\n",
      "           4       1.00      0.90      0.95        20\n",
      "           5       1.00      1.00      1.00        20\n",
      "\n",
      "    accuracy                           0.98       120\n",
      "   macro avg       0.98      0.98      0.98       120\n",
      "weighted avg       0.98      0.98      0.98       120\n",
      "\n",
      "-------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "tasks = ['S', 'S3', 'S6']\n",
    "def classification_report_csv(report, model_name):\n",
    "    report_data = []\n",
    "    lines = report.split('\\n')\n",
    "    index = 0\n",
    "    row = lines[-4].split('    ')\n",
    "    accuracy = row[-2]\n",
    "    for line in lines[2:-5]:\n",
    "        row = {}\n",
    "        row_data = line.split('      ')\n",
    "        row['class'] = uniques[index]\n",
    "        row['precision'] = float(row_data[2]) \n",
    "        row['recall'] = float(row_data[3]) \n",
    "        row['f1_score'] = float(row_data[4])\n",
    "        row['accuracy'] = accuracy\n",
    "        report_data.append(row)\n",
    "        index += 1\n",
    "    dataframe = pd.DataFrame.from_dict(report_data)\n",
    "    dataframe.to_csv(tasks[choosenIndex]+ '/classificationReports/'+'classification_report' + model_name +  '.csv', index = False)\n",
    "    \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=RANDOM_SEED)\n",
    "for name, model in models:\n",
    "    model.fit(X_train,  y_train)\n",
    "    pred_train = model.predict(X_train)\n",
    "    pred_test = model.predict(X_test)\n",
    "    print(f\"Model {name}: \")\n",
    "    report = classification_report(y_test, pred_test)\n",
    "    print(report)\n",
    "    classification_report_csv(report, name)\n",
    "    print(\"-------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Valutazione Inferance Rate medio (|X_test| = 50/50/100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEJCAYAAAB7UTvrAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAUuklEQVR4nO3df5BlZX3n8fdHDFEgoAmUicAwSBOyowiRDmh0gaxkdygdMeQXE2p3dQlTJiHuriaRJCZgNqlIdi0rGiwyEYK6ZBDN6oKZDWqUH1KsMkR+DYQ4gspQmwLEml0jisB3/7hnzlzanunbQz99+3a/X1Vd3HvOved+76V7Pvc8z3OeJ1WFJEkAzxp3AZKkpcNQkCT1DAVJUs9QkCT1DAVJUs9QkCT1DAVJUs9QkCT1nj3uAoYl2R+4Hriwqj4x1+MPPvjgWr16dfO6JGk5ufXWWx+pqkNm29c0FJJcBrwWeKiqXjK0fS3wp8A+wPur6p3drrcBV416/NWrV7Nly5YFrFiSlr8kX93dvtbNR5cDa2cUsw9wMXA6sAZYn2RNkp8G7gYealyTJGk3mp4pVNUNSVbP2HwisK2q7gNIciVwBnAAsD+DoHgsyeaqeqplfZKkpxtHn8KhwAND97cDJ1XVeQBJ3gA8srtASLIB2ACwatWqtpVK0gqz5EYfVdXle+pkrqqNVTVdVdOHHDJrP4kkaS+NIxQeBA4fun9Yt21kSdYl2bhjx44FLUySVrpxhMItwNFJjkyyL3AWcPV8DlBV11TVhoMOOqhJgZK0UjUNhSSbgJuBY5JsT3JOVT0BnAdcC9wDXFVVW1vWIUkaTevRR+t3s30zsHlvj5tkHbBuampqbw8hSZrFkrqieVRVdQ1wzfT09LnjrkWaVNeffMq4S1hwp9xw/bhLmHhLbvSRJGl8JjIUHH0kSW1MZCg4+kiS2pjIUJAktTGRoWDzkSS1MZGhYPORJLUxkaEgSWrDUJAk9SYyFOxTkKQ2JjIU7FOQpDYmMhQkSW0YCpKknqEgSepNZCjY0SxJbUxkKNjRLEltTGQoSJLaMBQkST1DQZLUMxQkSb2JDAVHH0lSGxMZCo4+kqQ2JjIUJEltGAqSpJ6hIEnqGQqSpJ6hIEnqGQqSpJ6hIEnqTWQoePGaJLUxkaHgxWuS1MZEhoIkqQ1DQZLUMxQkST1DQZLUMxQkST1DQZLUMxQkST1DQZLUMxQkST1DQZLUWzKhkORfJLkkyUeT/Mq465GklahpKCS5LMlDSe6asX1tknuTbEtyPkBV3VNVbwJ+AXhly7okSbNrfaZwObB2eEOSfYCLgdOBNcD6JGu6fa8D/gbY3LguSdIsmoZCVd0APDpj84nAtqq6r6oeB64Ezugef3VVnQ6c3bIuSdLsnj2G1zwUeGDo/nbgpCSnAmcC388ezhSSbAA2AKxatapZkZK0Eo0jFGZVVdcB143wuI3ARoDp6elqW5UkrSzjGH30IHD40P3Dum0jc+U1SWpjHKFwC3B0kiOT7AucBVw9nwO48poktdF6SOom4GbgmCTbk5xTVU8A5wHXAvcAV1XV1pZ1SJJG07RPoarW72b7Zp7BsNMk64B1U1NTe3sISdIslswVzfNh85EktTGRoSBJamMiQ8HRR5LUxkSGgs1HktTGRIaCJKmNiQwFm48kqY2JDAWbjySpjYkMBUlSG4aCJKk3kaFgn4IktTGRoWCfgiS1MZGhIElqw1CQJPUMBUlSbyJDwY5mSWpjIkPBjmZJaqPpIjuSNAn+7K3XjLuEBXfeu9bt1fMm8kxBktSGoSBJ6hkKkqTeRIaCo48kqY2JDAVHH0lSGxMZCpKkNgwFSVLPUJAk9eYVCkkOTHJCkue3KkiSND57DIUk/z3Jwd3tfwPcBVwE3Jbk5xehPknSIpprmovjquqR7vYFwMlV9ZUuKP4O+EjT6iRJi2qu5qNnJTmwu/0U8DWALiicN0mSlpm5/mF/B/DZJBcDNwEfSXI18FPA37YubneSrAPWTU1NjasESVqW9nimUFVXAb8IHAP8KLAv8HJgU1W9tX15u63Li9ckqYE5m4CqahvwtkWoRZI0ZnONPjo3ydHd7SS5LMmOJHckednilChJWixzdTT/R+Ar3e31wHHAi4C3AH/arixJ0jjMFQpPVNV3u9uvBT5YVV+vqk8D+7ctTZK02OYKhaeS/EiS5wCvBj49tO+57cqSJI3DXB3Nvw9sAfYBrq6qrQBJTgHua1ybJGmR7TEUquoTSY4AfqCqvjG0awuDoaqSpGVkzgnxquoJ4DtJfi/JX3SbXwic2rIwSdLiG3WW1L8EvgO8orv/IPCHTSqSJI3NqKFwVFX9CfBdgKr6FpBmVUmSxmLUSe0eT/JcoACSHMXgzGFBJXk98BrgQODSqvrkQr+GJGn3Rj1TuIDBBHiHJ7mCwbTZvzXKE7uroB9KcteM7WuT3JtkW5LzAarq41V1LvAm7MiWpEU3UihU1aeAM4E3AJuA6aq6bsTXuBxYO7whyT7AxcDpwBpgfZI1Qw95e7dfkrSI5rMc56EMrlfYFzg5yZmjPKmqbgAenbH5RGBbVd1XVY8DVwJndPMrXQT8r6r6+3nUJklaACP1KSS5DHgpsJXBYjsw6F/4H3v5uocCDwzd3w6cBPw6cBpwUJKpqrpkllo2ABsAVq1atZcvL0mazagdzS+vqjVzP+yZqar3AO+Z4zEbgY0A09PT1bomSVpJRm0+unlGm/8z9SBw+ND9w7ptI0myLsnGHTt2LGBJkqRRQ+GDDILh3m4thTuT3PEMXvcW4OgkRybZFzgLuHrUJ7vymiS1MWrz0aXAvwXuZFefwkiSbGIwJcbBSbYDF1TVpUnOA65l0Hl92c7J9iRJ4zNqKDxcVSN/kx9WVet3s30zsHlvjplkHbBuampqb54uSdqNUZuPvpjkr5KsT3Lmzp+mle2BzUeS1MaoZwrPZTCtxb8e2vZMhqRKkpagkUKhqt7YupD5sPlIktrYYygk+a2q+pMk76WbDG9YVb25WWV7UFXXANdMT0+fO47Xl6Tlaq4zhbu7/25pXYgkafzmCoU3A5+oqg8sRjGjsvlIktqYa/TRwYtSxTw5+kiS2pjrTOF5exp6WlWOPpKkZWSuUDgIeC2zL73pkFRJWmbmCoWvVdV/WJRK5sE+BUlqY64+hecsShXzZJ+CJLUxVyhMAST50CLUIkkas7maj+5N8kvAT87W4WxHsyQtL3OFwpuAs4HnAetm7LOjWZKWmT2GQlV9Dvhcki1Vdeki1TQnO5olqY1RJ8S7NMlPAquHn1NVH2xU11z1OPeRJDUwUih0Hc1HAbcBT3abi8EynZKkZWLU9RSmgTVV9T0zpUqSlo9RV167C/jhloVIksZv1DOFg4G7k3yBwQpsAFTV65pUJUkai1FD4cKWRcyXo48kqY1RRx9d37qQ+XD0kSS1MddynP+PWZbhZDBralXVgU2qkiSNxVwXr/3AYhUiSRq/UUcfSZJWAENBktQbdfTRxDnhN5ffxda3/td/N+4SJC1znilIknqGgiSpN5GhkGRdko07duwYdymStKxMZCi4RrMktTGRoSBJasNQkCT1DAVJUs9QkCT1DAVJUs9QkCT1lu00F9JsXvneV467hAV306/fNO4StIx4piBJ6hkKkqSeoSBJ6i2ZUEjyoiSXJvnouGuRpJWqaSgkuSzJQ0numrF9bZJ7k2xLcj5AVd1XVee0rEeStGetzxQuB9YOb0iyD3AxcDqwBlifZE3jOiRJI2gaClV1A/DojM0nAtu6M4PHgSuBM1rWIUkazTj6FA4FHhi6vx04NMkPJbkE+PEkv727JyfZkGRLki0PP/xw61olaUVZMhevVdXXgTeN8LiNwEaA6enpal2XJK0k4zhTeBA4fOj+Yd22kbnymiS1MY5QuAU4OsmRSfYFzgKuns8BXHlNktpoPSR1E3AzcEyS7UnOqaongPOAa4F7gKuqamvLOiRJo2nap1BV63ezfTOweW+Pm2QdsG5qampvDyFJmsWSuaJ5Pmw+kqQ2JjIUJEltTGQoOPpIktqYyFCw+UiS2pjIUJAktTGRoWDzkSS1MZGhYPORJLUxkaEgSWrDUJAk9SYyFOxTkKQ2JjIU7FOQpDYmMhQkSW0YCpKknqEgSepNZCjY0SxJbUxkKNjRLEltTGQoSJLaMBQkST1DQZLUMxQkST1DQZLUm8hQcEiqJLUxkaHgkFRJamMiQ0GS1IahIEnqGQqSpJ6hIEnqGQqSpJ6hIEnqGQqSpN5EhoIXr0lSGxMZCl68JkltTGQoSJLaMBQkST1DQZLUMxQkST1DQZLUMxQkST1DQZLUMxQkST1DQZLUe/a4C9gpyf7A+4DHgeuq6ooxlyRJK07TM4UklyV5KMldM7avTXJvkm1Jzu82nwl8tKrOBV7Xsi5J0uxaNx9dDqwd3pBkH+Bi4HRgDbA+yRrgMOCB7mFPNq5LkjSLpqFQVTcAj87YfCKwraruq6rHgSuBM4DtDIKheV2SpNmNo0/hUHadEcAgDE4C3gP8WZLXANfs7slJNgAbAFatWtWwzOXja39w7LhLWHCrfv/OcZcgLUtLpqO5qv4ZeOMIj9sIbASYnp6u1nVJ0koyjmaaB4HDh+4f1m0bmYvsSFIb4wiFW4CjkxyZZF/gLODq+RzARXYkqY3WQ1I3ATcDxyTZnuScqnoCOA+4FrgHuKqqtrasQ5I0mqZ9ClW1fjfbNwOb9/a4SdYB66ampvb2EJKkWUzk0E+bjySpjYkMBUlSGxMZCo4+kqQ2JjIUbD6SpDZSNbnXfyV5GPjquOsADgYeGXcRS4Cfwy5+Frv4WeyyVD6LI6rqkNl2THQoLBVJtlTV9LjrGDc/h138LHbxs9hlEj6LiWw+kiS1YShIknqGwsLYOO4Clgg/h138LHbxs9hlyX8W9ilIknqeKUiSeobCPCR5MsltSe5Kck2S53XbVyd5rNu382ffMZe7IJL8cJIrk3w5ya1JNif50W7ff0ry7SQHDT3+1CQ7us/gH5L8tyTHDn0ujya5v7v96fG9s4WT5JuzbLswyYPd+7w7yazzgC0HSX43ydYkd3Tv94IkfzzjMccnuae7fUCSPx/6nbouyUnjqX7hJHlBkr9Kcl/3vm5O8jPd30R1c7btfOwnkpza3b6uW7P+tiT3dAuJjY2hMD+PVdXxVfUSBsuM/trQvi93+3b+PD6mGhdMkgAfA66rqqOq6gTgt4EXdA9Zz2Aq9DNnPPXGqjoe+HHgtcCBOz8XBtOk/2Z3/7RFeBvj9O7uPZ8B/HmS7xtzPQsuySsY/D9+WVW9FDgN+CzwizMeehawqbv9fgZ/P0d3v1NvZDB+f2J1fysfB26oqhd17+ssdi0xvB343T0c4uzud+WVwEXj/FJpKOy9mxksLbqc/RTw3aq6ZOeGqrq9qm5MchRwAPB2BuHwParqMeA2lv/ntEdV9SXgW8Dzx11LAz8CPFJV3wGoqke6tdm/MePb/y8Am7rfm5OAt1fVU91z7q+qv1nswhfYvwIen/G38tWqem9393ZgR5KfnuM4BwD/DDzZpsy5GQp7Ick+wKt5+uJARw01kVw8ptIW2kuAW3ez7yzgSuBGButlvGDmA5I8HzgauKFZhRMgycuAL1XVQ+OupYFPAocn+cck70tySrd9E4PfEZK8HHi0C8cXA7dV1dj+0WvkxcDfz/GYP2LwJWo2VyS5A7gX+C/j/HwMhfl5bpLbgH9i0ITyqaF9w81Hvzbrs5eX9cCV3be9vwZ+fmjfv0xyO4NlVq+tqn8aR4FLwH9OshX4PIN/EJadqvomcAKwAXgY+HCSNwAfBn4uybN4etPRipDk4iS3J7ll57buDIokr5rlKWd3zW+rgN9IcsQilfo9DIX5eaxr9zsCCE/vU1iOtjL4g3+aJMcyOAP4VJKvMPijH25CurGqjmPw7emcJMe3L3VJendVvRj4WeDSJM8Zd0EtVNWTVXVdVV3AYFXFn62qB4D7gVMYvP8Pdw/fChzXnW0vJ1uBl+28030xfDUwc36hPZ0tUFUPMzjjGFvHu6GwF6rqW8Cbgbcmabp63Zh9Bvj+4dEQSV4KvAe4sKpWdz8vBF4489tNVd0PvBN422IWvdRU1dXAFuDfj7uWhZbkmCRHD206nl2TVG4C3g3cV1XbAarqyww+i3d0nbM7R++9ZvGqbuIzwHOS/MrQtv1mPqiqPsmgb+mlsx0kyX4MBmh8uUWRozAU9lJVfRG4g910si4HNbiy8WeA07rhg1uBPwZOZTAqadjH6NqQZ7gEODnJ6oaljtt+GaxBvvPnLbM85g+At3TNKcvJAcAHumG3dwBrgAu7fR9hcLY4s+nolxk0v25LchdwOTDR/S3d38rrgVO6IddfAD7A7F+I/gg4fMa2K7qm6VuBy6tqd315zXlFsySpt9y+tUiSngFDQZLUMxQkST1DQZLUMxQkST1DQStaktd3M1j+WHd/dTdMcqGO//4ka7rbv7NQx5VaMRS00q0HPkeD602S7FNVv1xVd3ebDAUteYaCVqwkBwCvAs5hlgvvkuyX5KruwqyPJfl8kulu3/okd2awtsZFQ8/5ZpJ3dXM/vaKbK386yTvp5s5KckV3RvIPSS7vJpO7IslpSW5K8qUkJ3bH+8EkH89grYL/3V1RLjVjKGglOwP426r6R+DrSWbO8/SrwDeqag3we3TzQCV5IXARg+mSjwd+Isnru+fsD3y+qo6rqs/tPFBVnc+u9TjO7jZPAe8Cfqz7+SUGIfUb7DqreAfwxW6ytN8BPrhA712alaGglWw9g+m/6f47swnpVTv3V9VdDKY1AfgJBgsPPVxVTwBXACd3+55kMGvsKO6vqju7mWa3An/XTZdwJ7B6qIYPdTV8BvihJAeO/A6leVrOk7lJu5XkBxl80z82SQH7AAU807Uwvj2PufC/M3T7qaH7T+HfpsbEMwWtVD8HfKiqjuhmej2cwVTPwxOV3cRgxTC6EUTHdtu/wGDis4O7KaDXA9eP8Jrf3YslOW8Ezu5qOJXBKmf/d57HkEZmKGilWs/3zvT61wzWoN7pfcAhSe4G/pBBE8+Oqvo/wPkM1iK+Hbi1qv7nCK+5EbgjyRXzqPNC4IRuBtJ3sgyn39bS4iyp0m50ZwHfV1Xf7tYW/jRwTFU9PubSpGZst5R2bz/gs12TT4BfNRC03HmmIEnq2acgSeoZCpKknqEgSeoZCpKknqEgSeoZCpKk3v8HPBdtiLUjBbwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "columns = ['InfTime', 'InfTimeS3', 'InfTimeS6']\n",
    "for c in columns:\n",
    "    csv = read_csv(\"InfTimeReport.csv\")\n",
    "    g = sbs.barplot(x=csv['Algoritmo'], y=csv[c])\n",
    "    g.set_yscale(\"log\")\n",
    "    plt.ylabel(c)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Memoria occupata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "columns = ['MemOccupata', 'MemOccupataS3', 'MemOccupataS6']\n",
    "for c in columns:   \n",
    "    csv = read_csv(\"MemOccupationReport.csv\")\n",
    "    g = sbs.barplot(x=csv['Algoritmo'], y=csv[c])\n",
    "    plt.ylabel(c)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNetwork(): \n",
    "    n = 100\n",
    "    model = Sequential(name=\"Sequential-NN\")\n",
    "    model.add(layers.Dense(X.shape[1], activation='relu', input_shape=(X.shape[1],)))\n",
    "    model.add(layers.Dense(np.unique(y).size * n, activation='relu'))\n",
    "    model.add(layers.Dense(np.unique(y).size, activation='softmax'))\n",
    "    learn_rate = 0.0001 if choosenIndex == 2 else 0.001\n",
    "    opt = Adam(learning_rate=learn_rate)\n",
    "    model.compile(optimizer=opt, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross-Validation NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 500\n",
    "BATCH_SIZE = 8\n",
    "num_folds = 10\n",
    "\n",
    "\n",
    "kf = StratifiedKFold(n_splits=num_folds, random_state=seed, shuffle=True)\n",
    "cv_results = np.array([])\n",
    "for train_idx, test_idx, in kf.split(X_train, y_train):\n",
    "    X_cross_train, y_cross_train = X_train[train_idx], y_train[train_idx]\n",
    "    X_cross_train = scaler.fit_transform(X_cross_train)\n",
    "    X_cross_test, y_cross_test = X_train[test_idx], y_train[test_idx]\n",
    "    X_cross_test = scaler.transform(X_cross_test)\n",
    "    model = getNetwork()\n",
    "    model.fit(X_cross_train, y_cross_train, epochs=EPOCHS, batch_size=BATCH_SIZE)  \n",
    "    y_pred = model.predict(X_cross_test)\n",
    "    predictions_categorical = np.argmax(y_pred, axis=1)\n",
    "    f1s = f1_score(y_cross_test, predictions_categorical, average=\"weighted\")\n",
    "    cv_results = np.append(cv_results, [f1s])\n",
    "\n",
    "print(f'Average score of Cross Validation: {cv_results.mean()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Sequential-NN\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 600)               19800     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 6)                 3606      \n",
      "=================================================================\n",
      "Total params: 24,462\n",
      "Trainable params: 24,462\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 325.5021 - accuracy: 0.1750 - val_loss: 98.1452 - val_accuracy: 0.1750\n",
      "Epoch 2/1000\n",
      "45/45 [==============================] - 0s 822us/step - loss: 68.1592 - accuracy: 0.1861 - val_loss: 64.9438 - val_accuracy: 0.2000\n",
      "Epoch 3/1000\n",
      "45/45 [==============================] - 0s 810us/step - loss: 43.4721 - accuracy: 0.1778 - val_loss: 36.8294 - val_accuracy: 0.1417\n",
      "Epoch 4/1000\n",
      "45/45 [==============================] - 0s 777us/step - loss: 24.0230 - accuracy: 0.1806 - val_loss: 15.3724 - val_accuracy: 0.1750\n",
      "Epoch 5/1000\n",
      "45/45 [==============================] - 0s 791us/step - loss: 10.5291 - accuracy: 0.2028 - val_loss: 7.1995 - val_accuracy: 0.1583\n",
      "Epoch 6/1000\n",
      "45/45 [==============================] - 0s 802us/step - loss: 6.7391 - accuracy: 0.1500 - val_loss: 7.4404 - val_accuracy: 0.1417\n",
      "Epoch 7/1000\n",
      "45/45 [==============================] - 0s 762us/step - loss: 4.5217 - accuracy: 0.1806 - val_loss: 3.3552 - val_accuracy: 0.1500\n",
      "Epoch 8/1000\n",
      "45/45 [==============================] - 0s 784us/step - loss: 2.5235 - accuracy: 0.1750 - val_loss: 2.5538 - val_accuracy: 0.1667\n",
      "Epoch 9/1000\n",
      "45/45 [==============================] - 0s 772us/step - loss: 2.1282 - accuracy: 0.1778 - val_loss: 2.4065 - val_accuracy: 0.1833\n",
      "Epoch 10/1000\n",
      "45/45 [==============================] - 0s 807us/step - loss: 2.2907 - accuracy: 0.2167 - val_loss: 2.5394 - val_accuracy: 0.1500\n",
      "Epoch 11/1000\n",
      "45/45 [==============================] - 0s 798us/step - loss: 2.3002 - accuracy: 0.1694 - val_loss: 2.1805 - val_accuracy: 0.1833\n",
      "Epoch 12/1000\n",
      "45/45 [==============================] - 0s 765us/step - loss: 2.2980 - accuracy: 0.2028 - val_loss: 1.9720 - val_accuracy: 0.2083\n",
      "Epoch 13/1000\n",
      "45/45 [==============================] - 0s 787us/step - loss: 1.8704 - accuracy: 0.1889 - val_loss: 2.0019 - val_accuracy: 0.3167\n",
      "Epoch 14/1000\n",
      "45/45 [==============================] - 0s 812us/step - loss: 1.8416 - accuracy: 0.2583 - val_loss: 1.9375 - val_accuracy: 0.1583\n",
      "Epoch 15/1000\n",
      "45/45 [==============================] - 0s 770us/step - loss: 2.1689 - accuracy: 0.1722 - val_loss: 2.2435 - val_accuracy: 0.1667\n",
      "Epoch 16/1000\n",
      "45/45 [==============================] - 0s 763us/step - loss: 1.9510 - accuracy: 0.1917 - val_loss: 1.8412 - val_accuracy: 0.1833\n",
      "Epoch 17/1000\n",
      "45/45 [==============================] - 0s 826us/step - loss: 1.9313 - accuracy: 0.2194 - val_loss: 1.8457 - val_accuracy: 0.1583\n",
      "Epoch 18/1000\n",
      "45/45 [==============================] - 0s 791us/step - loss: 1.8549 - accuracy: 0.2306 - val_loss: 1.8102 - val_accuracy: 0.2000\n",
      "Epoch 19/1000\n",
      "45/45 [==============================] - 0s 758us/step - loss: 1.9541 - accuracy: 0.1917 - val_loss: 2.2576 - val_accuracy: 0.3417\n",
      "Epoch 20/1000\n",
      "45/45 [==============================] - 0s 777us/step - loss: 1.8386 - accuracy: 0.2194 - val_loss: 1.6881 - val_accuracy: 0.2917\n",
      "Epoch 21/1000\n",
      "45/45 [==============================] - 0s 793us/step - loss: 1.7965 - accuracy: 0.2472 - val_loss: 1.6913 - val_accuracy: 0.2250\n",
      "Epoch 22/1000\n",
      "45/45 [==============================] - 0s 799us/step - loss: 1.8202 - accuracy: 0.1667 - val_loss: 1.8369 - val_accuracy: 0.1500\n",
      "Epoch 23/1000\n",
      "45/45 [==============================] - 0s 854us/step - loss: 1.7817 - accuracy: 0.1778 - val_loss: 1.7929 - val_accuracy: 0.1583\n",
      "Epoch 24/1000\n",
      "45/45 [==============================] - 0s 770us/step - loss: 1.7763 - accuracy: 0.1778 - val_loss: 1.8586 - val_accuracy: 0.1500\n",
      "Epoch 25/1000\n",
      "45/45 [==============================] - 0s 785us/step - loss: 1.7770 - accuracy: 0.1778 - val_loss: 1.7752 - val_accuracy: 0.1583\n",
      "Epoch 26/1000\n",
      "45/45 [==============================] - 0s 752us/step - loss: 1.7599 - accuracy: 0.1778 - val_loss: 1.7716 - val_accuracy: 0.1583\n",
      "Epoch 27/1000\n",
      "45/45 [==============================] - 0s 791us/step - loss: 1.7774 - accuracy: 0.1861 - val_loss: 1.7834 - val_accuracy: 0.1500\n",
      "Epoch 28/1000\n",
      "45/45 [==============================] - 0s 816us/step - loss: 1.7617 - accuracy: 0.1806 - val_loss: 1.7807 - val_accuracy: 0.1500\n",
      "Epoch 29/1000\n",
      "45/45 [==============================] - 0s 779us/step - loss: 1.7611 - accuracy: 0.1889 - val_loss: 1.7818 - val_accuracy: 0.1500\n",
      "Epoch 30/1000\n",
      "45/45 [==============================] - 0s 769us/step - loss: 1.7610 - accuracy: 0.1611 - val_loss: 1.7808 - val_accuracy: 0.1500\n",
      "Epoch 31/1000\n",
      "45/45 [==============================] - 0s 803us/step - loss: 1.7607 - accuracy: 0.1889 - val_loss: 1.7814 - val_accuracy: 0.1500\n",
      "Epoch 32/1000\n",
      "45/45 [==============================] - 0s 801us/step - loss: 1.7608 - accuracy: 0.1889 - val_loss: 1.7799 - val_accuracy: 0.1500\n",
      "Epoch 33/1000\n",
      "45/45 [==============================] - 0s 773us/step - loss: 1.7596 - accuracy: 0.1889 - val_loss: 1.7818 - val_accuracy: 0.1500\n",
      "Epoch 34/1000\n",
      "45/45 [==============================] - 0s 770us/step - loss: 1.7606 - accuracy: 0.1889 - val_loss: 1.7811 - val_accuracy: 0.1500\n",
      "Epoch 35/1000\n",
      "45/45 [==============================] - 0s 921us/step - loss: 1.7612 - accuracy: 0.1417 - val_loss: 1.7802 - val_accuracy: 0.1500\n",
      "Epoch 36/1000\n",
      "45/45 [==============================] - 0s 759us/step - loss: 1.7613 - accuracy: 0.1917 - val_loss: 1.7813 - val_accuracy: 0.1500\n",
      "Epoch 37/1000\n",
      "45/45 [==============================] - 0s 844us/step - loss: 1.7620 - accuracy: 0.1444 - val_loss: 1.7821 - val_accuracy: 0.1500\n",
      "Epoch 38/1000\n",
      "45/45 [==============================] - 0s 797us/step - loss: 1.7600 - accuracy: 0.1917 - val_loss: 1.7816 - val_accuracy: 0.1500\n",
      "Epoch 39/1000\n",
      "45/45 [==============================] - 0s 806us/step - loss: 1.7617 - accuracy: 0.1306 - val_loss: 1.7813 - val_accuracy: 0.1500\n",
      "Epoch 40/1000\n",
      "45/45 [==============================] - 0s 780us/step - loss: 1.7602 - accuracy: 0.1917 - val_loss: 1.7826 - val_accuracy: 0.1500\n",
      "Epoch 41/1000\n",
      "45/45 [==============================] - 0s 842us/step - loss: 1.7610 - accuracy: 0.1917 - val_loss: 1.7810 - val_accuracy: 0.1500\n",
      "Epoch 42/1000\n",
      "45/45 [==============================] - 0s 793us/step - loss: 1.7596 - accuracy: 0.1917 - val_loss: 1.7812 - val_accuracy: 0.1500\n",
      "Epoch 43/1000\n",
      "45/45 [==============================] - 0s 791us/step - loss: 1.7601 - accuracy: 0.1917 - val_loss: 1.7811 - val_accuracy: 0.1500\n",
      "Epoch 44/1000\n",
      "45/45 [==============================] - 0s 809us/step - loss: 1.7605 - accuracy: 0.1750 - val_loss: 1.7802 - val_accuracy: 0.1500\n",
      "Epoch 45/1000\n",
      "45/45 [==============================] - 0s 781us/step - loss: 1.7606 - accuracy: 0.1917 - val_loss: 1.7818 - val_accuracy: 0.1500\n",
      "Epoch 46/1000\n",
      "45/45 [==============================] - 0s 795us/step - loss: 1.7601 - accuracy: 0.1917 - val_loss: 1.7805 - val_accuracy: 0.1500\n",
      "Epoch 47/1000\n",
      "45/45 [==============================] - 0s 780us/step - loss: 1.7604 - accuracy: 0.1917 - val_loss: 1.7801 - val_accuracy: 0.1500\n",
      "Epoch 48/1000\n",
      "45/45 [==============================] - 0s 769us/step - loss: 1.7594 - accuracy: 0.1917 - val_loss: 1.7809 - val_accuracy: 0.1500\n",
      "Epoch 49/1000\n",
      "45/45 [==============================] - 0s 776us/step - loss: 1.7600 - accuracy: 0.1917 - val_loss: 1.7803 - val_accuracy: 0.1500\n",
      "Epoch 50/1000\n",
      "45/45 [==============================] - 0s 745us/step - loss: 1.7593 - accuracy: 0.1917 - val_loss: 1.7815 - val_accuracy: 0.1500\n",
      "Epoch 51/1000\n",
      "45/45 [==============================] - 0s 861us/step - loss: 1.7583 - accuracy: 0.1806 - val_loss: 1.7818 - val_accuracy: 0.1500\n",
      "Epoch 52/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 0s 797us/step - loss: 1.7587 - accuracy: 0.1917 - val_loss: 1.7822 - val_accuracy: 0.1500\n",
      "Epoch 53/1000\n",
      "45/45 [==============================] - 0s 794us/step - loss: 1.7567 - accuracy: 0.1917 - val_loss: 1.7813 - val_accuracy: 0.1500\n",
      "Epoch 54/1000\n",
      "45/45 [==============================] - 0s 753us/step - loss: 1.7567 - accuracy: 0.1917 - val_loss: 1.7803 - val_accuracy: 0.1500\n",
      "Epoch 55/1000\n",
      "45/45 [==============================] - 0s 776us/step - loss: 1.7567 - accuracy: 0.1444 - val_loss: 1.7813 - val_accuracy: 0.1500\n",
      "Epoch 56/1000\n",
      "45/45 [==============================] - 0s 781us/step - loss: 1.7559 - accuracy: 0.1917 - val_loss: 1.7798 - val_accuracy: 0.1500\n",
      "Epoch 57/1000\n",
      "45/45 [==============================] - 0s 774us/step - loss: 1.7569 - accuracy: 0.1917 - val_loss: 1.7804 - val_accuracy: 0.1500\n",
      "Epoch 58/1000\n",
      "45/45 [==============================] - 0s 772us/step - loss: 1.7557 - accuracy: 0.1917 - val_loss: 1.7811 - val_accuracy: 0.1500\n",
      "Epoch 59/1000\n",
      "45/45 [==============================] - 0s 775us/step - loss: 1.7565 - accuracy: 0.1917 - val_loss: 1.7813 - val_accuracy: 0.1500\n",
      "Epoch 60/1000\n",
      "45/45 [==============================] - 0s 797us/step - loss: 1.7555 - accuracy: 0.1917 - val_loss: 1.7818 - val_accuracy: 0.1500\n",
      "Epoch 61/1000\n",
      "45/45 [==============================] - 0s 749us/step - loss: 1.7568 - accuracy: 0.1917 - val_loss: 1.7797 - val_accuracy: 0.1500\n",
      "Epoch 62/1000\n",
      "45/45 [==============================] - 0s 770us/step - loss: 1.7564 - accuracy: 0.1917 - val_loss: 1.7810 - val_accuracy: 0.1500\n",
      "Epoch 63/1000\n",
      "45/45 [==============================] - 0s 788us/step - loss: 1.7719 - accuracy: 0.1944 - val_loss: 1.8364 - val_accuracy: 0.1250\n",
      "Epoch 64/1000\n",
      "45/45 [==============================] - 0s 782us/step - loss: 1.7644 - accuracy: 0.1889 - val_loss: 1.7800 - val_accuracy: 0.1500\n",
      "Epoch 65/1000\n",
      "45/45 [==============================] - 0s 780us/step - loss: 1.7616 - accuracy: 0.1583 - val_loss: 1.7795 - val_accuracy: 0.1500\n",
      "Epoch 66/1000\n",
      "45/45 [==============================] - 0s 770us/step - loss: 1.7619 - accuracy: 0.1889 - val_loss: 1.7797 - val_accuracy: 0.1500\n",
      "Epoch 67/1000\n",
      "45/45 [==============================] - 0s 790us/step - loss: 1.7615 - accuracy: 0.1917 - val_loss: 1.7828 - val_accuracy: 0.1500\n",
      "Epoch 68/1000\n",
      "45/45 [==============================] - 0s 805us/step - loss: 1.7603 - accuracy: 0.1889 - val_loss: 1.7813 - val_accuracy: 0.1500\n",
      "Epoch 69/1000\n",
      "45/45 [==============================] - 0s 806us/step - loss: 1.7624 - accuracy: 0.1889 - val_loss: 1.7793 - val_accuracy: 0.1500\n",
      "Epoch 70/1000\n",
      "45/45 [==============================] - 0s 775us/step - loss: 1.7618 - accuracy: 0.1889 - val_loss: 1.7809 - val_accuracy: 0.1500\n",
      "Epoch 71/1000\n",
      "45/45 [==============================] - 0s 770us/step - loss: 1.7605 - accuracy: 0.1889 - val_loss: 1.7812 - val_accuracy: 0.1500\n",
      "Epoch 72/1000\n",
      "45/45 [==============================] - 0s 777us/step - loss: 1.7617 - accuracy: 0.1667 - val_loss: 1.7829 - val_accuracy: 0.1500\n",
      "Epoch 73/1000\n",
      "45/45 [==============================] - 0s 791us/step - loss: 1.7617 - accuracy: 0.1667 - val_loss: 1.7822 - val_accuracy: 0.1500\n",
      "Epoch 74/1000\n",
      "45/45 [==============================] - 0s 792us/step - loss: 1.7616 - accuracy: 0.1889 - val_loss: 1.7819 - val_accuracy: 0.1500\n",
      "Epoch 75/1000\n",
      "45/45 [==============================] - 0s 791us/step - loss: 1.7673 - accuracy: 0.1861 - val_loss: 1.7808 - val_accuracy: 0.1500\n",
      "Epoch 76/1000\n",
      "45/45 [==============================] - 0s 794us/step - loss: 1.7678 - accuracy: 0.1861 - val_loss: 1.7810 - val_accuracy: 0.1500\n",
      "Epoch 77/1000\n",
      "45/45 [==============================] - 0s 800us/step - loss: 1.7681 - accuracy: 0.1861 - val_loss: 1.7822 - val_accuracy: 0.1500\n",
      "Epoch 78/1000\n",
      "45/45 [==============================] - 0s 800us/step - loss: 1.7681 - accuracy: 0.1694 - val_loss: 1.7828 - val_accuracy: 0.1500\n",
      "Epoch 79/1000\n",
      "45/45 [==============================] - 0s 773us/step - loss: 1.7685 - accuracy: 0.1778 - val_loss: 1.7824 - val_accuracy: 0.1500\n",
      "Epoch 80/1000\n",
      "45/45 [==============================] - 0s 768us/step - loss: 1.7676 - accuracy: 0.1667 - val_loss: 1.7825 - val_accuracy: 0.1500\n",
      "Epoch 81/1000\n",
      "45/45 [==============================] - 0s 793us/step - loss: 1.7676 - accuracy: 0.1806 - val_loss: 1.7816 - val_accuracy: 0.1500\n",
      "Epoch 82/1000\n",
      "45/45 [==============================] - 0s 793us/step - loss: 1.7684 - accuracy: 0.1861 - val_loss: 1.7836 - val_accuracy: 0.1500\n",
      "Epoch 83/1000\n",
      "45/45 [==============================] - 0s 794us/step - loss: 1.7677 - accuracy: 0.1861 - val_loss: 1.7819 - val_accuracy: 0.1500\n",
      "Epoch 84/1000\n",
      "45/45 [==============================] - 0s 804us/step - loss: 1.7681 - accuracy: 0.1861 - val_loss: 1.7815 - val_accuracy: 0.1500\n",
      "Epoch 85/1000\n",
      "45/45 [==============================] - 0s 798us/step - loss: 1.7676 - accuracy: 0.1861 - val_loss: 1.7828 - val_accuracy: 0.1500\n",
      "Epoch 86/1000\n",
      "45/45 [==============================] - 0s 810us/step - loss: 1.7676 - accuracy: 0.1722 - val_loss: 1.7823 - val_accuracy: 0.1500\n",
      "Epoch 87/1000\n",
      "45/45 [==============================] - 0s 787us/step - loss: 1.7685 - accuracy: 0.1833 - val_loss: 1.7822 - val_accuracy: 0.1500\n",
      "Epoch 88/1000\n",
      "45/45 [==============================] - 0s 815us/step - loss: 1.7673 - accuracy: 0.1861 - val_loss: 1.7829 - val_accuracy: 0.1500\n",
      "Epoch 89/1000\n",
      "45/45 [==============================] - 0s 793us/step - loss: 1.7682 - accuracy: 0.1583 - val_loss: 1.7822 - val_accuracy: 0.1500\n",
      "Epoch 90/1000\n",
      "45/45 [==============================] - 0s 809us/step - loss: 1.7679 - accuracy: 0.1694 - val_loss: 1.7822 - val_accuracy: 0.1500\n",
      "Epoch 91/1000\n",
      "45/45 [==============================] - 0s 806us/step - loss: 1.7677 - accuracy: 0.1694 - val_loss: 1.7820 - val_accuracy: 0.1500\n",
      "Epoch 92/1000\n",
      "45/45 [==============================] - 0s 795us/step - loss: 1.7675 - accuracy: 0.1861 - val_loss: 1.7809 - val_accuracy: 0.1500\n",
      "Epoch 93/1000\n",
      "45/45 [==============================] - 0s 781us/step - loss: 1.7688 - accuracy: 0.1528 - val_loss: 1.7827 - val_accuracy: 0.1500\n",
      "Epoch 94/1000\n",
      "45/45 [==============================] - 0s 810us/step - loss: 1.7688 - accuracy: 0.1444 - val_loss: 1.7826 - val_accuracy: 0.1500\n",
      "Epoch 95/1000\n",
      "45/45 [==============================] - 0s 764us/step - loss: 1.7679 - accuracy: 0.1278 - val_loss: 1.7809 - val_accuracy: 0.1500\n",
      "Epoch 96/1000\n",
      "45/45 [==============================] - 0s 804us/step - loss: 1.7673 - accuracy: 0.1611 - val_loss: 1.7816 - val_accuracy: 0.1500\n",
      "Epoch 97/1000\n",
      "45/45 [==============================] - 0s 796us/step - loss: 1.7686 - accuracy: 0.1861 - val_loss: 1.7825 - val_accuracy: 0.1500\n",
      "Epoch 98/1000\n",
      "45/45 [==============================] - 0s 856us/step - loss: 1.7681 - accuracy: 0.1861 - val_loss: 1.7812 - val_accuracy: 0.1500\n",
      "Epoch 99/1000\n",
      "45/45 [==============================] - 0s 787us/step - loss: 1.7677 - accuracy: 0.1861 - val_loss: 1.7816 - val_accuracy: 0.1500\n",
      "Epoch 100/1000\n",
      "45/45 [==============================] - 0s 768us/step - loss: 1.7679 - accuracy: 0.1778 - val_loss: 1.7821 - val_accuracy: 0.1500\n",
      "Epoch 101/1000\n",
      "45/45 [==============================] - 0s 777us/step - loss: 1.7678 - accuracy: 0.1806 - val_loss: 1.7823 - val_accuracy: 0.1500\n",
      "Epoch 102/1000\n",
      "45/45 [==============================] - 0s 790us/step - loss: 1.7682 - accuracy: 0.1722 - val_loss: 1.7823 - val_accuracy: 0.1500\n",
      "Epoch 103/1000\n",
      "45/45 [==============================] - 0s 813us/step - loss: 1.7678 - accuracy: 0.1778 - val_loss: 1.7839 - val_accuracy: 0.1500\n",
      "Epoch 104/1000\n",
      "45/45 [==============================] - 0s 785us/step - loss: 1.7686 - accuracy: 0.1667 - val_loss: 1.7815 - val_accuracy: 0.1500\n",
      "Epoch 105/1000\n",
      "45/45 [==============================] - 0s 782us/step - loss: 1.7681 - accuracy: 0.1861 - val_loss: 1.7830 - val_accuracy: 0.1500\n",
      "Epoch 106/1000\n",
      "45/45 [==============================] - 0s 779us/step - loss: 1.7675 - accuracy: 0.1861 - val_loss: 1.7826 - val_accuracy: 0.1500\n",
      "Epoch 107/1000\n",
      "45/45 [==============================] - 0s 789us/step - loss: 1.7674 - accuracy: 0.1861 - val_loss: 1.7814 - val_accuracy: 0.1500\n",
      "Epoch 108/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 0s 781us/step - loss: 1.7679 - accuracy: 0.1722 - val_loss: 1.7820 - val_accuracy: 0.1500\n",
      "Epoch 109/1000\n",
      "45/45 [==============================] - 0s 798us/step - loss: 1.7677 - accuracy: 0.1583 - val_loss: 1.7821 - val_accuracy: 0.1500\n",
      "Epoch 110/1000\n",
      "45/45 [==============================] - 0s 804us/step - loss: 1.7683 - accuracy: 0.1861 - val_loss: 1.7823 - val_accuracy: 0.1500\n",
      "Epoch 111/1000\n",
      "45/45 [==============================] - 0s 814us/step - loss: 1.7692 - accuracy: 0.1472 - val_loss: 1.7832 - val_accuracy: 0.1500\n",
      "Epoch 112/1000\n",
      "45/45 [==============================] - 0s 781us/step - loss: 1.7677 - accuracy: 0.1722 - val_loss: 1.7813 - val_accuracy: 0.1500\n",
      "Epoch 113/1000\n",
      "45/45 [==============================] - 0s 779us/step - loss: 1.7679 - accuracy: 0.1556 - val_loss: 1.7810 - val_accuracy: 0.1500\n",
      "Epoch 114/1000\n",
      "45/45 [==============================] - 0s 760us/step - loss: 1.7688 - accuracy: 0.1611 - val_loss: 1.7839 - val_accuracy: 0.1500\n",
      "Epoch 115/1000\n",
      "45/45 [==============================] - 0s 787us/step - loss: 1.7675 - accuracy: 0.1861 - val_loss: 1.7827 - val_accuracy: 0.1500\n",
      "Epoch 116/1000\n",
      "45/45 [==============================] - 0s 792us/step - loss: 1.7678 - accuracy: 0.1861 - val_loss: 1.7821 - val_accuracy: 0.1500\n",
      "Epoch 117/1000\n",
      "45/45 [==============================] - 0s 789us/step - loss: 1.7682 - accuracy: 0.1722 - val_loss: 1.7823 - val_accuracy: 0.1500\n",
      "Epoch 118/1000\n",
      "45/45 [==============================] - 0s 784us/step - loss: 1.7679 - accuracy: 0.1833 - val_loss: 1.7811 - val_accuracy: 0.1500\n",
      "Epoch 119/1000\n",
      "45/45 [==============================] - 0s 776us/step - loss: 1.7678 - accuracy: 0.1694 - val_loss: 1.7829 - val_accuracy: 0.1500\n",
      "Epoch 120/1000\n",
      "45/45 [==============================] - 0s 789us/step - loss: 1.7679 - accuracy: 0.1778 - val_loss: 1.7826 - val_accuracy: 0.1500\n",
      "Epoch 121/1000\n",
      "45/45 [==============================] - 0s 770us/step - loss: 1.7679 - accuracy: 0.1861 - val_loss: 1.7825 - val_accuracy: 0.1500\n",
      "Epoch 122/1000\n",
      "45/45 [==============================] - 0s 771us/step - loss: 1.7679 - accuracy: 0.1861 - val_loss: 1.7814 - val_accuracy: 0.1500\n",
      "Epoch 123/1000\n",
      "45/45 [==============================] - 0s 779us/step - loss: 1.7679 - accuracy: 0.1611 - val_loss: 1.7817 - val_accuracy: 0.1500\n",
      "Epoch 124/1000\n",
      "45/45 [==============================] - 0s 766us/step - loss: 1.7679 - accuracy: 0.1639 - val_loss: 1.7826 - val_accuracy: 0.1500\n",
      "Epoch 125/1000\n",
      "45/45 [==============================] - 0s 751us/step - loss: 1.7675 - accuracy: 0.1583 - val_loss: 1.7826 - val_accuracy: 0.1500\n",
      "Epoch 126/1000\n",
      "45/45 [==============================] - 0s 754us/step - loss: 1.7683 - accuracy: 0.1667 - val_loss: 1.7820 - val_accuracy: 0.1500\n",
      "Epoch 127/1000\n",
      "45/45 [==============================] - 0s 796us/step - loss: 1.7679 - accuracy: 0.1861 - val_loss: 1.7820 - val_accuracy: 0.1500\n",
      "Epoch 128/1000\n",
      "45/45 [==============================] - 0s 934us/step - loss: 1.7677 - accuracy: 0.1861 - val_loss: 1.7822 - val_accuracy: 0.1500\n",
      "Epoch 129/1000\n",
      "45/45 [==============================] - 0s 788us/step - loss: 1.7679 - accuracy: 0.1750 - val_loss: 1.7829 - val_accuracy: 0.1500\n",
      "Epoch 130/1000\n",
      "45/45 [==============================] - 0s 762us/step - loss: 1.7677 - accuracy: 0.1667 - val_loss: 1.7833 - val_accuracy: 0.1500\n",
      "Epoch 131/1000\n",
      "45/45 [==============================] - 0s 804us/step - loss: 1.7681 - accuracy: 0.1861 - val_loss: 1.7830 - val_accuracy: 0.1500\n",
      "Epoch 132/1000\n",
      "45/45 [==============================] - 0s 788us/step - loss: 1.7683 - accuracy: 0.1583 - val_loss: 1.7814 - val_accuracy: 0.1500\n",
      "Epoch 133/1000\n",
      "45/45 [==============================] - 0s 785us/step - loss: 1.7684 - accuracy: 0.1861 - val_loss: 1.7825 - val_accuracy: 0.1500\n",
      "Epoch 134/1000\n",
      "45/45 [==============================] - 0s 794us/step - loss: 1.7680 - accuracy: 0.1417 - val_loss: 1.7824 - val_accuracy: 0.1500\n",
      "Epoch 135/1000\n",
      "45/45 [==============================] - 0s 786us/step - loss: 1.7680 - accuracy: 0.1667 - val_loss: 1.7832 - val_accuracy: 0.1500\n",
      "Epoch 136/1000\n",
      "45/45 [==============================] - 0s 820us/step - loss: 1.7680 - accuracy: 0.1722 - val_loss: 1.7837 - val_accuracy: 0.1500\n",
      "Epoch 137/1000\n",
      "45/45 [==============================] - 0s 830us/step - loss: 1.7681 - accuracy: 0.1861 - val_loss: 1.7813 - val_accuracy: 0.1500\n",
      "Epoch 138/1000\n",
      "45/45 [==============================] - 0s 761us/step - loss: 1.7693 - accuracy: 0.1583 - val_loss: 1.7815 - val_accuracy: 0.1500\n",
      "Epoch 139/1000\n",
      "45/45 [==============================] - 0s 777us/step - loss: 1.7677 - accuracy: 0.1611 - val_loss: 1.7827 - val_accuracy: 0.1500\n",
      "Epoch 140/1000\n",
      "45/45 [==============================] - 0s 803us/step - loss: 1.7679 - accuracy: 0.1861 - val_loss: 1.7813 - val_accuracy: 0.1500\n",
      "Epoch 141/1000\n",
      "45/45 [==============================] - 0s 763us/step - loss: 1.7680 - accuracy: 0.1861 - val_loss: 1.7831 - val_accuracy: 0.1500\n",
      "Epoch 142/1000\n",
      "45/45 [==============================] - 0s 799us/step - loss: 1.7679 - accuracy: 0.1667 - val_loss: 1.7825 - val_accuracy: 0.1500\n",
      "Epoch 143/1000\n",
      "45/45 [==============================] - 0s 765us/step - loss: 1.7677 - accuracy: 0.1722 - val_loss: 1.7829 - val_accuracy: 0.1500\n",
      "Epoch 144/1000\n",
      "45/45 [==============================] - 0s 775us/step - loss: 1.7676 - accuracy: 0.1778 - val_loss: 1.7817 - val_accuracy: 0.1500\n",
      "Epoch 145/1000\n",
      "45/45 [==============================] - 0s 783us/step - loss: 1.7682 - accuracy: 0.1694 - val_loss: 1.7823 - val_accuracy: 0.1500\n",
      "Epoch 146/1000\n",
      "45/45 [==============================] - 0s 796us/step - loss: 1.7679 - accuracy: 0.1861 - val_loss: 1.7834 - val_accuracy: 0.1500\n",
      "Epoch 147/1000\n",
      "45/45 [==============================] - 0s 769us/step - loss: 1.7687 - accuracy: 0.1639 - val_loss: 1.7815 - val_accuracy: 0.1500\n",
      "Epoch 148/1000\n",
      "45/45 [==============================] - 0s 777us/step - loss: 1.7685 - accuracy: 0.1833 - val_loss: 1.7835 - val_accuracy: 0.1500\n",
      "Epoch 149/1000\n",
      "45/45 [==============================] - 0s 799us/step - loss: 1.7677 - accuracy: 0.1750 - val_loss: 1.7807 - val_accuracy: 0.1500\n",
      "Epoch 150/1000\n",
      "45/45 [==============================] - 0s 796us/step - loss: 1.7690 - accuracy: 0.1861 - val_loss: 1.7814 - val_accuracy: 0.1500\n",
      "Epoch 151/1000\n",
      "45/45 [==============================] - 0s 764us/step - loss: 1.7685 - accuracy: 0.1861 - val_loss: 1.7816 - val_accuracy: 0.1500\n",
      "Epoch 152/1000\n",
      "45/45 [==============================] - 0s 791us/step - loss: 1.7678 - accuracy: 0.1667 - val_loss: 1.7820 - val_accuracy: 0.1500\n",
      "Epoch 153/1000\n",
      "45/45 [==============================] - 0s 773us/step - loss: 1.7675 - accuracy: 0.1528 - val_loss: 1.7827 - val_accuracy: 0.1500\n",
      "Epoch 154/1000\n",
      "45/45 [==============================] - 0s 788us/step - loss: 1.7671 - accuracy: 0.1778 - val_loss: 1.7828 - val_accuracy: 0.1500\n",
      "Epoch 155/1000\n",
      "45/45 [==============================] - 0s 785us/step - loss: 1.7683 - accuracy: 0.1528 - val_loss: 1.7813 - val_accuracy: 0.1500\n",
      "Epoch 156/1000\n",
      "45/45 [==============================] - 0s 777us/step - loss: 1.7681 - accuracy: 0.1500 - val_loss: 1.7824 - val_accuracy: 0.1500\n",
      "Epoch 157/1000\n",
      "45/45 [==============================] - 0s 788us/step - loss: 1.7677 - accuracy: 0.1639 - val_loss: 1.7812 - val_accuracy: 0.1500\n",
      "Epoch 158/1000\n",
      "45/45 [==============================] - 0s 793us/step - loss: 1.7673 - accuracy: 0.1861 - val_loss: 1.7812 - val_accuracy: 0.1500\n",
      "Epoch 159/1000\n",
      "45/45 [==============================] - 0s 785us/step - loss: 1.7682 - accuracy: 0.1639 - val_loss: 1.7831 - val_accuracy: 0.1500\n",
      "Epoch 160/1000\n",
      "45/45 [==============================] - 0s 773us/step - loss: 1.7685 - accuracy: 0.1417 - val_loss: 1.7817 - val_accuracy: 0.1500\n",
      "Epoch 161/1000\n",
      "45/45 [==============================] - 0s 794us/step - loss: 1.7683 - accuracy: 0.1417 - val_loss: 1.7813 - val_accuracy: 0.1500\n",
      "Epoch 162/1000\n",
      "45/45 [==============================] - 0s 752us/step - loss: 1.7677 - accuracy: 0.1861 - val_loss: 1.7814 - val_accuracy: 0.1500\n",
      "Epoch 163/1000\n",
      "45/45 [==============================] - 0s 785us/step - loss: 1.7677 - accuracy: 0.1861 - val_loss: 1.7841 - val_accuracy: 0.1500\n",
      "Epoch 164/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 0s 797us/step - loss: 1.7679 - accuracy: 0.1583 - val_loss: 1.7819 - val_accuracy: 0.1500\n",
      "Epoch 165/1000\n",
      "45/45 [==============================] - 0s 767us/step - loss: 1.7686 - accuracy: 0.1861 - val_loss: 1.7821 - val_accuracy: 0.1500\n",
      "Epoch 166/1000\n",
      "45/45 [==============================] - 0s 774us/step - loss: 1.7675 - accuracy: 0.1861 - val_loss: 1.7818 - val_accuracy: 0.1500\n",
      "Epoch 167/1000\n",
      "45/45 [==============================] - 0s 787us/step - loss: 1.7679 - accuracy: 0.1861 - val_loss: 1.7832 - val_accuracy: 0.1500\n",
      "Epoch 168/1000\n",
      "45/45 [==============================] - 0s 781us/step - loss: 1.7685 - accuracy: 0.1472 - val_loss: 1.7822 - val_accuracy: 0.1500\n",
      "Epoch 169/1000\n",
      "45/45 [==============================] - 0s 892us/step - loss: 1.7676 - accuracy: 0.1750 - val_loss: 1.7835 - val_accuracy: 0.1500\n",
      "Epoch 170/1000\n",
      "45/45 [==============================] - 0s 816us/step - loss: 1.7675 - accuracy: 0.1861 - val_loss: 1.7819 - val_accuracy: 0.1500\n",
      "Epoch 171/1000\n",
      "45/45 [==============================] - 0s 778us/step - loss: 1.7678 - accuracy: 0.1639 - val_loss: 1.7822 - val_accuracy: 0.1500\n",
      "Epoch 172/1000\n",
      "45/45 [==============================] - 0s 830us/step - loss: 1.7681 - accuracy: 0.1833 - val_loss: 1.7814 - val_accuracy: 0.1500\n",
      "Epoch 173/1000\n",
      "45/45 [==============================] - 0s 778us/step - loss: 1.7680 - accuracy: 0.1861 - val_loss: 1.7820 - val_accuracy: 0.1500\n",
      "Epoch 174/1000\n",
      "45/45 [==============================] - 0s 817us/step - loss: 1.7675 - accuracy: 0.1861 - val_loss: 1.7817 - val_accuracy: 0.1500\n",
      "Epoch 175/1000\n",
      "45/45 [==============================] - 0s 781us/step - loss: 1.7686 - accuracy: 0.1444 - val_loss: 1.7830 - val_accuracy: 0.1500\n",
      "Epoch 176/1000\n",
      "45/45 [==============================] - 0s 811us/step - loss: 1.7675 - accuracy: 0.1694 - val_loss: 1.7829 - val_accuracy: 0.1500\n",
      "Epoch 177/1000\n",
      "45/45 [==============================] - 0s 785us/step - loss: 1.7684 - accuracy: 0.1861 - val_loss: 1.7820 - val_accuracy: 0.1500\n",
      "Epoch 178/1000\n",
      "45/45 [==============================] - 0s 806us/step - loss: 1.7676 - accuracy: 0.1694 - val_loss: 1.7820 - val_accuracy: 0.1500\n",
      "Epoch 179/1000\n",
      "45/45 [==============================] - 0s 785us/step - loss: 1.7680 - accuracy: 0.1889 - val_loss: 1.7812 - val_accuracy: 0.1500\n",
      "Epoch 180/1000\n",
      "45/45 [==============================] - 0s 763us/step - loss: 1.7679 - accuracy: 0.1861 - val_loss: 1.7819 - val_accuracy: 0.1500\n",
      "Epoch 181/1000\n",
      "45/45 [==============================] - 0s 815us/step - loss: 1.7681 - accuracy: 0.1639 - val_loss: 1.7825 - val_accuracy: 0.1500\n",
      "Epoch 182/1000\n",
      "45/45 [==============================] - 0s 800us/step - loss: 1.7684 - accuracy: 0.1417 - val_loss: 1.7822 - val_accuracy: 0.1500\n",
      "Epoch 183/1000\n",
      "45/45 [==============================] - 0s 778us/step - loss: 1.7673 - accuracy: 0.1833 - val_loss: 1.7825 - val_accuracy: 0.1500\n",
      "Epoch 184/1000\n",
      "45/45 [==============================] - 0s 799us/step - loss: 1.7672 - accuracy: 0.1861 - val_loss: 1.7832 - val_accuracy: 0.1500\n",
      "Epoch 185/1000\n",
      "45/45 [==============================] - 0s 803us/step - loss: 1.7681 - accuracy: 0.1583 - val_loss: 1.7820 - val_accuracy: 0.1500\n",
      "Epoch 186/1000\n",
      "45/45 [==============================] - 0s 809us/step - loss: 1.7671 - accuracy: 0.1861 - val_loss: 1.7823 - val_accuracy: 0.1500\n",
      "Epoch 187/1000\n",
      "45/45 [==============================] - 0s 804us/step - loss: 1.7676 - accuracy: 0.1667 - val_loss: 1.7818 - val_accuracy: 0.1500\n",
      "Epoch 188/1000\n",
      "45/45 [==============================] - 0s 804us/step - loss: 1.7682 - accuracy: 0.1861 - val_loss: 1.7826 - val_accuracy: 0.1500\n",
      "Epoch 189/1000\n",
      "45/45 [==============================] - 0s 806us/step - loss: 1.7677 - accuracy: 0.1861 - val_loss: 1.7820 - val_accuracy: 0.1500\n",
      "Epoch 190/1000\n",
      "45/45 [==============================] - 0s 799us/step - loss: 1.7677 - accuracy: 0.1861 - val_loss: 1.7808 - val_accuracy: 0.1500\n",
      "Epoch 191/1000\n",
      "45/45 [==============================] - 0s 789us/step - loss: 1.7674 - accuracy: 0.1694 - val_loss: 1.7819 - val_accuracy: 0.1500\n",
      "Epoch 192/1000\n",
      "45/45 [==============================] - 0s 809us/step - loss: 1.7674 - accuracy: 0.1861 - val_loss: 1.7821 - val_accuracy: 0.1500\n",
      "Epoch 193/1000\n",
      "45/45 [==============================] - 0s 778us/step - loss: 1.7677 - accuracy: 0.1722 - val_loss: 1.7823 - val_accuracy: 0.1500\n",
      "Epoch 194/1000\n",
      "45/45 [==============================] - 0s 820us/step - loss: 1.7683 - accuracy: 0.1889 - val_loss: 1.7819 - val_accuracy: 0.1500\n",
      "Epoch 195/1000\n",
      "45/45 [==============================] - 0s 814us/step - loss: 1.7683 - accuracy: 0.1861 - val_loss: 1.7817 - val_accuracy: 0.1500\n",
      "Epoch 196/1000\n",
      "45/45 [==============================] - 0s 817us/step - loss: 1.7684 - accuracy: 0.1861 - val_loss: 1.7826 - val_accuracy: 0.1500\n",
      "Epoch 197/1000\n",
      "45/45 [==============================] - 0s 806us/step - loss: 1.7678 - accuracy: 0.1750 - val_loss: 1.7829 - val_accuracy: 0.1500\n",
      "Epoch 198/1000\n",
      "45/45 [==============================] - 0s 756us/step - loss: 1.7677 - accuracy: 0.1722 - val_loss: 1.7814 - val_accuracy: 0.1500\n",
      "Epoch 199/1000\n",
      "45/45 [==============================] - 0s 812us/step - loss: 1.7676 - accuracy: 0.1722 - val_loss: 1.7821 - val_accuracy: 0.1500\n",
      "Epoch 200/1000\n",
      "45/45 [==============================] - 0s 846us/step - loss: 1.7678 - accuracy: 0.1861 - val_loss: 1.7813 - val_accuracy: 0.1500\n",
      "Epoch 201/1000\n",
      "45/45 [==============================] - 0s 796us/step - loss: 1.7679 - accuracy: 0.1861 - val_loss: 1.7829 - val_accuracy: 0.1500\n",
      "Epoch 202/1000\n",
      "45/45 [==============================] - 0s 781us/step - loss: 1.7672 - accuracy: 0.1806 - val_loss: 1.7836 - val_accuracy: 0.1500\n",
      "Epoch 203/1000\n",
      "45/45 [==============================] - 0s 766us/step - loss: 1.7685 - accuracy: 0.1583 - val_loss: 1.7820 - val_accuracy: 0.1500\n",
      "Epoch 204/1000\n",
      "45/45 [==============================] - 0s 806us/step - loss: 1.7678 - accuracy: 0.1639 - val_loss: 1.7816 - val_accuracy: 0.1500\n",
      "Epoch 205/1000\n",
      "45/45 [==============================] - 0s 821us/step - loss: 1.7679 - accuracy: 0.1583 - val_loss: 1.7816 - val_accuracy: 0.1500\n",
      "Epoch 206/1000\n",
      "45/45 [==============================] - 0s 769us/step - loss: 1.7678 - accuracy: 0.1583 - val_loss: 1.7824 - val_accuracy: 0.1500\n",
      "Epoch 207/1000\n",
      "45/45 [==============================] - 0s 791us/step - loss: 1.7679 - accuracy: 0.1861 - val_loss: 1.7831 - val_accuracy: 0.1500\n",
      "Epoch 208/1000\n",
      "45/45 [==============================] - 0s 793us/step - loss: 1.7681 - accuracy: 0.1861 - val_loss: 1.7832 - val_accuracy: 0.1500\n",
      "Epoch 209/1000\n",
      "45/45 [==============================] - 0s 917us/step - loss: 1.7680 - accuracy: 0.1861 - val_loss: 1.7822 - val_accuracy: 0.1500\n",
      "Epoch 210/1000\n",
      "45/45 [==============================] - 0s 783us/step - loss: 1.7686 - accuracy: 0.1500 - val_loss: 1.7817 - val_accuracy: 0.1500\n",
      "Epoch 211/1000\n",
      "45/45 [==============================] - 0s 817us/step - loss: 1.7676 - accuracy: 0.1861 - val_loss: 1.7826 - val_accuracy: 0.1500\n",
      "Epoch 212/1000\n",
      "45/45 [==============================] - 0s 781us/step - loss: 1.7675 - accuracy: 0.1861 - val_loss: 1.7829 - val_accuracy: 0.1500\n",
      "Epoch 213/1000\n",
      "45/45 [==============================] - 0s 765us/step - loss: 1.7680 - accuracy: 0.1611 - val_loss: 1.7816 - val_accuracy: 0.1500\n",
      "Epoch 214/1000\n",
      "45/45 [==============================] - 0s 755us/step - loss: 1.7681 - accuracy: 0.1611 - val_loss: 1.7823 - val_accuracy: 0.1500\n",
      "Epoch 215/1000\n",
      "45/45 [==============================] - 0s 796us/step - loss: 1.7675 - accuracy: 0.1861 - val_loss: 1.7817 - val_accuracy: 0.1500\n",
      "Epoch 216/1000\n",
      "45/45 [==============================] - 0s 803us/step - loss: 1.7681 - accuracy: 0.1861 - val_loss: 1.7817 - val_accuracy: 0.1500\n",
      "Epoch 217/1000\n",
      "45/45 [==============================] - 0s 806us/step - loss: 1.7674 - accuracy: 0.1667 - val_loss: 1.7814 - val_accuracy: 0.1500\n",
      "Epoch 218/1000\n",
      "45/45 [==============================] - 0s 776us/step - loss: 1.7680 - accuracy: 0.1639 - val_loss: 1.7823 - val_accuracy: 0.1500\n",
      "Epoch 219/1000\n",
      "45/45 [==============================] - 0s 784us/step - loss: 1.7677 - accuracy: 0.1861 - val_loss: 1.7815 - val_accuracy: 0.1500\n",
      "Epoch 220/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 0s 791us/step - loss: 1.7676 - accuracy: 0.1861 - val_loss: 1.7818 - val_accuracy: 0.1500\n",
      "Epoch 221/1000\n",
      "45/45 [==============================] - 0s 796us/step - loss: 1.7681 - accuracy: 0.1861 - val_loss: 1.7822 - val_accuracy: 0.1500\n",
      "Epoch 222/1000\n",
      "45/45 [==============================] - 0s 788us/step - loss: 1.7677 - accuracy: 0.1861 - val_loss: 1.7818 - val_accuracy: 0.1500\n",
      "Epoch 223/1000\n",
      "45/45 [==============================] - 0s 823us/step - loss: 1.7677 - accuracy: 0.1528 - val_loss: 1.7821 - val_accuracy: 0.1500\n",
      "Epoch 224/1000\n",
      "45/45 [==============================] - 0s 798us/step - loss: 1.7678 - accuracy: 0.1806 - val_loss: 1.7811 - val_accuracy: 0.1500\n",
      "Epoch 225/1000\n",
      "45/45 [==============================] - 0s 790us/step - loss: 1.7681 - accuracy: 0.1861 - val_loss: 1.7826 - val_accuracy: 0.1500\n",
      "Epoch 226/1000\n",
      "45/45 [==============================] - 0s 810us/step - loss: 1.7675 - accuracy: 0.1750 - val_loss: 1.7819 - val_accuracy: 0.1500\n",
      "Epoch 227/1000\n",
      "45/45 [==============================] - 0s 801us/step - loss: 1.7674 - accuracy: 0.1833 - val_loss: 1.7830 - val_accuracy: 0.1500\n",
      "Epoch 228/1000\n",
      "45/45 [==============================] - 0s 782us/step - loss: 1.7683 - accuracy: 0.1667 - val_loss: 1.7827 - val_accuracy: 0.1500\n",
      "Epoch 229/1000\n",
      "45/45 [==============================] - 0s 775us/step - loss: 1.7678 - accuracy: 0.1639 - val_loss: 1.7820 - val_accuracy: 0.1500\n",
      "Epoch 230/1000\n",
      "45/45 [==============================] - 0s 814us/step - loss: 1.7679 - accuracy: 0.1861 - val_loss: 1.7813 - val_accuracy: 0.1500\n",
      "Epoch 231/1000\n",
      "45/45 [==============================] - 0s 789us/step - loss: 1.7678 - accuracy: 0.1694 - val_loss: 1.7819 - val_accuracy: 0.1500\n",
      "Epoch 232/1000\n",
      "45/45 [==============================] - 0s 818us/step - loss: 1.7672 - accuracy: 0.1861 - val_loss: 1.7821 - val_accuracy: 0.1500\n",
      "Epoch 233/1000\n",
      "45/45 [==============================] - 0s 774us/step - loss: 1.7684 - accuracy: 0.1611 - val_loss: 1.7820 - val_accuracy: 0.1500\n",
      "Epoch 234/1000\n",
      "45/45 [==============================] - 0s 814us/step - loss: 1.7684 - accuracy: 0.1444 - val_loss: 1.7814 - val_accuracy: 0.1500\n",
      "Epoch 235/1000\n",
      "45/45 [==============================] - 0s 798us/step - loss: 1.7678 - accuracy: 0.1861 - val_loss: 1.7825 - val_accuracy: 0.1500\n",
      "Epoch 236/1000\n",
      "45/45 [==============================] - 0s 789us/step - loss: 1.7676 - accuracy: 0.1861 - val_loss: 1.7819 - val_accuracy: 0.1500\n",
      "Epoch 237/1000\n",
      "45/45 [==============================] - 0s 792us/step - loss: 1.7685 - accuracy: 0.1361 - val_loss: 1.7810 - val_accuracy: 0.1500\n",
      "Epoch 238/1000\n",
      "45/45 [==============================] - 0s 758us/step - loss: 1.7673 - accuracy: 0.1611 - val_loss: 1.7827 - val_accuracy: 0.1500\n",
      "Epoch 239/1000\n",
      "45/45 [==============================] - 0s 799us/step - loss: 1.7675 - accuracy: 0.1861 - val_loss: 1.7829 - val_accuracy: 0.1500\n",
      "Epoch 240/1000\n",
      "45/45 [==============================] - 0s 775us/step - loss: 1.7676 - accuracy: 0.1556 - val_loss: 1.7824 - val_accuracy: 0.1500\n",
      "Epoch 241/1000\n",
      "45/45 [==============================] - 0s 852us/step - loss: 1.7679 - accuracy: 0.1861 - val_loss: 1.7829 - val_accuracy: 0.1500\n",
      "Epoch 242/1000\n",
      "45/45 [==============================] - 0s 786us/step - loss: 1.7676 - accuracy: 0.1861 - val_loss: 1.7824 - val_accuracy: 0.1500\n",
      "Epoch 243/1000\n",
      "45/45 [==============================] - 0s 803us/step - loss: 1.7676 - accuracy: 0.1861 - val_loss: 1.7827 - val_accuracy: 0.1500\n",
      "Epoch 244/1000\n",
      "45/45 [==============================] - 0s 782us/step - loss: 1.7679 - accuracy: 0.1667 - val_loss: 1.7821 - val_accuracy: 0.1500\n",
      "Epoch 245/1000\n",
      "45/45 [==============================] - 0s 784us/step - loss: 1.7678 - accuracy: 0.1806 - val_loss: 1.7824 - val_accuracy: 0.1500\n",
      "Epoch 246/1000\n",
      "45/45 [==============================] - 0s 820us/step - loss: 1.7683 - accuracy: 0.1694 - val_loss: 1.7827 - val_accuracy: 0.1500\n",
      "Epoch 247/1000\n",
      "45/45 [==============================] - 0s 780us/step - loss: 1.7684 - accuracy: 0.1778 - val_loss: 1.7820 - val_accuracy: 0.1500\n",
      "Epoch 248/1000\n",
      "45/45 [==============================] - 0s 778us/step - loss: 1.7672 - accuracy: 0.1861 - val_loss: 1.7824 - val_accuracy: 0.1500\n",
      "Epoch 249/1000\n",
      "45/45 [==============================] - 0s 799us/step - loss: 1.7689 - accuracy: 0.1694 - val_loss: 1.7814 - val_accuracy: 0.1500\n",
      "Epoch 250/1000\n",
      "45/45 [==============================] - 0s 844us/step - loss: 1.7679 - accuracy: 0.1583 - val_loss: 1.7827 - val_accuracy: 0.1500\n",
      "Epoch 251/1000\n",
      "45/45 [==============================] - 0s 795us/step - loss: 1.7680 - accuracy: 0.1861 - val_loss: 1.7820 - val_accuracy: 0.1500\n",
      "Epoch 252/1000\n",
      "45/45 [==============================] - 0s 778us/step - loss: 1.7674 - accuracy: 0.1861 - val_loss: 1.7814 - val_accuracy: 0.1500\n",
      "Epoch 253/1000\n",
      "45/45 [==============================] - 0s 800us/step - loss: 1.7680 - accuracy: 0.1639 - val_loss: 1.7820 - val_accuracy: 0.1500\n",
      "Epoch 254/1000\n",
      "45/45 [==============================] - 0s 820us/step - loss: 1.7675 - accuracy: 0.1861 - val_loss: 1.7816 - val_accuracy: 0.1500\n",
      "Epoch 255/1000\n",
      "45/45 [==============================] - 0s 796us/step - loss: 1.7682 - accuracy: 0.1861 - val_loss: 1.7817 - val_accuracy: 0.1500\n",
      "Epoch 256/1000\n",
      "45/45 [==============================] - 0s 818us/step - loss: 1.7677 - accuracy: 0.1639 - val_loss: 1.7817 - val_accuracy: 0.1500\n",
      "Epoch 257/1000\n",
      "45/45 [==============================] - 0s 779us/step - loss: 1.7677 - accuracy: 0.1694 - val_loss: 1.7821 - val_accuracy: 0.1500\n",
      "Epoch 258/1000\n",
      "45/45 [==============================] - 0s 782us/step - loss: 1.7674 - accuracy: 0.1861 - val_loss: 1.7816 - val_accuracy: 0.1500\n",
      "Epoch 259/1000\n",
      "45/45 [==============================] - 0s 787us/step - loss: 1.7682 - accuracy: 0.1639 - val_loss: 1.7817 - val_accuracy: 0.1500\n",
      "Epoch 260/1000\n",
      "45/45 [==============================] - 0s 764us/step - loss: 1.7678 - accuracy: 0.1861 - val_loss: 1.7823 - val_accuracy: 0.1500\n",
      "Epoch 261/1000\n",
      "45/45 [==============================] - 0s 794us/step - loss: 1.7680 - accuracy: 0.1861 - val_loss: 1.7821 - val_accuracy: 0.1500\n",
      "Epoch 262/1000\n",
      "45/45 [==============================] - 0s 802us/step - loss: 1.7680 - accuracy: 0.1583 - val_loss: 1.7832 - val_accuracy: 0.1500\n",
      "Epoch 263/1000\n",
      "45/45 [==============================] - 0s 816us/step - loss: 1.7680 - accuracy: 0.1889 - val_loss: 1.7819 - val_accuracy: 0.1500\n",
      "Epoch 264/1000\n",
      "45/45 [==============================] - 0s 765us/step - loss: 1.7686 - accuracy: 0.1861 - val_loss: 1.7811 - val_accuracy: 0.1500\n",
      "Epoch 265/1000\n",
      "45/45 [==============================] - 0s 785us/step - loss: 1.7684 - accuracy: 0.1639 - val_loss: 1.7829 - val_accuracy: 0.1500\n",
      "Epoch 266/1000\n",
      "45/45 [==============================] - 0s 773us/step - loss: 1.7676 - accuracy: 0.1528 - val_loss: 1.7820 - val_accuracy: 0.1500\n",
      "Epoch 267/1000\n",
      "45/45 [==============================] - 0s 794us/step - loss: 1.7680 - accuracy: 0.1667 - val_loss: 1.7823 - val_accuracy: 0.1500\n",
      "Epoch 268/1000\n",
      "45/45 [==============================] - 0s 782us/step - loss: 1.7675 - accuracy: 0.1861 - val_loss: 1.7814 - val_accuracy: 0.1500\n",
      "Epoch 269/1000\n",
      "45/45 [==============================] - 0s 826us/step - loss: 1.7672 - accuracy: 0.1778 - val_loss: 1.7822 - val_accuracy: 0.1500\n",
      "Epoch 270/1000\n",
      "45/45 [==============================] - 0s 784us/step - loss: 1.7675 - accuracy: 0.1861 - val_loss: 1.7822 - val_accuracy: 0.1500\n",
      "Epoch 271/1000\n",
      "45/45 [==============================] - 0s 836us/step - loss: 1.7678 - accuracy: 0.1583 - val_loss: 1.7825 - val_accuracy: 0.1500\n",
      "Epoch 272/1000\n",
      "45/45 [==============================] - 0s 795us/step - loss: 1.7685 - accuracy: 0.1667 - val_loss: 1.7818 - val_accuracy: 0.1500\n",
      "Epoch 273/1000\n",
      "45/45 [==============================] - 0s 810us/step - loss: 1.7683 - accuracy: 0.1806 - val_loss: 1.7832 - val_accuracy: 0.1500\n",
      "Epoch 274/1000\n",
      "45/45 [==============================] - 0s 810us/step - loss: 1.7683 - accuracy: 0.1389 - val_loss: 1.7806 - val_accuracy: 0.1500\n",
      "Epoch 275/1000\n",
      "45/45 [==============================] - 0s 787us/step - loss: 1.7679 - accuracy: 0.1694 - val_loss: 1.7820 - val_accuracy: 0.1500\n",
      "Epoch 276/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 0s 786us/step - loss: 1.7675 - accuracy: 0.1861 - val_loss: 1.7821 - val_accuracy: 0.1500\n",
      "Epoch 277/1000\n",
      "45/45 [==============================] - 0s 797us/step - loss: 1.7672 - accuracy: 0.1861 - val_loss: 1.7825 - val_accuracy: 0.1500\n",
      "Epoch 278/1000\n",
      "45/45 [==============================] - 0s 745us/step - loss: 1.7676 - accuracy: 0.1861 - val_loss: 1.7821 - val_accuracy: 0.1500\n",
      "Epoch 279/1000\n",
      "45/45 [==============================] - 0s 807us/step - loss: 1.7676 - accuracy: 0.1861 - val_loss: 1.7821 - val_accuracy: 0.1500\n",
      "Epoch 280/1000\n",
      "45/45 [==============================] - 0s 786us/step - loss: 1.7677 - accuracy: 0.1861 - val_loss: 1.7832 - val_accuracy: 0.1500\n",
      "Epoch 281/1000\n",
      "45/45 [==============================] - 0s 773us/step - loss: 1.7683 - accuracy: 0.1472 - val_loss: 1.7820 - val_accuracy: 0.1500\n",
      "Epoch 282/1000\n",
      "45/45 [==============================] - 0s 767us/step - loss: 1.7676 - accuracy: 0.1472 - val_loss: 1.7822 - val_accuracy: 0.1500\n",
      "Epoch 283/1000\n",
      "45/45 [==============================] - 0s 790us/step - loss: 1.7674 - accuracy: 0.1722 - val_loss: 1.7831 - val_accuracy: 0.1500\n",
      "Epoch 284/1000\n",
      "45/45 [==============================] - 0s 806us/step - loss: 1.7675 - accuracy: 0.1528 - val_loss: 1.7815 - val_accuracy: 0.1500\n",
      "Epoch 285/1000\n",
      "45/45 [==============================] - 0s 805us/step - loss: 1.7679 - accuracy: 0.1722 - val_loss: 1.7825 - val_accuracy: 0.1500\n",
      "Epoch 286/1000\n",
      "45/45 [==============================] - 0s 816us/step - loss: 1.7680 - accuracy: 0.1861 - val_loss: 1.7821 - val_accuracy: 0.1500\n",
      "Epoch 287/1000\n",
      "45/45 [==============================] - 0s 773us/step - loss: 1.7691 - accuracy: 0.1861 - val_loss: 1.7813 - val_accuracy: 0.1500\n",
      "Epoch 288/1000\n",
      "45/45 [==============================] - 0s 786us/step - loss: 1.7680 - accuracy: 0.1667 - val_loss: 1.7835 - val_accuracy: 0.1500\n",
      "Epoch 289/1000\n",
      "45/45 [==============================] - 0s 793us/step - loss: 1.7686 - accuracy: 0.1833 - val_loss: 1.7820 - val_accuracy: 0.1500\n",
      "Epoch 290/1000\n",
      "45/45 [==============================] - 0s 792us/step - loss: 1.7676 - accuracy: 0.1861 - val_loss: 1.7829 - val_accuracy: 0.1500\n",
      "Epoch 291/1000\n",
      "45/45 [==============================] - 0s 792us/step - loss: 1.7676 - accuracy: 0.1639 - val_loss: 1.7833 - val_accuracy: 0.1500\n",
      "Epoch 292/1000\n",
      "45/45 [==============================] - 0s 781us/step - loss: 1.7675 - accuracy: 0.1667 - val_loss: 1.7833 - val_accuracy: 0.1500\n",
      "Epoch 293/1000\n",
      "45/45 [==============================] - 0s 798us/step - loss: 1.7687 - accuracy: 0.1639 - val_loss: 1.7829 - val_accuracy: 0.1500\n",
      "Epoch 294/1000\n",
      "45/45 [==============================] - 0s 803us/step - loss: 1.7681 - accuracy: 0.1806 - val_loss: 1.7808 - val_accuracy: 0.1500\n",
      "Epoch 295/1000\n",
      "45/45 [==============================] - 0s 786us/step - loss: 1.7681 - accuracy: 0.1583 - val_loss: 1.7826 - val_accuracy: 0.1500\n",
      "Epoch 296/1000\n",
      "45/45 [==============================] - 0s 778us/step - loss: 1.7677 - accuracy: 0.1889 - val_loss: 1.7830 - val_accuracy: 0.1500\n",
      "Epoch 297/1000\n",
      "45/45 [==============================] - 0s 784us/step - loss: 1.7680 - accuracy: 0.1472 - val_loss: 1.7823 - val_accuracy: 0.1500\n",
      "Epoch 298/1000\n",
      "45/45 [==============================] - 0s 777us/step - loss: 1.7679 - accuracy: 0.1861 - val_loss: 1.7804 - val_accuracy: 0.1500\n",
      "Epoch 299/1000\n",
      "45/45 [==============================] - 0s 752us/step - loss: 1.7685 - accuracy: 0.1861 - val_loss: 1.7821 - val_accuracy: 0.1500\n",
      "Epoch 300/1000\n",
      "45/45 [==============================] - 0s 745us/step - loss: 1.7679 - accuracy: 0.1861 - val_loss: 1.7824 - val_accuracy: 0.1500\n",
      "Epoch 301/1000\n",
      "45/45 [==============================] - 0s 908us/step - loss: 1.7679 - accuracy: 0.1861 - val_loss: 1.7838 - val_accuracy: 0.1500\n",
      "Epoch 302/1000\n",
      "45/45 [==============================] - 0s 844us/step - loss: 1.7677 - accuracy: 0.1611 - val_loss: 1.7813 - val_accuracy: 0.1500\n",
      "Epoch 303/1000\n",
      "45/45 [==============================] - 0s 804us/step - loss: 1.7674 - accuracy: 0.1917 - val_loss: 1.7814 - val_accuracy: 0.1500\n",
      "Epoch 304/1000\n",
      "45/45 [==============================] - 0s 805us/step - loss: 1.7680 - accuracy: 0.1861 - val_loss: 1.7815 - val_accuracy: 0.1500\n",
      "Epoch 305/1000\n",
      "45/45 [==============================] - 0s 814us/step - loss: 1.7676 - accuracy: 0.1861 - val_loss: 1.7821 - val_accuracy: 0.1500\n",
      "Epoch 306/1000\n",
      "45/45 [==============================] - 0s 822us/step - loss: 1.7695 - accuracy: 0.1667 - val_loss: 1.7828 - val_accuracy: 0.1500\n",
      "Epoch 307/1000\n",
      "45/45 [==============================] - 0s 772us/step - loss: 1.7694 - accuracy: 0.1806 - val_loss: 1.7825 - val_accuracy: 0.1500\n",
      "Epoch 308/1000\n",
      "45/45 [==============================] - 0s 790us/step - loss: 1.7676 - accuracy: 0.1667 - val_loss: 1.7821 - val_accuracy: 0.1500\n",
      "Epoch 309/1000\n",
      "45/45 [==============================] - 0s 810us/step - loss: 1.7676 - accuracy: 0.1583 - val_loss: 1.7817 - val_accuracy: 0.1500\n",
      "Epoch 310/1000\n",
      "45/45 [==============================] - 0s 765us/step - loss: 1.7680 - accuracy: 0.1694 - val_loss: 1.7815 - val_accuracy: 0.1500\n",
      "Epoch 311/1000\n",
      "45/45 [==============================] - 0s 807us/step - loss: 1.7673 - accuracy: 0.1556 - val_loss: 1.7815 - val_accuracy: 0.1500\n",
      "Epoch 312/1000\n",
      "45/45 [==============================] - 0s 798us/step - loss: 1.7675 - accuracy: 0.1861 - val_loss: 1.7818 - val_accuracy: 0.1500\n",
      "Epoch 313/1000\n",
      "45/45 [==============================] - 0s 785us/step - loss: 1.7676 - accuracy: 0.1861 - val_loss: 1.7825 - val_accuracy: 0.1500\n",
      "Epoch 314/1000\n",
      "45/45 [==============================] - 0s 799us/step - loss: 1.7676 - accuracy: 0.1667 - val_loss: 1.7829 - val_accuracy: 0.1500\n",
      "Epoch 315/1000\n",
      "45/45 [==============================] - 0s 787us/step - loss: 1.7679 - accuracy: 0.1611 - val_loss: 1.7818 - val_accuracy: 0.1500\n",
      "Epoch 316/1000\n",
      "45/45 [==============================] - 0s 821us/step - loss: 1.7679 - accuracy: 0.1861 - val_loss: 1.7823 - val_accuracy: 0.1500\n",
      "Epoch 317/1000\n",
      "45/45 [==============================] - 0s 784us/step - loss: 1.7676 - accuracy: 0.1861 - val_loss: 1.7838 - val_accuracy: 0.1500\n",
      "Epoch 318/1000\n",
      "45/45 [==============================] - 0s 811us/step - loss: 1.7678 - accuracy: 0.1611 - val_loss: 1.7823 - val_accuracy: 0.1500\n",
      "Epoch 319/1000\n",
      "45/45 [==============================] - 0s 804us/step - loss: 1.7675 - accuracy: 0.1722 - val_loss: 1.7816 - val_accuracy: 0.1500\n",
      "Epoch 320/1000\n",
      "45/45 [==============================] - 0s 833us/step - loss: 1.7677 - accuracy: 0.1806 - val_loss: 1.7835 - val_accuracy: 0.1500\n",
      "Epoch 321/1000\n",
      "45/45 [==============================] - 0s 805us/step - loss: 1.7679 - accuracy: 0.1861 - val_loss: 1.7820 - val_accuracy: 0.1500\n",
      "Epoch 322/1000\n",
      "45/45 [==============================] - 0s 806us/step - loss: 1.7687 - accuracy: 0.1861 - val_loss: 1.7821 - val_accuracy: 0.1500\n",
      "Epoch 323/1000\n",
      "45/45 [==============================] - 0s 817us/step - loss: 1.7675 - accuracy: 0.1861 - val_loss: 1.7825 - val_accuracy: 0.1500\n",
      "Epoch 324/1000\n",
      "45/45 [==============================] - 0s 815us/step - loss: 1.7676 - accuracy: 0.1861 - val_loss: 1.7813 - val_accuracy: 0.1500\n",
      "Epoch 325/1000\n",
      "45/45 [==============================] - 0s 800us/step - loss: 1.7681 - accuracy: 0.1528 - val_loss: 1.7825 - val_accuracy: 0.1500\n",
      "Epoch 326/1000\n",
      "45/45 [==============================] - 0s 801us/step - loss: 1.7682 - accuracy: 0.1583 - val_loss: 1.7817 - val_accuracy: 0.1500\n",
      "Epoch 327/1000\n",
      "45/45 [==============================] - 0s 815us/step - loss: 1.7683 - accuracy: 0.1528 - val_loss: 1.7824 - val_accuracy: 0.1500\n",
      "Epoch 328/1000\n",
      "45/45 [==============================] - 0s 785us/step - loss: 1.7684 - accuracy: 0.1500 - val_loss: 1.7824 - val_accuracy: 0.1500\n",
      "Epoch 329/1000\n",
      "45/45 [==============================] - 0s 817us/step - loss: 1.7679 - accuracy: 0.1250 - val_loss: 1.7812 - val_accuracy: 0.1500\n",
      "Epoch 330/1000\n",
      "45/45 [==============================] - 0s 799us/step - loss: 1.7681 - accuracy: 0.1861 - val_loss: 1.7823 - val_accuracy: 0.1500\n",
      "Epoch 331/1000\n",
      "45/45 [==============================] - 0s 797us/step - loss: 1.7682 - accuracy: 0.1861 - val_loss: 1.7816 - val_accuracy: 0.1500\n",
      "Epoch 332/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 0s 817us/step - loss: 1.7674 - accuracy: 0.1861 - val_loss: 1.7825 - val_accuracy: 0.1500\n",
      "Epoch 333/1000\n",
      "45/45 [==============================] - 0s 774us/step - loss: 1.7672 - accuracy: 0.1861 - val_loss: 1.7816 - val_accuracy: 0.1500\n",
      "Epoch 334/1000\n",
      "45/45 [==============================] - 0s 784us/step - loss: 1.7682 - accuracy: 0.1861 - val_loss: 1.7844 - val_accuracy: 0.1500\n",
      "Epoch 335/1000\n",
      "45/45 [==============================] - 0s 821us/step - loss: 1.7683 - accuracy: 0.1694 - val_loss: 1.7818 - val_accuracy: 0.1500\n",
      "Epoch 336/1000\n",
      "45/45 [==============================] - 0s 827us/step - loss: 1.7680 - accuracy: 0.1667 - val_loss: 1.7816 - val_accuracy: 0.1500\n",
      "Epoch 337/1000\n",
      "45/45 [==============================] - 0s 761us/step - loss: 1.7674 - accuracy: 0.1417 - val_loss: 1.7825 - val_accuracy: 0.1500\n",
      "Epoch 338/1000\n",
      "45/45 [==============================] - 0s 759us/step - loss: 1.7676 - accuracy: 0.1861 - val_loss: 1.7822 - val_accuracy: 0.1500\n",
      "Epoch 339/1000\n",
      "45/45 [==============================] - 0s 784us/step - loss: 1.7673 - accuracy: 0.1611 - val_loss: 1.7812 - val_accuracy: 0.1500\n",
      "Epoch 340/1000\n",
      "45/45 [==============================] - 0s 797us/step - loss: 1.7674 - accuracy: 0.1694 - val_loss: 1.7827 - val_accuracy: 0.1500\n",
      "Epoch 341/1000\n",
      "45/45 [==============================] - 0s 808us/step - loss: 1.7674 - accuracy: 0.1861 - val_loss: 1.7815 - val_accuracy: 0.1500\n",
      "Epoch 342/1000\n",
      "45/45 [==============================] - 0s 784us/step - loss: 1.7679 - accuracy: 0.1861 - val_loss: 1.7827 - val_accuracy: 0.1500\n",
      "Epoch 343/1000\n",
      "45/45 [==============================] - 0s 783us/step - loss: 1.7673 - accuracy: 0.1694 - val_loss: 1.7820 - val_accuracy: 0.1500\n",
      "Epoch 344/1000\n",
      "45/45 [==============================] - 0s 760us/step - loss: 1.7680 - accuracy: 0.1639 - val_loss: 1.7828 - val_accuracy: 0.1500\n",
      "Epoch 345/1000\n",
      "45/45 [==============================] - 0s 814us/step - loss: 1.7672 - accuracy: 0.1861 - val_loss: 1.7819 - val_accuracy: 0.1500\n",
      "Epoch 346/1000\n",
      "45/45 [==============================] - 0s 813us/step - loss: 1.7688 - accuracy: 0.1500 - val_loss: 1.7823 - val_accuracy: 0.1500\n",
      "Epoch 347/1000\n",
      "45/45 [==============================] - 0s 800us/step - loss: 1.7681 - accuracy: 0.1833 - val_loss: 1.7831 - val_accuracy: 0.1500\n",
      "Epoch 348/1000\n",
      "45/45 [==============================] - 0s 787us/step - loss: 1.7674 - accuracy: 0.1750 - val_loss: 1.7815 - val_accuracy: 0.1500\n",
      "Epoch 349/1000\n",
      "45/45 [==============================] - 0s 796us/step - loss: 1.7676 - accuracy: 0.1861 - val_loss: 1.7828 - val_accuracy: 0.1500\n",
      "Epoch 350/1000\n",
      "45/45 [==============================] - 0s 830us/step - loss: 1.7679 - accuracy: 0.1861 - val_loss: 1.7816 - val_accuracy: 0.1500\n",
      "Epoch 351/1000\n",
      "45/45 [==============================] - 0s 790us/step - loss: 1.7672 - accuracy: 0.1861 - val_loss: 1.7813 - val_accuracy: 0.1500\n",
      "Epoch 352/1000\n",
      "45/45 [==============================] - 0s 798us/step - loss: 1.7678 - accuracy: 0.1750 - val_loss: 1.7820 - val_accuracy: 0.1500\n",
      "Epoch 353/1000\n",
      "45/45 [==============================] - 0s 808us/step - loss: 1.7673 - accuracy: 0.1694 - val_loss: 1.7824 - val_accuracy: 0.1500\n",
      "Epoch 354/1000\n",
      "45/45 [==============================] - 0s 821us/step - loss: 1.7677 - accuracy: 0.1500 - val_loss: 1.7817 - val_accuracy: 0.1500\n",
      "Epoch 355/1000\n",
      "45/45 [==============================] - 0s 800us/step - loss: 1.7683 - accuracy: 0.1861 - val_loss: 1.7830 - val_accuracy: 0.1500\n",
      "Epoch 356/1000\n",
      "45/45 [==============================] - 0s 774us/step - loss: 1.7673 - accuracy: 0.1722 - val_loss: 1.7830 - val_accuracy: 0.1500\n",
      "Epoch 357/1000\n",
      "45/45 [==============================] - 0s 797us/step - loss: 1.7679 - accuracy: 0.1611 - val_loss: 1.7806 - val_accuracy: 0.1500\n",
      "Epoch 358/1000\n",
      "45/45 [==============================] - 0s 805us/step - loss: 1.7676 - accuracy: 0.1861 - val_loss: 1.7818 - val_accuracy: 0.1500\n",
      "Epoch 359/1000\n",
      "45/45 [==============================] - 0s 766us/step - loss: 1.7674 - accuracy: 0.1861 - val_loss: 1.7817 - val_accuracy: 0.1500\n",
      "Epoch 360/1000\n",
      "45/45 [==============================] - 0s 831us/step - loss: 1.7677 - accuracy: 0.1750 - val_loss: 1.7815 - val_accuracy: 0.1500\n",
      "Epoch 361/1000\n",
      "45/45 [==============================] - 0s 823us/step - loss: 1.7675 - accuracy: 0.1694 - val_loss: 1.7827 - val_accuracy: 0.1500\n",
      "Epoch 362/1000\n",
      "45/45 [==============================] - 0s 770us/step - loss: 1.7676 - accuracy: 0.1639 - val_loss: 1.7814 - val_accuracy: 0.1500\n",
      "Epoch 363/1000\n",
      "45/45 [==============================] - 0s 802us/step - loss: 1.7679 - accuracy: 0.1861 - val_loss: 1.7817 - val_accuracy: 0.1500\n",
      "Epoch 364/1000\n",
      "45/45 [==============================] - 0s 797us/step - loss: 1.7678 - accuracy: 0.1861 - val_loss: 1.7829 - val_accuracy: 0.1500\n",
      "Epoch 365/1000\n",
      "45/45 [==============================] - 0s 791us/step - loss: 1.7675 - accuracy: 0.1694 - val_loss: 1.7828 - val_accuracy: 0.1500\n",
      "Epoch 366/1000\n",
      "45/45 [==============================] - 0s 799us/step - loss: 1.7677 - accuracy: 0.1806 - val_loss: 1.7821 - val_accuracy: 0.1500\n",
      "Epoch 367/1000\n",
      "45/45 [==============================] - 0s 785us/step - loss: 1.7683 - accuracy: 0.1778 - val_loss: 1.7831 - val_accuracy: 0.1500\n",
      "Epoch 368/1000\n",
      "45/45 [==============================] - 0s 799us/step - loss: 1.7678 - accuracy: 0.1639 - val_loss: 1.7827 - val_accuracy: 0.1500\n",
      "Epoch 369/1000\n",
      "45/45 [==============================] - 0s 737us/step - loss: 1.7675 - accuracy: 0.1861 - val_loss: 1.7819 - val_accuracy: 0.1500\n",
      "Epoch 370/1000\n",
      "45/45 [==============================] - 0s 754us/step - loss: 1.7675 - accuracy: 0.1500 - val_loss: 1.7817 - val_accuracy: 0.1500\n",
      "Epoch 371/1000\n",
      "45/45 [==============================] - 0s 784us/step - loss: 1.7683 - accuracy: 0.1528 - val_loss: 1.7822 - val_accuracy: 0.1500\n",
      "Epoch 372/1000\n",
      "45/45 [==============================] - 0s 750us/step - loss: 1.7684 - accuracy: 0.1722 - val_loss: 1.7817 - val_accuracy: 0.1500\n",
      "Epoch 373/1000\n",
      "45/45 [==============================] - 0s 798us/step - loss: 1.7682 - accuracy: 0.1861 - val_loss: 1.7821 - val_accuracy: 0.1500\n",
      "Epoch 374/1000\n",
      "45/45 [==============================] - 0s 764us/step - loss: 1.7679 - accuracy: 0.1528 - val_loss: 1.7818 - val_accuracy: 0.1500\n",
      "Epoch 375/1000\n",
      "45/45 [==============================] - 0s 782us/step - loss: 1.7678 - accuracy: 0.1861 - val_loss: 1.7825 - val_accuracy: 0.1500\n",
      "Epoch 376/1000\n",
      "45/45 [==============================] - 0s 831us/step - loss: 1.7673 - accuracy: 0.1861 - val_loss: 1.7820 - val_accuracy: 0.1500\n",
      "Epoch 377/1000\n",
      "45/45 [==============================] - 0s 788us/step - loss: 1.7685 - accuracy: 0.1639 - val_loss: 1.7816 - val_accuracy: 0.1500\n",
      "Epoch 378/1000\n",
      "45/45 [==============================] - 0s 752us/step - loss: 1.7672 - accuracy: 0.1861 - val_loss: 1.7818 - val_accuracy: 0.1500\n",
      "Epoch 379/1000\n",
      "45/45 [==============================] - 0s 818us/step - loss: 1.7676 - accuracy: 0.1500 - val_loss: 1.7816 - val_accuracy: 0.1500\n",
      "Epoch 380/1000\n",
      "45/45 [==============================] - 0s 801us/step - loss: 1.7680 - accuracy: 0.1861 - val_loss: 1.7830 - val_accuracy: 0.1500\n",
      "Epoch 381/1000\n",
      "45/45 [==============================] - 0s 762us/step - loss: 1.7683 - accuracy: 0.1639 - val_loss: 1.7827 - val_accuracy: 0.1500\n",
      "Epoch 382/1000\n",
      "45/45 [==============================] - 0s 796us/step - loss: 1.7677 - accuracy: 0.1861 - val_loss: 1.7819 - val_accuracy: 0.1500\n",
      "Epoch 383/1000\n",
      "45/45 [==============================] - 0s 893us/step - loss: 1.7675 - accuracy: 0.1861 - val_loss: 1.7817 - val_accuracy: 0.1500\n",
      "Epoch 384/1000\n",
      "45/45 [==============================] - 0s 754us/step - loss: 1.7674 - accuracy: 0.1861 - val_loss: 1.7818 - val_accuracy: 0.1500\n",
      "Epoch 385/1000\n",
      "45/45 [==============================] - 0s 811us/step - loss: 1.7682 - accuracy: 0.1861 - val_loss: 1.7823 - val_accuracy: 0.1500\n",
      "Epoch 386/1000\n",
      "45/45 [==============================] - 0s 785us/step - loss: 1.7684 - accuracy: 0.1611 - val_loss: 1.7823 - val_accuracy: 0.1500\n",
      "Epoch 387/1000\n",
      "45/45 [==============================] - 0s 766us/step - loss: 1.7677 - accuracy: 0.1528 - val_loss: 1.7824 - val_accuracy: 0.1500\n",
      "Epoch 388/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 0s 781us/step - loss: 1.7678 - accuracy: 0.1861 - val_loss: 1.7821 - val_accuracy: 0.1500\n",
      "Epoch 389/1000\n",
      "45/45 [==============================] - 0s 804us/step - loss: 1.7682 - accuracy: 0.1694 - val_loss: 1.7816 - val_accuracy: 0.1500\n",
      "Epoch 390/1000\n",
      "45/45 [==============================] - 0s 804us/step - loss: 1.7671 - accuracy: 0.1861 - val_loss: 1.7822 - val_accuracy: 0.1500\n",
      "Epoch 391/1000\n",
      "45/45 [==============================] - 0s 771us/step - loss: 1.7675 - accuracy: 0.1861 - val_loss: 1.7813 - val_accuracy: 0.1500\n",
      "Epoch 392/1000\n",
      "45/45 [==============================] - 0s 782us/step - loss: 1.7676 - accuracy: 0.1861 - val_loss: 1.7823 - val_accuracy: 0.1500\n",
      "Epoch 393/1000\n",
      "45/45 [==============================] - 0s 819us/step - loss: 1.7675 - accuracy: 0.1861 - val_loss: 1.7821 - val_accuracy: 0.1500\n",
      "Epoch 394/1000\n",
      "45/45 [==============================] - 0s 798us/step - loss: 1.7677 - accuracy: 0.1861 - val_loss: 1.7814 - val_accuracy: 0.1500\n",
      "Epoch 395/1000\n",
      "45/45 [==============================] - 0s 820us/step - loss: 1.7682 - accuracy: 0.1694 - val_loss: 1.7830 - val_accuracy: 0.1500\n",
      "Epoch 396/1000\n",
      "45/45 [==============================] - 0s 791us/step - loss: 1.7674 - accuracy: 0.1833 - val_loss: 1.7820 - val_accuracy: 0.1500\n",
      "Epoch 397/1000\n",
      "45/45 [==============================] - 0s 792us/step - loss: 1.7672 - accuracy: 0.1861 - val_loss: 1.7815 - val_accuracy: 0.1500\n",
      "Epoch 398/1000\n",
      "45/45 [==============================] - 0s 763us/step - loss: 1.7674 - accuracy: 0.1861 - val_loss: 1.7816 - val_accuracy: 0.1500\n",
      "Epoch 399/1000\n",
      "45/45 [==============================] - 0s 791us/step - loss: 1.7678 - accuracy: 0.1667 - val_loss: 1.7831 - val_accuracy: 0.1500\n",
      "Epoch 400/1000\n",
      "45/45 [==============================] - 0s 759us/step - loss: 1.7671 - accuracy: 0.1750 - val_loss: 1.7812 - val_accuracy: 0.1500\n",
      "Epoch 401/1000\n",
      "45/45 [==============================] - 0s 800us/step - loss: 1.7677 - accuracy: 0.1639 - val_loss: 1.7824 - val_accuracy: 0.1500\n",
      "Epoch 402/1000\n",
      "45/45 [==============================] - 0s 802us/step - loss: 1.7671 - accuracy: 0.1722 - val_loss: 1.7819 - val_accuracy: 0.1500\n",
      "Epoch 403/1000\n",
      "45/45 [==============================] - 0s 812us/step - loss: 1.7673 - accuracy: 0.1861 - val_loss: 1.7807 - val_accuracy: 0.1500\n",
      "Epoch 404/1000\n",
      "45/45 [==============================] - 0s 801us/step - loss: 1.7672 - accuracy: 0.1861 - val_loss: 1.7819 - val_accuracy: 0.1500\n",
      "Epoch 405/1000\n",
      "45/45 [==============================] - 0s 783us/step - loss: 1.7683 - accuracy: 0.1500 - val_loss: 1.7829 - val_accuracy: 0.1500\n",
      "Epoch 406/1000\n",
      "45/45 [==============================] - 0s 798us/step - loss: 1.7673 - accuracy: 0.1861 - val_loss: 1.7814 - val_accuracy: 0.1500\n",
      "Epoch 407/1000\n",
      "45/45 [==============================] - 0s 794us/step - loss: 1.7677 - accuracy: 0.1861 - val_loss: 1.7816 - val_accuracy: 0.1500\n",
      "Epoch 408/1000\n",
      "45/45 [==============================] - 0s 777us/step - loss: 1.7675 - accuracy: 0.1472 - val_loss: 1.7819 - val_accuracy: 0.1500\n",
      "Epoch 409/1000\n",
      "45/45 [==============================] - 0s 825us/step - loss: 1.7681 - accuracy: 0.1556 - val_loss: 1.7816 - val_accuracy: 0.1500\n",
      "Epoch 410/1000\n",
      "45/45 [==============================] - 0s 814us/step - loss: 1.7674 - accuracy: 0.1556 - val_loss: 1.7820 - val_accuracy: 0.1500\n",
      "Epoch 411/1000\n",
      "45/45 [==============================] - 0s 802us/step - loss: 1.7675 - accuracy: 0.1861 - val_loss: 1.7813 - val_accuracy: 0.1500\n",
      "Epoch 412/1000\n",
      "45/45 [==============================] - 0s 780us/step - loss: 1.7676 - accuracy: 0.1667 - val_loss: 1.7812 - val_accuracy: 0.1500\n",
      "Epoch 413/1000\n",
      "45/45 [==============================] - 0s 772us/step - loss: 1.7675 - accuracy: 0.1861 - val_loss: 1.7820 - val_accuracy: 0.1500\n",
      "Epoch 414/1000\n",
      "45/45 [==============================] - 0s 812us/step - loss: 1.7674 - accuracy: 0.1861 - val_loss: 1.7826 - val_accuracy: 0.1500\n",
      "Epoch 415/1000\n",
      "45/45 [==============================] - 0s 816us/step - loss: 1.7678 - accuracy: 0.1861 - val_loss: 1.7811 - val_accuracy: 0.1500\n",
      "Epoch 416/1000\n",
      "45/45 [==============================] - 0s 823us/step - loss: 1.7683 - accuracy: 0.1639 - val_loss: 1.7813 - val_accuracy: 0.1500\n",
      "Epoch 417/1000\n",
      "45/45 [==============================] - 0s 805us/step - loss: 1.7673 - accuracy: 0.1333 - val_loss: 1.7821 - val_accuracy: 0.1500\n",
      "Epoch 418/1000\n",
      "45/45 [==============================] - 0s 783us/step - loss: 1.7679 - accuracy: 0.1861 - val_loss: 1.7818 - val_accuracy: 0.1500\n",
      "Epoch 419/1000\n",
      "45/45 [==============================] - 0s 786us/step - loss: 1.7672 - accuracy: 0.1722 - val_loss: 1.7828 - val_accuracy: 0.1500\n",
      "Epoch 420/1000\n",
      "45/45 [==============================] - 0s 814us/step - loss: 1.7672 - accuracy: 0.1667 - val_loss: 1.7820 - val_accuracy: 0.1500\n",
      "Epoch 421/1000\n",
      "45/45 [==============================] - 0s 782us/step - loss: 1.7674 - accuracy: 0.1861 - val_loss: 1.7824 - val_accuracy: 0.1500\n",
      "Epoch 422/1000\n",
      "45/45 [==============================] - 0s 787us/step - loss: 1.7676 - accuracy: 0.1861 - val_loss: 1.7825 - val_accuracy: 0.1500\n",
      "Epoch 423/1000\n",
      "45/45 [==============================] - 0s 777us/step - loss: 1.7671 - accuracy: 0.1639 - val_loss: 1.7818 - val_accuracy: 0.1500\n",
      "Epoch 424/1000\n",
      "45/45 [==============================] - 0s 770us/step - loss: 1.7673 - accuracy: 0.1861 - val_loss: 1.7821 - val_accuracy: 0.1500\n",
      "Epoch 425/1000\n",
      "45/45 [==============================] - 0s 816us/step - loss: 1.7672 - accuracy: 0.1722 - val_loss: 1.7824 - val_accuracy: 0.1500\n",
      "Epoch 426/1000\n",
      "45/45 [==============================] - 0s 801us/step - loss: 1.7675 - accuracy: 0.1722 - val_loss: 1.7819 - val_accuracy: 0.1500\n",
      "Epoch 427/1000\n",
      "45/45 [==============================] - 0s 776us/step - loss: 1.7673 - accuracy: 0.1861 - val_loss: 1.7820 - val_accuracy: 0.1500\n",
      "Epoch 428/1000\n",
      "45/45 [==============================] - 0s 802us/step - loss: 1.7679 - accuracy: 0.1861 - val_loss: 1.7810 - val_accuracy: 0.1500\n",
      "Epoch 429/1000\n",
      "45/45 [==============================] - 0s 834us/step - loss: 1.7676 - accuracy: 0.1667 - val_loss: 1.7821 - val_accuracy: 0.1500\n",
      "Epoch 430/1000\n",
      "45/45 [==============================] - 0s 830us/step - loss: 1.7672 - accuracy: 0.1861 - val_loss: 1.7821 - val_accuracy: 0.1500\n",
      "Epoch 431/1000\n",
      "45/45 [==============================] - 0s 797us/step - loss: 1.7673 - accuracy: 0.1861 - val_loss: 1.7827 - val_accuracy: 0.1500\n",
      "Epoch 432/1000\n",
      "45/45 [==============================] - 0s 787us/step - loss: 1.7676 - accuracy: 0.1861 - val_loss: 1.7827 - val_accuracy: 0.1500\n",
      "Epoch 433/1000\n",
      "45/45 [==============================] - 0s 769us/step - loss: 1.7679 - accuracy: 0.1861 - val_loss: 1.7822 - val_accuracy: 0.1500\n",
      "Epoch 434/1000\n",
      "45/45 [==============================] - 0s 822us/step - loss: 1.7675 - accuracy: 0.1861 - val_loss: 1.7827 - val_accuracy: 0.1500\n",
      "Epoch 435/1000\n",
      "45/45 [==============================] - 0s 814us/step - loss: 1.7675 - accuracy: 0.1861 - val_loss: 1.7809 - val_accuracy: 0.1500\n",
      "Epoch 436/1000\n",
      "45/45 [==============================] - 0s 788us/step - loss: 1.7669 - accuracy: 0.1861 - val_loss: 1.7816 - val_accuracy: 0.1500\n",
      "Epoch 437/1000\n",
      "45/45 [==============================] - 0s 819us/step - loss: 1.7675 - accuracy: 0.1861 - val_loss: 1.7813 - val_accuracy: 0.1500\n",
      "Epoch 438/1000\n",
      "45/45 [==============================] - 0s 794us/step - loss: 1.7676 - accuracy: 0.1861 - val_loss: 1.7807 - val_accuracy: 0.1500\n",
      "Epoch 439/1000\n",
      "45/45 [==============================] - 0s 796us/step - loss: 1.7674 - accuracy: 0.1861 - val_loss: 1.7828 - val_accuracy: 0.1500\n",
      "Epoch 440/1000\n",
      "45/45 [==============================] - 0s 769us/step - loss: 1.7676 - accuracy: 0.1861 - val_loss: 1.7816 - val_accuracy: 0.1500\n",
      "Epoch 441/1000\n",
      "45/45 [==============================] - 0s 783us/step - loss: 1.7674 - accuracy: 0.1861 - val_loss: 1.7821 - val_accuracy: 0.1500\n",
      "Epoch 442/1000\n",
      "45/45 [==============================] - 0s 801us/step - loss: 1.7672 - accuracy: 0.1750 - val_loss: 1.7817 - val_accuracy: 0.1500\n",
      "Epoch 443/1000\n",
      "45/45 [==============================] - 0s 797us/step - loss: 1.7677 - accuracy: 0.1861 - val_loss: 1.7820 - val_accuracy: 0.1500\n",
      "Epoch 444/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 0s 785us/step - loss: 1.7677 - accuracy: 0.1861 - val_loss: 1.7818 - val_accuracy: 0.1500\n",
      "Epoch 445/1000\n",
      "45/45 [==============================] - 0s 820us/step - loss: 1.7680 - accuracy: 0.1861 - val_loss: 1.7821 - val_accuracy: 0.1500\n",
      "Epoch 446/1000\n",
      "45/45 [==============================] - 0s 791us/step - loss: 1.7680 - accuracy: 0.1861 - val_loss: 1.7822 - val_accuracy: 0.1500\n",
      "Epoch 447/1000\n",
      "45/45 [==============================] - 0s 793us/step - loss: 1.7688 - accuracy: 0.1667 - val_loss: 1.7825 - val_accuracy: 0.1500\n",
      "Epoch 448/1000\n",
      "45/45 [==============================] - 0s 778us/step - loss: 1.7676 - accuracy: 0.1861 - val_loss: 1.7807 - val_accuracy: 0.1500\n",
      "Epoch 449/1000\n",
      "45/45 [==============================] - 0s 776us/step - loss: 1.7670 - accuracy: 0.1861 - val_loss: 1.7817 - val_accuracy: 0.1500\n",
      "Epoch 450/1000\n",
      "45/45 [==============================] - 0s 755us/step - loss: 1.7671 - accuracy: 0.1667 - val_loss: 1.7820 - val_accuracy: 0.1500\n",
      "Epoch 451/1000\n",
      "45/45 [==============================] - 0s 797us/step - loss: 1.7673 - accuracy: 0.1861 - val_loss: 1.7815 - val_accuracy: 0.1500\n",
      "Epoch 452/1000\n",
      "45/45 [==============================] - 0s 795us/step - loss: 1.7671 - accuracy: 0.1861 - val_loss: 1.7823 - val_accuracy: 0.1500\n",
      "Epoch 453/1000\n",
      "45/45 [==============================] - 0s 806us/step - loss: 1.7673 - accuracy: 0.1861 - val_loss: 1.7816 - val_accuracy: 0.1500\n",
      "Epoch 454/1000\n",
      "45/45 [==============================] - 0s 825us/step - loss: 1.7674 - accuracy: 0.1500 - val_loss: 1.7823 - val_accuracy: 0.1500\n",
      "Epoch 455/1000\n",
      "45/45 [==============================] - 0s 818us/step - loss: 1.7670 - accuracy: 0.1861 - val_loss: 1.7826 - val_accuracy: 0.1500\n",
      "Epoch 456/1000\n",
      "45/45 [==============================] - 0s 834us/step - loss: 1.7673 - accuracy: 0.1861 - val_loss: 1.7822 - val_accuracy: 0.1500\n",
      "Epoch 457/1000\n",
      "45/45 [==============================] - 0s 828us/step - loss: 1.7670 - accuracy: 0.1861 - val_loss: 1.7816 - val_accuracy: 0.1500\n",
      "Epoch 458/1000\n",
      "45/45 [==============================] - 0s 788us/step - loss: 1.7673 - accuracy: 0.1639 - val_loss: 1.7811 - val_accuracy: 0.1500\n",
      "Epoch 459/1000\n",
      "45/45 [==============================] - 0s 780us/step - loss: 1.7670 - accuracy: 0.1861 - val_loss: 1.7820 - val_accuracy: 0.1500\n",
      "Epoch 460/1000\n",
      "45/45 [==============================] - 0s 794us/step - loss: 1.7672 - accuracy: 0.1861 - val_loss: 1.7817 - val_accuracy: 0.1500\n",
      "Epoch 461/1000\n",
      "45/45 [==============================] - 0s 775us/step - loss: 1.7675 - accuracy: 0.1861 - val_loss: 1.7822 - val_accuracy: 0.1500\n",
      "Epoch 462/1000\n",
      "45/45 [==============================] - 0s 829us/step - loss: 1.7673 - accuracy: 0.1861 - val_loss: 1.7810 - val_accuracy: 0.1500\n",
      "Epoch 463/1000\n",
      "45/45 [==============================] - 0s 801us/step - loss: 1.7670 - accuracy: 0.1861 - val_loss: 1.7819 - val_accuracy: 0.1500\n",
      "Epoch 464/1000\n",
      "45/45 [==============================] - 0s 775us/step - loss: 1.7672 - accuracy: 0.1861 - val_loss: 1.7820 - val_accuracy: 0.1500\n",
      "Epoch 465/1000\n",
      "45/45 [==============================] - 0s 801us/step - loss: 1.7673 - accuracy: 0.1861 - val_loss: 1.7815 - val_accuracy: 0.1500\n",
      "Epoch 466/1000\n",
      "45/45 [==============================] - 0s 795us/step - loss: 1.7670 - accuracy: 0.1861 - val_loss: 1.7826 - val_accuracy: 0.1500\n",
      "Epoch 467/1000\n",
      "45/45 [==============================] - 0s 768us/step - loss: 1.7670 - accuracy: 0.1583 - val_loss: 1.7818 - val_accuracy: 0.1500\n",
      "Epoch 468/1000\n",
      "45/45 [==============================] - 0s 779us/step - loss: 1.7671 - accuracy: 0.1861 - val_loss: 1.7818 - val_accuracy: 0.1500\n",
      "Epoch 469/1000\n",
      "45/45 [==============================] - 0s 794us/step - loss: 1.7669 - accuracy: 0.1861 - val_loss: 1.7816 - val_accuracy: 0.1500\n",
      "Epoch 470/1000\n",
      "45/45 [==============================] - 0s 806us/step - loss: 1.7672 - accuracy: 0.1861 - val_loss: 1.7825 - val_accuracy: 0.1500\n",
      "Epoch 471/1000\n",
      "45/45 [==============================] - 0s 810us/step - loss: 1.7672 - accuracy: 0.1861 - val_loss: 1.7815 - val_accuracy: 0.1500\n",
      "Epoch 472/1000\n",
      "45/45 [==============================] - 0s 794us/step - loss: 1.7669 - accuracy: 0.1861 - val_loss: 1.7822 - val_accuracy: 0.1500\n",
      "Epoch 473/1000\n",
      "45/45 [==============================] - 0s 823us/step - loss: 1.7668 - accuracy: 0.1861 - val_loss: 1.7823 - val_accuracy: 0.1500\n",
      "Epoch 474/1000\n",
      "45/45 [==============================] - 0s 902us/step - loss: 1.7673 - accuracy: 0.1861 - val_loss: 1.7823 - val_accuracy: 0.1500\n",
      "Epoch 475/1000\n",
      "45/45 [==============================] - 0s 748us/step - loss: 1.7676 - accuracy: 0.1861 - val_loss: 1.7815 - val_accuracy: 0.1500\n",
      "Epoch 476/1000\n",
      "45/45 [==============================] - 0s 786us/step - loss: 1.7679 - accuracy: 0.1861 - val_loss: 1.7810 - val_accuracy: 0.1500\n",
      "Epoch 477/1000\n",
      "45/45 [==============================] - 0s 745us/step - loss: 1.7670 - accuracy: 0.1861 - val_loss: 1.7815 - val_accuracy: 0.1500\n",
      "Epoch 478/1000\n",
      "45/45 [==============================] - 0s 775us/step - loss: 1.7673 - accuracy: 0.1500 - val_loss: 1.7819 - val_accuracy: 0.1500\n",
      "Epoch 479/1000\n",
      "45/45 [==============================] - 0s 790us/step - loss: 1.7674 - accuracy: 0.1528 - val_loss: 1.7825 - val_accuracy: 0.1500\n",
      "Epoch 480/1000\n",
      "45/45 [==============================] - 0s 837us/step - loss: 1.7675 - accuracy: 0.1861 - val_loss: 1.7812 - val_accuracy: 0.1500\n",
      "Epoch 481/1000\n",
      "45/45 [==============================] - 0s 764us/step - loss: 1.7667 - accuracy: 0.1694 - val_loss: 1.7818 - val_accuracy: 0.1500\n",
      "Epoch 482/1000\n",
      "45/45 [==============================] - 0s 796us/step - loss: 1.7670 - accuracy: 0.1861 - val_loss: 1.7817 - val_accuracy: 0.1500\n",
      "Epoch 483/1000\n",
      "45/45 [==============================] - 0s 780us/step - loss: 1.7670 - accuracy: 0.1861 - val_loss: 1.7820 - val_accuracy: 0.1500\n",
      "Epoch 484/1000\n",
      "45/45 [==============================] - 0s 799us/step - loss: 1.7670 - accuracy: 0.1861 - val_loss: 1.7824 - val_accuracy: 0.1500\n",
      "Epoch 485/1000\n",
      "45/45 [==============================] - 0s 806us/step - loss: 1.7667 - accuracy: 0.1861 - val_loss: 1.7820 - val_accuracy: 0.1500\n",
      "Epoch 486/1000\n",
      "45/45 [==============================] - 0s 775us/step - loss: 1.7674 - accuracy: 0.1861 - val_loss: 1.7818 - val_accuracy: 0.1500\n",
      "Epoch 487/1000\n",
      "45/45 [==============================] - 0s 808us/step - loss: 1.7668 - accuracy: 0.1861 - val_loss: 1.7818 - val_accuracy: 0.1500\n",
      "Epoch 488/1000\n",
      "45/45 [==============================] - 0s 788us/step - loss: 1.7667 - accuracy: 0.1861 - val_loss: 1.7819 - val_accuracy: 0.1500\n",
      "Epoch 489/1000\n",
      "45/45 [==============================] - 0s 789us/step - loss: 1.7669 - accuracy: 0.1861 - val_loss: 1.7819 - val_accuracy: 0.1500\n",
      "Epoch 490/1000\n",
      "45/45 [==============================] - 0s 788us/step - loss: 1.7673 - accuracy: 0.1861 - val_loss: 1.7814 - val_accuracy: 0.1500\n",
      "Epoch 491/1000\n",
      "45/45 [==============================] - 0s 804us/step - loss: 1.7669 - accuracy: 0.1556 - val_loss: 1.7820 - val_accuracy: 0.1500\n",
      "Epoch 492/1000\n",
      "45/45 [==============================] - 0s 779us/step - loss: 1.7669 - accuracy: 0.1639 - val_loss: 1.7824 - val_accuracy: 0.1500\n",
      "Epoch 493/1000\n",
      "45/45 [==============================] - 0s 815us/step - loss: 1.7670 - accuracy: 0.1861 - val_loss: 1.7825 - val_accuracy: 0.1500\n",
      "Epoch 494/1000\n",
      "45/45 [==============================] - 0s 804us/step - loss: 1.7669 - accuracy: 0.1861 - val_loss: 1.7818 - val_accuracy: 0.1500\n",
      "Epoch 495/1000\n",
      "45/45 [==============================] - 0s 774us/step - loss: 1.7668 - accuracy: 0.1861 - val_loss: 1.7818 - val_accuracy: 0.1500\n",
      "Epoch 496/1000\n",
      "45/45 [==============================] - 0s 788us/step - loss: 1.7670 - accuracy: 0.1861 - val_loss: 1.7814 - val_accuracy: 0.1500\n",
      "Epoch 497/1000\n",
      "45/45 [==============================] - 0s 785us/step - loss: 1.7670 - accuracy: 0.1861 - val_loss: 1.7815 - val_accuracy: 0.1500\n",
      "Epoch 498/1000\n",
      "45/45 [==============================] - 0s 791us/step - loss: 1.7666 - accuracy: 0.1861 - val_loss: 1.7820 - val_accuracy: 0.1500\n",
      "Epoch 499/1000\n",
      "45/45 [==============================] - 0s 780us/step - loss: 1.7673 - accuracy: 0.1861 - val_loss: 1.7823 - val_accuracy: 0.1500\n",
      "Epoch 500/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 0s 800us/step - loss: 1.7669 - accuracy: 0.1861 - val_loss: 1.7818 - val_accuracy: 0.1500\n",
      "Epoch 501/1000\n",
      "45/45 [==============================] - 0s 782us/step - loss: 1.7672 - accuracy: 0.1861 - val_loss: 1.7819 - val_accuracy: 0.1500\n",
      "Epoch 502/1000\n",
      "45/45 [==============================] - 0s 792us/step - loss: 1.7671 - accuracy: 0.1861 - val_loss: 1.7815 - val_accuracy: 0.1500\n",
      "Epoch 503/1000\n",
      "45/45 [==============================] - 0s 814us/step - loss: 1.7666 - accuracy: 0.1861 - val_loss: 1.7816 - val_accuracy: 0.1500\n",
      "Epoch 504/1000\n",
      "45/45 [==============================] - 0s 793us/step - loss: 1.7667 - accuracy: 0.1861 - val_loss: 1.7817 - val_accuracy: 0.1500\n",
      "Epoch 505/1000\n",
      "45/45 [==============================] - 0s 799us/step - loss: 1.7672 - accuracy: 0.1861 - val_loss: 1.7819 - val_accuracy: 0.1500\n",
      "Epoch 506/1000\n",
      "45/45 [==============================] - 0s 757us/step - loss: 1.7667 - accuracy: 0.1861 - val_loss: 1.7820 - val_accuracy: 0.1500\n",
      "Epoch 507/1000\n",
      "45/45 [==============================] - 0s 816us/step - loss: 1.7670 - accuracy: 0.1861 - val_loss: 1.7813 - val_accuracy: 0.1500\n",
      "Epoch 508/1000\n",
      "45/45 [==============================] - 0s 783us/step - loss: 1.7669 - accuracy: 0.1861 - val_loss: 1.7818 - val_accuracy: 0.1500\n",
      "Epoch 509/1000\n",
      "45/45 [==============================] - 0s 812us/step - loss: 1.7668 - accuracy: 0.1861 - val_loss: 1.7825 - val_accuracy: 0.1500\n",
      "Epoch 510/1000\n",
      "45/45 [==============================] - 0s 809us/step - loss: 1.7671 - accuracy: 0.1861 - val_loss: 1.7814 - val_accuracy: 0.1500\n",
      "Epoch 511/1000\n",
      "45/45 [==============================] - 0s 788us/step - loss: 1.7672 - accuracy: 0.1861 - val_loss: 1.7810 - val_accuracy: 0.1500\n",
      "Epoch 512/1000\n",
      "45/45 [==============================] - 0s 774us/step - loss: 1.7669 - accuracy: 0.1861 - val_loss: 1.7819 - val_accuracy: 0.1500\n",
      "Epoch 513/1000\n",
      "45/45 [==============================] - 0s 787us/step - loss: 1.7668 - accuracy: 0.1861 - val_loss: 1.7816 - val_accuracy: 0.1500\n",
      "Epoch 514/1000\n",
      "45/45 [==============================] - 0s 787us/step - loss: 1.7669 - accuracy: 0.1861 - val_loss: 1.7822 - val_accuracy: 0.1500\n",
      "Epoch 515/1000\n",
      "45/45 [==============================] - 0s 808us/step - loss: 1.7668 - accuracy: 0.1861 - val_loss: 1.7820 - val_accuracy: 0.1500\n",
      "Epoch 516/1000\n",
      "45/45 [==============================] - 0s 775us/step - loss: 1.7669 - accuracy: 0.1722 - val_loss: 1.7820 - val_accuracy: 0.1500\n",
      "Epoch 517/1000\n",
      "45/45 [==============================] - 0s 786us/step - loss: 1.7667 - accuracy: 0.1861 - val_loss: 1.7819 - val_accuracy: 0.1500\n",
      "Epoch 518/1000\n",
      "45/45 [==============================] - 0s 815us/step - loss: 1.7671 - accuracy: 0.1861 - val_loss: 1.7816 - val_accuracy: 0.1500\n",
      "Epoch 519/1000\n",
      "45/45 [==============================] - 0s 785us/step - loss: 1.7670 - accuracy: 0.1444 - val_loss: 1.7821 - val_accuracy: 0.1500\n",
      "Epoch 520/1000\n",
      "45/45 [==============================] - 0s 750us/step - loss: 1.7668 - accuracy: 0.1861 - val_loss: 1.7820 - val_accuracy: 0.1500\n",
      "Epoch 521/1000\n",
      "45/45 [==============================] - 0s 762us/step - loss: 1.7669 - accuracy: 0.1861 - val_loss: 1.7821 - val_accuracy: 0.1500\n",
      "Epoch 522/1000\n",
      "45/45 [==============================] - 0s 806us/step - loss: 1.7668 - accuracy: 0.1861 - val_loss: 1.7819 - val_accuracy: 0.1500\n",
      "Epoch 523/1000\n",
      "45/45 [==============================] - 0s 779us/step - loss: 1.7668 - accuracy: 0.1861 - val_loss: 1.7818 - val_accuracy: 0.1500\n",
      "Epoch 524/1000\n",
      "45/45 [==============================] - 0s 783us/step - loss: 1.7666 - accuracy: 0.1861 - val_loss: 1.7822 - val_accuracy: 0.1500\n",
      "Epoch 525/1000\n",
      "45/45 [==============================] - 0s 812us/step - loss: 1.7667 - accuracy: 0.1861 - val_loss: 1.7822 - val_accuracy: 0.1500\n",
      "Epoch 526/1000\n",
      "45/45 [==============================] - 0s 763us/step - loss: 1.7670 - accuracy: 0.1861 - val_loss: 1.7815 - val_accuracy: 0.1500\n",
      "Epoch 527/1000\n",
      "45/45 [==============================] - 0s 801us/step - loss: 1.7668 - accuracy: 0.1861 - val_loss: 1.7818 - val_accuracy: 0.1500\n",
      "Epoch 528/1000\n",
      "45/45 [==============================] - 0s 800us/step - loss: 1.7666 - accuracy: 0.1722 - val_loss: 1.7818 - val_accuracy: 0.1500\n",
      "Epoch 529/1000\n",
      "45/45 [==============================] - 0s 789us/step - loss: 1.7668 - accuracy: 0.1861 - val_loss: 1.7817 - val_accuracy: 0.1500\n",
      "Epoch 530/1000\n",
      "45/45 [==============================] - 0s 818us/step - loss: 1.7667 - accuracy: 0.1861 - val_loss: 1.7819 - val_accuracy: 0.1500\n",
      "Epoch 531/1000\n",
      "45/45 [==============================] - 0s 799us/step - loss: 1.7667 - accuracy: 0.1861 - val_loss: 1.7815 - val_accuracy: 0.1500\n",
      "Epoch 532/1000\n",
      "45/45 [==============================] - 0s 788us/step - loss: 1.7667 - accuracy: 0.1861 - val_loss: 1.7815 - val_accuracy: 0.1500\n",
      "Epoch 533/1000\n",
      "45/45 [==============================] - 0s 792us/step - loss: 1.7666 - accuracy: 0.1861 - val_loss: 1.7820 - val_accuracy: 0.1500\n",
      "Epoch 534/1000\n",
      "45/45 [==============================] - 0s 793us/step - loss: 1.7668 - accuracy: 0.1861 - val_loss: 1.7823 - val_accuracy: 0.1500\n",
      "Epoch 535/1000\n",
      "45/45 [==============================] - 0s 805us/step - loss: 1.7668 - accuracy: 0.1861 - val_loss: 1.7816 - val_accuracy: 0.1500\n",
      "Epoch 536/1000\n",
      "45/45 [==============================] - 0s 810us/step - loss: 1.7667 - accuracy: 0.1861 - val_loss: 1.7818 - val_accuracy: 0.1500\n",
      "Epoch 537/1000\n",
      "45/45 [==============================] - 0s 789us/step - loss: 1.7667 - accuracy: 0.1528 - val_loss: 1.7822 - val_accuracy: 0.1500\n",
      "Epoch 538/1000\n",
      "45/45 [==============================] - 0s 795us/step - loss: 1.7669 - accuracy: 0.1861 - val_loss: 1.7821 - val_accuracy: 0.1500\n",
      "Epoch 539/1000\n",
      "45/45 [==============================] - 0s 774us/step - loss: 1.7668 - accuracy: 0.1861 - val_loss: 1.7824 - val_accuracy: 0.1500\n",
      "Epoch 540/1000\n",
      "45/45 [==============================] - 0s 790us/step - loss: 1.7667 - accuracy: 0.1861 - val_loss: 1.7822 - val_accuracy: 0.1500\n",
      "Epoch 541/1000\n",
      "45/45 [==============================] - 0s 786us/step - loss: 1.7668 - accuracy: 0.1861 - val_loss: 1.7816 - val_accuracy: 0.1500\n",
      "Epoch 542/1000\n",
      "45/45 [==============================] - 0s 832us/step - loss: 1.7668 - accuracy: 0.1861 - val_loss: 1.7819 - val_accuracy: 0.1500\n",
      "Epoch 543/1000\n",
      "45/45 [==============================] - 0s 791us/step - loss: 1.7669 - accuracy: 0.1861 - val_loss: 1.7822 - val_accuracy: 0.1500\n",
      "Epoch 544/1000\n",
      "45/45 [==============================] - 0s 803us/step - loss: 1.7669 - accuracy: 0.1861 - val_loss: 1.7817 - val_accuracy: 0.1500\n",
      "Epoch 545/1000\n",
      "45/45 [==============================] - 0s 812us/step - loss: 1.7667 - accuracy: 0.1861 - val_loss: 1.7821 - val_accuracy: 0.1500\n",
      "Epoch 546/1000\n",
      "45/45 [==============================] - 0s 782us/step - loss: 1.7669 - accuracy: 0.1667 - val_loss: 1.7817 - val_accuracy: 0.1500\n",
      "Epoch 547/1000\n",
      "45/45 [==============================] - 0s 759us/step - loss: 1.7669 - accuracy: 0.1861 - val_loss: 1.7817 - val_accuracy: 0.1500\n",
      "Epoch 548/1000\n",
      "45/45 [==============================] - 0s 827us/step - loss: 1.7669 - accuracy: 0.1861 - val_loss: 1.7816 - val_accuracy: 0.1500\n",
      "Epoch 549/1000\n",
      "45/45 [==============================] - 0s 806us/step - loss: 1.7671 - accuracy: 0.1861 - val_loss: 1.7819 - val_accuracy: 0.1500\n",
      "Epoch 550/1000\n",
      "45/45 [==============================] - 0s 785us/step - loss: 1.7667 - accuracy: 0.1861 - val_loss: 1.7817 - val_accuracy: 0.1500\n",
      "Epoch 551/1000\n",
      "45/45 [==============================] - 0s 869us/step - loss: 1.7668 - accuracy: 0.1861 - val_loss: 1.7825 - val_accuracy: 0.1500\n",
      "Epoch 552/1000\n",
      "45/45 [==============================] - 0s 819us/step - loss: 1.7666 - accuracy: 0.1861 - val_loss: 1.7822 - val_accuracy: 0.1500\n",
      "Epoch 553/1000\n",
      "45/45 [==============================] - 0s 796us/step - loss: 1.7668 - accuracy: 0.1861 - val_loss: 1.7821 - val_accuracy: 0.1500\n",
      "Epoch 554/1000\n",
      "45/45 [==============================] - 0s 773us/step - loss: 1.7666 - accuracy: 0.1861 - val_loss: 1.7822 - val_accuracy: 0.1500\n",
      "Epoch 555/1000\n",
      "45/45 [==============================] - 0s 780us/step - loss: 1.7670 - accuracy: 0.1861 - val_loss: 1.7827 - val_accuracy: 0.1500\n",
      "Epoch 556/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 0s 782us/step - loss: 1.7668 - accuracy: 0.1861 - val_loss: 1.7823 - val_accuracy: 0.1500\n",
      "Epoch 557/1000\n",
      "45/45 [==============================] - 0s 785us/step - loss: 1.7668 - accuracy: 0.1861 - val_loss: 1.7821 - val_accuracy: 0.1500\n",
      "Epoch 558/1000\n",
      "45/45 [==============================] - 0s 797us/step - loss: 1.7665 - accuracy: 0.1861 - val_loss: 1.7820 - val_accuracy: 0.1500\n",
      "Epoch 559/1000\n",
      "45/45 [==============================] - 0s 788us/step - loss: 1.7668 - accuracy: 0.1861 - val_loss: 1.7817 - val_accuracy: 0.1500\n",
      "Epoch 560/1000\n",
      "45/45 [==============================] - 0s 788us/step - loss: 1.7669 - accuracy: 0.1500 - val_loss: 1.7822 - val_accuracy: 0.1500\n",
      "Epoch 561/1000\n",
      "45/45 [==============================] - 0s 790us/step - loss: 1.7668 - accuracy: 0.1861 - val_loss: 1.7824 - val_accuracy: 0.1500\n",
      "Epoch 562/1000\n",
      "45/45 [==============================] - 0s 812us/step - loss: 1.7665 - accuracy: 0.1861 - val_loss: 1.7817 - val_accuracy: 0.1500\n",
      "Epoch 563/1000\n",
      "45/45 [==============================] - 0s 816us/step - loss: 1.7670 - accuracy: 0.1861 - val_loss: 1.7819 - val_accuracy: 0.1500\n",
      "Epoch 564/1000\n",
      "45/45 [==============================] - 0s 786us/step - loss: 1.7669 - accuracy: 0.1861 - val_loss: 1.7822 - val_accuracy: 0.1500\n",
      "Epoch 565/1000\n",
      "45/45 [==============================] - 0s 797us/step - loss: 1.7668 - accuracy: 0.1861 - val_loss: 1.7817 - val_accuracy: 0.1500\n",
      "Epoch 566/1000\n",
      "45/45 [==============================] - 0s 829us/step - loss: 1.7668 - accuracy: 0.1861 - val_loss: 1.7816 - val_accuracy: 0.1500\n",
      "Epoch 567/1000\n",
      "45/45 [==============================] - 0s 904us/step - loss: 1.7668 - accuracy: 0.1861 - val_loss: 1.7816 - val_accuracy: 0.1500\n",
      "Epoch 568/1000\n",
      "45/45 [==============================] - 0s 785us/step - loss: 1.7667 - accuracy: 0.1861 - val_loss: 1.7823 - val_accuracy: 0.1500\n",
      "Epoch 569/1000\n",
      "45/45 [==============================] - 0s 822us/step - loss: 1.7666 - accuracy: 0.1861 - val_loss: 1.7819 - val_accuracy: 0.1500\n",
      "Epoch 570/1000\n",
      "45/45 [==============================] - 0s 807us/step - loss: 1.7666 - accuracy: 0.1861 - val_loss: 1.7820 - val_accuracy: 0.1500\n",
      "Epoch 571/1000\n",
      "45/45 [==============================] - 0s 738us/step - loss: 1.7667 - accuracy: 0.1861 - val_loss: 1.7822 - val_accuracy: 0.1500\n",
      "Epoch 572/1000\n",
      "45/45 [==============================] - 0s 792us/step - loss: 1.7668 - accuracy: 0.1861 - val_loss: 1.7821 - val_accuracy: 0.1500\n",
      "Epoch 573/1000\n",
      "45/45 [==============================] - 0s 761us/step - loss: 1.7668 - accuracy: 0.1861 - val_loss: 1.7819 - val_accuracy: 0.1500\n",
      "Epoch 574/1000\n",
      "45/45 [==============================] - 0s 769us/step - loss: 1.7667 - accuracy: 0.1861 - val_loss: 1.7819 - val_accuracy: 0.1500\n",
      "Epoch 575/1000\n",
      "45/45 [==============================] - 0s 815us/step - loss: 1.7670 - accuracy: 0.1861 - val_loss: 1.7818 - val_accuracy: 0.1500\n",
      "Epoch 576/1000\n",
      "45/45 [==============================] - 0s 791us/step - loss: 1.7667 - accuracy: 0.1861 - val_loss: 1.7818 - val_accuracy: 0.1500\n",
      "Epoch 577/1000\n",
      "45/45 [==============================] - 0s 793us/step - loss: 1.7670 - accuracy: 0.1861 - val_loss: 1.7817 - val_accuracy: 0.1500\n",
      "Epoch 578/1000\n",
      "45/45 [==============================] - 0s 774us/step - loss: 1.7667 - accuracy: 0.1861 - val_loss: 1.7821 - val_accuracy: 0.1500\n",
      "Epoch 579/1000\n",
      "45/45 [==============================] - 0s 824us/step - loss: 1.7666 - accuracy: 0.1861 - val_loss: 1.7822 - val_accuracy: 0.1500\n",
      "Epoch 580/1000\n",
      "45/45 [==============================] - 0s 794us/step - loss: 1.7667 - accuracy: 0.1861 - val_loss: 1.7818 - val_accuracy: 0.1500\n",
      "Epoch 581/1000\n",
      "45/45 [==============================] - 0s 819us/step - loss: 1.7669 - accuracy: 0.1861 - val_loss: 1.7824 - val_accuracy: 0.1500\n",
      "Epoch 582/1000\n",
      "45/45 [==============================] - 0s 784us/step - loss: 1.7667 - accuracy: 0.1861 - val_loss: 1.7818 - val_accuracy: 0.1500\n",
      "Epoch 583/1000\n",
      "45/45 [==============================] - 0s 802us/step - loss: 1.7666 - accuracy: 0.1861 - val_loss: 1.7818 - val_accuracy: 0.1500\n",
      "Epoch 584/1000\n",
      "45/45 [==============================] - 0s 798us/step - loss: 1.7666 - accuracy: 0.1861 - val_loss: 1.7821 - val_accuracy: 0.1500\n",
      "Epoch 585/1000\n",
      "45/45 [==============================] - 0s 804us/step - loss: 1.7669 - accuracy: 0.1861 - val_loss: 1.7821 - val_accuracy: 0.1500\n",
      "Epoch 586/1000\n",
      "45/45 [==============================] - 0s 800us/step - loss: 1.7666 - accuracy: 0.1861 - val_loss: 1.7825 - val_accuracy: 0.1500\n",
      "Epoch 587/1000\n",
      "45/45 [==============================] - 0s 795us/step - loss: 1.7668 - accuracy: 0.1861 - val_loss: 1.7823 - val_accuracy: 0.1500\n",
      "Epoch 588/1000\n",
      "45/45 [==============================] - 0s 760us/step - loss: 1.7666 - accuracy: 0.1861 - val_loss: 1.7821 - val_accuracy: 0.1500\n",
      "Epoch 589/1000\n",
      "45/45 [==============================] - 0s 762us/step - loss: 1.7665 - accuracy: 0.1861 - val_loss: 1.7818 - val_accuracy: 0.1500\n",
      "Epoch 590/1000\n",
      "45/45 [==============================] - 0s 787us/step - loss: 1.7667 - accuracy: 0.1861 - val_loss: 1.7822 - val_accuracy: 0.1500\n",
      "Epoch 591/1000\n",
      "45/45 [==============================] - 0s 797us/step - loss: 1.7666 - accuracy: 0.1861 - val_loss: 1.7821 - val_accuracy: 0.1500\n",
      "Epoch 592/1000\n",
      "45/45 [==============================] - 0s 834us/step - loss: 1.7666 - accuracy: 0.1861 - val_loss: 1.7822 - val_accuracy: 0.1500\n",
      "Epoch 593/1000\n",
      "45/45 [==============================] - 0s 773us/step - loss: 1.7667 - accuracy: 0.1861 - val_loss: 1.7823 - val_accuracy: 0.1500\n",
      "Epoch 594/1000\n",
      "45/45 [==============================] - 0s 817us/step - loss: 1.7666 - accuracy: 0.1861 - val_loss: 1.7820 - val_accuracy: 0.1500\n",
      "Epoch 595/1000\n",
      "45/45 [==============================] - 0s 785us/step - loss: 1.7666 - accuracy: 0.1861 - val_loss: 1.7819 - val_accuracy: 0.1500\n",
      "Epoch 596/1000\n",
      "45/45 [==============================] - 0s 802us/step - loss: 1.7668 - accuracy: 0.1861 - val_loss: 1.7820 - val_accuracy: 0.1500\n",
      "Epoch 597/1000\n",
      "45/45 [==============================] - 0s 804us/step - loss: 1.7667 - accuracy: 0.1861 - val_loss: 1.7822 - val_accuracy: 0.1500\n",
      "Epoch 598/1000\n",
      "45/45 [==============================] - 0s 813us/step - loss: 1.7666 - accuracy: 0.1861 - val_loss: 1.7819 - val_accuracy: 0.1500\n",
      "Epoch 599/1000\n",
      "45/45 [==============================] - 0s 785us/step - loss: 1.7666 - accuracy: 0.1861 - val_loss: 1.7823 - val_accuracy: 0.1500\n",
      "Epoch 600/1000\n",
      "45/45 [==============================] - 0s 790us/step - loss: 1.7666 - accuracy: 0.1861 - val_loss: 1.7821 - val_accuracy: 0.1500\n",
      "Epoch 601/1000\n",
      "45/45 [==============================] - 0s 806us/step - loss: 1.7669 - accuracy: 0.1861 - val_loss: 1.7821 - val_accuracy: 0.1500\n",
      "Epoch 602/1000\n",
      "45/45 [==============================] - 0s 799us/step - loss: 1.7667 - accuracy: 0.1861 - val_loss: 1.7818 - val_accuracy: 0.1500\n",
      "Epoch 603/1000\n",
      "45/45 [==============================] - 0s 791us/step - loss: 1.7667 - accuracy: 0.1861 - val_loss: 1.7823 - val_accuracy: 0.1500\n",
      "Epoch 604/1000\n",
      "45/45 [==============================] - 0s 791us/step - loss: 1.7666 - accuracy: 0.1861 - val_loss: 1.7821 - val_accuracy: 0.1500\n",
      "Epoch 605/1000\n",
      "45/45 [==============================] - 0s 761us/step - loss: 1.7666 - accuracy: 0.1861 - val_loss: 1.7821 - val_accuracy: 0.1500\n",
      "Epoch 606/1000\n",
      "45/45 [==============================] - 0s 771us/step - loss: 1.7669 - accuracy: 0.1861 - val_loss: 1.7821 - val_accuracy: 0.1500\n",
      "Epoch 607/1000\n",
      "45/45 [==============================] - 0s 824us/step - loss: 1.7668 - accuracy: 0.1861 - val_loss: 1.7821 - val_accuracy: 0.1500\n",
      "Epoch 608/1000\n",
      "45/45 [==============================] - 0s 772us/step - loss: 1.7669 - accuracy: 0.1861 - val_loss: 1.7823 - val_accuracy: 0.1500\n",
      "Epoch 609/1000\n",
      "45/45 [==============================] - 0s 818us/step - loss: 1.7668 - accuracy: 0.1861 - val_loss: 1.7822 - val_accuracy: 0.1500\n",
      "Epoch 610/1000\n",
      "45/45 [==============================] - 0s 781us/step - loss: 1.7667 - accuracy: 0.1861 - val_loss: 1.7820 - val_accuracy: 0.1500\n",
      "Epoch 611/1000\n",
      "45/45 [==============================] - 0s 805us/step - loss: 1.7667 - accuracy: 0.1861 - val_loss: 1.7824 - val_accuracy: 0.1500\n",
      "Epoch 612/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 0s 813us/step - loss: 1.7667 - accuracy: 0.1861 - val_loss: 1.7819 - val_accuracy: 0.1500\n",
      "Epoch 613/1000\n",
      "45/45 [==============================] - 0s 804us/step - loss: 1.7667 - accuracy: 0.1861 - val_loss: 1.7820 - val_accuracy: 0.1500\n",
      "Epoch 614/1000\n",
      "45/45 [==============================] - 0s 806us/step - loss: 1.7669 - accuracy: 0.1861 - val_loss: 1.7818 - val_accuracy: 0.1500\n",
      "Epoch 615/1000\n",
      "45/45 [==============================] - 0s 811us/step - loss: 1.7670 - accuracy: 0.1861 - val_loss: 1.7824 - val_accuracy: 0.1500\n",
      "Epoch 616/1000\n",
      "45/45 [==============================] - 0s 779us/step - loss: 1.7665 - accuracy: 0.1861 - val_loss: 1.7823 - val_accuracy: 0.1500\n",
      "Epoch 617/1000\n",
      "45/45 [==============================] - 0s 807us/step - loss: 1.7666 - accuracy: 0.1861 - val_loss: 1.7822 - val_accuracy: 0.1500\n",
      "Epoch 618/1000\n",
      "45/45 [==============================] - 0s 799us/step - loss: 1.7665 - accuracy: 0.1861 - val_loss: 1.7825 - val_accuracy: 0.1500\n",
      "Epoch 619/1000\n",
      "45/45 [==============================] - 0s 763us/step - loss: 1.7668 - accuracy: 0.1861 - val_loss: 1.7821 - val_accuracy: 0.1500\n",
      "Epoch 620/1000\n",
      "45/45 [==============================] - 0s 792us/step - loss: 1.7672 - accuracy: 0.1861 - val_loss: 1.7818 - val_accuracy: 0.1500\n",
      "Epoch 621/1000\n",
      "45/45 [==============================] - 0s 774us/step - loss: 1.7668 - accuracy: 0.1861 - val_loss: 1.7822 - val_accuracy: 0.1500\n",
      "Epoch 622/1000\n",
      "45/45 [==============================] - 0s 815us/step - loss: 1.7667 - accuracy: 0.1861 - val_loss: 1.7823 - val_accuracy: 0.1500\n",
      "Epoch 623/1000\n",
      "45/45 [==============================] - 0s 788us/step - loss: 1.7667 - accuracy: 0.1861 - val_loss: 1.7820 - val_accuracy: 0.1500\n",
      "Epoch 624/1000\n",
      "45/45 [==============================] - 0s 767us/step - loss: 1.7667 - accuracy: 0.1861 - val_loss: 1.7825 - val_accuracy: 0.1500\n",
      "Epoch 625/1000\n",
      "45/45 [==============================] - 0s 759us/step - loss: 1.7666 - accuracy: 0.1861 - val_loss: 1.7821 - val_accuracy: 0.1500\n",
      "Epoch 626/1000\n",
      "45/45 [==============================] - 0s 801us/step - loss: 1.7666 - accuracy: 0.1861 - val_loss: 1.7824 - val_accuracy: 0.1500\n",
      "Epoch 627/1000\n",
      "45/45 [==============================] - 0s 797us/step - loss: 1.7668 - accuracy: 0.1861 - val_loss: 1.7818 - val_accuracy: 0.1500\n",
      "Epoch 628/1000\n",
      "45/45 [==============================] - 0s 802us/step - loss: 1.7670 - accuracy: 0.1861 - val_loss: 1.7827 - val_accuracy: 0.1500\n",
      "Epoch 629/1000\n",
      "45/45 [==============================] - 0s 782us/step - loss: 1.7668 - accuracy: 0.1861 - val_loss: 1.7824 - val_accuracy: 0.1500\n",
      "Epoch 630/1000\n",
      "45/45 [==============================] - 0s 808us/step - loss: 1.7665 - accuracy: 0.1861 - val_loss: 1.7820 - val_accuracy: 0.1500\n",
      "Epoch 631/1000\n",
      "45/45 [==============================] - 0s 781us/step - loss: 1.7669 - accuracy: 0.1861 - val_loss: 1.7823 - val_accuracy: 0.1500\n",
      "Epoch 632/1000\n",
      "45/45 [==============================] - 0s 808us/step - loss: 1.7667 - accuracy: 0.1861 - val_loss: 1.7821 - val_accuracy: 0.1500\n",
      "Epoch 633/1000\n",
      "45/45 [==============================] - 0s 776us/step - loss: 1.7667 - accuracy: 0.1861 - val_loss: 1.7820 - val_accuracy: 0.1500\n",
      "Epoch 634/1000\n",
      "45/45 [==============================] - 0s 804us/step - loss: 1.7668 - accuracy: 0.1639 - val_loss: 1.7818 - val_accuracy: 0.1500\n",
      "Epoch 635/1000\n",
      "45/45 [==============================] - 0s 777us/step - loss: 1.7665 - accuracy: 0.1861 - val_loss: 1.7821 - val_accuracy: 0.1500\n",
      "Epoch 636/1000\n",
      "45/45 [==============================] - 0s 806us/step - loss: 1.7667 - accuracy: 0.1861 - val_loss: 1.7820 - val_accuracy: 0.1500\n",
      "Epoch 637/1000\n",
      "45/45 [==============================] - 0s 792us/step - loss: 1.7666 - accuracy: 0.1861 - val_loss: 1.7821 - val_accuracy: 0.1500\n",
      "Epoch 638/1000\n",
      "45/45 [==============================] - 0s 809us/step - loss: 1.7667 - accuracy: 0.1861 - val_loss: 1.7821 - val_accuracy: 0.1500\n",
      "Epoch 639/1000\n",
      "45/45 [==============================] - 0s 764us/step - loss: 1.7666 - accuracy: 0.1861 - val_loss: 1.7822 - val_accuracy: 0.1500\n",
      "Epoch 640/1000\n",
      "45/45 [==============================] - 0s 769us/step - loss: 1.7669 - accuracy: 0.1861 - val_loss: 1.7820 - val_accuracy: 0.1500\n",
      "Epoch 641/1000\n",
      "45/45 [==============================] - 0s 937us/step - loss: 1.7667 - accuracy: 0.1861 - val_loss: 1.7823 - val_accuracy: 0.1500\n",
      "Epoch 642/1000\n",
      "45/45 [==============================] - 0s 798us/step - loss: 1.7669 - accuracy: 0.1417 - val_loss: 1.7821 - val_accuracy: 0.1500\n",
      "Epoch 643/1000\n",
      "45/45 [==============================] - 0s 782us/step - loss: 1.7666 - accuracy: 0.1861 - val_loss: 1.7821 - val_accuracy: 0.1500\n",
      "Epoch 644/1000\n",
      "45/45 [==============================] - 0s 812us/step - loss: 1.7665 - accuracy: 0.1861 - val_loss: 1.7822 - val_accuracy: 0.1500\n",
      "Epoch 645/1000\n",
      "45/45 [==============================] - 0s 798us/step - loss: 1.7669 - accuracy: 0.1861 - val_loss: 1.7823 - val_accuracy: 0.1500\n",
      "Epoch 646/1000\n",
      "45/45 [==============================] - 0s 779us/step - loss: 1.7669 - accuracy: 0.1861 - val_loss: 1.7821 - val_accuracy: 0.1500\n",
      "Epoch 647/1000\n",
      "45/45 [==============================] - 0s 798us/step - loss: 1.7667 - accuracy: 0.1861 - val_loss: 1.7823 - val_accuracy: 0.1500\n",
      "Epoch 648/1000\n",
      "45/45 [==============================] - 0s 818us/step - loss: 1.7667 - accuracy: 0.1861 - val_loss: 1.7822 - val_accuracy: 0.1500\n",
      "Epoch 649/1000\n",
      "45/45 [==============================] - 0s 818us/step - loss: 1.7667 - accuracy: 0.1861 - val_loss: 1.7823 - val_accuracy: 0.1500\n",
      "Epoch 650/1000\n",
      "45/45 [==============================] - 0s 798us/step - loss: 1.7666 - accuracy: 0.1861 - val_loss: 1.7820 - val_accuracy: 0.1500\n",
      "Epoch 651/1000\n",
      "45/45 [==============================] - 0s 807us/step - loss: 1.7669 - accuracy: 0.1861 - val_loss: 1.7820 - val_accuracy: 0.1500\n",
      "Epoch 652/1000\n",
      "45/45 [==============================] - 0s 776us/step - loss: 1.7667 - accuracy: 0.1861 - val_loss: 1.7821 - val_accuracy: 0.1500\n",
      "Epoch 653/1000\n",
      "45/45 [==============================] - 0s 801us/step - loss: 1.7667 - accuracy: 0.1861 - val_loss: 1.7820 - val_accuracy: 0.1500\n",
      "Epoch 654/1000\n",
      "45/45 [==============================] - 0s 790us/step - loss: 1.7666 - accuracy: 0.1861 - val_loss: 1.7822 - val_accuracy: 0.1500\n",
      "Epoch 655/1000\n",
      "45/45 [==============================] - 0s 805us/step - loss: 1.7667 - accuracy: 0.1861 - val_loss: 1.7821 - val_accuracy: 0.1500\n",
      "Epoch 656/1000\n",
      "45/45 [==============================] - 0s 788us/step - loss: 1.7666 - accuracy: 0.1861 - val_loss: 1.7826 - val_accuracy: 0.1500\n",
      "Epoch 657/1000\n",
      "45/45 [==============================] - 0s 824us/step - loss: 1.7667 - accuracy: 0.1861 - val_loss: 1.7823 - val_accuracy: 0.1500\n",
      "Epoch 658/1000\n",
      "45/45 [==============================] - 0s 773us/step - loss: 1.7669 - accuracy: 0.1861 - val_loss: 1.7821 - val_accuracy: 0.1500\n",
      "Epoch 659/1000\n",
      "45/45 [==============================] - 0s 778us/step - loss: 1.7666 - accuracy: 0.1861 - val_loss: 1.7823 - val_accuracy: 0.1500\n",
      "Epoch 660/1000\n",
      "45/45 [==============================] - 0s 789us/step - loss: 1.7666 - accuracy: 0.1861 - val_loss: 1.7822 - val_accuracy: 0.1500\n",
      "Epoch 661/1000\n",
      "45/45 [==============================] - 0s 782us/step - loss: 1.7666 - accuracy: 0.1861 - val_loss: 1.7825 - val_accuracy: 0.1500\n",
      "Epoch 662/1000\n",
      "45/45 [==============================] - 0s 814us/step - loss: 1.7668 - accuracy: 0.1861 - val_loss: 1.7821 - val_accuracy: 0.1500\n",
      "Epoch 663/1000\n",
      "45/45 [==============================] - 0s 802us/step - loss: 1.7666 - accuracy: 0.1861 - val_loss: 1.7824 - val_accuracy: 0.1500\n",
      "Epoch 664/1000\n",
      "45/45 [==============================] - 0s 779us/step - loss: 1.7667 - accuracy: 0.1861 - val_loss: 1.7827 - val_accuracy: 0.1500\n",
      "Epoch 665/1000\n",
      "45/45 [==============================] - 0s 809us/step - loss: 1.7666 - accuracy: 0.1861 - val_loss: 1.7821 - val_accuracy: 0.1500\n",
      "Epoch 666/1000\n",
      "45/45 [==============================] - 0s 780us/step - loss: 1.7666 - accuracy: 0.1861 - val_loss: 1.7819 - val_accuracy: 0.1500\n",
      "Epoch 667/1000\n",
      "45/45 [==============================] - 0s 824us/step - loss: 1.7666 - accuracy: 0.1861 - val_loss: 1.7820 - val_accuracy: 0.1500\n",
      "Epoch 668/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 0s 774us/step - loss: 1.7669 - accuracy: 0.1861 - val_loss: 1.7821 - val_accuracy: 0.1500\n",
      "Epoch 669/1000\n",
      "45/45 [==============================] - 0s 815us/step - loss: 1.7665 - accuracy: 0.1861 - val_loss: 1.7821 - val_accuracy: 0.1500\n",
      "Epoch 670/1000\n",
      "45/45 [==============================] - 0s 808us/step - loss: 1.7666 - accuracy: 0.1861 - val_loss: 1.7821 - val_accuracy: 0.1500\n",
      "Epoch 671/1000\n",
      "45/45 [==============================] - 0s 819us/step - loss: 1.7666 - accuracy: 0.1861 - val_loss: 1.7823 - val_accuracy: 0.1500\n",
      "Epoch 672/1000\n",
      "45/45 [==============================] - 0s 783us/step - loss: 1.7666 - accuracy: 0.1861 - val_loss: 1.7822 - val_accuracy: 0.1500\n",
      "Epoch 673/1000\n",
      "45/45 [==============================] - 0s 776us/step - loss: 1.7665 - accuracy: 0.1861 - val_loss: 1.7823 - val_accuracy: 0.1500\n",
      "Epoch 674/1000\n",
      "45/45 [==============================] - 0s 779us/step - loss: 1.7668 - accuracy: 0.1861 - val_loss: 1.7821 - val_accuracy: 0.1500\n",
      "Epoch 675/1000\n",
      "45/45 [==============================] - 0s 805us/step - loss: 1.7668 - accuracy: 0.1861 - val_loss: 1.7822 - val_accuracy: 0.1500\n",
      "Epoch 676/1000\n",
      "45/45 [==============================] - 0s 779us/step - loss: 1.7667 - accuracy: 0.1861 - val_loss: 1.7824 - val_accuracy: 0.1500\n",
      "Epoch 677/1000\n",
      "45/45 [==============================] - 0s 776us/step - loss: 1.7665 - accuracy: 0.1861 - val_loss: 1.7822 - val_accuracy: 0.1500\n",
      "Epoch 678/1000\n",
      "45/45 [==============================] - 0s 775us/step - loss: 1.7666 - accuracy: 0.1861 - val_loss: 1.7823 - val_accuracy: 0.1500\n",
      "Epoch 679/1000\n",
      "45/45 [==============================] - 0s 777us/step - loss: 1.7667 - accuracy: 0.1861 - val_loss: 1.7825 - val_accuracy: 0.1500\n",
      "Epoch 680/1000\n",
      "45/45 [==============================] - 0s 777us/step - loss: 1.7667 - accuracy: 0.1861 - val_loss: 1.7819 - val_accuracy: 0.1500\n",
      "Epoch 681/1000\n",
      "45/45 [==============================] - 0s 799us/step - loss: 1.7669 - accuracy: 0.1861 - val_loss: 1.7820 - val_accuracy: 0.1500\n",
      "Epoch 682/1000\n",
      "45/45 [==============================] - 0s 800us/step - loss: 1.7665 - accuracy: 0.1861 - val_loss: 1.7822 - val_accuracy: 0.1500\n",
      "Epoch 683/1000\n",
      "45/45 [==============================] - 0s 812us/step - loss: 1.7667 - accuracy: 0.1861 - val_loss: 1.7821 - val_accuracy: 0.1500\n",
      "Epoch 684/1000\n",
      "45/45 [==============================] - 0s 766us/step - loss: 1.7667 - accuracy: 0.1861 - val_loss: 1.7822 - val_accuracy: 0.1500\n",
      "Epoch 685/1000\n",
      "45/45 [==============================] - 0s 829us/step - loss: 1.7669 - accuracy: 0.1444 - val_loss: 1.7823 - val_accuracy: 0.1500\n",
      "Epoch 686/1000\n",
      "45/45 [==============================] - 0s 779us/step - loss: 1.7668 - accuracy: 0.1861 - val_loss: 1.7822 - val_accuracy: 0.1500\n",
      "Epoch 687/1000\n",
      "45/45 [==============================] - 0s 768us/step - loss: 1.7668 - accuracy: 0.1861 - val_loss: 1.7826 - val_accuracy: 0.1500\n",
      "Epoch 688/1000\n",
      "45/45 [==============================] - 0s 784us/step - loss: 1.7666 - accuracy: 0.1861 - val_loss: 1.7821 - val_accuracy: 0.1500\n",
      "Epoch 689/1000\n",
      "45/45 [==============================] - 0s 801us/step - loss: 1.7669 - accuracy: 0.1861 - val_loss: 1.7823 - val_accuracy: 0.1500\n",
      "Epoch 690/1000\n",
      "45/45 [==============================] - 0s 826us/step - loss: 1.7666 - accuracy: 0.1861 - val_loss: 1.7824 - val_accuracy: 0.1500\n",
      "Epoch 691/1000\n",
      "45/45 [==============================] - 0s 790us/step - loss: 1.7666 - accuracy: 0.1861 - val_loss: 1.7822 - val_accuracy: 0.1500\n",
      "Epoch 692/1000\n",
      "45/45 [==============================] - 0s 781us/step - loss: 1.7668 - accuracy: 0.1861 - val_loss: 1.7823 - val_accuracy: 0.1500\n",
      "Epoch 693/1000\n",
      "45/45 [==============================] - 0s 776us/step - loss: 1.7665 - accuracy: 0.1861 - val_loss: 1.7822 - val_accuracy: 0.1500\n",
      "Epoch 694/1000\n",
      "45/45 [==============================] - 0s 791us/step - loss: 1.7666 - accuracy: 0.1861 - val_loss: 1.7822 - val_accuracy: 0.1500\n",
      "Epoch 695/1000\n",
      "45/45 [==============================] - 0s 779us/step - loss: 1.7668 - accuracy: 0.1861 - val_loss: 1.7824 - val_accuracy: 0.1500\n",
      "Epoch 696/1000\n",
      "45/45 [==============================] - 0s 772us/step - loss: 1.7668 - accuracy: 0.1861 - val_loss: 1.7820 - val_accuracy: 0.1500\n",
      "Epoch 697/1000\n",
      "45/45 [==============================] - 0s 774us/step - loss: 1.7666 - accuracy: 0.1861 - val_loss: 1.7822 - val_accuracy: 0.1500\n",
      "Epoch 698/1000\n",
      "45/45 [==============================] - 0s 796us/step - loss: 1.7666 - accuracy: 0.1861 - val_loss: 1.7822 - val_accuracy: 0.1500\n",
      "Epoch 699/1000\n",
      "45/45 [==============================] - 0s 824us/step - loss: 1.7668 - accuracy: 0.1861 - val_loss: 1.7825 - val_accuracy: 0.1500\n",
      "Epoch 700/1000\n",
      "45/45 [==============================] - 0s 859us/step - loss: 1.7667 - accuracy: 0.1861 - val_loss: 1.7824 - val_accuracy: 0.1500\n",
      "Epoch 701/1000\n",
      "45/45 [==============================] - 0s 776us/step - loss: 1.7666 - accuracy: 0.1861 - val_loss: 1.7819 - val_accuracy: 0.1500\n",
      "Epoch 702/1000\n",
      "45/45 [==============================] - 0s 791us/step - loss: 1.7667 - accuracy: 0.1861 - val_loss: 1.7819 - val_accuracy: 0.1500\n",
      "Epoch 703/1000\n",
      "45/45 [==============================] - 0s 796us/step - loss: 1.7669 - accuracy: 0.1861 - val_loss: 1.7825 - val_accuracy: 0.1500\n",
      "Epoch 704/1000\n",
      "45/45 [==============================] - 0s 766us/step - loss: 1.7666 - accuracy: 0.1861 - val_loss: 1.7820 - val_accuracy: 0.1500\n",
      "Epoch 705/1000\n",
      "45/45 [==============================] - 0s 796us/step - loss: 1.7666 - accuracy: 0.1861 - val_loss: 1.7825 - val_accuracy: 0.1500\n",
      "Epoch 706/1000\n",
      "45/45 [==============================] - 0s 782us/step - loss: 1.7665 - accuracy: 0.1861 - val_loss: 1.7822 - val_accuracy: 0.1500\n",
      "Epoch 707/1000\n",
      "45/45 [==============================] - 0s 798us/step - loss: 1.7667 - accuracy: 0.1861 - val_loss: 1.7824 - val_accuracy: 0.1500\n",
      "Epoch 708/1000\n",
      "45/45 [==============================] - 0s 796us/step - loss: 1.7666 - accuracy: 0.1861 - val_loss: 1.7820 - val_accuracy: 0.1500\n",
      "Epoch 709/1000\n",
      "45/45 [==============================] - 0s 754us/step - loss: 1.7671 - accuracy: 0.1861 - val_loss: 1.7818 - val_accuracy: 0.1500\n",
      "Epoch 710/1000\n",
      "45/45 [==============================] - 0s 820us/step - loss: 1.7666 - accuracy: 0.1861 - val_loss: 1.7821 - val_accuracy: 0.1500\n",
      "Epoch 711/1000\n",
      "45/45 [==============================] - 0s 809us/step - loss: 1.7667 - accuracy: 0.1861 - val_loss: 1.7824 - val_accuracy: 0.1500\n",
      "Epoch 712/1000\n",
      "45/45 [==============================] - 0s 824us/step - loss: 1.7666 - accuracy: 0.1861 - val_loss: 1.7823 - val_accuracy: 0.1500\n",
      "Epoch 713/1000\n",
      "45/45 [==============================] - 0s 785us/step - loss: 1.7666 - accuracy: 0.1861 - val_loss: 1.7824 - val_accuracy: 0.1500\n",
      "Epoch 714/1000\n",
      "45/45 [==============================] - 0s 809us/step - loss: 1.7666 - accuracy: 0.1861 - val_loss: 1.7821 - val_accuracy: 0.1500\n",
      "Epoch 715/1000\n",
      "45/45 [==============================] - 0s 768us/step - loss: 1.7666 - accuracy: 0.1861 - val_loss: 1.7822 - val_accuracy: 0.1500\n",
      "Epoch 716/1000\n",
      "45/45 [==============================] - 0s 823us/step - loss: 1.7667 - accuracy: 0.1861 - val_loss: 1.7820 - val_accuracy: 0.1500\n",
      "Epoch 717/1000\n",
      "45/45 [==============================] - 0s 785us/step - loss: 1.7668 - accuracy: 0.1861 - val_loss: 1.7819 - val_accuracy: 0.1500\n",
      "Epoch 718/1000\n",
      "45/45 [==============================] - 0s 804us/step - loss: 1.7666 - accuracy: 0.1861 - val_loss: 1.7822 - val_accuracy: 0.1500\n",
      "Epoch 719/1000\n",
      "45/45 [==============================] - 0s 916us/step - loss: 2.9844 - accuracy: 0.1528 - val_loss: 2.0865 - val_accuracy: 0.1417\n",
      "Epoch 720/1000\n",
      "45/45 [==============================] - 0s 781us/step - loss: 3.0083 - accuracy: 0.1556 - val_loss: 1.8004 - val_accuracy: 0.1417\n",
      "Epoch 721/1000\n",
      "45/45 [==============================] - 0s 804us/step - loss: 1.7875 - accuracy: 0.1472 - val_loss: 1.8010 - val_accuracy: 0.1417\n",
      "Epoch 722/1000\n",
      "45/45 [==============================] - 0s 799us/step - loss: 1.7871 - accuracy: 0.1778 - val_loss: 1.7984 - val_accuracy: 0.1417\n",
      "Epoch 723/1000\n",
      "45/45 [==============================] - 0s 807us/step - loss: 1.7866 - accuracy: 0.1778 - val_loss: 1.7992 - val_accuracy: 0.1417\n",
      "Epoch 724/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 0s 799us/step - loss: 1.7865 - accuracy: 0.1778 - val_loss: 1.7992 - val_accuracy: 0.1417\n",
      "Epoch 725/1000\n",
      "45/45 [==============================] - 0s 781us/step - loss: 1.7864 - accuracy: 0.1778 - val_loss: 1.7989 - val_accuracy: 0.1417\n",
      "Epoch 726/1000\n",
      "45/45 [==============================] - 0s 795us/step - loss: 1.7865 - accuracy: 0.1778 - val_loss: 1.7991 - val_accuracy: 0.1417\n",
      "Epoch 727/1000\n",
      "45/45 [==============================] - 0s 786us/step - loss: 1.7865 - accuracy: 0.1778 - val_loss: 1.7980 - val_accuracy: 0.1417\n",
      "Epoch 728/1000\n",
      "45/45 [==============================] - 0s 773us/step - loss: 1.7865 - accuracy: 0.1778 - val_loss: 1.7988 - val_accuracy: 0.1417\n",
      "Epoch 729/1000\n",
      "45/45 [==============================] - 0s 824us/step - loss: 1.7863 - accuracy: 0.1528 - val_loss: 1.7989 - val_accuracy: 0.1417\n",
      "Epoch 730/1000\n",
      "45/45 [==============================] - 0s 781us/step - loss: 1.7864 - accuracy: 0.1778 - val_loss: 1.7984 - val_accuracy: 0.1417\n",
      "Epoch 731/1000\n",
      "45/45 [==============================] - 0s 794us/step - loss: 1.7863 - accuracy: 0.1778 - val_loss: 1.7987 - val_accuracy: 0.1417\n",
      "Epoch 732/1000\n",
      "45/45 [==============================] - 0s 798us/step - loss: 1.7865 - accuracy: 0.1778 - val_loss: 1.7983 - val_accuracy: 0.1417\n",
      "Epoch 733/1000\n",
      "45/45 [==============================] - 0s 796us/step - loss: 1.7862 - accuracy: 0.1778 - val_loss: 1.7983 - val_accuracy: 0.1417\n",
      "Epoch 734/1000\n",
      "45/45 [==============================] - 0s 797us/step - loss: 1.7867 - accuracy: 0.1778 - val_loss: 1.7983 - val_accuracy: 0.1417\n",
      "Epoch 735/1000\n",
      "45/45 [==============================] - 0s 767us/step - loss: 1.7863 - accuracy: 0.1778 - val_loss: 1.7981 - val_accuracy: 0.1417\n",
      "Epoch 736/1000\n",
      "45/45 [==============================] - 0s 785us/step - loss: 1.7865 - accuracy: 0.1778 - val_loss: 1.7986 - val_accuracy: 0.1417\n",
      "Epoch 737/1000\n",
      "45/45 [==============================] - 0s 784us/step - loss: 1.7864 - accuracy: 0.1778 - val_loss: 1.7980 - val_accuracy: 0.1417\n",
      "Epoch 738/1000\n",
      "45/45 [==============================] - 0s 770us/step - loss: 1.7867 - accuracy: 0.1778 - val_loss: 1.7984 - val_accuracy: 0.1417\n",
      "Epoch 739/1000\n",
      "45/45 [==============================] - 0s 782us/step - loss: 1.7862 - accuracy: 0.1778 - val_loss: 1.7987 - val_accuracy: 0.1417\n",
      "Epoch 740/1000\n",
      "45/45 [==============================] - 0s 794us/step - loss: 1.7863 - accuracy: 0.1778 - val_loss: 1.7981 - val_accuracy: 0.1417\n",
      "Epoch 741/1000\n",
      "45/45 [==============================] - 0s 801us/step - loss: 1.7864 - accuracy: 0.1778 - val_loss: 1.7981 - val_accuracy: 0.1417\n",
      "Epoch 742/1000\n",
      "45/45 [==============================] - 0s 797us/step - loss: 1.7863 - accuracy: 0.1778 - val_loss: 1.7981 - val_accuracy: 0.1417\n",
      "Epoch 743/1000\n",
      "45/45 [==============================] - 0s 798us/step - loss: 1.7863 - accuracy: 0.1778 - val_loss: 1.7983 - val_accuracy: 0.1417\n",
      "Epoch 744/1000\n",
      "45/45 [==============================] - 0s 746us/step - loss: 1.7864 - accuracy: 0.1778 - val_loss: 1.7985 - val_accuracy: 0.1417\n",
      "Epoch 745/1000\n",
      "45/45 [==============================] - 0s 795us/step - loss: 1.7867 - accuracy: 0.1778 - val_loss: 1.7984 - val_accuracy: 0.1417\n",
      "Epoch 746/1000\n",
      "45/45 [==============================] - 0s 797us/step - loss: 1.7864 - accuracy: 0.1778 - val_loss: 1.7984 - val_accuracy: 0.1417\n",
      "Epoch 747/1000\n",
      "45/45 [==============================] - 0s 802us/step - loss: 1.7862 - accuracy: 0.1778 - val_loss: 1.7987 - val_accuracy: 0.1417\n",
      "Epoch 748/1000\n",
      "45/45 [==============================] - 0s 769us/step - loss: 1.7863 - accuracy: 0.1778 - val_loss: 1.7985 - val_accuracy: 0.1417\n",
      "Epoch 749/1000\n",
      "45/45 [==============================] - 0s 789us/step - loss: 1.7863 - accuracy: 0.1778 - val_loss: 1.7985 - val_accuracy: 0.1417\n",
      "Epoch 750/1000\n",
      "45/45 [==============================] - 0s 802us/step - loss: 1.7866 - accuracy: 0.1778 - val_loss: 1.7989 - val_accuracy: 0.1417\n",
      "Epoch 751/1000\n",
      "45/45 [==============================] - 0s 807us/step - loss: 1.7862 - accuracy: 0.1778 - val_loss: 1.7986 - val_accuracy: 0.1417\n",
      "Epoch 752/1000\n",
      "45/45 [==============================] - 0s 772us/step - loss: 1.7863 - accuracy: 0.1778 - val_loss: 1.7980 - val_accuracy: 0.1417\n",
      "Epoch 753/1000\n",
      "45/45 [==============================] - 0s 770us/step - loss: 1.7862 - accuracy: 0.1778 - val_loss: 1.7984 - val_accuracy: 0.1417\n",
      "Epoch 754/1000\n",
      "45/45 [==============================] - 0s 801us/step - loss: 1.7862 - accuracy: 0.1778 - val_loss: 1.7981 - val_accuracy: 0.1417\n",
      "Epoch 755/1000\n",
      "45/45 [==============================] - 0s 806us/step - loss: 1.7863 - accuracy: 0.1778 - val_loss: 1.7982 - val_accuracy: 0.1417\n",
      "Epoch 756/1000\n",
      "45/45 [==============================] - 0s 757us/step - loss: 1.7864 - accuracy: 0.1778 - val_loss: 1.7985 - val_accuracy: 0.1417\n",
      "Epoch 757/1000\n",
      "45/45 [==============================] - 0s 769us/step - loss: 1.7864 - accuracy: 0.1778 - val_loss: 1.7983 - val_accuracy: 0.1417\n",
      "Epoch 758/1000\n",
      "45/45 [==============================] - 0s 802us/step - loss: 1.7862 - accuracy: 0.1778 - val_loss: 1.7982 - val_accuracy: 0.1417\n",
      "Epoch 759/1000\n",
      "45/45 [==============================] - 0s 785us/step - loss: 1.7863 - accuracy: 0.1778 - val_loss: 1.7985 - val_accuracy: 0.1417\n",
      "Epoch 760/1000\n",
      "45/45 [==============================] - 0s 775us/step - loss: 1.7864 - accuracy: 0.1778 - val_loss: 1.7984 - val_accuracy: 0.1417\n",
      "Epoch 761/1000\n",
      "45/45 [==============================] - 0s 752us/step - loss: 1.7865 - accuracy: 0.1778 - val_loss: 1.7983 - val_accuracy: 0.1417\n",
      "Epoch 762/1000\n",
      "45/45 [==============================] - 0s 799us/step - loss: 1.7864 - accuracy: 0.1778 - val_loss: 1.7984 - val_accuracy: 0.1417\n",
      "Epoch 763/1000\n",
      "45/45 [==============================] - 0s 787us/step - loss: 1.7863 - accuracy: 0.1778 - val_loss: 1.7983 - val_accuracy: 0.1417\n",
      "Epoch 764/1000\n",
      "45/45 [==============================] - 0s 788us/step - loss: 1.7865 - accuracy: 0.1778 - val_loss: 1.7983 - val_accuracy: 0.1417\n",
      "Epoch 765/1000\n",
      "45/45 [==============================] - 0s 786us/step - loss: 1.7863 - accuracy: 0.1778 - val_loss: 1.7986 - val_accuracy: 0.1417\n",
      "Epoch 766/1000\n",
      "45/45 [==============================] - 0s 758us/step - loss: 1.7866 - accuracy: 0.1778 - val_loss: 1.7981 - val_accuracy: 0.1417\n",
      "Epoch 767/1000\n",
      "45/45 [==============================] - 0s 797us/step - loss: 1.7864 - accuracy: 0.1778 - val_loss: 1.7985 - val_accuracy: 0.1417\n",
      "Epoch 768/1000\n",
      "45/45 [==============================] - 0s 768us/step - loss: 1.7863 - accuracy: 0.1778 - val_loss: 1.7983 - val_accuracy: 0.1417\n",
      "Epoch 769/1000\n",
      "45/45 [==============================] - 0s 778us/step - loss: 1.7864 - accuracy: 0.1778 - val_loss: 1.7987 - val_accuracy: 0.1417\n",
      "Epoch 770/1000\n",
      "45/45 [==============================] - 0s 798us/step - loss: 1.7863 - accuracy: 0.1778 - val_loss: 1.7987 - val_accuracy: 0.1417\n",
      "Epoch 771/1000\n",
      "45/45 [==============================] - 0s 773us/step - loss: 1.7863 - accuracy: 0.1778 - val_loss: 1.7984 - val_accuracy: 0.1417\n",
      "Epoch 772/1000\n",
      "45/45 [==============================] - 0s 789us/step - loss: 1.7863 - accuracy: 0.1778 - val_loss: 1.7983 - val_accuracy: 0.1417\n",
      "Epoch 773/1000\n",
      "45/45 [==============================] - 0s 752us/step - loss: 1.7864 - accuracy: 0.1778 - val_loss: 1.7985 - val_accuracy: 0.1417\n",
      "Epoch 774/1000\n",
      "45/45 [==============================] - 0s 805us/step - loss: 1.7865 - accuracy: 0.1778 - val_loss: 1.7984 - val_accuracy: 0.1417\n",
      "Epoch 775/1000\n",
      "45/45 [==============================] - 0s 765us/step - loss: 1.7865 - accuracy: 0.1778 - val_loss: 1.7983 - val_accuracy: 0.1417\n",
      "Epoch 776/1000\n",
      "45/45 [==============================] - 0s 791us/step - loss: 1.7866 - accuracy: 0.1778 - val_loss: 1.7984 - val_accuracy: 0.1417\n",
      "Epoch 777/1000\n",
      "45/45 [==============================] - 0s 811us/step - loss: 1.7863 - accuracy: 0.1778 - val_loss: 1.7984 - val_accuracy: 0.1417\n",
      "Epoch 778/1000\n",
      "45/45 [==============================] - 0s 799us/step - loss: 1.7863 - accuracy: 0.1778 - val_loss: 1.7981 - val_accuracy: 0.1417\n",
      "Epoch 779/1000\n",
      "45/45 [==============================] - 0s 833us/step - loss: 1.7861 - accuracy: 0.1778 - val_loss: 1.7986 - val_accuracy: 0.1417\n",
      "Epoch 780/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 0s 817us/step - loss: 1.7863 - accuracy: 0.1778 - val_loss: 1.7985 - val_accuracy: 0.1417\n",
      "Epoch 781/1000\n",
      "45/45 [==============================] - 0s 820us/step - loss: 1.7863 - accuracy: 0.1778 - val_loss: 1.7986 - val_accuracy: 0.1417\n",
      "Epoch 782/1000\n",
      "45/45 [==============================] - 0s 819us/step - loss: 1.7865 - accuracy: 0.1778 - val_loss: 1.7982 - val_accuracy: 0.1417\n",
      "Epoch 783/1000\n",
      "45/45 [==============================] - 0s 759us/step - loss: 1.7865 - accuracy: 0.1778 - val_loss: 1.7989 - val_accuracy: 0.1417\n",
      "Epoch 784/1000\n",
      "45/45 [==============================] - 0s 827us/step - loss: 1.7864 - accuracy: 0.1778 - val_loss: 1.7987 - val_accuracy: 0.1417\n",
      "Epoch 785/1000\n",
      "45/45 [==============================] - 0s 781us/step - loss: 1.7862 - accuracy: 0.1778 - val_loss: 1.7985 - val_accuracy: 0.1417\n",
      "Epoch 786/1000\n",
      "45/45 [==============================] - 0s 789us/step - loss: 1.7862 - accuracy: 0.1778 - val_loss: 1.7984 - val_accuracy: 0.1417\n",
      "Epoch 787/1000\n",
      "45/45 [==============================] - 0s 797us/step - loss: 1.7864 - accuracy: 0.1778 - val_loss: 1.7985 - val_accuracy: 0.1417\n",
      "Epoch 788/1000\n",
      "45/45 [==============================] - 0s 792us/step - loss: 1.7866 - accuracy: 0.1778 - val_loss: 1.7981 - val_accuracy: 0.1417\n",
      "Epoch 789/1000\n",
      "45/45 [==============================] - 0s 770us/step - loss: 1.7864 - accuracy: 0.1778 - val_loss: 1.7986 - val_accuracy: 0.1417\n",
      "Epoch 790/1000\n",
      "45/45 [==============================] - 0s 822us/step - loss: 1.7863 - accuracy: 0.1778 - val_loss: 1.7984 - val_accuracy: 0.1417\n",
      "Epoch 791/1000\n",
      "45/45 [==============================] - 0s 804us/step - loss: 1.7863 - accuracy: 0.1778 - val_loss: 1.7986 - val_accuracy: 0.1417\n",
      "Epoch 792/1000\n",
      "45/45 [==============================] - 0s 796us/step - loss: 1.7863 - accuracy: 0.1778 - val_loss: 1.7985 - val_accuracy: 0.1417\n",
      "Epoch 793/1000\n",
      "45/45 [==============================] - 0s 794us/step - loss: 1.7866 - accuracy: 0.1778 - val_loss: 1.7987 - val_accuracy: 0.1417\n",
      "Epoch 794/1000\n",
      "45/45 [==============================] - 0s 808us/step - loss: 1.7865 - accuracy: 0.1778 - val_loss: 1.7986 - val_accuracy: 0.1417\n",
      "Epoch 795/1000\n",
      "45/45 [==============================] - 0s 823us/step - loss: 1.7862 - accuracy: 0.1778 - val_loss: 1.7982 - val_accuracy: 0.1417\n",
      "Epoch 796/1000\n",
      "45/45 [==============================] - 0s 789us/step - loss: 1.7865 - accuracy: 0.1778 - val_loss: 1.7979 - val_accuracy: 0.1417\n",
      "Epoch 797/1000\n",
      "45/45 [==============================] - 0s 769us/step - loss: 1.7864 - accuracy: 0.1778 - val_loss: 1.7979 - val_accuracy: 0.1417\n",
      "Epoch 798/1000\n",
      "45/45 [==============================] - 0s 773us/step - loss: 1.7864 - accuracy: 0.1778 - val_loss: 1.7986 - val_accuracy: 0.1417\n",
      "Epoch 799/1000\n",
      "45/45 [==============================] - 0s 774us/step - loss: 1.7867 - accuracy: 0.1778 - val_loss: 1.7981 - val_accuracy: 0.1417\n",
      "Epoch 800/1000\n",
      "45/45 [==============================] - 0s 786us/step - loss: 1.7861 - accuracy: 0.1778 - val_loss: 1.7982 - val_accuracy: 0.1417\n",
      "Epoch 801/1000\n",
      "45/45 [==============================] - 0s 781us/step - loss: 1.7864 - accuracy: 0.1778 - val_loss: 1.7986 - val_accuracy: 0.1417\n",
      "Epoch 802/1000\n",
      "45/45 [==============================] - 0s 810us/step - loss: 1.7863 - accuracy: 0.1778 - val_loss: 1.7981 - val_accuracy: 0.1417\n",
      "Epoch 803/1000\n",
      "45/45 [==============================] - 0s 768us/step - loss: 1.7863 - accuracy: 0.1778 - val_loss: 1.7984 - val_accuracy: 0.1417\n",
      "Epoch 804/1000\n",
      "45/45 [==============================] - 0s 838us/step - loss: 1.7862 - accuracy: 0.1778 - val_loss: 1.7985 - val_accuracy: 0.1417\n",
      "Epoch 805/1000\n",
      "45/45 [==============================] - 0s 759us/step - loss: 1.7864 - accuracy: 0.1778 - val_loss: 1.7980 - val_accuracy: 0.1417\n",
      "Epoch 806/1000\n",
      "45/45 [==============================] - 0s 787us/step - loss: 1.7864 - accuracy: 0.1778 - val_loss: 1.7984 - val_accuracy: 0.1417\n",
      "Epoch 807/1000\n",
      "45/45 [==============================] - 0s 773us/step - loss: 1.7862 - accuracy: 0.1778 - val_loss: 1.7983 - val_accuracy: 0.1417\n",
      "Epoch 808/1000\n",
      "45/45 [==============================] - 0s 811us/step - loss: 1.7863 - accuracy: 0.1778 - val_loss: 1.7984 - val_accuracy: 0.1417\n",
      "Epoch 809/1000\n",
      "45/45 [==============================] - 0s 803us/step - loss: 1.7864 - accuracy: 0.1778 - val_loss: 1.7988 - val_accuracy: 0.1417\n",
      "Epoch 810/1000\n",
      "45/45 [==============================] - 0s 926us/step - loss: 1.7865 - accuracy: 0.1778 - val_loss: 1.7983 - val_accuracy: 0.1417\n",
      "Epoch 811/1000\n",
      "45/45 [==============================] - 0s 777us/step - loss: 1.7863 - accuracy: 0.1778 - val_loss: 1.7987 - val_accuracy: 0.1417\n",
      "Epoch 812/1000\n",
      "45/45 [==============================] - 0s 819us/step - loss: 1.7863 - accuracy: 0.1778 - val_loss: 1.7985 - val_accuracy: 0.1417\n",
      "Epoch 813/1000\n",
      "45/45 [==============================] - 0s 811us/step - loss: 1.7864 - accuracy: 0.1778 - val_loss: 1.7985 - val_accuracy: 0.1417\n",
      "Epoch 814/1000\n",
      "45/45 [==============================] - 0s 821us/step - loss: 1.7861 - accuracy: 0.1778 - val_loss: 1.7983 - val_accuracy: 0.1417\n",
      "Epoch 815/1000\n",
      "45/45 [==============================] - 0s 816us/step - loss: 1.7863 - accuracy: 0.1778 - val_loss: 1.7983 - val_accuracy: 0.1417\n",
      "Epoch 816/1000\n",
      "45/45 [==============================] - 0s 810us/step - loss: 1.7864 - accuracy: 0.1778 - val_loss: 1.7985 - val_accuracy: 0.1417\n",
      "Epoch 817/1000\n",
      "45/45 [==============================] - 0s 804us/step - loss: 1.7865 - accuracy: 0.1778 - val_loss: 1.7985 - val_accuracy: 0.1417\n",
      "Epoch 818/1000\n",
      "45/45 [==============================] - 0s 774us/step - loss: 1.7864 - accuracy: 0.1639 - val_loss: 1.7984 - val_accuracy: 0.1417\n",
      "Epoch 819/1000\n",
      "45/45 [==============================] - 0s 802us/step - loss: 1.7865 - accuracy: 0.1778 - val_loss: 1.7983 - val_accuracy: 0.1417\n",
      "Epoch 820/1000\n",
      "45/45 [==============================] - 0s 807us/step - loss: 1.7863 - accuracy: 0.1667 - val_loss: 1.7985 - val_accuracy: 0.1417\n",
      "Epoch 821/1000\n",
      "45/45 [==============================] - 0s 801us/step - loss: 1.7865 - accuracy: 0.1778 - val_loss: 1.7979 - val_accuracy: 0.1417\n",
      "Epoch 822/1000\n",
      "45/45 [==============================] - 0s 784us/step - loss: 1.7863 - accuracy: 0.1778 - val_loss: 1.7980 - val_accuracy: 0.1417\n",
      "Epoch 823/1000\n",
      "45/45 [==============================] - 0s 788us/step - loss: 1.7864 - accuracy: 0.1778 - val_loss: 1.7983 - val_accuracy: 0.1417\n",
      "Epoch 824/1000\n",
      "45/45 [==============================] - 0s 796us/step - loss: 1.7866 - accuracy: 0.1778 - val_loss: 1.7979 - val_accuracy: 0.1417\n",
      "Epoch 825/1000\n",
      "45/45 [==============================] - 0s 790us/step - loss: 1.7864 - accuracy: 0.1778 - val_loss: 1.7983 - val_accuracy: 0.1417\n",
      "Epoch 826/1000\n",
      "45/45 [==============================] - 0s 817us/step - loss: 1.7862 - accuracy: 0.1778 - val_loss: 1.7985 - val_accuracy: 0.1417\n",
      "Epoch 827/1000\n",
      "45/45 [==============================] - 0s 831us/step - loss: 1.7861 - accuracy: 0.1778 - val_loss: 1.7985 - val_accuracy: 0.1417\n",
      "Epoch 828/1000\n",
      "45/45 [==============================] - 0s 821us/step - loss: 1.7865 - accuracy: 0.1778 - val_loss: 1.7981 - val_accuracy: 0.1417\n",
      "Epoch 829/1000\n",
      "45/45 [==============================] - 0s 771us/step - loss: 1.7863 - accuracy: 0.1778 - val_loss: 1.7985 - val_accuracy: 0.1417\n",
      "Epoch 830/1000\n",
      "45/45 [==============================] - 0s 821us/step - loss: 1.7863 - accuracy: 0.1778 - val_loss: 1.7984 - val_accuracy: 0.1417\n",
      "Epoch 831/1000\n",
      "45/45 [==============================] - 0s 786us/step - loss: 1.7863 - accuracy: 0.1778 - val_loss: 1.7981 - val_accuracy: 0.1417\n",
      "Epoch 832/1000\n",
      "45/45 [==============================] - 0s 814us/step - loss: 1.7864 - accuracy: 0.1778 - val_loss: 1.7985 - val_accuracy: 0.1417\n",
      "Epoch 833/1000\n",
      "45/45 [==============================] - 0s 839us/step - loss: 1.7862 - accuracy: 0.1778 - val_loss: 1.7986 - val_accuracy: 0.1417\n",
      "Epoch 834/1000\n",
      "45/45 [==============================] - 0s 780us/step - loss: 1.7864 - accuracy: 0.1778 - val_loss: 1.7984 - val_accuracy: 0.1417\n",
      "Epoch 835/1000\n",
      "45/45 [==============================] - 0s 804us/step - loss: 1.7864 - accuracy: 0.1778 - val_loss: 1.7982 - val_accuracy: 0.1417\n",
      "Epoch 836/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 0s 812us/step - loss: 1.7862 - accuracy: 0.1778 - val_loss: 1.7983 - val_accuracy: 0.1417\n",
      "Epoch 837/1000\n",
      "45/45 [==============================] - 0s 808us/step - loss: 1.7862 - accuracy: 0.1778 - val_loss: 1.7984 - val_accuracy: 0.1417\n",
      "Epoch 838/1000\n",
      "45/45 [==============================] - 0s 820us/step - loss: 1.7861 - accuracy: 0.1778 - val_loss: 1.7985 - val_accuracy: 0.1417\n",
      "Epoch 839/1000\n",
      "45/45 [==============================] - 0s 799us/step - loss: 1.7866 - accuracy: 0.1778 - val_loss: 1.7987 - val_accuracy: 0.1417\n",
      "Epoch 840/1000\n",
      "45/45 [==============================] - 0s 759us/step - loss: 1.7862 - accuracy: 0.1778 - val_loss: 1.7983 - val_accuracy: 0.1417\n",
      "Epoch 841/1000\n",
      "45/45 [==============================] - 0s 800us/step - loss: 1.7864 - accuracy: 0.1778 - val_loss: 1.7989 - val_accuracy: 0.1417\n",
      "Epoch 842/1000\n",
      "45/45 [==============================] - 0s 780us/step - loss: 1.7863 - accuracy: 0.1778 - val_loss: 1.7984 - val_accuracy: 0.1417\n",
      "Epoch 843/1000\n",
      "45/45 [==============================] - 0s 774us/step - loss: 1.7864 - accuracy: 0.1778 - val_loss: 1.7986 - val_accuracy: 0.1417\n",
      "Epoch 844/1000\n",
      "45/45 [==============================] - 0s 778us/step - loss: 1.7865 - accuracy: 0.1778 - val_loss: 1.7983 - val_accuracy: 0.1417\n",
      "Epoch 845/1000\n",
      "45/45 [==============================] - 0s 795us/step - loss: 1.7862 - accuracy: 0.1778 - val_loss: 1.7986 - val_accuracy: 0.1417\n",
      "Epoch 846/1000\n",
      "45/45 [==============================] - 0s 798us/step - loss: 1.7862 - accuracy: 0.1778 - val_loss: 1.7984 - val_accuracy: 0.1417\n",
      "Epoch 847/1000\n",
      "45/45 [==============================] - 0s 793us/step - loss: 1.7863 - accuracy: 0.1778 - val_loss: 1.7980 - val_accuracy: 0.1417\n",
      "Epoch 848/1000\n",
      "45/45 [==============================] - 0s 796us/step - loss: 1.7864 - accuracy: 0.1778 - val_loss: 1.7985 - val_accuracy: 0.1417\n",
      "Epoch 849/1000\n",
      "45/45 [==============================] - 0s 798us/step - loss: 1.7862 - accuracy: 0.1778 - val_loss: 1.7984 - val_accuracy: 0.1417\n",
      "Epoch 850/1000\n",
      "45/45 [==============================] - 0s 796us/step - loss: 1.7861 - accuracy: 0.1778 - val_loss: 1.7984 - val_accuracy: 0.1417\n",
      "Epoch 851/1000\n",
      "45/45 [==============================] - 0s 770us/step - loss: 1.7864 - accuracy: 0.1778 - val_loss: 1.7983 - val_accuracy: 0.1417\n",
      "Epoch 852/1000\n",
      "45/45 [==============================] - 0s 781us/step - loss: 1.7863 - accuracy: 0.1778 - val_loss: 1.7983 - val_accuracy: 0.1417\n",
      "Epoch 853/1000\n",
      "45/45 [==============================] - 0s 818us/step - loss: 1.7865 - accuracy: 0.1778 - val_loss: 1.7983 - val_accuracy: 0.1417\n",
      "Epoch 854/1000\n",
      "45/45 [==============================] - 0s 782us/step - loss: 1.7865 - accuracy: 0.1778 - val_loss: 1.7981 - val_accuracy: 0.1417\n",
      "Epoch 855/1000\n",
      "45/45 [==============================] - 0s 808us/step - loss: 1.7862 - accuracy: 0.1556 - val_loss: 1.7982 - val_accuracy: 0.1417\n",
      "Epoch 856/1000\n",
      "45/45 [==============================] - 0s 831us/step - loss: 1.7861 - accuracy: 0.1778 - val_loss: 1.7985 - val_accuracy: 0.1417\n",
      "Epoch 857/1000\n",
      "45/45 [==============================] - 0s 799us/step - loss: 1.7865 - accuracy: 0.1778 - val_loss: 1.7983 - val_accuracy: 0.1417\n",
      "Epoch 858/1000\n",
      "45/45 [==============================] - 0s 775us/step - loss: 1.7865 - accuracy: 0.1778 - val_loss: 1.7984 - val_accuracy: 0.1417\n",
      "Epoch 859/1000\n",
      "45/45 [==============================] - 0s 778us/step - loss: 1.7863 - accuracy: 0.1778 - val_loss: 1.7985 - val_accuracy: 0.1417\n",
      "Epoch 860/1000\n",
      "45/45 [==============================] - 0s 786us/step - loss: 1.7863 - accuracy: 0.1778 - val_loss: 1.7987 - val_accuracy: 0.1417\n",
      "Epoch 861/1000\n",
      "45/45 [==============================] - 0s 782us/step - loss: 1.7862 - accuracy: 0.1778 - val_loss: 1.7987 - val_accuracy: 0.1417\n",
      "Epoch 862/1000\n",
      "45/45 [==============================] - 0s 791us/step - loss: 1.7862 - accuracy: 0.1778 - val_loss: 1.7984 - val_accuracy: 0.1417\n",
      "Epoch 863/1000\n",
      "45/45 [==============================] - 0s 795us/step - loss: 1.7863 - accuracy: 0.1778 - val_loss: 1.7982 - val_accuracy: 0.1417\n",
      "Epoch 864/1000\n",
      "45/45 [==============================] - 0s 799us/step - loss: 1.7863 - accuracy: 0.1778 - val_loss: 1.7982 - val_accuracy: 0.1417\n",
      "Epoch 865/1000\n",
      "45/45 [==============================] - 0s 794us/step - loss: 1.7862 - accuracy: 0.1778 - val_loss: 1.7985 - val_accuracy: 0.1417\n",
      "Epoch 866/1000\n",
      "45/45 [==============================] - 0s 829us/step - loss: 1.7864 - accuracy: 0.1778 - val_loss: 1.7989 - val_accuracy: 0.1417\n",
      "Epoch 867/1000\n",
      "45/45 [==============================] - 0s 777us/step - loss: 1.7861 - accuracy: 0.1778 - val_loss: 1.7985 - val_accuracy: 0.1417\n",
      "Epoch 868/1000\n",
      "45/45 [==============================] - 0s 793us/step - loss: 1.7862 - accuracy: 0.1778 - val_loss: 1.7985 - val_accuracy: 0.1417\n",
      "Epoch 869/1000\n",
      "45/45 [==============================] - 0s 771us/step - loss: 1.7865 - accuracy: 0.1417 - val_loss: 1.7982 - val_accuracy: 0.1417\n",
      "Epoch 870/1000\n",
      "45/45 [==============================] - 0s 766us/step - loss: 1.7863 - accuracy: 0.1778 - val_loss: 1.7983 - val_accuracy: 0.1417\n",
      "Epoch 871/1000\n",
      "45/45 [==============================] - 0s 792us/step - loss: 1.7864 - accuracy: 0.1778 - val_loss: 1.7985 - val_accuracy: 0.1417\n",
      "Epoch 872/1000\n",
      "45/45 [==============================] - 0s 783us/step - loss: 1.7861 - accuracy: 0.1778 - val_loss: 1.7984 - val_accuracy: 0.1417\n",
      "Epoch 873/1000\n",
      "45/45 [==============================] - 0s 801us/step - loss: 1.7864 - accuracy: 0.1778 - val_loss: 1.7983 - val_accuracy: 0.1417\n",
      "Epoch 874/1000\n",
      "45/45 [==============================] - 0s 772us/step - loss: 1.7866 - accuracy: 0.1778 - val_loss: 1.7983 - val_accuracy: 0.1417\n",
      "Epoch 875/1000\n",
      "45/45 [==============================] - 0s 773us/step - loss: 1.7862 - accuracy: 0.1778 - val_loss: 1.7985 - val_accuracy: 0.1417\n",
      "Epoch 876/1000\n",
      "45/45 [==============================] - 0s 787us/step - loss: 1.7864 - accuracy: 0.1778 - val_loss: 1.7984 - val_accuracy: 0.1417\n",
      "Epoch 877/1000\n",
      "45/45 [==============================] - 0s 798us/step - loss: 1.7862 - accuracy: 0.1778 - val_loss: 1.7986 - val_accuracy: 0.1417\n",
      "Epoch 878/1000\n",
      "45/45 [==============================] - 0s 816us/step - loss: 1.7863 - accuracy: 0.1778 - val_loss: 1.7981 - val_accuracy: 0.1417\n",
      "Epoch 879/1000\n",
      "45/45 [==============================] - 0s 760us/step - loss: 1.7861 - accuracy: 0.1778 - val_loss: 1.7984 - val_accuracy: 0.1417\n",
      "Epoch 880/1000\n",
      "45/45 [==============================] - 0s 824us/step - loss: 1.7862 - accuracy: 0.1778 - val_loss: 1.7984 - val_accuracy: 0.1417\n",
      "Epoch 881/1000\n",
      "45/45 [==============================] - 0s 824us/step - loss: 1.7864 - accuracy: 0.1778 - val_loss: 1.7984 - val_accuracy: 0.1417\n",
      "Epoch 882/1000\n",
      "45/45 [==============================] - 0s 778us/step - loss: 1.7863 - accuracy: 0.1778 - val_loss: 1.7984 - val_accuracy: 0.1417\n",
      "Epoch 883/1000\n",
      "45/45 [==============================] - 0s 756us/step - loss: 1.7864 - accuracy: 0.1778 - val_loss: 1.7986 - val_accuracy: 0.1417\n",
      "Epoch 884/1000\n",
      "45/45 [==============================] - 0s 809us/step - loss: 1.7862 - accuracy: 0.1778 - val_loss: 1.7982 - val_accuracy: 0.1417\n",
      "Epoch 885/1000\n",
      "45/45 [==============================] - 0s 755us/step - loss: 1.7863 - accuracy: 0.1778 - val_loss: 1.7987 - val_accuracy: 0.1417\n",
      "Epoch 886/1000\n",
      "45/45 [==============================] - 0s 777us/step - loss: 1.7863 - accuracy: 0.1778 - val_loss: 1.7984 - val_accuracy: 0.1417\n",
      "Epoch 887/1000\n",
      "45/45 [==============================] - 0s 768us/step - loss: 1.7863 - accuracy: 0.1778 - val_loss: 1.7988 - val_accuracy: 0.1417\n",
      "Epoch 888/1000\n",
      "45/45 [==============================] - 0s 877us/step - loss: 1.7865 - accuracy: 0.1778 - val_loss: 1.7983 - val_accuracy: 0.1417\n",
      "Epoch 889/1000\n",
      "45/45 [==============================] - 0s 802us/step - loss: 1.7862 - accuracy: 0.1778 - val_loss: 1.7985 - val_accuracy: 0.1417\n",
      "Epoch 890/1000\n",
      "45/45 [==============================] - 0s 817us/step - loss: 1.7863 - accuracy: 0.1778 - val_loss: 1.7985 - val_accuracy: 0.1417\n",
      "Epoch 891/1000\n",
      "45/45 [==============================] - 0s 782us/step - loss: 1.7862 - accuracy: 0.1778 - val_loss: 1.7984 - val_accuracy: 0.1417\n",
      "Epoch 892/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 0s 784us/step - loss: 1.7867 - accuracy: 0.1778 - val_loss: 1.7987 - val_accuracy: 0.1417\n",
      "Epoch 893/1000\n",
      "45/45 [==============================] - 0s 794us/step - loss: 1.7865 - accuracy: 0.1778 - val_loss: 1.7986 - val_accuracy: 0.1417\n",
      "Epoch 894/1000\n",
      "45/45 [==============================] - 0s 828us/step - loss: 1.7863 - accuracy: 0.1778 - val_loss: 1.7982 - val_accuracy: 0.1417\n",
      "Epoch 895/1000\n",
      "45/45 [==============================] - 0s 789us/step - loss: 1.7864 - accuracy: 0.1778 - val_loss: 1.7984 - val_accuracy: 0.1417\n",
      "Epoch 896/1000\n",
      "45/45 [==============================] - 0s 811us/step - loss: 1.7863 - accuracy: 0.1778 - val_loss: 1.7983 - val_accuracy: 0.1417\n",
      "Epoch 897/1000\n",
      "45/45 [==============================] - 0s 809us/step - loss: 1.7862 - accuracy: 0.1778 - val_loss: 1.7985 - val_accuracy: 0.1417\n",
      "Epoch 898/1000\n",
      "45/45 [==============================] - 0s 803us/step - loss: 1.7861 - accuracy: 0.1778 - val_loss: 1.7986 - val_accuracy: 0.1417\n",
      "Epoch 899/1000\n",
      "45/45 [==============================] - 0s 793us/step - loss: 1.7862 - accuracy: 0.1778 - val_loss: 1.7983 - val_accuracy: 0.1417\n",
      "Epoch 900/1000\n",
      "45/45 [==============================] - 0s 774us/step - loss: 1.7862 - accuracy: 0.1778 - val_loss: 1.7985 - val_accuracy: 0.1417\n",
      "Epoch 901/1000\n",
      "45/45 [==============================] - 0s 775us/step - loss: 1.7862 - accuracy: 0.1778 - val_loss: 1.7987 - val_accuracy: 0.1417\n",
      "Epoch 902/1000\n",
      "45/45 [==============================] - 0s 785us/step - loss: 1.7863 - accuracy: 0.1778 - val_loss: 1.7985 - val_accuracy: 0.1417\n",
      "Epoch 903/1000\n",
      "45/45 [==============================] - 0s 773us/step - loss: 1.7864 - accuracy: 0.1778 - val_loss: 1.7987 - val_accuracy: 0.1417\n",
      "Epoch 904/1000\n",
      "45/45 [==============================] - 0s 763us/step - loss: 1.7862 - accuracy: 0.1778 - val_loss: 1.7983 - val_accuracy: 0.1417\n",
      "Epoch 905/1000\n",
      "45/45 [==============================] - 0s 776us/step - loss: 1.7864 - accuracy: 0.1778 - val_loss: 1.7986 - val_accuracy: 0.1417\n",
      "Epoch 906/1000\n",
      "45/45 [==============================] - 0s 796us/step - loss: 1.7864 - accuracy: 0.1778 - val_loss: 1.7987 - val_accuracy: 0.1417\n",
      "Epoch 907/1000\n",
      "45/45 [==============================] - 0s 802us/step - loss: 1.7865 - accuracy: 0.1778 - val_loss: 1.7981 - val_accuracy: 0.1417\n",
      "Epoch 908/1000\n",
      "45/45 [==============================] - 0s 739us/step - loss: 1.7862 - accuracy: 0.1778 - val_loss: 1.7986 - val_accuracy: 0.1417\n",
      "Epoch 909/1000\n",
      "45/45 [==============================] - 0s 806us/step - loss: 1.7863 - accuracy: 0.1778 - val_loss: 1.7985 - val_accuracy: 0.1417\n",
      "Epoch 910/1000\n",
      "45/45 [==============================] - 0s 767us/step - loss: 1.7863 - accuracy: 0.1778 - val_loss: 1.7981 - val_accuracy: 0.1417\n",
      "Epoch 911/1000\n",
      "45/45 [==============================] - 0s 777us/step - loss: 1.7863 - accuracy: 0.1778 - val_loss: 1.7986 - val_accuracy: 0.1417\n",
      "Epoch 912/1000\n",
      "45/45 [==============================] - 0s 779us/step - loss: 1.7862 - accuracy: 0.1778 - val_loss: 1.7985 - val_accuracy: 0.1417\n",
      "Epoch 913/1000\n",
      "45/45 [==============================] - 0s 774us/step - loss: 1.7864 - accuracy: 0.1778 - val_loss: 1.7981 - val_accuracy: 0.1417\n",
      "Epoch 914/1000\n",
      "45/45 [==============================] - 0s 791us/step - loss: 1.7862 - accuracy: 0.1778 - val_loss: 1.7981 - val_accuracy: 0.1417\n",
      "Epoch 915/1000\n",
      "45/45 [==============================] - 0s 801us/step - loss: 1.7863 - accuracy: 0.1778 - val_loss: 1.7984 - val_accuracy: 0.1417\n",
      "Epoch 916/1000\n",
      "45/45 [==============================] - 0s 807us/step - loss: 1.7862 - accuracy: 0.1778 - val_loss: 1.7981 - val_accuracy: 0.1417\n",
      "Epoch 917/1000\n",
      "45/45 [==============================] - 0s 787us/step - loss: 1.7863 - accuracy: 0.1778 - val_loss: 1.7987 - val_accuracy: 0.1417\n",
      "Epoch 918/1000\n",
      "45/45 [==============================] - 0s 789us/step - loss: 1.7862 - accuracy: 0.1778 - val_loss: 1.7987 - val_accuracy: 0.1417\n",
      "Epoch 919/1000\n",
      "45/45 [==============================] - 0s 814us/step - loss: 1.7863 - accuracy: 0.1556 - val_loss: 1.7985 - val_accuracy: 0.1417\n",
      "Epoch 920/1000\n",
      "45/45 [==============================] - 0s 795us/step - loss: 1.7862 - accuracy: 0.1778 - val_loss: 1.7984 - val_accuracy: 0.1417\n",
      "Epoch 921/1000\n",
      "45/45 [==============================] - 0s 800us/step - loss: 1.7863 - accuracy: 0.1778 - val_loss: 1.7981 - val_accuracy: 0.1417\n",
      "Epoch 922/1000\n",
      "45/45 [==============================] - 0s 792us/step - loss: 1.7863 - accuracy: 0.1778 - val_loss: 1.7982 - val_accuracy: 0.1417\n",
      "Epoch 923/1000\n",
      "45/45 [==============================] - 0s 775us/step - loss: 1.7863 - accuracy: 0.1778 - val_loss: 1.7984 - val_accuracy: 0.1417\n",
      "Epoch 924/1000\n",
      "45/45 [==============================] - 0s 788us/step - loss: 1.7862 - accuracy: 0.1778 - val_loss: 1.7986 - val_accuracy: 0.1417\n",
      "Epoch 925/1000\n",
      "45/45 [==============================] - 0s 795us/step - loss: 1.7862 - accuracy: 0.1778 - val_loss: 1.7985 - val_accuracy: 0.1417\n",
      "Epoch 926/1000\n",
      "45/45 [==============================] - 0s 818us/step - loss: 1.7862 - accuracy: 0.1778 - val_loss: 1.7985 - val_accuracy: 0.1417\n",
      "Epoch 927/1000\n",
      "45/45 [==============================] - 0s 812us/step - loss: 1.7863 - accuracy: 0.1778 - val_loss: 1.7986 - val_accuracy: 0.1417\n",
      "Epoch 928/1000\n",
      "45/45 [==============================] - 0s 753us/step - loss: 1.7866 - accuracy: 0.1778 - val_loss: 1.7984 - val_accuracy: 0.1417\n",
      "Epoch 929/1000\n",
      "45/45 [==============================] - 0s 863us/step - loss: 1.7864 - accuracy: 0.1778 - val_loss: 1.7985 - val_accuracy: 0.1417\n",
      "Epoch 930/1000\n",
      "45/45 [==============================] - 0s 766us/step - loss: 1.7864 - accuracy: 0.1778 - val_loss: 1.7984 - val_accuracy: 0.1417\n",
      "Epoch 931/1000\n",
      "45/45 [==============================] - 0s 838us/step - loss: 1.7862 - accuracy: 0.1778 - val_loss: 1.7984 - val_accuracy: 0.1417\n",
      "Epoch 932/1000\n",
      "45/45 [==============================] - 0s 792us/step - loss: 1.7864 - accuracy: 0.1778 - val_loss: 1.7987 - val_accuracy: 0.1417\n",
      "Epoch 933/1000\n",
      "45/45 [==============================] - 0s 780us/step - loss: 1.7863 - accuracy: 0.1778 - val_loss: 1.7985 - val_accuracy: 0.1417\n",
      "Epoch 934/1000\n",
      "45/45 [==============================] - 0s 799us/step - loss: 1.7865 - accuracy: 0.1778 - val_loss: 1.7990 - val_accuracy: 0.1417\n",
      "Epoch 935/1000\n",
      "45/45 [==============================] - 0s 794us/step - loss: 1.7862 - accuracy: 0.1778 - val_loss: 1.7985 - val_accuracy: 0.1417\n",
      "Epoch 936/1000\n",
      "45/45 [==============================] - 0s 818us/step - loss: 1.7864 - accuracy: 0.1778 - val_loss: 1.7982 - val_accuracy: 0.1417\n",
      "Epoch 937/1000\n",
      "45/45 [==============================] - 0s 802us/step - loss: 1.7861 - accuracy: 0.1778 - val_loss: 1.7984 - val_accuracy: 0.1417\n",
      "Epoch 938/1000\n",
      "45/45 [==============================] - 0s 787us/step - loss: 1.7861 - accuracy: 0.1778 - val_loss: 1.7983 - val_accuracy: 0.1417\n",
      "Epoch 939/1000\n",
      "45/45 [==============================] - 0s 796us/step - loss: 1.7863 - accuracy: 0.1778 - val_loss: 1.7987 - val_accuracy: 0.1417\n",
      "Epoch 940/1000\n",
      "45/45 [==============================] - 0s 790us/step - loss: 1.7863 - accuracy: 0.1778 - val_loss: 1.7986 - val_accuracy: 0.1417\n",
      "Epoch 941/1000\n",
      "45/45 [==============================] - 0s 802us/step - loss: 1.7863 - accuracy: 0.1778 - val_loss: 1.7985 - val_accuracy: 0.1417\n",
      "Epoch 942/1000\n",
      "45/45 [==============================] - 0s 794us/step - loss: 1.7863 - accuracy: 0.1778 - val_loss: 1.7981 - val_accuracy: 0.1417\n",
      "Epoch 943/1000\n",
      "45/45 [==============================] - 0s 813us/step - loss: 1.7861 - accuracy: 0.1778 - val_loss: 1.7984 - val_accuracy: 0.1417\n",
      "Epoch 944/1000\n",
      "45/45 [==============================] - 0s 793us/step - loss: 1.7864 - accuracy: 0.1778 - val_loss: 1.7982 - val_accuracy: 0.1417\n",
      "Epoch 945/1000\n",
      "45/45 [==============================] - 0s 802us/step - loss: 1.7863 - accuracy: 0.1778 - val_loss: 1.7985 - val_accuracy: 0.1417\n",
      "Epoch 946/1000\n",
      "45/45 [==============================] - 0s 817us/step - loss: 1.7863 - accuracy: 0.1778 - val_loss: 1.7983 - val_accuracy: 0.1417\n",
      "Epoch 947/1000\n",
      "45/45 [==============================] - 0s 789us/step - loss: 1.7866 - accuracy: 0.1778 - val_loss: 1.7981 - val_accuracy: 0.1417\n",
      "Epoch 948/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 0s 845us/step - loss: 1.7862 - accuracy: 0.1778 - val_loss: 1.7983 - val_accuracy: 0.1417\n",
      "Epoch 949/1000\n",
      "45/45 [==============================] - 0s 799us/step - loss: 1.7862 - accuracy: 0.1778 - val_loss: 1.7984 - val_accuracy: 0.1417\n",
      "Epoch 950/1000\n",
      "45/45 [==============================] - 0s 767us/step - loss: 1.7862 - accuracy: 0.1778 - val_loss: 1.7983 - val_accuracy: 0.1417\n",
      "Epoch 951/1000\n",
      "45/45 [==============================] - 0s 786us/step - loss: 1.7865 - accuracy: 0.1778 - val_loss: 1.7987 - val_accuracy: 0.1417\n",
      "Epoch 952/1000\n",
      "45/45 [==============================] - 0s 775us/step - loss: 1.7863 - accuracy: 0.1778 - val_loss: 1.7983 - val_accuracy: 0.1417\n",
      "Epoch 953/1000\n",
      "45/45 [==============================] - 0s 759us/step - loss: 1.7863 - accuracy: 0.1778 - val_loss: 1.7984 - val_accuracy: 0.1417\n",
      "Epoch 954/1000\n",
      "45/45 [==============================] - 0s 782us/step - loss: 1.7863 - accuracy: 0.1778 - val_loss: 1.7981 - val_accuracy: 0.1417\n",
      "Epoch 955/1000\n",
      "45/45 [==============================] - 0s 768us/step - loss: 1.7862 - accuracy: 0.1778 - val_loss: 1.7986 - val_accuracy: 0.1417\n",
      "Epoch 956/1000\n",
      "45/45 [==============================] - 0s 813us/step - loss: 1.7862 - accuracy: 0.1778 - val_loss: 1.7987 - val_accuracy: 0.1417\n",
      "Epoch 957/1000\n",
      "45/45 [==============================] - 0s 826us/step - loss: 1.7863 - accuracy: 0.1778 - val_loss: 1.7985 - val_accuracy: 0.1417\n",
      "Epoch 958/1000\n",
      "45/45 [==============================] - 0s 789us/step - loss: 1.7863 - accuracy: 0.1778 - val_loss: 1.7988 - val_accuracy: 0.1417\n",
      "Epoch 959/1000\n",
      "45/45 [==============================] - 0s 788us/step - loss: 1.7864 - accuracy: 0.1778 - val_loss: 1.7982 - val_accuracy: 0.1417\n",
      "Epoch 960/1000\n",
      "45/45 [==============================] - 0s 766us/step - loss: 1.7863 - accuracy: 0.1778 - val_loss: 1.7984 - val_accuracy: 0.1417\n",
      "Epoch 961/1000\n",
      "45/45 [==============================] - 0s 802us/step - loss: 1.7862 - accuracy: 0.1778 - val_loss: 1.7986 - val_accuracy: 0.1417\n",
      "Epoch 962/1000\n",
      "45/45 [==============================] - 0s 795us/step - loss: 1.7862 - accuracy: 0.1778 - val_loss: 1.7983 - val_accuracy: 0.1417\n",
      "Epoch 963/1000\n",
      "45/45 [==============================] - 0s 782us/step - loss: 1.7863 - accuracy: 0.1778 - val_loss: 1.7985 - val_accuracy: 0.1417\n",
      "Epoch 964/1000\n",
      "45/45 [==============================] - 0s 816us/step - loss: 1.7864 - accuracy: 0.1778 - val_loss: 1.7982 - val_accuracy: 0.1417\n",
      "Epoch 965/1000\n",
      "45/45 [==============================] - 0s 794us/step - loss: 1.7863 - accuracy: 0.1778 - val_loss: 1.7984 - val_accuracy: 0.1417\n",
      "Epoch 966/1000\n",
      "45/45 [==============================] - 0s 827us/step - loss: 1.7861 - accuracy: 0.1778 - val_loss: 1.7984 - val_accuracy: 0.1417\n",
      "Epoch 967/1000\n",
      "45/45 [==============================] - 0s 818us/step - loss: 1.7862 - accuracy: 0.1778 - val_loss: 1.7985 - val_accuracy: 0.1417\n",
      "Epoch 968/1000\n",
      "45/45 [==============================] - 0s 807us/step - loss: 1.7864 - accuracy: 0.1778 - val_loss: 1.7983 - val_accuracy: 0.1417\n",
      "Epoch 969/1000\n",
      "45/45 [==============================] - 0s 825us/step - loss: 1.7863 - accuracy: 0.1778 - val_loss: 1.7984 - val_accuracy: 0.1417\n",
      "Epoch 970/1000\n",
      "45/45 [==============================] - 0s 803us/step - loss: 1.7864 - accuracy: 0.1500 - val_loss: 1.7981 - val_accuracy: 0.1417\n",
      "Epoch 971/1000\n",
      "45/45 [==============================] - 0s 803us/step - loss: 1.7862 - accuracy: 0.1778 - val_loss: 1.7984 - val_accuracy: 0.1417\n",
      "Epoch 972/1000\n",
      "45/45 [==============================] - 0s 755us/step - loss: 1.7862 - accuracy: 0.1778 - val_loss: 1.7983 - val_accuracy: 0.1417\n",
      "Epoch 973/1000\n",
      "45/45 [==============================] - 0s 770us/step - loss: 1.7862 - accuracy: 0.1778 - val_loss: 1.7982 - val_accuracy: 0.1417\n",
      "Epoch 974/1000\n",
      "45/45 [==============================] - 0s 792us/step - loss: 1.7865 - accuracy: 0.1778 - val_loss: 1.7983 - val_accuracy: 0.1417\n",
      "Epoch 975/1000\n",
      "45/45 [==============================] - 0s 774us/step - loss: 1.7862 - accuracy: 0.1778 - val_loss: 1.7985 - val_accuracy: 0.1417\n",
      "Epoch 976/1000\n",
      "45/45 [==============================] - 0s 809us/step - loss: 1.7861 - accuracy: 0.1778 - val_loss: 1.7985 - val_accuracy: 0.1417\n",
      "Epoch 977/1000\n",
      "45/45 [==============================] - 0s 778us/step - loss: 1.7864 - accuracy: 0.1778 - val_loss: 1.7986 - val_accuracy: 0.1417\n",
      "Epoch 978/1000\n",
      "45/45 [==============================] - 0s 834us/step - loss: 1.7862 - accuracy: 0.1778 - val_loss: 1.7986 - val_accuracy: 0.1417\n",
      "Epoch 979/1000\n",
      "45/45 [==============================] - 0s 769us/step - loss: 1.7861 - accuracy: 0.1778 - val_loss: 1.7986 - val_accuracy: 0.1417\n",
      "Epoch 980/1000\n",
      "45/45 [==============================] - 0s 936us/step - loss: 1.7862 - accuracy: 0.1778 - val_loss: 1.7985 - val_accuracy: 0.1417\n",
      "Epoch 981/1000\n",
      "45/45 [==============================] - 0s 799us/step - loss: 1.7863 - accuracy: 0.1778 - val_loss: 1.7985 - val_accuracy: 0.1417\n",
      "Epoch 982/1000\n",
      "45/45 [==============================] - 0s 789us/step - loss: 1.7861 - accuracy: 0.1778 - val_loss: 1.7984 - val_accuracy: 0.1417\n",
      "Epoch 983/1000\n",
      "45/45 [==============================] - 0s 812us/step - loss: 1.7863 - accuracy: 0.1778 - val_loss: 1.7984 - val_accuracy: 0.1417\n",
      "Epoch 984/1000\n",
      "45/45 [==============================] - 0s 789us/step - loss: 1.7862 - accuracy: 0.1778 - val_loss: 1.7984 - val_accuracy: 0.1417\n",
      "Epoch 985/1000\n",
      "45/45 [==============================] - 0s 774us/step - loss: 1.7864 - accuracy: 0.1778 - val_loss: 1.7986 - val_accuracy: 0.1417\n",
      "Epoch 986/1000\n",
      "45/45 [==============================] - 0s 763us/step - loss: 1.7864 - accuracy: 0.1778 - val_loss: 1.7988 - val_accuracy: 0.1417\n",
      "Epoch 987/1000\n",
      "45/45 [==============================] - 0s 830us/step - loss: 1.7864 - accuracy: 0.1778 - val_loss: 1.7983 - val_accuracy: 0.1417\n",
      "Epoch 988/1000\n",
      "45/45 [==============================] - 0s 778us/step - loss: 1.7862 - accuracy: 0.1778 - val_loss: 1.7982 - val_accuracy: 0.1417\n",
      "Epoch 989/1000\n",
      "45/45 [==============================] - 0s 794us/step - loss: 1.7863 - accuracy: 0.1778 - val_loss: 1.7983 - val_accuracy: 0.1417\n",
      "Epoch 990/1000\n",
      "45/45 [==============================] - 0s 763us/step - loss: 1.7863 - accuracy: 0.1778 - val_loss: 1.7981 - val_accuracy: 0.1417\n",
      "Epoch 991/1000\n",
      "45/45 [==============================] - 0s 765us/step - loss: 1.7862 - accuracy: 0.1778 - val_loss: 1.7985 - val_accuracy: 0.1417\n",
      "Epoch 992/1000\n",
      "45/45 [==============================] - 0s 761us/step - loss: 1.7862 - accuracy: 0.1778 - val_loss: 1.7984 - val_accuracy: 0.1417\n",
      "Epoch 993/1000\n",
      "45/45 [==============================] - 0s 828us/step - loss: 1.7864 - accuracy: 0.1778 - val_loss: 1.7985 - val_accuracy: 0.1417\n",
      "Epoch 994/1000\n",
      "45/45 [==============================] - 0s 794us/step - loss: 1.7863 - accuracy: 0.1778 - val_loss: 1.7982 - val_accuracy: 0.1417\n",
      "Epoch 995/1000\n",
      "45/45 [==============================] - 0s 843us/step - loss: 1.7863 - accuracy: 0.1778 - val_loss: 1.7987 - val_accuracy: 0.1417\n",
      "Epoch 996/1000\n",
      "45/45 [==============================] - 0s 753us/step - loss: 1.7862 - accuracy: 0.1778 - val_loss: 1.7984 - val_accuracy: 0.1417\n",
      "Epoch 997/1000\n",
      "45/45 [==============================] - 0s 822us/step - loss: 1.7862 - accuracy: 0.1778 - val_loss: 1.7983 - val_accuracy: 0.1417\n",
      "Epoch 998/1000\n",
      "45/45 [==============================] - 0s 804us/step - loss: 1.7864 - accuracy: 0.1778 - val_loss: 1.7983 - val_accuracy: 0.1417\n",
      "Epoch 999/1000\n",
      "45/45 [==============================] - 0s 756us/step - loss: 1.7861 - accuracy: 0.1778 - val_loss: 1.7985 - val_accuracy: 0.1417\n",
      "Epoch 1000/1000\n",
      "45/45 [==============================] - 0s 768us/step - loss: 1.7862 - accuracy: 0.1778 - val_loss: 1.7984 - val_accuracy: 0.1417\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        20\n",
      "           1       0.00      0.00      0.00        20\n",
      "           2       0.00      0.00      0.00        20\n",
      "           3       0.00      0.00      0.00        20\n",
      "           4       0.15      0.85      0.25        20\n",
      "           5       0.00      0.00      0.00        20\n",
      "\n",
      "    accuracy                           0.14       120\n",
      "   macro avg       0.02      0.14      0.04       120\n",
      "weighted avg       0.02      0.14      0.04       120\n",
      "\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 500 + (500 * choosenIndex)\n",
    "BATCH_SIZE = 8\n",
    "\n",
    "model = getNetwork()\n",
    "history = model.fit(X_train, y_train, epochs=EPOCHS, batch_size=BATCH_SIZE, validation_split=0.25)\n",
    "pred = model.predict(X_test)\n",
    "pred = np.argmax(pred, axis=1)\n",
    "report = classification_report(y_test, pred)\n",
    "classification_report_csv(report, \"NN\")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export Models in C code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/sakka/anaconda3/envs/ts/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From /home/sakka/anaconda3/envs/ts/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpgkqpu7i0/assets\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Neural network with TinyMLGen\n",
    "with open(tasks[choosenIndex] + '/exportedModels/' + 'NNmodel.h', 'w') as f:\n",
    "    f.write(tiny.port(model, optimize=False))\n",
    "\n",
    "# Classifiers with MicroMLGen\n",
    "for name, model in models:\n",
    "    prepath = tasks[choosenIndex] + '/exportedModels/'\n",
    "    path = prepath + name + '.h'\n",
    "    with open(path, 'w') as f:\n",
    "        f.write(port(model, optimize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

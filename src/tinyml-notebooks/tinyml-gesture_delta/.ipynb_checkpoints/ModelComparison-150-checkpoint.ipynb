{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models Comparison for TinyML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "import numpy as np\n",
    "from numpy import arange\n",
    "import pickle\n",
    "#\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#\n",
    "import pandas as pd\n",
    "from pandas import read_csv\n",
    "\n",
    "from sklearn.metrics import confusion_matrix,  classification_report, f1_score\n",
    "from sklearn.model_selection import train_test_split, KFold,StratifiedKFold, cross_val_score, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from keras.models import Sequential, Model \n",
    "from keras.layers import Dense, Input, concatenate, Activation, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "import tensorflow\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from micromlgen import port\n",
    "import tinymlgen as tiny\n",
    "\n",
    "import warnings\n",
    "import seaborn as sbs\n",
    "import sys\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "tensorflow.random.set_seed(RANDOM_SEED)\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "tasks = [\"2Labels\", \"3Labels\", \"4Labels\", \"5Labels\"]\n",
    "choosenIndex = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/X.pkl', 'rb') as f:\n",
    "    X = pickle.load(f)\n",
    "\n",
    "with open('data/y.pkl', 'rb') as f:\n",
    "    y = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_labels = 2 + choosenIndex\n",
    "samples = 30\n",
    "X = X[:n_labels*samples]\n",
    "y = y[:n_labels*samples]\n",
    "labels = np.unique(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = np.unique(y).tolist()\n",
    "for i in range(len(classes)):\n",
    "    y = np.where(y==classes[i], i, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "y = np.array([int(el) for el in y])\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12, 42)\n",
      "(12,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=RANDOM_SEED)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.06, -0.02,  0.99, -0.07,  0.  ,  0.93, -0.1 , -0.06,  1.51,\n",
       "         0.01, -0.04,  0.53,  0.04,  0.  ,  0.63, -0.02,  0.31,  1.08,\n",
       "        -0.09, -0.12,  1.12, -0.02,  0.02,  0.99, -0.01,  0.1 ,  0.95,\n",
       "        -0.01,  0.12,  0.95, -0.01,  0.11,  0.99, -0.03,  0.07,  0.96,\n",
       "        -0.01,  0.1 ,  0.97, -0.02,  0.08,  0.96],\n",
       "       [-0.01, -0.01, -0.  ,  0.  , -0.04, -0.  ,  0.05,  0.09,  0.43,\n",
       "         0.05,  0.23, -0.16,  0.15,  0.02, -0.3 ,  0.08, -0.27, -0.13,\n",
       "        -0.04, -0.22,  0.13, -0.04,  0.1 ,  0.09, -0.03,  0.04, -0.04,\n",
       "        -0.07, -0.04,  0.01, -0.02, -0.03, -0.  , -0.04, -0.05, -0.02,\n",
       "        -0.06, -0.05,  0.04, -0.05, -0.06, -0.  ],\n",
       "       [-0.  , -0.  ,  0.01, -0.  , -0.01, -0.01, -0.06,  0.15, -0.1 ,\n",
       "         0.04, -0.18,  0.32, -0.15, -0.19, -0.38, -0.  ,  0.39, -0.41,\n",
       "        -0.06,  0.28,  0.21, -0.09,  0.  ,  0.07, -0.06,  0.04, -0.02,\n",
       "        -0.04,  0.09, -0.03, -0.04,  0.1 ,  0.01, -0.03,  0.06, -0.01,\n",
       "        -0.04,  0.04, -0.01, -0.03,  0.05,  0.01],\n",
       "       [ 0.03,  0.02, -0.01,  0.02,  0.04, -0.02,  0.04,  0.12,  0.31,\n",
       "         0.02, -0.08,  0.15,  0.13,  0.02, -0.4 ,  0.11,  0.17, -0.1 ,\n",
       "        -0.08,  0.08,  0.09, -0.24, -0.06,  0.21, -0.14, -0.06, -0.05,\n",
       "        -0.13,  0.05, -0.04, -0.14,  0.03,  0.02, -0.12,  0.09, -0.03,\n",
       "        -0.09,  0.06,  0.02, -0.05,  0.12, -0.03],\n",
       "       [-0.01, -0.06,  0.  , -0.01, -0.08,  0.  , -0.01,  0.43,  0.03,\n",
       "        -0.1 , -0.36,  0.3 , -0.02, -0.03, -0.38,  0.1 ,  0.33, -0.05,\n",
       "        -0.05,  0.12,  0.14, -0.09, -0.09,  0.12, -0.07, -0.04, -0.01,\n",
       "        -0.07, -0.02, -0.03, -0.05, -0.02,  0.06, -0.07, -0.02,  0.01,\n",
       "        -0.06, -0.02, -0.03, -0.06, -0.  , -0.01],\n",
       "       [ 0.01,  0.02, -0.  ,  0.  ,  0.01, -0.01,  0.04,  0.24,  0.14,\n",
       "         0.02, -0.16,  0.23,  0.07,  0.1 , -0.44,  0.05,  0.2 , -0.02,\n",
       "         0.02,  0.24,  0.2 , -0.08,  0.01,  0.  , -0.05,  0.07, -0.02,\n",
       "         0.01,  0.16,  0.02, -0.01,  0.13,  0.  ,  0.  ,  0.14,  0.01,\n",
       "         0.  ,  0.14,  0.02, -0.01,  0.13,  0.  ],\n",
       "       [-0.01,  0.01, -0.02, -0.01, -0.03,  0.05,  0.08,  0.11,  0.2 ,\n",
       "         0.1 ,  0.11, -0.19,  0.17,  0.12, -0.24,  0.03, -0.09, -0.1 ,\n",
       "        -0.08,  0.01,  0.05, -0.17,  0.01,  0.11, -0.19,  0.16,  0.11,\n",
       "        -0.15,  0.29,  0.01, -0.07,  0.11, -0.07, -0.02,  0.05,  0.01,\n",
       "        -0.01,  0.07,  0.02,  0.01,  0.1 ,  0.04],\n",
       "       [ 0.  ,  0.02,  0.01,  0.  ,  0.01, -0.01,  0.03, -0.2 ,  0.1 ,\n",
       "         0.11,  0.23,  0.19,  0.15,  0.09, -0.34,  0.19,  0.05, -0.32,\n",
       "        -0.01, -0.24,  0.05,  0.01, -0.02,  0.16, -0.04, -0.  ,  0.03,\n",
       "        -0.04, -0.1 ,  0.01, -0.01, -0.08, -0.04, -0.03, -0.12, -0.03,\n",
       "        -0.06, -0.18, -0.01, -0.03, -0.13, -0.01],\n",
       "       [ 0.01,  0.01, -0.  ,  0.01, -0.  , -0.02, -0.04,  0.26,  0.35,\n",
       "         0.04, -0.29,  0.08,  0.14, -0.04, -0.36,  0.24,  0.32, -0.16,\n",
       "         0.09,  0.14,  0.03,  0.  , -0.01,  0.09, -0.  , -0.12,  0.01,\n",
       "        -0.01, -0.04, -0.05,  0.  , -0.  ,  0.02,  0.  ,  0.02, -0.01,\n",
       "        -0.01,  0.  , -0.01,  0.01,  0.02, -0.01],\n",
       "       [-0.01, -0.01, -0.  , -0.03, -0.03, -0.05,  0.09,  0.07,  0.21,\n",
       "         0.06,  0.04,  0.18, -0.03, -0.11, -0.52, -0.03, -0.19,  0.08,\n",
       "        -0.09, -0.24,  0.26, -0.11, -0.18, -0.04, -0.07, -0.3 , -0.01,\n",
       "        -0.06, -0.28, -0.03, -0.06, -0.24, -0.02, -0.06, -0.25, -0.03,\n",
       "        -0.08, -0.28, -0.02, -0.08, -0.25, -0.05],\n",
       "       [ 0.  ,  0.  , -0.01, -0.  , -0.06, -0.01,  0.06,  0.08,  0.27,\n",
       "         0.13,  0.27, -0.17,  0.22,  0.09, -0.25,  0.1 , -0.2 , -0.04,\n",
       "         0.06, -0.09,  0.12,  0.01,  0.1 ,  0.04,  0.01,  0.08, -0.01,\n",
       "         0.03,  0.02,  0.02, -0.01, -0.1 , -0.1 , -0.01, -0.04,  0.01,\n",
       "         0.01,  0.01, -0.01,  0.01, -0.03,  0.01],\n",
       "       [ 0.13, -0.01,  0.9 ,  0.12,  0.01,  1.  ,  0.26,  0.3 ,  1.14,\n",
       "         0.05, -0.2 ,  0.89,  0.09,  0.03,  0.65,  0.08,  0.33,  1.2 ,\n",
       "         0.06, -0.22,  1.  ,  0.19,  0.22,  1.  ,  0.17,  0.09,  1.05,\n",
       "         0.13,  0.09,  1.02,  0.14,  0.04,  0.91,  0.15,  0.05,  0.96,\n",
       "         0.14,  0.09,  1.01,  0.16,  0.06,  0.97]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Spotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test options and evaluation metric\n",
    "num_folds = 5\n",
    "seed = 42\n",
    "scoring = 'f1_macro'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spot-Check Algorithms\n",
    "models = []\n",
    "\n",
    "#models.append(('XGB', XGBClassifier(random_state=seed)))\n",
    "models.append(('GNB', GaussianNB(var_smoothing=2e-9)))\n",
    "models.append(('LR', LogisticRegression(random_state=seed)))\n",
    "models.append(('CART' , DecisionTreeClassifier(random_state=seed)))\n",
    "models.append(('SVC' , SVC(gamma=0.05, random_state=seed)))\n",
    "if n_labels == 5:\n",
    "    models.append(('RF', RandomForestClassifier(random_state=RANDOM_SEED, n_estimators=250, \n",
    "                                                           max_features=9, criterion='entropy', max_depth=None,\n",
    "                                                           min_samples_split=4, min_samples_leaf=1\n",
    "                                                          )))\n",
    "\n",
    "else:\n",
    "    models.append(('RF', RandomForestClassifier(random_state=RANDOM_SEED, n_estimators=50, \n",
    "                                                           max_features=5, criterion='gini', max_depth=None,\n",
    "                                                           min_samples_split=4, min_samples_leaf=1\n",
    "                                                          )))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GNB - 0,60 0,11\n",
      "LR - 0,62 0,18\n",
      "CART - 0,73 0,17\n",
      "SVC - 0,51 0,14\n",
      "RF - 0,88 0,15\n"
     ]
    }
   ],
   "source": [
    "# Cross Validation\n",
    "results = []\n",
    "names = []\n",
    "for name, model in models:\n",
    "    # Dividere dati in n = num_folds\n",
    "    kf = StratifiedKFold(n_splits=num_folds, random_state=seed, shuffle=True)\n",
    "    cv_results = np.array([])\n",
    "    for train_idx, test_idx, in kf.split(X_train, y_train):\n",
    "        X_cross_train, y_cross_train = X_train[train_idx], y_train[train_idx]\n",
    "        X_cross_test, y_cross_test = X_train[test_idx], y_train[test_idx]\n",
    "        model.fit(X_cross_train, y_cross_train)  \n",
    "        y_pred = model.predict(X_cross_test)\n",
    "        f1s = f1_score(y_cross_test, y_pred, average=\"weighted\")\n",
    "        cv_results = np.append(cv_results, [f1s])\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    #msg = \"%s - %f - %f\" % (name, cv_results.mean(), cv_results.std())\n",
    "    msg = \"{} - {:.2f} {:.2f}\".format(name, cv_results.mean(), cv_results.std()).replace('.', ',')\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compare Algorithms\n",
    "fig = plt.figure(figsize=(10,5))\n",
    "fig.suptitle('Algorithms Comparison')\n",
    "ax = fig.add_subplot(111)\n",
    "plt.boxplot(results)\n",
    "ax.set_xticklabels(names)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Valutazione dei migliori algoritmi su test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Valutazione modelli sul Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model GNB: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.67      0.57         6\n",
      "           1       0.50      0.33      0.40         6\n",
      "\n",
      "    accuracy                           0.50        12\n",
      "   macro avg       0.50      0.50      0.49        12\n",
      "weighted avg       0.50      0.50      0.49        12\n",
      "\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '2Labels/classificationReports/reportGNB.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-68-d1d0d16ad903>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mreport\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreport\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0mclassification_report_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreport\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"-------------------------------------------------------------\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-68-d1d0d16ad903>\u001b[0m in \u001b[0;36mclassification_report_csv\u001b[0;34m(report, model_name)\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mdataframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreport_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mdataframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mchoosenIndex\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/classificationReports/\"\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m'report'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmodel_name\u001b[0m \u001b[0;34m+\u001b[0m  \u001b[0;34m'.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ts/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mto_csv\u001b[0;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, decimal, errors)\u001b[0m\n\u001b[1;32m   3168\u001b[0m             \u001b[0mdecimal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecimal\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3169\u001b[0m         )\n\u001b[0;32m-> 3170\u001b[0;31m         \u001b[0mformatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3172\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpath_or_buf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ts/lib/python3.6/site-packages/pandas/io/formats/csvs.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    188\u001b[0m                 \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m                 \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m                 \u001b[0mcompression\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompression_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompression\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    191\u001b[0m             )\n\u001b[1;32m    192\u001b[0m             \u001b[0mclose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ts/lib/python3.6/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors)\u001b[0m\n\u001b[1;32m    491\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mis_text\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0;31m# No explicit encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '2Labels/classificationReports/reportGNB.csv'"
     ]
    }
   ],
   "source": [
    "def classification_report_csv(report, model_name):\n",
    "    report_data = []\n",
    "    lines = report.split('\\n')\n",
    "    index = 0\n",
    "    row = lines[-4].split('    ')\n",
    "    accuracy = row[-2] if choosenIndex > 1 else row[-3]\n",
    "    for line in lines[2:-5]:\n",
    "        row = {}\n",
    "        row_data = line.split('      ')\n",
    "        row['class'] = labels[index]\n",
    "        row['precision'] = float(row_data[2]) \n",
    "        row['recall'] = float(row_data[3]) \n",
    "        row['f1_score'] = float(row_data[4])\n",
    "        row['accuracy'] = accuracy\n",
    "        report_data.append(row)\n",
    "        index += 1\n",
    "    dataframe = pd.DataFrame.from_dict(report_data)\n",
    "    dataframe.to_csv(tasks[choosenIndex] + \"/classificationReports/\" +'report' + model_name +  '.csv', index = False)\n",
    "    \n",
    "for name, model in models:\n",
    "    model.fit(X_train,  y_train)\n",
    "    pred_train = model.predict(X_train)\n",
    "    pred_test = model.predict(X_test)\n",
    "    print(f\"Model {name}: \")\n",
    "    report = classification_report(y_test, pred_test)\n",
    "    print(report)\n",
    "    classification_report_csv(report, name)\n",
    "    print(\"-------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Valutazione Inferance Rate medio (|X_test| = 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "csv = read_csv(\"InfTimeReport.csv\")\n",
    "g = sbs.barplot(x=csv['Algoritmo'], y=csv['InfTime'])\n",
    "g.set_yscale(\"log\")\n",
    "plt.ylabel(\"Inference Time\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Memoria occupata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "csv = read_csv(\"MemOccupationReport.csv\")\n",
    "sbs.barplot(x=csv['Algoritmo'], y=csv['MemOccupata2'])\n",
    "plt.ylabel(\"MemOccupata in Byte\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "EPOCHS = 500 \n",
    "BATCH_SIZE = 8 if choosenIndex > 1 else 4 #16 with 5 labels\n",
    "learn_rate = 0.001\n",
    "nodes =  512 if choosenIndex > 1 else 256\n",
    "def getNetwork():\n",
    "    model = Sequential(name=\"Sequential-NN\")\n",
    "    model.add(layers.Dense(X.shape[1], activation='relu', input_shape=(X.shape[1],)))\n",
    "    model.add(layers.Dropout(0.25))    \n",
    "    model.add(layers.Dense(nodes, activation='relu'))\n",
    "    model.add(layers.Dropout(0.25))\n",
    "    model.add(layers.Dense(np.unique(y).size, activation='softmax'))\n",
    "    opt = Adam(learning_rate=learn_rate)\n",
    "    # SGB\n",
    "    model.compile(optimizer=opt, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "n_splits=10 cannot be greater than the number of members in each class.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-2806a537579f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mkf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStratifiedKFold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_folds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mcv_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mtrain_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mX_cross_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_cross_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mX_cross_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_cross_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ts/lib/python3.6/site-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36msplit\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m    330\u001b[0m                 .format(self.n_splits, n_samples))\n\u001b[1;32m    331\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ts/lib/python3.6/site-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36msplit\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mtest_index\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iter_test_masks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m             \u001b[0mtrain_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogical_not\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m             \u001b[0mtest_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ts/lib/python3.6/site-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36m_iter_test_masks\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m    691\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    692\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_iter_test_masks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 693\u001b[0;31m         \u001b[0mtest_folds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_test_folds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    694\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    695\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mtest_folds\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ts/lib/python3.6/site-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36m_make_test_folds\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    662\u001b[0m             raise ValueError(\"n_splits=%d cannot be greater than the\"\n\u001b[1;32m    663\u001b[0m                              \u001b[0;34m\" number of members in each class.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 664\u001b[0;31m                              % (self.n_splits))\n\u001b[0m\u001b[1;32m    665\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_splits\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mmin_groups\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m             warnings.warn((\"The least populated class in y has only %d\"\n",
      "\u001b[0;31mValueError\u001b[0m: n_splits=10 cannot be greater than the number of members in each class."
     ]
    }
   ],
   "source": [
    "num_folds = 5\n",
    "\n",
    "kf = StratifiedKFold(n_splits=num_folds, random_state=seed, shuffle=True)\n",
    "cv_results = np.array([])\n",
    "for train_idx, test_idx, in kf.split(X_train, y_train):\n",
    "    X_cross_train, y_cross_train = X_train[train_idx], y_train[train_idx]\n",
    "    X_cross_train = scaler.fit_transform(X_cross_train)\n",
    "    X_cross_test, y_cross_test = X_train[test_idx], y_train[test_idx]\n",
    "    X_cross_test = scaler.transform(X_cross_test)\n",
    "    model = getNetwork()\n",
    "    model.fit(X_cross_train, y_cross_train, epochs=EPOCHS, batch_size=BATCH_SIZE)  \n",
    "    y_pred = model.predict(X_cross_test)\n",
    "    predictions_categorical = np.argmax(y_pred, axis=1)\n",
    "    f1s = f1_score(y_cross_test, predictions_categorical, average=\"weighted\")\n",
    "    cv_results = np.append(cv_results, [f1s])\n",
    "\n",
    "print(f'Average score of Cross Validation: {cv_results.mean()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Sequential-NN\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_15 (Dense)             (None, 42)                1806      \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 42)                0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 256)               11008     \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 2)                 514       \n",
      "=================================================================\n",
      "Total params: 13,328\n",
      "Trainable params: 13,328\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.7376 - accuracy: 0.4722 - val_loss: 0.6903 - val_accuracy: 0.5833\n",
      "Epoch 2/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.6813 - accuracy: 0.5833 - val_loss: 0.6792 - val_accuracy: 0.8333\n",
      "Epoch 3/500\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.6946 - accuracy: 0.6944 - val_loss: 0.6739 - val_accuracy: 0.9167\n",
      "Epoch 4/500\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.6535 - accuracy: 0.6944 - val_loss: 0.6663 - val_accuracy: 0.8333\n",
      "Epoch 5/500\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.6460 - accuracy: 0.8056 - val_loss: 0.6544 - val_accuracy: 0.8333\n",
      "Epoch 6/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.6323 - accuracy: 0.7500 - val_loss: 0.6423 - val_accuracy: 0.7500\n",
      "Epoch 7/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.6343 - accuracy: 0.7778 - val_loss: 0.6298 - val_accuracy: 0.9167\n",
      "Epoch 8/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.6184 - accuracy: 0.7222 - val_loss: 0.6100 - val_accuracy: 0.9167\n",
      "Epoch 9/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.5854 - accuracy: 0.7778 - val_loss: 0.5953 - val_accuracy: 0.9167\n",
      "Epoch 10/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.5779 - accuracy: 0.7778 - val_loss: 0.5745 - val_accuracy: 0.9167\n",
      "Epoch 11/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.5298 - accuracy: 0.8056 - val_loss: 0.5536 - val_accuracy: 0.9167\n",
      "Epoch 12/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.5210 - accuracy: 0.7778 - val_loss: 0.5288 - val_accuracy: 0.9167\n",
      "Epoch 13/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.4941 - accuracy: 0.8056 - val_loss: 0.5029 - val_accuracy: 0.9167\n",
      "Epoch 14/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.4657 - accuracy: 0.8333 - val_loss: 0.4773 - val_accuracy: 0.9167\n",
      "Epoch 15/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.4311 - accuracy: 0.8889 - val_loss: 0.4529 - val_accuracy: 0.9167\n",
      "Epoch 16/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.4349 - accuracy: 0.8333 - val_loss: 0.4320 - val_accuracy: 0.9167\n",
      "Epoch 17/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.3801 - accuracy: 0.8889 - val_loss: 0.4105 - val_accuracy: 1.0000\n",
      "Epoch 18/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.3910 - accuracy: 0.8889 - val_loss: 0.3924 - val_accuracy: 0.9167\n",
      "Epoch 19/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.3690 - accuracy: 0.8611 - val_loss: 0.3734 - val_accuracy: 0.9167\n",
      "Epoch 20/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.3290 - accuracy: 0.8889 - val_loss: 0.3613 - val_accuracy: 0.9167\n",
      "Epoch 21/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.2896 - accuracy: 0.9444 - val_loss: 0.3406 - val_accuracy: 1.0000\n",
      "Epoch 22/500\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.2832 - accuracy: 0.8889 - val_loss: 0.3269 - val_accuracy: 0.9167\n",
      "Epoch 23/500\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.2406 - accuracy: 0.9722 - val_loss: 0.3140 - val_accuracy: 0.9167\n",
      "Epoch 24/500\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.2350 - accuracy: 0.9167 - val_loss: 0.3033 - val_accuracy: 0.9167\n",
      "Epoch 25/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1978 - accuracy: 1.0000 - val_loss: 0.2869 - val_accuracy: 0.9167\n",
      "Epoch 26/500\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.2116 - accuracy: 0.9444 - val_loss: 0.2726 - val_accuracy: 1.0000\n",
      "Epoch 27/500\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1691 - accuracy: 0.9444 - val_loss: 0.2618 - val_accuracy: 1.0000\n",
      "Epoch 28/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1412 - accuracy: 0.9722 - val_loss: 0.2510 - val_accuracy: 1.0000\n",
      "Epoch 29/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1419 - accuracy: 1.0000 - val_loss: 0.2462 - val_accuracy: 0.9167\n",
      "Epoch 30/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1353 - accuracy: 1.0000 - val_loss: 0.2429 - val_accuracy: 0.9167\n",
      "Epoch 31/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1613 - accuracy: 1.0000 - val_loss: 0.2325 - val_accuracy: 0.9167\n",
      "Epoch 32/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1564 - accuracy: 0.9444 - val_loss: 0.2289 - val_accuracy: 0.9167\n",
      "Epoch 33/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1034 - accuracy: 0.9722 - val_loss: 0.2105 - val_accuracy: 0.9167\n",
      "Epoch 34/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0867 - accuracy: 1.0000 - val_loss: 0.2017 - val_accuracy: 0.9167\n",
      "Epoch 35/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0982 - accuracy: 1.0000 - val_loss: 0.2016 - val_accuracy: 0.9167\n",
      "Epoch 36/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0760 - accuracy: 1.0000 - val_loss: 0.2185 - val_accuracy: 0.9167\n",
      "Epoch 37/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0711 - accuracy: 1.0000 - val_loss: 0.2018 - val_accuracy: 0.9167\n",
      "Epoch 38/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0492 - accuracy: 1.0000 - val_loss: 0.1931 - val_accuracy: 0.9167\n",
      "Epoch 39/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0902 - accuracy: 0.9722 - val_loss: 0.1914 - val_accuracy: 0.9167\n",
      "Epoch 40/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0486 - accuracy: 1.0000 - val_loss: 0.1811 - val_accuracy: 0.9167\n",
      "Epoch 41/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0550 - accuracy: 1.0000 - val_loss: 0.1731 - val_accuracy: 0.9167\n",
      "Epoch 42/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0565 - accuracy: 1.0000 - val_loss: 0.1841 - val_accuracy: 0.9167\n",
      "Epoch 43/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0496 - accuracy: 1.0000 - val_loss: 0.1870 - val_accuracy: 0.9167\n",
      "Epoch 44/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0560 - accuracy: 1.0000 - val_loss: 0.2189 - val_accuracy: 0.8333\n",
      "Epoch 45/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0496 - accuracy: 1.0000 - val_loss: 0.2158 - val_accuracy: 0.8333\n",
      "Epoch 46/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0357 - accuracy: 1.0000 - val_loss: 0.1839 - val_accuracy: 0.9167\n",
      "Epoch 47/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0287 - accuracy: 1.0000 - val_loss: 0.1757 - val_accuracy: 0.9167\n",
      "Epoch 48/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0379 - accuracy: 1.0000 - val_loss: 0.1759 - val_accuracy: 0.9167\n",
      "Epoch 49/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0402 - accuracy: 1.0000 - val_loss: 0.1663 - val_accuracy: 0.9167\n",
      "Epoch 50/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0236 - accuracy: 1.0000 - val_loss: 0.1604 - val_accuracy: 0.9167\n",
      "Epoch 51/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0272 - accuracy: 1.0000 - val_loss: 0.1838 - val_accuracy: 0.9167\n",
      "Epoch 52/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0412 - accuracy: 1.0000 - val_loss: 0.2382 - val_accuracy: 0.9167\n",
      "Epoch 53/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0147 - accuracy: 1.0000 - val_loss: 0.2624 - val_accuracy: 0.9167\n",
      "Epoch 54/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0274 - accuracy: 1.0000 - val_loss: 0.2524 - val_accuracy: 0.9167\n",
      "Epoch 55/500\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0712 - accuracy: 1.0000 - val_loss: 0.2053 - val_accuracy: 0.9167\n",
      "Epoch 56/500\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0308 - accuracy: 1.0000 - val_loss: 0.1808 - val_accuracy: 0.9167\n",
      "Epoch 57/500\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0091 - accuracy: 1.0000 - val_loss: 0.1683 - val_accuracy: 0.9167\n",
      "Epoch 58/500\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 0.1674 - val_accuracy: 0.9167\n",
      "Epoch 59/500\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0845 - accuracy: 0.9444 - val_loss: 0.1770 - val_accuracy: 0.9167\n",
      "Epoch 60/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0217 - accuracy: 1.0000 - val_loss: 0.2120 - val_accuracy: 0.8333\n",
      "Epoch 61/500\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0114 - accuracy: 1.0000 - val_loss: 0.2129 - val_accuracy: 0.8333\n",
      "Epoch 62/500\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0345 - accuracy: 1.0000 - val_loss: 0.1834 - val_accuracy: 0.8333\n",
      "Epoch 63/500\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0134 - accuracy: 1.0000 - val_loss: 0.1513 - val_accuracy: 0.9167\n",
      "Epoch 64/500\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0627 - accuracy: 0.9722 - val_loss: 0.1628 - val_accuracy: 0.9167\n",
      "Epoch 65/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0306 - accuracy: 1.0000 - val_loss: 0.2339 - val_accuracy: 0.8333\n",
      "Epoch 66/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0127 - accuracy: 1.0000 - val_loss: 0.2654 - val_accuracy: 0.8333\n",
      "Epoch 67/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0302 - accuracy: 1.0000 - val_loss: 0.2327 - val_accuracy: 0.8333\n",
      "Epoch 68/500\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0252 - accuracy: 1.0000 - val_loss: 0.2370 - val_accuracy: 0.8333\n",
      "Epoch 69/500\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0161 - accuracy: 1.0000 - val_loss: 0.2726 - val_accuracy: 0.8333\n",
      "Epoch 70/500\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0136 - accuracy: 1.0000 - val_loss: 0.2786 - val_accuracy: 0.8333\n",
      "Epoch 71/500\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0358 - accuracy: 1.0000 - val_loss: 0.2614 - val_accuracy: 0.8333\n",
      "Epoch 72/500\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0166 - accuracy: 1.0000 - val_loss: 0.2368 - val_accuracy: 0.8333\n",
      "Epoch 73/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.2146 - val_accuracy: 0.8333\n",
      "Epoch 74/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0114 - accuracy: 1.0000 - val_loss: 0.1910 - val_accuracy: 0.8333\n",
      "Epoch 75/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0114 - accuracy: 1.0000 - val_loss: 0.1692 - val_accuracy: 0.8333\n",
      "Epoch 76/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 0.1514 - val_accuracy: 0.9167\n",
      "Epoch 77/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 0.1435 - val_accuracy: 0.9167\n",
      "Epoch 78/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: 0.1497 - val_accuracy: 0.9167\n",
      "Epoch 79/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.1452 - val_accuracy: 0.9167\n",
      "Epoch 80/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0095 - accuracy: 1.0000 - val_loss: 0.1503 - val_accuracy: 0.9167\n",
      "Epoch 81/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 0.1737 - val_accuracy: 0.9167\n",
      "Epoch 82/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0273 - accuracy: 1.0000 - val_loss: 0.2517 - val_accuracy: 0.9167\n",
      "Epoch 83/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 0.3003 - val_accuracy: 0.8333\n",
      "Epoch 84/500\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0210 - accuracy: 1.0000 - val_loss: 0.3270 - val_accuracy: 0.8333\n",
      "Epoch 85/500\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0215 - accuracy: 1.0000 - val_loss: 0.3502 - val_accuracy: 0.8333\n",
      "Epoch 86/500\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 0.3410 - val_accuracy: 0.8333\n",
      "Epoch 87/500\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.3289 - val_accuracy: 0.8333\n",
      "Epoch 88/500\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 0.2998 - val_accuracy: 0.8333\n",
      "Epoch 89/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.2721 - val_accuracy: 0.8333\n",
      "Epoch 90/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.2614 - val_accuracy: 0.8333\n",
      "Epoch 91/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.2570 - val_accuracy: 0.8333\n",
      "Epoch 92/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 0.2461 - val_accuracy: 0.8333\n",
      "Epoch 93/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0135 - accuracy: 1.0000 - val_loss: 0.2497 - val_accuracy: 0.8333\n",
      "Epoch 94/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.2762 - val_accuracy: 0.8333\n",
      "Epoch 95/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0814 - accuracy: 0.9722 - val_loss: 0.3921 - val_accuracy: 0.8333\n",
      "Epoch 96/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0105 - accuracy: 1.0000 - val_loss: 0.4568 - val_accuracy: 0.8333\n",
      "Epoch 97/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0327 - accuracy: 1.0000 - val_loss: 0.3955 - val_accuracy: 0.8333\n",
      "Epoch 98/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.3513 - val_accuracy: 0.9167\n",
      "Epoch 99/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.3342 - val_accuracy: 0.9167\n",
      "Epoch 100/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.3253 - val_accuracy: 0.9167\n",
      "Epoch 101/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0163 - accuracy: 1.0000 - val_loss: 0.3482 - val_accuracy: 0.9167\n",
      "Epoch 102/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.3754 - val_accuracy: 0.8333\n",
      "Epoch 103/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.3715 - val_accuracy: 0.9167\n",
      "Epoch 104/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 0.3637 - val_accuracy: 0.9167\n",
      "Epoch 105/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.3522 - val_accuracy: 0.9167\n",
      "Epoch 106/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.3497 - val_accuracy: 0.9167\n",
      "Epoch 107/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.3323 - val_accuracy: 0.9167\n",
      "Epoch 108/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0206 - accuracy: 1.0000 - val_loss: 0.3479 - val_accuracy: 0.9167\n",
      "Epoch 109/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.3884 - val_accuracy: 0.8333\n",
      "Epoch 110/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.3975 - val_accuracy: 0.8333\n",
      "Epoch 111/500\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.3786 - val_accuracy: 0.9167\n",
      "Epoch 112/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.3679 - val_accuracy: 0.9167\n",
      "Epoch 113/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 0.3685 - val_accuracy: 0.9167\n",
      "Epoch 114/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.3661 - val_accuracy: 0.9167\n",
      "Epoch 115/500\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.3645 - val_accuracy: 0.9167\n",
      "Epoch 116/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.3603 - val_accuracy: 0.9167\n",
      "Epoch 117/500\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.3668 - val_accuracy: 0.9167\n",
      "Epoch 118/500\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.3530 - val_accuracy: 0.9167\n",
      "Epoch 119/500\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.3366 - val_accuracy: 0.9167\n",
      "Epoch 120/500\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.3302 - val_accuracy: 0.9167\n",
      "Epoch 121/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0102 - accuracy: 1.0000 - val_loss: 0.3402 - val_accuracy: 0.9167\n",
      "Epoch 122/500\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.3586 - val_accuracy: 0.9167\n",
      "Epoch 123/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.3580 - val_accuracy: 0.9167\n",
      "Epoch 124/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.3561 - val_accuracy: 0.9167\n",
      "Epoch 125/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.3530 - val_accuracy: 0.9167\n",
      "Epoch 126/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 9.5772e-04 - accuracy: 1.0000 - val_loss: 0.3556 - val_accuracy: 0.9167\n",
      "Epoch 127/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.3545 - val_accuracy: 0.9167\n",
      "Epoch 128/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.3516 - val_accuracy: 0.9167\n",
      "Epoch 129/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0102 - accuracy: 1.0000 - val_loss: 0.3591 - val_accuracy: 0.9167\n",
      "Epoch 130/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 0.3526 - val_accuracy: 0.9167\n",
      "Epoch 131/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.3253 - val_accuracy: 0.9167\n",
      "Epoch 132/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.3158 - val_accuracy: 0.9167\n",
      "Epoch 133/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.3137 - val_accuracy: 0.9167\n",
      "Epoch 134/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.3122 - val_accuracy: 0.9167\n",
      "Epoch 135/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.3110 - val_accuracy: 0.9167\n",
      "Epoch 136/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.3124 - val_accuracy: 0.9167\n",
      "Epoch 137/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 0.3215 - val_accuracy: 0.9167\n",
      "Epoch 138/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0105 - accuracy: 1.0000 - val_loss: 0.3480 - val_accuracy: 0.9167\n",
      "Epoch 139/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.3757 - val_accuracy: 0.9167\n",
      "Epoch 140/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.3683 - val_accuracy: 0.9167\n",
      "Epoch 141/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.3622 - val_accuracy: 0.9167\n",
      "Epoch 142/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.3453 - val_accuracy: 0.9167\n",
      "Epoch 143/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 5.2760e-04 - accuracy: 1.0000 - val_loss: 0.3343 - val_accuracy: 0.9167\n",
      "Epoch 144/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.3320 - val_accuracy: 0.9167\n",
      "Epoch 145/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.3417 - val_accuracy: 0.9167\n",
      "Epoch 146/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.3491 - val_accuracy: 0.9167\n",
      "Epoch 147/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.3526 - val_accuracy: 0.9167\n",
      "Epoch 148/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.3579 - val_accuracy: 0.9167\n",
      "Epoch 149/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 0.3515 - val_accuracy: 0.9167\n",
      "Epoch 150/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.3565 - val_accuracy: 0.9167\n",
      "Epoch 151/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.3591 - val_accuracy: 0.8333\n",
      "Epoch 152/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.3666 - val_accuracy: 0.8333\n",
      "Epoch 153/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.3754 - val_accuracy: 0.8333\n",
      "Epoch 154/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.3781 - val_accuracy: 0.8333\n",
      "Epoch 155/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.3703 - val_accuracy: 0.8333\n",
      "Epoch 156/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0244 - accuracy: 0.9722 - val_loss: 0.4116 - val_accuracy: 0.8333\n",
      "Epoch 157/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.5798 - val_accuracy: 0.8333\n",
      "Epoch 158/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.6244 - val_accuracy: 0.8333\n",
      "Epoch 159/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.6080 - val_accuracy: 0.8333\n",
      "Epoch 160/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.5708 - val_accuracy: 0.8333\n",
      "Epoch 161/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.4921 - val_accuracy: 0.8333\n",
      "Epoch 162/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0135 - accuracy: 1.0000 - val_loss: 0.4028 - val_accuracy: 0.8333\n",
      "Epoch 163/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 8.4526e-04 - accuracy: 1.0000 - val_loss: 0.3646 - val_accuracy: 0.8333\n",
      "Epoch 164/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.3448 - val_accuracy: 0.8333\n",
      "Epoch 165/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 8.6300e-04 - accuracy: 1.0000 - val_loss: 0.3347 - val_accuracy: 0.8333\n",
      "Epoch 166/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.3303 - val_accuracy: 0.8333\n",
      "Epoch 167/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.3399 - val_accuracy: 0.8333\n",
      "Epoch 168/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.3723 - val_accuracy: 0.8333\n",
      "Epoch 169/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.3961 - val_accuracy: 0.8333\n",
      "Epoch 170/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0099 - accuracy: 1.0000 - val_loss: 0.3995 - val_accuracy: 0.8333\n",
      "Epoch 171/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.3745 - val_accuracy: 0.8333\n",
      "Epoch 172/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.3661 - val_accuracy: 0.8333\n",
      "Epoch 173/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.3633 - val_accuracy: 0.8333\n",
      "Epoch 174/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.3666 - val_accuracy: 0.8333\n",
      "Epoch 175/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 6.8742e-04 - accuracy: 1.0000 - val_loss: 0.3710 - val_accuracy: 0.8333\n",
      "Epoch 176/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 8.8307e-04 - accuracy: 1.0000 - val_loss: 0.3753 - val_accuracy: 0.8333\n",
      "Epoch 177/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.3973 - val_accuracy: 0.8333\n",
      "Epoch 178/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 5.7465e-04 - accuracy: 1.0000 - val_loss: 0.4077 - val_accuracy: 0.8333\n",
      "Epoch 179/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.4167 - val_accuracy: 0.8333\n",
      "Epoch 180/500\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.4622 - val_accuracy: 0.8333\n",
      "Epoch 181/500\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 4.1545e-04 - accuracy: 1.0000 - val_loss: 0.4901 - val_accuracy: 0.8333\n",
      "Epoch 182/500\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.4979 - val_accuracy: 0.8333\n",
      "Epoch 183/500\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.5010 - val_accuracy: 0.8333\n",
      "Epoch 184/500\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.4919 - val_accuracy: 0.8333\n",
      "Epoch 185/500\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 4.6055e-04 - accuracy: 1.0000 - val_loss: 0.4824 - val_accuracy: 0.8333\n",
      "Epoch 186/500\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.4835 - val_accuracy: 0.8333\n",
      "Epoch 187/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 7.5893e-04 - accuracy: 1.0000 - val_loss: 0.4812 - val_accuracy: 0.8333\n",
      "Epoch 188/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 7.5893e-04 - accuracy: 1.0000 - val_loss: 0.4832 - val_accuracy: 0.8333\n",
      "Epoch 189/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 4.0714e-04 - accuracy: 1.0000 - val_loss: 0.4859 - val_accuracy: 0.8333\n",
      "Epoch 190/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 8.4065e-04 - accuracy: 1.0000 - val_loss: 0.4833 - val_accuracy: 0.8333\n",
      "Epoch 191/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 7.1237e-04 - accuracy: 1.0000 - val_loss: 0.4821 - val_accuracy: 0.8333\n",
      "Epoch 192/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 5.0164e-04 - accuracy: 1.0000 - val_loss: 0.4910 - val_accuracy: 0.8333\n",
      "Epoch 193/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.5092 - val_accuracy: 0.8333\n",
      "Epoch 194/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 2.2387e-04 - accuracy: 1.0000 - val_loss: 0.5478 - val_accuracy: 0.8333\n",
      "Epoch 195/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.5543 - val_accuracy: 0.8333\n",
      "Epoch 196/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 2.6294e-04 - accuracy: 1.0000 - val_loss: 0.5524 - val_accuracy: 0.8333\n",
      "Epoch 197/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 8.9822e-04 - accuracy: 1.0000 - val_loss: 0.5439 - val_accuracy: 0.8333\n",
      "Epoch 198/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.5234 - val_accuracy: 0.8333\n",
      "Epoch 199/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.5046 - val_accuracy: 0.8333\n",
      "Epoch 200/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 2.7771e-04 - accuracy: 1.0000 - val_loss: 0.4963 - val_accuracy: 0.8333\n",
      "Epoch 201/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 7.2497e-04 - accuracy: 1.0000 - val_loss: 0.4890 - val_accuracy: 0.8333\n",
      "Epoch 202/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.4921 - val_accuracy: 0.8333\n",
      "Epoch 203/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 2.4630e-04 - accuracy: 1.0000 - val_loss: 0.5130 - val_accuracy: 0.8333\n",
      "Epoch 204/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 7.8661e-04 - accuracy: 1.0000 - val_loss: 0.5170 - val_accuracy: 0.8333\n",
      "Epoch 205/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 2.7685e-04 - accuracy: 1.0000 - val_loss: 0.5158 - val_accuracy: 0.8333\n",
      "Epoch 206/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.5179 - val_accuracy: 0.8333\n",
      "Epoch 207/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.5223 - val_accuracy: 0.8333\n",
      "Epoch 208/500\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.8003e-04 - accuracy: 1.0000 - val_loss: 0.5240 - val_accuracy: 0.8333\n",
      "Epoch 209/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 7.0590e-04 - accuracy: 1.0000 - val_loss: 0.5219 - val_accuracy: 0.8333\n",
      "Epoch 210/500\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 5.1556e-04 - accuracy: 1.0000 - val_loss: 0.5132 - val_accuracy: 0.8333\n",
      "Epoch 211/500\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.7916e-04 - accuracy: 1.0000 - val_loss: 0.5098 - val_accuracy: 0.8333\n",
      "Epoch 212/500\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.5206 - val_accuracy: 0.8333\n",
      "Epoch 213/500\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.3298e-04 - accuracy: 1.0000 - val_loss: 0.5413 - val_accuracy: 0.8333\n",
      "Epoch 214/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 5.8237e-04 - accuracy: 1.0000 - val_loss: 0.5527 - val_accuracy: 0.8333\n",
      "Epoch 215/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 9.6714e-04 - accuracy: 1.0000 - val_loss: 0.5522 - val_accuracy: 0.8333\n",
      "Epoch 216/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 3.7123e-04 - accuracy: 1.0000 - val_loss: 0.5395 - val_accuracy: 0.8333\n",
      "Epoch 217/500\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.8970e-04 - accuracy: 1.0000 - val_loss: 0.5330 - val_accuracy: 0.8333\n",
      "Epoch 218/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 6.4400e-04 - accuracy: 1.0000 - val_loss: 0.5272 - val_accuracy: 0.8333\n",
      "Epoch 219/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 9.3132e-04 - accuracy: 1.0000 - val_loss: 0.5108 - val_accuracy: 0.8333\n",
      "Epoch 220/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 2.5413e-04 - accuracy: 1.0000 - val_loss: 0.5044 - val_accuracy: 0.8333\n",
      "Epoch 221/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.4934 - val_accuracy: 0.8333\n",
      "Epoch 222/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.4987 - val_accuracy: 0.8333\n",
      "Epoch 223/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 0.4978 - val_accuracy: 0.8333\n",
      "Epoch 224/500\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 8.9355e-04 - accuracy: 1.0000 - val_loss: 0.4612 - val_accuracy: 0.8333\n",
      "Epoch 225/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.4710 - val_accuracy: 0.8333\n",
      "Epoch 226/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.4473 - val_accuracy: 0.8333\n",
      "Epoch 227/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 7.2453e-04 - accuracy: 1.0000 - val_loss: 0.4306 - val_accuracy: 0.9167\n",
      "Epoch 228/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 7.7490e-04 - accuracy: 1.0000 - val_loss: 0.4259 - val_accuracy: 0.9167\n",
      "Epoch 229/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.4431 - val_accuracy: 0.9167\n",
      "Epoch 230/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 1.3519e-04 - accuracy: 1.0000 - val_loss: 0.4763 - val_accuracy: 0.8333\n",
      "Epoch 231/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 3.5806e-04 - accuracy: 1.0000 - val_loss: 0.4918 - val_accuracy: 0.8333\n",
      "Epoch 232/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.5199 - val_accuracy: 0.8333\n",
      "Epoch 233/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 7.1505e-04 - accuracy: 1.0000 - val_loss: 0.5414 - val_accuracy: 0.8333\n",
      "Epoch 234/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 2.2477e-04 - accuracy: 1.0000 - val_loss: 0.5470 - val_accuracy: 0.8333\n",
      "Epoch 235/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.5334 - val_accuracy: 0.8333\n",
      "Epoch 236/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 6.0074e-04 - accuracy: 1.0000 - val_loss: 0.5346 - val_accuracy: 0.8333\n",
      "Epoch 237/500\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 3.1301e-04 - accuracy: 1.0000 - val_loss: 0.5302 - val_accuracy: 0.8333\n",
      "Epoch 238/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.5408 - val_accuracy: 0.8333\n",
      "Epoch 239/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 7.9855e-04 - accuracy: 1.0000 - val_loss: 0.5644 - val_accuracy: 0.8333\n",
      "Epoch 240/500\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.5633 - val_accuracy: 0.8333\n",
      "Epoch 241/500\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 8.0798e-04 - accuracy: 1.0000 - val_loss: 0.5498 - val_accuracy: 0.8333\n",
      "Epoch 242/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.4994 - val_accuracy: 0.8333\n",
      "Epoch 243/500\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.4698 - val_accuracy: 0.8333\n",
      "Epoch 244/500\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 0.4938 - val_accuracy: 0.8333\n",
      "Epoch 245/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 8.7600e-04 - accuracy: 1.0000 - val_loss: 0.4983 - val_accuracy: 0.8333\n",
      "Epoch 246/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 5.9634e-04 - accuracy: 1.0000 - val_loss: 0.4913 - val_accuracy: 0.8333\n",
      "Epoch 247/500\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.4938 - val_accuracy: 0.8333\n",
      "Epoch 248/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 5.4560e-04 - accuracy: 1.0000 - val_loss: 0.5069 - val_accuracy: 0.8333\n",
      "Epoch 249/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.5797 - val_accuracy: 0.8333\n",
      "Epoch 250/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 5.5149e-04 - accuracy: 1.0000 - val_loss: 0.6093 - val_accuracy: 0.8333\n",
      "Epoch 251/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 1.2467e-04 - accuracy: 1.0000 - val_loss: 0.6190 - val_accuracy: 0.8333\n",
      "Epoch 252/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 6.0964e-04 - accuracy: 1.0000 - val_loss: 0.6159 - val_accuracy: 0.8333\n",
      "Epoch 253/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 4.5539e-04 - accuracy: 1.0000 - val_loss: 0.6085 - val_accuracy: 0.8333\n",
      "Epoch 254/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 5.5715e-04 - accuracy: 1.0000 - val_loss: 0.6004 - val_accuracy: 0.8333\n",
      "Epoch 255/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.5711 - val_accuracy: 0.8333\n",
      "Epoch 256/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.5202 - val_accuracy: 0.8333\n",
      "Epoch 257/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 5.3877e-04 - accuracy: 1.0000 - val_loss: 0.4462 - val_accuracy: 0.8333\n",
      "Epoch 258/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.4124 - val_accuracy: 0.8333\n",
      "Epoch 259/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 2.4572e-04 - accuracy: 1.0000 - val_loss: 0.3505 - val_accuracy: 0.9167\n",
      "Epoch 260/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.3197 - val_accuracy: 0.9167\n",
      "Epoch 261/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 5.7313e-04 - accuracy: 1.0000 - val_loss: 0.3064 - val_accuracy: 0.9167\n",
      "Epoch 262/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 2.8370e-04 - accuracy: 1.0000 - val_loss: 0.3050 - val_accuracy: 0.9167\n",
      "Epoch 263/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.2945 - val_accuracy: 0.9167\n",
      "Epoch 264/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 3.3846e-04 - accuracy: 1.0000 - val_loss: 0.2894 - val_accuracy: 0.9167\n",
      "Epoch 265/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.2950 - val_accuracy: 0.9167\n",
      "Epoch 266/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 2.3913e-04 - accuracy: 1.0000 - val_loss: 0.3065 - val_accuracy: 0.9167\n",
      "Epoch 267/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.4135 - val_accuracy: 0.9167\n",
      "Epoch 268/500\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.4919 - val_accuracy: 0.9167\n",
      "Epoch 269/500\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.5694e-04 - accuracy: 1.0000 - val_loss: 0.5270 - val_accuracy: 0.9167\n",
      "Epoch 270/500\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.3228e-04 - accuracy: 1.0000 - val_loss: 0.5411 - val_accuracy: 0.9167\n",
      "Epoch 271/500\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.5382 - val_accuracy: 0.9167\n",
      "Epoch 272/500\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 3.7561e-04 - accuracy: 1.0000 - val_loss: 0.5049 - val_accuracy: 0.9167\n",
      "Epoch 273/500\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.5499 - val_accuracy: 0.8333\n",
      "Epoch 274/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 9.2900e-04 - accuracy: 1.0000 - val_loss: 0.6264 - val_accuracy: 0.8333\n",
      "Epoch 275/500\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 3.0766e-04 - accuracy: 1.0000 - val_loss: 0.6572 - val_accuracy: 0.8333\n",
      "Epoch 276/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 2.4639e-04 - accuracy: 1.0000 - val_loss: 0.6638 - val_accuracy: 0.8333\n",
      "Epoch 277/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.6374 - val_accuracy: 0.8333\n",
      "Epoch 278/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.6045 - val_accuracy: 0.8333\n",
      "Epoch 279/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 9.4420e-04 - accuracy: 1.0000 - val_loss: 0.5653 - val_accuracy: 0.8333\n",
      "Epoch 280/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 1.5165e-04 - accuracy: 1.0000 - val_loss: 0.5438 - val_accuracy: 0.8333\n",
      "Epoch 281/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 2.3224e-04 - accuracy: 1.0000 - val_loss: 0.5331 - val_accuracy: 0.8333\n",
      "Epoch 282/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 2ms/step - loss: 4.0619e-04 - accuracy: 1.0000 - val_loss: 0.5278 - val_accuracy: 0.8333\n",
      "Epoch 283/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 2.7593e-04 - accuracy: 1.0000 - val_loss: 0.5234 - val_accuracy: 0.8333\n",
      "Epoch 284/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0240 - accuracy: 0.9722 - val_loss: 0.6484 - val_accuracy: 0.8333\n",
      "Epoch 285/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.8126 - val_accuracy: 0.8333\n",
      "Epoch 286/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.8351 - val_accuracy: 0.8333\n",
      "Epoch 287/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.7978 - val_accuracy: 0.8333\n",
      "Epoch 288/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 9.8724e-04 - accuracy: 1.0000 - val_loss: 0.7763 - val_accuracy: 0.8333\n",
      "Epoch 289/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 2.8988e-04 - accuracy: 1.0000 - val_loss: 0.7525 - val_accuracy: 0.8333\n",
      "Epoch 290/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1274 - accuracy: 0.9722 - val_loss: 0.6872 - val_accuracy: 0.8333\n",
      "Epoch 291/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 2.1853e-04 - accuracy: 1.0000 - val_loss: 0.4416 - val_accuracy: 0.9167\n",
      "Epoch 292/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 4.8401e-04 - accuracy: 1.0000 - val_loss: 0.3728 - val_accuracy: 0.9167\n",
      "Epoch 293/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0618 - accuracy: 0.9722 - val_loss: 0.5312 - val_accuracy: 0.8333\n",
      "Epoch 294/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 2.0718e-04 - accuracy: 1.0000 - val_loss: 0.7014 - val_accuracy: 0.8333\n",
      "Epoch 295/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 6.0004e-04 - accuracy: 1.0000 - val_loss: 0.7589 - val_accuracy: 0.8333\n",
      "Epoch 296/500\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.7567 - val_accuracy: 0.8333\n",
      "Epoch 297/500\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.6594 - val_accuracy: 0.8333\n",
      "Epoch 298/500\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.6063 - val_accuracy: 0.8333\n",
      "Epoch 299/500\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 4.7365e-04 - accuracy: 1.0000 - val_loss: 0.5490 - val_accuracy: 0.8333\n",
      "Epoch 300/500\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.9629e-04 - accuracy: 1.0000 - val_loss: 0.5278 - val_accuracy: 0.8333\n",
      "Epoch 301/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 9.1623e-04 - accuracy: 1.0000 - val_loss: 0.5157 - val_accuracy: 0.8333\n",
      "Epoch 302/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0356 - accuracy: 0.9722 - val_loss: 0.7724 - val_accuracy: 0.8333\n",
      "Epoch 303/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 8.8616e-04 - accuracy: 1.0000 - val_loss: 0.9153 - val_accuracy: 0.8333\n",
      "Epoch 304/500\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 8.8021e-04 - accuracy: 1.0000 - val_loss: 0.9627 - val_accuracy: 0.8333\n",
      "Epoch 305/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.9343 - val_accuracy: 0.8333\n",
      "Epoch 306/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.8859 - val_accuracy: 0.8333\n",
      "Epoch 307/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0366 - accuracy: 0.9722 - val_loss: 0.7322 - val_accuracy: 0.8333\n",
      "Epoch 308/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.6340 - val_accuracy: 0.8333\n",
      "Epoch 309/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 7.8766e-05 - accuracy: 1.0000 - val_loss: 0.6018 - val_accuracy: 0.8333\n",
      "Epoch 310/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 1.7659e-04 - accuracy: 1.0000 - val_loss: 0.5890 - val_accuracy: 0.8333\n",
      "Epoch 311/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 7.9986e-04 - accuracy: 1.0000 - val_loss: 0.5838 - val_accuracy: 0.8333\n",
      "Epoch 312/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 6.7269e-04 - accuracy: 1.0000 - val_loss: 0.5769 - val_accuracy: 0.8333\n",
      "Epoch 313/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.5808 - val_accuracy: 0.8333\n",
      "Epoch 314/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.5892 - val_accuracy: 0.8333\n",
      "Epoch 315/500\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 5.9365e-05 - accuracy: 1.0000 - val_loss: 0.5893 - val_accuracy: 0.8333\n",
      "Epoch 316/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 6.1596e-04 - accuracy: 1.0000 - val_loss: 0.5850 - val_accuracy: 0.8333\n",
      "Epoch 317/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 7.7284e-04 - accuracy: 1.0000 - val_loss: 0.5834 - val_accuracy: 0.8333\n",
      "Epoch 318/500\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 3.4665e-04 - accuracy: 1.0000 - val_loss: 0.5820 - val_accuracy: 0.8333\n",
      "Epoch 319/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 8.5106e-04 - accuracy: 1.0000 - val_loss: 0.5798 - val_accuracy: 0.8333\n",
      "Epoch 320/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 1.8729e-04 - accuracy: 1.0000 - val_loss: 0.5747 - val_accuracy: 0.8333\n",
      "Epoch 321/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 1.2115e-04 - accuracy: 1.0000 - val_loss: 0.5734 - val_accuracy: 0.8333\n",
      "Epoch 322/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 2.0642e-04 - accuracy: 1.0000 - val_loss: 0.5737 - val_accuracy: 0.8333\n",
      "Epoch 323/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0199 - accuracy: 1.0000 - val_loss: 0.5019 - val_accuracy: 0.8333\n",
      "Epoch 324/500\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.3448 - val_accuracy: 0.8333\n",
      "Epoch 325/500\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 5.6434e-05 - accuracy: 1.0000 - val_loss: 0.2877 - val_accuracy: 0.8333\n",
      "Epoch 326/500\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.2748e-04 - accuracy: 1.0000 - val_loss: 0.2673 - val_accuracy: 0.8333\n",
      "Epoch 327/500\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.2595 - val_accuracy: 0.8333\n",
      "Epoch 328/500\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.2618 - val_accuracy: 0.8333\n",
      "Epoch 329/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 6.8290e-04 - accuracy: 1.0000 - val_loss: 0.2718 - val_accuracy: 0.8333\n",
      "Epoch 330/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 2.3989e-04 - accuracy: 1.0000 - val_loss: 0.2857 - val_accuracy: 0.8333\n",
      "Epoch 331/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 3.0075e-04 - accuracy: 1.0000 - val_loss: 0.2895 - val_accuracy: 0.8333\n",
      "Epoch 332/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 2.9426e-04 - accuracy: 1.0000 - val_loss: 0.2872 - val_accuracy: 0.8333\n",
      "Epoch 333/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 2.0253e-04 - accuracy: 1.0000 - val_loss: 0.2876 - val_accuracy: 0.8333\n",
      "Epoch 334/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 3.6261e-04 - accuracy: 1.0000 - val_loss: 0.2939 - val_accuracy: 0.8333\n",
      "Epoch 335/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.2860 - val_accuracy: 0.8333\n",
      "Epoch 336/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 1.7048e-04 - accuracy: 1.0000 - val_loss: 0.2834 - val_accuracy: 0.8333\n",
      "Epoch 337/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 1.7064e-04 - accuracy: 1.0000 - val_loss: 0.2835 - val_accuracy: 0.8333\n",
      "Epoch 338/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 7.9387e-04 - accuracy: 1.0000 - val_loss: 0.2943 - val_accuracy: 0.8333\n",
      "Epoch 339/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 2ms/step - loss: 7.6191e-04 - accuracy: 1.0000 - val_loss: 0.3061 - val_accuracy: 0.8333\n",
      "Epoch 340/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 2.1005e-04 - accuracy: 1.0000 - val_loss: 0.3132 - val_accuracy: 0.8333\n",
      "Epoch 341/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 4.1083e-04 - accuracy: 1.0000 - val_loss: 0.3187 - val_accuracy: 0.8333\n",
      "Epoch 342/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 6.7628e-04 - accuracy: 1.0000 - val_loss: 0.3259 - val_accuracy: 0.8333\n",
      "Epoch 343/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 1.2414e-04 - accuracy: 1.0000 - val_loss: 0.3317 - val_accuracy: 0.8333\n",
      "Epoch 344/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.3428 - val_accuracy: 0.8333\n",
      "Epoch 345/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 1.1477e-04 - accuracy: 1.0000 - val_loss: 0.3541 - val_accuracy: 0.8333\n",
      "Epoch 346/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 8.4677e-04 - accuracy: 1.0000 - val_loss: 0.3611 - val_accuracy: 0.8333\n",
      "Epoch 347/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 9.2156e-05 - accuracy: 1.0000 - val_loss: 0.3656 - val_accuracy: 0.8333\n",
      "Epoch 348/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 5.3660e-04 - accuracy: 1.0000 - val_loss: 0.3699 - val_accuracy: 0.8333\n",
      "Epoch 349/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 1.6054e-04 - accuracy: 1.0000 - val_loss: 0.3772 - val_accuracy: 0.8333\n",
      "Epoch 350/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.3951 - val_accuracy: 0.8333\n",
      "Epoch 351/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 3.8735e-04 - accuracy: 1.0000 - val_loss: 0.4148 - val_accuracy: 0.8333\n",
      "Epoch 352/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 2.3599e-04 - accuracy: 1.0000 - val_loss: 0.4217 - val_accuracy: 0.8333\n",
      "Epoch 353/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 8.4781e-04 - accuracy: 1.0000 - val_loss: 0.4186 - val_accuracy: 0.8333\n",
      "Epoch 354/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 3.8055e-04 - accuracy: 1.0000 - val_loss: 0.4172 - val_accuracy: 0.8333\n",
      "Epoch 355/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 6.0538e-05 - accuracy: 1.0000 - val_loss: 0.4174 - val_accuracy: 0.8333\n",
      "Epoch 356/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 9.9400e-05 - accuracy: 1.0000 - val_loss: 0.4169 - val_accuracy: 0.8333\n",
      "Epoch 357/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 2.9584e-04 - accuracy: 1.0000 - val_loss: 0.4180 - val_accuracy: 0.8333\n",
      "Epoch 358/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 4.4538e-04 - accuracy: 1.0000 - val_loss: 0.4246 - val_accuracy: 0.8333\n",
      "Epoch 359/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.4321 - val_accuracy: 0.8333\n",
      "Epoch 360/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 3.0816e-04 - accuracy: 1.0000 - val_loss: 0.4483 - val_accuracy: 0.8333\n",
      "Epoch 361/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 2.1748e-04 - accuracy: 1.0000 - val_loss: 0.4529 - val_accuracy: 0.8333\n",
      "Epoch 362/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 4.4080e-04 - accuracy: 1.0000 - val_loss: 0.4476 - val_accuracy: 0.8333\n",
      "Epoch 363/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 6.6006e-04 - accuracy: 1.0000 - val_loss: 0.4436 - val_accuracy: 0.8333\n",
      "Epoch 364/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 8.4910e-04 - accuracy: 1.0000 - val_loss: 0.4487 - val_accuracy: 0.8333\n",
      "Epoch 365/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 8.8303e-05 - accuracy: 1.0000 - val_loss: 0.4552 - val_accuracy: 0.8333\n",
      "Epoch 366/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.5065 - val_accuracy: 0.8333\n",
      "Epoch 367/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 1.5771e-04 - accuracy: 1.0000 - val_loss: 0.5280 - val_accuracy: 0.8333\n",
      "Epoch 368/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 1.8943e-04 - accuracy: 1.0000 - val_loss: 0.5372 - val_accuracy: 0.8333\n",
      "Epoch 369/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 1.3351e-04 - accuracy: 1.0000 - val_loss: 0.5408 - val_accuracy: 0.8333\n",
      "Epoch 370/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 1.0715e-04 - accuracy: 1.0000 - val_loss: 0.5423 - val_accuracy: 0.8333\n",
      "Epoch 371/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 3.7362e-04 - accuracy: 1.0000 - val_loss: 0.5331 - val_accuracy: 0.8333\n",
      "Epoch 372/500\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 5.2919e-04 - accuracy: 1.0000 - val_loss: 0.5218 - val_accuracy: 0.8333\n",
      "Epoch 373/500\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.5642e-04 - accuracy: 1.0000 - val_loss: 0.5150 - val_accuracy: 0.8333\n",
      "Epoch 374/500\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.1666e-04 - accuracy: 1.0000 - val_loss: 0.5110 - val_accuracy: 0.8333\n",
      "Epoch 375/500\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 9.6327e-05 - accuracy: 1.0000 - val_loss: 0.5087 - val_accuracy: 0.8333\n",
      "Epoch 376/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 5.5101e-04 - accuracy: 1.0000 - val_loss: 0.5131 - val_accuracy: 0.8333\n",
      "Epoch 377/500\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.5329e-04 - accuracy: 1.0000 - val_loss: 0.5179 - val_accuracy: 0.8333\n",
      "Epoch 378/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 2.1233e-04 - accuracy: 1.0000 - val_loss: 0.5207 - val_accuracy: 0.8333\n",
      "Epoch 379/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.6205 - val_accuracy: 0.8333\n",
      "Epoch 380/500\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 9.8845e-05 - accuracy: 1.0000 - val_loss: 0.6595 - val_accuracy: 0.8333\n",
      "Epoch 381/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.6581 - val_accuracy: 0.8333\n",
      "Epoch 382/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 1.0341e-04 - accuracy: 1.0000 - val_loss: 0.6446 - val_accuracy: 0.8333\n",
      "Epoch 383/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 1.1086e-04 - accuracy: 1.0000 - val_loss: 0.6372 - val_accuracy: 0.8333\n",
      "Epoch 384/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.7282 - val_accuracy: 0.8333\n",
      "Epoch 385/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.7411 - val_accuracy: 0.8333\n",
      "Epoch 386/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 1.6428e-04 - accuracy: 1.0000 - val_loss: 0.7347 - val_accuracy: 0.8333\n",
      "Epoch 387/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 2.0442e-04 - accuracy: 1.0000 - val_loss: 0.7296 - val_accuracy: 0.8333\n",
      "Epoch 388/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 4.3293e-05 - accuracy: 1.0000 - val_loss: 0.7268 - val_accuracy: 0.8333\n",
      "Epoch 389/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 2.5014e-04 - accuracy: 1.0000 - val_loss: 0.7248 - val_accuracy: 0.8333\n",
      "Epoch 390/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 9.4388e-04 - accuracy: 1.0000 - val_loss: 0.7165 - val_accuracy: 0.8333\n",
      "Epoch 391/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 4.9654e-04 - accuracy: 1.0000 - val_loss: 0.7105 - val_accuracy: 0.8333\n",
      "Epoch 392/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 6.5461e-05 - accuracy: 1.0000 - val_loss: 0.7034 - val_accuracy: 0.8333\n",
      "Epoch 393/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 8.2889e-05 - accuracy: 1.0000 - val_loss: 0.7002 - val_accuracy: 0.8333\n",
      "Epoch 394/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 5.8150e-04 - accuracy: 1.0000 - val_loss: 0.7012 - val_accuracy: 0.8333\n",
      "Epoch 395/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 8.6490e-04 - accuracy: 1.0000 - val_loss: 0.6955 - val_accuracy: 0.8333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 396/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 5.3277e-04 - accuracy: 1.0000 - val_loss: 0.6877 - val_accuracy: 0.8333\n",
      "Epoch 397/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 1.2965e-04 - accuracy: 1.0000 - val_loss: 0.6841 - val_accuracy: 0.8333\n",
      "Epoch 398/500\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 5.5062e-04 - accuracy: 1.0000 - val_loss: 0.6766 - val_accuracy: 0.8333\n",
      "Epoch 399/500\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 3.1901e-04 - accuracy: 1.0000 - val_loss: 0.6666 - val_accuracy: 0.8333\n",
      "Epoch 400/500\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 7.8411e-05 - accuracy: 1.0000 - val_loss: 0.6610 - val_accuracy: 0.8333\n",
      "Epoch 401/500\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.6707 - val_accuracy: 0.8333\n",
      "Epoch 402/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 1.8614e-04 - accuracy: 1.0000 - val_loss: 0.6913 - val_accuracy: 0.8333\n",
      "Epoch 403/500\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.6489e-04 - accuracy: 1.0000 - val_loss: 0.7003 - val_accuracy: 0.8333\n",
      "Epoch 404/500\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.1330e-04 - accuracy: 1.0000 - val_loss: 0.7026 - val_accuracy: 0.8333\n",
      "Epoch 405/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 8.7402e-05 - accuracy: 1.0000 - val_loss: 0.7044 - val_accuracy: 0.8333\n",
      "Epoch 406/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 1.8430e-04 - accuracy: 1.0000 - val_loss: 0.7034 - val_accuracy: 0.8333\n",
      "Epoch 407/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 2.2135e-04 - accuracy: 1.0000 - val_loss: 0.7007 - val_accuracy: 0.8333\n",
      "Epoch 408/500\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.0567e-04 - accuracy: 1.0000 - val_loss: 0.6979 - val_accuracy: 0.8333\n",
      "Epoch 409/500\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.2991e-04 - accuracy: 1.0000 - val_loss: 0.6913 - val_accuracy: 0.8333\n",
      "Epoch 410/500\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.4713e-04 - accuracy: 1.0000 - val_loss: 0.6860 - val_accuracy: 0.8333\n",
      "Epoch 411/500\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 3.5508e-04 - accuracy: 1.0000 - val_loss: 0.6801 - val_accuracy: 0.8333\n",
      "Epoch 412/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 8.8848e-05 - accuracy: 1.0000 - val_loss: 0.6742 - val_accuracy: 0.8333\n",
      "Epoch 413/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.6551 - val_accuracy: 0.8333\n",
      "Epoch 414/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 9.3529e-05 - accuracy: 1.0000 - val_loss: 0.6469 - val_accuracy: 0.8333\n",
      "Epoch 415/500\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.2429e-04 - accuracy: 1.0000 - val_loss: 0.6426 - val_accuracy: 0.8333\n",
      "Epoch 416/500\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.8499e-04 - accuracy: 1.0000 - val_loss: 0.6405 - val_accuracy: 0.8333\n",
      "Epoch 417/500\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.3530e-04 - accuracy: 1.0000 - val_loss: 0.6404 - val_accuracy: 0.8333\n",
      "Epoch 418/500\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.5779e-04 - accuracy: 1.0000 - val_loss: 0.6384 - val_accuracy: 0.8333\n",
      "Epoch 419/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 2.9263e-04 - accuracy: 1.0000 - val_loss: 0.6346 - val_accuracy: 0.8333\n",
      "Epoch 420/500\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 4.1773e-04 - accuracy: 1.0000 - val_loss: 0.6255 - val_accuracy: 0.8333\n",
      "Epoch 421/500\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 5.6956e-04 - accuracy: 1.0000 - val_loss: 0.6241 - val_accuracy: 0.8333\n",
      "Epoch 422/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 3.4911e-04 - accuracy: 1.0000 - val_loss: 0.6356 - val_accuracy: 0.8333\n",
      "Epoch 423/500\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.5732e-04 - accuracy: 1.0000 - val_loss: 0.6385 - val_accuracy: 0.8333\n",
      "Epoch 424/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 7.3378e-05 - accuracy: 1.0000 - val_loss: 0.6399 - val_accuracy: 0.8333\n",
      "Epoch 425/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 6.9490e-05 - accuracy: 1.0000 - val_loss: 0.6392 - val_accuracy: 0.8333\n",
      "Epoch 426/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 8.0021e-04 - accuracy: 1.0000 - val_loss: 0.6337 - val_accuracy: 0.8333\n",
      "Epoch 427/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 1.0995e-04 - accuracy: 1.0000 - val_loss: 0.6231 - val_accuracy: 0.8333\n",
      "Epoch 428/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 5.0420e-05 - accuracy: 1.0000 - val_loss: 0.6191 - val_accuracy: 0.8333\n",
      "Epoch 429/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 8.0814e-05 - accuracy: 1.0000 - val_loss: 0.6162 - val_accuracy: 0.8333\n",
      "Epoch 430/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 1.4069e-05 - accuracy: 1.0000 - val_loss: 0.6145 - val_accuracy: 0.8333\n",
      "Epoch 431/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 4.2392e-05 - accuracy: 1.0000 - val_loss: 0.6139 - val_accuracy: 0.8333\n",
      "Epoch 432/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 7.7462e-05 - accuracy: 1.0000 - val_loss: 0.6133 - val_accuracy: 0.8333\n",
      "Epoch 433/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 1.0343e-04 - accuracy: 1.0000 - val_loss: 0.6134 - val_accuracy: 0.8333\n",
      "Epoch 434/500\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.7759e-04 - accuracy: 1.0000 - val_loss: 0.6116 - val_accuracy: 0.8333\n",
      "Epoch 435/500\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.5734 - val_accuracy: 0.8333\n",
      "Epoch 436/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 1.7602e-04 - accuracy: 1.0000 - val_loss: 0.6205 - val_accuracy: 0.8333\n",
      "Epoch 437/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 7.5044e-05 - accuracy: 1.0000 - val_loss: 0.6385 - val_accuracy: 0.8333\n",
      "Epoch 438/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 3.0341e-04 - accuracy: 1.0000 - val_loss: 0.6392 - val_accuracy: 0.8333\n",
      "Epoch 439/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 5.2814e-05 - accuracy: 1.0000 - val_loss: 0.6388 - val_accuracy: 0.8333\n",
      "Epoch 440/500\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 4.7974e-05 - accuracy: 1.0000 - val_loss: 0.6373 - val_accuracy: 0.8333\n",
      "Epoch 441/500\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.2551e-05 - accuracy: 1.0000 - val_loss: 0.6360 - val_accuracy: 0.8333\n",
      "Epoch 442/500\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.1677e-04 - accuracy: 1.0000 - val_loss: 0.6347 - val_accuracy: 0.8333\n",
      "Epoch 443/500\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.8061 - val_accuracy: 0.8333\n",
      "Epoch 444/500\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.0896e-04 - accuracy: 1.0000 - val_loss: 0.9416 - val_accuracy: 0.8333\n",
      "Epoch 445/500\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.9624 - val_accuracy: 0.8333\n",
      "Epoch 446/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 9.4402e-05 - accuracy: 1.0000 - val_loss: 0.9291 - val_accuracy: 0.8333\n",
      "Epoch 447/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 1.0306e-04 - accuracy: 1.0000 - val_loss: 0.9131 - val_accuracy: 0.8333\n",
      "Epoch 448/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.9362 - val_accuracy: 0.8333\n",
      "Epoch 449/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.8987 - val_accuracy: 0.8333\n",
      "Epoch 450/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 8.7983e-05 - accuracy: 1.0000 - val_loss: 0.8349 - val_accuracy: 0.8333\n",
      "Epoch 451/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 9.8106e-05 - accuracy: 1.0000 - val_loss: 0.8080 - val_accuracy: 0.8333\n",
      "Epoch 452/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0268 - accuracy: 0.9722 - val_loss: 0.8428 - val_accuracy: 0.8333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 453/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 1.0493 - val_accuracy: 0.8333\n",
      "Epoch 454/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0245 - accuracy: 0.9722 - val_loss: 0.9703 - val_accuracy: 0.8333\n",
      "Epoch 455/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 1.4712e-04 - accuracy: 1.0000 - val_loss: 0.7408 - val_accuracy: 0.8333\n",
      "Epoch 456/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0107 - accuracy: 1.0000 - val_loss: 0.8115 - val_accuracy: 0.8333\n",
      "Epoch 457/500\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 6.6083e-05 - accuracy: 1.0000 - val_loss: 0.8483 - val_accuracy: 0.8333\n",
      "Epoch 458/500\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.8523 - val_accuracy: 0.8333\n",
      "Epoch 459/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 1.6735e-04 - accuracy: 1.0000 - val_loss: 0.8433 - val_accuracy: 0.8333\n",
      "Epoch 460/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 5.2753e-04 - accuracy: 1.0000 - val_loss: 0.8360 - val_accuracy: 0.8333\n",
      "Epoch 461/500\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 9.6543e-04 - accuracy: 1.0000 - val_loss: 0.8283 - val_accuracy: 0.8333\n",
      "Epoch 462/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.7941 - val_accuracy: 0.8333\n",
      "Epoch 463/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 7.8796e-05 - accuracy: 1.0000 - val_loss: 0.7742 - val_accuracy: 0.8333\n",
      "Epoch 464/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.7249 - val_accuracy: 0.8333\n",
      "Epoch 465/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 3.3041e-04 - accuracy: 1.0000 - val_loss: 0.7017 - val_accuracy: 0.8333\n",
      "Epoch 466/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 2.3474e-04 - accuracy: 1.0000 - val_loss: 0.6858 - val_accuracy: 0.8333\n",
      "Epoch 467/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 5.8308e-05 - accuracy: 1.0000 - val_loss: 0.6785 - val_accuracy: 0.8333\n",
      "Epoch 468/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 6.2607e-04 - accuracy: 1.0000 - val_loss: 0.6706 - val_accuracy: 0.8333\n",
      "Epoch 469/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 0.5619 - val_accuracy: 0.9167\n",
      "Epoch 470/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 6.0670e-04 - accuracy: 1.0000 - val_loss: 0.5352 - val_accuracy: 0.9167\n",
      "Epoch 471/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 1.0891e-04 - accuracy: 1.0000 - val_loss: 0.5189 - val_accuracy: 0.9167\n",
      "Epoch 472/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 0.4866 - val_accuracy: 0.9167\n",
      "Epoch 473/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 1.5688e-04 - accuracy: 1.0000 - val_loss: 0.4636 - val_accuracy: 0.9167\n",
      "Epoch 474/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 4.1545e-04 - accuracy: 1.0000 - val_loss: 0.4648 - val_accuracy: 0.9167\n",
      "Epoch 475/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 1.0415e-04 - accuracy: 1.0000 - val_loss: 0.4726 - val_accuracy: 0.9167\n",
      "Epoch 476/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 9.4979e-05 - accuracy: 1.0000 - val_loss: 0.4767 - val_accuracy: 0.9167\n",
      "Epoch 477/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.4885 - val_accuracy: 0.9167\n",
      "Epoch 478/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 1.9638e-04 - accuracy: 1.0000 - val_loss: 0.4965 - val_accuracy: 0.9167\n",
      "Epoch 479/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 1.8760e-04 - accuracy: 1.0000 - val_loss: 0.5020 - val_accuracy: 0.9167\n",
      "Epoch 480/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.5307 - val_accuracy: 0.9167\n",
      "Epoch 481/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 1.1891e-05 - accuracy: 1.0000 - val_loss: 0.5422 - val_accuracy: 0.9167\n",
      "Epoch 482/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 1.5911e-05 - accuracy: 1.0000 - val_loss: 0.5467 - val_accuracy: 0.9167\n",
      "Epoch 483/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 1.6289e-04 - accuracy: 1.0000 - val_loss: 0.5478 - val_accuracy: 0.9167\n",
      "Epoch 484/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 9.2670e-05 - accuracy: 1.0000 - val_loss: 0.5478 - val_accuracy: 0.9167\n",
      "Epoch 485/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 5.7928e-04 - accuracy: 1.0000 - val_loss: 0.5516 - val_accuracy: 0.9167\n",
      "Epoch 486/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 2.2321e-05 - accuracy: 1.0000 - val_loss: 0.5566 - val_accuracy: 0.9167\n",
      "Epoch 487/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 6.2053e-05 - accuracy: 1.0000 - val_loss: 0.5589 - val_accuracy: 0.9167\n",
      "Epoch 488/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 2.3040e-05 - accuracy: 1.0000 - val_loss: 0.5600 - val_accuracy: 0.9167\n",
      "Epoch 489/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 9.7479e-05 - accuracy: 1.0000 - val_loss: 0.5609 - val_accuracy: 0.9167\n",
      "Epoch 490/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 9.1202e-05 - accuracy: 1.0000 - val_loss: 0.5619 - val_accuracy: 0.9167\n",
      "Epoch 491/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 1.1758e-04 - accuracy: 1.0000 - val_loss: 0.5630 - val_accuracy: 0.9167\n",
      "Epoch 492/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 3.8716e-04 - accuracy: 1.0000 - val_loss: 0.5749 - val_accuracy: 0.9167\n",
      "Epoch 493/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 3.6021e-05 - accuracy: 1.0000 - val_loss: 0.5817 - val_accuracy: 0.9167\n",
      "Epoch 494/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 5.9424e-05 - accuracy: 1.0000 - val_loss: 0.5844 - val_accuracy: 0.9167\n",
      "Epoch 495/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 6.3346e-04 - accuracy: 1.0000 - val_loss: 0.6015 - val_accuracy: 0.9167\n",
      "Epoch 496/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 2.1385e-04 - accuracy: 1.0000 - val_loss: 0.6188 - val_accuracy: 0.9167\n",
      "Epoch 497/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 7.9085e-05 - accuracy: 1.0000 - val_loss: 0.6286 - val_accuracy: 0.9167\n",
      "Epoch 498/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 1.4965e-04 - accuracy: 1.0000 - val_loss: 0.6355 - val_accuracy: 0.9167\n",
      "Epoch 499/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 2.1505e-05 - accuracy: 1.0000 - val_loss: 0.6385 - val_accuracy: 0.9167\n",
      "Epoch 500/500\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 1.0934e-05 - accuracy: 1.0000 - val_loss: 0.6398 - val_accuracy: 0.9167\n"
     ]
    }
   ],
   "source": [
    "model = getNetwork()\n",
    "history = model.fit(X_train, y_train, epochs=EPOCHS, batch_size=BATCH_SIZE, validation_split=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.67      0.73         6\n",
      "           1       0.71      0.83      0.77         6\n",
      "\n",
      "    accuracy                           0.75        12\n",
      "   macro avg       0.76      0.75      0.75        12\n",
      "weighted avg       0.76      0.75      0.75        12\n",
      "\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '2Labels/classificationReports/reportNN.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-74-6f5515a903c7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mreport\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions_categorical\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreport\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mclassification_report_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreport\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"NN\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-68-d1d0d16ad903>\u001b[0m in \u001b[0;36mclassification_report_csv\u001b[0;34m(report, model_name)\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mdataframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreport_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mdataframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mchoosenIndex\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/classificationReports/\"\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m'report'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmodel_name\u001b[0m \u001b[0;34m+\u001b[0m  \u001b[0;34m'.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ts/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mto_csv\u001b[0;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, decimal, errors)\u001b[0m\n\u001b[1;32m   3168\u001b[0m             \u001b[0mdecimal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecimal\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3169\u001b[0m         )\n\u001b[0;32m-> 3170\u001b[0;31m         \u001b[0mformatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3172\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpath_or_buf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ts/lib/python3.6/site-packages/pandas/io/formats/csvs.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    188\u001b[0m                 \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m                 \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m                 \u001b[0mcompression\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompression_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompression\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    191\u001b[0m             )\n\u001b[1;32m    192\u001b[0m             \u001b[0mclose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ts/lib/python3.6/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors)\u001b[0m\n\u001b[1;32m    491\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mis_text\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0;31m# No explicit encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '2Labels/classificationReports/reportNN.csv'"
     ]
    }
   ],
   "source": [
    "pred_test = model.predict(X_test)\n",
    "predictions_categorical = np.argmax(pred_test, axis=1)\n",
    "report = classification_report(y_test, predictions_categorical)\n",
    "print(report)\n",
    "classification_report_csv(report, \"NN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export Models in C code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp5aw55c9c/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp5aw55c9c/assets\n"
     ]
    }
   ],
   "source": [
    "# Neural network with TinyMLGen\n",
    "with open(tasks[choosenIndex] + '/exportedModels/NNmodel.h', 'w') as f:\n",
    "    f.write(tiny.port(model, optimize=False))\n",
    "\n",
    "# Classifiers with MicroMLGen\n",
    "for name, model in models:\n",
    "    prepath = tasks[choosenIndex] + '/exportedModels/'\n",
    "    path = prepath + name + '.h'\n",
    "    x = port(model, optimize=True)\n",
    "    with open(path, 'w') as f:\n",
    "        f.write(port(model, optimize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
